{
    "id_table_1": {
        "caption": "Table 1: A comparison of transformer based methods for 2D body pose estimation with direct regression. Both TFPose [8] and PRTR [7] models use a Resnet50 for backbone. The dataset is COCO2017-Val. Flip test is used on all methods. The decoder depth for all models is 666. Note: the code for TFPose [8] is not available and the model is not provided by the authors, so the number of parameters is unknown. In our work the “-Dino” suffix denotes the use of unsupervised pretraining, Xcit refers to Xcit-small-12, and Deit refers to Deit-small.",
        "table": [
            "<table id=\"S4.T1.3\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T1.3.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S4.T1.3.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>&#13;\n<th id=\"S4.T1.3.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.1.1.2.1\" class=\"ltx_text ltx_font_bold\">Input size</span></th>&#13;\n<th id=\"S4.T1.3.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.1.1.3.1\" class=\"ltx_text ltx_font_bold\">#Parameters</span></th>&#13;\n<th id=\"S4.T1.3.1.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.1.1.4.1\" class=\"ltx_text ltx_font_bold\">AP</span></th>&#13;\n<th id=\"S4.T1.3.1.1.5\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T1.3.1.1.5.1\" class=\"ltx_text ltx_font_bold\">AR</span></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T1.3.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">TFPose</th>&#13;\n<td id=\"S4.T1.3.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">192x256</td>&#13;\n<td id=\"S4.T1.3.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">&#8211;</td>&#13;\n<td id=\"S4.T1.3.2.1.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">71.0</td>&#13;\n<td id=\"S4.T1.3.2.1.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">&#8211;</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">TFPose</th>&#13;\n<td id=\"S4.T1.3.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">288x384</td>&#13;\n<td id=\"S4.T1.3.3.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">&#8211;</td>&#13;\n<td id=\"S4.T1.3.3.2.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">72.4</td>&#13;\n<td id=\"S4.T1.3.3.2.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">&#8211;</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">PRTR</th>&#13;\n<td id=\"S4.T1.3.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">288x384</td>&#13;\n<td id=\"S4.T1.3.4.3.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">41.5M</td>&#13;\n<td id=\"S4.T1.3.4.3.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">68.2</td>&#13;\n<td id=\"S4.T1.3.4.3.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">76</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">PRTR</th>&#13;\n<td id=\"S4.T1.3.5.4.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">384x512</td>&#13;\n<td id=\"S4.T1.3.5.4.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">41.5M</td>&#13;\n<td id=\"S4.T1.3.5.4.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">71.0</td>&#13;\n<td id=\"S4.T1.3.5.4.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">78</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">OURS-Deit-dino-p8</th>&#13;\n<td id=\"S4.T1.3.6.5.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">192x256</td>&#13;\n<td id=\"S4.T1.3.6.5.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">36.4M</td>&#13;\n<td id=\"S4.T1.3.6.5.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">70.6</td>&#13;\n<td id=\"S4.T1.3.6.5.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">78.1</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">OURS-Xcit-p16</th>&#13;\n<td id=\"S4.T1.3.7.6.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">288x384</td>&#13;\n<td id=\"S4.T1.3.7.6.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">40.6M</td>&#13;\n<td id=\"S4.T1.3.7.6.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">70.2</td>&#13;\n<td id=\"S4.T1.3.7.6.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">77.4</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.8.7\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">OURS-Xcit-dino-p16</th>&#13;\n<td id=\"S4.T1.3.8.7.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">288x384</td>&#13;\n<td id=\"S4.T1.3.8.7.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">40.6M</td>&#13;\n<td id=\"S4.T1.3.8.7.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">70.7</td>&#13;\n<td id=\"S4.T1.3.8.7.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">77.9</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.9.8\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">OURS-Xcit-dino-p8</th>&#13;\n<td id=\"S4.T1.3.9.8.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">192x256</td>&#13;\n<td id=\"S4.T1.3.9.8.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">40.5M</td>&#13;\n<td id=\"S4.T1.3.9.8.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">71.6</td>&#13;\n<td id=\"S4.T1.3.9.8.5\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">78.7</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T1.3.10.9\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T1.3.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">OURS-Xcit-dino-p8</th>&#13;\n<td id=\"S4.T1.3.10.9.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">288x384</td>&#13;\n<td id=\"S4.T1.3.10.9.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">40.5M</td>&#13;\n<td id=\"S4.T1.3.10.9.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">72.6</td>&#13;\n<td id=\"S4.T1.3.10.9.5\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">79.4</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[8] [8]\r\n\r\nMao, W., Ge, Y., Shen, C., Tian, Z., Wang, X., Wang, Z.: Tfpose: Direct human\r\npose estimation with transformers. arXiv preprint arXiv:2103.15320 (2021)",
            "[7] [7]\r\n\r\nLi, K., Wang, S., Zhang, X., Xu, Y., Xu, W., Tu, Z.: Pose recognition with\r\ncascade transformers. In: Proceedings of the IEEE/CVF Conference on Computer\r\nVision and Pattern Recognition. pp. 1944–1953 (2021)",
            "[8] [8]\r\n\r\nMao, W., Ge, Y., Shen, C., Tian, Z., Wang, X., Wang, Z.: Tfpose: Direct human\r\npose estimation with transformers. arXiv preprint arXiv:2103.15320 (2021)"
        ],
        "references": [
            "As shown in Table 1, our architecture performs on par or surpasses methods that use CNN backbones for the same task. Using the DEIT encoder requires more memory and CPU resources although the number of parameters is relatively low. Due to the increased requirements, we limit our comparison tests of DEIT to 192×256192256192\\times 256 resolution for patch sizes of 8×8888\\times 8 pixels.",
            "Table 3 presents the obtained results.\r\nFor the purposes of our evaluation we train two Deit (deit-small) and two Xcit (xcit-small-12) variants. For all variants, input resolution of 192×256192256192\\times 256 and patch size is set to 16×16161616\\times 16. All hyperparameters are kept the same. We initialize the encoders of the Dino\r\nvariants using weights acquired with unsupervised learning on Imagenet. In contrast, the normal variants start with encoders initialized with weights acquired with supervised learning on Imagenet. For both Deit and Xcit we observe significant improvement on the performance.\r\nHowever, the amount of improvement drops as the overall performance of the network gets higher (see the entries of Table 1 for OURS-Xcit-p16 and OURS-Xcit-dino-p16)."
        ]
    },
    "id_table_2": {
        "caption": "Table 2: Encoder Comparison. Deit vs Xcit vs resnet50 vs VAB.\r\nFor all experiments the patch size is set to 16×16161616\\times 16 pixels. Input resolution is 192×256192256192\\times 256.\r\nAll Networks are trained and evaluated on the COCO val dataset. Deit performs worse while also having the smallest number of parameters. Xcit is the best performing overall, however it also has 10%percent1010\\% more parameters than Deit.",
        "table": [
            "<table id=\"S4.T2.7\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T2.7.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T2.7.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S4.T2.7.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>&#13;\n<th id=\"S4.T2.7.1.1.2\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.7.1.1.2.1\" class=\"ltx_text ltx_font_bold\">#Parameters</span></th>&#13;\n<th id=\"S4.T2.7.1.1.3\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.7.1.1.3.1\" class=\"ltx_text ltx_font_bold\">AP</span></th>&#13;\n<th id=\"S4.T2.7.1.1.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T2.7.1.1.4.1\" class=\"ltx_text ltx_font_bold\">AR</span></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T2.7.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T2.7.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Resnet50-PE-former</th>&#13;\n<td id=\"S4.T2.7.2.1.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">39.0M</td>&#13;\n<td id=\"S4.T2.7.2.1.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">63.4</td>&#13;\n<td id=\"S4.T2.7.2.1.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_tt\">72.2</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.7.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T2.7.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">VAB</th>&#13;\n<td id=\"S4.T2.7.3.2.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">47.4M</td>&#13;\n<td id=\"S4.T2.7.3.2.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">63.2</td>&#13;\n<td id=\"S4.T2.7.3.2.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">72.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.7.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T2.7.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Deit</th>&#13;\n<td id=\"S4.T2.7.4.3.2\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">36.4M</td>&#13;\n<td id=\"S4.T2.7.4.3.3\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">62.2</td>&#13;\n<td id=\"S4.T2.7.4.3.4\" class=\"ltx_td ltx_align_right ltx_border_r ltx_border_t\">71.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.7.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T2.7.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">Xcit</th>&#13;\n<td id=\"S4.T2.7.5.4.2\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">40.6M</td>&#13;\n<td id=\"S4.T2.7.5.4.3\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">66.2</td>&#13;\n<td id=\"S4.T2.7.5.4.4\" class=\"ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t\">74.6</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "We evaluate the performance of a transformer based encoder (Deit, Xcit) versus a\r\nCNN (Resnet50) based encoder and a VAB model. The networks are trained on COCO\r\nand evaluated on the COCO2017-val.\r\nFor all the encoders, the imagenet pretrained weights are used. The results are shown in Table 2. The networks are trained with an input resolution of 192×256192256192\\times 256 and patch size of 16×16161616\\times 16 pixels.\r\nApart from replacing the encoders, the rest of the model (decoder) and training hyperparameters are kept the same."
        ]
    },
    "id_table_3": {
        "caption": "Table 3: Comparison of Unsupervised Dino weight init.\r\nPatch size is set to 161616 and input size is 192×256192256192\\times 256. Dino networks are\r\nidentical but initialized with the weights of networks trained with the dino unsupervised methodology. Networks are trained and evaluated on the COCO val dataset. Interestingly, the Resnet50 variant does not show the same improvements as the attention-based encoders with unsupervised pre-training.",
        "table": [
            "<table id=\"S4.T3.5\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T3.5.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\"><span id=\"S4.T3.5.1.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>&#13;\n<th id=\"S4.T3.5.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T3.5.1.1.2.1\" class=\"ltx_text ltx_font_bold\"># Parameters</span></th>&#13;\n<th id=\"S4.T3.5.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T3.5.1.1.3.1\" class=\"ltx_text ltx_font_bold\">AP</span></th>&#13;\n<th id=\"S4.T3.5.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\"><span id=\"S4.T3.5.1.1.4.1\" class=\"ltx_text ltx_font_bold\">AR</span></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T3.5.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Deit</th>&#13;\n<td id=\"S4.T3.5.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">36.4M</td>&#13;\n<td id=\"S4.T3.5.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">62.2</td>&#13;\n<td id=\"S4.T3.5.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">71.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.5.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Dino Deit</th>&#13;\n<td id=\"S4.T3.5.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">36.4M</td>&#13;\n<td id=\"S4.T3.5.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.7</td>&#13;\n<td id=\"S4.T3.5.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">75.0</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.5.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Xcit</th>&#13;\n<td id=\"S4.T3.5.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40.6M</td>&#13;\n<td id=\"S4.T3.5.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">66.2</td>&#13;\n<td id=\"S4.T3.5.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">74.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.5.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t\">Dino Xcit</th>&#13;\n<td id=\"S4.T3.5.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40.6M</td>&#13;\n<td id=\"S4.T3.5.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">68.0</td>&#13;\n<td id=\"S4.T3.5.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.1</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.5.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_tt\">Resnet50-PE-former</th>&#13;\n<td id=\"S4.T3.5.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">39.0M</td>&#13;\n<td id=\"S4.T3.5.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">63.4</td>&#13;\n<td id=\"S4.T3.5.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">72.2</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.5.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.5.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_rr ltx_border_t\">Dino Resnet50-PE-former</th>&#13;\n<td id=\"S4.T3.5.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">39.0M</td>&#13;\n<td id=\"S4.T3.5.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">61.0</td>&#13;\n<td id=\"S4.T3.5.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">70.1</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "Table 3 presents the obtained results.\r\nFor the purposes of our evaluation we train two Deit (deit-small) and two Xcit (xcit-small-12) variants. For all variants, input resolution of 192×256192256192\\times 256 and patch size is set to 16×16161616\\times 16. All hyperparameters are kept the same. We initialize the encoders of the Dino\r\nvariants using weights acquired with unsupervised learning on Imagenet. In contrast, the normal variants start with encoders initialized with weights acquired with supervised learning on Imagenet. For both Deit and Xcit we observe significant improvement on the performance.\r\nHowever, the amount of improvement drops as the overall performance of the network gets higher (see the entries of Table 1 for OURS-Xcit-p16 and OURS-Xcit-dino-p16)."
        ]
    }
}