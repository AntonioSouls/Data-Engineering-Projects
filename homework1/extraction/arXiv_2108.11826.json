{
    "id_table_1": {
        "caption": "Table 1. API study. * denotes single-human datasets only.",
        "table": [
            "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_border_tt\"/>&#13;\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Algorithm</th>&#13;\n<th id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Dataset</th>&#13;\n<th id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">DNN</th>&#13;\n<th id=\"S3.T1.1.1.1.5\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Config.</th>&#13;\n<th id=\"S3.T1.1.1.1.6\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt\">Ext.</th>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_align_left ltx_border_t\">TF-Pose</td>&#13;\n<td id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>&#13;\n<td id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_align_left ltx_border_t\">1</td>&#13;\n<td id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_align_left ltx_border_t\">5</td>&#13;\n<td id=\"S3.T1.1.2.2.5\" class=\"ltx_td ltx_align_left ltx_border_t\">5</td>&#13;\n<td id=\"S3.T1.1.2.2.6\" class=\"ltx_td ltx_align_left ltx_border_t\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.3.3\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.1.3.3.1\" class=\"ltx_td ltx_align_left\">PyTorch-Pose</td>&#13;\n<td id=\"S3.T1.1.3.3.2\" class=\"ltx_td ltx_align_left\">2</td>&#13;\n<td id=\"S3.T1.1.3.3.3\" class=\"ltx_td ltx_align_left\">3*</td>&#13;\n<td id=\"S3.T1.1.3.3.4\" class=\"ltx_td ltx_align_left\">13</td>&#13;\n<td id=\"S3.T1.1.3.3.5\" class=\"ltx_td ltx_align_left\">26</td>&#13;\n<td id=\"S3.T1.1.3.3.6\" class=\"ltx_td ltx_align_left\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.4.4\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_border_bb\"><span id=\"S3.T1.1.4.4.1.1\" class=\"ltx_text ltx_font_bold\">HyperPose</span></td>&#13;\n<td id=\"S3.T1.1.4.4.2\" class=\"ltx_td ltx_align_left ltx_border_bb\">3</td>&#13;\n<td id=\"S3.T1.1.4.4.3\" class=\"ltx_td ltx_align_left ltx_border_bb\">2</td>&#13;\n<td id=\"S3.T1.1.4.4.4\" class=\"ltx_td ltx_align_left ltx_border_bb\">10</td>&#13;\n<td id=\"S3.T1.1.4.4.5\" class=\"ltx_td ltx_align_left ltx_border_bb\">30</td>&#13;\n<td id=\"S3.T1.1.4.4.6\" class=\"ltx_td ltx_align_left ltx_border_bb\">&#10003;</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "In Table 1,\r\nour comparison follows five metrics:\r\n(i) the number of pre-defined pose estimation algorithms, (ii) the number of pre-defined datasets,\r\n(iii) the number of pre-defined backbone deep neural networks (DNNs),\r\n(iv) the total number of pre-defined\r\nconfigurations of the pose estimation system, and (v) the ability\r\nto extend the library to support custom algorithms."
        ]
    },
    "id_table_2": {
        "caption": "Table 2. Performance Evaluation of Inference Engine. 444For fair accuracy comparison, the weights are from PifPaf and PoseProposal libraries.",
        "table": [
            "<table id=\"S3.T2.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S3.T2.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Configuration</th>&#13;\n<th id=\"S3.T2.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">&#13;\n<table id=\"S3.T2.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T2.1.1.1.2.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Baseline</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.2.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">FPS</td>&#13;\n</tr>&#13;\n</table>&#13;\n</th>&#13;\n<th id=\"S3.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">&#13;\n<table id=\"S3.T2.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T2.1.1.1.3.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Our FPS</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.3.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(Operators)</td>&#13;\n</tr>&#13;\n</table>&#13;\n</th>&#13;\n<th id=\"S3.T2.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">&#13;\n<table id=\"S3.T2.1.1.1.4.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T2.1.1.1.4.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Our FPS</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.4.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(Scheduler)</td>&#13;\n</tr>&#13;\n</table>&#13;\n</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T2.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">OpenPose (VGG19)</th>&#13;\n<td id=\"S3.T2.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">8<cite class=\"ltx_cite ltx_citemacro_citep\">(Gin&#233;s Hidalgo, <a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2020</a>)</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">19.78</td>&#13;\n<td id=\"S3.T2.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S3.T2.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">27.32</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">OpenPose (MobileNet)</th>&#13;\n<td id=\"S3.T2.1.3.2.2\" class=\"ltx_td ltx_align_center\">8.5<cite class=\"ltx_cite ltx_citemacro_citep\">(Ildoo&#160;Kim, <a href=\"#bib.bib9\" title=\"\" class=\"ltx_ref\">2019</a>)</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.1.3.2.3\" class=\"ltx_td ltx_align_center\">50.89</td>&#13;\n<td id=\"S3.T2.1.3.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.1.3.2.4.1\" class=\"ltx_text ltx_font_bold\">84.32</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">LWOpenPose (ResNet50)</th>&#13;\n<td id=\"S3.T2.1.4.3.2\" class=\"ltx_td ltx_align_center\">N/A</td>&#13;\n<td id=\"S3.T2.1.4.3.3\" class=\"ltx_td ltx_align_center\">38.09</td>&#13;\n<td id=\"S3.T2.1.4.3.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.1.4.3.4.1\" class=\"ltx_text ltx_font_bold\">63.52</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">LWOpenPose (TinyVGG)</th>&#13;\n<td id=\"S3.T2.1.5.4.2\" class=\"ltx_td ltx_align_center\">N/A</td>&#13;\n<td id=\"S3.T2.1.5.4.3\" class=\"ltx_td ltx_align_center\">66.62</td>&#13;\n<td id=\"S3.T2.1.5.4.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.1.5.4.4.1\" class=\"ltx_text ltx_font_bold\">124.92</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">PoseProposal (ResNet18)</th>&#13;\n<td id=\"S3.T2.1.6.5.2\" class=\"ltx_td ltx_align_center\">47.6<cite class=\"ltx_cite ltx_citemacro_citep\">(Terasaki, <a href=\"#bib.bib17\" title=\"\" class=\"ltx_ref\">2018</a>)</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.1.6.5.3\" class=\"ltx_td ltx_align_center\">212.42</td>&#13;\n<td id=\"S3.T2.1.6.5.4\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.1.6.5.4.1\" class=\"ltx_text ltx_font_bold\">349.17</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">PifPaf (ResNet50)</th>&#13;\n<td id=\"S3.T2.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">14.8<cite class=\"ltx_cite ltx_citemacro_citep\">(Sven Kreiss, <a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">2021</a>)</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">18.5</td>&#13;\n<td id=\"S3.T2.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_bb\"><span id=\"S3.T2.1.7.6.4.1\" class=\"ltx_text ltx_font_bold\">44.13</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n",
            "<table id=\"S3.T2.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T2.1.1.1.2.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Baseline</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.2.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">FPS</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n",
            "<table id=\"S3.T2.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T2.1.1.1.3.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Our FPS</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.3.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(Operators)</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n",
            "<table id=\"S3.T2.1.1.1.4.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T2.1.1.1.4.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.4.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Our FPS</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.4.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.1.1.1.4.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">(Scheduler)</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "(Ginés Hidalgo, 2020) Ginés Hidalgo (2020)\r\n\r\nGinés Hidalgo 2020.\r\n\r\n\r\nOpenPose: Real-time multi-person keypoint\r\ndetection library.\r\n\r\n\r\n\r\nhttps://github.com/CMU-Perceptual-Computing-Lab/openpose",
            "(Ildoo Kim, 2019) Ildoo Kim (2019)\r\n\r\nDongwoo Kim Ildoo Kim.\r\n2019.\r\n\r\n\r\ntf-pose-estimation.\r\n\r\n\r\n\r\nRetrieved June 7, 2021 from https://github.com/ildoonet/tf-pose-estimation",
            "(Terasaki, 2018) Terasaki (2018)\r\n\r\nSatoshi Terasaki.\r\n2018.\r\n\r\n\r\nChainer implementation of Pose Proposal\r\nNetworks.\r\n\r\n\r\n\r\nhttps://github.com/Idein/chainer-pose-proposal-net",
            "(Sven Kreiss, 2021) Sven Kreiss (2021)\r\n\r\nSven Kreiss 2021.\r\n\r\n\r\nOpenPifPaf: Composite Fields for Semantic\r\nKeypoint Detection and Spatio-Temporal Association.\r\n\r\n\r\n\r\nhttps://github.com/openpifpaf/openpifpaf"
        ],
        "references": [
            "Table 4 compares the existing libraries and HyperPose.\r\nAll benchmarks are evaluated under the same configuration.\r\nThe test-bed is of 6 CPU cores and 1 NVIDIA 1070Ti GPU.\r\nWe measure the throughput of the pose estimation systems.\r\nThe benchmark video stream comes from the Crazy Uptown Funk Flashmob in Sydney which contains 7458 frames with 640x360 resolution.",
            "We first compare the performance of HyperPose with the OpenPose framework (Cao\r\net al., 2017),\r\nwhich leverages Caffe as its backend and uses C++ for implementing pre-processing and post-processing.\r\nAs is shown in Table 4, OpenPose is only able to achieve 8 FPS on 1070 Ti, which HyperPose can reach 27.32 FPS, outperforming the baseline by 3.1x.\r\nOn one hand, this improvement is attributed to the careful use of the TensorRT library as the implementation of the inference operator.\r\nOn the other hand, the hybrid dataflow operator scheduler makes the execution of HyperPose even 1.38x faster than the non-scheduled one.\r\nTF-Pose (Ildoo Kim, 2019) leverages TensorFlow as its inference engine and its post-processing is implemented in C++ as well.\r\nWhen executing MobileNet-based OpenPose, it only achieves 8.5 FPS, which is 10x slower than HyperPose."
        ]
    },
    "id_table_3": {
        "caption": "Table 3. Accuracy Evaluation of Development Platform.",
        "table": [
            "<table id=\"S3.T3.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S3.T3.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt\">Configuration</th>&#13;\n<th id=\"S3.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">&#13;\n<table id=\"S3.T3.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T3.1.1.1.2.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Original</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.1.1.2.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Accuracy(map)</td>&#13;\n</tr>&#13;\n</table>&#13;\n</th>&#13;\n<th id=\"S3.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\">&#13;\n<table id=\"S3.T3.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T3.1.1.1.3.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Our</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.1.1.3.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Accuracy(map)</td>&#13;\n</tr>&#13;\n</table>&#13;\n</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T3.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T3.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t\">OpenPose (VGG19)</th>&#13;\n<td id=\"S3.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">58.4</td>&#13;\n<td id=\"S3.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">57.0</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T3.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">OpenPose (MobileNet)</th>&#13;\n<td id=\"S3.T3.1.3.2.2\" class=\"ltx_td ltx_align_center\">28.1</td>&#13;\n<td id=\"S3.T3.1.3.2.3\" class=\"ltx_td ltx_align_center\">44.2</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T3.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">LWOpenPose (MobileNet)</th>&#13;\n<td id=\"S3.T3.1.4.3.2\" class=\"ltx_td ltx_align_center\">42.8</td>&#13;\n<td id=\"S3.T3.1.4.3.3\" class=\"ltx_td ltx_align_center\">46.1</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T3.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row\">LWOpenPose (Resnet50)</th>&#13;\n<td id=\"S3.T3.1.5.4.2\" class=\"ltx_td ltx_align_center\">N/A</td>&#13;\n<td id=\"S3.T3.1.5.4.3\" class=\"ltx_td ltx_align_center\">48.2</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T3.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb\">LWOpenPose (TinyVGG)</th>&#13;\n<td id=\"S3.T3.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_bb\">N/A</td>&#13;\n<td id=\"S3.T3.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_bb\">47.3</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n",
            "<table id=\"S3.T3.1.1.1.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T3.1.1.1.2.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Original</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.1.1.2.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Accuracy(map)</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n",
            "<table id=\"S3.T3.1.1.1.3.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tr id=\"S3.T3.1.1.1.3.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.3.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Our</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T3.1.1.1.3.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T3.1.1.1.3.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Accuracy(map)</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "In addition to OpenPose-based algorithms, HyperPose also outperforms Chainer’s (Terasaki, 2018) implementation of Pose Proposal Network by 8 times.\r\nWe verified the performance consistency by replacing the backbones and post-processing methods. For example, HyperPose also beats OpenPose when evaluating a smaller model (i.e., MobileNet).\r\nThis proves that the execution engine design is generic so that its benefits should be shared by all custom algorithms. Table 3 shows the accuracy evaluation result of HyperPose."
        ]
    }
}