{
    "id_table_1": {
        "caption": "Table 1: Performance on NOCS-CAMERA dataset.",
        "table": [
            "<table id=\"S3.T1.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S3.T1.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Data</th>&#13;\n<th id=\"S3.T1.4.4.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Methods</th>&#13;\n<th id=\"S3.T1.4.4.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU50</th>&#13;\n<th id=\"S3.T1.4.4.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU75</th>&#13;\n<th id=\"S3.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S3.T1.1.1.1.1\" class=\"ltx_sup\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S3.T1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S3.T1.2.2.2.1\" class=\"ltx_sup\"><span id=\"S3.T1.2.2.2.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n<th id=\"S3.T1.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10<sup id=\"S3.T1.3.3.3.1\" class=\"ltx_sup\"><span id=\"S3.T1.3.3.3.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S3.T1.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">10<sup id=\"S3.T1.4.4.4.1\" class=\"ltx_sup\"><span id=\"S3.T1.4.4.4.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T1.4.5.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"4\"><span id=\"S3.T1.4.5.1.1.1\" class=\"ltx_text\">CAMERA</span></td>&#13;\n<td id=\"S3.T1.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NOCS<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib43\" title=\"\" class=\"ltx_ref\">43</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T1.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">83.9</td>&#13;\n<td id=\"S3.T1.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">69.5</td>&#13;\n<td id=\"S3.T1.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.3</td>&#13;\n<td id=\"S3.T1.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">40.9</td>&#13;\n<td id=\"S3.T1.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">48.2</td>&#13;\n<td id=\"S3.T1.4.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">64.6</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.4.6.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T1.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">93.2</td>&#13;\n<td id=\"S3.T1.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">83.1</td>&#13;\n<td id=\"S3.T1.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">54.3</td>&#13;\n<td id=\"S3.T1.4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">59.0</td>&#13;\n<td id=\"S3.T1.4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">73.3</td>&#13;\n<td id=\"S3.T1.4.6.2.7\" class=\"ltx_td ltx_align_center\">81.5</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.4.7.3\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">DualPoseNet<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T1.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">92.4</td>&#13;\n<td id=\"S3.T1.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">86.4</td>&#13;\n<td id=\"S3.T1.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">64.7</td>&#13;\n<td id=\"S3.T1.4.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">70.7</td>&#13;\n<td id=\"S3.T1.4.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">77.2</td>&#13;\n<td id=\"S3.T1.4.7.3.7\" class=\"ltx_td ltx_align_center\">84.7</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.4.8.4\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.4.8.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FS-Net<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T1.4.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T1.4.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">85.2</td>&#13;\n<td id=\"S3.T1.4.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T1.4.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">62.0</td>&#13;\n<td id=\"S3.T1.4.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T1.4.8.4.7\" class=\"ltx_td ltx_align_center\">60.8</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.4.9.5\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T1.4.9.5.1\" class=\"ltx_td ltx_border_b ltx_border_r\"/>&#13;\n<td id=\"S3.T1.4.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">ACR-Pose(Ours)</td>&#13;\n<td id=\"S3.T1.4.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T1.4.9.5.3.1\" class=\"ltx_text ltx_font_bold\">93.8</span></td>&#13;\n<td id=\"S3.T1.4.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T1.4.9.5.4.1\" class=\"ltx_text ltx_font_bold\">89.9</span></td>&#13;\n<td id=\"S3.T1.4.9.5.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T1.4.9.5.5.1\" class=\"ltx_text ltx_font_bold\">70.4</span></td>&#13;\n<td id=\"S3.T1.4.9.5.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T1.4.9.5.6.1\" class=\"ltx_text ltx_font_bold\">74.1</span></td>&#13;\n<td id=\"S3.T1.4.9.5.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T1.4.9.5.7.1\" class=\"ltx_text ltx_font_bold\">82.6</span></td>&#13;\n<td id=\"S3.T1.4.9.5.8\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S3.T1.4.9.5.8.1\" class=\"ltx_text ltx_font_bold\">87.8</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[43] [43]\r\n\r\nHe Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran Song, and\r\nLeonidas J Guibas.\r\n\r\n\r\nNormalized object coordinate space for category-level 6d object pose\r\nand size estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition, pages 2642–2651, 2019.",
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020.",
            "[23] [23]\r\n\r\nJiehong Lin, Zewei Wei, Zhihao Li, Songcen Xu, Kui Jia, and Yuanqing Li.\r\n\r\n\r\nDualposenet: Category-level 6d object pose and size estimation using\r\ndual pose network with refined learning of pose consistency.\r\n\r\n\r\narXiv preprint arXiv:2103.06526, 2021.",
            "[6] [6]\r\n\r\nWei Chen, Xi Jia, Hyung Jin Chang, Jinming Duan, Linlin Shen, and Ales\r\nLeonardis.\r\n\r\n\r\nFs-net: Fast shape-based network for category-level 6d object pose\r\nestimation with decoupled rotation mechanism.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition, pages 1581–1590, 2021."
        ],
        "references": [
            "Results on NOCS-CAMERA: Table 1 shows the result of our method and the results of all competitors on the val set of NOCS-CAMERA. It is obvious that our method outperforms all the strong baselines for a large margin. For example, SPD [38] shares the same backbone and the same Shape Prior Deformation step as our work, however, it is outperformed by our ACR-Pose by 16.3%, 15.1%, 9.3% and 6.3% in terms of the 5∘2cm, 5∘5cm, 10∘2cm and 10∘5cm, respectively, which is a significant improvement. The comparison between SPD [38] and our method demonstrates that the improvement really comes from our adversarial reconstruction scheme, which also benefits from the two proposed modules in the Reconstructor. They have increased our model’s 6D object pose estimation performance by increasing the reconstruction quality and reality of the NOCS representations through adversarial training. Our method also outperforms the second-best method DualPoseNet [23] by 5.7%, 3.4%, 4.6%, 3.1% at the above four metrics respectively, which is also a great improvement. This further proves the effectiveness our method."
        ]
    },
    "id_table_2": {
        "caption": "Table 2: Performance on NOCS-REAL dataset.",
        "table": [
            "<table id=\"S3.T2.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S3.T2.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Data</th>&#13;\n<th id=\"S3.T2.4.4.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Methods</th>&#13;\n<th id=\"S3.T2.4.4.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU50</th>&#13;\n<th id=\"S3.T2.4.4.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU75</th>&#13;\n<th id=\"S3.T2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S3.T2.1.1.1.1\" class=\"ltx_sup\"><span id=\"S3.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S3.T2.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S3.T2.2.2.2.1\" class=\"ltx_sup\"><span id=\"S3.T2.2.2.2.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n<th id=\"S3.T2.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10<sup id=\"S3.T2.3.3.3.1\" class=\"ltx_sup\"><span id=\"S3.T2.3.3.3.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S3.T2.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">10<sup id=\"S3.T2.4.4.4.1\" class=\"ltx_sup\"><span id=\"S3.T2.4.4.4.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T2.4.5.1\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"6\"><span id=\"S3.T2.4.5.1.1.1\" class=\"ltx_text\">REAL</span></td>&#13;\n<td id=\"S3.T2.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">NOCS<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib43\" title=\"\" class=\"ltx_ref\">43</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.0</td>&#13;\n<td id=\"S3.T2.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30.1</td>&#13;\n<td id=\"S3.T2.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7.2</td>&#13;\n<td id=\"S3.T2.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">10.0</td>&#13;\n<td id=\"S3.T2.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">13.8</td>&#13;\n<td id=\"S3.T2.4.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">25.2</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.4.6.2\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">CASS<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">77.7</td>&#13;\n<td id=\"S3.T2.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T2.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T2.4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">23.5</td>&#13;\n<td id=\"S3.T2.4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T2.4.6.2.7\" class=\"ltx_td ltx_align_center\">58.0</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.4.7.3\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">77.3</td>&#13;\n<td id=\"S3.T2.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">53.2</td>&#13;\n<td id=\"S3.T2.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">19.3</td>&#13;\n<td id=\"S3.T2.4.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">21.4</td>&#13;\n<td id=\"S3.T2.4.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">43.2</td>&#13;\n<td id=\"S3.T2.4.7.3.7\" class=\"ltx_td ltx_align_center\">54.1</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.4.8.4\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.4.8.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">DualPoseNet<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\">23</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.4.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">79.8</td>&#13;\n<td id=\"S3.T2.4.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">62.2</td>&#13;\n<td id=\"S3.T2.4.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">29.3</td>&#13;\n<td id=\"S3.T2.4.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">35.9</td>&#13;\n<td id=\"S3.T2.4.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\">50.0</td>&#13;\n<td id=\"S3.T2.4.8.4.7\" class=\"ltx_td ltx_align_center\"><span id=\"S3.T2.4.8.4.7.1\" class=\"ltx_text ltx_font_bold\">66.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.4.9.5\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.4.9.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">FS-Net<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">6</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.4.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S3.T2.4.9.5.2.1\" class=\"ltx_text ltx_font_bold\">92.2</span></td>&#13;\n<td id=\"S3.T2.4.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">63.5</td>&#13;\n<td id=\"S3.T2.4.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T2.4.9.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\">28.2</td>&#13;\n<td id=\"S3.T2.4.9.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S3.T2.4.9.5.7\" class=\"ltx_td ltx_align_center\">60.8</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.4.10.6\" class=\"ltx_tr\">&#13;\n<td id=\"S3.T2.4.10.6.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">ACR-Pose(Ours)</td>&#13;\n<td id=\"S3.T2.4.10.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">82.8</td>&#13;\n<td id=\"S3.T2.4.10.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T2.4.10.6.3.1\" class=\"ltx_text ltx_font_bold\">66.0</span></td>&#13;\n<td id=\"S3.T2.4.10.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T2.4.10.6.4.1\" class=\"ltx_text ltx_font_bold\">31.6</span></td>&#13;\n<td id=\"S3.T2.4.10.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T2.4.10.6.5.1\" class=\"ltx_text ltx_font_bold\">36.9</span></td>&#13;\n<td id=\"S3.T2.4.10.6.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S3.T2.4.10.6.6.1\" class=\"ltx_text ltx_font_bold\">54.8</span></td>&#13;\n<td id=\"S3.T2.4.10.6.7\" class=\"ltx_td ltx_align_center ltx_border_b\">65.9</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[43] [43]\r\n\r\nHe Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran Song, and\r\nLeonidas J Guibas.\r\n\r\n\r\nNormalized object coordinate space for category-level 6d object pose\r\nand size estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition, pages 2642–2651, 2019.",
            "[5] [5]\r\n\r\nDengsheng Chen, Jun Li, Zheng Wang, and Kai Xu.\r\n\r\n\r\nLearning canonical shape space for category-level 6d object pose and\r\nsize estimation.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF conference on computer vision and\r\npattern recognition, pages 11973–11982, 2020.",
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020.",
            "[23] [23]\r\n\r\nJiehong Lin, Zewei Wei, Zhihao Li, Songcen Xu, Kui Jia, and Yuanqing Li.\r\n\r\n\r\nDualposenet: Category-level 6d object pose and size estimation using\r\ndual pose network with refined learning of pose consistency.\r\n\r\n\r\narXiv preprint arXiv:2103.06526, 2021.",
            "[6] [6]\r\n\r\nWei Chen, Xi Jia, Hyung Jin Chang, Jinming Duan, Linlin Shen, and Ales\r\nLeonardis.\r\n\r\n\r\nFs-net: Fast shape-based network for category-level 6d object pose\r\nestimation with decoupled rotation mechanism.\r\n\r\n\r\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition, pages 1581–1590, 2021."
        ],
        "references": [
            "Results on NOCS-REAL: We also compare ACR-Pose with other methods on the NOCS-REAL test set. Results are shown in Table 2. Our method is defeated by FS-Net [6] at the IoU50 metric and defeated by DualPoseNet [23] at the 10∘5cm metric. However, these two metrics are relatively loose metrics. Besides, the training setting of FS-Net [6] is strongly different from all the other baselines. For example, it uses the YOLO v3 [30] object detector to detect and crop image patches and depth regions, while all the other baselines use the Mask-RCNN detector. When it comes to other strict metrics, our method outperforms other baselines for a large margin. The excellent performance of our method on the NOCS-REAL dataset at more strict metrics demonstrate that ACR-Pose is powered with strong generalization ability and owns the potential of being deployed into real-world industry products. We contribute the superiority of our model into PIM, RRM and the adversarial reconstruction scheme."
        ]
    },
    "id_table_3": {
        "caption": "Table 3: Results of ablation study. We gradually add our designs one by one to the baseline to investigate their impacts.",
        "table": [
            "<table id=\"S4.T3.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T3.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Versions</th>&#13;\n<th id=\"S4.T3.4.4.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU50</th>&#13;\n<th id=\"S4.T3.4.4.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU75</th>&#13;\n<th id=\"S4.T3.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S4.T3.1.1.1.1\" class=\"ltx_sup\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S4.T3.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S4.T3.2.2.2.1\" class=\"ltx_sup\"><span id=\"S4.T3.2.2.2.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n<th id=\"S4.T3.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10<sup id=\"S4.T3.3.3.3.1\" class=\"ltx_sup\"><span id=\"S4.T3.3.3.3.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S4.T3.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">10<sup id=\"S4.T3.4.4.4.1\" class=\"ltx_sup\"><span id=\"S4.T3.4.4.4.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T3.4.5.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Baseline</td>&#13;\n<td id=\"S4.T3.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">93.3</td>&#13;\n<td id=\"S4.T3.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">86.7</td>&#13;\n<td id=\"S4.T3.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">58.6</td>&#13;\n<td id=\"S4.T3.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.3</td>&#13;\n<td id=\"S4.T3.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">76.4</td>&#13;\n<td id=\"S4.T3.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">84.2</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.4.6.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">+ Relational Instance Features</td>&#13;\n<td id=\"S4.T3.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">93.8</td>&#13;\n<td id=\"S4.T3.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">84.6</td>&#13;\n<td id=\"S4.T3.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">62.4</td>&#13;\n<td id=\"S4.T3.4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\">67.0</td>&#13;\n<td id=\"S4.T3.4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\">78.8</td>&#13;\n<td id=\"S4.T3.4.6.2.7\" class=\"ltx_td ltx_align_center\">85.7</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.4.7.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">+ Pose Irrelevant Module</td>&#13;\n<td id=\"S4.T3.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">93.4</td>&#13;\n<td id=\"S4.T3.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">88.9</td>&#13;\n<td id=\"S4.T3.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">65.5</td>&#13;\n<td id=\"S4.T3.4.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">69.2</td>&#13;\n<td id=\"S4.T3.4.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">79.7</td>&#13;\n<td id=\"S4.T3.4.7.3.7\" class=\"ltx_td ltx_align_center\">85.2</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.4.8.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.4.8.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\">+ Adversarial Reconstruction</td>&#13;\n<td id=\"S4.T3.4.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">93.7</td>&#13;\n<td id=\"S4.T3.4.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">84.0</td>&#13;\n<td id=\"S4.T3.4.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">67.4</td>&#13;\n<td id=\"S4.T3.4.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_r\">71.0</td>&#13;\n<td id=\"S4.T3.4.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_r\">81.2</td>&#13;\n<td id=\"S4.T3.4.8.4.7\" class=\"ltx_td ltx_align_center\">86.3</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.4.9.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.4.9.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\">+ Relational Deformation Features</td>&#13;\n<td id=\"S4.T3.4.9.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">93.7</td>&#13;\n<td id=\"S4.T3.4.9.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">89.3</td>&#13;\n<td id=\"S4.T3.4.9.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">68.4</td>&#13;\n<td id=\"S4.T3.4.9.5.5\" class=\"ltx_td ltx_align_center ltx_border_r\">72.1</td>&#13;\n<td id=\"S4.T3.4.9.5.6\" class=\"ltx_td ltx_align_center ltx_border_r\">81.9</td>&#13;\n<td id=\"S4.T3.4.9.5.7\" class=\"ltx_td ltx_align_center\">87.0</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.4.10.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.4.10.6.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">+ Relational Assignment Features (Full model)</td>&#13;\n<td id=\"S4.T3.4.10.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.4.10.6.2.1\" class=\"ltx_text ltx_font_bold\">93.8</span></td>&#13;\n<td id=\"S4.T3.4.10.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.4.10.6.3.1\" class=\"ltx_text ltx_font_bold\">89.9</span></td>&#13;\n<td id=\"S4.T3.4.10.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.4.10.6.4.1\" class=\"ltx_text ltx_font_bold\">70.4</span></td>&#13;\n<td id=\"S4.T3.4.10.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.4.10.6.5.1\" class=\"ltx_text ltx_font_bold\">74.1</span></td>&#13;\n<td id=\"S4.T3.4.10.6.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.4.10.6.6.1\" class=\"ltx_text ltx_font_bold\">82.6</span></td>&#13;\n<td id=\"S4.T3.4.10.6.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T3.4.10.6.7.1\" class=\"ltx_text ltx_font_bold\">87.8</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "In this section, we conduct experiments on the NOCS-CAMERA dataset to investigate the effectiveness and necessity of our several design choices. In Table 3, we replace all of our novel network designs in ACR-Pose as MLPs and then gradually add them back one by one to study their impact on the final 6D object pose estimation results.",
            "Impact of the Relational Reconstruction Module: The RRM is proposed to learn relational information between three different modalities in our Reconstructor. It includes three graphs that learn relational instance features, relational deformation features and relational assignment features respectively. From row 4, row 6 and row 7 of Table 3, we can find that all the three kinds of features contribute to the accuracy improvement because adding them one by one cumulatively increases the model’s performance. The improvement comes from the message passing through graphs in the feature space. Using them, powerful semantic features can be learned by the model to better reconstruct the canonical representation. These semantics can effectively describe both object-specified shape and common category-level characteristics (category specialities), therefore, high-quality NOCS representations can be reconstructed. The above results demonstrate that relational features are essential for high-quality NOCS representation reconstruction.",
            "Impact of Adversarial Reconstruction: The adversarial reconstruction scheme plays a role of increasing reconstruction reality. Besides, since the Discriminator is only required at the training time, it is an very efficient strategy for improving performance. The 5th row of Table 3 evidently verifies that the adversarial training scheme would help the model learn better, more realistic and more high-quality canonical representations because adding it brings significant performance gains. That is because the reconstructed canonical representations would be more realistic after adding the Discriminator. Further, the following Umeyama algorithm [40] would also perform much better and more robust if it receives more realistic canonical representations."
        ]
    },
    "id_table_4": {
        "caption": "Table 4: Performance of SPD and our method evaluated by the overall accuracy metric.",
        "table": [
            "<table id=\"S6.T4.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S6.T4.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T4.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Data</th>&#13;\n<th id=\"S6.T4.4.4.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Methods</th>&#13;\n<th id=\"S6.T4.4.4.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU50</th>&#13;\n<th id=\"S6.T4.4.4.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU75</th>&#13;\n<th id=\"S6.T4.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S6.T4.1.1.1.1\" class=\"ltx_sup\"><span id=\"S6.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S6.T4.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S6.T4.2.2.2.1\" class=\"ltx_sup\"><span id=\"S6.T4.2.2.2.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n<th id=\"S6.T4.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10<sup id=\"S6.T4.3.3.3.1\" class=\"ltx_sup\"><span id=\"S6.T4.3.3.3.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S6.T4.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">10<sup id=\"S6.T4.4.4.4.1\" class=\"ltx_sup\"><span id=\"S6.T4.4.4.4.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S6.T4.4.5.1\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T4.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S6.T4.4.5.1.1.1\" class=\"ltx_text\">CAMERA</span></td>&#13;\n<td id=\"S6.T4.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S6.T4.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">84.5</td>&#13;\n<td id=\"S6.T4.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">78.8</td>&#13;\n<td id=\"S6.T4.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">67.5</td>&#13;\n<td id=\"S6.T4.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">71.2</td>&#13;\n<td id=\"S6.T4.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">82.3</td>&#13;\n<td id=\"S6.T4.4.5.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">88.1</td>&#13;\n</tr>&#13;\n<tr id=\"S6.T4.4.6.2\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T4.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ACR-Pose(Ours)</td>&#13;\n<td id=\"S6.T4.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T4.4.6.2.2.1\" class=\"ltx_text ltx_font_bold\">84.8</span></td>&#13;\n<td id=\"S6.T4.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T4.4.6.2.3.1\" class=\"ltx_text ltx_font_bold\">82.6</span></td>&#13;\n<td id=\"S6.T4.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T4.4.6.2.4.1\" class=\"ltx_text ltx_font_bold\">80.4</span></td>&#13;\n<td id=\"S6.T4.4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T4.4.6.2.5.1\" class=\"ltx_text ltx_font_bold\">83.0</span></td>&#13;\n<td id=\"S6.T4.4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T4.4.6.2.6.1\" class=\"ltx_text ltx_font_bold\">88.6</span></td>&#13;\n<td id=\"S6.T4.4.6.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T4.4.6.2.7.1\" class=\"ltx_text ltx_font_bold\">92.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S6.T4.4.7.3\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T4.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S6.T4.4.7.3.1.1\" class=\"ltx_text\">Real</span></td>&#13;\n<td id=\"S6.T4.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S6.T4.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">87.8</td>&#13;\n<td id=\"S6.T4.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">69.4</td>&#13;\n<td id=\"S6.T4.4.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">31.4</td>&#13;\n<td id=\"S6.T4.4.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">34.4</td>&#13;\n<td id=\"S6.T4.4.7.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">54.9</td>&#13;\n<td id=\"S6.T4.4.7.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">63.1</td>&#13;\n</tr>&#13;\n<tr id=\"S6.T4.4.8.4\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T4.4.8.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">ACR-Pose(Ours)</td>&#13;\n<td id=\"S6.T4.4.8.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T4.4.8.4.2.1\" class=\"ltx_text ltx_font_bold\">91.1</span></td>&#13;\n<td id=\"S6.T4.4.8.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T4.4.8.4.3.1\" class=\"ltx_text ltx_font_bold\">79.2</span></td>&#13;\n<td id=\"S6.T4.4.8.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T4.4.8.4.4.1\" class=\"ltx_text ltx_font_bold\">44.8</span></td>&#13;\n<td id=\"S6.T4.4.8.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T4.4.8.4.5.1\" class=\"ltx_text ltx_font_bold\">49.9</span></td>&#13;\n<td id=\"S6.T4.4.8.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T4.4.8.4.6.1\" class=\"ltx_text ltx_font_bold\">65.0</span></td>&#13;\n<td id=\"S6.T4.4.8.4.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S6.T4.4.8.4.7.1\" class=\"ltx_text ltx_font_bold\">73.4</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020.",
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020."
        ],
        "references": [
            "Except for the mAP metric we mainly report, we also calculate the overall accuracy at the threshold of IoU50, IoU75, 5∘2cm, 5∘5cm, 10∘2cm and 10∘5cm. We show the results on Table 4 and compare our ACR-Pose with SPD [38]. Our method outperforms SPD for a large margin in terms of overall accuracy. This is consistent with the result of using mAP as an evaluation metric, which further indicates the superiority of our method."
        ]
    },
    "id_table_5": {
        "caption": "Table 5: Results of generalization ability evaluation.",
        "table": [
            "<table id=\"S6.T5.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S6.T5.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T5.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Methods</th>&#13;\n<th id=\"S6.T5.4.4.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU50</th>&#13;\n<th id=\"S6.T5.4.4.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">IoU75</th>&#13;\n<th id=\"S6.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S6.T5.1.1.1.1\" class=\"ltx_sup\"><span id=\"S6.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S6.T5.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S6.T5.2.2.2.1\" class=\"ltx_sup\"><span id=\"S6.T5.2.2.2.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n<th id=\"S6.T5.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10<sup id=\"S6.T5.3.3.3.1\" class=\"ltx_sup\"><span id=\"S6.T5.3.3.3.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S6.T5.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">10<sup id=\"S6.T5.4.4.4.1\" class=\"ltx_sup\"><span id=\"S6.T5.4.4.4.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S6.T5.4.5.1\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T5.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite> CAMERA only)</th>&#13;\n<td id=\"S6.T5.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">70.0</td>&#13;\n<td id=\"S6.T5.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S6.T5.4.5.1.3.1\" class=\"ltx_text ltx_font_bold\">37.9</span></td>&#13;\n<td id=\"S6.T5.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11.2</td>&#13;\n<td id=\"S6.T5.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">12.9</td>&#13;\n<td id=\"S6.T5.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">32.2</td>&#13;\n<td id=\"S6.T5.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">41.3</td>&#13;\n</tr>&#13;\n<tr id=\"S6.T5.4.6.2\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T5.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">ACR-Pose(CAMERA only)</th>&#13;\n<td id=\"S6.T5.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T5.4.6.2.2.1\" class=\"ltx_text ltx_font_bold\">70.0</span></td>&#13;\n<td id=\"S6.T5.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">35.8</td>&#13;\n<td id=\"S6.T5.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T5.4.6.2.4.1\" class=\"ltx_text ltx_font_bold\">12.2</span></td>&#13;\n<td id=\"S6.T5.4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T5.4.6.2.5.1\" class=\"ltx_text ltx_font_bold\">14.8</span></td>&#13;\n<td id=\"S6.T5.4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T5.4.6.2.6.1\" class=\"ltx_text ltx_font_bold\">32.2</span></td>&#13;\n<td id=\"S6.T5.4.6.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T5.4.6.2.7.1\" class=\"ltx_text ltx_font_bold\">42.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S6.T5.4.7.3\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T5.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">ACR-Pose(CAMERA+REAL)</th>&#13;\n<td id=\"S6.T5.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T5.4.7.3.2.1\" class=\"ltx_text ltx_font_bold\">82.8</span></td>&#13;\n<td id=\"S6.T5.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T5.4.7.3.3.1\" class=\"ltx_text ltx_font_bold\">66.0</span></td>&#13;\n<td id=\"S6.T5.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T5.4.7.3.4.1\" class=\"ltx_text ltx_font_bold\">31.6</span></td>&#13;\n<td id=\"S6.T5.4.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T5.4.7.3.5.1\" class=\"ltx_text ltx_font_bold\">36.9</span></td>&#13;\n<td id=\"S6.T5.4.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T5.4.7.3.6.1\" class=\"ltx_text ltx_font_bold\">54.8</span></td>&#13;\n<td id=\"S6.T5.4.7.3.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S6.T5.4.7.3.7.1\" class=\"ltx_text ltx_font_bold\">65.9</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020."
        ],
        "references": [
            "To evaluate the generalization ability, we evaluate ACR-Pose on the NOCA-REAL test set using the model only trained on the synthetic NOCS-CAMERA dataset. We also compare our method with SPD here. The evaluation metric is mAP. Results are shown in Table 5. Our method demonstrates better generalization ability towards real-world scenarios compared to SPD. However, there is still much room for performance improvement compared to the model trained on both NOCS-CAMERA and NOCS-REAL."
        ]
    },
    "id_table_6": {
        "caption": "Table 6: Reconstruction quality evaluation. The evaluation metric is chamfer distance.",
        "table": [
            "<table id=\"S6.T6.2\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S6.T6.2.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T6.2.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Data</th>&#13;\n<th id=\"S6.T6.2.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Methods</th>&#13;\n<th id=\"S6.T6.2.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">bottle</th>&#13;\n<th id=\"S6.T6.2.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">bowl</th>&#13;\n<th id=\"S6.T6.2.1.1.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">camera</th>&#13;\n<th id=\"S6.T6.2.1.1.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">can</th>&#13;\n<th id=\"S6.T6.2.1.1.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">laptop</th>&#13;\n<th id=\"S6.T6.2.1.1.8\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">mug</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S6.T6.2.2.1\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T6.2.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S6.T6.2.2.1.1.1\" class=\"ltx_text\">CAMERA</span></td>&#13;\n<td id=\"S6.T6.2.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S6.T6.2.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0235</td>&#13;\n<td id=\"S6.T6.2.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0142</td>&#13;\n<td id=\"S6.T6.2.2.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0196</td>&#13;\n<td id=\"S6.T6.2.2.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0262</td>&#13;\n<td id=\"S6.T6.2.2.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0153</td>&#13;\n<td id=\"S6.T6.2.2.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0187</td>&#13;\n</tr>&#13;\n<tr id=\"S6.T6.2.3.2\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T6.2.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\">ACR-Pose(Ours)</td>&#13;\n<td id=\"S6.T6.2.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T6.2.3.2.2.1\" class=\"ltx_text ltx_font_bold\">0.0216</span></td>&#13;\n<td id=\"S6.T6.2.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T6.2.3.2.3.1\" class=\"ltx_text ltx_font_bold\">0.0137</span></td>&#13;\n<td id=\"S6.T6.2.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T6.2.3.2.4.1\" class=\"ltx_text ltx_font_bold\">0.0185</span></td>&#13;\n<td id=\"S6.T6.2.3.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T6.2.3.2.5.1\" class=\"ltx_text ltx_font_bold\">0.0253</span></td>&#13;\n<td id=\"S6.T6.2.3.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T6.2.3.2.6.1\" class=\"ltx_text ltx_font_bold\">&#13;\n0.0137</span></td>&#13;\n<td id=\"S6.T6.2.3.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T6.2.3.2.7.1\" class=\"ltx_text ltx_font_bold\">0.0172</span></td>&#13;\n</tr>&#13;\n<tr id=\"S6.T6.2.4.3\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T6.2.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" rowspan=\"2\"><span id=\"S6.T6.2.4.3.1.1\" class=\"ltx_text\">Real</span></td>&#13;\n<td id=\"S6.T6.2.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SPD<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib38\" title=\"\" class=\"ltx_ref\">38</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S6.T6.2.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0251</td>&#13;\n<td id=\"S6.T6.2.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0192</td>&#13;\n<td id=\"S6.T6.2.4.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0209</td>&#13;\n<td id=\"S6.T6.2.4.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0213</td>&#13;\n<td id=\"S6.T6.2.4.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">0.0207</td>&#13;\n<td id=\"S6.T6.2.4.3.8\" class=\"ltx_td ltx_align_center ltx_border_t\">0.0210</td>&#13;\n</tr>&#13;\n<tr id=\"S6.T6.2.5.4\" class=\"ltx_tr\">&#13;\n<td id=\"S6.T6.2.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">ACR-Pose(Ours)</td>&#13;\n<td id=\"S6.T6.2.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T6.2.5.4.2.1\" class=\"ltx_text ltx_font_bold\">0.0235</span></td>&#13;\n<td id=\"S6.T6.2.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T6.2.5.4.3.1\" class=\"ltx_text ltx_font_bold\">0.0157</span></td>&#13;\n<td id=\"S6.T6.2.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T6.2.5.4.4.1\" class=\"ltx_text ltx_font_bold\">0.0196</span></td>&#13;\n<td id=\"S6.T6.2.5.4.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T6.2.5.4.5.1\" class=\"ltx_text ltx_font_bold\">0.0182</span></td>&#13;\n<td id=\"S6.T6.2.5.4.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S6.T6.2.5.4.6.1\" class=\"ltx_text ltx_font_bold\">0.0180</span></td>&#13;\n<td id=\"S6.T6.2.5.4.7\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S6.T6.2.5.4.7.1\" class=\"ltx_text ltx_font_bold\">0.0175</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020.",
            "[38] [38]\r\n\r\nMeng Tian, Marcelo H Ang, and Gim Hee Lee.\r\n\r\n\r\nShape prior deformation for categorical 6d object pose and size\r\nestimation.\r\n\r\n\r\nIn European Conference on Computer Vision, pages 530–546.\r\nSpringer, 2020."
        ],
        "references": [
            "To verify whether our model can reconstruct high-quality NOCS representations, we evaluate the reconstruction quality of the results of SPD and ACR-Pose using the chamfer distance. Results are shown in Table 6. Our method significantly outperforms SPD. Since we use the same Shape Prior Deformation step and Umeyama algorithm for NOCS representation reconstruction and object pose estimation, we claim that the mAP improvement really comes from the higher quality NOCS representation. Note our work mainly benefits from the Pose-Irrelevant Module, the Relational Reconstruction Module and the adversarial reconstruction scheme, while SPD doesn’t use these modules."
        ]
    },
    "id_table_7": {
        "caption": "Table 7: Impact of the number of adjacency neighbors.",
        "table": [
            "<table id=\"S6.T7.4\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S6.T7.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T7.4.4.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Versions</th>&#13;\n<th id=\"S6.T7.4.4.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">IoU50</th>&#13;\n<th id=\"S6.T7.4.4.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">IoU75</th>&#13;\n<th id=\"S6.T7.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S6.T7.1.1.1.1\" class=\"ltx_sup\"><span id=\"S6.T7.1.1.1.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S6.T7.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">5<sup id=\"S6.T7.2.2.2.1\" class=\"ltx_sup\"><span id=\"S6.T7.2.2.2.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n<th id=\"S6.T7.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">10<sup id=\"S6.T7.3.3.3.1\" class=\"ltx_sup\"><span id=\"S6.T7.3.3.3.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>2cm</th>&#13;\n<th id=\"S6.T7.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">10<sup id=\"S6.T7.4.4.4.1\" class=\"ltx_sup\"><span id=\"S6.T7.4.4.4.1.1\" class=\"ltx_text ltx_font_italic\">&#8728;</span></sup>5cm</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S6.T7.4.5.1\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T7.4.5.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">K=24</th>&#13;\n<th id=\"S6.T7.4.5.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">94.5</th>&#13;\n<th id=\"S6.T7.4.5.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">93.7</th>&#13;\n<td id=\"S6.T7.4.5.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">69.9</td>&#13;\n<td id=\"S6.T7.4.5.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">73.7</td>&#13;\n<td id=\"S6.T7.4.5.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">82.2</td>&#13;\n<td id=\"S6.T7.4.5.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\">87.5</td>&#13;\n</tr>&#13;\n<tr id=\"S6.T7.4.6.2\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T7.4.6.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">K=36</th>&#13;\n<th id=\"S6.T7.4.6.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S6.T7.4.6.2.2.1\" class=\"ltx_text ltx_font_bold\">94.5</span></th>&#13;\n<th id=\"S6.T7.4.6.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><span id=\"S6.T7.4.6.2.3.1\" class=\"ltx_text ltx_font_bold\">93.8</span></th>&#13;\n<td id=\"S6.T7.4.6.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T7.4.6.2.4.1\" class=\"ltx_text ltx_font_bold\">70.4</span></td>&#13;\n<td id=\"S6.T7.4.6.2.5\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T7.4.6.2.5.1\" class=\"ltx_text ltx_font_bold\">74.1</span></td>&#13;\n<td id=\"S6.T7.4.6.2.6\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S6.T7.4.6.2.6.1\" class=\"ltx_text ltx_font_bold\">82.6</span></td>&#13;\n<td id=\"S6.T7.4.6.2.7\" class=\"ltx_td ltx_align_center\"><span id=\"S6.T7.4.6.2.7.1\" class=\"ltx_text ltx_font_bold\">87.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S6.T7.4.7.3\" class=\"ltx_tr\">&#13;\n<th id=\"S6.T7.4.7.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">K=48</th>&#13;\n<th id=\"S6.T7.4.7.3.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">94.4</th>&#13;\n<th id=\"S6.T7.4.7.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\">93.7</th>&#13;\n<td id=\"S6.T7.4.7.3.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">70.1</td>&#13;\n<td id=\"S6.T7.4.7.3.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">73.7</td>&#13;\n<td id=\"S6.T7.4.7.3.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">82.8</td>&#13;\n<td id=\"S6.T7.4.7.3.7\" class=\"ltx_td ltx_align_center ltx_border_b\">87.8</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "For the Relational Reconstruction Module, in each graph, we use KNN to search for the adjacent neighbors for each node. In Table 7, we show the impact of the number of adjacent neighbors K. We conclude that setting K as 36 is the best choice. When K is too small, it may cause a small receptive field for learning relationships between different modalities. While when it is too large, it may cause over-fitting and additional unnecessary computational costs."
        ]
    }
}