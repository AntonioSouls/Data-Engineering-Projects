{
    "id_table_1": {
        "caption": "Table 1: Overview of existing 6DoF object pose estimation datasets.",
        "table": [
            "<table id=\"S2.T1.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tr id=\"S2.T1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S2.T1.1.1.1.1\" class=\"ltx_text\">Dataset</span></td>&#13;\n<td id=\"S2.T1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">&#13;\n<span id=\"S2.T1.1.1.2.1\" class=\"ltx_text\"/> <span id=\"S2.T1.1.1.2.2\" class=\"ltx_text\">&#13;\n<span id=\"S2.T1.1.1.2.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<span id=\"S2.T1.1.1.2.2.1.1\" class=\"ltx_tr\">&#13;\n<span id=\"S2.T1.1.1.2.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Visual</span></span>&#13;\n<span id=\"S2.T1.1.1.2.2.1.2\" class=\"ltx_tr\">&#13;\n<span id=\"S2.T1.1.1.2.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Modality</span></span>&#13;\n</span></span><span id=\"S2.T1.1.1.2.3\" class=\"ltx_text\"/></td>&#13;\n<td id=\"S2.T1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">&#13;\n<span id=\"S2.T1.1.1.3.1\" class=\"ltx_text\"/> <span id=\"S2.T1.1.1.3.2\" class=\"ltx_text\">&#13;\n<span id=\"S2.T1.1.1.3.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<span id=\"S2.T1.1.1.3.2.1.1\" class=\"ltx_tr\">&#13;\n<span id=\"S2.T1.1.1.3.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">Real/Synthetic</span></span>&#13;\n<span id=\"S2.T1.1.1.3.2.1.2\" class=\"ltx_tr\">&#13;\n<span id=\"S2.T1.1.1.3.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">images</span></span>&#13;\n</span></span><span id=\"S2.T1.1.1.3.3\" class=\"ltx_text\"/></td>&#13;\n<td id=\"S2.T1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.1.4.1\" class=\"ltx_text\">#objects</span></td>&#13;\n<td id=\"S2.T1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.1.5.1\" class=\"ltx_text\">resolution</span></td>&#13;\n<td id=\"S2.T1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.1.6.1\" class=\"ltx_text\">marker</span></td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.1.2\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Linemod-Occluded&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib3\" title=\"\" class=\"ltx_ref\">3</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.1.2.2\" class=\"ltx_td ltx_align_center ltx_border_t\">RGBD</td>&#13;\n<td id=\"S2.T1.1.2.3\" class=\"ltx_td ltx_align_center ltx_border_t\">10k/-</td>&#13;\n<td id=\"S2.T1.1.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">20</td>&#13;\n<td id=\"S2.T1.1.2.5\" class=\"ltx_td ltx_align_center ltx_border_t\">640 x 480</td>&#13;\n<td id=\"S2.T1.1.2.6\" class=\"ltx_td ltx_align_center ltx_border_t\">yes</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.1.3\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">T-LESS&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">7</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.1.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\">RGBD</td>&#13;\n<td id=\"S2.T1.1.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\">48k/-</td>&#13;\n<td id=\"S2.T1.1.3.4\" class=\"ltx_td ltx_align_center ltx_border_t\">30</td>&#13;\n<td id=\"S2.T1.1.3.5\" class=\"ltx_td ltx_align_center ltx_border_t\">1280 x 1024</td>&#13;\n<td id=\"S2.T1.1.3.6\" class=\"ltx_td ltx_align_center ltx_border_t\">yes</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.1.4\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">YCB-Video&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\">16</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.1.4.2\" class=\"ltx_td ltx_align_center ltx_border_t\">RGBD</td>&#13;\n<td id=\"S2.T1.1.4.3\" class=\"ltx_td ltx_align_center ltx_border_t\">133827/-</td>&#13;\n<td id=\"S2.T1.1.4.4\" class=\"ltx_td ltx_align_center ltx_border_t\">21</td>&#13;\n<td id=\"S2.T1.1.4.5\" class=\"ltx_td ltx_align_center ltx_border_t\">640 x 480</td>&#13;\n<td id=\"S2.T1.1.4.6\" class=\"ltx_td ltx_align_center ltx_border_t\">no</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.1.5\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S2.T1.1.5.1.1\" class=\"ltx_text\">HomebrewedDB&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">10</a>]</cite></span></td>&#13;\n<td id=\"S2.T1.1.5.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.5.2.1\" class=\"ltx_text\">RGBD</span></td>&#13;\n<td id=\"S2.T1.1.5.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.5.3.1\" class=\"ltx_text\">34830/-</span></td>&#13;\n<td id=\"S2.T1.1.5.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.5.4.1\" class=\"ltx_text\">30</span></td>&#13;\n<td id=\"S2.T1.1.5.5\" class=\"ltx_td ltx_align_center ltx_border_t\">&#13;\n<span id=\"S2.T1.1.5.5.1\" class=\"ltx_text\"/> <span id=\"S2.T1.1.5.5.2\" class=\"ltx_text\">&#13;\n<span id=\"S2.T1.1.5.5.2.1\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<span id=\"S2.T1.1.5.5.2.1.1\" class=\"ltx_tr\">&#13;\n<span id=\"S2.T1.1.5.5.2.1.1.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">640 x 480 &amp;</span></span>&#13;\n<span id=\"S2.T1.1.5.5.2.1.2\" class=\"ltx_tr\">&#13;\n<span id=\"S2.T1.1.5.5.2.1.2.1\" class=\"ltx_td ltx_nopad_r ltx_align_center\">1920 x 1080</span></span>&#13;\n</span></span><span id=\"S2.T1.1.5.5.3\" class=\"ltx_text\"/></td>&#13;\n<td id=\"S2.T1.1.5.6\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S2.T1.1.5.6.1\" class=\"ltx_text\">yes</span></td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.1.6\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.6.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">Fraunhofer IPA&#160;<cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\">11</a>]</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.1.6.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">Stereo</td>&#13;\n<td id=\"S2.T1.1.6.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">520/206,000</td>&#13;\n<td id=\"S2.T1.1.6.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">10</td>&#13;\n<td id=\"S2.T1.1.6.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">1280&#215;1024</td>&#13;\n<td id=\"S2.T1.1.6.6\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\">no</td>&#13;\n</tr>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[3] [3]\r\n\r\nBrachmann, E., Krull, A., Michel, F., Gumhold, S., Shotton, J., Rother, C.:\r\nLearning 6d object pose estimation using 3d object coordinates. In: European\r\nconference on computer vision. pp. 536–551. Springer (2014)",
            "[7] [7]\r\n\r\nHodan, T., Haluza, P., Obdržálek, Š., Matas, J., Lourakis, M.,\r\nZabulis, X.: T-less: An rgb-d dataset for 6d pose estimation of texture-less\r\nobjects. In: 2017 IEEE Winter Conference on Applications of Computer Vision\r\n(WACV). pp. 880–888. IEEE (2017)",
            "[16] [16]\r\n\r\nXiang, Y., Schmidt, T., Narayanan, V., Fox, D.: Posecnn: A convolutional neural\r\nnetwork for 6d object pose estimation in cluttered scenes. arXiv preprint\r\narXiv:1711.00199 (2017)",
            "[10] [10]\r\n\r\nKaskman, R., Zakharov, S., Shugurov, I., Ilic, S.: Homebreweddb: Rgb-d dataset\r\nfor 6d pose estimation of 3d objects. In: Proceedings of the IEEE/CVF\r\nInternational Conference on Computer Vision Workshops. pp. 0–0 (2019)",
            "[11] [11]\r\n\r\nKleeberger, K., Landgraf, C., Huber, M.F.: Large-scale 6d object pose\r\nestimation dataset for industrial bin-picking. In: 2019 IEEE/RSJ\r\nInternational Conference on Intelligent Robots and Systems (IROS). pp.\r\n2573–2578. IEEE (2019)"
        ],
        "references": [
            "The overview of these datasets is given in Table 1. These works inspired the way of generating a 6DoF object pose dataset. Most of them fix the objects’ poses and track objects in the trajectory of cameras. In contrast, our dataset setup is fixing the cameras, and the objects are movable during the process."
        ]
    }
}