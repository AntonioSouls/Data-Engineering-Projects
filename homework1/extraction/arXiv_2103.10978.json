{
    "id_table_1": {
        "caption": "Table 1: PVE-T-SC (mm) results on synthetic data (see Figure 3) investigating: i) probabilistic shape combination (PC) versus simple averaging (Mean), ii) effect of increasing input group size from 1 to 2 (Pairs) to 4 (Quadruplets) and iii) effect of global rotation variation within pairs of inputs.",
        "table": [
            "<table id=\"S3.T1.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T1.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Input groups</span></th>&#13;\n<th id=\"S3.T1.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Method</span></th>&#13;\n<td id=\"S3.T1.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Synthetic</span></td>&#13;\n<td id=\"S3.T1.1.1.1.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.1.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Synthetic</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<th id=\"S3.T1.1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.2.2.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Clean</span></td>&#13;\n<td id=\"S3.T1.1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.2.2.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Corrupted</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.3.3\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-bottom:1.93748pt;padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<th id=\"S3.T1.1.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-bottom:1.93748pt;padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-bottom:1.93748pt;padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">PVE-T-SC</span></td>&#13;\n<td id=\"S3.T1.1.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-bottom:1.93748pt;padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">PVE-T-SC</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.4.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.4.4.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Single-Input</span></th>&#13;\n<th id=\"S3.T1.1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></th>&#13;\n<td id=\"S3.T1.1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">14.4</span></td>&#13;\n<td id=\"S3.T1.1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.5.5\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\" rowspan=\"2\"><span id=\"S3.T1.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\"><span id=\"S3.T1.1.5.5.1.1.1\" class=\"ltx_text ltx_font_bold\">Quadruplets</span> Front + L/R Side + Back</span></th>&#13;\n<th id=\"S3.T1.1.5.5.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.5.5.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.5.5.4\" class=\"ltx_td ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.6.6\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.6.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + Mean</span></th>&#13;\n<td id=\"S3.T1.1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.1</span></td>&#13;\n<td id=\"S3.T1.1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.3</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.7.7\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.7.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<th id=\"S3.T1.1.7.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></th>&#13;\n<td id=\"S3.T1.1.7.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.7.7.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.0</span></td>&#13;\n<td id=\"S3.T1.1.7.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.7.7.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">12.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.8.8\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.8.8.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.8.8.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Pairs</span></th>&#13;\n<th id=\"S3.T1.1.8.8.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.8.8.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.8.8.4\" class=\"ltx_td ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.9.9\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.9.9.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.9.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Front + L Side or</span></th>&#13;\n<th id=\"S3.T1.1.9.9.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></th>&#13;\n<td id=\"S3.T1.1.9.9.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.9.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.5</span></td>&#13;\n<td id=\"S3.T1.1.9.9.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.9.9.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.4</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.10.10\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.10.10.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.10.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Back + R Side</span></th>&#13;\n<th id=\"S3.T1.1.10.10.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.10.10.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.10.10.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.11.11\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.11.11.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.11.11.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Pairs</span></th>&#13;\n<th id=\"S3.T1.1.11.11.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.11.11.3\" class=\"ltx_td ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.11.11.4\" class=\"ltx_td ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.12.12\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.12.12.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.12.12.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Front + Back or</span></th>&#13;\n<th id=\"S3.T1.1.12.12.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.12.12.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></th>&#13;\n<td id=\"S3.T1.1.12.12.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.12.12.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.6</span></td>&#13;\n<td id=\"S3.T1.1.12.12.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.12.12.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T1.1.13.13\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T1.1.13.13.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S3.T1.1.13.13.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">L + R Side</span></th>&#13;\n<th id=\"S3.T1.1.13.13.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.13.13.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S3.T1.1.13.13.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "Body shape combination method. We compare probabilistic body shape combination (from Section 3.4) with a simpler heuristic combination, where we obtain combined body shape estimates from a group of inputs {ùêón}n=1Nsuperscriptsubscriptsubscriptùêóùëõùëõ1ùëÅ\\{\\mathbf{X}_{n}\\}_{n=1}^{N} by simply averaging (i.e. taking the mean of) the shape distribution means {ùùÅŒ≤‚Äã(ùêón)}n=1NsuperscriptsubscriptsubscriptùùÅùõΩsubscriptùêóùëõùëõ1ùëÅ\\{\\boldsymbol{\\mu}_{\\beta}(\\mathbf{X}_{n})\\}_{n=1}^{N}. Rows 3-4 in Table 1 show that better shape estimation metrics are attained using probabilistic combination versus simple averaging on synthetic input quadruplets (examples in Figure 3). This is replicated on groups of real inputs from SSP-3D, as shown in Table 2, row 5 versus row 6. Since probabilistic combination may be interpreted as uncertainty-weighted averaging (Eqn. 4), these experiments suggest that inaccurate mean body shape predictions are generally accompanied by large prediction uncertainty, and subsequently down-weighted during probabilistic combination. This may explain why probabilistic combination actually gives better shape metrics when evaluating on corrupted synthetic inputs compared to clean inputs in Table 1, since heavy input corruption results in inaccurate but highly-uncertain shape estimates.",
            "Input group size. Table 1 also investigates the effect of the input group size, evaluated on our synthetic dataset, by comparing single inputs (i.e. group size of 1) with body shape combination applied to pairs and quadruplets (i.e. input group sizes of 2 and 4). Body shape metrics are significantly improved when using pairs compared to single images, suggesting that probabilistic combination is successfully using shape information from the multiple inputs. A smaller improvement is seen when using quadruplets versus pairs. Table 2 shows that increasing the input group size on real data (from SSP-3D) also results in a consistent but diminishing improvement in shape prediction metrics.",
            "Global rotation variation. To investigate whether variation in global rotation of the subject between inputs is correlated with shape prediction accuracy, we split each group of 4 inputs from our synthetic dataset into groups of 2 in two ways: (front, left) + (back, right) and (front, back) + (left, right). We expect the latter split to be less informative for shape prediction as the pairs contain more redundant visual shape information. This is corroborated by the experiments labelled ‚ÄúPairs‚Äù in Table 1, where the former split yields better shape metrics, particularly for corrupted inputs where the amount of visual shape information in each individual input is lower."
        ]
    },
    "id_table_2": {
        "caption": "Table 2: PVE-T-SC (mm) results on SSP-3D [45] comparing i) probabilistic shape combination (PC) versus simple averaging (Mean) and ii) effect of increasing input group size from 1 to 5.",
        "table": [
            "<table id=\"S4.T2.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T2.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T2.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Max. input group size</span></td>&#13;\n<td id=\"S4.T2.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Method</span></td>&#13;\n<td id=\"S4.T2.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SSP-3D</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.2.2.1\" class=\"ltx_td\" style=\"padding-bottom:1.93748pt;\"/>&#13;\n<td id=\"S4.T2.1.2.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:1.93748pt;\"><span id=\"S4.T2.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">PVE-T-SC</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.3.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">1</span></td>&#13;\n<td id=\"S4.T2.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></td>&#13;\n<td id=\"S4.T2.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.2</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.4.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.4.4.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2</span></td>&#13;\n<td id=\"S4.T2.1.4.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></td>&#13;\n<td id=\"S4.T2.1.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.5.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.5.5.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">3</span></td>&#13;\n<td id=\"S4.T2.1.5.5.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></td>&#13;\n<td id=\"S4.T2.1.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.6</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.6.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.6.6.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">4</span></td>&#13;\n<td id=\"S4.T2.1.6.6.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T2.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></td>&#13;\n<td id=\"S4.T2.1.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T2.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.5</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.7.7\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">5</span></td>&#13;\n<td id=\"S4.T2.1.7.7.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T2.1.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + Mean</span></td>&#13;\n<td id=\"S4.T2.1.7.7.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T2.1.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.6</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T2.1.8.8\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T2.1.8.8.1\" class=\"ltx_td ltx_border_b\"/>&#13;\n<td id=\"S4.T2.1.8.8.2\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S4.T2.1.8.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></td>&#13;\n<td id=\"S4.T2.1.8.8.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T2.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.3</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020."
        ],
        "references": [
            "Body shape combination method. We compare probabilistic body shape combination (from Section 3.4) with a simpler heuristic combination, where we obtain combined body shape estimates from a group of inputs {ùêón}n=1Nsuperscriptsubscriptsubscriptùêóùëõùëõ1ùëÅ\\{\\mathbf{X}_{n}\\}_{n=1}^{N} by simply averaging (i.e. taking the mean of) the shape distribution means {ùùÅŒ≤‚Äã(ùêón)}n=1NsuperscriptsubscriptsubscriptùùÅùõΩsubscriptùêóùëõùëõ1ùëÅ\\{\\boldsymbol{\\mu}_{\\beta}(\\mathbf{X}_{n})\\}_{n=1}^{N}. Rows 3-4 in Table 1 show that better shape estimation metrics are attained using probabilistic combination versus simple averaging on synthetic input quadruplets (examples in Figure 3). This is replicated on groups of real inputs from SSP-3D, as shown in Table 2, row 5 versus row 6. Since probabilistic combination may be interpreted as uncertainty-weighted averaging (Eqn. 4), these experiments suggest that inaccurate mean body shape predictions are generally accompanied by large prediction uncertainty, and subsequently down-weighted during probabilistic combination. This may explain why probabilistic combination actually gives better shape metrics when evaluating on corrupted synthetic inputs compared to clean inputs in Table 1, since heavy input corruption results in inaccurate but highly-uncertain shape estimates.",
            "Input group size. Table 1 also investigates the effect of the input group size, evaluated on our synthetic dataset, by comparing single inputs (i.e. group size of 1) with body shape combination applied to pairs and quadruplets (i.e. input group sizes of 2 and 4). Body shape metrics are significantly improved when using pairs compared to single images, suggesting that probabilistic combination is successfully using shape information from the multiple inputs. A smaller improvement is seen when using quadruplets versus pairs. Table 2 shows that increasing the input group size on real data (from SSP-3D) also results in a consistent but diminishing improvement in shape prediction metrics."
        ]
    },
    "id_table_3": {
        "caption": "Table 3: Comparison with the state-of-the-art in terms of PVE-T-SC (mm) on SSP-3D [45]. Our method surpasses the state-of-the-art when using single-image inputs. Probabilistic shape combination (PC) outperforms simple averaging of predictions from other methods when using groups of up to 5 images, as well as video predictions from [26].",
        "table": [
            "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_t\" rowspan=\"2\"><span id=\"S4.T3.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Max. input group size</span></td>&#13;\n<td id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S4.T3.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Method</span></td>&#13;\n<td id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">SSP-3D</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.2.2.1\" class=\"ltx_td\" style=\"padding-bottom:1.93748pt;\"/>&#13;\n<td id=\"S4.T3.1.2.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:1.93748pt;\"><span id=\"S4.T3.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">PVE-T-SC</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.3.3\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.3.3.1\" class=\"ltx_td ltx_border_t\"/>&#13;\n<td id=\"S4.T3.1.3.3.2\" class=\"ltx_td ltx_align_left ltx_border_t\">&#13;\n<span id=\"S4.T3.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">HMR </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a><span id=\"S4.T3.1.3.3.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.4.4\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.4.4.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.4.4.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">GraphCMR </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.4.4.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a><span id=\"S4.T3.1.4.4.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.5</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.5.5\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.5.5.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:120%;\">1</span></td>&#13;\n<td id=\"S4.T3.1.5.5.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">SPIN </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.5.5.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a><span id=\"S4.T3.1.5.5.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.2</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.6.6\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.6.6.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.6.6.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DaNet </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.6.6.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib57\" title=\"\" class=\"ltx_ref\">57</a><span id=\"S4.T3.1.6.6.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.7.7\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.7.7.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.7.7.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">STRAPS </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.7.7.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">45</a><span id=\"S4.T3.1.7.7.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.7.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">15.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.8.8\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.8.8.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.8.8.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.1.8.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></td>&#13;\n<td id=\"S4.T3.1.8.8.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">15.2</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.9.9\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.9.9.1\" class=\"ltx_td ltx_border_t\"/>&#13;\n<td id=\"S4.T3.1.9.9.2\" class=\"ltx_td ltx_align_left ltx_border_t\">&#13;\n<span id=\"S4.T3.1.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">HMR </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.9.9.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a><span id=\"S4.T3.1.9.9.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S4.T3.1.9.9.2.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T3.1.9.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.10.10\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.10.10.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.10.10.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.10.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">GraphCMR </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.10.10.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a><span id=\"S4.T3.1.10.10.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S4.T3.1.10.10.2.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.10.10.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.10.10.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">19.3</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.11.11\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.11.11.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.11.11.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.11.11.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">SPIN </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.11.11.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a><span id=\"S4.T3.1.11.11.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S4.T3.1.11.11.2.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.11.11.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.11.11.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">21.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.12.12\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.12.12.1\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.12.12.1.1\" class=\"ltx_text\" style=\"font-size:120%;\">5</span></td>&#13;\n<td id=\"S4.T3.1.12.12.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.12.12.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">DaNet </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.12.12.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib57\" title=\"\" class=\"ltx_ref\">57</a><span id=\"S4.T3.1.12.12.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S4.T3.1.12.12.2.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.12.12.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.12.12.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">22.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.13.13\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.13.13.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.13.13.2\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S4.T3.1.13.13.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">STRAPS </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.13.13.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">45</a><span id=\"S4.T3.1.13.13.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S4.T3.1.13.13.2.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.13.13.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.13.13.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">14.4</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.14.14\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.14.14.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.14.14.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.1.14.14.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + Mean</span></td>&#13;\n<td id=\"S4.T3.1.14.14.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.14.14.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">13.6</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.15.15\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.15.15.1\" class=\"ltx_td\"/>&#13;\n<td id=\"S4.T3.1.15.15.2\" class=\"ltx_td ltx_align_left\"><span id=\"S4.T3.1.15.15.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></td>&#13;\n<td id=\"S4.T3.1.15.15.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T3.1.15.15.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">13.3</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.16.16\" class=\"ltx_tr\">&#13;\n<td id=\"S4.T3.1.16.16.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T3.1.16.16.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Video</span></td>&#13;\n<td id=\"S4.T3.1.16.16.2\" class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\">&#13;\n<span id=\"S4.T3.1.16.16.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">VIBE </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T3.1.16.16.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib26\" title=\"\" class=\"ltx_ref\">26</a><span id=\"S4.T3.1.16.16.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</td>&#13;\n<td id=\"S4.T3.1.16.16.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\"><span id=\"S4.T3.1.16.16.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">24.1</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[19] [19]\r\n\r\nAngjoo Kanazawa, Michael¬†J. Black, David¬†W. Jacobs, and Jitendra Malik.\r\n\r\n\r\nEnd-to-end recovery of human shape and pose.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2018.",
            "[28] [28]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis.\r\n\r\n\r\nConvolutional mesh regression for single-image human shape\r\nreconstruction.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2019.",
            "[27] [27]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, Michael¬†J Black, and Kostas Daniilidis.\r\n\r\n\r\nLearning to reconstruct 3D human pose and shape via model-fitting\r\nin the loop.\r\n\r\n\r\nIn Proceedings of the IEEE International Conference on Computer\r\nVision (ICCV), 2019.",
            "[57] [57]\r\n\r\nHongwen Zhang, Jie Cao, Guo Lu, Wanli Ouyang, and Zhenan Sun.\r\n\r\n\r\nDanet: Decompose-and-aggregate network for 3D human shape and pose\r\nestimation.\r\n\r\n\r\nIn Proceedings of the 27th ACM International Conference on\r\nMultimedia, pages 935‚Äì944, 2019.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020.",
            "[19] [19]\r\n\r\nAngjoo Kanazawa, Michael¬†J. Black, David¬†W. Jacobs, and Jitendra Malik.\r\n\r\n\r\nEnd-to-end recovery of human shape and pose.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2018.",
            "[28] [28]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis.\r\n\r\n\r\nConvolutional mesh regression for single-image human shape\r\nreconstruction.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2019.",
            "[27] [27]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, Michael¬†J Black, and Kostas Daniilidis.\r\n\r\n\r\nLearning to reconstruct 3D human pose and shape via model-fitting\r\nin the loop.\r\n\r\n\r\nIn Proceedings of the IEEE International Conference on Computer\r\nVision (ICCV), 2019.",
            "[57] [57]\r\n\r\nHongwen Zhang, Jie Cao, Guo Lu, Wanli Ouyang, and Zhenan Sun.\r\n\r\n\r\nDanet: Decompose-and-aggregate network for 3D human shape and pose\r\nestimation.\r\n\r\n\r\nIn Proceedings of the 27th ACM International Conference on\r\nMultimedia, pages 935‚Äì944, 2019.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020.",
            "[26] [26]\r\n\r\nMuhammed Kocabas, Nikos Athanasiou, and Michael¬†J. Black.\r\n\r\n\r\nVIBE: Video inference for human body pose and shape estimation.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2020.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020.",
            "[26] [26]\r\n\r\nMuhammed Kocabas, Nikos Athanasiou, and Michael¬†J. Black.\r\n\r\n\r\nVIBE: Video inference for human body pose and shape estimation.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2020."
        ],
        "references": [
            "Shape prediction. Our method surpasses the state-of-the-art on SSP-3D in the single-input case (group size of 1), as shown in Table 3 and Figure 5. The improvement over the similar synthetic training method in STRAPS [45] is primarily due to our improved training data augmentations. When using groups of multiple images as inputs (with group size = 5), probabilistic combination outperforms simple averaging of predictions from all other methods. The distribution of errors per SSP-3D sample, shown in Figure 6, suggests that probabilistic combination particularly improves errors for challenging samples, where the uncertainty weighting is more meaningful."
        ]
    },
    "id_table_4": {
        "caption": "Table 4: Comparison with the state-of-the-art in terms of MPJPE-SC and MPJPE-PA (both mm) on 3DPW [52]. Methods in the top half require training images paired with 3D ground-truth, methods in the bottom half do not.",
        "table": [
            "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S4.T4.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Method</span></th>&#13;\n<td id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" colspan=\"2\"><span id=\"S4.T4.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3DPW</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.2.2.1\" class=\"ltx_td ltx_th ltx_th_row\" style=\"padding-bottom:1.93748pt;\"/>&#13;\n<td id=\"S4.T4.1.2.2.2\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:1.93748pt;\"><span id=\"S4.T4.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">MPJPE-SC</span></td>&#13;\n<td id=\"S4.T4.1.2.2.3\" class=\"ltx_td ltx_align_center\" style=\"padding-bottom:1.93748pt;\"><span id=\"S4.T4.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">MPJPE-PA</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.3.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.3.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">&#13;\n<span id=\"S4.T4.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">HMR </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.3.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a><span id=\"S4.T4.1.3.3.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.3.3.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">102.8</span></td>&#13;\n<td id=\"S4.T4.1.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">71.5</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.4.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">GraphCMR </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.4.4.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\">28</a><span id=\"S4.T4.1.4.4.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.4.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">102.0</span></td>&#13;\n<td id=\"S4.T4.1.4.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">70.2</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.5.5\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.5.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">SPIN </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.5.5.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a><span id=\"S4.T4.1.5.5.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.5.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.4</span></td>&#13;\n<td id=\"S4.T4.1.5.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">59.2</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.6.6\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.6.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">I2L-MeshNet </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.6.6.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\">36</a><span id=\"S4.T4.1.6.6.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.6.6.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>&#13;\n<td id=\"S4.T4.1.6.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">57.7</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.7.7\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.7.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Biggs et al. </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.7.7.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib5\" title=\"\" class=\"ltx_ref\">5</a><span id=\"S4.T4.1.7.7.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.7.7.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>&#13;\n<td id=\"S4.T4.1.7.7.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">55.6</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.8.8\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.8.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.8.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">DaNet </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.8.8.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib57\" title=\"\" class=\"ltx_ref\">57</a><span id=\"S4.T4.1.8.8.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.8.8.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.8.8.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">82.4</span></td>&#13;\n<td id=\"S4.T4.1.8.8.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.8.8.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">54.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.9.9\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.9.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\">&#13;\n<span id=\"S4.T4.1.9.9.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">HMR (unpaired) </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.9.9.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib19\" title=\"\" class=\"ltx_ref\">19</a><span id=\"S4.T4.1.9.9.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.9.9.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">126.3</span></td>&#13;\n<td id=\"S4.T4.1.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S4.T4.1.9.9.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">92.0</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.10.10\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.10.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.10.10.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Kundu et al. </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.10.10.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib29\" title=\"\" class=\"ltx_ref\">29</a><span id=\"S4.T4.1.10.10.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.10.10.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.10.10.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">-</span></td>&#13;\n<td id=\"S4.T4.1.10.10.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.10.10.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">89.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.11.11\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.11.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\">&#13;\n<span id=\"S4.T4.1.11.11.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">STRAPS </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S4.T4.1.11.11.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">45</a><span id=\"S4.T4.1.11.11.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S4.T4.1.11.11.2\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.11.11.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">99.0</span></td>&#13;\n<td id=\"S4.T4.1.11.11.3\" class=\"ltx_td ltx_align_center\"><span id=\"S4.T4.1.11.11.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">66.8</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.12.12\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.12.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\"><span id=\"S4.T4.1.12.12.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></th>&#13;\n<td id=\"S4.T4.1.12.12.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.12.12.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">90.9</span></td>&#13;\n<td id=\"S4.T4.1.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S4.T4.1.12.12.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">61.0</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[19] [19]\r\n\r\nAngjoo Kanazawa, Michael¬†J. Black, David¬†W. Jacobs, and Jitendra Malik.\r\n\r\n\r\nEnd-to-end recovery of human shape and pose.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2018.",
            "[28] [28]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis.\r\n\r\n\r\nConvolutional mesh regression for single-image human shape\r\nreconstruction.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2019.",
            "[27] [27]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, Michael¬†J Black, and Kostas Daniilidis.\r\n\r\n\r\nLearning to reconstruct 3D human pose and shape via model-fitting\r\nin the loop.\r\n\r\n\r\nIn Proceedings of the IEEE International Conference on Computer\r\nVision (ICCV), 2019.",
            "[36] [36]\r\n\r\nGyeongsik Moon and Kyoung¬†Mu Lee.\r\n\r\n\r\nI2l-meshnet: Image-to-lixel prediction network for accurate 3d human\r\npose and mesh estimation from a single rgb image.\r\n\r\n\r\nIn Proceedings of the European Conference on Computer Vision\r\n(ECCV), 2020.",
            "[5] [5]\r\n\r\nBenjamin Biggs, S√©bastien Erhardt, Hanbyul Joo, Benjamin Graham, Andrea\r\nVedaldi, and David Novotny.\r\n\r\n\r\n3D multibodies: Fitting sets of plausible 3D models to ambiguous\r\nimage data.\r\n\r\n\r\nIn Advances in Neural Information Processing Systems (NeuRIPS),\r\n2020.",
            "[57] [57]\r\n\r\nHongwen Zhang, Jie Cao, Guo Lu, Wanli Ouyang, and Zhenan Sun.\r\n\r\n\r\nDanet: Decompose-and-aggregate network for 3D human shape and pose\r\nestimation.\r\n\r\n\r\nIn Proceedings of the 27th ACM International Conference on\r\nMultimedia, pages 935‚Äì944, 2019.",
            "[19] [19]\r\n\r\nAngjoo Kanazawa, Michael¬†J. Black, David¬†W. Jacobs, and Jitendra Malik.\r\n\r\n\r\nEnd-to-end recovery of human shape and pose.\r\n\r\n\r\nIn Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR), 2018.",
            "[29] [29]\r\n\r\nJogendra¬†Nath Kundu, Mugalodi Rakesh, Varun Jampani, Rahul¬†M Venkatesh, and\r\nR.¬†Venkatesh Babu.\r\n\r\n\r\nAppearance consensus driven self-supervised human mesh recovery.\r\n\r\n\r\nIn Proceedings of the European Conference on Computer Vision\r\n(ECCV), 2020.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020.",
            "[52] [52]\r\n\r\nTimo von Marcard, Roberto Henschel, Michael Black, Bodo Rosenhahn, and Gerard\r\nPons-Moll.\r\n\r\n\r\nRecovering accurate 3D human pose in the wild using imus and a\r\nmoving camera.\r\n\r\n\r\nIn Proceedings of the European Conference on Computer Vision\r\n(ECCV), 2018."
        ],
        "references": [
            "Pose prediction. While we focus on body shape estimation, Table 4 shows that our method is competitive with the state-of-the-art on 3DPW, and surpasses other methods that do not require training images paired with 3D labels. Figure 6 demonstrates that our method does well on low-to-medium difficulty samples, but struggles with the most challenging ones, which typically exhibit very severe occlusions leading to degraded proxy representations. Nevertheless, we outperform STRAPS [45] on these challenging samples due to improved data augmentation and the adaptive loss weighting discussed in Section 3.5, which results in a more stable improvement of pose metrics during training."
        ]
    },
    "id_table_5": {
        "caption": "Table 5: Comparison with the state-of-the-art in terms of tape measurement RMSE (cm) on our private shape evaluation dataset. Errors are reported for the chest (C), stomach (S), hips (H), biceps (B), forearms (F) and thighs (T).",
        "table": [
            "<table id=\"S5.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T5.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.1.1.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\" rowspan=\"2\"><span id=\"S5.T5.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Group size</span></th>&#13;\n<th id=\"S5.T5.1.1.1.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Method</span></th>&#13;\n<td id=\"S5.T5.1.1.1.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\" colspan=\"6\"><span id=\"S5.T5.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">RMSE</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.2.2.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<td id=\"S5.T5.1.2.2.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">C</span></td>&#13;\n<td id=\"S5.T5.1.2.2.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">S</span></td>&#13;\n<td id=\"S5.T5.1.2.2.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">H</span></td>&#13;\n<td id=\"S5.T5.1.2.2.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.2.2.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">B</span></td>&#13;\n<td id=\"S5.T5.1.2.2.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.2.2.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">F</span></td>&#13;\n<td id=\"S5.T5.1.2.2.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.2.2.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">T</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.3.3\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.3.3.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\" rowspan=\"3\"><span id=\"S5.T5.1.3.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">1</span></th>&#13;\n<th id=\"S5.T5.1.3.3.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">&#13;\n<span id=\"S5.T5.1.3.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">SPIN </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S5.T5.1.3.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a><span id=\"S5.T5.1.3.3.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S5.T5.1.3.3.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.3.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.9</span></td>&#13;\n<td id=\"S5.T5.1.3.3.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.3.3.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">8.0</span></td>&#13;\n<td id=\"S5.T5.1.3.3.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.3.3.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.6</span></td>&#13;\n<td id=\"S5.T5.1.3.3.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.3.3.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.9</span></td>&#13;\n<td id=\"S5.T5.1.3.3.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.3.3.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">2.5</span></td>&#13;\n<td id=\"S5.T5.1.3.3.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.3.3.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.3</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.4.4.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">&#13;\n<span id=\"S5.T5.1.4.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">STRAPS </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S5.T5.1.4.4.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">45</a><span id=\"S5.T5.1.4.4.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite>&#13;\n</th>&#13;\n<td id=\"S5.T5.1.4.4.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.4.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.7</span></td>&#13;\n<td id=\"S5.T5.1.4.4.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.4.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.3</span></td>&#13;\n<td id=\"S5.T5.1.4.4.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.4.4.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.3</span></td>&#13;\n<td id=\"S5.T5.1.4.4.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.4.4.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.9</span></td>&#13;\n<td id=\"S5.T5.1.4.4.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.4.4.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.8</span></td>&#13;\n<td id=\"S5.T5.1.4.4.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.4.4.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.7</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.5.5\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.5.5.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours</span></th>&#13;\n<td id=\"S5.T5.1.5.5.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.9</span></td>&#13;\n<td id=\"S5.T5.1.5.5.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.7</span></td>&#13;\n<td id=\"S5.T5.1.5.5.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.5</span></td>&#13;\n<td id=\"S5.T5.1.5.5.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.2</span></td>&#13;\n<td id=\"S5.T5.1.5.5.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.8</span></td>&#13;\n<td id=\"S5.T5.1.5.5.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.5.5.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.9</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.6.6\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.6.6.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\" rowspan=\"3\"><span id=\"S5.T5.1.6.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">4</span></th>&#13;\n<th id=\"S5.T5.1.6.6.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">&#13;\n<span id=\"S5.T5.1.6.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">SPIN </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S5.T5.1.6.6.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\">27</a><span id=\"S5.T5.1.6.6.2.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S5.T5.1.6.6.2.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</th>&#13;\n<td id=\"S5.T5.1.6.6.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.6.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.5</span></td>&#13;\n<td id=\"S5.T5.1.6.6.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.6.6.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">8.1</span></td>&#13;\n<td id=\"S5.T5.1.6.6.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.6.6.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.4</span></td>&#13;\n<td id=\"S5.T5.1.6.6.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.6.6.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.7</span></td>&#13;\n<td id=\"S5.T5.1.6.6.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.6.6.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">2.4</span></td>&#13;\n<td id=\"S5.T5.1.6.6.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.6.6.8.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.7.7\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.7.7.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\">&#13;\n<span id=\"S5.T5.1.7.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">STRAPS </span><cite class=\"ltx_cite ltx_citemacro_cite\"><span id=\"S5.T5.1.7.7.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">[</span><a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\">45</a><span id=\"S5.T5.1.7.7.1.3.2\" class=\"ltx_text\" style=\"font-size:90%;\">]</span></cite><span id=\"S5.T5.1.7.7.1.4\" class=\"ltx_text\" style=\"font-size:90%;\"> + Mean</span>&#13;\n</th>&#13;\n<td id=\"S5.T5.1.7.7.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.7.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">6.1</span></td>&#13;\n<td id=\"S5.T5.1.7.7.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.7.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.2</span></td>&#13;\n<td id=\"S5.T5.1.7.7.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.7.7.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.0</span></td>&#13;\n<td id=\"S5.T5.1.7.7.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.7.7.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.2</span></td>&#13;\n<td id=\"S5.T5.1.7.7.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.7.7.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.7</span></td>&#13;\n<td id=\"S5.T5.1.7.7.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.7.7.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.3</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.8.8\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.8.8.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + Mean</span></th>&#13;\n<td id=\"S5.T5.1.8.8.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.4</span></td>&#13;\n<td id=\"S5.T5.1.8.8.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.9</span></td>&#13;\n<td id=\"S5.T5.1.8.8.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.4.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.8</span></td>&#13;\n<td id=\"S5.T5.1.8.8.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.5.1\" class=\"ltx_text\" style=\"font-size:90%;\">4.9</span></td>&#13;\n<td id=\"S5.T5.1.8.8.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.6.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">1.6</span></td>&#13;\n<td id=\"S5.T5.1.8.8.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.8.8.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">3.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S5.T5.1.9.9\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T5.1.9.9.1\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"/>&#13;\n<th id=\"S5.T5.1.9.9.2\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Ours + PC</span></th>&#13;\n<td id=\"S5.T5.1.9.9.3\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.1</span></td>&#13;\n<td id=\"S5.T5.1.9.9.4\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">3.8</span></td>&#13;\n<td id=\"S5.T5.1.9.9.5\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">2.7</span></td>&#13;\n<td id=\"S5.T5.1.9.9.6\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.6.1\" class=\"ltx_text\" style=\"font-size:90%;\">5.0</span></td>&#13;\n<td id=\"S5.T5.1.9.9.7\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.7.1\" class=\"ltx_text\" style=\"font-size:90%;\">1.7</span></td>&#13;\n<td id=\"S5.T5.1.9.9.8\" class=\"ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b\" style=\"padding-left:0.0pt;padding-right:0.0pt;\"><span id=\"S5.T5.1.9.9.8.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">2.8</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[27] [27]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, Michael¬†J Black, and Kostas Daniilidis.\r\n\r\n\r\nLearning to reconstruct 3D human pose and shape via model-fitting\r\nin the loop.\r\n\r\n\r\nIn Proceedings of the IEEE International Conference on Computer\r\nVision (ICCV), 2019.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020.",
            "[27] [27]\r\n\r\nNikos Kolotouros, Georgios Pavlakos, Michael¬†J Black, and Kostas Daniilidis.\r\n\r\n\r\nLearning to reconstruct 3D human pose and shape via model-fitting\r\nin the loop.\r\n\r\n\r\nIn Proceedings of the IEEE International Conference on Computer\r\nVision (ICCV), 2019.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020."
        ],
        "references": [
            "Table 5 compares tape measurement errors computed using shape predictions from our method and competitors on a private dataset. Probabilistic combination results in the lowest measurement errors for large body parts, such as the chest, stomach, waist and hips. However, it is less accurate on smaller body parts (e.g. biceps and forearms), which are significantly obscured by clothing. In general, our method may over-estimate measurements for subjects with loose clothing, since silhouette-based inputs don‚Äôt distinguish between clothing and the human body."
        ]
    },
    "id_table_6": {
        "caption": "Table 6: List of synthetic training data augmentations and their associated hyperparameter values. Body part occlusion uses the 24 DensePose [13] parts. Joint L/R swap is done for shoulders, elbows, wrists, hips, knees, ankles.",
        "table": [
            "<table id=\"S7.T6.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S7.T6.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T6.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T6.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Augmentation</span></th>&#13;\n<th id=\"S7.T6.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T6.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Hyperparameter</span></th>&#13;\n<th id=\"S7.T6.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T6.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Value</span></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S7.T6.1.2.1\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S7.T6.1.2.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Body part occlusion</span></td>&#13;\n<td id=\"S7.T6.1.2.1.2\" class=\"ltx_td ltx_align_left ltx_border_t\"><span id=\"S7.T6.1.2.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Occlusion prob.</span></td>&#13;\n<td id=\"S7.T6.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T6.1.2.1.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T6.1.3.2\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.3.2.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.3.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2D joints L/R swap</span></td>&#13;\n<td id=\"S7.T6.1.3.2.2\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.3.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Swap prob.</span></td>&#13;\n<td id=\"S7.T6.1.3.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T6.1.3.2.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T6.1.4.3\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.4.3.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.4.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Half-image occlusion</span></td>&#13;\n<td id=\"S7.T6.1.4.3.2\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.4.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Occlusion prob.</span></td>&#13;\n<td id=\"S7.T6.1.4.3.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T6.1.4.3.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.05</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T6.1.5.4\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.5.4.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.5.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2D joints removal</span></td>&#13;\n<td id=\"S7.T6.1.5.4.2\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.5.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Removal prob.</span></td>&#13;\n<td id=\"S7.T6.1.5.4.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T6.1.5.4.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T6.1.6.5\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.6.5.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.6.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2D joints noise</span></td>&#13;\n<td id=\"S7.T6.1.6.5.2\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.6.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Noise range</span></td>&#13;\n<td id=\"S7.T6.1.6.5.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T6.1.6.5.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">[-8, 8] pixels</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T6.1.7.6\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.7.6.1\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.7.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2D vertices noise</span></td>&#13;\n<td id=\"S7.T6.1.7.6.2\" class=\"ltx_td ltx_align_left\"><span id=\"S7.T6.1.7.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Noise range</span></td>&#13;\n<td id=\"S7.T6.1.7.6.3\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T6.1.7.6.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">[-10, 10] mm</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T6.1.8.7\" class=\"ltx_tr\">&#13;\n<td id=\"S7.T6.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S7.T6.1.8.7.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Occlusion box</span></td>&#13;\n<td id=\"S7.T6.1.8.7.2\" class=\"ltx_td ltx_align_left ltx_border_b\"><span id=\"S7.T6.1.8.7.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Probability, Size</span></td>&#13;\n<td id=\"S7.T6.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S7.T6.1.8.7.3.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.5, 48 pixels</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[13] [13]\r\n\r\nRiza¬†Alp G√ºler, Natalia Neverova, and Iasonas Kokkinos.\r\n\r\n\r\nDensepose: Dense human pose estimation in the wild.\r\n\r\n\r\nIn Proceedings of IEEE Conference on Computer Vision and Pattern\r\nRecognition (CVPR), 2018."
        ],
        "references": [
            "Training. Table 6 lists the data augmentation methods used to bridge the synthetic-to-real domain gap during synthetic training data generation, along with associated hyperparameter values. Table 7 lists additional hyperparameter values not given in the main manuscript.",
            "Evaluation using ground-truth vs predicted inputs. The synthetic training data augmentations listed in Table 6 and the main manuscript are used to increase the robustness of our distribution prediction neural network to noisy and occluded test data, as demonstrated in Figure 9. However, the synthetic-to-real domain gap still persists, as evidenced by Table 8, which compares body shape and pose prediction metrics when using ground-truth, synthetic ground-truth and predicted input proxy representations. A significant improvement in both body shape and pose metrics is observed when using synthetic inputs, instead of predicted inputs. This is mostly because predicted input silhouettes and 2D joints can be very inaccurate in cases with challenging poses, significant occlusion or occluding humans, such that the synthetic training data augmentations are not sufficient. Moreover, synthetic SMPL human silhouettes are not clothed, while silhouette predictors generally classify clothing pixels as part of the human body. This is particularly detrimental to body shape prediction metrics when subjects are dressed in loose clothing, as can be seen in Figure 9 (left side, rows 3 and 4), where our method tends to over-estimate the subject‚Äôs body proportions."
        ]
    },
    "id_table_7": {
        "caption": "Table 7: List of hyperparameter values not provided in the main manuscript.",
        "table": [
            "<table id=\"S7.T7.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S7.T7.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t\"><span id=\"S7.T7.1.2.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Hyperparameter</span></th>&#13;\n<th id=\"S7.T7.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\"><span id=\"S7.T7.1.2.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:90%;\">Value</span></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S7.T7.1.3.1\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t\"><span id=\"S7.T7.1.3.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Shape parameter sampling mean</span></th>&#13;\n<td id=\"S7.T7.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S7.T7.1.3.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T7.1.4.2\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.4.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T7.1.4.2.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Shape parameter sampling var.</span></th>&#13;\n<td id=\"S7.T7.1.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T7.1.4.2.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">2.25</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T7.1.5.3\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T7.1.5.3.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cam. translation sampling mean</span></th>&#13;\n<td id=\"S7.T7.1.5.3.2\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T7.1.5.3.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">(0, -0.2, 2.5) m</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T7.1.6.4\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.6.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T7.1.6.4.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cam. translation sampling var.</span></th>&#13;\n<td id=\"S7.T7.1.6.4.2\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T7.1.6.4.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">(0.05, 0.05, 0.25) m</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T7.1.7.5\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.7.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T7.1.7.5.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">Cam. focal length</span></th>&#13;\n<td id=\"S7.T7.1.7.5.2\" class=\"ltx_td ltx_align_center\"><span id=\"S7.T7.1.7.5.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">300.0</span></td>&#13;\n</tr>&#13;\n<tr id=\"S7.T7.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row\"><span id=\"S7.T7.1.1.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">Proxy representation dimensions</span></th>&#13;\n<td id=\"S7.T7.1.1.1\" class=\"ltx_td ltx_align_center\">&#13;\n<math id=\"S7.T7.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"256\\times 256\" display=\"inline\"><semantics id=\"S7.T7.1.1.1.m1.1a\"><mrow id=\"S7.T7.1.1.1.m1.1.1\" xref=\"S7.T7.1.1.1.m1.1.1.cmml\"><mn mathsize=\"90%\" id=\"S7.T7.1.1.1.m1.1.1.2\" xref=\"S7.T7.1.1.1.m1.1.1.2.cmml\">256</mn><mo lspace=\"0.222em\" mathsize=\"90%\" rspace=\"0.222em\" id=\"S7.T7.1.1.1.m1.1.1.1\" xref=\"S7.T7.1.1.1.m1.1.1.1.cmml\">&#215;</mo><mn mathsize=\"90%\" id=\"S7.T7.1.1.1.m1.1.1.3\" xref=\"S7.T7.1.1.1.m1.1.1.3.cmml\">256</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S7.T7.1.1.1.m1.1b\"><apply id=\"S7.T7.1.1.1.m1.1.1.cmml\" xref=\"S7.T7.1.1.1.m1.1.1\"><times id=\"S7.T7.1.1.1.m1.1.1.1.cmml\" xref=\"S7.T7.1.1.1.m1.1.1.1\"/><cn type=\"integer\" id=\"S7.T7.1.1.1.m1.1.1.2.cmml\" xref=\"S7.T7.1.1.1.m1.1.1.2\">256</cn><cn type=\"integer\" id=\"S7.T7.1.1.1.m1.1.1.3.cmml\" xref=\"S7.T7.1.1.1.m1.1.1.3\">256</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S7.T7.1.1.1.m1.1c\">256\\times 256</annotation></semantics></math><span id=\"S7.T7.1.1.1.1\" class=\"ltx_text\" style=\"font-size:90%;\"> pixels</span>&#13;\n</td>&#13;\n</tr>&#13;\n<tr id=\"S7.T7.1.8.6\" class=\"ltx_tr\">&#13;\n<th id=\"S7.T7.1.8.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b\"><span id=\"S7.T7.1.8.6.1.1\" class=\"ltx_text\" style=\"font-size:90%;\">2D joint confidence threshold</span></th>&#13;\n<td id=\"S7.T7.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S7.T7.1.8.6.2.1\" class=\"ltx_text\" style=\"font-size:90%;\">0.025</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [],
        "references": [
            "Training. Table 6 lists the data augmentation methods used to bridge the synthetic-to-real domain gap during synthetic training data generation, along with associated hyperparameter values. Table 7 lists additional hyperparameter values not given in the main manuscript."
        ]
    },
    "id_table_8": {
        "caption": "Table 8: Comparison between ground-truth (GT), synthetic ground-truth and predicted input silhouettes and 2D joints, in terms of MPJPE-SC and MPJPE-PA (both in mm) on 3DPW [52], as well as PVE-PA and PVE-T-SC (both in mm) on SSP-3D [45]. Predicted silhouettes are obtained using DensePose [13] and predicted 2D joint coordinates and confidences (for thresholding) are obtained using Keypoint-RCNN from Detectron2 [53]. Synthetic ground-truth inputs are obtained by rendering the SMPL [33] body mesh labels given by SSP-3D and 3DPW, using ground-truth camera parameters, into silhouette and 2D joint input representations.",
        "table": [
            "<table id=\"S8.T8.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S8.T8.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S8.T8.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t\" rowspan=\"2\"><span id=\"S8.T8.1.1.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">Input</span></th>&#13;\n<th id=\"S8.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\"><span id=\"S8.T8.1.1.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">3DPW</span></th>&#13;\n<th id=\"S8.T8.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" colspan=\"2\"><span id=\"S8.T8.1.1.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">SSP-3D</span></th>&#13;\n</tr>&#13;\n<tr id=\"S8.T8.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S8.T8.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S8.T8.1.2.2.1.1\" class=\"ltx_text\" style=\"font-size:120%;\">MPJPE-SC</span></th>&#13;\n<th id=\"S8.T8.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S8.T8.1.2.2.2.1\" class=\"ltx_text\" style=\"font-size:120%;\">MPJPE-PA</span></th>&#13;\n<th id=\"S8.T8.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S8.T8.1.2.2.3.1\" class=\"ltx_text\" style=\"font-size:120%;\">PVE-PA</span></th>&#13;\n<th id=\"S8.T8.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column\"><span id=\"S8.T8.1.2.2.4.1\" class=\"ltx_text\" style=\"font-size:120%;\">PVE-T-SC</span></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S8.T8.1.3.1\" class=\"ltx_tr\">&#13;\n<td id=\"S8.T8.1.3.1.1\" class=\"ltx_td ltx_align_left ltx_border_t\">&#13;\n<span id=\"S8.T8.1.3.1.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">GT Synthetic</span><span id=\"S8.T8.1.3.1.1.2\" class=\"ltx_text\" style=\"font-size:120%;\"> Silh. + 2D Joint Heatmaps</span>&#13;\n</td>&#13;\n<td id=\"S8.T8.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S8.T8.1.3.1.2.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">64.3</span></td>&#13;\n<td id=\"S8.T8.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S8.T8.1.3.1.3.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">45.7</span></td>&#13;\n<td id=\"S8.T8.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S8.T8.1.3.1.4.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">52.9</span></td>&#13;\n<td id=\"S8.T8.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\"><span id=\"S8.T8.1.3.1.5.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">10.1</span></td>&#13;\n</tr>&#13;\n<tr id=\"S8.T8.1.4.2\" class=\"ltx_tr\">&#13;\n<td id=\"S8.T8.1.4.2.1\" class=\"ltx_td ltx_align_left\">&#13;\n<span id=\"S8.T8.1.4.2.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">GT</span><span id=\"S8.T8.1.4.2.1.2\" class=\"ltx_text\" style=\"font-size:120%;\"> Silh. + 2D Joint Heatmaps</span>&#13;\n</td>&#13;\n<td id=\"S8.T8.1.4.2.2\" class=\"ltx_td ltx_align_center\"><span id=\"S8.T8.1.4.2.2.1\" class=\"ltx_text\" style=\"font-size:120%;\">-</span></td>&#13;\n<td id=\"S8.T8.1.4.2.3\" class=\"ltx_td ltx_align_center\"><span id=\"S8.T8.1.4.2.3.1\" class=\"ltx_text\" style=\"font-size:120%;\">-</span></td>&#13;\n<td id=\"S8.T8.1.4.2.4\" class=\"ltx_td ltx_align_center\"><span id=\"S8.T8.1.4.2.4.1\" class=\"ltx_text\" style=\"font-size:120%;\">69.9</span></td>&#13;\n<td id=\"S8.T8.1.4.2.5\" class=\"ltx_td ltx_align_center\"><span id=\"S8.T8.1.4.2.5.1\" class=\"ltx_text\" style=\"font-size:120%;\">14.4</span></td>&#13;\n</tr>&#13;\n<tr id=\"S8.T8.1.5.3\" class=\"ltx_tr\">&#13;\n<td id=\"S8.T8.1.5.3.1\" class=\"ltx_td ltx_align_left ltx_border_b\">&#13;\n<span id=\"S8.T8.1.5.3.1.1\" class=\"ltx_text ltx_font_bold\" style=\"font-size:120%;\">Predicted</span><span id=\"S8.T8.1.5.3.1.2\" class=\"ltx_text\" style=\"font-size:120%;\"> Silh. + 2D Joint Heatmaps</span>&#13;\n</td>&#13;\n<td id=\"S8.T8.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S8.T8.1.5.3.2.1\" class=\"ltx_text\" style=\"font-size:120%;\">90.9</span></td>&#13;\n<td id=\"S8.T8.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S8.T8.1.5.3.3.1\" class=\"ltx_text\" style=\"font-size:120%;\">61.0</span></td>&#13;\n<td id=\"S8.T8.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S8.T8.1.5.3.4.1\" class=\"ltx_text\" style=\"font-size:120%;\">71.4</span></td>&#13;\n<td id=\"S8.T8.1.5.3.5\" class=\"ltx_td ltx_align_center ltx_border_b\"><span id=\"S8.T8.1.5.3.5.1\" class=\"ltx_text\" style=\"font-size:120%;\">15.2</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[52] [52]\r\n\r\nTimo von Marcard, Roberto Henschel, Michael Black, Bodo Rosenhahn, and Gerard\r\nPons-Moll.\r\n\r\n\r\nRecovering accurate 3D human pose in the wild using imus and a\r\nmoving camera.\r\n\r\n\r\nIn Proceedings of the European Conference on Computer Vision\r\n(ECCV), 2018.",
            "[45] [45]\r\n\r\nAkash Sengupta, Ignas Budvytis, and Roberto Cipolla.\r\n\r\n\r\nSynthetic training for accurate 3d human pose and shape estimation in\r\nthe wild.\r\n\r\n\r\nIn Proceedings of the British Machine Vision Conference (BMVC),\r\n2020.",
            "[13] [13]\r\n\r\nRiza¬†Alp G√ºler, Natalia Neverova, and Iasonas Kokkinos.\r\n\r\n\r\nDensepose: Dense human pose estimation in the wild.\r\n\r\n\r\nIn Proceedings of IEEE Conference on Computer Vision and Pattern\r\nRecognition (CVPR), 2018.",
            "[53] [53]\r\n\r\nYuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick.\r\n\r\n\r\nDetectron2.\r\n\r\n\r\nhttps://github.com/facebookresearch/detectron2, 2019.",
            "[33] [33]\r\n\r\nMatthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael¬†J.\r\nBlack.\r\n\r\n\r\nSMPL: A skinned multi-person linear model.\r\n\r\n\r\nIn ACM Transactions on Graphics (TOG) - Proceedings of ACM\r\nSIGGRAPH Asia, volume¬†34, pages 248:1‚Äì248:16. ACM, 2015."
        ],
        "references": [
            "Evaluation using ground-truth vs predicted inputs. The synthetic training data augmentations listed in Table 6 and the main manuscript are used to increase the robustness of our distribution prediction neural network to noisy and occluded test data, as demonstrated in Figure 9. However, the synthetic-to-real domain gap still persists, as evidenced by Table 8, which compares body shape and pose prediction metrics when using ground-truth, synthetic ground-truth and predicted input proxy representations. A significant improvement in both body shape and pose metrics is observed when using synthetic inputs, instead of predicted inputs. This is mostly because predicted input silhouettes and 2D joints can be very inaccurate in cases with challenging poses, significant occlusion or occluding humans, such that the synthetic training data augmentations are not sufficient. Moreover, synthetic SMPL human silhouettes are not clothed, while silhouette predictors generally classify clothing pixels as part of the human body. This is particularly detrimental to body shape prediction metrics when subjects are dressed in loose clothing, as can be seen in Figure 9 (left side, rows 3 and 4), where our method tends to over-estimate the subject‚Äôs body proportions."
        ]
    }
}