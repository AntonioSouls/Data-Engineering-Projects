{
    "id_table_1": {
        "caption": "Table 1: Popular datasets used to compare, train and test human pose estimation models. Video frames, the number of subjects and actions give an indication about the dataset diversity and the number of pose configurations. The number of views from RGB cameras, the resolution and acquisition frequency of cameras assess the quality and quantity of exploitable video information. Inertial Measurement Units (IMU) are sometimes used to refine results from the motion capture or single-image detection. If not specified, the motion capture method is marker-based.",
        "table": [
            "<table id=\"S2.T1.3.3\" class=\"ltx_tabular ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S2.T1.3.3.4.1\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.4.1.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Dataset</td>&#13;\n<td id=\"S2.T1.3.3.4.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Frame</td>&#13;\n<td id=\"S2.T1.3.3.4.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#Subject</td>&#13;\n<td id=\"S2.T1.3.3.4.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">#View</td>&#13;\n<td id=\"S2.T1.3.3.4.1.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Resolution</td>&#13;\n<td id=\"S2.T1.3.3.4.1.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Frequency</td>&#13;\n<td id=\"S2.T1.3.3.4.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Depth</td>&#13;\n<td id=\"S2.T1.3.3.4.1.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">IMU</td>&#13;\n<td id=\"S2.T1.3.3.4.1.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Context and</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.5.2\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.5.2.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">#Video Sequence</td>&#13;\n<td id=\"S2.T1.3.3.5.2.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.5.2.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Main Characteristics</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.6.3\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.6.3.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Human3.6M: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Ionescu et&#160;al.</span> (<a href=\"#bib.bib27\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2014</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.6.3.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3.6 millions</td>&#13;\n<td id=\"S2.T1.3.3.6.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">11</td>&#13;\n<td id=\"S2.T1.3.3.6.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4</td>&#13;\n<td id=\"S2.T1.3.3.6.3.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1000x1000</td>&#13;\n<td id=\"S2.T1.3.3.6.3.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">50Hz</td>&#13;\n<td id=\"S2.T1.3.3.6.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>&#13;\n<td id=\"S2.T1.3.3.6.3.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.6.3.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Lab environnement</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.7.4\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.7.4.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">1 376</td>&#13;\n<td id=\"S2.T1.3.3.7.4.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.7.4.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.8.5\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.8.5.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">HumanEva: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Sigal et&#160;al.</span> (<a href=\"#bib.bib64\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2010</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.8.5.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">80 000</td>&#13;\n<td id=\"S2.T1.3.3.8.5.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4</td>&#13;\n<td id=\"S2.T1.3.3.8.5.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">7</td>&#13;\n<td id=\"S2.T1.3.3.8.5.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">660x500</td>&#13;\n<td id=\"S2.T1.3.3.8.5.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60Hz</td>&#13;\n<td id=\"S2.T1.3.3.8.5.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.8.5.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.8.5.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Lab environnement</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.9.6\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.9.6.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">56</td>&#13;\n<td id=\"S2.T1.3.3.9.6.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.9.6.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.10.7\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.10.7.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Total Capture: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Trumble et&#160;al.</span> (<a href=\"#bib.bib71\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.10.7.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1.9 millions</td>&#13;\n<td id=\"S2.T1.3.3.10.7.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">5</td>&#13;\n<td id=\"S2.T1.3.3.10.7.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8</td>&#13;\n<td id=\"S2.T1.3.3.10.7.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1920x1080</td>&#13;\n<td id=\"S2.T1.3.3.10.7.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">60Hz</td>&#13;\n<td id=\"S2.T1.3.3.10.7.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.10.7.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>&#13;\n<td id=\"S2.T1.3.3.10.7.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Lab environnement</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.11.8\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.11.8.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.11.8.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.11.8.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Inertial Measurement Units</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.12.9\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.12.9.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.2\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.3\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.12.9.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;In the wild&#8221; &amp; Lab</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.13.10\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.13.10.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">MPI-INF-3DHP: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib47\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2016</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.13.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">1.3 millions</td>&#13;\n<td id=\"S2.T1.3.3.13.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">8</td>&#13;\n<td id=\"S2.T1.3.3.13.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">14</td>&#13;\n<td id=\"S2.T1.3.3.13.10.5\" class=\"ltx_td ltx_align_center ltx_border_r\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.13.10.6\" class=\"ltx_td ltx_align_center ltx_border_r\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.13.10.7\" class=\"ltx_td ltx_align_center ltx_border_r\">No</td>&#13;\n<td id=\"S2.T1.3.3.13.10.8\" class=\"ltx_td ltx_align_center ltx_border_r\">No</td>&#13;\n<td id=\"S2.T1.3.3.13.10.9\" class=\"ltx_td ltx_align_center ltx_border_r\">outdoor/indoor green screens.</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.14.11\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.14.11.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">64</td>&#13;\n<td id=\"S2.T1.3.3.14.11.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.14.11.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Markerless ground truthes</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.15.12\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.15.12.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.2\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.3\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.15.12.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Multi-person, &#8221;In the wild&#8221;</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.16.13\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.16.13.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">MuPoTS-3D (2018): <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib49\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.16.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">8 000</td>&#13;\n<td id=\"S2.T1.3.3.16.13.3\" class=\"ltx_td ltx_align_center ltx_border_r\">8</td>&#13;\n<td id=\"S2.T1.3.3.16.13.4\" class=\"ltx_td ltx_align_center ltx_border_r\">1</td>&#13;\n<td id=\"S2.T1.3.3.16.13.5\" class=\"ltx_td ltx_align_center ltx_border_r\">2048x2048</td>&#13;\n<td id=\"S2.T1.3.3.16.13.6\" class=\"ltx_td ltx_align_center ltx_border_r\">30Hz - 60Hz</td>&#13;\n<td id=\"S2.T1.3.3.16.13.7\" class=\"ltx_td ltx_align_center ltx_border_r\">No</td>&#13;\n<td id=\"S2.T1.3.3.16.13.8\" class=\"ltx_td ltx_align_center ltx_border_r\">No</td>&#13;\n<td id=\"S2.T1.3.3.16.13.9\" class=\"ltx_td ltx_align_center ltx_border_r\">indoor/outdoor scenes.</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.17.14\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.17.14.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.17.14.2\" class=\"ltx_td ltx_align_center ltx_border_r\">20</td>&#13;\n<td id=\"S2.T1.3.3.17.14.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.17.14.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.17.14.5\" class=\"ltx_td ltx_align_center ltx_border_r\">1920x1080</td>&#13;\n<td id=\"S2.T1.3.3.17.14.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.17.14.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.17.14.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.17.14.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Markerless ground truthes</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.18.15\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.18.15.1\" class=\"ltx_td ltx_border_l ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.2\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.3\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S2.T1.3.3.18.15.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;In the wild&#8221; outdoor</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.1.1.1\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r\">3DPW <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><math id=\"S2.T1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"&gt;50000\" display=\"inline\"><semantics id=\"S2.T1.1.1.1.1.m1.1a\"><mrow id=\"S2.T1.1.1.1.1.m1.1.1\" xref=\"S2.T1.1.1.1.1.m1.1.1.cmml\"><mi id=\"S2.T1.1.1.1.1.m1.1.1.2\" xref=\"S2.T1.1.1.1.1.m1.1.1.2.cmml\"/><mo id=\"S2.T1.1.1.1.1.m1.1.1.1\" xref=\"S2.T1.1.1.1.1.m1.1.1.1.cmml\">&gt;</mo><mn id=\"S2.T1.1.1.1.1.m1.1.1.3\" xref=\"S2.T1.1.1.1.1.m1.1.1.3.cmml\">50000</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.1.1.1.1.m1.1b\"><apply id=\"S2.T1.1.1.1.1.m1.1.1.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1\"><gt id=\"S2.T1.1.1.1.1.m1.1.1.1.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1.1\"/><csymbol cd=\"latexml\" id=\"S2.T1.1.1.1.1.m1.1.1.2.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1.2\">absent</csymbol><cn type=\"integer\" id=\"S2.T1.1.1.1.1.m1.1.1.3.cmml\" xref=\"S2.T1.1.1.1.1.m1.1.1.3\">50000</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.1.1.1.1.m1.1c\">&gt;50000</annotation></semantics></math></td>&#13;\n<td id=\"S2.T1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r\">7</td>&#13;\n<td id=\"S2.T1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\">1</td>&#13;\n<td id=\"S2.T1.1.1.1.5\" class=\"ltx_td ltx_align_center ltx_border_r\">N/A</td>&#13;\n<td id=\"S2.T1.1.1.1.6\" class=\"ltx_td ltx_align_center ltx_border_r\">30Hz</td>&#13;\n<td id=\"S2.T1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r\">No</td>&#13;\n<td id=\"S2.T1.1.1.1.8\" class=\"ltx_td ltx_align_center ltx_border_r\">Yes</td>&#13;\n<td id=\"S2.T1.1.1.1.9\" class=\"ltx_td ltx_align_center ltx_border_r\">single moving camera &amp; IMUs</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.19.16\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.19.16.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.2\" class=\"ltx_td ltx_align_center ltx_border_r\">60</td>&#13;\n<td id=\"S2.T1.3.3.19.16.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.19.16.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Up to two subjects</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.20.17\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.20.17.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">Carnegie Mellon <cite class=\"ltx_cite ltx_citemacro_cite\"><a href=\"#bib.bib72\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">University</span> </a></cite> Mocap</td>&#13;\n<td id=\"S2.T1.3.3.20.17.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.20.17.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">109</td>&#13;\n<td id=\"S2.T1.3.3.20.17.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1</td>&#13;\n<td id=\"S2.T1.3.3.20.17.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">352x240</td>&#13;\n<td id=\"S2.T1.3.3.20.17.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30Hz</td>&#13;\n<td id=\"S2.T1.3.3.20.17.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.20.17.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.20.17.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Indoor environment</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.21.18\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.21.18.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.2\" class=\"ltx_td ltx_align_center ltx_border_r\">2 605</td>&#13;\n<td id=\"S2.T1.3.3.21.18.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.21.18.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Various actions and subjects</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.2.2.2\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.2.2.2.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">CMU-MMAC: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">De&#160;la Torre et&#160;al.</span> (<a href=\"#bib.bib69\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2008</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#13;\n<math id=\"S2.T1.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\approx\" display=\"inline\"><semantics id=\"S2.T1.2.2.2.1.m1.1a\"><mo id=\"S2.T1.2.2.2.1.m1.1.1\" xref=\"S2.T1.2.2.2.1.m1.1.1.cmml\">&#8776;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.2.2.2.1.m1.1b\"><approx id=\"S2.T1.2.2.2.1.m1.1.1.cmml\" xref=\"S2.T1.2.2.2.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.2.2.2.1.m1.1c\">\\approx</annotation></semantics></math>450 000</td>&#13;\n<td id=\"S2.T1.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">25</td>&#13;\n<td id=\"S2.T1.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">5</td>&#13;\n<td id=\"S2.T1.2.2.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">1024x768 (x3)</td>&#13;\n<td id=\"S2.T1.2.2.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30Hz (x3)</td>&#13;\n<td id=\"S2.T1.2.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.2.2.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>&#13;\n<td id=\"S2.T1.2.2.2.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Lab Environnement</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.22.19\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.22.19.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.22.19.2\" class=\"ltx_td ltx_align_center ltx_border_r\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.22.19.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.22.19.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.22.19.5\" class=\"ltx_td ltx_align_center ltx_border_r\">640x480 (x2)</td>&#13;\n<td id=\"S2.T1.3.3.22.19.6\" class=\"ltx_td ltx_align_center ltx_border_r\">60Hz (x2)</td>&#13;\n<td id=\"S2.T1.3.3.22.19.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.22.19.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.22.19.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Subjects cooking 5 recipes</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.23.20\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.23.20.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">TNT15: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib41\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2016</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.23.20.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">13 000</td>&#13;\n<td id=\"S2.T1.3.3.23.20.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4</td>&#13;\n<td id=\"S2.T1.3.3.23.20.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">8</td>&#13;\n<td id=\"S2.T1.3.3.23.20.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">800x600</td>&#13;\n<td id=\"S2.T1.3.3.23.20.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">50Hz</td>&#13;\n<td id=\"S2.T1.3.3.23.20.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.23.20.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>&#13;\n<td id=\"S2.T1.3.3.23.20.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Office environment</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.24.21\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.24.21.1\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.2\" class=\"ltx_td ltx_align_center ltx_border_r\">20</td>&#13;\n<td id=\"S2.T1.3.3.24.21.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.24.21.9\" class=\"ltx_td ltx_align_center ltx_border_r\">No marker-based labeling, only IMU</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.25.22\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.25.22.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">AMASS: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mahmood et&#160;al.</span> (<a href=\"#bib.bib39\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.25.22.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.25.22.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">346</td>&#13;\n<td id=\"S2.T1.3.3.25.22.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">variable</td>&#13;\n<td id=\"S2.T1.3.3.25.22.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">variable</td>&#13;\n<td id=\"S2.T1.3.3.25.22.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">variable</td>&#13;\n<td id=\"S2.T1.3.3.25.22.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.25.22.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.25.22.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Unified parametrization of 15 datasets</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.3\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.3.2\" class=\"ltx_td ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\">(<math id=\"S2.T1.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"&gt;\" display=\"inline\"><semantics id=\"S2.T1.3.3.3.1.m1.1a\"><mo id=\"S2.T1.3.3.3.1.m1.1.1\" xref=\"S2.T1.3.3.3.1.m1.1.1.cmml\">&gt;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S2.T1.3.3.3.1.m1.1b\"><gt id=\"S2.T1.3.3.3.1.m1.1.1.cmml\" xref=\"S2.T1.3.3.3.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S2.T1.3.3.3.1.m1.1c\">&gt;</annotation></semantics></math>40 hours)</td>&#13;\n<td id=\"S2.T1.3.3.3.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.3.9\" class=\"ltx_td ltx_align_center ltx_border_r\">Mesh body models</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.26.23\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.26.23.1\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\">MoVi: <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Ghorbani et&#160;al.</span> (<a href=\"#bib.bib16\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S2.T1.3.3.26.23.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S2.T1.3.3.26.23.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">90</td>&#13;\n<td id=\"S2.T1.3.3.26.23.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">4</td>&#13;\n<td id=\"S2.T1.3.3.26.23.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">800x600</td>&#13;\n<td id=\"S2.T1.3.3.26.23.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30Hz</td>&#13;\n<td id=\"S2.T1.3.3.26.23.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">No</td>&#13;\n<td id=\"S2.T1.3.3.26.23.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Yes</td>&#13;\n<td id=\"S2.T1.3.3.26.23.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Synchronized MoCap</td>&#13;\n</tr>&#13;\n<tr id=\"S2.T1.3.3.27.24\" class=\"ltx_tr\">&#13;\n<td id=\"S2.T1.3.3.27.24.1\" class=\"ltx_td ltx_border_b ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.27.24.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">(17 hours)</td>&#13;\n<td id=\"S2.T1.3.3.27.24.3\" class=\"ltx_td ltx_border_b ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.27.24.4\" class=\"ltx_td ltx_border_b ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.27.24.5\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">1920x1080</td>&#13;\n<td id=\"S2.T1.3.3.27.24.6\" class=\"ltx_td ltx_border_b ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.27.24.7\" class=\"ltx_td ltx_border_b ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.27.24.8\" class=\"ltx_td ltx_border_b ltx_border_r\"/>&#13;\n<td id=\"S2.T1.3.3.27.24.9\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">shape, video and IMU data</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Ionescu et al. (2014) Ionescu et al. (2014)\r\n\r\nIonescu, C., Papava, D.,\r\nOlaru, V., Sminchisescu, C.,\r\n2014.\r\n\r\n\r\nHuman3.6M: Large Scale Datasets and\r\nPredictive Methods for 3D Human Sensing in Natural\r\nEnvironments.\r\n\r\n\r\nIEEE Transactions on Pattern Analysis and Machine\r\nIntelligence 36, 1325--1339.\r\n\r\n\r\nURL: http://ieeexplore.ieee.org/document/6682899/,\r\ndoi:10.1109/TPAMI.2013.248.",
            "Sigal et al. (2010) Sigal et al. (2010)\r\n\r\nSigal, L., Balan, A.O.,\r\nBlack, M.J., 2010.\r\n\r\n\r\nHumanEva: Synchronized Video and Motion\r\nCapture Dataset and Baseline Algorithm for Evaluation of\r\nArticulated Human Motion.\r\n\r\n\r\nInternational Journal of Computer Vision\r\n87, 4--27.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/s11263-009-0273-6,\r\ndoi:10.1007/s11263-009-0273-6.",
            "Trumble et al. (2017) Trumble et al. (2017)\r\n\r\nTrumble, M., Gilbert, A.,\r\nMalleson, C., Hilton, A.,\r\nCollomosse, J., 2017.\r\n\r\n\r\nTotal Capture: 3D Human Pose Estimation\r\nFusing Video and Inertial Sensors, in:\r\nProcedings of the British Machine Vision\r\nConference 2017, British Machine Vision Association,\r\nLondon, UK. p. 14.\r\n\r\n\r\nURL: http://www.bmva.org/bmvc/2017/papers/paper014/index.html,\r\ndoi:10.5244/C.31.14.",
            "Mehta et al. (2016) Mehta et al. (2016)\r\n\r\nMehta, D., Rhodin, H.,\r\nCasas, D., Fua, P.,\r\nSotnychenko, O., Xu, W.,\r\nTheobalt, C., 2016.\r\n\r\n\r\n[1611.09813] Monocular 3D Human Pose\r\nEstimation In The Wild Using Improved CNN Supervision.\r\n\r\n\r\nURL: https://arxiv.org/abs/1611.09813.",
            "Mehta et al. (2018) Mehta et al. (2018)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nSridhar, S., Pons-Moll, G.,\r\nTheobalt, C., 2018.\r\n\r\n\r\nSingle-Shot Multi-Person 3D Pose\r\nEstimation From Monocular RGB.\r\n\r\n\r\narXiv:1712.03453 [cs] URL: http://arxiv.org/abs/1712.03453. arXiv: 1712.03453.",
            "von Marcard et al. (2018) von Marcard et al. (2018)\r\n\r\nvon Marcard, T., Henschel, R.,\r\nBlack, M.J., Rosenhahn, B.,\r\nPons-Moll, G., 2018.\r\n\r\n\r\nRecovering Accurate 3D Human Pose in the\r\nWild Using IMUs and a Moving Camera, in: Ferrari,\r\nV., Hebert, M., Sminchisescu, C.,\r\nWeiss, Y. (Eds.), Computer Vision –\r\nECCV 2018. Springer International Publishing,\r\nCham. volume 11214, pp.\r\n614--631.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-01249-6_37,\r\ndoi:10.1007/978-3-030-01249-6_37. series Title:\r\nLecture Notes in Computer Science.",
            "University (72)\r\n\r\nUniversity, C.M., .\r\n\r\n\r\nGraphic lab motion capture database.\r\n\r\n\r\nhttp://mocap.cs.cmu.edu/.\r\n\r\n\r\nURL: http://mocap.cs.cmu.edu/. accessed:\r\n2020-04-29.",
            "De la Torre et al. (2008) De la Torre et al. (2008)\r\n\r\nDe la Torre, F., Hodgins, J.,\r\nBargteil, A., Martin, X.,\r\nMacey, J., Collado, A.,\r\nBeltran, P., 2008.\r\n\r\n\r\nGuide to the Carnegie Mellon University\r\nMultimodal Activity (CMU-MMAC) Database.\r\n\r\n\r\nURL: https://www.ri.cmu.edu/publications/guide-to-the-carnegie-mellon-university-multimodal-activity-cmu-mmac-database/.\r\nlibrary Catalog: www.ri.cmu.edu.",
            "von Marcard et al. (2016) von Marcard et al. (2016)\r\n\r\nvon Marcard, T., Pons-Moll, G.,\r\nRosenhahn, B., 2016.\r\n\r\n\r\nHuman pose estimation from video and imus.\r\n\r\n\r\nTransactions on Pattern Analysis and Machine\r\nIntelligence 38, 1533--1547.\r\n\r\n\r\nURL: http://dx.doi.org/10.1109/TPAMI.2016.2522398,\r\ndoi:10.1109/TPAMI.2016.2522398.",
            "Mahmood et al. (2019) Mahmood et al. (2019)\r\n\r\nMahmood, N., Ghorbani, N.,\r\nTroje, N.F., Pons-Moll, G.,\r\nBlack, M.J., 2019.\r\n\r\n\r\nAmass: Archive of motion capture as surface shapes,\r\nin: The IEEE International Conference on Computer Vision\r\n(ICCV).\r\n\r\n\r\nURL: https://amass.is.tue.mpg.de.",
            "Ghorbani et al. (2020) Ghorbani et al. (2020)\r\n\r\nGhorbani, S., Mahdaviani, K.,\r\nThaler, A., Kording, K.,\r\nCook, D.J., Blohm, G.,\r\nTroje, N.F., 2020.\r\n\r\n\r\nMoVi: A Large Multipurpose Motion and\r\nVideo Dataset.\r\n\r\n\r\narXiv:2003.01888 [cs, eess] URL: http://arxiv.org/abs/2003.01888. arXiv: 2003.01888."
        ],
        "references": [
            "The complexity of this task explains why it has taken time for the scientific community to create large benchmarks: today many variations exist between monocular versus multi-view, laboratory controlled versus in-the-wild environments (see Table 1) etc. With new commercial solutions (ie: Theia, The Captury) starting to produce results similar to traditional motion capture Kanko et al. (2020), some benchmarks are also starting to use markerless labeled ground truths. They as the advantage of easily providing in-the-wild images. However, using this kind of data as ground truth can be questioned as it is itself obtained using methods that are not always available and transparent. Despite this diversity, there are still only a few openly accessible academic benchmarks containing more than millions of images.",
            "For this reason, our review describes each criterion separately and explains in which use case it performs the best. Tables 6, 7 and 10 classify these methods with accuracy reported in MPJPE. The level of robustness corresponds to the number of assumptions or constraints necessary for correct detection. Lastly, to express the speed, we report whether the model can run in real-time. Each of these tables allow to cross-compare the different methods best suited to the most needed specifications.",
            "Most of the reviewed methods can be trained to adapt to new challenging contexts or refined on new data. It is also important to have an idea of the training time when an application might consider online training. The number of parameters is a good indication of the depth of the architecture (see Table 11), which can also be calculated using backbone 2D detection networks in many cases.",
            "In the speed part of table 10, we report all methods that can run in real time. The inference speed is in frames per second and the GPU used is also specified. Robustness is variable in this collection of methods, and the accuracy seems a bit below average for the fastest methods. The most accurate is Huang et al. (2019), which achieves 37.5 MPJPE on Human3.6M without using its IMU component (it also performs well on TotalCapture with the addition of IMU data)."
        ]
    },
    "id_table_2": {
        "caption": "Table 2: The taxonomy of reviewed methods. In case of multiple stages we indicate intermediate representations. For learning methods, loss functions and backbone architecture are indicated when they are present (for many two-stage methods these backbones concern only the first stage of 2D detection). Backbones are referred to as SHNet: Stacked Hourglass (Newell et al. (2016)), CPN: Cascaded Pyramid (Chen et al. (2018)), HRNet: High Resolution Network (Sun et al. (2019)) and SimpleNet: Simple Baselines (Xiao et al. (2018)).",
        "table": [
            "<table id=\"S3.T2.29.29.29\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S3.T2.29.29.29.30.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.30.1.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\" colspan=\"3\"/>&#13;\n<td id=\"S3.T2.29.29.29.30.1.2\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_t\" colspan=\"3\">Human Body Models</td>&#13;\n<td id=\"S3.T2.29.29.29.30.1.3\" class=\"ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t\" colspan=\"6\">Neural Networks</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.31.2\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.31.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Method</th>&#13;\n<td id=\"S3.T2.29.29.29.31.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Proxy Representation</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Losses</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Kinematic</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Skeleton</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Mesh</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Backbone</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GAN</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RNN</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.10\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">TCN</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.11\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Attention</td>&#13;\n<td id=\"S3.T2.29.29.29.31.2.12\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">GCNN</td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.32.3\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.32.3.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.32.3.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.32.3.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.32.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Chains</td>&#13;\n<td id=\"S3.T2.29.29.29.32.3.5\" class=\"ltx_td ltx_align_center ltx_border_r\">(e.g. PSM)</td>&#13;\n<td id=\"S3.T2.29.29.29.32.3.6\" class=\"ltx_td ltx_align_center ltx_border_r\">(e.g. SMPL)</td>&#13;\n<td id=\"S3.T2.29.29.29.32.3.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.32.3.8\" class=\"ltx_td ltx_align_center ltx_border_r\">Adv.lea.</td>&#13;\n<td id=\"S3.T2.29.29.29.32.3.9\" class=\"ltx_td ltx_align_center ltx_border_r\">LSTM</td>&#13;\n<td id=\"S3.T2.29.29.29.32.3.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.32.3.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.32.3.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.33.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.33.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavlakos et&#160;al.</span> (<a href=\"#bib.bib57\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.33.4.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D Heatmaps</td>&#13;\n<td id=\"S3.T2.29.29.29.33.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.29.29.29.33.4.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet</td>&#13;\n<td id=\"S3.T2.29.29.29.33.4.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.33.4.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.1.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.1.1.1.1.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib50\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.1.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D heatmaps,</td>&#13;\n<td id=\"S3.T2.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.1.1.1.1.1.m1.1a\"><mo id=\"S3.T2.1.1.1.1.1.m1.1.1\" xref=\"S3.T2.1.1.1.1.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.1.1.1.1.1.m1.1b\"><ci id=\"S3.T2.1.1.1.1.1.m1.1.1.cmml\" xref=\"S3.T2.1.1.1.1.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.1.1.1.1.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.1.1.1.1.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.1.1.1.1.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.1.1.1.1.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Resnet50</td>&#13;\n<td id=\"S3.T2.1.1.1.1.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.1.1.1.1.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.1.1.1.1.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.1.1.1.1.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.1.1.1.1.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.34.5\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.34.5.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#8221;Location maps&#8221;</td>&#13;\n<td id=\"S3.T2.29.29.29.34.5.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.34.5.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.35.6\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.35.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Zhou et&#160;al.</span> (<a href=\"#bib.bib81\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.35.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D heatmaps</td>&#13;\n<td id=\"S3.T2.29.29.29.35.6.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2,</td>&#13;\n<td id=\"S3.T2.29.29.29.35.6.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet</td>&#13;\n<td id=\"S3.T2.29.29.29.35.6.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.35.6.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.36.7\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.36.7.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">&#8221;geometric loss&#8221;</td>&#13;\n<td id=\"S3.T2.29.29.29.36.7.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.36.7.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.37.8\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.37.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Martinez et&#160;al.</span> (<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.37.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose</td>&#13;\n<td id=\"S3.T2.29.29.29.37.8.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.29.29.29.37.8.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet (2D)</td>&#13;\n<td id=\"S3.T2.29.29.29.37.8.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.37.8.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.38.9\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.38.9.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.7\" class=\"ltx_td ltx_align_center ltx_border_r\">+ MLP</td>&#13;\n<td id=\"S3.T2.29.29.29.38.9.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.38.9.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.39.10\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.39.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Sun et&#160;al.</span> (<a href=\"#bib.bib67\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.39.10.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D/3D heatmaps</td>&#13;\n<td id=\"S3.T2.29.29.29.39.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">any heatmap losses</td>&#13;\n<td id=\"S3.T2.29.29.29.39.10.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Resnet models</td>&#13;\n<td id=\"S3.T2.29.29.29.39.10.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.39.10.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.40.11\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.40.11.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.7\" class=\"ltx_td ltx_align_center ltx_border_r\">and SHNet tested</td>&#13;\n<td id=\"S3.T2.29.29.29.40.11.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.40.11.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.2.2.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.2.2.2.2.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Omran et&#160;al.</span> (<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.2.2.2.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">part segmentation map</td>&#13;\n<td id=\"S3.T2.2.2.2.2.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">3D and 2D joint loss (L2)</td>&#13;\n<td id=\"S3.T2.2.2.2.2.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.2.2.2.2.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.2.2.2.2.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.2.2.2.2.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.2.2.2.2.1.m1.1a\"><mo id=\"S3.T2.2.2.2.2.1.m1.1.1\" xref=\"S3.T2.2.2.2.2.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.2.2.2.2.1.m1.1b\"><ci id=\"S3.T2.2.2.2.2.1.m1.1.1.cmml\" xref=\"S3.T2.2.2.2.2.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.2.2.2.2.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.2.2.2.2.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">RefineNet <cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Lin et&#160;al.</span> (<a href=\"#bib.bib35\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2016</span></a>)</cite>&#13;\n</td>&#13;\n<td id=\"S3.T2.2.2.2.2.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.2.2.2.2.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.2.2.2.2.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.2.2.2.2.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.2.2.2.2.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.41.12\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.41.12.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">3D latent parameter loss (L1)</td>&#13;\n<td id=\"S3.T2.29.29.29.41.12.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.7\" class=\"ltx_td ltx_align_center ltx_border_r\">+ Resnet50</td>&#13;\n<td id=\"S3.T2.29.29.29.41.12.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.41.12.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.3.3.3.3\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.3.3.3.3.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib49\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.3.3.3.3.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;Occlusion Robust Pose Maps&#8221;</td>&#13;\n<td id=\"S3.T2.3.3.3.3.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.3.3.3.3.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.3.3.3.3.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.3.3.3.3.1.m1.1a\"><mo id=\"S3.T2.3.3.3.3.1.m1.1.1\" xref=\"S3.T2.3.3.3.3.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.3.3.3.3.1.m1.1b\"><ci id=\"S3.T2.3.3.3.3.1.m1.1.1.cmml\" xref=\"S3.T2.3.3.3.3.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.3.3.3.3.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.3.3.3.3.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.3.3.3.3.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.3.3.3.3.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ResNet50</td>&#13;\n<td id=\"S3.T2.3.3.3.3.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.3.3.3.3.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.3.3.3.3.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.3.3.3.3.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.3.3.3.3.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.42.13\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.42.13.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Part affinity fields</td>&#13;\n<td id=\"S3.T2.29.29.29.42.13.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.42.13.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.4.4.4.4\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.4.4.4.4.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Kolotouros et&#160;al.</span> (<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.4.4.4.4.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.4.4.4.4.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.4.4.4.4.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.4.4.4.4.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.4.4.4.4.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.4.4.4.4.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.4.4.4.4.1.m1.1a\"><mo id=\"S3.T2.4.4.4.4.1.m1.1.1\" xref=\"S3.T2.4.4.4.4.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.4.4.4.4.1.m1.1b\"><ci id=\"S3.T2.4.4.4.4.1.m1.1.1.cmml\" xref=\"S3.T2.4.4.4.4.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.4.4.4.4.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.4.4.4.4.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">ResNet50</td>&#13;\n<td id=\"S3.T2.4.4.4.4.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.4.4.4.4.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.4.4.4.4.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.4.4.4.4.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.4.4.4.4.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.6.6.6.6\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.6.6.6.6.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wandt and Rosenhahn</span> (<a href=\"#bib.bib73\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.6.6.6.6.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.6.6.6.6.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;Reprojection loss&#8221;</td>&#13;\n<td id=\"S3.T2.5.5.5.5.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.5.5.5.5.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.5.5.5.5.1.m1.1a\"><mo id=\"S3.T2.5.5.5.5.1.m1.1.1\" xref=\"S3.T2.5.5.5.5.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.5.5.5.5.1.m1.1b\"><ci id=\"S3.T2.5.5.5.5.1.m1.1.1.cmml\" xref=\"S3.T2.5.5.5.5.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.5.5.5.5.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.6.6.6.6.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.6.6.6.6.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.6.6.6.6.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet (2D)</td>&#13;\n<td id=\"S3.T2.6.6.6.6.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.6.6.6.6.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.6.6.6.6.2.m1.1a\"><mo id=\"S3.T2.6.6.6.6.2.m1.1.1\" xref=\"S3.T2.6.6.6.6.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.6.6.6.6.2.m1.1b\"><ci id=\"S3.T2.6.6.6.6.2.m1.1.1.cmml\" xref=\"S3.T2.6.6.6.6.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.6.6.6.6.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.6.6.6.6.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.6.6.6.6.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.6.6.6.6.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.6.6.6.6.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.43.14\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.43.14.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.3\" class=\"ltx_td ltx_align_center ltx_border_r\">Wasserstein loss, Camera loss</td>&#13;\n<td id=\"S3.T2.29.29.29.43.14.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.43.14.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.8.8.8.8\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.8.8.8.8.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Xu et&#160;al.</span> (<a href=\"#bib.bib76\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.8.8.8.8.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">pixel-to-surface maps</td>&#13;\n<td id=\"S3.T2.8.8.8.8.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;render-and-compare loss&#8221;</td>&#13;\n<td id=\"S3.T2.8.8.8.8.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.8.8.8.8.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.7.7.7.7.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.7.7.7.7.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.7.7.7.7.1.m1.1a\"><mo id=\"S3.T2.7.7.7.7.1.m1.1.1\" xref=\"S3.T2.7.7.7.7.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.7.7.7.7.1.m1.1b\"><ci id=\"S3.T2.7.7.7.7.1.m1.1.1.cmml\" xref=\"S3.T2.7.7.7.7.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.7.7.7.7.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.8.8.8.8.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Resnet50</td>&#13;\n<td id=\"S3.T2.8.8.8.8.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.8.8.8.8.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.8.8.8.8.2.m1.1a\"><mo id=\"S3.T2.8.8.8.8.2.m1.1.1\" xref=\"S3.T2.8.8.8.8.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.8.8.8.8.2.m1.1b\"><ci id=\"S3.T2.8.8.8.8.2.m1.1.1.cmml\" xref=\"S3.T2.8.8.8.8.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.8.8.8.8.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.8.8.8.8.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.8.8.8.8.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.8.8.8.8.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.8.8.8.8.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.44.15\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.44.15.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.3\" class=\"ltx_td ltx_align_center ltx_border_r\">reconstruction loss (L2), parameter loss (L2)</td>&#13;\n<td id=\"S3.T2.29.29.29.44.15.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.44.15.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.45.16\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.45.16.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Kocabas et&#160;al.</span> (<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019b</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.45.16.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose</td>&#13;\n<td id=\"S3.T2.29.29.29.45.16.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">smooth L1</td>&#13;\n<td id=\"S3.T2.29.29.29.45.16.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Resnet50</td>&#13;\n<td id=\"S3.T2.29.29.29.45.16.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.45.16.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.46.17\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.46.17.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mathis et&#160;al.</span> (<a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.46.17.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.29.29.29.46.17.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.29.29.29.46.17.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Resnet50</td>&#13;\n<td id=\"S3.T2.29.29.29.46.17.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.46.17.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.47.18\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.47.18.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.7\" class=\"ltx_td ltx_align_center ltx_border_r\">Resnet101 tested</td>&#13;\n<td id=\"S3.T2.29.29.29.47.18.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.47.18.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.9.9.9.9\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.9.9.9.9.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib48\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.9.9.9.9.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;3D pose encoding&#8221;</td>&#13;\n<td id=\"S3.T2.9.9.9.9.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">smooth L1</td>&#13;\n<td id=\"S3.T2.9.9.9.9.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.9.9.9.9.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.9.9.9.9.1.m1.1a\"><mo id=\"S3.T2.9.9.9.9.1.m1.1.1\" xref=\"S3.T2.9.9.9.9.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.9.9.9.9.1.m1.1b\"><ci id=\"S3.T2.9.9.9.9.1.m1.1.1.cmml\" xref=\"S3.T2.9.9.9.9.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.9.9.9.9.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.9.9.9.9.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.9.9.9.9.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.9.9.9.9.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;SelecSLS Net&#8221;</td>&#13;\n<td id=\"S3.T2.9.9.9.9.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.9.9.9.9.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.9.9.9.9.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.9.9.9.9.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.9.9.9.9.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.48.19\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.48.19.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Part affinity fields</td>&#13;\n<td id=\"S3.T2.29.29.29.48.19.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.7\" class=\"ltx_td ltx_align_center ltx_border_r\">Fully connected</td>&#13;\n<td id=\"S3.T2.29.29.29.48.19.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.48.19.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.10.10.10.10\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.10.10.10.10.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Hossain and Little</span> (<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.10.10.10.10.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose sequence</td>&#13;\n<td id=\"S3.T2.10.10.10.10.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.10.10.10.10.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.10.10.10.10.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.10.10.10.10.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.10.10.10.10.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet (2D)</td>&#13;\n<td id=\"S3.T2.10.10.10.10.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.10.10.10.10.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.10.10.10.10.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.10.10.10.10.1.m1.1a\"><mo id=\"S3.T2.10.10.10.10.1.m1.1.1\" xref=\"S3.T2.10.10.10.10.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.10.10.10.10.1.m1.1b\"><ci id=\"S3.T2.10.10.10.10.1.m1.1.1.cmml\" xref=\"S3.T2.10.10.10.10.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.10.10.10.10.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.10.10.10.10.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.10.10.10.10.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.10.10.10.10.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.49.20\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.49.20.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.3\" class=\"ltx_td ltx_align_center ltx_border_r\">derivative loss on joint sets</td>&#13;\n<td id=\"S3.T2.29.29.29.49.20.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.49.20.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.11.11.11.11\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.11.11.11.11.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cai et&#160;al. (<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></th>&#13;\n<td id=\"S3.T2.11.11.11.11.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose, ST-graph</td>&#13;\n<td id=\"S3.T2.11.11.11.11.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2, &#8221;symmetry loss&#8221;</td>&#13;\n<td id=\"S3.T2.11.11.11.11.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPN</td>&#13;\n<td id=\"S3.T2.11.11.11.11.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.11.11.11.11.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.11.11.11.11.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.11.11.11.11.1.m1.1a\"><mo id=\"S3.T2.11.11.11.11.1.m1.1.1\" xref=\"S3.T2.11.11.11.11.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.11.11.11.11.1.m1.1b\"><ci id=\"S3.T2.11.11.11.11.1.m1.1.1.cmml\" xref=\"S3.T2.11.11.11.11.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.11.11.11.11.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.50.21\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.50.21.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.3\" class=\"ltx_td ltx_align_center ltx_border_r\">derivative loss on joint sets</td>&#13;\n<td id=\"S3.T2.29.29.29.50.21.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.50.21.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.12.12.12.12\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.12.12.12.12.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavllo et&#160;al.</span> (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.12.12.12.12.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose</td>&#13;\n<td id=\"S3.T2.12.12.12.12.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">trajectory and pose loss</td>&#13;\n<td id=\"S3.T2.12.12.12.12.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.12.12.12.12.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.12.12.12.12.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.12.12.12.12.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet, CPN</td>&#13;\n<td id=\"S3.T2.12.12.12.12.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.12.12.12.12.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.12.12.12.12.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.12.12.12.12.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.12.12.12.12.1.m1.1a\"><mo id=\"S3.T2.12.12.12.12.1.m1.1.1\" xref=\"S3.T2.12.12.12.12.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.12.12.12.12.1.m1.1b\"><ci id=\"S3.T2.12.12.12.12.1.m1.1.1.cmml\" xref=\"S3.T2.12.12.12.12.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.12.12.12.12.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.12.12.12.12.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.12.12.12.12.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.51.22\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.51.22.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.3\" class=\"ltx_td ltx_align_center ltx_border_r\">bone length L2 loss, 2D projection loss</td>&#13;\n<td id=\"S3.T2.29.29.29.51.22.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.7\" class=\"ltx_td ltx_align_center ltx_border_r\">and Mask-RCNN tested (2D)</td>&#13;\n<td id=\"S3.T2.29.29.29.51.22.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.51.22.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.15.15.15.15\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.15.15.15.15.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Cheng et&#160;al.</span> (<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.15.15.15.15.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose</td>&#13;\n<td id=\"S3.T2.15.15.15.15.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2, 2D projection loss</td>&#13;\n<td id=\"S3.T2.15.15.15.15.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.13.13.13.13.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.13.13.13.13.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.13.13.13.13.1.m1.1a\"><mo id=\"S3.T2.13.13.13.13.1.m1.1.1\" xref=\"S3.T2.13.13.13.13.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.13.13.13.13.1.m1.1b\"><ci id=\"S3.T2.13.13.13.13.1.m1.1.1.cmml\" xref=\"S3.T2.13.13.13.13.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.13.13.13.13.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.15.15.15.15.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.15.15.15.15.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet (2D)</td>&#13;\n<td id=\"S3.T2.14.14.14.14.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.14.14.14.14.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.14.14.14.14.2.m1.1a\"><mo id=\"S3.T2.14.14.14.14.2.m1.1.1\" xref=\"S3.T2.14.14.14.14.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.14.14.14.14.2.m1.1b\"><ci id=\"S3.T2.14.14.14.14.2.m1.1.1.cmml\" xref=\"S3.T2.14.14.14.14.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.14.14.14.14.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.15.15.15.15.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.15.15.15.15.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.15.15.15.15.3.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.15.15.15.15.3.m1.1a\"><mo id=\"S3.T2.15.15.15.15.3.m1.1.1\" xref=\"S3.T2.15.15.15.15.3.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.15.15.15.15.3.m1.1b\"><ci id=\"S3.T2.15.15.15.15.3.m1.1.1.cmml\" xref=\"S3.T2.15.15.15.15.3.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.15.15.15.15.3.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.15.15.15.15.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.15.15.15.15.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.18.18.18.18\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.18.18.18.18.4\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></th>&#13;\n<td id=\"S3.T2.18.18.18.18.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D heatmaps</td>&#13;\n<td id=\"S3.T2.18.18.18.18.6\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2, &#8221;multi-view loss&#8221;</td>&#13;\n<td id=\"S3.T2.16.16.16.16.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.16.16.16.16.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.16.16.16.16.1.m1.1a\"><mo id=\"S3.T2.16.16.16.16.1.m1.1.1\" xref=\"S3.T2.16.16.16.16.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.16.16.16.16.1.m1.1b\"><ci id=\"S3.T2.16.16.16.16.1.m1.1.1.cmml\" xref=\"S3.T2.16.16.16.16.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.16.16.16.16.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.18.18.18.18.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.18.18.18.18.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.18.18.18.18.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">HRNet (2D)</td>&#13;\n<td id=\"S3.T2.17.17.17.17.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.17.17.17.17.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.17.17.17.17.2.m1.1a\"><mo id=\"S3.T2.17.17.17.17.2.m1.1.1\" xref=\"S3.T2.17.17.17.17.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.17.17.17.17.2.m1.1b\"><ci id=\"S3.T2.17.17.17.17.2.m1.1.1.cmml\" xref=\"S3.T2.17.17.17.17.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.17.17.17.17.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.18.18.18.18.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.18.18.18.18.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.18.18.18.18.3.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.18.18.18.18.3.m1.1a\"><mo id=\"S3.T2.18.18.18.18.3.m1.1.1\" xref=\"S3.T2.18.18.18.18.3.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.18.18.18.18.3.m1.1b\"><ci id=\"S3.T2.18.18.18.18.3.m1.1.1.cmml\" xref=\"S3.T2.18.18.18.18.3.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.18.18.18.18.3.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.18.18.18.18.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.18.18.18.18.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.52.23\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.52.23.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.3\" class=\"ltx_td ltx_align_center ltx_border_r\">2D projection loss</td>&#13;\n<td id=\"S3.T2.29.29.29.52.23.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.52.23.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.20.20.20.20\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.20.20.20.20.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Liu et&#160;al.</span> (<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.20.20.20.20.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.20.20.20.20.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.20.20.20.20.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.20.20.20.20.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.20.20.20.20.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.20.20.20.20.9\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet and CPN</td>&#13;\n<td id=\"S3.T2.20.20.20.20.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.20.20.20.20.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.19.19.19.19.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.19.19.19.19.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.19.19.19.19.1.m1.1a\"><mo id=\"S3.T2.19.19.19.19.1.m1.1.1\" xref=\"S3.T2.19.19.19.19.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.19.19.19.19.1.m1.1b\"><ci id=\"S3.T2.19.19.19.19.1.m1.1.1.cmml\" xref=\"S3.T2.19.19.19.19.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.19.19.19.19.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.20.20.20.20.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.20.20.20.20.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.20.20.20.20.2.m1.1a\"><mo id=\"S3.T2.20.20.20.20.2.m1.1.1\" xref=\"S3.T2.20.20.20.20.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.20.20.20.20.2.m1.1b\"><ci id=\"S3.T2.20.20.20.20.2.m1.1.1.cmml\" xref=\"S3.T2.20.20.20.20.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.20.20.20.20.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.20.20.20.20.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.53.24\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.53.24.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.7\" class=\"ltx_td ltx_align_center ltx_border_r\">tested (2D)</td>&#13;\n<td id=\"S3.T2.29.29.29.53.24.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.53.24.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.21.21.21.21\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.21.21.21.21.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wang et&#160;al.</span> (<a href=\"#bib.bib74\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.21.21.21.21.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose, ST-graph</td>&#13;\n<td id=\"S3.T2.21.21.21.21.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2, &#8221;motion loss&#8221;</td>&#13;\n<td id=\"S3.T2.21.21.21.21.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">CPN and HRNet</td>&#13;\n<td id=\"S3.T2.21.21.21.21.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.21.21.21.21.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.21.21.21.21.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.21.21.21.21.1.m1.1a\"><mo id=\"S3.T2.21.21.21.21.1.m1.1.1\" xref=\"S3.T2.21.21.21.21.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.21.21.21.21.1.m1.1b\"><ci id=\"S3.T2.21.21.21.21.1.m1.1.1.cmml\" xref=\"S3.T2.21.21.21.21.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.21.21.21.21.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.54.25\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.54.25.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.7\" class=\"ltx_td ltx_align_center ltx_border_r\">tested (2D)</td>&#13;\n<td id=\"S3.T2.29.29.29.54.25.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.54.25.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.22.22.22.22\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.22.22.22.22.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Qiu et&#160;al.</span> (<a href=\"#bib.bib59\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.22.22.22.22.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D heatmaps</td>&#13;\n<td id=\"S3.T2.22.22.22.22.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.22.22.22.22.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.22.22.22.22.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.22.22.22.22.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.22.22.22.22.1.m1.1a\"><mo id=\"S3.T2.22.22.22.22.1.m1.1.1\" xref=\"S3.T2.22.22.22.22.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.22.22.22.22.1.m1.1b\"><ci id=\"S3.T2.22.22.22.22.1.m1.1.1.cmml\" xref=\"S3.T2.22.22.22.22.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.22.22.22.22.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.22.22.22.22.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.22.22.22.22.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SimpleNet</td>&#13;\n<td id=\"S3.T2.22.22.22.22.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.22.22.22.22.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.22.22.22.22.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.22.22.22.22.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.22.22.22.22.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.55.26\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.55.26.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.55.26.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D heatmaps</td>&#13;\n<td id=\"S3.T2.29.29.29.55.26.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">soft L2, L1 regularized</td>&#13;\n<td id=\"S3.T2.29.29.29.55.26.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SimpleNet</td>&#13;\n<td id=\"S3.T2.29.29.29.55.26.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.55.26.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.23.23.23.23\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.23.23.23.23.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">He et&#160;al.</span> (<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.23.23.23.23.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose</td>&#13;\n<td id=\"S3.T2.23.23.23.23.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.23.23.23.23.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.23.23.23.23.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.23.23.23.23.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.23.23.23.23.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SimpleNet</td>&#13;\n<td id=\"S3.T2.23.23.23.23.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.23.23.23.23.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.23.23.23.23.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.23.23.23.23.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.23.23.23.23.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.23.23.23.23.1.m1.1a\"><mo id=\"S3.T2.23.23.23.23.1.m1.1.1\" xref=\"S3.T2.23.23.23.23.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.23.23.23.23.1.m1.1b\"><ci id=\"S3.T2.23.23.23.23.1.m1.1.1.cmml\" xref=\"S3.T2.23.23.23.23.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.23.23.23.23.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.23.23.23.23.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.25.25.25.25\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.25.25.25.25.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib41\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2016</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.25.25.25.25.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">multi-view silhouettes</td>&#13;\n<td id=\"S3.T2.25.25.25.25.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.24.24.24.24.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.24.24.24.24.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.24.24.24.24.1.m1.1a\"><mo id=\"S3.T2.24.24.24.24.1.m1.1.1\" xref=\"S3.T2.24.24.24.24.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.24.24.24.24.1.m1.1b\"><ci id=\"S3.T2.24.24.24.24.1.m1.1.1.cmml\" xref=\"S3.T2.24.24.24.24.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.24.24.24.24.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.25.25.25.25.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.25.25.25.25.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.25.25.25.25.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.25.25.25.25.2.m1.1a\"><mo id=\"S3.T2.25.25.25.25.2.m1.1.1\" xref=\"S3.T2.25.25.25.25.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.25.25.25.25.2.m1.1b\"><ci id=\"S3.T2.25.25.25.25.2.m1.1.1.cmml\" xref=\"S3.T2.25.25.25.25.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.25.25.25.25.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.25.25.25.25.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.25.25.25.25.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.25.25.25.25.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.25.25.25.25.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.25.25.25.25.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.25.25.25.25.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.56.27\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.56.27.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.2\" class=\"ltx_td ltx_align_center ltx_border_r\">IMU orientations</td>&#13;\n<td id=\"S3.T2.29.29.29.56.27.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.7\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.56.27.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.26.26.26.26\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.26.26.26.26.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Trumble et&#160;al.</span> (<a href=\"#bib.bib71\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.26.26.26.26.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">PVH, IMU orientations</td>&#13;\n<td id=\"S3.T2.26.26.26.26.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.26.26.26.26.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.26.26.26.26.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.26.26.26.26.7\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.26.26.26.26.8\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Classical</td>&#13;\n<td id=\"S3.T2.26.26.26.26.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.26.26.26.26.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.26.26.26.26.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.26.26.26.26.1.m1.1a\"><mo id=\"S3.T2.26.26.26.26.1.m1.1.1\" xref=\"S3.T2.26.26.26.26.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.26.26.26.26.1.m1.1b\"><ci id=\"S3.T2.26.26.26.26.1.m1.1.1.cmml\" xref=\"S3.T2.26.26.26.26.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.26.26.26.26.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.26.26.26.26.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.26.26.26.26.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.26.26.26.26.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.57.28\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.57.28.1\" class=\"ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.2\" class=\"ltx_td ltx_align_center ltx_border_r\">then 2D coordinates</td>&#13;\n<td id=\"S3.T2.29.29.29.57.28.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.4\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.5\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.6\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.7\" class=\"ltx_td ltx_align_center ltx_border_r\">3D CNN</td>&#13;\n<td id=\"S3.T2.29.29.29.57.28.8\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.9\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.10\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.11\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S3.T2.29.29.29.57.28.12\" class=\"ltx_td ltx_border_r\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.28.28.28.28\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.28.28.28.28.3\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.28.28.28.28.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">2D pose, IMU orientations</td>&#13;\n<td id=\"S3.T2.28.28.28.28.5\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.27.27.27.27.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.27.27.27.27.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.27.27.27.27.1.m1.1a\"><mo id=\"S3.T2.27.27.27.27.1.m1.1.1\" xref=\"S3.T2.27.27.27.27.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.27.27.27.27.1.m1.1b\"><ci id=\"S3.T2.27.27.27.27.1.m1.1.1.cmml\" xref=\"S3.T2.27.27.27.27.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.27.27.27.27.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.28.28.28.28.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.28.28.28.28.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><math id=\"S3.T2.28.28.28.28.2.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.28.28.28.28.2.m1.1a\"><mo id=\"S3.T2.28.28.28.28.2.m1.1.1\" xref=\"S3.T2.28.28.28.28.2.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.28.28.28.28.2.m1.1b\"><ci id=\"S3.T2.28.28.28.28.2.m1.1.1.cmml\" xref=\"S3.T2.28.28.28.28.2.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.28.28.28.28.2.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.28.28.28.28.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#13;\n<cite class=\"ltx_cite ltx_citemacro_cite\">Cao et&#160;al. (<a href=\"#bib.bib7\" title=\"\" class=\"ltx_ref\">2017</a>)</cite> (multi-person)</td>&#13;\n<td id=\"S3.T2.28.28.28.28.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.28.28.28.28.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.28.28.28.28.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.28.28.28.28.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.28.28.28.28.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.58.29\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.58.29.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Huang et&#160;al.</span> (<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.58.29.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#8221;multi-channel volume&#8221;</td>&#13;\n<td id=\"S3.T2.29.29.29.58.29.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">L2</td>&#13;\n<td id=\"S3.T2.29.29.29.58.29.4\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.5\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.6\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.7\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">SHNet (3D Conv)</td>&#13;\n<td id=\"S3.T2.29.29.29.58.29.8\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.9\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.10\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.11\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.58.29.12\" class=\"ltx_td ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n<tr id=\"S3.T2.29.29.29.29\" class=\"ltx_tr\">&#13;\n<th id=\"S3.T2.29.29.29.29.2\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Zhang et&#160;al.</span> (<a href=\"#bib.bib80\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S3.T2.29.29.29.29.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">2D heatmaps</td>&#13;\n<td id=\"S3.T2.29.29.29.29.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">N/A</td>&#13;\n<td id=\"S3.T2.29.29.29.29.5\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.29.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\"><math id=\"S3.T2.29.29.29.29.1.m1.1\" class=\"ltx_Math\" alttext=\"\\bullet\" display=\"inline\"><semantics id=\"S3.T2.29.29.29.29.1.m1.1a\"><mo id=\"S3.T2.29.29.29.29.1.m1.1.1\" xref=\"S3.T2.29.29.29.29.1.m1.1.1.cmml\">&#8729;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S3.T2.29.29.29.29.1.m1.1b\"><ci id=\"S3.T2.29.29.29.29.1.m1.1.1.cmml\" xref=\"S3.T2.29.29.29.29.1.m1.1.1\">&#8729;</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T2.29.29.29.29.1.m1.1c\">\\bullet</annotation></semantics></math></td>&#13;\n<td id=\"S3.T2.29.29.29.29.6\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.29.7\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\">SimpleNet</td>&#13;\n<td id=\"S3.T2.29.29.29.29.8\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.29.9\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.29.10\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.29.11\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n<td id=\"S3.T2.29.29.29.29.12\" class=\"ltx_td ltx_border_b ltx_border_r ltx_border_t\"/>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Pavlakos et al. (2017) Pavlakos et al. (2017)\r\n\r\nPavlakos, G., Zhou, X.,\r\nDerpanis, K.G., Daniilidis, K.,\r\n2017.\r\n\r\n\r\nCoarse-to-Fine Volumetric Prediction for\r\nSingle-Image 3D Human Pose.\r\n\r\n\r\narXiv:1611.07828 [cs] URL: http://arxiv.org/abs/1611.07828. arXiv: 1611.07828.",
            "Mehta et al. (2017) Mehta et al. (2017)\r\n\r\nMehta, D., Sridhar, S.,\r\nSotnychenko, O., Rhodin, H.,\r\nShafiei, M., Seidel, H.P.,\r\nXu, W., Casas, D.,\r\nTheobalt, C., 2017.\r\n\r\n\r\nVNect: real-time 3D human pose estimation with a\r\nsingle RGB camera.\r\n\r\n\r\nACM Transactions on Graphics 36,\r\n1--14.\r\n\r\n\r\nURL: http://dl.acm.org/citation.cfm?doid=3072959.3073596,\r\ndoi:10.1145/3072959.3073596.",
            "Zhou et al. (2017) Zhou et al. (2017)\r\n\r\nZhou, X., Huang, Q., Sun,\r\nX., Xue, X., Wei, Y.,\r\n2017.\r\n\r\n\r\nTowards 3D Human Pose Estimation in the\r\nWild: a Weakly-supervised Approach.\r\n\r\n\r\narXiv:1704.02447 [cs] URL: http://arxiv.org/abs/1704.02447. arXiv: 1704.02447.",
            "Martinez et al. (2017) Martinez et al. (2017)\r\n\r\nMartinez, J., Hossain, R.,\r\nRomero, J., Little, J.J.,\r\n2017.\r\n\r\n\r\nA simple yet effective baseline for 3d human pose\r\nestimation.\r\n\r\n\r\narXiv:1705.03098 [cs] URL: http://arxiv.org/abs/1705.03098. arXiv: 1705.03098.",
            "Sun et al. (2018) Sun et al. (2018)\r\n\r\nSun, X., Xiao, B., Wei,\r\nF., Liang, S., Wei, Y.,\r\n2018.\r\n\r\n\r\nIntegral Human Pose Regression.\r\n\r\n\r\narXiv:1711.08229 [cs] URL: http://arxiv.org/abs/1711.08229. arXiv: 1711.08229.",
            "Omran et al. (2018) Omran et al. (2018)\r\n\r\nOmran, M., Lassner, C.,\r\nPons-Moll, G., Gehler, P.V.,\r\nSchiele, B., 2018.\r\n\r\n\r\nNeural Body Fitting: Unifying Deep Learning\r\nand Model-Based Human Pose and Shape Estimation.\r\n\r\n\r\narXiv:1808.05942 [cs] URL: http://arxiv.org/abs/1808.05942. arXiv: 1808.05942.",
            "Lin et al. (2016) Lin et al. (2016)\r\n\r\nLin, G., Milan, A., Shen,\r\nC., Reid, I., 2016.\r\n\r\n\r\nRefineNet: Multi-Path Refinement Networks\r\nfor High-Resolution Semantic Segmentation.\r\n\r\n\r\narXiv:1611.06612 [cs] URL: http://arxiv.org/abs/1611.06612. arXiv: 1611.06612.",
            "Mehta et al. (2018) Mehta et al. (2018)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nSridhar, S., Pons-Moll, G.,\r\nTheobalt, C., 2018.\r\n\r\n\r\nSingle-Shot Multi-Person 3D Pose\r\nEstimation From Monocular RGB.\r\n\r\n\r\narXiv:1712.03453 [cs] URL: http://arxiv.org/abs/1712.03453. arXiv: 1712.03453.",
            "Kolotouros et al. (2019) Kolotouros et al. (2019)\r\n\r\nKolotouros, N., Pavlakos, G.,\r\nBlack, M.J., Daniilidis, K.,\r\n2019.\r\n\r\n\r\nLearning to Reconstruct 3D Human Pose and\r\nShape via Model-fitting in the Loop.\r\n\r\n\r\narXiv:1909.12828 [cs] URL: http://arxiv.org/abs/1909.12828. arXiv: 1909.12828.",
            "Wandt and Rosenhahn (2019) Wandt and Rosenhahn (2019)\r\n\r\nWandt, B., Rosenhahn, B.,\r\n2019.\r\n\r\n\r\nRepNet: Weakly Supervised Training of an\r\nAdversarial Reprojection Network for 3D Human Pose Estimation.\r\n\r\n\r\narXiv:1902.09868 [cs] URL: http://arxiv.org/abs/1902.09868. arXiv: 1902.09868.",
            "Xu et al. (2019) Xu et al. (2019)\r\n\r\nXu, Y., Zhu, S.C., Tung,\r\nT., 2019.\r\n\r\n\r\nDenseRaC: Joint 3D Pose and Shape\r\nEstimation by Dense Render-and-Compare.\r\n\r\n\r\narXiv:1910.00116 [cs, eess] URL: http://arxiv.org/abs/1910.00116. arXiv: 1910.00116.",
            "Kocabas et al. (2019b) Kocabas et al. (2019b)\r\n\r\nKocabas, M., Karagoz, S.,\r\nAkbas, E., 2019b.\r\n\r\n\r\nSelf-Supervised Learning of 3D Human Pose\r\nusing Multi-view Geometry.\r\n\r\n\r\narXiv:1903.02330 [cs] URL: http://arxiv.org/abs/1903.02330. arXiv: 1903.02330.",
            "Mathis et al. (2018) Mathis et al. (2018)\r\n\r\nMathis, A., Mamidanna, P.,\r\nCury, K.M., Abe, T.,\r\nMurthy, V.N., Mathis, M.W.,\r\nBethge, M., 2018.\r\n\r\n\r\nDeepLabCut: markerless pose estimation of\r\nuser-defined body parts with deep learning.\r\n\r\n\r\nNature Neuroscience 21,\r\n1281--1289.\r\n\r\n\r\nURL: https://www.nature.com/articles/s41593-018-0209-y,\r\ndoi:10.1038/s41593-018-0209-y. number: 9\r\nPublisher: Nature Publishing Group.",
            "Mehta et al. (2020) Mehta et al. (2020)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nElgharib, M., Fua, P.,\r\nSeidel, H.P., Rhodin, H.,\r\nPons-Moll, G., Theobalt, C.,\r\n2020.\r\n\r\n\r\nXNect: Real-time Multi-Person 3D Motion\r\nCapture with a Single RGB Camera.\r\n\r\n\r\nACM Transactions on Graphics 39.\r\n\r\n\r\nURL: http://arxiv.org/abs/1907.00837,\r\ndoi:10.1145/3386569.3392410. arXiv: 1907.00837.",
            "Hossain and Little (2018) Hossain and Little (2018)\r\n\r\nHossain, M.R.I., Little, J.J.,\r\n2018.\r\n\r\n\r\nExploiting temporal information for 3D pose\r\nestimation.\r\n\r\n\r\narXiv:1711.08585 [cs] 11214,\r\n69--86.\r\n\r\n\r\nURL: http://arxiv.org/abs/1711.08585,\r\ndoi:10.1007/978-3-030-01249-6_5. arXiv:\r\n1711.08585.",
            "Cai et al. (2019) Cai et al. (2019)\r\n\r\nCai, Y., Ge, L., Liu, J.,\r\nCai, J., Cham, T.J.,\r\nYuan, J., Thalmann, N.M.,\r\n2019.\r\n\r\n\r\nExploiting Spatial-Temporal Relationships for\r\n3D Pose Estimation via Graph Convolutional Networks, in:\r\n2019 IEEE/CVF International Conference on\r\nComputer Vision (ICCV), IEEE,\r\nSeoul, Korea (South). pp. 2272–2281.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9009459/,\r\ndoi:10.1109/ICCV.2019.00236.",
            "Pavllo et al. (2019) Pavllo et al. (2019)\r\n\r\nPavllo, D., Feichtenhofer, C.,\r\nGrangier, D., Auli, M.,\r\n2019.\r\n\r\n\r\n3D Human Pose Estimation in Video With\r\nTemporal Convolutions and Semi-Supervised Training, in:\r\n2019 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nLong Beach, CA, USA. pp. 7745--7754.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/8954163/,\r\ndoi:10.1109/CVPR.2019.00794.",
            "Cheng et al. (2019) Cheng et al. (2019)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Yan, W., Tan, R.T.,\r\n2019.\r\n\r\n\r\nOcclusion-Aware Networks for 3D Human Pose\r\nEstimation in Video, pp. 723--732.\r\n\r\n\r\nURL: http://openaccess.thecvf.com/content_ICCV_2019/html/Cheng_Occlusion-Aware_Networks_for_3D_Human_Pose_Estimation_in_Video_ICCV_2019_paper.html.",
            "Cheng et al. (2020) Cheng et al. (2020)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Tan, R.T., 2020.\r\n\r\n\r\n3d human pose estimation using spatio-temporal\r\nnetworks with explicit occlusion training.\r\n\r\n\r\narXiv:2004.11822.",
            "Liu et al. (2020) Liu et al. (2020)\r\n\r\nLiu, R., Shen, J., Wang,\r\nH., Chen, C., Cheung, S.c.,\r\nAsari, V., 2020.\r\n\r\n\r\nAttention Mechanism Exploits Temporal\r\nContexts: Real-Time 3D Human Pose Reconstruction, in:\r\n2020 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nSeattle, WA, USA. pp. 5063--5072.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9156272/,\r\ndoi:10.1109/CVPR42600.2020.00511.",
            "Wang et al. (2020) Wang et al. (2020)\r\n\r\nWang, J., Yan, S., Xiong,\r\nY., Lin, D., 2020.\r\n\r\n\r\nMotion Guided 3D Pose Estimation from\r\nVideos, in: Vedaldi, A., Bischof, H.,\r\nBrox, T., Frahm, J.M. (Eds.),\r\nComputer Vision – ECCV 2020.\r\nSpringer International Publishing,\r\nCham. volume 12358, pp.\r\n764--780.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-58601-0_45,\r\ndoi:10.1007/978-3-030-58601-0_45. series Title:\r\nLecture Notes in Computer Science.",
            "Qiu et al. (2019) Qiu et al. (2019)\r\n\r\nQiu, H., Wang, C., Wang,\r\nJ., Wang, N., Zeng, W.,\r\n2019.\r\n\r\n\r\nCross View Fusion for 3D Human Pose\r\nEstimation.\r\n\r\n\r\narXiv:1909.01203 [cs] URL: http://arxiv.org/abs/1909.01203. arXiv: 1909.01203.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "He et al. (2020) He et al. (2020)\r\n\r\nHe, Y., Yan, R.,\r\nFragkiadaki, K., Yu, S.I.,\r\n2020.\r\n\r\n\r\nEpipolar Transformers.\r\n\r\n\r\narXiv:2005.04551 [cs] URL: http://arxiv.org/abs/2005.04551. arXiv: 2005.04551.",
            "von Marcard et al. (2016) von Marcard et al. (2016)\r\n\r\nvon Marcard, T., Pons-Moll, G.,\r\nRosenhahn, B., 2016.\r\n\r\n\r\nHuman pose estimation from video and imus.\r\n\r\n\r\nTransactions on Pattern Analysis and Machine\r\nIntelligence 38, 1533--1547.\r\n\r\n\r\nURL: http://dx.doi.org/10.1109/TPAMI.2016.2522398,\r\ndoi:10.1109/TPAMI.2016.2522398.",
            "Trumble et al. (2017) Trumble et al. (2017)\r\n\r\nTrumble, M., Gilbert, A.,\r\nMalleson, C., Hilton, A.,\r\nCollomosse, J., 2017.\r\n\r\n\r\nTotal Capture: 3D Human Pose Estimation\r\nFusing Video and Inertial Sensors, in:\r\nProcedings of the British Machine Vision\r\nConference 2017, British Machine Vision Association,\r\nLondon, UK. p. 14.\r\n\r\n\r\nURL: http://www.bmva.org/bmvc/2017/papers/paper014/index.html,\r\ndoi:10.5244/C.31.14.",
            "von Marcard et al. (2018) von Marcard et al. (2018)\r\n\r\nvon Marcard, T., Henschel, R.,\r\nBlack, M.J., Rosenhahn, B.,\r\nPons-Moll, G., 2018.\r\n\r\n\r\nRecovering Accurate 3D Human Pose in the\r\nWild Using IMUs and a Moving Camera, in: Ferrari,\r\nV., Hebert, M., Sminchisescu, C.,\r\nWeiss, Y. (Eds.), Computer Vision –\r\nECCV 2018. Springer International Publishing,\r\nCham. volume 11214, pp.\r\n614--631.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-01249-6_37,\r\ndoi:10.1007/978-3-030-01249-6_37. series Title:\r\nLecture Notes in Computer Science.",
            "Cao et al. (2017) Cao et al. (2017)\r\n\r\nCao, Z., Simon, T., Wei,\r\nS.E., Sheikh, Y., 2017.\r\n\r\n\r\nRealtime Multi-person 2D Pose Estimation\r\nUsing Part Affinity Fields, in: 2017 IEEE\r\nConference on Computer Vision and Pattern Recognition (CVPR),\r\npp. 1302–1310.\r\n\r\n\r\ndoi:10.1109/CVPR.2017.143. iSSN:\r\n1063-6919.",
            "Huang et al. (2019) Huang et al. (2019)\r\n\r\nHuang, F., Zeng, A., Liu,\r\nM., Lai, Q., Xu, Q.,\r\n2019.\r\n\r\n\r\nDeepFuse: An IMU-Aware Network for\r\nReal-Time 3D Human Pose Estimation from Multi-View Image.\r\n\r\n\r\narXiv:1912.04071 [cs] URL: http://arxiv.org/abs/1912.04071. arXiv: 1912.04071.",
            "Zhang et al. (2020) Zhang et al. (2020)\r\n\r\nZhang, Z., Wang, C., Qin,\r\nW., Zeng, W., 2020.\r\n\r\n\r\nFusing wearable imus with multi-view images for human\r\npose estimation: A geometric approach.\r\n\r\n\r\narXiv:2003.11163.",
            "Newell et al. (2016) Newell et al. (2016)\r\n\r\nNewell, A., Yang, K.,\r\nDeng, J., 2016.\r\n\r\n\r\nStacked Hourglass Networks for Human Pose\r\nEstimation.\r\n\r\n\r\narXiv:1603.06937 [cs] URL: http://arxiv.org/abs/1603.06937. arXiv: 1603.06937.",
            "Chen et al. (2018) Chen et al. (2018)\r\n\r\nChen, Y., Wang, Z., Peng,\r\nY., Zhang, Z., Yu, G.,\r\nSun, J., 2018.\r\n\r\n\r\nCascaded Pyramid Network for Multi-Person\r\nPose Estimation.\r\n\r\n\r\narXiv:1711.07319 [cs] URL: http://arxiv.org/abs/1711.07319. arXiv: 1711.07319.",
            "Sun et al. (2019) Sun et al. (2019)\r\n\r\nSun, K., Xiao, B., Liu,\r\nD., Wang, J., 2019.\r\n\r\n\r\nDeep high-resolution representation learning for\r\nhuman pose estimation.\r\n\r\n\r\narXiv:1902.09212.",
            "Xiao et al. (2018) Xiao et al. (2018)\r\n\r\nXiao, B., Wu, H., Wei,\r\nY., 2018.\r\n\r\n\r\nSimple baselines for human pose estimation and\r\ntracking.\r\n\r\n\r\narXiv:1804.06208."
        ],
        "references": [
            "In this section, the main 3D pose estimation families of methods will be described. They can be classified as methods using human body models, learning algorithms or geometric information. In the case of a neural network learning approach, backbone networks are employed and new loss functions are created. Table 2 is the complete taxonomy of all discussed methods according to these criteria. In the second part of this section, we summarize the most commonly used architectures for 2D and 3D pose estimation."
        ]
    },
    "id_table_3": {
        "caption": "Table 3: Accuracy comparison from several state-of-the-art monocular methods. Human3.6M and HumanEva results reported in absolute MPJPE (lower is better); Results from MPI-INF-3DHP are reported in 3DPCK (higher is better). Techniques with the annotation with + are using extra-training data to obtain the result; the others use the benchmark’s recommended protocols. The * annotation indicates results published with procrustes alignment to ground truth poses before evaluation.",
        "table": [
            "<table id=\"S4.T3.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T3.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S4.T3.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Human3.6M</th>&#13;\n<th id=\"S4.T3.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">MPI-INF-3DHP</th>&#13;\n<th id=\"S4.T3.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">HumanEva</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T3.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavlakos et&#160;al.</span> (<a href=\"#bib.bib57\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">71.90</td>&#13;\n<td id=\"S4.T3.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">-</td>&#13;\n<td id=\"S4.T3.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\"><span id=\"S4.T3.1.2.1.4.1\" class=\"ltx_text ltx_font_bold\">24.3</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib50\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">80.5*</td>&#13;\n<td id=\"S4.T3.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">76.6</td>&#13;\n<td id=\"S4.T3.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Zhou et&#160;al.</span> (<a href=\"#bib.bib81\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">64.9</td>&#13;\n<td id=\"S4.T3.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">69.2</td>&#13;\n<td id=\"S4.T3.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Martinez et&#160;al.</span> (<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">62.9/47.7*</td>&#13;\n<td id=\"S4.T3.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T3.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">24.6</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Sun et&#160;al.</span> (<a href=\"#bib.bib67\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">64.1/49.6+/40.6*+</td>&#13;\n<td id=\"S4.T3.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T3.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Omran et&#160;al.</span> (<a href=\"#bib.bib56\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">59.9*</td>&#13;\n<td id=\"S4.T3.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T3.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">64.0*</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.8.7\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib49\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">69.9</td>&#13;\n<td id=\"S4.T3.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">74.1</td>&#13;\n<td id=\"S4.T3.1.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.9.8\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Kolotouros et&#160;al.</span> (<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T3.1.9.8.2.1\" class=\"ltx_text ltx_font_bold\">41.1</span></td>&#13;\n<td id=\"S4.T3.1.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\">76.4</td>&#13;\n<td id=\"S4.T3.1.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.10.9\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.10.9.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wandt and Rosenhahn</span> (<a href=\"#bib.bib73\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.10.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">50.9 / 38.2*</td>&#13;\n<td id=\"S4.T3.1.10.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">82.5</td>&#13;\n<td id=\"S4.T3.1.10.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.11.10\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.11.10.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Xu et&#160;al.</span> (<a href=\"#bib.bib76\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.11.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">82.4 / 53.9* /48.0*+</td>&#13;\n<td id=\"S4.T3.1.11.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">73.1 / 76.9+ / 89.0*+</td>&#13;\n<td id=\"S4.T3.1.11.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.12.11\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.12.11.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Kocabas et&#160;al.</span> (<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019b</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.12.11.2\" class=\"ltx_td ltx_align_center ltx_border_r\">51.83+/45.04*+</td>&#13;\n<td id=\"S4.T3.1.12.11.3\" class=\"ltx_td ltx_align_center ltx_border_r\">77.5</td>&#13;\n<td id=\"S4.T3.1.12.11.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.13.12\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.13.12.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\">&#13;\n<cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mathis et&#160;al.</span> (<a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite> (DeepLabCut)</th>&#13;\n<td id=\"S4.T3.1.13.12.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T3.1.13.12.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T3.1.13.12.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T3.1.14.13\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T3.1.14.13.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib48\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S4.T3.1.14.13.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">63.6</td>&#13;\n<td id=\"S4.T3.1.14.13.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T3.1.14.13.3.1\" class=\"ltx_text ltx_font_bold\">82.8</span></td>&#13;\n<td id=\"S4.T3.1.14.13.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">-</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Pavlakos et al. (2017) Pavlakos et al. (2017)\r\n\r\nPavlakos, G., Zhou, X.,\r\nDerpanis, K.G., Daniilidis, K.,\r\n2017.\r\n\r\n\r\nCoarse-to-Fine Volumetric Prediction for\r\nSingle-Image 3D Human Pose.\r\n\r\n\r\narXiv:1611.07828 [cs] URL: http://arxiv.org/abs/1611.07828. arXiv: 1611.07828.",
            "Mehta et al. (2017) Mehta et al. (2017)\r\n\r\nMehta, D., Sridhar, S.,\r\nSotnychenko, O., Rhodin, H.,\r\nShafiei, M., Seidel, H.P.,\r\nXu, W., Casas, D.,\r\nTheobalt, C., 2017.\r\n\r\n\r\nVNect: real-time 3D human pose estimation with a\r\nsingle RGB camera.\r\n\r\n\r\nACM Transactions on Graphics 36,\r\n1--14.\r\n\r\n\r\nURL: http://dl.acm.org/citation.cfm?doid=3072959.3073596,\r\ndoi:10.1145/3072959.3073596.",
            "Zhou et al. (2017) Zhou et al. (2017)\r\n\r\nZhou, X., Huang, Q., Sun,\r\nX., Xue, X., Wei, Y.,\r\n2017.\r\n\r\n\r\nTowards 3D Human Pose Estimation in the\r\nWild: a Weakly-supervised Approach.\r\n\r\n\r\narXiv:1704.02447 [cs] URL: http://arxiv.org/abs/1704.02447. arXiv: 1704.02447.",
            "Martinez et al. (2017) Martinez et al. (2017)\r\n\r\nMartinez, J., Hossain, R.,\r\nRomero, J., Little, J.J.,\r\n2017.\r\n\r\n\r\nA simple yet effective baseline for 3d human pose\r\nestimation.\r\n\r\n\r\narXiv:1705.03098 [cs] URL: http://arxiv.org/abs/1705.03098. arXiv: 1705.03098.",
            "Sun et al. (2018) Sun et al. (2018)\r\n\r\nSun, X., Xiao, B., Wei,\r\nF., Liang, S., Wei, Y.,\r\n2018.\r\n\r\n\r\nIntegral Human Pose Regression.\r\n\r\n\r\narXiv:1711.08229 [cs] URL: http://arxiv.org/abs/1711.08229. arXiv: 1711.08229.",
            "Omran et al. (2018) Omran et al. (2018)\r\n\r\nOmran, M., Lassner, C.,\r\nPons-Moll, G., Gehler, P.V.,\r\nSchiele, B., 2018.\r\n\r\n\r\nNeural Body Fitting: Unifying Deep Learning\r\nand Model-Based Human Pose and Shape Estimation.\r\n\r\n\r\narXiv:1808.05942 [cs] URL: http://arxiv.org/abs/1808.05942. arXiv: 1808.05942.",
            "Mehta et al. (2018) Mehta et al. (2018)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nSridhar, S., Pons-Moll, G.,\r\nTheobalt, C., 2018.\r\n\r\n\r\nSingle-Shot Multi-Person 3D Pose\r\nEstimation From Monocular RGB.\r\n\r\n\r\narXiv:1712.03453 [cs] URL: http://arxiv.org/abs/1712.03453. arXiv: 1712.03453.",
            "Kolotouros et al. (2019) Kolotouros et al. (2019)\r\n\r\nKolotouros, N., Pavlakos, G.,\r\nBlack, M.J., Daniilidis, K.,\r\n2019.\r\n\r\n\r\nLearning to Reconstruct 3D Human Pose and\r\nShape via Model-fitting in the Loop.\r\n\r\n\r\narXiv:1909.12828 [cs] URL: http://arxiv.org/abs/1909.12828. arXiv: 1909.12828.",
            "Wandt and Rosenhahn (2019) Wandt and Rosenhahn (2019)\r\n\r\nWandt, B., Rosenhahn, B.,\r\n2019.\r\n\r\n\r\nRepNet: Weakly Supervised Training of an\r\nAdversarial Reprojection Network for 3D Human Pose Estimation.\r\n\r\n\r\narXiv:1902.09868 [cs] URL: http://arxiv.org/abs/1902.09868. arXiv: 1902.09868.",
            "Xu et al. (2019) Xu et al. (2019)\r\n\r\nXu, Y., Zhu, S.C., Tung,\r\nT., 2019.\r\n\r\n\r\nDenseRaC: Joint 3D Pose and Shape\r\nEstimation by Dense Render-and-Compare.\r\n\r\n\r\narXiv:1910.00116 [cs, eess] URL: http://arxiv.org/abs/1910.00116. arXiv: 1910.00116.",
            "Kocabas et al. (2019b) Kocabas et al. (2019b)\r\n\r\nKocabas, M., Karagoz, S.,\r\nAkbas, E., 2019b.\r\n\r\n\r\nSelf-Supervised Learning of 3D Human Pose\r\nusing Multi-view Geometry.\r\n\r\n\r\narXiv:1903.02330 [cs] URL: http://arxiv.org/abs/1903.02330. arXiv: 1903.02330.",
            "Mathis et al. (2018) Mathis et al. (2018)\r\n\r\nMathis, A., Mamidanna, P.,\r\nCury, K.M., Abe, T.,\r\nMurthy, V.N., Mathis, M.W.,\r\nBethge, M., 2018.\r\n\r\n\r\nDeepLabCut: markerless pose estimation of\r\nuser-defined body parts with deep learning.\r\n\r\n\r\nNature Neuroscience 21,\r\n1281--1289.\r\n\r\n\r\nURL: https://www.nature.com/articles/s41593-018-0209-y,\r\ndoi:10.1038/s41593-018-0209-y. number: 9\r\nPublisher: Nature Publishing Group.",
            "Mehta et al. (2020) Mehta et al. (2020)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nElgharib, M., Fua, P.,\r\nSeidel, H.P., Rhodin, H.,\r\nPons-Moll, G., Theobalt, C.,\r\n2020.\r\n\r\n\r\nXNect: Real-time Multi-Person 3D Motion\r\nCapture with a Single RGB Camera.\r\n\r\n\r\nACM Transactions on Graphics 39.\r\n\r\n\r\nURL: http://arxiv.org/abs/1907.00837,\r\ndoi:10.1145/3386569.3392410. arXiv: 1907.00837."
        ],
        "references": [
            "This section describes and compares the top performing methods for vision based 3D markerless pose estimation (see Tables 3, 4 and 5). The selection process was as the follows :"
        ]
    },
    "id_table_4": {
        "caption": "Table 4: Accuracy comparison from several state-of-the-art monocular temporal methods. Human3.6M and HumanEva results reported in absolute MPJPE (lower is better); Results from MPI-INF-3DHP are reported in 3DPCK (higher is better). Techniques with the annotation with + are using extra-training data to obtain the result; the others use the benchmark’s recommended protocols. The * annotation indicates results published with procrustes alignment to ground truth poses before evaluation. ",
        "table": [
            "<table id=\"S4.T4.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T4.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S4.T4.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Human3.6M</th>&#13;\n<th id=\"S4.T4.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">MPI-INF-3DHP</th>&#13;\n<th id=\"S4.T4.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">HumanEva</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T4.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Hossain and Little</span> (<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S4.T4.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">58.5</td>&#13;\n<td id=\"S4.T4.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">-</td>&#13;\n<td id=\"S4.T4.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">22.0</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cai et&#160;al. (<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></th>&#13;\n<td id=\"S4.T4.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">48.8 / 39.0*</td>&#13;\n<td id=\"S4.T4.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T4.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavllo et&#160;al.</span> (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T4.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">46.8 / 36.5*</td>&#13;\n<td id=\"S4.T4.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T4.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">23.1/15.8*</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Cheng et&#160;al.</span> (<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T4.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">42.9/32.8*</td>&#13;\n<td id=\"S4.T4.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T4.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">14.3*</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></th>&#13;\n<td id=\"S4.T4.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T4.1.6.5.2.1\" class=\"ltx_text ltx_font_bold\">40.1</span></td>&#13;\n<td id=\"S4.T4.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T4.1.6.5.3.1\" class=\"ltx_text ltx_font_bold\">84.1</span></td>&#13;\n<td id=\"S4.T4.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S4.T4.1.6.5.4.1\" class=\"ltx_text ltx_font_bold\">13.5*</span></td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Liu et&#160;al.</span> (<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S4.T4.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">45.1 / 35.6*</td>&#13;\n<td id=\"S4.T4.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T4.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">15.4*</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T4.1.8.7\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T4.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wang et&#160;al.</span> (<a href=\"#bib.bib74\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S4.T4.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">42.6 / 32.7*</td>&#13;\n<td id=\"S4.T4.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">86.9(2d GT)</td>&#13;\n<td id=\"S4.T4.1.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">-</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Hossain and Little (2018) Hossain and Little (2018)\r\n\r\nHossain, M.R.I., Little, J.J.,\r\n2018.\r\n\r\n\r\nExploiting temporal information for 3D pose\r\nestimation.\r\n\r\n\r\narXiv:1711.08585 [cs] 11214,\r\n69--86.\r\n\r\n\r\nURL: http://arxiv.org/abs/1711.08585,\r\ndoi:10.1007/978-3-030-01249-6_5. arXiv:\r\n1711.08585.",
            "Cai et al. (2019) Cai et al. (2019)\r\n\r\nCai, Y., Ge, L., Liu, J.,\r\nCai, J., Cham, T.J.,\r\nYuan, J., Thalmann, N.M.,\r\n2019.\r\n\r\n\r\nExploiting Spatial-Temporal Relationships for\r\n3D Pose Estimation via Graph Convolutional Networks, in:\r\n2019 IEEE/CVF International Conference on\r\nComputer Vision (ICCV), IEEE,\r\nSeoul, Korea (South). pp. 2272–2281.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9009459/,\r\ndoi:10.1109/ICCV.2019.00236.",
            "Pavllo et al. (2019) Pavllo et al. (2019)\r\n\r\nPavllo, D., Feichtenhofer, C.,\r\nGrangier, D., Auli, M.,\r\n2019.\r\n\r\n\r\n3D Human Pose Estimation in Video With\r\nTemporal Convolutions and Semi-Supervised Training, in:\r\n2019 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nLong Beach, CA, USA. pp. 7745--7754.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/8954163/,\r\ndoi:10.1109/CVPR.2019.00794.",
            "Cheng et al. (2019) Cheng et al. (2019)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Yan, W., Tan, R.T.,\r\n2019.\r\n\r\n\r\nOcclusion-Aware Networks for 3D Human Pose\r\nEstimation in Video, pp. 723--732.\r\n\r\n\r\nURL: http://openaccess.thecvf.com/content_ICCV_2019/html/Cheng_Occlusion-Aware_Networks_for_3D_Human_Pose_Estimation_in_Video_ICCV_2019_paper.html.",
            "Cheng et al. (2020) Cheng et al. (2020)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Tan, R.T., 2020.\r\n\r\n\r\n3d human pose estimation using spatio-temporal\r\nnetworks with explicit occlusion training.\r\n\r\n\r\narXiv:2004.11822.",
            "Liu et al. (2020) Liu et al. (2020)\r\n\r\nLiu, R., Shen, J., Wang,\r\nH., Chen, C., Cheung, S.c.,\r\nAsari, V., 2020.\r\n\r\n\r\nAttention Mechanism Exploits Temporal\r\nContexts: Real-Time 3D Human Pose Reconstruction, in:\r\n2020 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nSeattle, WA, USA. pp. 5063--5072.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9156272/,\r\ndoi:10.1109/CVPR42600.2020.00511.",
            "Wang et al. (2020) Wang et al. (2020)\r\n\r\nWang, J., Yan, S., Xiong,\r\nY., Lin, D., 2020.\r\n\r\n\r\nMotion Guided 3D Pose Estimation from\r\nVideos, in: Vedaldi, A., Bischof, H.,\r\nBrox, T., Frahm, J.M. (Eds.),\r\nComputer Vision – ECCV 2020.\r\nSpringer International Publishing,\r\nCham. volume 12358, pp.\r\n764--780.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-58601-0_45,\r\ndoi:10.1007/978-3-030-58601-0_45. series Title:\r\nLecture Notes in Computer Science."
        ],
        "references": [
            "This section describes and compares the top performing methods for vision based 3D markerless pose estimation (see Tables 3, 4 and 5). The selection process was as the follows :"
        ]
    },
    "id_table_5": {
        "caption": "Table 5: Accuracy comparison from several state-of-the-art multi-view and multimodal methods. Human3.6M and TotalCapture results reported in absolute MPJPE (lower is better). Techniques with the annotation with + are using extra-training data to obtain the result; the others use the benchmark’s recommended protocols. The * annotation indicates results published with procrustes alignment to ground truth poses before evaluation.",
        "table": [
            "<table id=\"S4.T5.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S4.T5.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.1.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S4.T5.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Human3.6M</th>&#13;\n<th id=\"S4.T5.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Total Capture</th>&#13;\n<th id=\"S4.T5.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Input</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S4.T5.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.2.1.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Qiu et&#160;al.</span> (<a href=\"#bib.bib59\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">31.17 / 26.21+</td>&#13;\n<td id=\"S4.T5.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">29</td>&#13;\n<td id=\"S4.T5.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_tt\">Multi-view</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.3.2.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#13;\n<span id=\"S4.T5.1.3.2.2.1\" class=\"ltx_text ltx_font_bold\">17.7+</span>/20.80*+</td>&#13;\n<td id=\"S4.T5.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T5.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.4.3.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">He et&#160;al.</span> (<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">26.9/19.0+</td>&#13;\n<td id=\"S4.T5.1.4.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T5.1.4.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.5.4.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib41\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2016</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T5.1.5.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T5.1.5.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view, IMU</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.6.5.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Trumble et&#160;al.</span> (<a href=\"#bib.bib71\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">87.3</td>&#13;\n<td id=\"S4.T5.1.6.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">77.0</td>&#13;\n<td id=\"S4.T5.1.6.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view, Temporal, IMU</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.7.6.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S4.T5.1.7.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">26.0</td>&#13;\n<td id=\"S4.T5.1.7.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Monocular, IMU</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.8.7\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.8.7.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Huang et&#160;al.</span> (<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">37.5/13.4*</td>&#13;\n<td id=\"S4.T5.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">28.9</td>&#13;\n<td id=\"S4.T5.1.8.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view, IMU</td>&#13;\n</tr>&#13;\n<tr id=\"S4.T5.1.9.8\" class=\"ltx_tr\">&#13;\n<th id=\"S4.T5.1.9.8.1\" class=\"ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Zhang et&#160;al.</span> (<a href=\"#bib.bib80\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S4.T5.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">-</td>&#13;\n<td id=\"S4.T5.1.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S4.T5.1.9.8.3.1\" class=\"ltx_text ltx_font_bold\">24.6</span></td>&#13;\n<td id=\"S4.T5.1.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Multi-view, IMU</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Qiu et al. (2019) Qiu et al. (2019)\r\n\r\nQiu, H., Wang, C., Wang,\r\nJ., Wang, N., Zeng, W.,\r\n2019.\r\n\r\n\r\nCross View Fusion for 3D Human Pose\r\nEstimation.\r\n\r\n\r\narXiv:1909.01203 [cs] URL: http://arxiv.org/abs/1909.01203. arXiv: 1909.01203.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "He et al. (2020) He et al. (2020)\r\n\r\nHe, Y., Yan, R.,\r\nFragkiadaki, K., Yu, S.I.,\r\n2020.\r\n\r\n\r\nEpipolar Transformers.\r\n\r\n\r\narXiv:2005.04551 [cs] URL: http://arxiv.org/abs/2005.04551. arXiv: 2005.04551.",
            "von Marcard et al. (2016) von Marcard et al. (2016)\r\n\r\nvon Marcard, T., Pons-Moll, G.,\r\nRosenhahn, B., 2016.\r\n\r\n\r\nHuman pose estimation from video and imus.\r\n\r\n\r\nTransactions on Pattern Analysis and Machine\r\nIntelligence 38, 1533--1547.\r\n\r\n\r\nURL: http://dx.doi.org/10.1109/TPAMI.2016.2522398,\r\ndoi:10.1109/TPAMI.2016.2522398.",
            "Trumble et al. (2017) Trumble et al. (2017)\r\n\r\nTrumble, M., Gilbert, A.,\r\nMalleson, C., Hilton, A.,\r\nCollomosse, J., 2017.\r\n\r\n\r\nTotal Capture: 3D Human Pose Estimation\r\nFusing Video and Inertial Sensors, in:\r\nProcedings of the British Machine Vision\r\nConference 2017, British Machine Vision Association,\r\nLondon, UK. p. 14.\r\n\r\n\r\nURL: http://www.bmva.org/bmvc/2017/papers/paper014/index.html,\r\ndoi:10.5244/C.31.14.",
            "von Marcard et al. (2018) von Marcard et al. (2018)\r\n\r\nvon Marcard, T., Henschel, R.,\r\nBlack, M.J., Rosenhahn, B.,\r\nPons-Moll, G., 2018.\r\n\r\n\r\nRecovering Accurate 3D Human Pose in the\r\nWild Using IMUs and a Moving Camera, in: Ferrari,\r\nV., Hebert, M., Sminchisescu, C.,\r\nWeiss, Y. (Eds.), Computer Vision –\r\nECCV 2018. Springer International Publishing,\r\nCham. volume 11214, pp.\r\n614--631.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-01249-6_37,\r\ndoi:10.1007/978-3-030-01249-6_37. series Title:\r\nLecture Notes in Computer Science.",
            "Huang et al. (2019) Huang et al. (2019)\r\n\r\nHuang, F., Zeng, A., Liu,\r\nM., Lai, Q., Xu, Q.,\r\n2019.\r\n\r\n\r\nDeepFuse: An IMU-Aware Network for\r\nReal-Time 3D Human Pose Estimation from Multi-View Image.\r\n\r\n\r\narXiv:1912.04071 [cs] URL: http://arxiv.org/abs/1912.04071. arXiv: 1912.04071.",
            "Zhang et al. (2020) Zhang et al. (2020)\r\n\r\nZhang, Z., Wang, C., Qin,\r\nW., Zeng, W., 2020.\r\n\r\n\r\nFusing wearable imus with multi-view images for human\r\npose estimation: A geometric approach.\r\n\r\n\r\narXiv:2003.11163."
        ],
        "references": [
            "This section describes and compares the top performing methods for vision based 3D markerless pose estimation (see Tables 3, 4 and 5). The selection process was as the follows :"
        ]
    },
    "id_table_6": {
        "caption": "Table 6: Best accuracy methods. Methods reported with performance criteria of current real-life applications that use 3D pose estimation for four setups (monocular, temporal, multi-view). Accuracy is reported in MPJPE on Human3.6M dataset bold for best and underlined for second best. The best multi-modal approaches using IMU (marked with *) are evaluated with MPJPE on TotalCapture for comparison.",
        "table": [
            "<table id=\"S5.T6.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S5.T6.1.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t\" colspan=\"5\">Accuracy</th>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S5.T6.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Type</th>&#13;\n<th id=\"S5.T6.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Accuracy</th>&#13;\n<th id=\"S5.T6.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Robustness Level</th>&#13;\n<th id=\"S5.T6.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Real-time</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T6.1.1.3.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Kolotouros et&#160;al.</span> (<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Monocular</td>&#13;\n<td id=\"S5.T6.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><span id=\"S5.T6.1.1.3.1.3.1\" class=\"ltx_text ltx_font_bold\">41.1</span></td>&#13;\n<td id=\"S5.T6.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">average</td>&#13;\n<td id=\"S5.T6.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.4.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wandt and Rosenhahn</span> (<a href=\"#bib.bib73\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Monocular</td>&#13;\n<td id=\"S5.T6.1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.1.1.4.2.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">50.9</span></td>&#13;\n<td id=\"S5.T6.1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T6.1.1.4.2.5\" class=\"ltx_td ltx_align_center\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.5.3\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view</td>&#13;\n<td id=\"S5.T6.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.1.1.5.3.3.1\" class=\"ltx_text ltx_font_bold\">17.7</span></td>&#13;\n<td id=\"S5.T6.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T6.1.1.5.3.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.6.4\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">He et&#160;al.</span> (<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view</td>&#13;\n<td id=\"S5.T6.1.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.1.1.6.4.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">26.9</span></td>&#13;\n<td id=\"S5.T6.1.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">low</td>&#13;\n<td id=\"S5.T6.1.1.6.4.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.7.5\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Temporal</td>&#13;\n<td id=\"S5.T6.1.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.1.1.7.5.3.1\" class=\"ltx_text ltx_font_bold\">40.1</span></td>&#13;\n<td id=\"S5.T6.1.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T6.1.1.7.5.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.8.6\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wang et&#160;al.</span> (<a href=\"#bib.bib74\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Temporal</td>&#13;\n<td id=\"S5.T6.1.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\"><span id=\"S5.T6.1.1.8.6.3.1\" class=\"ltx_text ltx_framed ltx_framed_underline\">42.6</span></td>&#13;\n<td id=\"S5.T6.1.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T6.1.1.8.6.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T6.1.1.9.7\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T6.1.1.9.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Zhang et&#160;al.</span> (<a href=\"#bib.bib80\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T6.1.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Multimodal</td>&#13;\n<td id=\"S5.T6.1.1.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><span id=\"S5.T6.1.1.9.7.3.1\" class=\"ltx_text ltx_font_italic\">24.6*</span></td>&#13;\n<td id=\"S5.T6.1.1.9.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">low</td>&#13;\n<td id=\"S5.T6.1.1.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_b\">&#10007;</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Kolotouros et al. (2019) Kolotouros et al. (2019)\r\n\r\nKolotouros, N., Pavlakos, G.,\r\nBlack, M.J., Daniilidis, K.,\r\n2019.\r\n\r\n\r\nLearning to Reconstruct 3D Human Pose and\r\nShape via Model-fitting in the Loop.\r\n\r\n\r\narXiv:1909.12828 [cs] URL: http://arxiv.org/abs/1909.12828. arXiv: 1909.12828.",
            "Wandt and Rosenhahn (2019) Wandt and Rosenhahn (2019)\r\n\r\nWandt, B., Rosenhahn, B.,\r\n2019.\r\n\r\n\r\nRepNet: Weakly Supervised Training of an\r\nAdversarial Reprojection Network for 3D Human Pose Estimation.\r\n\r\n\r\narXiv:1902.09868 [cs] URL: http://arxiv.org/abs/1902.09868. arXiv: 1902.09868.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "He et al. (2020) He et al. (2020)\r\n\r\nHe, Y., Yan, R.,\r\nFragkiadaki, K., Yu, S.I.,\r\n2020.\r\n\r\n\r\nEpipolar Transformers.\r\n\r\n\r\narXiv:2005.04551 [cs] URL: http://arxiv.org/abs/2005.04551. arXiv: 2005.04551.",
            "Cheng et al. (2020) Cheng et al. (2020)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Tan, R.T., 2020.\r\n\r\n\r\n3d human pose estimation using spatio-temporal\r\nnetworks with explicit occlusion training.\r\n\r\n\r\narXiv:2004.11822.",
            "Wang et al. (2020) Wang et al. (2020)\r\n\r\nWang, J., Yan, S., Xiong,\r\nY., Lin, D., 2020.\r\n\r\n\r\nMotion Guided 3D Pose Estimation from\r\nVideos, in: Vedaldi, A., Bischof, H.,\r\nBrox, T., Frahm, J.M. (Eds.),\r\nComputer Vision – ECCV 2020.\r\nSpringer International Publishing,\r\nCham. volume 12358, pp.\r\n764--780.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-58601-0_45,\r\ndoi:10.1007/978-3-030-58601-0_45. series Title:\r\nLecture Notes in Computer Science.",
            "Zhang et al. (2020) Zhang et al. (2020)\r\n\r\nZhang, Z., Wang, C., Qin,\r\nW., Zeng, W., 2020.\r\n\r\n\r\nFusing wearable imus with multi-view images for human\r\npose estimation: A geometric approach.\r\n\r\n\r\narXiv:2003.11163."
        ],
        "references": [
            "For this reason, our review describes each criterion separately and explains in which use case it performs the best. Tables 6, 7 and 10 classify these methods with accuracy reported in MPJPE. The level of robustness corresponds to the number of assumptions or constraints necessary for correct detection. Lastly, to express the speed, we report whether the model can run in real-time. Each of these tables allow to cross-compare the different methods best suited to the most needed specifications.",
            "The table 6 shows that the most accurate methods have a medium to low level of robustness and that few of them work in real time. The explanation comes from the fact that they are often complex methods that tackle issues such as occlusion with specific modules that increase the overall computational cost. As explained above, the best methods are naturally multi-view techniques that exploit geometric constraints and therefore need calibrations.\r\nCurrently, the architectures that achieve the best accuracy are two-stage top-down algorithms. They achieve the best results on a variety of benchmarks in monocular image, monocular video, and multi-view configurations. They often build on the success of 2D pose estimation, which is a nearly solved problem (i.e., it achieves average PCK scores above 90%). Many different approaches are effective: direct regression from 2D to 3D, initialization of human parametric models, exploitation of temporal sequences, occlusion-aware modules, generative models, volumetric input representation, multi-view triangulation, to name the most important (See 4 and Fig. 3). An interesting point is that, logically, video sequence methods perform better for activities with temporal coherence, such as walking or running, while monocular methods best detect complex static poses better."
        ]
    },
    "id_table_7": {
        "caption": "Table 7: Most robust methods. Robustness level is defined as follows: 1 - 3 assumptions: high level, 3 - 4 assumptions: average level and 5 or more: low level.",
        "table": [
            "<table id=\"S5.T7.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S5.T7.1.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\" colspan=\"5\">Robustness</th>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S5.T7.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Type</th>&#13;\n<th id=\"S5.T7.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Accuracy</th>&#13;\n<th id=\"S5.T7.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Robustness Level</th>&#13;\n<th id=\"S5.T7.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Real-time</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T7.1.1.3.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib48\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Monocular</td>&#13;\n<td id=\"S5.T7.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">63.6</td>&#13;\n<td id=\"S5.T7.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">high</td>&#13;\n<td id=\"S5.T7.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.4.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Xu et&#160;al.</span> (<a href=\"#bib.bib76\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Monocular</td>&#13;\n<td id=\"S5.T7.1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">82.4</td>&#13;\n<td id=\"S5.T7.1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>&#13;\n<td id=\"S5.T7.1.1.4.2.5\" class=\"ltx_td ltx_align_center\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.5.3\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Hossain and Little</span> (<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Temporal</td>&#13;\n<td id=\"S5.T7.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">58.5</td>&#13;\n<td id=\"S5.T7.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>&#13;\n<td id=\"S5.T7.1.1.5.3.5\" class=\"ltx_td ltx_align_center\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.6.4\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Temporal</td>&#13;\n<td id=\"S5.T7.1.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">40.1</td>&#13;\n<td id=\"S5.T7.1.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T7.1.1.6.4.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.7.5\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Liu et&#160;al.</span> (<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Temporal</td>&#13;\n<td id=\"S5.T7.1.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">45.1</td>&#13;\n<td id=\"S5.T7.1.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T7.1.1.7.5.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.8.6\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">Multi-view</td>&#13;\n<td id=\"S5.T7.1.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">17.7</td>&#13;\n<td id=\"S5.T7.1.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T7.1.1.8.6.5\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T7.1.1.9.7\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T7.1.1.9.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">von Marcard et&#160;al.</span> (<a href=\"#bib.bib40\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S5.T7.1.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">Multimodal</td>&#13;\n<td id=\"S5.T7.1.1.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">26.0*</td>&#13;\n<td id=\"S5.T7.1.1.9.7.4\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">high</td>&#13;\n<td id=\"S5.T7.1.1.9.7.5\" class=\"ltx_td ltx_align_center ltx_border_b\">&#10007;</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Mehta et al. (2020) Mehta et al. (2020)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nElgharib, M., Fua, P.,\r\nSeidel, H.P., Rhodin, H.,\r\nPons-Moll, G., Theobalt, C.,\r\n2020.\r\n\r\n\r\nXNect: Real-time Multi-Person 3D Motion\r\nCapture with a Single RGB Camera.\r\n\r\n\r\nACM Transactions on Graphics 39.\r\n\r\n\r\nURL: http://arxiv.org/abs/1907.00837,\r\ndoi:10.1145/3386569.3392410. arXiv: 1907.00837.",
            "Xu et al. (2019) Xu et al. (2019)\r\n\r\nXu, Y., Zhu, S.C., Tung,\r\nT., 2019.\r\n\r\n\r\nDenseRaC: Joint 3D Pose and Shape\r\nEstimation by Dense Render-and-Compare.\r\n\r\n\r\narXiv:1910.00116 [cs, eess] URL: http://arxiv.org/abs/1910.00116. arXiv: 1910.00116.",
            "Hossain and Little (2018) Hossain and Little (2018)\r\n\r\nHossain, M.R.I., Little, J.J.,\r\n2018.\r\n\r\n\r\nExploiting temporal information for 3D pose\r\nestimation.\r\n\r\n\r\narXiv:1711.08585 [cs] 11214,\r\n69--86.\r\n\r\n\r\nURL: http://arxiv.org/abs/1711.08585,\r\ndoi:10.1007/978-3-030-01249-6_5. arXiv:\r\n1711.08585.",
            "Cheng et al. (2020) Cheng et al. (2020)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Tan, R.T., 2020.\r\n\r\n\r\n3d human pose estimation using spatio-temporal\r\nnetworks with explicit occlusion training.\r\n\r\n\r\narXiv:2004.11822.",
            "Liu et al. (2020) Liu et al. (2020)\r\n\r\nLiu, R., Shen, J., Wang,\r\nH., Chen, C., Cheung, S.c.,\r\nAsari, V., 2020.\r\n\r\n\r\nAttention Mechanism Exploits Temporal\r\nContexts: Real-Time 3D Human Pose Reconstruction, in:\r\n2020 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nSeattle, WA, USA. pp. 5063--5072.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9156272/,\r\ndoi:10.1109/CVPR42600.2020.00511.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "von Marcard et al. (2018) von Marcard et al. (2018)\r\n\r\nvon Marcard, T., Henschel, R.,\r\nBlack, M.J., Rosenhahn, B.,\r\nPons-Moll, G., 2018.\r\n\r\n\r\nRecovering Accurate 3D Human Pose in the\r\nWild Using IMUs and a Moving Camera, in: Ferrari,\r\nV., Hebert, M., Sminchisescu, C.,\r\nWeiss, Y. (Eds.), Computer Vision –\r\nECCV 2018. Springer International Publishing,\r\nCham. volume 11214, pp.\r\n614--631.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-01249-6_37,\r\ndoi:10.1007/978-3-030-01249-6_37. series Title:\r\nLecture Notes in Computer Science."
        ],
        "references": [
            "For this reason, our review describes each criterion separately and explains in which use case it performs the best. Tables 6, 7 and 10 classify these methods with accuracy reported in MPJPE. The level of robustness corresponds to the number of assumptions or constraints necessary for correct detection. Lastly, to express the speed, we report whether the model can run in real-time. Each of these tables allow to cross-compare the different methods best suited to the most needed specifications.",
            "Table 7 shows the less constrained methods and their performance. Robustness relates to the number of assumptions (the fewer the better). For monocular techniques, the multi-person methods trained on complex datasets containing severe occlusions logically impose fewer constraints. For temporal techniques, the ones that do not need future frames for inference perform best. Hossain and Little (2018) achieves maximum accuracy with the fewest images Liu et al. (2020). cheng203d address fast motion and occlusions but require a higher acquisition frequency and a wider temporal receptive field to produce better results. The most robust multi-view method is Iskakov et al. (2019) because it does not require any special hardware and can work with only two cameras while achieving acceptable accuracy (see table 9). Finally, von Marcard et al. (2018) can perform multi-person pose estimation in the wild with mobile cameras. Yet, the low constraints in terms of environment and subject come at the cost of high constraints in terms of additional hardware (IMU and scans)."
        ]
    },
    "id_table_8": {
        "caption": "Table 8: Monocular temporal models assumptions. Needed number of frames to obtain the optimal accuracy and whether the system can be adapted to only use past frames (for real-time use)",
        "table": [
            "<table id=\"S5.T8.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S5.T8.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T8.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S5.T8.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">#Frames</th>&#13;\n<th id=\"S5.T8.1.1.1.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">Causal</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T8.1.2.1\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Hossain and Little</span> (<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></td>&#13;\n<td id=\"S5.T8.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">5</td>&#13;\n<td id=\"S5.T8.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T8.1.3.2\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cai et&#160;al. (<a href=\"#bib.bib6\" title=\"\" class=\"ltx_ref\">2019</a>)</cite></td>&#13;\n<td id=\"S5.T8.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">7</td>&#13;\n<td id=\"S5.T8.1.3.2.3\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T8.1.4.3\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavllo et&#160;al.</span> (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></td>&#13;\n<td id=\"S5.T8.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">243</td>&#13;\n<td id=\"S5.T8.1.4.3.3\" class=\"ltx_td ltx_align_center\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T8.1.5.4\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Cheng et&#160;al.</span> (<a href=\"#bib.bib11\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></td>&#13;\n<td id=\"S5.T8.1.5.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">256</td>&#13;\n<td id=\"S5.T8.1.5.4.3\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T8.1.6.5\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\">Cheng et&#160;al. (<a href=\"#bib.bib10\" title=\"\" class=\"ltx_ref\">2020</a>)</cite></td>&#13;\n<td id=\"S5.T8.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">128</td>&#13;\n<td id=\"S5.T8.1.6.5.3\" class=\"ltx_td ltx_align_center\">&#10007;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T8.1.7.6\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Liu et&#160;al.</span> (<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></td>&#13;\n<td id=\"S5.T8.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">243</td>&#13;\n<td id=\"S5.T8.1.7.6.3\" class=\"ltx_td ltx_align_center\">&#10003;</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T8.1.8.7\" class=\"ltx_tr\">&#13;\n<td id=\"S5.T8.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wang et&#160;al.</span> (<a href=\"#bib.bib74\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></td>&#13;\n<td id=\"S5.T8.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">96</td>&#13;\n<td id=\"S5.T8.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_b\">&#10007;</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Hossain and Little (2018) Hossain and Little (2018)\r\n\r\nHossain, M.R.I., Little, J.J.,\r\n2018.\r\n\r\n\r\nExploiting temporal information for 3D pose\r\nestimation.\r\n\r\n\r\narXiv:1711.08585 [cs] 11214,\r\n69--86.\r\n\r\n\r\nURL: http://arxiv.org/abs/1711.08585,\r\ndoi:10.1007/978-3-030-01249-6_5. arXiv:\r\n1711.08585.",
            "Cai et al. (2019) Cai et al. (2019)\r\n\r\nCai, Y., Ge, L., Liu, J.,\r\nCai, J., Cham, T.J.,\r\nYuan, J., Thalmann, N.M.,\r\n2019.\r\n\r\n\r\nExploiting Spatial-Temporal Relationships for\r\n3D Pose Estimation via Graph Convolutional Networks, in:\r\n2019 IEEE/CVF International Conference on\r\nComputer Vision (ICCV), IEEE,\r\nSeoul, Korea (South). pp. 2272–2281.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9009459/,\r\ndoi:10.1109/ICCV.2019.00236.",
            "Pavllo et al. (2019) Pavllo et al. (2019)\r\n\r\nPavllo, D., Feichtenhofer, C.,\r\nGrangier, D., Auli, M.,\r\n2019.\r\n\r\n\r\n3D Human Pose Estimation in Video With\r\nTemporal Convolutions and Semi-Supervised Training, in:\r\n2019 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nLong Beach, CA, USA. pp. 7745--7754.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/8954163/,\r\ndoi:10.1109/CVPR.2019.00794.",
            "Cheng et al. (2019) Cheng et al. (2019)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Yan, W., Tan, R.T.,\r\n2019.\r\n\r\n\r\nOcclusion-Aware Networks for 3D Human Pose\r\nEstimation in Video, pp. 723--732.\r\n\r\n\r\nURL: http://openaccess.thecvf.com/content_ICCV_2019/html/Cheng_Occlusion-Aware_Networks_for_3D_Human_Pose_Estimation_in_Video_ICCV_2019_paper.html.",
            "Cheng et al. (2020) Cheng et al. (2020)\r\n\r\nCheng, Y., Yang, B., Wang,\r\nB., Tan, R.T., 2020.\r\n\r\n\r\n3d human pose estimation using spatio-temporal\r\nnetworks with explicit occlusion training.\r\n\r\n\r\narXiv:2004.11822.",
            "Liu et al. (2020) Liu et al. (2020)\r\n\r\nLiu, R., Shen, J., Wang,\r\nH., Chen, C., Cheung, S.c.,\r\nAsari, V., 2020.\r\n\r\n\r\nAttention Mechanism Exploits Temporal\r\nContexts: Real-Time 3D Human Pose Reconstruction, in:\r\n2020 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nSeattle, WA, USA. pp. 5063--5072.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9156272/,\r\ndoi:10.1109/CVPR42600.2020.00511.",
            "Wang et al. (2020) Wang et al. (2020)\r\n\r\nWang, J., Yan, S., Xiong,\r\nY., Lin, D., 2020.\r\n\r\n\r\nMotion Guided 3D Pose Estimation from\r\nVideos, in: Vedaldi, A., Bischof, H.,\r\nBrox, T., Frahm, J.M. (Eds.),\r\nComputer Vision – ECCV 2020.\r\nSpringer International Publishing,\r\nCham. volume 12358, pp.\r\n764--780.\r\n\r\n\r\nURL: http://link.springer.com/10.1007/978-3-030-58601-0_45,\r\ndoi:10.1007/978-3-030-58601-0_45. series Title:\r\nLecture Notes in Computer Science."
        ],
        "references": [
            "Former markerless motion tracking systems were sometimes constrained to slow motion of only few limbs to perform good detection. It is less and less the case, but there is still some difficulty in predicting quick motions (e.g., in sports video). Cheng et al. (2020) suggest that temporal and spatial data at different resolutions can be a solution to this issue. A new assumption that can be added for methods based on temporal data : if the video footage is not long enough to provide sufficient information, this can be an issue for real-time inference and even for accuracy. Additionally, temporal methods often use information in the future frame, which is not suitable for real-time. Table 8 show that these methods perform best with varying temporal receptive fields. Some methods only need a few past and future images, while the accuracy of others saturates at more than 200. These methods can be adapted to shorter video clips and to real-time application using only past frames, but at the price of a decrease in accuracy. Another strong constraint is the use of video from moving cameras, but this is rarely addressed von Marcard et al. (2018). Many applications can work with the assumption of fixed cameras, but there is a substantial amount of video data produced with moving camera coordinate systems (e.g., in outdoor sports)."
        ]
    },
    "id_table_9": {
        "caption": "Table 9: Multi-view models hardware-related assumptions. The number of camera view used to achieve less than the baseline 40mm MPJPE error (best results from monocular methods) on Human3.6M is also shown (and on TotalCapture under parenthesis).",
        "table": [
            "<table id=\"S5.T9.1.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T9.1.1.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\">Method</th>&#13;\n<td id=\"S5.T9.1.1.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Calibration</td>&#13;\n<td id=\"S5.T9.1.1.1.2.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">Additional</td>&#13;\n<td id=\"S5.T9.1.1.1.2.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\">#Views</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.1.2\" class=\"ltx_td ltx_th ltx_th_row ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.1.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.1.4\" class=\"ltx_td ltx_align_center ltx_border_r\">Hardware</td>&#13;\n<td id=\"S5.T9.1.1.1.1.1\" class=\"ltx_td ltx_align_center\">&#13;\n<math id=\"S5.T9.1.1.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"&lt;\" display=\"inline\"><semantics id=\"S5.T9.1.1.1.1.1.m1.1a\"><mo id=\"S5.T9.1.1.1.1.1.m1.1.1\" xref=\"S5.T9.1.1.1.1.1.m1.1.1.cmml\">&lt;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S5.T9.1.1.1.1.1.m1.1b\"><lt id=\"S5.T9.1.1.1.1.1.m1.1.1.cmml\" xref=\"S5.T9.1.1.1.1.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S5.T9.1.1.1.1.1.m1.1c\">&lt;</annotation></semantics></math> 40 MPJPE</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Trumble et&#160;al.</span> (<a href=\"#bib.bib71\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.3.2.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.3.2.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.3.2.4\" class=\"ltx_td ltx_align_center ltx_border_t\">4</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Qiu et&#160;al.</span> (<a href=\"#bib.bib59\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.4.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.4.3.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.4.3.4\" class=\"ltx_td ltx_align_center\">4</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Kocabas et&#160;al.</span> (<a href=\"#bib.bib32\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019b</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.5.4.2\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.5.4.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.5.4.4\" class=\"ltx_td ltx_align_center\">4</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.6.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.6.5.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.6.5.4\" class=\"ltx_td ltx_align_center\">2</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">He et&#160;al.</span> (<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.7.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.7.6.3\" class=\"ltx_td ltx_border_r\"/>&#13;\n<td id=\"S5.T9.1.1.1.7.6.4\" class=\"ltx_td ltx_align_center\">3</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.8.7\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Huang et&#160;al.</span> (<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.8.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.8.7.4\" class=\"ltx_td ltx_align_center\">4(8)</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T9.1.1.1.9.8\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T9.1.1.1.9.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Zhang et&#160;al.</span> (<a href=\"#bib.bib80\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T9.1.1.1.9.8.2\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.9.8.3\" class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r\">&#10003;</td>&#13;\n<td id=\"S5.T9.1.1.1.9.8.4\" class=\"ltx_td ltx_align_center ltx_border_b\">4(8)</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Trumble et al. (2017) Trumble et al. (2017)\r\n\r\nTrumble, M., Gilbert, A.,\r\nMalleson, C., Hilton, A.,\r\nCollomosse, J., 2017.\r\n\r\n\r\nTotal Capture: 3D Human Pose Estimation\r\nFusing Video and Inertial Sensors, in:\r\nProcedings of the British Machine Vision\r\nConference 2017, British Machine Vision Association,\r\nLondon, UK. p. 14.\r\n\r\n\r\nURL: http://www.bmva.org/bmvc/2017/papers/paper014/index.html,\r\ndoi:10.5244/C.31.14.",
            "Qiu et al. (2019) Qiu et al. (2019)\r\n\r\nQiu, H., Wang, C., Wang,\r\nJ., Wang, N., Zeng, W.,\r\n2019.\r\n\r\n\r\nCross View Fusion for 3D Human Pose\r\nEstimation.\r\n\r\n\r\narXiv:1909.01203 [cs] URL: http://arxiv.org/abs/1909.01203. arXiv: 1909.01203.",
            "Kocabas et al. (2019b) Kocabas et al. (2019b)\r\n\r\nKocabas, M., Karagoz, S.,\r\nAkbas, E., 2019b.\r\n\r\n\r\nSelf-Supervised Learning of 3D Human Pose\r\nusing Multi-view Geometry.\r\n\r\n\r\narXiv:1903.02330 [cs] URL: http://arxiv.org/abs/1903.02330. arXiv: 1903.02330.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "He et al. (2020) He et al. (2020)\r\n\r\nHe, Y., Yan, R.,\r\nFragkiadaki, K., Yu, S.I.,\r\n2020.\r\n\r\n\r\nEpipolar Transformers.\r\n\r\n\r\narXiv:2005.04551 [cs] URL: http://arxiv.org/abs/2005.04551. arXiv: 2005.04551.",
            "Huang et al. (2019) Huang et al. (2019)\r\n\r\nHuang, F., Zeng, A., Liu,\r\nM., Lai, Q., Xu, Q.,\r\n2019.\r\n\r\n\r\nDeepFuse: An IMU-Aware Network for\r\nReal-Time 3D Human Pose Estimation from Multi-View Image.\r\n\r\n\r\narXiv:1912.04071 [cs] URL: http://arxiv.org/abs/1912.04071. arXiv: 1912.04071.",
            "Zhang et al. (2020) Zhang et al. (2020)\r\n\r\nZhang, Z., Wang, C., Qin,\r\nW., Zeng, W., 2020.\r\n\r\n\r\nFusing wearable imus with multi-view images for human\r\npose estimation: A geometric approach.\r\n\r\n\r\narXiv:2003.11163."
        ],
        "references": [
            "Two constraints are still relevant: first, the need for specific hardware, second, the need for calibration in multi-view configurations. The two most commonly used extra hardware added for pose estimation are inertial motion units and depth sensors such as infrared or time-of-flight cameras. Inertial motion unit provide additional information on the limbs orientation but suffer from drift in their results after a short usage. They are also more practical than reflecting markers and motion capture suits but are still intrusive for the subject. Different depth sensors have also been used to infer the depth of joints directly or to construct more complex features as a pre-processing step of pose estimation. Less frequently some methods use the 3D scan of each subjects that is captured to fit shapes parameter of human body models. Logically, while most research is conducted on monocular methods, they are always outperformed by 10 to 20 mm MPJPE by multi-view techniques. In multi-view systems, the calibration step is a frequent requirement. Multi-view methods that do not use or use partial calibration need more views to achieve acceptable accuracy, while others can produce good results with fewer cameras but need extrinsic parameters (see table 9).",
            "Table 7 shows the less constrained methods and their performance. Robustness relates to the number of assumptions (the fewer the better). For monocular techniques, the multi-person methods trained on complex datasets containing severe occlusions logically impose fewer constraints. For temporal techniques, the ones that do not need future frames for inference perform best. Hossain and Little (2018) achieves maximum accuracy with the fewest images Liu et al. (2020). cheng203d address fast motion and occlusions but require a higher acquisition frequency and a wider temporal receptive field to produce better results. The most robust multi-view method is Iskakov et al. (2019) because it does not require any special hardware and can work with only two cameras while achieving acceptable accuracy (see table 9). Finally, von Marcard et al. (2018) can perform multi-person pose estimation in the wild with mobile cameras. Yet, the low constraints in terms of environment and subject come at the cost of high constraints in terms of additional hardware (IMU and scans)."
        ]
    },
    "id_table_10": {
        "caption": "Table 10: Real-time methods. Along with the other criteria for comparison, the speed (in frames inferred per second) and the graphical card used are reported. Note that methods such as Hossain and Little (2018) and Wandt and Rosenhahn (2019) are not considering the speed of the 2D detector in the first stage of their techniques when reporting fps.",
        "table": [
            "<table id=\"S5.T10.1.1\" class=\"ltx_tabular ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S5.T10.1.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row\" colspan=\"5\">Speed</th>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.2.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.2.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S5.T10.1.1.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Accuracy</th>&#13;\n<th id=\"S5.T10.1.1.2.2.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Robustness Level</th>&#13;\n<th id=\"S5.T10.1.1.2.2.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t\">Speed</th>&#13;\n<th id=\"S5.T10.1.1.2.2.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">GPU used</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T10.1.1.3.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.3.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib50\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.3.1.2\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">80.5</td>&#13;\n<td id=\"S5.T10.1.1.3.1.3\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">average</td>&#13;\n<td id=\"S5.T10.1.1.3.1.4\" class=\"ltx_td ltx_align_center ltx_border_r ltx_border_t\">30fps</td>&#13;\n<td id=\"S5.T10.1.1.3.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\">N/A</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.4.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.4.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Wandt and Rosenhahn</span> (<a href=\"#bib.bib73\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.4.2.2\" class=\"ltx_td ltx_align_center ltx_border_r\">50.9</td>&#13;\n<td id=\"S5.T10.1.1.4.2.3\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T10.1.1.4.2.4\" class=\"ltx_td ltx_align_center ltx_border_r\">20 000fps</td>&#13;\n<td id=\"S5.T10.1.1.4.2.5\" class=\"ltx_td ltx_align_center\">Nvidia Titan X</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.5.3\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.5.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Xu et&#160;al.</span> (<a href=\"#bib.bib76\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.5.3.2\" class=\"ltx_td ltx_align_center ltx_border_r\">82.4</td>&#13;\n<td id=\"S5.T10.1.1.5.3.3\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>&#13;\n<td id=\"S5.T10.1.1.5.3.4\" class=\"ltx_td ltx_align_center ltx_border_r\">120fps</td>&#13;\n<td id=\"S5.T10.1.1.5.3.5\" class=\"ltx_td ltx_align_center\">N/A</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.6.4\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.6.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mathis et&#160;al.</span> (<a href=\"#bib.bib45\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.6.4.2\" class=\"ltx_td ltx_align_center ltx_border_r\">-</td>&#13;\n<td id=\"S5.T10.1.1.6.4.3\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T10.1.1.6.4.4\" class=\"ltx_td ltx_align_center ltx_border_r\">30fps</td>&#13;\n<td id=\"S5.T10.1.1.6.4.5\" class=\"ltx_td ltx_align_center\">Nvidia 1080Ti</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.7.5\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.7.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Mehta et&#160;al.</span> (<a href=\"#bib.bib48\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.7.5.2\" class=\"ltx_td ltx_align_center ltx_border_r\">63.6</td>&#13;\n<td id=\"S5.T10.1.1.7.5.3\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>&#13;\n<td id=\"S5.T10.1.1.7.5.4\" class=\"ltx_td ltx_align_center ltx_border_r\">30fps</td>&#13;\n<td id=\"S5.T10.1.1.7.5.5\" class=\"ltx_td ltx_align_center\">N/A</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.8.6\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.8.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Hossain and Little</span> (<a href=\"#bib.bib23\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.8.6.2\" class=\"ltx_td ltx_align_center ltx_border_r\">58.5</td>&#13;\n<td id=\"S5.T10.1.1.8.6.3\" class=\"ltx_td ltx_align_center ltx_border_r\">high</td>&#13;\n<td id=\"S5.T10.1.1.8.6.4\" class=\"ltx_td ltx_align_center ltx_border_r\">300fps</td>&#13;\n<td id=\"S5.T10.1.1.8.6.5\" class=\"ltx_td ltx_align_center\">Nvidia Titan X</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.9.7\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.9.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Liu et&#160;al.</span> (<a href=\"#bib.bib36\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.9.7.2\" class=\"ltx_td ltx_align_center ltx_border_r\">45.1</td>&#13;\n<td id=\"S5.T10.1.1.9.7.3\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T10.1.1.9.7.4\" class=\"ltx_td ltx_align_center ltx_border_r\">3000fps</td>&#13;\n<td id=\"S5.T10.1.1.9.7.5\" class=\"ltx_td ltx_align_center\">Nvidia Titan RTX</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.10.8\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.10.8.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavllo et&#160;al.</span> (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.10.8.2\" class=\"ltx_td ltx_align_center ltx_border_r\">46.8</td>&#13;\n<td id=\"S5.T10.1.1.10.8.3\" class=\"ltx_td ltx_align_center ltx_border_r\">average</td>&#13;\n<td id=\"S5.T10.1.1.10.8.4\" class=\"ltx_td ltx_align_center ltx_border_r\">150 000fps</td>&#13;\n<td id=\"S5.T10.1.1.10.8.5\" class=\"ltx_td ltx_align_center\">Nvidia GP100</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.11.9\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.11.9.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Trumble et&#160;al.</span> (<a href=\"#bib.bib71\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.11.9.2\" class=\"ltx_td ltx_align_center ltx_border_r\">87.3</td>&#13;\n<td id=\"S5.T10.1.1.11.9.3\" class=\"ltx_td ltx_align_center ltx_border_r\">low</td>&#13;\n<td id=\"S5.T10.1.1.11.9.4\" class=\"ltx_td ltx_align_center ltx_border_r\">25fps</td>&#13;\n<td id=\"S5.T10.1.1.11.9.5\" class=\"ltx_td ltx_align_center\">N/A</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T10.1.1.12.10\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T10.1.1.12.10.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Huang et&#160;al.</span> (<a href=\"#bib.bib25\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T10.1.1.12.10.2\" class=\"ltx_td ltx_align_center ltx_border_r\">37.5</td>&#13;\n<td id=\"S5.T10.1.1.12.10.3\" class=\"ltx_td ltx_align_center ltx_border_r\">low</td>&#13;\n<td id=\"S5.T10.1.1.12.10.4\" class=\"ltx_td ltx_align_center ltx_border_r\">25fps</td>&#13;\n<td id=\"S5.T10.1.1.12.10.5\" class=\"ltx_td ltx_align_center\">Nvidia 1080Ti</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Mehta et al. (2017) Mehta et al. (2017)\r\n\r\nMehta, D., Sridhar, S.,\r\nSotnychenko, O., Rhodin, H.,\r\nShafiei, M., Seidel, H.P.,\r\nXu, W., Casas, D.,\r\nTheobalt, C., 2017.\r\n\r\n\r\nVNect: real-time 3D human pose estimation with a\r\nsingle RGB camera.\r\n\r\n\r\nACM Transactions on Graphics 36,\r\n1--14.\r\n\r\n\r\nURL: http://dl.acm.org/citation.cfm?doid=3072959.3073596,\r\ndoi:10.1145/3072959.3073596.",
            "Wandt and Rosenhahn (2019) Wandt and Rosenhahn (2019)\r\n\r\nWandt, B., Rosenhahn, B.,\r\n2019.\r\n\r\n\r\nRepNet: Weakly Supervised Training of an\r\nAdversarial Reprojection Network for 3D Human Pose Estimation.\r\n\r\n\r\narXiv:1902.09868 [cs] URL: http://arxiv.org/abs/1902.09868. arXiv: 1902.09868.",
            "Xu et al. (2019) Xu et al. (2019)\r\n\r\nXu, Y., Zhu, S.C., Tung,\r\nT., 2019.\r\n\r\n\r\nDenseRaC: Joint 3D Pose and Shape\r\nEstimation by Dense Render-and-Compare.\r\n\r\n\r\narXiv:1910.00116 [cs, eess] URL: http://arxiv.org/abs/1910.00116. arXiv: 1910.00116.",
            "Mathis et al. (2018) Mathis et al. (2018)\r\n\r\nMathis, A., Mamidanna, P.,\r\nCury, K.M., Abe, T.,\r\nMurthy, V.N., Mathis, M.W.,\r\nBethge, M., 2018.\r\n\r\n\r\nDeepLabCut: markerless pose estimation of\r\nuser-defined body parts with deep learning.\r\n\r\n\r\nNature Neuroscience 21,\r\n1281--1289.\r\n\r\n\r\nURL: https://www.nature.com/articles/s41593-018-0209-y,\r\ndoi:10.1038/s41593-018-0209-y. number: 9\r\nPublisher: Nature Publishing Group.",
            "Mehta et al. (2020) Mehta et al. (2020)\r\n\r\nMehta, D., Sotnychenko, O.,\r\nMueller, F., Xu, W.,\r\nElgharib, M., Fua, P.,\r\nSeidel, H.P., Rhodin, H.,\r\nPons-Moll, G., Theobalt, C.,\r\n2020.\r\n\r\n\r\nXNect: Real-time Multi-Person 3D Motion\r\nCapture with a Single RGB Camera.\r\n\r\n\r\nACM Transactions on Graphics 39.\r\n\r\n\r\nURL: http://arxiv.org/abs/1907.00837,\r\ndoi:10.1145/3386569.3392410. arXiv: 1907.00837.",
            "Hossain and Little (2018) Hossain and Little (2018)\r\n\r\nHossain, M.R.I., Little, J.J.,\r\n2018.\r\n\r\n\r\nExploiting temporal information for 3D pose\r\nestimation.\r\n\r\n\r\narXiv:1711.08585 [cs] 11214,\r\n69--86.\r\n\r\n\r\nURL: http://arxiv.org/abs/1711.08585,\r\ndoi:10.1007/978-3-030-01249-6_5. arXiv:\r\n1711.08585.",
            "Liu et al. (2020) Liu et al. (2020)\r\n\r\nLiu, R., Shen, J., Wang,\r\nH., Chen, C., Cheung, S.c.,\r\nAsari, V., 2020.\r\n\r\n\r\nAttention Mechanism Exploits Temporal\r\nContexts: Real-Time 3D Human Pose Reconstruction, in:\r\n2020 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nSeattle, WA, USA. pp. 5063--5072.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/9156272/,\r\ndoi:10.1109/CVPR42600.2020.00511.",
            "Pavllo et al. (2019) Pavllo et al. (2019)\r\n\r\nPavllo, D., Feichtenhofer, C.,\r\nGrangier, D., Auli, M.,\r\n2019.\r\n\r\n\r\n3D Human Pose Estimation in Video With\r\nTemporal Convolutions and Semi-Supervised Training, in:\r\n2019 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nLong Beach, CA, USA. pp. 7745--7754.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/8954163/,\r\ndoi:10.1109/CVPR.2019.00794.",
            "Trumble et al. (2017) Trumble et al. (2017)\r\n\r\nTrumble, M., Gilbert, A.,\r\nMalleson, C., Hilton, A.,\r\nCollomosse, J., 2017.\r\n\r\n\r\nTotal Capture: 3D Human Pose Estimation\r\nFusing Video and Inertial Sensors, in:\r\nProcedings of the British Machine Vision\r\nConference 2017, British Machine Vision Association,\r\nLondon, UK. p. 14.\r\n\r\n\r\nURL: http://www.bmva.org/bmvc/2017/papers/paper014/index.html,\r\ndoi:10.5244/C.31.14.",
            "Huang et al. (2019) Huang et al. (2019)\r\n\r\nHuang, F., Zeng, A., Liu,\r\nM., Lai, Q., Xu, Q.,\r\n2019.\r\n\r\n\r\nDeepFuse: An IMU-Aware Network for\r\nReal-Time 3D Human Pose Estimation from Multi-View Image.\r\n\r\n\r\narXiv:1912.04071 [cs] URL: http://arxiv.org/abs/1912.04071. arXiv: 1912.04071.",
            "Hossain and Little (2018) Hossain and Little (2018)\r\n\r\nHossain, M.R.I., Little, J.J.,\r\n2018.\r\n\r\n\r\nExploiting temporal information for 3D pose\r\nestimation.\r\n\r\n\r\narXiv:1711.08585 [cs] 11214,\r\n69--86.\r\n\r\n\r\nURL: http://arxiv.org/abs/1711.08585,\r\ndoi:10.1007/978-3-030-01249-6_5. arXiv:\r\n1711.08585.",
            "Wandt and Rosenhahn (2019) Wandt and Rosenhahn (2019)\r\n\r\nWandt, B., Rosenhahn, B.,\r\n2019.\r\n\r\n\r\nRepNet: Weakly Supervised Training of an\r\nAdversarial Reprojection Network for 3D Human Pose Estimation.\r\n\r\n\r\narXiv:1902.09868 [cs] URL: http://arxiv.org/abs/1902.09868. arXiv: 1902.09868."
        ],
        "references": [
            "For this reason, our review describes each criterion separately and explains in which use case it performs the best. Tables 6, 7 and 10 classify these methods with accuracy reported in MPJPE. The level of robustness corresponds to the number of assumptions or constraints necessary for correct detection. Lastly, to express the speed, we report whether the model can run in real-time. Each of these tables allow to cross-compare the different methods best suited to the most needed specifications.",
            "In the speed part of table 10, we report all methods that can run in real time. The inference speed is in frames per second and the GPU used is also specified. Robustness is variable in this collection of methods, and the accuracy seems a bit below average for the fastest methods. The most accurate is Huang et al. (2019), which achieves 37.5 MPJPE on Human3.6M without using its IMU component (it also performs well on TotalCapture with the addition of IMU data)."
        ]
    },
    "id_table_11": {
        "caption": "Table 11: Number of reported parameters of different reviewed techniques.",
        "table": [
            "<table id=\"S5.T11.1\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S5.T11.1.1.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t\">Method</th>&#13;\n<th id=\"S5.T11.1.1.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\">#Parameters</th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S5.T11.1.2.1\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.2.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Martinez et&#160;al.</span> (<a href=\"#bib.bib44\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2017</span></a>)</cite></th>&#13;\n<td id=\"S5.T11.1.2.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\">4-5M</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T11.1.3.2\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.3.2.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">&#13;\n<cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Sun et&#160;al.</span> (<a href=\"#bib.bib67\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2018</span></a>)</cite> HG/Res50/Res101</th>&#13;\n<td id=\"S5.T11.1.3.2.2\" class=\"ltx_td ltx_align_center\">26M/26M/45M</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T11.1.4.3\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.4.3.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Pavllo et&#160;al.</span> (<a href=\"#bib.bib58\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T11.1.4.3.2\" class=\"ltx_td ltx_align_center\">16.95M</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T11.1.5.4\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.5.4.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Qiu et&#160;al.</span> (<a href=\"#bib.bib59\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite></th>&#13;\n<td id=\"S5.T11.1.5.4.2\" class=\"ltx_td ltx_align_center\">560M</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T11.1.6.5\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.6.5.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">&#13;\n<cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite> alg.</th>&#13;\n<td id=\"S5.T11.1.6.5.2\" class=\"ltx_td ltx_align_center\">80M</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T11.1.7.6\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.7.6.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r\">&#13;\n<cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">Iskakov et&#160;al.</span> (<a href=\"#bib.bib28\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2019</span></a>)</cite> vol.</th>&#13;\n<td id=\"S5.T11.1.7.6.2\" class=\"ltx_td ltx_align_center\">81M</td>&#13;\n</tr>&#13;\n<tr id=\"S5.T11.1.8.7\" class=\"ltx_tr\">&#13;\n<th id=\"S5.T11.1.8.7.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r\"><cite class=\"ltx_cite ltx_citemacro_cite\"><span class=\"ltx_text ltx_font_typewriter\">He et&#160;al.</span> (<a href=\"#bib.bib22\" title=\"\" class=\"ltx_ref\"><span class=\"ltx_text ltx_font_typewriter\">2020</span></a>)</cite></th>&#13;\n<td id=\"S5.T11.1.8.7.2\" class=\"ltx_td ltx_align_center ltx_border_b\">69M</td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "Martinez et al. (2017) Martinez et al. (2017)\r\n\r\nMartinez, J., Hossain, R.,\r\nRomero, J., Little, J.J.,\r\n2017.\r\n\r\n\r\nA simple yet effective baseline for 3d human pose\r\nestimation.\r\n\r\n\r\narXiv:1705.03098 [cs] URL: http://arxiv.org/abs/1705.03098. arXiv: 1705.03098.",
            "Sun et al. (2018) Sun et al. (2018)\r\n\r\nSun, X., Xiao, B., Wei,\r\nF., Liang, S., Wei, Y.,\r\n2018.\r\n\r\n\r\nIntegral Human Pose Regression.\r\n\r\n\r\narXiv:1711.08229 [cs] URL: http://arxiv.org/abs/1711.08229. arXiv: 1711.08229.",
            "Pavllo et al. (2019) Pavllo et al. (2019)\r\n\r\nPavllo, D., Feichtenhofer, C.,\r\nGrangier, D., Auli, M.,\r\n2019.\r\n\r\n\r\n3D Human Pose Estimation in Video With\r\nTemporal Convolutions and Semi-Supervised Training, in:\r\n2019 IEEE/CVF Conference on Computer Vision and\r\nPattern Recognition (CVPR), IEEE,\r\nLong Beach, CA, USA. pp. 7745--7754.\r\n\r\n\r\nURL: https://ieeexplore.ieee.org/document/8954163/,\r\ndoi:10.1109/CVPR.2019.00794.",
            "Qiu et al. (2019) Qiu et al. (2019)\r\n\r\nQiu, H., Wang, C., Wang,\r\nJ., Wang, N., Zeng, W.,\r\n2019.\r\n\r\n\r\nCross View Fusion for 3D Human Pose\r\nEstimation.\r\n\r\n\r\narXiv:1909.01203 [cs] URL: http://arxiv.org/abs/1909.01203. arXiv: 1909.01203.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "Iskakov et al. (2019) Iskakov et al. (2019)\r\n\r\nIskakov, K., Burkov, E.,\r\nLempitsky, V., Malkov, Y.,\r\n2019.\r\n\r\n\r\nLearnable Triangulation of Human Pose.\r\n\r\n\r\narXiv:1905.05754 [cs] URL: http://arxiv.org/abs/1905.05754. arXiv: 1905.05754.",
            "He et al. (2020) He et al. (2020)\r\n\r\nHe, Y., Yan, R.,\r\nFragkiadaki, K., Yu, S.I.,\r\n2020.\r\n\r\n\r\nEpipolar Transformers.\r\n\r\n\r\narXiv:2005.04551 [cs] URL: http://arxiv.org/abs/2005.04551. arXiv: 2005.04551."
        ],
        "references": [
            "Most of the reviewed methods can be trained to adapt to new challenging contexts or refined on new data. It is also important to have an idea of the training time when an application might consider online training. The number of parameters is a good indication of the depth of the architecture (see Table 11), which can also be calculated using backbone 2D detection networks in many cases."
        ]
    }
}