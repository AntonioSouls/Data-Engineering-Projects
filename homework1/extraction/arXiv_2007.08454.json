{
    "id_table_1": {
        "caption": "Table 1: \r\nComparisons on CAMERA25 and REAL275.\r\nWe report the mAP w.r.t. different thresholds on 3D IoU, and rotation and translation errors.\r\n",
        "table": [],
        "footnotes": [
            "[33] [33]\r\n\r\nWang, H., Sridhar, S., Huang, J., Valentin, J., Song, S., Guibas, L.J.:\r\nNormalized object coordinate space for category-level 6d object pose and size\r\nestimation. In: Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition. pp. 2642â€“2651 (2019)",
            "[33] [33]\r\n\r\nWang, H., Sridhar, S., Huang, J., Valentin, J., Song, S., Guibas, L.J.:\r\nNormalized object coordinate space for category-level 6d object pose and size\r\nestimation. In: Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition. pp. 2642â€“2651 (2019)"
        ],
        "references": [
            "We compare our approach to the Baseline [33] on CAMERA25 and REAL275.\r\nQuantitative results are summarized in Table 1.",
            "CAMERA25.\r\nIn the setting of estimating 6D object pose and size from an RGB-D image, we achieve a mAP of 83.1% for 3D IoU at 0.75, and a mAP of 54.3% for 6D pose at 5âˆ˜â€‹â€‰2â€‹cmsuperscript52cm5^{\\circ}\\,2\\text{cm}.\r\nOur results are 14% and 22% higher than the Baseline [33], respectively.\r\nWe naively remove the depth input and related sub-networks in our network (i.e. RGB image as the only input) to make fair comparisons with the Baseline [33], which takes an RGB image as its input.\r\nAs shown in TableÂ 1, our results without depth input are still significantly better than the Baseline [33] (i.e. +15.5% and +17.9%).\r\nOn one hand, this experiment shows the advantage of explicit handling of the intra-class shape variation, and the effectiveness of our method which reconstructs the object via deformation.\r\nOn the other hand, it also shows that adding depth to the network does help to improve overall performance, although our improved performance does not rely on it solely.\r\nGiven that depth image is required to uniquely determine the scale of the object, we recommend it in practical applications.\r\nThe top row of Fig. 4 shows the average precision at different error thresholds for all 6 object categories.\r\nIt provides independent analysis for 3D IoU, rotation, and translation error."
        ]
    },
    "id_table_2": {
        "caption": "Table 2: Evaluation of shape reconstruction with CD metric (Ã—10âˆ’3absentsuperscript103\\times 10^{-3}).",
        "table": [],
        "footnotes": [],
        "references": [
            "To evaluate the quality of the reconstruction, we compute the CD metric (c.f. Eq. 2) of the reconstructed model from our method with the ground truth model in the NOCS.\r\nWe get a CD metric of 1.97 on CAMERA25 and 3.17 on REAL275. In comparison, the CD metrics are 3.70 and 4.41 on the respective dataset for the shape priors from our autoencoder.\r\nThe better CD metrics of the reconstructed models compared to the shape priors show that the deformation estimation in our framework improves the quality of the 3D model reconstruction.\r\nTable 2 shows the CD metric of our reconstructed models and the shape priors for each category."
        ]
    },
    "id_table_3": {
        "caption": "Table 3: Ablation studies on CAMERA25. Refer to text for more details.",
        "table": [],
        "footnotes": [],
        "references": [
            "Different shape priors.\r\nWe first evaluate how different shape priors influence the performance.\r\nAll settings are kept the same in this experiment except for the choices of the priors.\r\nResults are summarized in Table 3 and 4.\r\nâ€œEmbeddingâ€ refers to the priors obtained from decoding the mean latent embeddings.\r\nWe also try the instance whose latent embedding has the minimum L2subscriptğ¿2L_{2} distance to the mean latent embedding (denoted as â€œNNâ€).\r\nIn addition, we explore random selection of one instance per category from the shape collection to compose our priors (denoted as â€œRandomâ€).\r\nIn general, our approach remains stable under different priors.\r\nOur network can adapt to different shape priors because the deformation is explicitly estimated.\r\nWe achieve the best result for accurate pose (i.e. 5âˆ˜â€‹â€‰2â€‹cmsuperscript52cm5^{\\circ}\\,2\\text{cm}) estimation when the learned categorical shape prior is used.\r\nSince our main target is to recover the 6D pose, we choose â€œEmbeddingâ€ as our best model.\r\nTo validate whether the priors are necessary, we use a point cloud uniformly sampled from a sphere of diameter one as our prior (denoted as â€œNoneâ€).\r\nThe mAP decreases by 3.7% on real dataset\r\nwhen there are no priors, but the best result is achieved for object size estimation.\r\nAlthough shape priors are beneficial for estimating 6D pose, they sometimes bias shape reconstruction.",
            "Directly regress the NOCS Coordinates?\r\nAs indicated by Eq. 4, our approach decouples the NOCS coordinates Pğ‘ƒP to shape reconstruction Mğ‘€M and dense correspondences Ağ´A.\r\nHowever, both the network architecture and the training will be much simpler when we follow [33] to regress Pğ‘ƒP directly (denoted as â€œRegressionâ€ in Table 3 and 4).\r\nFor 6D pose estimation, the mAP of â€œRegressionâ€ at 5âˆ˜â€‹â€‰2â€‹cmsuperscript52cm5^{\\circ}\\,2\\text{cm} is notably lower than â€œEmbeddingâ€ on CAMERA25 (-3.1%) and REAL275 (-5.6%).\r\nThis result further supports the benefit of handling shape variation via reconstruction over naive regression of the NOCS coordinates.\r\nâ€œRegressionâ€ achieves slightly better mAP for object size estimation since it only finds the NOCS coordinates for the observed part, while â€œEmbeddingâ€ needs to complete the unknown part of the object."
        ]
    },
    "id_table_4": {
        "caption": "Table 4: Ablation studies on REAL275. Refer to text for more details.",
        "table": [],
        "footnotes": [],
        "references": [
            "Different shape priors.\r\nWe first evaluate how different shape priors influence the performance.\r\nAll settings are kept the same in this experiment except for the choices of the priors.\r\nResults are summarized in Table 3 and 4.\r\nâ€œEmbeddingâ€ refers to the priors obtained from decoding the mean latent embeddings.\r\nWe also try the instance whose latent embedding has the minimum L2subscriptğ¿2L_{2} distance to the mean latent embedding (denoted as â€œNNâ€).\r\nIn addition, we explore random selection of one instance per category from the shape collection to compose our priors (denoted as â€œRandomâ€).\r\nIn general, our approach remains stable under different priors.\r\nOur network can adapt to different shape priors because the deformation is explicitly estimated.\r\nWe achieve the best result for accurate pose (i.e. 5âˆ˜â€‹â€‰2â€‹cmsuperscript52cm5^{\\circ}\\,2\\text{cm}) estimation when the learned categorical shape prior is used.\r\nSince our main target is to recover the 6D pose, we choose â€œEmbeddingâ€ as our best model.\r\nTo validate whether the priors are necessary, we use a point cloud uniformly sampled from a sphere of diameter one as our prior (denoted as â€œNoneâ€).\r\nThe mAP decreases by 3.7% on real dataset\r\nwhen there are no priors, but the best result is achieved for object size estimation.\r\nAlthough shape priors are beneficial for estimating 6D pose, they sometimes bias shape reconstruction.",
            "Directly regress the NOCS Coordinates?\r\nAs indicated by Eq. 4, our approach decouples the NOCS coordinates Pğ‘ƒP to shape reconstruction Mğ‘€M and dense correspondences Ağ´A.\r\nHowever, both the network architecture and the training will be much simpler when we follow [33] to regress Pğ‘ƒP directly (denoted as â€œRegressionâ€ in Table 3 and 4).\r\nFor 6D pose estimation, the mAP of â€œRegressionâ€ at 5âˆ˜â€‹â€‰2â€‹cmsuperscript52cm5^{\\circ}\\,2\\text{cm} is notably lower than â€œEmbeddingâ€ on CAMERA25 (-3.1%) and REAL275 (-5.6%).\r\nThis result further supports the benefit of handling shape variation via reconstruction over naive regression of the NOCS coordinates.\r\nâ€œRegressionâ€ achieves slightly better mAP for object size estimation since it only finds the NOCS coordinates for the observed part, while â€œEmbeddingâ€ needs to complete the unknown part of the object."
        ]
    },
    "id_table_5": {
        "caption": "Table 5: Quantitative comparison with CASS on REAL275.",
        "table": [
            "<table id=\"S1.T5.10\" class=\"ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle\">&#13;\n<thead class=\"ltx_thead\">&#13;\n<tr id=\"S1.T5.10.11.1\" class=\"ltx_tr\">&#13;\n<th id=\"S1.T5.10.11.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" rowspan=\"2\"><span id=\"S1.T5.10.11.1.1.1\" class=\"ltx_text ltx_font_bold\">Method</span></th>&#13;\n<th id=\"S1.T5.10.11.1.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\" colspan=\"6\"><span id=\"S1.T5.10.11.1.2.1\" class=\"ltx_text ltx_font_bold\">mAP</span></th>&#13;\n<th id=\"S1.T5.10.11.1.3\" class=\"ltx_td ltx_th ltx_th_column ltx_border_tt\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"/>&#13;\n</tr>&#13;\n<tr id=\"S1.T5.7.7\" class=\"ltx_tr\">&#13;\n<th id=\"S1.T5.1.1.1\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"3\\text{D}_{25}\" display=\"inline\"><semantics id=\"S1.T5.1.1.1.m1.1a\"><mrow id=\"S1.T5.1.1.1.m1.1.1\" xref=\"S1.T5.1.1.1.m1.1.1.cmml\"><mn id=\"S1.T5.1.1.1.m1.1.1.2\" xref=\"S1.T5.1.1.1.m1.1.1.2.cmml\">3</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.1.1.1.m1.1.1.1\" xref=\"S1.T5.1.1.1.m1.1.1.1.cmml\">&#8203;</mo><msub id=\"S1.T5.1.1.1.m1.1.1.3\" xref=\"S1.T5.1.1.1.m1.1.1.3.cmml\"><mtext id=\"S1.T5.1.1.1.m1.1.1.3.2\" xref=\"S1.T5.1.1.1.m1.1.1.3.2a.cmml\">D</mtext><mn id=\"S1.T5.1.1.1.m1.1.1.3.3\" xref=\"S1.T5.1.1.1.m1.1.1.3.3.cmml\">25</mn></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.1.1.1.m1.1b\"><apply id=\"S1.T5.1.1.1.m1.1.1.cmml\" xref=\"S1.T5.1.1.1.m1.1.1\"><times id=\"S1.T5.1.1.1.m1.1.1.1.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.1\"/><cn type=\"integer\" id=\"S1.T5.1.1.1.m1.1.1.2.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.2\">3</cn><apply id=\"S1.T5.1.1.1.m1.1.1.3.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S1.T5.1.1.1.m1.1.1.3.1.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.3\">subscript</csymbol><ci id=\"S1.T5.1.1.1.m1.1.1.3.2a.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.3.2\"><mtext id=\"S1.T5.1.1.1.m1.1.1.3.2.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.3.2\">D</mtext></ci><cn type=\"integer\" id=\"S1.T5.1.1.1.m1.1.1.3.3.cmml\" xref=\"S1.T5.1.1.1.m1.1.1.3.3\">25</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.1.1.1.m1.1c\">3\\text{D}_{25}</annotation></semantics></math></th>&#13;\n<th id=\"S1.T5.2.2.2\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.2.2.2.m1.1\" class=\"ltx_Math\" alttext=\"3\\text{D}_{50}\" display=\"inline\"><semantics id=\"S1.T5.2.2.2.m1.1a\"><mrow id=\"S1.T5.2.2.2.m1.1.1\" xref=\"S1.T5.2.2.2.m1.1.1.cmml\"><mn id=\"S1.T5.2.2.2.m1.1.1.2\" xref=\"S1.T5.2.2.2.m1.1.1.2.cmml\">3</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.2.2.2.m1.1.1.1\" xref=\"S1.T5.2.2.2.m1.1.1.1.cmml\">&#8203;</mo><msub id=\"S1.T5.2.2.2.m1.1.1.3\" xref=\"S1.T5.2.2.2.m1.1.1.3.cmml\"><mtext id=\"S1.T5.2.2.2.m1.1.1.3.2\" xref=\"S1.T5.2.2.2.m1.1.1.3.2a.cmml\">D</mtext><mn id=\"S1.T5.2.2.2.m1.1.1.3.3\" xref=\"S1.T5.2.2.2.m1.1.1.3.3.cmml\">50</mn></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.2.2.2.m1.1b\"><apply id=\"S1.T5.2.2.2.m1.1.1.cmml\" xref=\"S1.T5.2.2.2.m1.1.1\"><times id=\"S1.T5.2.2.2.m1.1.1.1.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.1\"/><cn type=\"integer\" id=\"S1.T5.2.2.2.m1.1.1.2.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.2\">3</cn><apply id=\"S1.T5.2.2.2.m1.1.1.3.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S1.T5.2.2.2.m1.1.1.3.1.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.3\">subscript</csymbol><ci id=\"S1.T5.2.2.2.m1.1.1.3.2a.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.3.2\"><mtext id=\"S1.T5.2.2.2.m1.1.1.3.2.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.3.2\">D</mtext></ci><cn type=\"integer\" id=\"S1.T5.2.2.2.m1.1.1.3.3.cmml\" xref=\"S1.T5.2.2.2.m1.1.1.3.3\">50</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.2.2.2.m1.1c\">3\\text{D}_{50}</annotation></semantics></math></th>&#13;\n<th id=\"S1.T5.3.3.3\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.3.3.3.m1.1\" class=\"ltx_Math\" alttext=\"3\\text{D}_{75}\" display=\"inline\"><semantics id=\"S1.T5.3.3.3.m1.1a\"><mrow id=\"S1.T5.3.3.3.m1.1.1\" xref=\"S1.T5.3.3.3.m1.1.1.cmml\"><mn id=\"S1.T5.3.3.3.m1.1.1.2\" xref=\"S1.T5.3.3.3.m1.1.1.2.cmml\">3</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.3.3.3.m1.1.1.1\" xref=\"S1.T5.3.3.3.m1.1.1.1.cmml\">&#8203;</mo><msub id=\"S1.T5.3.3.3.m1.1.1.3\" xref=\"S1.T5.3.3.3.m1.1.1.3.cmml\"><mtext id=\"S1.T5.3.3.3.m1.1.1.3.2\" xref=\"S1.T5.3.3.3.m1.1.1.3.2a.cmml\">D</mtext><mn id=\"S1.T5.3.3.3.m1.1.1.3.3\" xref=\"S1.T5.3.3.3.m1.1.1.3.3.cmml\">75</mn></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.3.3.3.m1.1b\"><apply id=\"S1.T5.3.3.3.m1.1.1.cmml\" xref=\"S1.T5.3.3.3.m1.1.1\"><times id=\"S1.T5.3.3.3.m1.1.1.1.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.1\"/><cn type=\"integer\" id=\"S1.T5.3.3.3.m1.1.1.2.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.2\">3</cn><apply id=\"S1.T5.3.3.3.m1.1.1.3.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S1.T5.3.3.3.m1.1.1.3.1.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.3\">subscript</csymbol><ci id=\"S1.T5.3.3.3.m1.1.1.3.2a.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.3.2\"><mtext id=\"S1.T5.3.3.3.m1.1.1.3.2.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.3.2\">D</mtext></ci><cn type=\"integer\" id=\"S1.T5.3.3.3.m1.1.1.3.3.cmml\" xref=\"S1.T5.3.3.3.m1.1.1.3.3\">75</cn></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.3.3.3.m1.1c\">3\\text{D}_{75}</annotation></semantics></math></th>&#13;\n<th id=\"S1.T5.4.4.4\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.4.4.4.m1.1\" class=\"ltx_Math\" alttext=\"5^{\\circ}\\,2\\text{cm}\" display=\"inline\"><semantics id=\"S1.T5.4.4.4.m1.1a\"><mrow id=\"S1.T5.4.4.4.m1.1.1\" xref=\"S1.T5.4.4.4.m1.1.1.cmml\"><msup id=\"S1.T5.4.4.4.m1.1.1.2\" xref=\"S1.T5.4.4.4.m1.1.1.2.cmml\"><mn id=\"S1.T5.4.4.4.m1.1.1.2.2\" xref=\"S1.T5.4.4.4.m1.1.1.2.2.cmml\">5</mn><mo id=\"S1.T5.4.4.4.m1.1.1.2.3\" xref=\"S1.T5.4.4.4.m1.1.1.2.3.cmml\">&#8728;</mo></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.4.4.4.m1.1.1.1\" xref=\"S1.T5.4.4.4.m1.1.1.1.cmml\">&#8203;</mo><mn id=\"S1.T5.4.4.4.m1.1.1.3\" xref=\"S1.T5.4.4.4.m1.1.1.3.cmml\">&#8201;2</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.4.4.4.m1.1.1.1a\" xref=\"S1.T5.4.4.4.m1.1.1.1.cmml\">&#8203;</mo><mtext id=\"S1.T5.4.4.4.m1.1.1.4\" xref=\"S1.T5.4.4.4.m1.1.1.4a.cmml\">cm</mtext></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.4.4.4.m1.1b\"><apply id=\"S1.T5.4.4.4.m1.1.1.cmml\" xref=\"S1.T5.4.4.4.m1.1.1\"><times id=\"S1.T5.4.4.4.m1.1.1.1.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.1\"/><apply id=\"S1.T5.4.4.4.m1.1.1.2.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S1.T5.4.4.4.m1.1.1.2.1.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.2\">superscript</csymbol><cn type=\"integer\" id=\"S1.T5.4.4.4.m1.1.1.2.2.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.2.2\">5</cn><compose id=\"S1.T5.4.4.4.m1.1.1.2.3.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.2.3\"/></apply><cn type=\"integer\" id=\"S1.T5.4.4.4.m1.1.1.3.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.3\">2</cn><ci id=\"S1.T5.4.4.4.m1.1.1.4a.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.4\"><mtext id=\"S1.T5.4.4.4.m1.1.1.4.cmml\" xref=\"S1.T5.4.4.4.m1.1.1.4\">cm</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.4.4.4.m1.1c\">5^{\\circ}\\,2\\text{cm}</annotation></semantics></math></th>&#13;\n<th id=\"S1.T5.5.5.5\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.5.5.5.m1.1\" class=\"ltx_Math\" alttext=\"5^{\\circ}\\,5\\text{cm}\" display=\"inline\"><semantics id=\"S1.T5.5.5.5.m1.1a\"><mrow id=\"S1.T5.5.5.5.m1.1.1\" xref=\"S1.T5.5.5.5.m1.1.1.cmml\"><msup id=\"S1.T5.5.5.5.m1.1.1.2\" xref=\"S1.T5.5.5.5.m1.1.1.2.cmml\"><mn id=\"S1.T5.5.5.5.m1.1.1.2.2\" xref=\"S1.T5.5.5.5.m1.1.1.2.2.cmml\">5</mn><mo id=\"S1.T5.5.5.5.m1.1.1.2.3\" xref=\"S1.T5.5.5.5.m1.1.1.2.3.cmml\">&#8728;</mo></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.5.5.5.m1.1.1.1\" xref=\"S1.T5.5.5.5.m1.1.1.1.cmml\">&#8203;</mo><mn id=\"S1.T5.5.5.5.m1.1.1.3\" xref=\"S1.T5.5.5.5.m1.1.1.3.cmml\">&#8201;5</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.5.5.5.m1.1.1.1a\" xref=\"S1.T5.5.5.5.m1.1.1.1.cmml\">&#8203;</mo><mtext id=\"S1.T5.5.5.5.m1.1.1.4\" xref=\"S1.T5.5.5.5.m1.1.1.4a.cmml\">cm</mtext></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.5.5.5.m1.1b\"><apply id=\"S1.T5.5.5.5.m1.1.1.cmml\" xref=\"S1.T5.5.5.5.m1.1.1\"><times id=\"S1.T5.5.5.5.m1.1.1.1.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.1\"/><apply id=\"S1.T5.5.5.5.m1.1.1.2.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S1.T5.5.5.5.m1.1.1.2.1.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.2\">superscript</csymbol><cn type=\"integer\" id=\"S1.T5.5.5.5.m1.1.1.2.2.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.2.2\">5</cn><compose id=\"S1.T5.5.5.5.m1.1.1.2.3.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.2.3\"/></apply><cn type=\"integer\" id=\"S1.T5.5.5.5.m1.1.1.3.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.3\">5</cn><ci id=\"S1.T5.5.5.5.m1.1.1.4a.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.4\"><mtext id=\"S1.T5.5.5.5.m1.1.1.4.cmml\" xref=\"S1.T5.5.5.5.m1.1.1.4\">cm</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.5.5.5.m1.1c\">5^{\\circ}\\,5\\text{cm}</annotation></semantics></math></th>&#13;\n<th id=\"S1.T5.6.6.6\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.6.6.6.m1.1\" class=\"ltx_Math\" alttext=\"10^{\\circ}\\,2\\text{cm}\" display=\"inline\"><semantics id=\"S1.T5.6.6.6.m1.1a\"><mrow id=\"S1.T5.6.6.6.m1.1.1\" xref=\"S1.T5.6.6.6.m1.1.1.cmml\"><msup id=\"S1.T5.6.6.6.m1.1.1.2\" xref=\"S1.T5.6.6.6.m1.1.1.2.cmml\"><mn id=\"S1.T5.6.6.6.m1.1.1.2.2\" xref=\"S1.T5.6.6.6.m1.1.1.2.2.cmml\">10</mn><mo id=\"S1.T5.6.6.6.m1.1.1.2.3\" xref=\"S1.T5.6.6.6.m1.1.1.2.3.cmml\">&#8728;</mo></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.6.6.6.m1.1.1.1\" xref=\"S1.T5.6.6.6.m1.1.1.1.cmml\">&#8203;</mo><mn id=\"S1.T5.6.6.6.m1.1.1.3\" xref=\"S1.T5.6.6.6.m1.1.1.3.cmml\">&#8201;2</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.6.6.6.m1.1.1.1a\" xref=\"S1.T5.6.6.6.m1.1.1.1.cmml\">&#8203;</mo><mtext id=\"S1.T5.6.6.6.m1.1.1.4\" xref=\"S1.T5.6.6.6.m1.1.1.4a.cmml\">cm</mtext></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.6.6.6.m1.1b\"><apply id=\"S1.T5.6.6.6.m1.1.1.cmml\" xref=\"S1.T5.6.6.6.m1.1.1\"><times id=\"S1.T5.6.6.6.m1.1.1.1.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.1\"/><apply id=\"S1.T5.6.6.6.m1.1.1.2.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S1.T5.6.6.6.m1.1.1.2.1.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.2\">superscript</csymbol><cn type=\"integer\" id=\"S1.T5.6.6.6.m1.1.1.2.2.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.2.2\">10</cn><compose id=\"S1.T5.6.6.6.m1.1.1.2.3.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.2.3\"/></apply><cn type=\"integer\" id=\"S1.T5.6.6.6.m1.1.1.3.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.3\">2</cn><ci id=\"S1.T5.6.6.6.m1.1.1.4a.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.4\"><mtext id=\"S1.T5.6.6.6.m1.1.1.4.cmml\" xref=\"S1.T5.6.6.6.m1.1.1.4\">cm</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.6.6.6.m1.1c\">10^{\\circ}\\,2\\text{cm}</annotation></semantics></math></th>&#13;\n<th id=\"S1.T5.7.7.7\" class=\"ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.7.7.7.m1.1\" class=\"ltx_Math\" alttext=\"10^{\\circ}\\,5\\text{cm}\" display=\"inline\"><semantics id=\"S1.T5.7.7.7.m1.1a\"><mrow id=\"S1.T5.7.7.7.m1.1.1\" xref=\"S1.T5.7.7.7.m1.1.1.cmml\"><msup id=\"S1.T5.7.7.7.m1.1.1.2\" xref=\"S1.T5.7.7.7.m1.1.1.2.cmml\"><mn id=\"S1.T5.7.7.7.m1.1.1.2.2\" xref=\"S1.T5.7.7.7.m1.1.1.2.2.cmml\">10</mn><mo id=\"S1.T5.7.7.7.m1.1.1.2.3\" xref=\"S1.T5.7.7.7.m1.1.1.2.3.cmml\">&#8728;</mo></msup><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.7.7.7.m1.1.1.1\" xref=\"S1.T5.7.7.7.m1.1.1.1.cmml\">&#8203;</mo><mn id=\"S1.T5.7.7.7.m1.1.1.3\" xref=\"S1.T5.7.7.7.m1.1.1.3.cmml\">&#8201;5</mn><mo lspace=\"0em\" rspace=\"0em\" id=\"S1.T5.7.7.7.m1.1.1.1a\" xref=\"S1.T5.7.7.7.m1.1.1.1.cmml\">&#8203;</mo><mtext id=\"S1.T5.7.7.7.m1.1.1.4\" xref=\"S1.T5.7.7.7.m1.1.1.4a.cmml\">cm</mtext></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.7.7.7.m1.1b\"><apply id=\"S1.T5.7.7.7.m1.1.1.cmml\" xref=\"S1.T5.7.7.7.m1.1.1\"><times id=\"S1.T5.7.7.7.m1.1.1.1.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.1\"/><apply id=\"S1.T5.7.7.7.m1.1.1.2.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S1.T5.7.7.7.m1.1.1.2.1.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.2\">superscript</csymbol><cn type=\"integer\" id=\"S1.T5.7.7.7.m1.1.1.2.2.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.2.2\">10</cn><compose id=\"S1.T5.7.7.7.m1.1.1.2.3.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.2.3\"/></apply><cn type=\"integer\" id=\"S1.T5.7.7.7.m1.1.1.3.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.3\">5</cn><ci id=\"S1.T5.7.7.7.m1.1.1.4a.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.4\"><mtext id=\"S1.T5.7.7.7.m1.1.1.4.cmml\" xref=\"S1.T5.7.7.7.m1.1.1.4\">cm</mtext></ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.7.7.7.m1.1c\">10^{\\circ}\\,5\\text{cm}</annotation></semantics></math></th>&#13;\n</tr>&#13;\n</thead>&#13;\n<tbody class=\"ltx_tbody\">&#13;\n<tr id=\"S1.T5.10.12.1\" class=\"ltx_tr\">&#13;\n<th id=\"S1.T5.10.12.1.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Baseline <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib33\" title=\"\" class=\"ltx_ref\">33</a>]</cite>&#13;\n</th>&#13;\n<td id=\"S1.T5.10.12.1.2\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.12.1.2.1\" class=\"ltx_text ltx_font_bold\">84.8</span></td>&#13;\n<td id=\"S1.T5.10.12.1.3\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.12.1.3.1\" class=\"ltx_text ltx_font_bold\">78.0</span></td>&#13;\n<td id=\"S1.T5.10.12.1.4\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">30.1</td>&#13;\n<td id=\"S1.T5.10.12.1.5\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">7.2</td>&#13;\n<td id=\"S1.T5.10.12.1.6\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">10.0</td>&#13;\n<td id=\"S1.T5.10.12.1.7\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13.8</td>&#13;\n<td id=\"S1.T5.10.12.1.8\" class=\"ltx_td ltx_align_center ltx_border_t\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">25.2</td>&#13;\n</tr>&#13;\n<tr id=\"S1.T5.10.10\" class=\"ltx_tr\">&#13;\n<th id=\"S1.T5.10.10.4\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">CASS <cite class=\"ltx_cite ltx_citemacro_cite\">[<a href=\"#bib.bib4\" title=\"\" class=\"ltx_ref\">4</a>]</cite>&#13;\n</th>&#13;\n<td id=\"S1.T5.10.10.5\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">84.2</td>&#13;\n<td id=\"S1.T5.10.10.6\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">77.7</td>&#13;\n<td id=\"S1.T5.8.8.1\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.8.8.1.m1.1\" class=\"ltx_Math\" alttext=\"-\" display=\"inline\"><semantics id=\"S1.T5.8.8.1.m1.1a\"><mo id=\"S1.T5.8.8.1.m1.1.1\" xref=\"S1.T5.8.8.1.m1.1.1.cmml\">&#8722;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.8.8.1.m1.1b\"><minus id=\"S1.T5.8.8.1.m1.1.1.cmml\" xref=\"S1.T5.8.8.1.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.8.8.1.m1.1c\">-</annotation></semantics></math></td>&#13;\n<td id=\"S1.T5.9.9.2\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.9.9.2.m1.1\" class=\"ltx_Math\" alttext=\"-\" display=\"inline\"><semantics id=\"S1.T5.9.9.2.m1.1a\"><mo id=\"S1.T5.9.9.2.m1.1.1\" xref=\"S1.T5.9.9.2.m1.1.1.cmml\">&#8722;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.9.9.2.m1.1b\"><minus id=\"S1.T5.9.9.2.m1.1.1.cmml\" xref=\"S1.T5.9.9.2.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.9.9.2.m1.1c\">-</annotation></semantics></math></td>&#13;\n<td id=\"S1.T5.10.10.7\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">13.0</td>&#13;\n<td id=\"S1.T5.10.10.3\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><math id=\"S1.T5.10.10.3.m1.1\" class=\"ltx_Math\" alttext=\"-\" display=\"inline\"><semantics id=\"S1.T5.10.10.3.m1.1a\"><mo id=\"S1.T5.10.10.3.m1.1.1\" xref=\"S1.T5.10.10.3.m1.1.1.cmml\">&#8722;</mo><annotation-xml encoding=\"MathML-Content\" id=\"S1.T5.10.10.3.m1.1b\"><minus id=\"S1.T5.10.10.3.m1.1.1.cmml\" xref=\"S1.T5.10.10.3.m1.1.1\"/></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S1.T5.10.10.3.m1.1c\">-</annotation></semantics></math></td>&#13;\n<td id=\"S1.T5.10.10.8\" class=\"ltx_td ltx_align_center\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">37.6</td>&#13;\n</tr>&#13;\n<tr id=\"S1.T5.10.13.2\" class=\"ltx_tr\">&#13;\n<th id=\"S1.T5.10.13.2.1\" class=\"ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">Ours</th>&#13;\n<td id=\"S1.T5.10.13.2.2\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">83.4</td>&#13;\n<td id=\"S1.T5.10.13.2.3\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\">77.3</td>&#13;\n<td id=\"S1.T5.10.13.2.4\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.13.2.4.1\" class=\"ltx_text ltx_font_bold\">53.2</span></td>&#13;\n<td id=\"S1.T5.10.13.2.5\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.13.2.5.1\" class=\"ltx_text ltx_font_bold\">19.3</span></td>&#13;\n<td id=\"S1.T5.10.13.2.6\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.13.2.6.1\" class=\"ltx_text ltx_font_bold\">21.4</span></td>&#13;\n<td id=\"S1.T5.10.13.2.7\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.13.2.7.1\" class=\"ltx_text ltx_font_bold\">43.2</span></td>&#13;\n<td id=\"S1.T5.10.13.2.8\" class=\"ltx_td ltx_align_center ltx_border_bb\" style=\"padding-left:4.0pt;padding-right:4.0pt;\"><span id=\"S1.T5.10.13.2.8.1\" class=\"ltx_text ltx_font_bold\">54.1</span></td>&#13;\n</tr>&#13;\n</tbody>&#13;\n</table>&#13;\n\n"
        ],
        "footnotes": [
            "[33] [33]\r\n\r\nWang, H., Sridhar, S., Huang, J., Valentin, J., Song, S., Guibas, L.J.:\r\nNormalized object coordinate space for category-level 6d object pose and size\r\nestimation. In: Proceedings of the IEEE Conference on Computer Vision and\r\nPattern Recognition. pp. 2642â€“2651 (2019)",
            "[4] [4]\r\n\r\nChen, D., Li, J., Wang, Z., Xu, K.: Learning canonical shape space for\r\ncategory-level 6d object pose and size estimation. In: Proceedings of the\r\nIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (June\r\n2020)"
        ],
        "references": [
            "CASS [4] is the latest work on category-level 6D object pose and size estimation.\r\nSimilar to our work, they reconstruct the complete object model in the canonical space as a by-product.\r\nHowever, they train a variational autoencoder to generate the point cloud, while we estimate the deformation field of the corresponding shape prior.\r\nIn addition, they directly regresses the pose and size by comparing pose-independent and pose-dependent features, while we recover the pose by establishing dense correspondences.\r\nAs shown in Table 5, our approach significantly outperforms CASS in pose accuracy. This demonstrates the superiority of our correspondence-based approach over direct pose regression."
        ]
    }
}