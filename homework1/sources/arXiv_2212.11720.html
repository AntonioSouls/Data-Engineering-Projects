<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.11720] GOOD: Exploring Geometric Cues for Detecting Objects in an Open World</title><meta property="og:description" content="We address the task of open-world class-agnostic object detection, i.e., detecting every object in an image by learning from a limited number of base object classes. State-of-the-art RGB-based models suffer from overfiâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GOOD: Exploring Geometric Cues for Detecting Objects in an Open World">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="GOOD: Exploring Geometric Cues for Detecting Objects in an Open World">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.11720">

<!--Generated on Fri Mar  1 09:46:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">GOOD: Exploring Geometric Cues for Detecting Objects in an Open World</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haiwen Huang<sup id="id8.8.id1" class="ltx_sup"><span id="id8.8.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup> â€„ Andreas Geiger<sup id="id9.9.id2" class="ltx_sup"><span id="id9.9.id2.1" class="ltx_text ltx_font_italic">2,3</span></sup> â€„ Dan Zhang<sup id="id10.10.id3" class="ltx_sup"><span id="id10.10.id3.1" class="ltx_text ltx_font_italic">1,4</span></sup> 
<br class="ltx_break"><sup id="id11.11.id4" class="ltx_sup"><span id="id11.11.id4.1" class="ltx_text ltx_font_italic">1</span></sup>Bosch Industry on Campus Lab, University of TÃ¼bingen
<br class="ltx_break"><sup id="id12.12.id5" class="ltx_sup"><span id="id12.12.id5.1" class="ltx_text ltx_font_italic">2</span></sup>Autonomous Vision Group, University of TÃ¼bingen
<br class="ltx_break"><sup id="id13.13.id6" class="ltx_sup"><span id="id13.13.id6.1" class="ltx_text ltx_font_italic">3</span></sup>Max Planck Institute for Intelligent Systems, TÃ¼bingen â€„
<sup id="id14.14.id7" class="ltx_sup"><span id="id14.14.id7.1" class="ltx_text ltx_font_italic">4</span></sup>Bosch Center for Artificial Intelligence
<br class="ltx_break"><span id="id15.15.id8" class="ltx_text ltx_font_typewriter">{haiwen.huang, a.geiger}@uni-tuebingen.de, Dan.Zhang2@de.bosch.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.id1" class="ltx_p">We address the task of open-world class-agnostic object detection, i.e., detecting every object in an image by learning from a limited number of base object classes. State-of-the-art RGB-based models suffer from overfitting the training classes and often fail at detecting novel-looking objects. This is because RGB-based models primarily rely on appearance similarity to detect novel objects and are also prone to overfitting short-cut cues such as textures and discriminative parts.
To address these shortcomings of RGB-based object detectors, we propose incorporating geometric cues such as depth and normals, predicted by general-purpose monocular estimators.
Specifically, we use the geometric cues to train an object proposal network for pseudo-labeling unannotated novel objects in the training set.
Our resulting Geometry-guided Open-world Object Detector (GOOD) significantly improves detection recall for novel object categories and already performs well with only a few training classes.
Using a single â€œpersonâ€ class for training on the COCO dataset, GOOD surpasses SOTA methods by 5.0% AR@100, a relative improvement of 24%.</p>
</div>
<figure id="S0.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/gt/ADE_val_00000669_numbox_20.jpg" id="S0.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="361" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth (20)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/oln/ADE_val_00000669_gtnum20_tpnum13_vis_num13.jpg" id="S0.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>OLN (13)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/ggn/ADE_val_00000669_gtnum20_tpnum14_vis_num14.jpg" id="S0.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>GGN (14)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/midow/ADE_val_00000669_gtnum20_tpnum18_vis_num18.jpg" id="S0.F1.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>GOOD (18)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/gt/ADE_val_00001463_numbox_22.jpg" id="S0.F1.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="361" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Ground truth (22)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/oln/ADE_val_00001463_gtnum22_tpnum6_vis_num6.jpg" id="S0.F1.sf6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="364" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>OLN (6)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/ggn/ADE_val_00001463_gtnum22_tpnum6_vis_num6.jpg" id="S0.F1.sf7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="364" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(g) </span>GGN (6)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/midow/ADE_val_00001463_gtnum22_tpnum15_vis_num15.jpg" id="S0.F1.sf8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="364" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(h) </span>GOOD (15)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S0.F1.2.1" class="ltx_text ltx_font_bold">Comparison of GOOD with different baselines.</span> Images in the first column are from validation sets of ADE20KÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al., <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite>. From the second to fourth columns we show the detection results of three open-world object detection methods: OLNÂ <cite class="ltx_cite ltx_citemacro_cite">Kim etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>, GGNÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>, and our Geometry-guided Open-world Object Detector (GOOD). The shown detection results are true-positive proposals from the top 100 proposals of each method. The numbers of true positive proposals or ground truth objects are denoted in parentheses. All models are trained on the RGB images from the PASCAL-VOC classes of the COCO datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>, which do not include houses, trees, or kitchen furniture. Both OLN and GGN fail to detect many objects not seen during training. GOOD generalizes better to unseen categories by exploiting the geometric cues.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">The standard object detection task is to detect objects from a predefined class list. However, when deploying the model in the real world, it is rarely the case that the model will only encounter objects from its predefined taxonomy. In the open-world setup, object detectors are required to detect all the objects in the scene even though they have only been trained on objects from a limited number of classes.
Current state-of-the-art object detectors typically struggle in the open-world setup. As a consequence, open-world object detection has gained increased attention over the last few yearsÂ <cite class="ltx_cite ltx_citemacro_citep">(Jaiswal etÂ al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Joseph etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2021</a>; Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>.
In this work, we specifically address the task of open-world class-agnostic object detection, which is a fundamental task for downstream applications like open-world multi-object trackingÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al., <a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite>, roboticsÂ <cite class="ltx_cite ltx_citemacro_citep">(Jiang etÂ al., <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite>, and autonomous AI agentsÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al., <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">One reason for the failure of current object detectors in the open-world setting is that during training, they are penalized for detecting unlabeled objects in the background and are thus discouraged from detecting them.
Motivated by this, previous works have designed different architecturesÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Konan etÂ al., <a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> and training pipelinesÂ <cite class="ltx_cite ltx_citemacro_citep">(Saito etÂ al., <a href="#bib.bib34" title="" class="ltx_ref">2021</a>; Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> to avoid suppressing the unannotated objects in the background, which have led to significant performance improvements. However, these methods still suffer from overfitting the training classes.
Training only on RGB images, they mainly rely on appearance cues to detect objects of new categories and have great difficulty generalizing to novel-looking objects.
Also, there are known short-cut learning problems with regard to training on RGB imagesÂ <cite class="ltx_cite ltx_citemacro_cite">Geirhos etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>; <a href="#bib.bib13" title="" class="ltx_ref">2020</a>); Sauer &amp; Geiger (<a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite> â€“ there is no constraint for overfitting the textures or the discriminative parts of the known classes during training.
In this work, we propose to tackle this challenge by incorporating geometry cues extracted by general-purpose monocular estimators from the RGB images. We show that such cues significantly improve detection recall for novel object categories on challenging benchmarks.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Estimating geometric cues such as depth and normals from a single RGB image has been an active research area for a long time.
Such mid-level representations possess built-in invariance to many changes (e.g., brightness, color) and are more class-agnostic than RGB signals, see FigureÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In other words, there is less discrepancy between known and unknown objects in terms of geometric cues.
In recent years, thanks to stronger architectures and larger datasetsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ranftl etÂ al., <a href="#bib.bib31" title="" class="ltx_ref">2021b</a>; <a href="#bib.bib32" title="" class="ltx_ref">2022</a>; Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>, monocular estimators for mid-level representations have significantly advanced in terms of prediction quality and generalization to novel scenes. These models are able to compute high-quality geometric cues efficiently when used off-the-shelf as pre-trained models on new datasets. Therefore, it becomes natural to ask if these models can provide additional knowledge for current RGB-based open-world object detectors to overcome the generalization problem.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<div id="S1.F2.7" class="ltx_block ltx_parbox ltx_align_center ltx_align_middle" style="width:397.5pt;">
<div id="S1.F2.2.2" class="ltx_block ltx_parbox ltx_align_bottom" style="width:79.5pt;">
<img src="/html/2212.11720/assets/iclr2023/figures/fig2/000000159791.jpg" id="S1.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption"><img src="/html/2212.11720/assets/iclr2023/figures/fig2/000000005802.jpg" id="S1.F2.2.2.g2" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
</div>
<div id="S1.F2.4.4" class="ltx_block ltx_parbox ltx_align_bottom" style="width:79.5pt;">
<img src="/html/2212.11720/assets/iclr2023/figures/fig2/depth000000159791.jpg" id="S1.F2.3.3.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption"><img src="/html/2212.11720/assets/iclr2023/figures/fig2/depth000000005802.jpg" id="S1.F2.4.4.g2" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
</div>
<div id="S1.F2.6.6" class="ltx_block ltx_parbox ltx_align_bottom" style="width:79.5pt;">
<img src="/html/2212.11720/assets/iclr2023/figures/fig2/normal000000159791.jpg" id="S1.F2.5.5.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption"><img src="/html/2212.11720/assets/iclr2023/figures/fig2/normal000000005802.jpg" id="S1.F2.6.6.g2" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
</div>
<div id="S1.F2.7.7" class="ltx_block ltx_parbox ltx_align_bottom" style="width:159.0pt;">
<img src="/html/2212.11720/assets/x1.png" id="S1.F2.7.7.g1" class="ltx_graphics ltx_img_landscape" width="165" height="128" alt="Refer to caption">
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S1.F2.11.1" class="ltx_text ltx_font_bold">Geometry cues are complementary to appearance cues for object localization.</span> The depth and normal cues of the RGB image are extracted using off-the-shelf general-purpose monocular predictors. <span id="S1.F2.12.2" class="ltx_text ltx_font_bold">Left:</span>
Geometric cues abstract away the appearance details and focus on more holistic information such as object shapes and relative spatial locations (depth) and directional changes (normals).
<span id="S1.F2.13.3" class="ltx_text ltx_font_bold">Right:</span>
By incorporating geometric cues, GOODs generalize better than the RGB-based model OLNÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>, i.e., much smaller AR gaps between the base and novel classes.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose to use a pseudo-labeling method for incorporating geometric cues into open-world object detector training.
We first train an object proposal network on the predicted depth or normal maps to discover novel unannotated objects in the training set. The top-ranked novel object predictions are used as pseudo boxes for training the open-world object detector on the original RGB input. We observe that incorporating the geometry cues can significantly improve the detection recall of unseen objects, especially those that differ strongly from the training objects, as shown in FigureÂ <a href="#S0.F1" title="Figure 1 â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> andÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We speculate that this is due to the complementary nature of geometry cues and the RGB-based detection cues: the geometry cues help discover novel-looking objects that RGB-based detectors cannot detect, and the RGB-based detectors can make use of more annotations with their strong representation learning ability to generalize to novel, unseen categories.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">Our resulting Geometry-guided Open-world Object Detector (GOOD) surpasses the state-of-the-art performance on multiple benchmarks for open-world class-agnostic object detection.
Thanks to the rich geometry information, GOOD can generalize to unseen categories with only a few known classes for training.
Particularly, with a single training class â€œpersonâ€ on the COCO datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>, GOOD can surpass SOTA methods by 5.0% AR@100 (a relative improvement of 24%) on detecting objects from non-person classes. With 20 PASCAL-VOC classes for training, GOOD surpasses SOTA methods even by 6.1% AR@100 in detecting non-VOC classes.
Furthermore, we also analyze the advantages of geometric cues and show that they are less sensitive to semantic shifts across classes, and are better than other strategies for improving generalization.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Open-world class-agnostic object detection</span> is the task of localizing all the objects in an image by learning with only a limited number of object classes (base classes).
The core problem with standard object detection training is that the model is trained to classify the unannotated objects as background and thus is suppressed to detect them at inference time.
To solve this issue, <cite class="ltx_cite ltx_citemacro_citet">Kim etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> proposed object localization network (OLN), which replaces the classification heads of Faster RCNNÂ <cite class="ltx_cite ltx_citemacro_citep">(Ren etÂ al., <a href="#bib.bib33" title="" class="ltx_ref">2015</a>)</cite> with class-agnostic objectness heads so that the training loss is only calculated on positive samples, i.e., known objects, and thus not suppressing the detection of unannotated novel objects.
<cite class="ltx_cite ltx_citemacro_citet">Saito etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite> synthesized a training set by copy-pasting known objects onto synthetic backgrounds. However, the model struggles with the synthetic-to-real domain gap in solving the object detection task.
Besides background non-suppression, a more proactive approach is to exploit unannotated objects for training.Â <cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> built upon traditional learning-free methods and developed a pairwise affinity predictor to discover unannotated objects. Their object detector, GGN, is then trained using the newly-discovered object masks and ground truth base class annotations as supervision.
Finally, another promising direction is to use open-world knowledge from large pretrained multi-modal models. Recently,Â <cite class="ltx_cite ltx_citemacro_citet">Minderer etÂ al. (<a href="#bib.bib28" title="" class="ltx_ref">2022</a>); Maaz etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite> made use of pretrained language-vision modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite> to detect open-world objects using text queries. Our work is most related to OLN and GGN. We used the OLN architecture and training loss, but additionally incorporated geometry cues through our pseudo-labeling method. GGN used the pairwise affinity for pseudo labeling. However, since the pairwise affinity is trained on RGB inputs using the base class annotations, GGN still suffers from the overfitting problems of RGB-based methods. Our experiments showed geometric cues as a better source of pseudo boxes.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Incorporating geometric cues for generalization.</span>
The estimation of geometric cues has been an active research area for decades.
With the introduction of deep neural networks, the seminal work byÂ <cite class="ltx_cite ltx_citemacro_citet">Eigen etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2014</a>); Eigen &amp; Fergus (<a href="#bib.bib9" title="" class="ltx_ref">2015</a>)</cite> significantly improved over early worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Hoiem etÂ al., <a href="#bib.bib14" title="" class="ltx_ref">2005a</a>; <a href="#bib.bib15" title="" class="ltx_ref">b</a>; <a href="#bib.bib16" title="" class="ltx_ref">2007</a>; <a href="#bib.bib17" title="" class="ltx_ref">2008</a>; Saxena etÂ al., <a href="#bib.bib36" title="" class="ltx_ref">2005</a>; <a href="#bib.bib37" title="" class="ltx_ref">2008a</a>; <a href="#bib.bib38" title="" class="ltx_ref">2008b</a>)</cite>. Recent progress in estimating geometric cues can be attributed to the use of modern architecturesÂ <cite class="ltx_cite ltx_citemacro_citep">(Ranftl etÂ al., <a href="#bib.bib32" title="" class="ltx_ref">2022</a>)</cite>, stronger training strategiesÂ <cite class="ltx_cite ltx_citemacro_citep">(Zamir etÂ al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> and large-scale datasetsÂ <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>.
In particular, OmnidataÂ <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> has made significant headway in prediction quality and cross-dataset generalization.
Since geometric cues abstract away the appearance details and retain more holistic information about the objects, such as shapes, they have been incorporated into many applications for generalization.
For example, <cite class="ltx_cite ltx_citemacro_citet">Xiang etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite> incorporated them into the 3D shape completion pipeline to generalize to novel classes. <cite class="ltx_cite ltx_citemacro_citet">Yu etÂ al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> used them to guide the optimization of neural implicit surface models for tackling scenes captured from sparse viewpoints. <cite class="ltx_cite ltx_citemacro_citet">Chen etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> applied mid-level visual representations to reinforcement training and gained robustness under domain shifts.
In this work, we propose to incorporate geometric cues through pseudo-labeling and also demonstrate large performance gains on open-world class-agnostic object detection benchmarks.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2212.11720/assets/x2.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S2.F3.2.1" class="ltx_text ltx_font_bold">Overview of the geometry-guided pseudo labeling method.</span> It consists of two training phases. Phase I: the RGB input is firstly preprocessed by the off-the-shelf model to extract the geometry cues, which are then used to train an object proposal network with the base class bounding box annotations. The proposal networks then pseudo-label the training samples, discovering unannotated novel objects. The top-ranked pseudo boxes are added to the annotation pool for Phase II training, i.e., a class-agnostic object detector is directly trained on the RGB input using both the base class and pseudo annotations. At inference time, we only need the model from Phase II.
</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">Our goal is to incorporate geometric cues for an improved open-world class-agnostic object detection performance. Concretely, we propose a pseudo labeling method, which can effectively utilize the geometric cues to detect unannotated novel objects in the training set and then use them for training the object detector. See the overview of our method in FigureÂ <a href="#S2.F3" title="Figure 3 â€£ 2 Related work â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>open-world class-agnostic object detection problem</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.3" class="ltx_p">Current state-of-the-art object detection methods work well under the closed-world assumption. They are trained with a set of object bounding box annotations <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\{t_{i}\}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">{</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.2.cmml">t</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p1.1.m1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><set id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1"><apply id="S3.SS1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\{t_{i}\}</annotation></semantics></math> from a pre-specified list <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{K}</annotation></semantics></math> of semantic classes, i.e., the base classes. At test time, their generalization is evaluated by detecting the objects from the known base classes. The standard training loss of object detection for an image <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">â„</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathcal{I}</annotation></semantics></math> has two parts: classification loss and bounding box regression loss</p>
<table id="A5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\displaystyle\mathcal{L}(\mathcal{I})=\dfrac{1}{N_{cls}}\sum_{i\in\mathcal{B}}\mathcal{L}_{cls}(p_{i},p_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})," display="inline"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.6" xref="S3.E1.m1.2.2.1.1.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.6.2" xref="S3.E1.m1.2.2.1.1.6.2.cmml">â„’</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.6.1" xref="S3.E1.m1.2.2.1.1.6.1.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.6.3.2" xref="S3.E1.m1.2.2.1.1.6.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.6.3.2.1" xref="S3.E1.m1.2.2.1.1.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">â„</mi><mo stretchy="false" id="S3.E1.m1.2.2.1.1.6.3.2.2" xref="S3.E1.m1.2.2.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.5" xref="S3.E1.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.4" xref="S3.E1.m1.2.2.1.1.4.cmml"><mrow id="S3.E1.m1.2.2.1.1.2.2" xref="S3.E1.m1.2.2.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.2.2.4" xref="S3.E1.m1.2.2.1.1.2.2.4.cmml"><mfrac id="S3.E1.m1.2.2.1.1.2.2.4a" xref="S3.E1.m1.2.2.1.1.2.2.4.cmml"><mn id="S3.E1.m1.2.2.1.1.2.2.4.2" xref="S3.E1.m1.2.2.1.1.2.2.4.2.cmml">1</mn><msub id="S3.E1.m1.2.2.1.1.2.2.4.3" xref="S3.E1.m1.2.2.1.1.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.2" xref="S3.E1.m1.2.2.1.1.2.2.4.3.2.cmml">N</mi><mrow id="S3.E1.m1.2.2.1.1.2.2.4.3.3" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.3.2" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.4.3.3.1" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.3.3" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.4.3.3.1a" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.3.4" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.4.cmml">s</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.cmml"><munder id="S3.E1.m1.2.2.1.1.2.2.2.3a" xref="S3.E1.m1.2.2.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E1.m1.2.2.1.1.2.2.2.3.2" xref="S3.E1.m1.2.2.1.1.2.2.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.2.2.1.1.2.2.2.3.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.3.3.2" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.2.2.2.3.3.1" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.2.2.3.3.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.3.cmml">â„¬</mi></mrow></munder></mstyle><mrow id="S3.E1.m1.2.2.1.1.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E1.m1.2.2.1.1.2.2.2.2.4" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.2.cmml">â„’</mi><mrow id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1a" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4.cmml">s</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.4.5" xref="S3.E1.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S3.E1.m1.2.2.1.1.4.4" xref="S3.E1.m1.2.2.1.1.4.4.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.4.4.4" xref="S3.E1.m1.2.2.1.1.4.4.4.cmml"><mfrac id="S3.E1.m1.2.2.1.1.4.4.4a" xref="S3.E1.m1.2.2.1.1.4.4.4.cmml"><mn id="S3.E1.m1.2.2.1.1.4.4.4.2" xref="S3.E1.m1.2.2.1.1.4.4.4.2.cmml">1</mn><msub id="S3.E1.m1.2.2.1.1.4.4.4.3" xref="S3.E1.m1.2.2.1.1.4.4.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.2" xref="S3.E1.m1.2.2.1.1.4.4.4.3.2.cmml">N</mi><mrow id="S3.E1.m1.2.2.1.1.4.4.4.3.3" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.3.2" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.4.3.3.1" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.3.3" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.4.3.3.1a" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.3.4" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.3" xref="S3.E1.m1.2.2.1.1.4.4.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.4.4.2" xref="S3.E1.m1.2.2.1.1.4.4.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.4.4.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.cmml"><munder id="S3.E1.m1.2.2.1.1.4.4.2.3a" xref="S3.E1.m1.2.2.1.1.4.4.2.3.cmml"><mo movablelimits="false" id="S3.E1.m1.2.2.1.1.4.4.2.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E1.m1.2.2.1.1.4.4.2.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.2.3.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.4.4.2.3.3.1" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.1.cmml">âˆˆ</mo><msub id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3.cmml">ğ’¦</mi></msub></mrow></munder></mstyle><mrow id="S3.E1.m1.2.2.1.1.4.4.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.cmml"><msub id="S3.E1.m1.2.2.1.1.4.4.2.2.4" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.2.cmml">â„’</mi><mrow id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1a" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.4" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.5" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.5.cmml" xref="S3.E1.m1.2.2.1.1.5"></eq><apply id="S3.E1.m1.2.2.1.1.6.cmml" xref="S3.E1.m1.2.2.1.1.6"><times id="S3.E1.m1.2.2.1.1.6.1.cmml" xref="S3.E1.m1.2.2.1.1.6.1"></times><ci id="S3.E1.m1.2.2.1.1.6.2.cmml" xref="S3.E1.m1.2.2.1.1.6.2">â„’</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">â„</ci></apply><apply id="S3.E1.m1.2.2.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.4"><plus id="S3.E1.m1.2.2.1.1.4.5.cmml" xref="S3.E1.m1.2.2.1.1.4.5"></plus><apply id="S3.E1.m1.2.2.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2"><times id="S3.E1.m1.2.2.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.3"></times><apply id="S3.E1.m1.2.2.1.1.2.2.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4"><divide id="S3.E1.m1.2.2.1.1.2.2.4.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4"></divide><cn type="integer" id="S3.E1.m1.2.2.1.1.2.2.4.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.2">1</cn><apply id="S3.E1.m1.2.2.1.1.2.2.4.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.2">ğ‘</ci><apply id="S3.E1.m1.2.2.1.1.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3"><times id="S3.E1.m1.2.2.1.1.2.2.4.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.1"></times><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.2">ğ‘</ci><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.3">ğ‘™</ci><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.3.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.4">ğ‘ </ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2"><apply id="S3.E1.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E1.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.2"></sum><apply id="S3.E1.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3"><in id="S3.E1.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.1"></in><ci id="S3.E1.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.2">ğ‘–</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.3">â„¬</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2"><times id="S3.E1.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.3"></times><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.2">â„’</ci><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3"><times id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1"></times><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2">ğ‘</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3">ğ‘™</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4">ğ‘ </ci></apply></apply><interval closure="open" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.4.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4"><times id="S3.E1.m1.2.2.1.1.4.4.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.3"></times><apply id="S3.E1.m1.2.2.1.1.4.4.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4"><divide id="S3.E1.m1.2.2.1.1.4.4.4.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4"></divide><cn type="integer" id="S3.E1.m1.2.2.1.1.4.4.4.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.2">1</cn><apply id="S3.E1.m1.2.2.1.1.4.4.4.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.2">ğ‘</ci><apply id="S3.E1.m1.2.2.1.1.4.4.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3"><times id="S3.E1.m1.2.2.1.1.4.4.4.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.1"></times><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.2">ğ‘Ÿ</ci><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.3">ğ‘’</ci><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.3.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.4">ğ‘”</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.4.4.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2"><apply id="S3.E1.m1.2.2.1.1.4.4.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3">subscript</csymbol><sum id="S3.E1.m1.2.2.1.1.4.4.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.2"></sum><apply id="S3.E1.m1.2.2.1.1.4.4.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3"><in id="S3.E1.m1.2.2.1.1.4.4.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.1"></in><ci id="S3.E1.m1.2.2.1.1.4.4.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.2">ğ‘–</ci><apply id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2">â„¬</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3">ğ’¦</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2"><times id="S3.E1.m1.2.2.1.1.4.4.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.3"></times><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.2">â„’</ci><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3"><times id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1"></times><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2">ğ‘Ÿ</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3">ğ‘’</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4">ğ‘”</ci></apply></apply><interval closure="open" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2"><apply id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2">ğ‘¡</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\displaystyle\mathcal{L}(\mathcal{I})=\dfrac{1}{N_{cls}}\sum_{i\in\mathcal{B}}\mathcal{L}_{cls}(p_{i},p_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.17" class="ltx_p">where <math id="S3.SS1.p1.4.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p1.4.m1.1a"><mi id="S3.SS1.p1.4.m1.1.1" xref="S3.SS1.p1.4.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m1.1b"><ci id="S3.SS1.p1.4.m1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m1.1c">i</annotation></semantics></math> is the index of an anchor from the candidate set <math id="S3.SS1.p1.5.m2.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p1.5.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.5.m2.1.1" xref="S3.SS1.p1.5.m2.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m2.1b"><ci id="S3.SS1.p1.5.m2.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m2.1c">\mathcal{B}</annotation></semantics></math>, <math id="S3.SS1.p1.6.m3.2" class="ltx_Math" alttext="\{p_{i},t_{i}\}" display="inline"><semantics id="S3.SS1.p1.6.m3.2a"><mrow id="S3.SS1.p1.6.m3.2.2.2" xref="S3.SS1.p1.6.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.6.m3.2.2.2.3" xref="S3.SS1.p1.6.m3.2.2.3.cmml">{</mo><msub id="S3.SS1.p1.6.m3.1.1.1.1" xref="S3.SS1.p1.6.m3.1.1.1.1.cmml"><mi id="S3.SS1.p1.6.m3.1.1.1.1.2" xref="S3.SS1.p1.6.m3.1.1.1.1.2.cmml">p</mi><mi id="S3.SS1.p1.6.m3.1.1.1.1.3" xref="S3.SS1.p1.6.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p1.6.m3.2.2.2.4" xref="S3.SS1.p1.6.m3.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.6.m3.2.2.2.2" xref="S3.SS1.p1.6.m3.2.2.2.2.cmml"><mi id="S3.SS1.p1.6.m3.2.2.2.2.2" xref="S3.SS1.p1.6.m3.2.2.2.2.2.cmml">t</mi><mi id="S3.SS1.p1.6.m3.2.2.2.2.3" xref="S3.SS1.p1.6.m3.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p1.6.m3.2.2.2.5" xref="S3.SS1.p1.6.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m3.2b"><set id="S3.SS1.p1.6.m3.2.2.3.cmml" xref="S3.SS1.p1.6.m3.2.2.2"><apply id="S3.SS1.p1.6.m3.1.1.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m3.1.1.1.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m3.1.1.1.1.2.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1.2">ğ‘</ci><ci id="S3.SS1.p1.6.m3.1.1.1.1.3.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS1.p1.6.m3.2.2.2.2.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m3.2.2.2.2.1.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.6.m3.2.2.2.2.2.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2.2">ğ‘¡</ci><ci id="S3.SS1.p1.6.m3.2.2.2.2.3.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2.3">ğ‘–</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m3.2c">\{p_{i},t_{i}\}</annotation></semantics></math> are the predicted label and bounding box coordinates, and <math id="S3.SS1.p1.7.m4.2" class="ltx_Math" alttext="\{p_{i}^{*},t_{i}^{*}\}" display="inline"><semantics id="S3.SS1.p1.7.m4.2a"><mrow id="S3.SS1.p1.7.m4.2.2.2" xref="S3.SS1.p1.7.m4.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.7.m4.2.2.2.3" xref="S3.SS1.p1.7.m4.2.2.3.cmml">{</mo><msubsup id="S3.SS1.p1.7.m4.1.1.1.1" xref="S3.SS1.p1.7.m4.1.1.1.1.cmml"><mi id="S3.SS1.p1.7.m4.1.1.1.1.2.2" xref="S3.SS1.p1.7.m4.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p1.7.m4.1.1.1.1.2.3" xref="S3.SS1.p1.7.m4.1.1.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p1.7.m4.1.1.1.1.3" xref="S3.SS1.p1.7.m4.1.1.1.1.3.cmml">âˆ—</mo></msubsup><mo id="S3.SS1.p1.7.m4.2.2.2.4" xref="S3.SS1.p1.7.m4.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p1.7.m4.2.2.2.2" xref="S3.SS1.p1.7.m4.2.2.2.2.cmml"><mi id="S3.SS1.p1.7.m4.2.2.2.2.2.2" xref="S3.SS1.p1.7.m4.2.2.2.2.2.2.cmml">t</mi><mi id="S3.SS1.p1.7.m4.2.2.2.2.2.3" xref="S3.SS1.p1.7.m4.2.2.2.2.2.3.cmml">i</mi><mo id="S3.SS1.p1.7.m4.2.2.2.2.3" xref="S3.SS1.p1.7.m4.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.SS1.p1.7.m4.2.2.2.5" xref="S3.SS1.p1.7.m4.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m4.2b"><set id="S3.SS1.p1.7.m4.2.2.3.cmml" xref="S3.SS1.p1.7.m4.2.2.2"><apply id="S3.SS1.p1.7.m4.1.1.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.7.m4.1.1.1.1.2.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m4.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p1.7.m4.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1.2.3">ğ‘–</ci></apply><times id="S3.SS1.p1.7.m4.1.1.1.1.3.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1.3"></times></apply><apply id="S3.SS1.p1.7.m4.2.2.2.2.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p1.7.m4.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.7.m4.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2.2.2">ğ‘¡</ci><ci id="S3.SS1.p1.7.m4.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.SS1.p1.7.m4.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2.3"></times></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m4.2c">\{p_{i}^{*},t_{i}^{*}\}</annotation></semantics></math> are the corresponding ground truths. <math id="S3.SS1.p1.8.m5.1" class="ltx_Math" alttext="N_{cls}" display="inline"><semantics id="S3.SS1.p1.8.m5.1a"><msub id="S3.SS1.p1.8.m5.1.1" xref="S3.SS1.p1.8.m5.1.1.cmml"><mi id="S3.SS1.p1.8.m5.1.1.2" xref="S3.SS1.p1.8.m5.1.1.2.cmml">N</mi><mrow id="S3.SS1.p1.8.m5.1.1.3" xref="S3.SS1.p1.8.m5.1.1.3.cmml"><mi id="S3.SS1.p1.8.m5.1.1.3.2" xref="S3.SS1.p1.8.m5.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.8.m5.1.1.3.1" xref="S3.SS1.p1.8.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p1.8.m5.1.1.3.3" xref="S3.SS1.p1.8.m5.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.8.m5.1.1.3.1a" xref="S3.SS1.p1.8.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p1.8.m5.1.1.3.4" xref="S3.SS1.p1.8.m5.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m5.1b"><apply id="S3.SS1.p1.8.m5.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m5.1.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m5.1.1.2.cmml" xref="S3.SS1.p1.8.m5.1.1.2">ğ‘</ci><apply id="S3.SS1.p1.8.m5.1.1.3.cmml" xref="S3.SS1.p1.8.m5.1.1.3"><times id="S3.SS1.p1.8.m5.1.1.3.1.cmml" xref="S3.SS1.p1.8.m5.1.1.3.1"></times><ci id="S3.SS1.p1.8.m5.1.1.3.2.cmml" xref="S3.SS1.p1.8.m5.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p1.8.m5.1.1.3.3.cmml" xref="S3.SS1.p1.8.m5.1.1.3.3">ğ‘™</ci><ci id="S3.SS1.p1.8.m5.1.1.3.4.cmml" xref="S3.SS1.p1.8.m5.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m5.1c">N_{cls}</annotation></semantics></math> is the total number of anchors in the candidate set <math id="S3.SS1.p1.9.m6.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p1.9.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.9.m6.1.1" xref="S3.SS1.p1.9.m6.1.1.cmml">â„¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m6.1b"><ci id="S3.SS1.p1.9.m6.1.1.cmml" xref="S3.SS1.p1.9.m6.1.1">â„¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m6.1c">\mathcal{B}</annotation></semantics></math>. <math id="S3.SS1.p1.10.m7.1" class="ltx_Math" alttext="N_{reg}" display="inline"><semantics id="S3.SS1.p1.10.m7.1a"><msub id="S3.SS1.p1.10.m7.1.1" xref="S3.SS1.p1.10.m7.1.1.cmml"><mi id="S3.SS1.p1.10.m7.1.1.2" xref="S3.SS1.p1.10.m7.1.1.2.cmml">N</mi><mrow id="S3.SS1.p1.10.m7.1.1.3" xref="S3.SS1.p1.10.m7.1.1.3.cmml"><mi id="S3.SS1.p1.10.m7.1.1.3.2" xref="S3.SS1.p1.10.m7.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m7.1.1.3.1" xref="S3.SS1.p1.10.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p1.10.m7.1.1.3.3" xref="S3.SS1.p1.10.m7.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m7.1.1.3.1a" xref="S3.SS1.p1.10.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p1.10.m7.1.1.3.4" xref="S3.SS1.p1.10.m7.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m7.1b"><apply id="S3.SS1.p1.10.m7.1.1.cmml" xref="S3.SS1.p1.10.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m7.1.1.1.cmml" xref="S3.SS1.p1.10.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m7.1.1.2.cmml" xref="S3.SS1.p1.10.m7.1.1.2">ğ‘</ci><apply id="S3.SS1.p1.10.m7.1.1.3.cmml" xref="S3.SS1.p1.10.m7.1.1.3"><times id="S3.SS1.p1.10.m7.1.1.3.1.cmml" xref="S3.SS1.p1.10.m7.1.1.3.1"></times><ci id="S3.SS1.p1.10.m7.1.1.3.2.cmml" xref="S3.SS1.p1.10.m7.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.SS1.p1.10.m7.1.1.3.3.cmml" xref="S3.SS1.p1.10.m7.1.1.3.3">ğ‘’</ci><ci id="S3.SS1.p1.10.m7.1.1.3.4.cmml" xref="S3.SS1.p1.10.m7.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m7.1c">N_{reg}</annotation></semantics></math> is the size of the subset <math id="S3.SS1.p1.11.m8.1" class="ltx_Math" alttext="\mathcal{B}_{\mathcal{K}}" display="inline"><semantics id="S3.SS1.p1.11.m8.1a"><msub id="S3.SS1.p1.11.m8.1.1" xref="S3.SS1.p1.11.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.11.m8.1.1.2" xref="S3.SS1.p1.11.m8.1.1.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.11.m8.1.1.3" xref="S3.SS1.p1.11.m8.1.1.3.cmml">ğ’¦</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m8.1b"><apply id="S3.SS1.p1.11.m8.1.1.cmml" xref="S3.SS1.p1.11.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m8.1.1.1.cmml" xref="S3.SS1.p1.11.m8.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m8.1.1.2.cmml" xref="S3.SS1.p1.11.m8.1.1.2">â„¬</ci><ci id="S3.SS1.p1.11.m8.1.1.3.cmml" xref="S3.SS1.p1.11.m8.1.1.3">ğ’¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m8.1c">\mathcal{B}_{\mathcal{K}}</annotation></semantics></math>, which only contains the anchors with the ground truth label <math id="S3.SS1.p1.12.m9.1" class="ltx_Math" alttext="p_{i}^{*}=1" display="inline"><semantics id="S3.SS1.p1.12.m9.1a"><mrow id="S3.SS1.p1.12.m9.1.1" xref="S3.SS1.p1.12.m9.1.1.cmml"><msubsup id="S3.SS1.p1.12.m9.1.1.2" xref="S3.SS1.p1.12.m9.1.1.2.cmml"><mi id="S3.SS1.p1.12.m9.1.1.2.2.2" xref="S3.SS1.p1.12.m9.1.1.2.2.2.cmml">p</mi><mi id="S3.SS1.p1.12.m9.1.1.2.2.3" xref="S3.SS1.p1.12.m9.1.1.2.2.3.cmml">i</mi><mo id="S3.SS1.p1.12.m9.1.1.2.3" xref="S3.SS1.p1.12.m9.1.1.2.3.cmml">âˆ—</mo></msubsup><mo id="S3.SS1.p1.12.m9.1.1.1" xref="S3.SS1.p1.12.m9.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.12.m9.1.1.3" xref="S3.SS1.p1.12.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m9.1b"><apply id="S3.SS1.p1.12.m9.1.1.cmml" xref="S3.SS1.p1.12.m9.1.1"><eq id="S3.SS1.p1.12.m9.1.1.1.cmml" xref="S3.SS1.p1.12.m9.1.1.1"></eq><apply id="S3.SS1.p1.12.m9.1.1.2.cmml" xref="S3.SS1.p1.12.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m9.1.1.2.1.cmml" xref="S3.SS1.p1.12.m9.1.1.2">superscript</csymbol><apply id="S3.SS1.p1.12.m9.1.1.2.2.cmml" xref="S3.SS1.p1.12.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m9.1.1.2.2.1.cmml" xref="S3.SS1.p1.12.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.12.m9.1.1.2.2.2.cmml" xref="S3.SS1.p1.12.m9.1.1.2.2.2">ğ‘</ci><ci id="S3.SS1.p1.12.m9.1.1.2.2.3.cmml" xref="S3.SS1.p1.12.m9.1.1.2.2.3">ğ‘–</ci></apply><times id="S3.SS1.p1.12.m9.1.1.2.3.cmml" xref="S3.SS1.p1.12.m9.1.1.2.3"></times></apply><cn type="integer" id="S3.SS1.p1.12.m9.1.1.3.cmml" xref="S3.SS1.p1.12.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m9.1c">p_{i}^{*}=1</annotation></semantics></math>. Note <math id="S3.SS1.p1.13.m10.1" class="ltx_Math" alttext="p_{i}^{*}" display="inline"><semantics id="S3.SS1.p1.13.m10.1a"><msubsup id="S3.SS1.p1.13.m10.1.1" xref="S3.SS1.p1.13.m10.1.1.cmml"><mi id="S3.SS1.p1.13.m10.1.1.2.2" xref="S3.SS1.p1.13.m10.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p1.13.m10.1.1.2.3" xref="S3.SS1.p1.13.m10.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p1.13.m10.1.1.3" xref="S3.SS1.p1.13.m10.1.1.3.cmml">âˆ—</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m10.1b"><apply id="S3.SS1.p1.13.m10.1.1.cmml" xref="S3.SS1.p1.13.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m10.1.1.1.cmml" xref="S3.SS1.p1.13.m10.1.1">superscript</csymbol><apply id="S3.SS1.p1.13.m10.1.1.2.cmml" xref="S3.SS1.p1.13.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m10.1.1.2.1.cmml" xref="S3.SS1.p1.13.m10.1.1">subscript</csymbol><ci id="S3.SS1.p1.13.m10.1.1.2.2.cmml" xref="S3.SS1.p1.13.m10.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p1.13.m10.1.1.2.3.cmml" xref="S3.SS1.p1.13.m10.1.1.2.3">ğ‘–</ci></apply><times id="S3.SS1.p1.13.m10.1.1.3.cmml" xref="S3.SS1.p1.13.m10.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m10.1c">p_{i}^{*}</annotation></semantics></math> equals <math id="S3.SS1.p1.14.m11.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS1.p1.14.m11.1a"><mn id="S3.SS1.p1.14.m11.1.1" xref="S3.SS1.p1.14.m11.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m11.1b"><cn type="integer" id="S3.SS1.p1.14.m11.1.1.cmml" xref="S3.SS1.p1.14.m11.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m11.1c">1</annotation></semantics></math> only when the anchor <math id="S3.SS1.p1.15.m12.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p1.15.m12.1a"><mi id="S3.SS1.p1.15.m12.1.1" xref="S3.SS1.p1.15.m12.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m12.1b"><ci id="S3.SS1.p1.15.m12.1.1.cmml" xref="S3.SS1.p1.15.m12.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m12.1c">i</annotation></semantics></math> can be associated to an annotated object bounding box from the known classes <math id="S3.SS1.p1.16.m13.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p1.16.m13.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.16.m13.1.1" xref="S3.SS1.p1.16.m13.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m13.1b"><ci id="S3.SS1.p1.16.m13.1.1.cmml" xref="S3.SS1.p1.16.m13.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m13.1c">\mathcal{K}</annotation></semantics></math>; otherwise it equals <math id="S3.SS1.p1.17.m14.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS1.p1.17.m14.1a"><mn id="S3.SS1.p1.17.m14.1.1" xref="S3.SS1.p1.17.m14.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.17.m14.1b"><cn type="integer" id="S3.SS1.p1.17.m14.1.1.cmml" xref="S3.SS1.p1.17.m14.1.1">0</cn></annotation-xml></semantics></math> (background).</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">From the closed-world to the open-world setup, the generalization goal extends to localizing every object in the image, which can belong to an unknown novel class <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">u</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">ğ’°</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><in id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></in><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘¢</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ’°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">u\in\mathcal{U}</annotation></semantics></math>. Under the training loss in (<a href="#S3.E1" title="In 3.1 open-world class-agnostic object detection problem â€£ 3 Method â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), an unannotated object will be classified as â€œbackgroundâ€. As a result, the model will treat similar types of objects as â€œbackgroundâ€ at inference time. To avoid suppressing the detection of novel objects in the background, <cite class="ltx_cite ltx_citemacro_citet">Kim etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> proposed to replace the classification loss in (<a href="#S3.E1" title="In 3.1 open-world class-agnostic object detection problem â€£ 3 Method â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) by the objectness score prediction loss, yielding</p>
<table id="A5.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{OLN}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*})," display="inline"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.6" xref="S3.E2.m1.2.2.1.1.6.cmml"><msub id="S3.E2.m1.2.2.1.1.6.2" xref="S3.E2.m1.2.2.1.1.6.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.6.2.2" xref="S3.E2.m1.2.2.1.1.6.2.2.cmml">â„’</mi><mrow id="S3.E2.m1.2.2.1.1.6.2.3" xref="S3.E2.m1.2.2.1.1.6.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.6.2.3.2" xref="S3.E2.m1.2.2.1.1.6.2.3.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.2.3.1" xref="S3.E2.m1.2.2.1.1.6.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.6.2.3.3" xref="S3.E2.m1.2.2.1.1.6.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.2.3.1a" xref="S3.E2.m1.2.2.1.1.6.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.6.2.3.4" xref="S3.E2.m1.2.2.1.1.6.2.3.4.cmml">N</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.1" xref="S3.E2.m1.2.2.1.1.6.1.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.6.3.2" xref="S3.E2.m1.2.2.1.1.6.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.6.3.2.1" xref="S3.E2.m1.2.2.1.1.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">â„</mi><mo stretchy="false" id="S3.E2.m1.2.2.1.1.6.3.2.2" xref="S3.E2.m1.2.2.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.5" xref="S3.E2.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.4" xref="S3.E2.m1.2.2.1.1.4.cmml"><mrow id="S3.E2.m1.2.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.4.cmml"><mfrac id="S3.E2.m1.2.2.1.1.2.2.4a" xref="S3.E2.m1.2.2.1.1.2.2.4.cmml"><mn id="S3.E2.m1.2.2.1.1.2.2.4.2" xref="S3.E2.m1.2.2.1.1.2.2.4.2.cmml">1</mn><msub id="S3.E2.m1.2.2.1.1.2.2.4.3" xref="S3.E2.m1.2.2.1.1.2.2.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.2" xref="S3.E2.m1.2.2.1.1.2.2.4.3.2.cmml">N</mi><mrow id="S3.E2.m1.2.2.1.1.2.2.4.3.3" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.4.3.3.1" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.3.3" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.4.3.3.1a" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.3.4" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.cmml"><munder id="S3.E2.m1.2.2.1.1.2.2.2.3a" xref="S3.E2.m1.2.2.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E2.m1.2.2.1.1.2.2.2.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.2.2.2.3.3.1" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.1.cmml">âˆˆ</mo><msub id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3.cmml">ğ’¦</mi></msub></mrow></munder></mstyle><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E2.m1.2.2.1.1.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.2.cmml">â„’</mi><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1a" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.4.5" xref="S3.E2.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S3.E2.m1.2.2.1.1.4.4" xref="S3.E2.m1.2.2.1.1.4.4.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.4.4.4" xref="S3.E2.m1.2.2.1.1.4.4.4.cmml"><mfrac id="S3.E2.m1.2.2.1.1.4.4.4a" xref="S3.E2.m1.2.2.1.1.4.4.4.cmml"><mn id="S3.E2.m1.2.2.1.1.4.4.4.2" xref="S3.E2.m1.2.2.1.1.4.4.4.2.cmml">1</mn><msub id="S3.E2.m1.2.2.1.1.4.4.4.3" xref="S3.E2.m1.2.2.1.1.4.4.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.2" xref="S3.E2.m1.2.2.1.1.4.4.4.3.2.cmml">N</mi><mrow id="S3.E2.m1.2.2.1.1.4.4.4.3.3" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.3.2" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.4.3.3.1" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.3.3" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.4.3.3.1a" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.3.4" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.3" xref="S3.E2.m1.2.2.1.1.4.4.3.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.4.4.2" xref="S3.E2.m1.2.2.1.1.4.4.2.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.4.4.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.cmml"><munder id="S3.E2.m1.2.2.1.1.4.4.2.3a" xref="S3.E2.m1.2.2.1.1.4.4.2.3.cmml"><mo movablelimits="false" id="S3.E2.m1.2.2.1.1.4.4.2.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.2.2.1.1.4.4.2.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.2.3.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.4.4.2.3.3.1" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.1.cmml">âˆˆ</mo><msub id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3.cmml">ğ’¦</mi></msub></mrow></munder></mstyle><mrow id="S3.E2.m1.2.2.1.1.4.4.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.cmml"><msub id="S3.E2.m1.2.2.1.1.4.4.2.2.4" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.2.cmml">â„’</mi><mrow id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1a" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml">o</mi><mi id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml">o</mi><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.5" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.5.cmml" xref="S3.E2.m1.2.2.1.1.5"></eq><apply id="S3.E2.m1.2.2.1.1.6.cmml" xref="S3.E2.m1.2.2.1.1.6"><times id="S3.E2.m1.2.2.1.1.6.1.cmml" xref="S3.E2.m1.2.2.1.1.6.1"></times><apply id="S3.E2.m1.2.2.1.1.6.2.cmml" xref="S3.E2.m1.2.2.1.1.6.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.6.2.1.cmml" xref="S3.E2.m1.2.2.1.1.6.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.6.2.2.cmml" xref="S3.E2.m1.2.2.1.1.6.2.2">â„’</ci><apply id="S3.E2.m1.2.2.1.1.6.2.3.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3"><times id="S3.E2.m1.2.2.1.1.6.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.1"></times><ci id="S3.E2.m1.2.2.1.1.6.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.2">ğ‘‚</ci><ci id="S3.E2.m1.2.2.1.1.6.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.3">ğ¿</ci><ci id="S3.E2.m1.2.2.1.1.6.2.3.4.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.4">ğ‘</ci></apply></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">â„</ci></apply><apply id="S3.E2.m1.2.2.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.4"><plus id="S3.E2.m1.2.2.1.1.4.5.cmml" xref="S3.E2.m1.2.2.1.1.4.5"></plus><apply id="S3.E2.m1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2"><times id="S3.E2.m1.2.2.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3"></times><apply id="S3.E2.m1.2.2.1.1.2.2.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4"><divide id="S3.E2.m1.2.2.1.1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4"></divide><cn type="integer" id="S3.E2.m1.2.2.1.1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.2">1</cn><apply id="S3.E2.m1.2.2.1.1.2.2.4.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.2">ğ‘</ci><apply id="S3.E2.m1.2.2.1.1.2.2.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3"><times id="S3.E2.m1.2.2.1.1.2.2.4.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.2">ğ‘Ÿ</ci><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.3">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.4">ğ‘”</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2"><apply id="S3.E2.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.2"></sum><apply id="S3.E2.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3"><in id="S3.E2.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.1"></in><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.2">ğ‘–</ci><apply id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2">â„¬</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3">ğ’¦</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2"><times id="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3"></times><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.2">â„’</ci><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3"><times id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1"></times><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2">ğ‘Ÿ</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4">ğ‘”</ci></apply></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2">ğ‘¡</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.4.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4"><times id="S3.E2.m1.2.2.1.1.4.4.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.3"></times><apply id="S3.E2.m1.2.2.1.1.4.4.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4"><divide id="S3.E2.m1.2.2.1.1.4.4.4.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4"></divide><cn type="integer" id="S3.E2.m1.2.2.1.1.4.4.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.2">1</cn><apply id="S3.E2.m1.2.2.1.1.4.4.4.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.2">ğ‘</ci><apply id="S3.E2.m1.2.2.1.1.4.4.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3"><times id="S3.E2.m1.2.2.1.1.4.4.4.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.2">ğ‘Ÿ</ci><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.3">ğ‘’</ci><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.4">ğ‘”</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.4.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2"><apply id="S3.E2.m1.2.2.1.1.4.4.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.4.4.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.2"></sum><apply id="S3.E2.m1.2.2.1.1.4.4.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3"><in id="S3.E2.m1.2.2.1.1.4.4.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.1"></in><ci id="S3.E2.m1.2.2.1.1.4.4.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.2">ğ‘–</ci><apply id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2">â„¬</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3">ğ’¦</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2"><times id="S3.E2.m1.2.2.1.1.4.4.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.3"></times><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.2">â„’</ci><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3"><times id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1"></times><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2">ğ‘œ</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3">ğ‘</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4">ğ‘—</ci></apply></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2"><apply id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2">ğ‘œ</ci><ci id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2">ğ‘œ</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\displaystyle\mathcal{L}_{OLN}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.5" class="ltx_p">where <math id="S3.SS1.p2.2.m1.1" class="ltx_Math" alttext="o_{i}" display="inline"><semantics id="S3.SS1.p2.2.m1.1a"><msub id="S3.SS1.p2.2.m1.1.1" xref="S3.SS1.p2.2.m1.1.1.cmml"><mi id="S3.SS1.p2.2.m1.1.1.2" xref="S3.SS1.p2.2.m1.1.1.2.cmml">o</mi><mi id="S3.SS1.p2.2.m1.1.1.3" xref="S3.SS1.p2.2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m1.1b"><apply id="S3.SS1.p2.2.m1.1.1.cmml" xref="S3.SS1.p2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m1.1.1.1.cmml" xref="S3.SS1.p2.2.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m1.1.1.2.cmml" xref="S3.SS1.p2.2.m1.1.1.2">ğ‘œ</ci><ci id="S3.SS1.p2.2.m1.1.1.3.cmml" xref="S3.SS1.p2.2.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m1.1c">o_{i}</annotation></semantics></math> and <math id="S3.SS1.p2.3.m2.1" class="ltx_Math" alttext="o_{i}^{*}" display="inline"><semantics id="S3.SS1.p2.3.m2.1a"><msubsup id="S3.SS1.p2.3.m2.1.1" xref="S3.SS1.p2.3.m2.1.1.cmml"><mi id="S3.SS1.p2.3.m2.1.1.2.2" xref="S3.SS1.p2.3.m2.1.1.2.2.cmml">o</mi><mi id="S3.SS1.p2.3.m2.1.1.2.3" xref="S3.SS1.p2.3.m2.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p2.3.m2.1.1.3" xref="S3.SS1.p2.3.m2.1.1.3.cmml">âˆ—</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m2.1b"><apply id="S3.SS1.p2.3.m2.1.1.cmml" xref="S3.SS1.p2.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m2.1.1.1.cmml" xref="S3.SS1.p2.3.m2.1.1">superscript</csymbol><apply id="S3.SS1.p2.3.m2.1.1.2.cmml" xref="S3.SS1.p2.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m2.1.1.2.1.cmml" xref="S3.SS1.p2.3.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m2.1.1.2.2.cmml" xref="S3.SS1.p2.3.m2.1.1.2.2">ğ‘œ</ci><ci id="S3.SS1.p2.3.m2.1.1.2.3.cmml" xref="S3.SS1.p2.3.m2.1.1.2.3">ğ‘–</ci></apply><times id="S3.SS1.p2.3.m2.1.1.3.cmml" xref="S3.SS1.p2.3.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m2.1c">o_{i}^{*}</annotation></semantics></math> are the predicted objectness score and its ground truth of anchor <math id="S3.SS1.p2.4.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p2.4.m3.1a"><mi id="S3.SS1.p2.4.m3.1.1" xref="S3.SS1.p2.4.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m3.1b"><ci id="S3.SS1.p2.4.m3.1.1.cmml" xref="S3.SS1.p2.4.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m3.1c">i</annotation></semantics></math>. In doing so, only the anchors with <math id="S3.SS1.p2.5.m4.1" class="ltx_Math" alttext="p_{i}^{*}=1" display="inline"><semantics id="S3.SS1.p2.5.m4.1a"><mrow id="S3.SS1.p2.5.m4.1.1" xref="S3.SS1.p2.5.m4.1.1.cmml"><msubsup id="S3.SS1.p2.5.m4.1.1.2" xref="S3.SS1.p2.5.m4.1.1.2.cmml"><mi id="S3.SS1.p2.5.m4.1.1.2.2.2" xref="S3.SS1.p2.5.m4.1.1.2.2.2.cmml">p</mi><mi id="S3.SS1.p2.5.m4.1.1.2.2.3" xref="S3.SS1.p2.5.m4.1.1.2.2.3.cmml">i</mi><mo id="S3.SS1.p2.5.m4.1.1.2.3" xref="S3.SS1.p2.5.m4.1.1.2.3.cmml">âˆ—</mo></msubsup><mo id="S3.SS1.p2.5.m4.1.1.1" xref="S3.SS1.p2.5.m4.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.5.m4.1.1.3" xref="S3.SS1.p2.5.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m4.1b"><apply id="S3.SS1.p2.5.m4.1.1.cmml" xref="S3.SS1.p2.5.m4.1.1"><eq id="S3.SS1.p2.5.m4.1.1.1.cmml" xref="S3.SS1.p2.5.m4.1.1.1"></eq><apply id="S3.SS1.p2.5.m4.1.1.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m4.1.1.2.1.cmml" xref="S3.SS1.p2.5.m4.1.1.2">superscript</csymbol><apply id="S3.SS1.p2.5.m4.1.1.2.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m4.1.1.2.2.1.cmml" xref="S3.SS1.p2.5.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.5.m4.1.1.2.2.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2.2.2">ğ‘</ci><ci id="S3.SS1.p2.5.m4.1.1.2.2.3.cmml" xref="S3.SS1.p2.5.m4.1.1.2.2.3">ğ‘–</ci></apply><times id="S3.SS1.p2.5.m4.1.1.2.3.cmml" xref="S3.SS1.p2.5.m4.1.1.2.3"></times></apply><cn type="integer" id="S3.SS1.p2.5.m4.1.1.3.cmml" xref="S3.SS1.p2.5.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m4.1c">p_{i}^{*}=1</annotation></semantics></math> are involved in training, completely removing any â€œbackgroundâ€ prediction. At inference time, the objectness score is used to rank the detections. However, since these anchors only capture the annotated objects from the base classes, this loss modification cannot effectively mitigate the overfitting to the base classes. We further resort to adding additional â€œobjectsâ€ into training, especially novel ones with very different appearances than objects from the base classes.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Exploiting geometric cues</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">Models trained on RGB images tend to over-rely on the appearance cues for object detection. Therefore, it is hard for them to detect novel objects that appear very differently from the base classes. For instance, a model trained on cars is likely to detect trucks, but unlikely to also detect sandwiches. Involving such novel objects, e.g., food, into training is then an effective way to mitigate the appearance bias towards the base classes, e.g., vehicles. To this end, we exploit two types of geometric cues, i.e., depth and normals, for detecting unannotated novel objects in the training set, see some examples in FigureÂ <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Both of them are common geometric cues that capture local information. Depth focuses on the relative spatial difference of objects and abstracts away the details on the object surfaces. Surface normals focus on the directional difference and remain the same on flat surfaces. Compared with the original RGB image, they discard most appearance details and focus on the geometry information such as object shapes and relative spatial locations. Models trained with them can thus discover many novel-looking objects that RGB-based ones cannot detect.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">We use off-the-shelf pretrained models to extract geometric cues. Specifically, we use Omnidata modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> trained using cross-task consistencyÂ <cite class="ltx_cite ltx_citemacro_citep">(Zamir etÂ al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> and 2D/3D data augmentationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Kar etÂ al., <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.
The training dataset for the models is the Omnidata Starter Dataset (OSD)Â <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> which contains 2200 real and rendered scenes.
Despite the difference between the OSD to the object detection benchmark datasets, the Omnidata model can produce high-quality results, implying that the invariances behind these geometric cues are robust.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Pseudo labeling method</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.2" class="ltx_p">To use the geometric cues to discover unannotated novel objects in the training set, we first train an object proposal network on the depth or normal input using the same training loss as in (<a href="#S3.E2" title="In 3.1 open-world class-agnostic object detection problem â€£ 3 Method â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), i.e., Phase-I training in FigureÂ <a href="#S2.F3" title="Figure 3 â€£ 2 Related work â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
Then, this object proposal network will pseudo-label the training images using its detected bounding boxes.
After filtering out the detected bounding boxes which overlap with the base class annotations, we then add the remaining top-<math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">k</annotation></semantics></math> boxes to the ground truth annotations.
Here <math id="S3.SS3.p1.2.m2.3" class="ltx_Math" alttext="k\in\{1,2,3\}" display="inline"><semantics id="S3.SS3.p1.2.m2.3a"><mrow id="S3.SS3.p1.2.m2.3.4" xref="S3.SS3.p1.2.m2.3.4.cmml"><mi id="S3.SS3.p1.2.m2.3.4.2" xref="S3.SS3.p1.2.m2.3.4.2.cmml">k</mi><mo id="S3.SS3.p1.2.m2.3.4.1" xref="S3.SS3.p1.2.m2.3.4.1.cmml">âˆˆ</mo><mrow id="S3.SS3.p1.2.m2.3.4.3.2" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.3.4.3.2.1" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">{</mo><mn id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">1</mn><mo id="S3.SS3.p1.2.m2.3.4.3.2.2" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.2.2" xref="S3.SS3.p1.2.m2.2.2.cmml">2</mn><mo id="S3.SS3.p1.2.m2.3.4.3.2.3" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.3.3" xref="S3.SS3.p1.2.m2.3.3.cmml">3</mn><mo stretchy="false" id="S3.SS3.p1.2.m2.3.4.3.2.4" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.3b"><apply id="S3.SS3.p1.2.m2.3.4.cmml" xref="S3.SS3.p1.2.m2.3.4"><in id="S3.SS3.p1.2.m2.3.4.1.cmml" xref="S3.SS3.p1.2.m2.3.4.1"></in><ci id="S3.SS3.p1.2.m2.3.4.2.cmml" xref="S3.SS3.p1.2.m2.3.4.2">ğ‘˜</ci><set id="S3.SS3.p1.2.m2.3.4.3.1.cmml" xref="S3.SS3.p1.2.m2.3.4.3.2"><cn type="integer" id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">1</cn><cn type="integer" id="S3.SS3.p1.2.m2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2">2</cn><cn type="integer" id="S3.SS3.p1.2.m2.3.3.cmml" xref="S3.SS3.p1.2.m2.3.3">3</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.3c">k\in\{1,2,3\}</annotation></semantics></math> is determined for each detector on a small holdout validation set. Finally, we train a new class-agnostic object detector using the RGB image as input and the extended bounding box annotation pool as ground truth, i.e., Phase-II in FigureÂ <a href="#S2.F3" title="Figure 3 â€£ 2 Related work â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The training loss is</p>
<table id="A5.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.2" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{GOOD}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*})." display="inline"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.6" xref="S3.E3.m1.2.2.1.1.6.cmml"><msub id="S3.E3.m1.2.2.1.1.6.2" xref="S3.E3.m1.2.2.1.1.6.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.6.2.2" xref="S3.E3.m1.2.2.1.1.6.2.2.cmml">â„’</mi><mrow id="S3.E3.m1.2.2.1.1.6.2.3" xref="S3.E3.m1.2.2.1.1.6.2.3.cmml"><mi id="S3.E3.m1.2.2.1.1.6.2.3.2" xref="S3.E3.m1.2.2.1.1.6.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.2.3.1" xref="S3.E3.m1.2.2.1.1.6.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.6.2.3.3" xref="S3.E3.m1.2.2.1.1.6.2.3.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.2.3.1a" xref="S3.E3.m1.2.2.1.1.6.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.6.2.3.4" xref="S3.E3.m1.2.2.1.1.6.2.3.4.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.2.3.1b" xref="S3.E3.m1.2.2.1.1.6.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.6.2.3.5" xref="S3.E3.m1.2.2.1.1.6.2.3.5.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.1" xref="S3.E3.m1.2.2.1.1.6.1.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.6.3.2" xref="S3.E3.m1.2.2.1.1.6.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.6.3.2.1" xref="S3.E3.m1.2.2.1.1.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">â„</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.1.6.3.2.2" xref="S3.E3.m1.2.2.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.5" xref="S3.E3.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E3.m1.2.2.1.1.4" xref="S3.E3.m1.2.2.1.1.4.cmml"><mrow id="S3.E3.m1.2.2.1.1.2.2" xref="S3.E3.m1.2.2.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.2.2.4" xref="S3.E3.m1.2.2.1.1.2.2.4.cmml"><mfrac id="S3.E3.m1.2.2.1.1.2.2.4a" xref="S3.E3.m1.2.2.1.1.2.2.4.cmml"><mn id="S3.E3.m1.2.2.1.1.2.2.4.2" xref="S3.E3.m1.2.2.1.1.2.2.4.2.cmml">1</mn><msub id="S3.E3.m1.2.2.1.1.2.2.4.3" xref="S3.E3.m1.2.2.1.1.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.2" xref="S3.E3.m1.2.2.1.1.2.2.4.3.2.cmml">N</mi><mrow id="S3.E3.m1.2.2.1.1.2.2.4.3.3" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.4.3.3.1" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.4.3.3.1a" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.3.4" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.cmml"><munder id="S3.E3.m1.2.2.1.1.2.2.2.3a" xref="S3.E3.m1.2.2.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.2.2.1.1.2.2.2.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.2.2.2.3.3.1" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.1.cmml">âˆˆ</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.cmml"><msub id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3.cmml">ğ’¦</mi></msub><mo id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1.cmml">âˆª</mo><msub id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3.cmml">ğ’©</mi></msub></mrow></mrow></munder></mstyle><mrow id="S3.E3.m1.2.2.1.1.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E3.m1.2.2.1.1.2.2.2.2.4" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.2.cmml">â„’</mi><mrow id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1a" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.4.5" xref="S3.E3.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S3.E3.m1.2.2.1.1.4.4" xref="S3.E3.m1.2.2.1.1.4.4.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.4.4.4" xref="S3.E3.m1.2.2.1.1.4.4.4.cmml"><mfrac id="S3.E3.m1.2.2.1.1.4.4.4a" xref="S3.E3.m1.2.2.1.1.4.4.4.cmml"><mn id="S3.E3.m1.2.2.1.1.4.4.4.2" xref="S3.E3.m1.2.2.1.1.4.4.4.2.cmml">1</mn><msub id="S3.E3.m1.2.2.1.1.4.4.4.3" xref="S3.E3.m1.2.2.1.1.4.4.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.2" xref="S3.E3.m1.2.2.1.1.4.4.4.3.2.cmml">N</mi><mrow id="S3.E3.m1.2.2.1.1.4.4.4.3.3" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.4.3.3.1" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.4.3.3.1a" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.3.4" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.3" xref="S3.E3.m1.2.2.1.1.4.4.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2" xref="S3.E3.m1.2.2.1.1.4.4.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.4.4.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.cmml"><munder id="S3.E3.m1.2.2.1.1.4.4.2.3a" xref="S3.E3.m1.2.2.1.1.4.4.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.2.2.1.1.4.4.2.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.2.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.2.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.4.4.2.3.3.1" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.1.cmml">âˆˆ</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.cmml"><msub id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3.cmml">ğ’¦</mi></msub><mo id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1.cmml">âˆª</mo><msub id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3.cmml">ğ’©</mi></msub></mrow></mrow></munder></mstyle><mrow id="S3.E3.m1.2.2.1.1.4.4.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.cmml"><msub id="S3.E3.m1.2.2.1.1.4.4.2.2.4" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.2.cmml">â„’</mi><mrow id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1a" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml">o</mi><mi id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.4" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml">o</mi><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml">âˆ—</mo></msubsup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.5" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><eq id="S3.E3.m1.2.2.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.5"></eq><apply id="S3.E3.m1.2.2.1.1.6.cmml" xref="S3.E3.m1.2.2.1.1.6"><times id="S3.E3.m1.2.2.1.1.6.1.cmml" xref="S3.E3.m1.2.2.1.1.6.1"></times><apply id="S3.E3.m1.2.2.1.1.6.2.cmml" xref="S3.E3.m1.2.2.1.1.6.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.6.2.1.cmml" xref="S3.E3.m1.2.2.1.1.6.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.6.2.2.cmml" xref="S3.E3.m1.2.2.1.1.6.2.2">â„’</ci><apply id="S3.E3.m1.2.2.1.1.6.2.3.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3"><times id="S3.E3.m1.2.2.1.1.6.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.1"></times><ci id="S3.E3.m1.2.2.1.1.6.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.2">ğº</ci><ci id="S3.E3.m1.2.2.1.1.6.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.3">ğ‘‚</ci><ci id="S3.E3.m1.2.2.1.1.6.2.3.4.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.4">ğ‘‚</ci><ci id="S3.E3.m1.2.2.1.1.6.2.3.5.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.5">ğ·</ci></apply></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">â„</ci></apply><apply id="S3.E3.m1.2.2.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.4"><plus id="S3.E3.m1.2.2.1.1.4.5.cmml" xref="S3.E3.m1.2.2.1.1.4.5"></plus><apply id="S3.E3.m1.2.2.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2"><times id="S3.E3.m1.2.2.1.1.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.3"></times><apply id="S3.E3.m1.2.2.1.1.2.2.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4"><divide id="S3.E3.m1.2.2.1.1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4"></divide><cn type="integer" id="S3.E3.m1.2.2.1.1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.2">1</cn><apply id="S3.E3.m1.2.2.1.1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.2">ğ‘</ci><apply id="S3.E3.m1.2.2.1.1.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3"><times id="S3.E3.m1.2.2.1.1.2.2.4.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.1"></times><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.2">ğ‘Ÿ</ci><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.3">ğ‘’</ci><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.3.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.4">ğ‘”</ci></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2"><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E3.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.2"></sum><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3"><in id="S3.E3.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.1"></in><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.2">ğ‘–</ci><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3"><union id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1"></union><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2">â„¬</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3">ğ’¦</ci></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2">â„¬</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3">ğ’©</ci></apply></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2"><times id="S3.E3.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.3"></times><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.2">â„’</ci><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3"><times id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1"></times><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2">ğ‘Ÿ</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3">ğ‘’</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4">ğ‘”</ci></apply></apply><interval closure="open" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2">ğ‘¡</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4"><times id="S3.E3.m1.2.2.1.1.4.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.3"></times><apply id="S3.E3.m1.2.2.1.1.4.4.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4"><divide id="S3.E3.m1.2.2.1.1.4.4.4.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4"></divide><cn type="integer" id="S3.E3.m1.2.2.1.1.4.4.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.2">1</cn><apply id="S3.E3.m1.2.2.1.1.4.4.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.2">ğ‘</ci><apply id="S3.E3.m1.2.2.1.1.4.4.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3"><times id="S3.E3.m1.2.2.1.1.4.4.4.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.1"></times><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.2">ğ‘Ÿ</ci><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.3">ğ‘’</ci><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.3.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.4">ğ‘”</ci></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2"><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3">subscript</csymbol><sum id="S3.E3.m1.2.2.1.1.4.4.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.2"></sum><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3"><in id="S3.E3.m1.2.2.1.1.4.4.2.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.1"></in><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.2">ğ‘–</ci><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3"><union id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1"></union><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2">â„¬</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3">ğ’¦</ci></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2">â„¬</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3">ğ’©</ci></apply></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2"><times id="S3.E3.m1.2.2.1.1.4.4.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.3"></times><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.2">â„’</ci><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3"><times id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1"></times><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2">ğ‘œ</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3">ğ‘</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4">ğ‘—</ci></apply></apply><interval closure="open" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2"><apply id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2">ğ‘œ</ci><ci id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2">ğ‘œ</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3">ğ‘–</ci></apply><times id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\displaystyle\mathcal{L}_{GOOD}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.8" class="ltx_p">Compared with (<a href="#S3.E2" title="In 3.1 open-world class-agnostic object detection problem â€£ 3 Method â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), the anchors that overlap with the pseudo boxes of the detected novel objects, i.e., <math id="S3.SS3.p1.3.m1.1" class="ltx_Math" alttext="i\in\mathcal{B}_{\mathcal{N}}" display="inline"><semantics id="S3.SS3.p1.3.m1.1a"><mrow id="S3.SS3.p1.3.m1.1.1" xref="S3.SS3.p1.3.m1.1.1.cmml"><mi id="S3.SS3.p1.3.m1.1.1.2" xref="S3.SS3.p1.3.m1.1.1.2.cmml">i</mi><mo id="S3.SS3.p1.3.m1.1.1.1" xref="S3.SS3.p1.3.m1.1.1.1.cmml">âˆˆ</mo><msub id="S3.SS3.p1.3.m1.1.1.3" xref="S3.SS3.p1.3.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.3.m1.1.1.3.2" xref="S3.SS3.p1.3.m1.1.1.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.3.m1.1.1.3.3" xref="S3.SS3.p1.3.m1.1.1.3.3.cmml">ğ’©</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.1b"><apply id="S3.SS3.p1.3.m1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1"><in id="S3.SS3.p1.3.m1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1"></in><ci id="S3.SS3.p1.3.m1.1.1.2.cmml" xref="S3.SS3.p1.3.m1.1.1.2">ğ‘–</ci><apply id="S3.SS3.p1.3.m1.1.1.3.cmml" xref="S3.SS3.p1.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.3.1.cmml" xref="S3.SS3.p1.3.m1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.3.m1.1.1.3.2.cmml" xref="S3.SS3.p1.3.m1.1.1.3.2">â„¬</ci><ci id="S3.SS3.p1.3.m1.1.1.3.3.cmml" xref="S3.SS3.p1.3.m1.1.1.3.3">ğ’©</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.1c">i\in\mathcal{B}_{\mathcal{N}}</annotation></semantics></math>, are also involved in training.
The pseudo boxes can be acquired from a single source, i.e., one of the geometric cues, and from both, i.e., pseudo label ensembling. We name our method <math id="S3.SS3.p1.4.m2.1" class="ltx_Math" alttext="\mathrm{GOOD}" display="inline"><semantics id="S3.SS3.p1.4.m2.1a"><mi id="S3.SS3.p1.4.m2.1.1" xref="S3.SS3.p1.4.m2.1.1.cmml">GOOD</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.1b"><ci id="S3.SS3.p1.4.m2.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1">GOOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.1c">\mathrm{GOOD}</annotation></semantics></math>-<math id="S3.SS3.p1.5.m3.1" class="ltx_Math" alttext="\mathrm{X}" display="inline"><semantics id="S3.SS3.p1.5.m3.1a"><mi mathvariant="normal" id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.1b"><ci id="S3.SS3.p1.5.m3.1.1.cmml" xref="S3.SS3.p1.5.m3.1.1">X</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.1c">\mathrm{X}</annotation></semantics></math> when using a specific geometric cue <math id="S3.SS3.p1.6.m4.1" class="ltx_Math" alttext="\mathrm{X}" display="inline"><semantics id="S3.SS3.p1.6.m4.1a"><mi mathvariant="normal" id="S3.SS3.p1.6.m4.1.1" xref="S3.SS3.p1.6.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m4.1b"><ci id="S3.SS3.p1.6.m4.1.1.cmml" xref="S3.SS3.p1.6.m4.1.1">X</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m4.1c">\mathrm{X}</annotation></semantics></math> as the pseudo labeling source, whereas <math id="S3.SS3.p1.7.m5.1" class="ltx_Math" alttext="\mathrm{GOOD}" display="inline"><semantics id="S3.SS3.p1.7.m5.1a"><mi id="S3.SS3.p1.7.m5.1.1" xref="S3.SS3.p1.7.m5.1.1.cmml">GOOD</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m5.1b"><ci id="S3.SS3.p1.7.m5.1.1.cmml" xref="S3.SS3.p1.7.m5.1.1">GOOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m5.1c">\mathrm{GOOD}</annotation></semantics></math>-<math id="S3.SS3.p1.8.m6.1" class="ltx_Math" alttext="\mathrm{Both}" display="inline"><semantics id="S3.SS3.p1.8.m6.1a"><mi id="S3.SS3.p1.8.m6.1.1" xref="S3.SS3.p1.8.m6.1.1.cmml">Both</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m6.1b"><ci id="S3.SS3.p1.8.m6.1.1.cmml" xref="S3.SS3.p1.8.m6.1.1">Both</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m6.1c">\mathrm{Both}</annotation></semantics></math> stands for ensembling the pseudo labels from both the depth and normals.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">Inspired by previous works in self-trainingÂ <cite class="ltx_cite ltx_citemacro_citep">(Xie etÂ al., <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Sohn etÂ al., <a href="#bib.bib40" title="" class="ltx_ref">2020</a>; Xu etÂ al., <a href="#bib.bib46" title="" class="ltx_ref">2021</a>)</cite>, we use strong data augmentation during Phase-II to counteract the noise in pseudo boxes and further boost the performance of GOOD.
Specifically, for Phase-II training, we use AutoAugmentÂ <cite class="ltx_cite ltx_citemacro_citep">(Cubuk etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite> which includes random resizing, flip, and cropping.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.5" class="ltx_p"><span id="S4.p1.5.1" class="ltx_text ltx_font_bold">Benchmarks.</span>
We target two major challenges of open-world class-agnostic object detection: <span id="S4.p1.5.2" class="ltx_text ltx_font_italic">cross-category and cross-dataset generalization</span>.
For the cross-category evaluation, we follow the common practice in the literatureÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> to split the class category list into two parts. One is used as the base class for training, whereas the other is reserved only for testing cross-category generalization. Specifically, we adopt two splits of the <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">80</annotation></semantics></math> classes in the COCO datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>.
The first benchmark splits the COCO classes into a single â€œpersonâ€ class and 79 non-person classes. This is to stress-test the generalization ability of the methods. We followÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> to choose the â€œpersonâ€ category as the training class because it contains diverse viewpoints and shapes. The second benchmark splits the COCO classes into <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">20</annotation></semantics></math> PASCAL-VOCÂ <cite class="ltx_cite ltx_citemacro_citep">(Everingham etÂ al., <a href="#bib.bib11" title="" class="ltx_ref">2010</a>)</cite> classes for training and the other <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="60" display="inline"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn type="integer" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">60</annotation></semantics></math> for testing.
For the cross-dataset evaluation, we use the ADE20K datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al., <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite> for testing. We compare models trained using only <math id="S4.p1.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.p1.4.m4.1a"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><cn type="integer" id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">20</annotation></semantics></math> PASCAL-VOC classes or all <math id="S4.p1.5.m5.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.p1.5.m5.1a"><mn id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><cn type="integer" id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">80</annotation></semantics></math> COCO classes on detecting objects in ADE20K.
This is to evaluate open-world class-agnostic object detectors when used in the wild.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.5" class="ltx_p"><span id="S4.p2.5.1" class="ltx_text ltx_font_bold">Implementation.</span>
We use the same architecture as OLN inÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> for both Phase I and Phase II training. OLN is built on top of a standard Faster RCNN <cite class="ltx_cite ltx_citemacro_citep">(Ren etÂ al., <a href="#bib.bib33" title="" class="ltx_ref">2015</a>)</cite> architecture with a ResNet-50 backbone pretrained on ImageNetÂ <cite class="ltx_cite ltx_citemacro_citep">(Deng etÂ al., <a href="#bib.bib7" title="" class="ltx_ref">2009</a>)</cite>. We implement our method using MMDetection frameworkÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al., <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> and use the SGD optimizer with an initial learning rate of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="float" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">0.01</annotation></semantics></math> and batch size of <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p2.2.m2.1a"><mn id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><cn type="integer" id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">16</annotation></semantics></math>. The models with data augmentation are all trained for <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p2.3.m3.1a"><mn id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><cn type="integer" id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">16</annotation></semantics></math> epochs. Other models are trained for <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.p2.4.m4.1a"><mn id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><cn type="integer" id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">8</annotation></semantics></math> epochs.
We did not find training for longer epochs beneficial for models without data augmentation.
The optimal number of pseudo boxes, i.e., <math id="S4.p2.5.m5.3" class="ltx_Math" alttext="k\in\{1,2,3\}" display="inline"><semantics id="S4.p2.5.m5.3a"><mrow id="S4.p2.5.m5.3.4" xref="S4.p2.5.m5.3.4.cmml"><mi id="S4.p2.5.m5.3.4.2" xref="S4.p2.5.m5.3.4.2.cmml">k</mi><mo id="S4.p2.5.m5.3.4.1" xref="S4.p2.5.m5.3.4.1.cmml">âˆˆ</mo><mrow id="S4.p2.5.m5.3.4.3.2" xref="S4.p2.5.m5.3.4.3.1.cmml"><mo stretchy="false" id="S4.p2.5.m5.3.4.3.2.1" xref="S4.p2.5.m5.3.4.3.1.cmml">{</mo><mn id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">1</mn><mo id="S4.p2.5.m5.3.4.3.2.2" xref="S4.p2.5.m5.3.4.3.1.cmml">,</mo><mn id="S4.p2.5.m5.2.2" xref="S4.p2.5.m5.2.2.cmml">2</mn><mo id="S4.p2.5.m5.3.4.3.2.3" xref="S4.p2.5.m5.3.4.3.1.cmml">,</mo><mn id="S4.p2.5.m5.3.3" xref="S4.p2.5.m5.3.3.cmml">3</mn><mo stretchy="false" id="S4.p2.5.m5.3.4.3.2.4" xref="S4.p2.5.m5.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.3b"><apply id="S4.p2.5.m5.3.4.cmml" xref="S4.p2.5.m5.3.4"><in id="S4.p2.5.m5.3.4.1.cmml" xref="S4.p2.5.m5.3.4.1"></in><ci id="S4.p2.5.m5.3.4.2.cmml" xref="S4.p2.5.m5.3.4.2">ğ‘˜</ci><set id="S4.p2.5.m5.3.4.3.1.cmml" xref="S4.p2.5.m5.3.4.3.2"><cn type="integer" id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">1</cn><cn type="integer" id="S4.p2.5.m5.2.2.cmml" xref="S4.p2.5.m5.2.2">2</cn><cn type="integer" id="S4.p2.5.m5.3.3.cmml" xref="S4.p2.5.m5.3.3">3</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.3c">k\in\{1,2,3\}</annotation></semantics></math>, varies across input types and is determined on a small holdout validation set.
See AppendixÂ <a href="#A1" title="Appendix A Implementation details â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for further details.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.5" class="ltx_p"><span id="S4.p3.5.1" class="ltx_text ltx_font_bold">Evaluation metrics.</span>
FollowingÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>, we use Average Recall (AR@k) over multiple IoU thresholds (0.5:0.95), and set the detection budget k as <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.p3.1.m1.1a"><mn id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><cn type="integer" id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">100</annotation></semantics></math> by default. All ARs are shown in percentage. AR<sub id="S4.p3.5.2" class="ltx_sub"><span id="S4.p3.5.2.1" class="ltx_text ltx_font_italic">A</span></sub> and AR<sub id="S4.p3.5.3" class="ltx_sub"><span id="S4.p3.5.3.1" class="ltx_text ltx_font_italic">N</span></sub> respectively denote the AR score on detecting all classes (including the base and novel ones) and on detecting the novel classes. To evaluate AR<sub id="S4.p3.5.4" class="ltx_sub"><span id="S4.p3.5.4.1" class="ltx_text ltx_font_italic">N</span></sub>, we do not count the boxes associated to the base classes into the budget k. The same protocol is applied when evaluating per-class ARs and ARs for small, medium and large size of objects, i.e., AR<math id="S4.p3.5.m5.1" class="ltx_Math" alttext="{}_{\cdot}^{s/m/l}" display="inline"><semantics id="S4.p3.5.m5.1a"><mmultiscripts id="S4.p3.5.m5.1.1" xref="S4.p3.5.m5.1.1.cmml"><mi id="S4.p3.5.m5.1.1.2.2" xref="S4.p3.5.m5.1.1.2.2.cmml"></mi><mprescripts id="S4.p3.5.m5.1.1a" xref="S4.p3.5.m5.1.1.cmml"></mprescripts><mrow id="S4.p3.5.m5.1.1b" xref="S4.p3.5.m5.1.1.cmml"></mrow><mrow id="S4.p3.5.m5.1.1.3" xref="S4.p3.5.m5.1.1.3.cmml"><mi id="S4.p3.5.m5.1.1.3.2" xref="S4.p3.5.m5.1.1.3.2.cmml">s</mi><mo id="S4.p3.5.m5.1.1.3.1" xref="S4.p3.5.m5.1.1.3.1.cmml">/</mo><mi id="S4.p3.5.m5.1.1.3.3" xref="S4.p3.5.m5.1.1.3.3.cmml">m</mi><mo id="S4.p3.5.m5.1.1.3.1a" xref="S4.p3.5.m5.1.1.3.1.cmml">/</mo><mi id="S4.p3.5.m5.1.1.3.4" xref="S4.p3.5.m5.1.1.3.4.cmml">l</mi></mrow><mo id="S4.p3.5.m5.1.1.2.3" xref="S4.p3.5.m5.1.1.2.3.cmml">â‹…</mo><mrow id="S4.p3.5.m5.1.1c" xref="S4.p3.5.m5.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.p3.5.m5.1b"><apply id="S4.p3.5.m5.1.1.cmml" xref="S4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p3.5.m5.1.1.1.cmml" xref="S4.p3.5.m5.1.1">superscript</csymbol><apply id="S4.p3.5.m5.1.1.2.cmml" xref="S4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p3.5.m5.1.1.2.1.cmml" xref="S4.p3.5.m5.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.p3.5.m5.1.1.2.2.cmml" xref="S4.p3.5.m5.1.1.2.2">absent</csymbol><ci id="S4.p3.5.m5.1.1.2.3.cmml" xref="S4.p3.5.m5.1.1.2.3">â‹…</ci></apply><apply id="S4.p3.5.m5.1.1.3.cmml" xref="S4.p3.5.m5.1.1.3"><divide id="S4.p3.5.m5.1.1.3.1.cmml" xref="S4.p3.5.m5.1.1.3.1"></divide><ci id="S4.p3.5.m5.1.1.3.2.cmml" xref="S4.p3.5.m5.1.1.3.2">ğ‘ </ci><ci id="S4.p3.5.m5.1.1.3.3.cmml" xref="S4.p3.5.m5.1.1.3.3">ğ‘š</ci><ci id="S4.p3.5.m5.1.1.3.4.cmml" xref="S4.p3.5.m5.1.1.3.4">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.5.m5.1c">{}_{\cdot}^{s/m/l}</annotation></semantics></math>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Detecting unknown objects in an open world</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">TableÂ <a href="#S4.T1.st1" title="In Table 1 â€£ 4.1 Detecting unknown objects in an open world â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> andÂ <a href="#S4.T1.st2" title="In Table 1 â€£ 4.1 Detecting unknown objects in an open world â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> compare open-world class-agnostic object detectors on two cross-category benchmarks and two cross-dataset benchmarks, respectively. Our method GOOD, which incorporates geometric cues, considerably outperforms state-of-the-art RGB-based open-world class-agnostic object detection methods, i.e., OLNÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> and GGNÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>. OLN did not involve any novel object into training. Although GGN proposed to use an intermediate pairwise affinity (PA) representation for pseudo labeling, the PA predictor is still trained on the RGB images, therefore it still has the bias towards the known classes as other RGB-based methods.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T1.st1" class="ltx_table ltx_figure_panel">
<div id="S4.T1.st1.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:120.9pt;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,3.1pt) scale(0.95,0.95) ;">
<div id="S4.T1.st1.12.12" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:126.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-86.0pt,27.2pt) scale(0.697887023566809,0.697887023566809) ;">
<table id="S4.T1.st1.12.12.12" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.st1.2.2.2.2" class="ltx_tr">
<td id="S4.T1.st1.2.2.2.2.3" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.T1.st1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="5"><span id="S4.T1.st1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Person<math id="S4.T1.st1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.st1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.st1.1.1.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.st1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.st1.1.1.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-Person</span></td>
<td id="S4.T1.st1.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S4.T1.st1.2.2.2.2.2.1" class="ltx_text ltx_font_bold">VOC<math id="S4.T1.st1.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st1.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T1.st1.2.2.2.2.2.1.m1.1.1" xref="S4.T1.st1.2.2.2.2.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st1.2.2.2.2.2.1.m1.1b"><ci id="S4.T1.st1.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.st1.2.2.2.2.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>Non-VOC</span></td>
</tr>
<tr id="S4.T1.st1.12.12.12.12" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.12.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="S4.T1.st1.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.3.3.3.3.1.1" class="ltx_sub"><span id="S4.T1.st1.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st1.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.4.4.4.4.2.1" class="ltx_sub"><span id="S4.T1.st1.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</td>
<td id="S4.T1.st1.5.5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T1.st1.5.5.5.5.3.m1.1a"><mmultiscripts id="S4.T1.st1.5.5.5.5.3.m1.1.1" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"><mi id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.5.5.5.5.3.m1.1.1a" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.5.5.5.5.3.m1.1.1b" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.5.5.5.5.3.m1.1.1.3" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.5.5.5.5.3.m1.1.1c" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.5.5.5.5.3.m1.1b"><apply id="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.5.5.5.5.3.m1.1.1.1.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.1.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T1.st1.5.5.5.5.3.m1.1.1.3.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T1.st1.6.6.6.6.4.m1.1a"><mmultiscripts id="S4.T1.st1.6.6.6.6.4.m1.1.1" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"><mi id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.6.6.6.6.4.m1.1.1a" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.6.6.6.6.4.m1.1.1b" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.6.6.6.6.4.m1.1.1.3" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.6.6.6.6.4.m1.1.1c" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.6.6.6.6.4.m1.1b"><apply id="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.6.6.6.6.4.m1.1.1.1.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.1.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T1.st1.6.6.6.6.4.m1.1.1.3.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.7.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T1.st1.7.7.7.7.5.m1.1a"><mmultiscripts id="S4.T1.st1.7.7.7.7.5.m1.1.1" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"><mi id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.7.7.7.7.5.m1.1.1a" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.7.7.7.7.5.m1.1.1b" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.7.7.7.7.5.m1.1.1.3" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.7.7.7.7.5.m1.1.1c" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.7.7.7.7.5.m1.1b"><apply id="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.7.7.7.7.5.m1.1.1.1.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.1.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T1.st1.7.7.7.7.5.m1.1.1.3.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.8.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.8.8.8.8.6.1" class="ltx_sub"><span id="S4.T1.st1.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st1.9.9.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.9.9.9.9.7.1" class="ltx_sub"><span id="S4.T1.st1.9.9.9.9.7.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</td>
<td id="S4.T1.st1.10.10.10.10.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T1.st1.10.10.10.10.8.m1.1a"><mmultiscripts id="S4.T1.st1.10.10.10.10.8.m1.1.1" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"><mi id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.10.10.10.10.8.m1.1.1a" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.10.10.10.10.8.m1.1.1b" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.10.10.10.10.8.m1.1.1.3" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.10.10.10.10.8.m1.1.1c" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.10.10.10.10.8.m1.1b"><apply id="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.10.10.10.10.8.m1.1.1.1.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.1.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T1.st1.10.10.10.10.8.m1.1.1.3.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.10.10.10.10.8.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.11.11.11.11.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T1.st1.11.11.11.11.9.m1.1a"><mmultiscripts id="S4.T1.st1.11.11.11.11.9.m1.1.1" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"><mi id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.11.11.11.11.9.m1.1.1a" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.11.11.11.11.9.m1.1.1b" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.11.11.11.11.9.m1.1.1.3" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.11.11.11.11.9.m1.1.1c" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.11.11.11.11.9.m1.1b"><apply id="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.11.11.11.11.9.m1.1.1.1.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.1.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T1.st1.11.11.11.11.9.m1.1.1.3.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.11.11.11.11.9.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.12.12.12.12.10" class="ltx_td ltx_align_left ltx_border_t">AR<math id="S4.T1.st1.12.12.12.12.10.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T1.st1.12.12.12.12.10.m1.1a"><mmultiscripts id="S4.T1.st1.12.12.12.12.10.m1.1.1" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"><mi id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.12.12.12.12.10.m1.1.1a" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.12.12.12.12.10.m1.1.1b" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.12.12.12.12.10.m1.1.1.3" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.12.12.12.12.10.m1.1.1c" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.12.12.12.12.10.m1.1b"><apply id="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.12.12.12.12.10.m1.1.1.1.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.1.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T1.st1.12.12.12.12.10.m1.1.1.3.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.12.12.12.12.10.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.st1.12.12.12.13.1" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.13.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.1.1" class="ltx_text" style="color:#808080;">FRCNN (oracle)</span></td>
<td id="S4.T1.st1.12.12.12.13.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.2.1" class="ltx_text" style="color:#808080;">55.9</span></td>
<td id="S4.T1.st1.12.12.12.13.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.3.1" class="ltx_text" style="color:#808080;">53.4</span></td>
<td id="S4.T1.st1.12.12.12.13.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.4.1" class="ltx_text" style="color:#808080;">37.9</span></td>
<td id="S4.T1.st1.12.12.12.13.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.5.1" class="ltx_text" style="color:#808080;">59.5</span></td>
<td id="S4.T1.st1.12.12.12.13.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.6.1" class="ltx_text" style="color:#808080;">73.0</span></td>
<td id="S4.T1.st1.12.12.12.13.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.7.1" class="ltx_text" style="color:#808080;">55.9</span></td>
<td id="S4.T1.st1.12.12.12.13.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.8.1" class="ltx_text" style="color:#808080;">52.6</span></td>
<td id="S4.T1.st1.12.12.12.13.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.9.1" class="ltx_text" style="color:#808080;">37.1</span></td>
<td id="S4.T1.st1.12.12.12.13.1.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.10.1" class="ltx_text" style="color:#808080;">60.0</span></td>
<td id="S4.T1.st1.12.12.12.13.1.11" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.11.1" class="ltx_text" style="color:#808080;">73.1</span></td>
</tr>
<tr id="S4.T1.st1.12.12.12.14.2" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.14.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FRCNN (cls-agn)</td>
<td id="S4.T1.st1.12.12.12.14.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.7</td>
<td id="S4.T1.st1.12.12.12.14.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.2</td>
<td id="S4.T1.st1.12.12.12.14.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8.7</td>
<td id="S4.T1.st1.12.12.12.14.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.4</td>
<td id="S4.T1.st1.12.12.12.14.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.2</td>
<td id="S4.T1.st1.12.12.12.14.2.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.5</td>
<td id="S4.T1.st1.12.12.12.14.2.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">27.3</td>
<td id="S4.T1.st1.12.12.12.14.2.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">10.8</td>
<td id="S4.T1.st1.12.12.12.14.2.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">30.2</td>
<td id="S4.T1.st1.12.12.12.14.2.11" class="ltx_td ltx_align_left ltx_border_t">55.8</td>
</tr>
<tr id="S4.T1.st1.12.12.12.15.3" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.15.3.1" class="ltx_td ltx_align_left ltx_border_r">OLNÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.st1.12.12.12.15.3.2" class="ltx_td ltx_align_left ltx_border_r">30.9</td>
<td id="S4.T1.st1.12.12.12.15.3.3" class="ltx_td ltx_align_left ltx_border_r">16.5</td>
<td id="S4.T1.st1.12.12.12.15.3.4" class="ltx_td ltx_align_left ltx_border_r">8.7</td>
<td id="S4.T1.st1.12.12.12.15.3.5" class="ltx_td ltx_align_left ltx_border_r">14.7</td>
<td id="S4.T1.st1.12.12.12.15.3.6" class="ltx_td ltx_align_left ltx_border_r">33.4</td>
<td id="S4.T1.st1.12.12.12.15.3.7" class="ltx_td ltx_align_left ltx_border_r">47.5</td>
<td id="S4.T1.st1.12.12.12.15.3.8" class="ltx_td ltx_align_left ltx_border_r">33.2</td>
<td id="S4.T1.st1.12.12.12.15.3.9" class="ltx_td ltx_align_left ltx_border_r">18.7</td>
<td id="S4.T1.st1.12.12.12.15.3.10" class="ltx_td ltx_align_left ltx_border_r">39.3</td>
<td id="S4.T1.st1.12.12.12.15.3.11" class="ltx_td ltx_align_left">58.6</td>
</tr>
<tr id="S4.T1.st1.12.12.12.16.4" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.16.4.1" class="ltx_td ltx_align_left ltx_border_r">GGNÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.st1.12.12.12.16.4.2" class="ltx_td ltx_align_left ltx_border_r">30.3</td>
<td id="S4.T1.st1.12.12.12.16.4.3" class="ltx_td ltx_align_left ltx_border_r">20.7</td>
<td id="S4.T1.st1.12.12.12.16.4.4" class="ltx_td ltx_align_left ltx_border_r">12.0</td>
<td id="S4.T1.st1.12.12.12.16.4.5" class="ltx_td ltx_align_left ltx_border_r">25.6</td>
<td id="S4.T1.st1.12.12.12.16.4.6" class="ltx_td ltx_align_left ltx_border_r">29.6</td>
<td id="S4.T1.st1.12.12.12.16.4.7" class="ltx_td ltx_align_left ltx_border_r">39.8</td>
<td id="S4.T1.st1.12.12.12.16.4.8" class="ltx_td ltx_align_left ltx_border_r">31.5</td>
<td id="S4.T1.st1.12.12.12.16.4.9" class="ltx_td ltx_align_left ltx_border_r">11.8</td>
<td id="S4.T1.st1.12.12.12.16.4.10" class="ltx_td ltx_align_left ltx_border_r">37.4</td>
<td id="S4.T1.st1.12.12.12.16.4.11" class="ltx_td ltx_align_left"><span id="S4.T1.st1.12.12.12.16.4.11.1" class="ltx_text ltx_font_bold">63.8</span></td>
</tr>
<tr id="S4.T1.st1.12.12.12.17.5" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.17.5.1" class="ltx_td ltx_align_left ltx_border_r">SelfTrain-RGB</td>
<td id="S4.T1.st1.12.12.12.17.5.2" class="ltx_td ltx_align_left ltx_border_r">32.5</td>
<td id="S4.T1.st1.12.12.12.17.5.3" class="ltx_td ltx_align_left ltx_border_r">18.7</td>
<td id="S4.T1.st1.12.12.12.17.5.4" class="ltx_td ltx_align_left ltx_border_r">11.3</td>
<td id="S4.T1.st1.12.12.12.17.5.5" class="ltx_td ltx_align_left ltx_border_r">18.6</td>
<td id="S4.T1.st1.12.12.12.17.5.6" class="ltx_td ltx_align_left ltx_border_r">32.6</td>
<td id="S4.T1.st1.12.12.12.17.5.7" class="ltx_td ltx_align_left ltx_border_r">48.1</td>
<td id="S4.T1.st1.12.12.12.17.5.8" class="ltx_td ltx_align_left ltx_border_r">37.4</td>
<td id="S4.T1.st1.12.12.12.17.5.9" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.st1.12.12.12.17.5.9.1" class="ltx_text ltx_font_bold">22.8</span></td>
<td id="S4.T1.st1.12.12.12.17.5.10" class="ltx_td ltx_align_left ltx_border_r">43.9</td>
<td id="S4.T1.st1.12.12.12.17.5.11" class="ltx_td ltx_align_left">57.7</td>
</tr>
<tr id="S4.T1.st1.12.12.12.18.6" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.18.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Depth</td>
<td id="S4.T1.st1.12.12.12.18.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.0</td>
<td id="S4.T1.st1.12.12.12.18.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.6</td>
<td id="S4.T1.st1.12.12.12.18.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.8</td>
<td id="S4.T1.st1.12.12.12.18.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">30.4</td>
<td id="S4.T1.st1.12.12.12.18.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.18.6.6.1" class="ltx_text ltx_font_bold">42.4</span></td>
<td id="S4.T1.st1.12.12.12.18.6.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.18.6.7.1" class="ltx_text ltx_font_bold">49.6</span></td>
<td id="S4.T1.st1.12.12.12.18.6.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">39.0</td>
<td id="S4.T1.st1.12.12.12.18.6.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.1</td>
<td id="S4.T1.st1.12.12.12.18.6.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.5</td>
<td id="S4.T1.st1.12.12.12.18.6.11" class="ltx_td ltx_align_left ltx_border_t">63.2</td>
</tr>
<tr id="S4.T1.st1.12.12.12.19.7" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.19.7.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Normal</td>
<td id="S4.T1.st1.12.12.12.19.7.2" class="ltx_td ltx_align_left ltx_border_r">35.6</td>
<td id="S4.T1.st1.12.12.12.19.7.3" class="ltx_td ltx_align_left ltx_border_r">23.7</td>
<td id="S4.T1.st1.12.12.12.19.7.4" class="ltx_td ltx_align_left ltx_border_r">13.9</td>
<td id="S4.T1.st1.12.12.12.19.7.5" class="ltx_td ltx_align_left ltx_border_r">27.6</td>
<td id="S4.T1.st1.12.12.12.19.7.6" class="ltx_td ltx_align_left ltx_border_r">36.0</td>
<td id="S4.T1.st1.12.12.12.19.7.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.st1.12.12.12.19.7.7.1" class="ltx_text ltx_font_bold">49.6</span></td>
<td id="S4.T1.st1.12.12.12.19.7.8" class="ltx_td ltx_align_left ltx_border_r">38.9</td>
<td id="S4.T1.st1.12.12.12.19.7.9" class="ltx_td ltx_align_left ltx_border_r">21.2</td>
<td id="S4.T1.st1.12.12.12.19.7.10" class="ltx_td ltx_align_left ltx_border_r">47.9</td>
<td id="S4.T1.st1.12.12.12.19.7.11" class="ltx_td ltx_align_left">62.0</td>
</tr>
<tr id="S4.T1.st1.12.12.12.20.8" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.20.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="S4.T1.st1.12.12.12.20.8.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.2.1" class="ltx_text ltx_font_bold">37.3</span></td>
<td id="S4.T1.st1.12.12.12.20.8.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.3.1" class="ltx_text ltx_font_bold">25.9</span></td>
<td id="S4.T1.st1.12.12.12.20.8.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.4.1" class="ltx_text ltx_font_bold">14.2</span></td>
<td id="S4.T1.st1.12.12.12.20.8.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.5.1" class="ltx_text ltx_font_bold">32.6</span></td>
<td id="S4.T1.st1.12.12.12.20.8.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">38.9</td>
<td id="S4.T1.st1.12.12.12.20.8.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">49.5</td>
<td id="S4.T1.st1.12.12.12.20.8.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.8.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="S4.T1.st1.12.12.12.20.8.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.6</td>
<td id="S4.T1.st1.12.12.12.20.8.10" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.10.1" class="ltx_text ltx_font_bold">48.2</span></td>
<td id="S4.T1.st1.12.12.12.20.8.11" class="ltx_td ltx_align_left ltx_border_bb">62.4</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(a) </span><span id="S4.T1.st1.14.1" class="ltx_text ltx_font_bold">Cross-category benchmarks</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T1.st2" class="ltx_table ltx_figure_panel">
<div id="S4.T1.st2.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:320.7pt;height:104.4pt;vertical-align:-1.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.1pt,12.9pt) scale(0.8,0.8) ;">
<div id="S4.T1.st2.10.10" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:129.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-51.3pt,16.6pt) scale(0.794727172432763,0.794727172432763) ;">
<table id="S4.T1.st2.10.10.10" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.st2.2.2.2.2" class="ltx_tr">
<td id="S4.T1.st2.2.2.2.2.3" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.T1.st2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span id="S4.T1.st2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">VOC<math id="S4.T1.st2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st2.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.st2.1.1.1.1.1.1.m1.1.1" xref="S4.T1.st2.1.1.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st2.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.st2.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.st2.1.1.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></td>
<td id="S4.T1.st2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S4.T1.st2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">COCO<math id="S4.T1.st2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T1.st2.2.2.2.2.2.1.m1.1.1" xref="S4.T1.st2.2.2.2.2.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st2.2.2.2.2.2.1.m1.1b"><ci id="S4.T1.st2.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.st2.2.2.2.2.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></td>
</tr>
<tr id="S4.T1.st2.10.10.10.10" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.10.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="S4.T1.st2.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st2.3.3.3.3.1.1" class="ltx_sub"><span id="S4.T1.st2.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st2.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.4.4.4.4.2.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="S4.T1.st2.4.4.4.4.2.m1.1a"><mmultiscripts id="S4.T1.st2.4.4.4.4.2.m1.1.1" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"><mi id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.4.4.4.4.2.m1.1.1a" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.4.4.4.4.2.m1.1.1b" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.4.4.4.4.2.m1.1.1.3" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.4.4.4.4.2.m1.1.1c" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.4.4.4.4.2.m1.1b"><apply id="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.4.4.4.4.2.m1.1.1.1.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.1.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3">ğ´</ci></apply><ci id="S4.T1.st2.4.4.4.4.2.m1.1.1.3.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.4.4.4.4.2.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.5.5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="S4.T1.st2.5.5.5.5.3.m1.1a"><mmultiscripts id="S4.T1.st2.5.5.5.5.3.m1.1.1" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"><mi id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.5.5.5.5.3.m1.1.1a" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.5.5.5.5.3.m1.1.1b" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.5.5.5.5.3.m1.1.1.3" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.5.5.5.5.3.m1.1.1c" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.5.5.5.5.3.m1.1b"><apply id="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.5.5.5.5.3.m1.1.1.1.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.1.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3">ğ´</ci></apply><ci id="S4.T1.st2.5.5.5.5.3.m1.1.1.3.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.5.5.5.5.3.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="S4.T1.st2.6.6.6.6.4.m1.1a"><mmultiscripts id="S4.T1.st2.6.6.6.6.4.m1.1.1" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"><mi id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.6.6.6.6.4.m1.1.1a" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.6.6.6.6.4.m1.1.1b" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.6.6.6.6.4.m1.1.1.3" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.6.6.6.6.4.m1.1.1c" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.6.6.6.6.4.m1.1b"><apply id="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.6.6.6.6.4.m1.1.1.1.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.1.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3">ğ´</ci></apply><ci id="S4.T1.st2.6.6.6.6.4.m1.1.1.3.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.6.6.6.6.4.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.7.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st2.7.7.7.7.5.1" class="ltx_sub"><span id="S4.T1.st2.7.7.7.7.5.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st2.8.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.8.8.8.8.6.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="S4.T1.st2.8.8.8.8.6.m1.1a"><mmultiscripts id="S4.T1.st2.8.8.8.8.6.m1.1.1" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"><mi id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.8.8.8.8.6.m1.1.1a" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.8.8.8.8.6.m1.1.1b" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.8.8.8.8.6.m1.1.1.3" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.8.8.8.8.6.m1.1.1c" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.8.8.8.8.6.m1.1b"><apply id="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.8.8.8.8.6.m1.1.1.1.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.1.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3">ğ´</ci></apply><ci id="S4.T1.st2.8.8.8.8.6.m1.1.1.3.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.8.8.8.8.6.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.9.9.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="S4.T1.st2.9.9.9.9.7.m1.1a"><mmultiscripts id="S4.T1.st2.9.9.9.9.7.m1.1.1" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"><mi id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.9.9.9.9.7.m1.1.1a" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.9.9.9.9.7.m1.1.1b" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.9.9.9.9.7.m1.1.1.3" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.9.9.9.9.7.m1.1.1c" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.9.9.9.9.7.m1.1b"><apply id="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.9.9.9.9.7.m1.1.1.1.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.1.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3">ğ´</ci></apply><ci id="S4.T1.st2.9.9.9.9.7.m1.1.1.3.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.9.9.9.9.7.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.10.10.10.10.8" class="ltx_td ltx_align_left ltx_border_t">AR<math id="S4.T1.st2.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="S4.T1.st2.10.10.10.10.8.m1.1a"><mmultiscripts id="S4.T1.st2.10.10.10.10.8.m1.1.1" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"><mi id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.10.10.10.10.8.m1.1.1a" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.10.10.10.10.8.m1.1.1b" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.10.10.10.10.8.m1.1.1.3" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.10.10.10.10.8.m1.1.1c" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.10.10.10.10.8.m1.1b"><apply id="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.10.10.10.10.8.m1.1.1.1.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.1.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3">ğ´</ci></apply><ci id="S4.T1.st2.10.10.10.10.8.m1.1.1.3.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.10.10.10.10.8.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.st2.10.10.10.11.1" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.11.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FRCNN (cls-agn)</td>
<td id="S4.T1.st2.10.10.10.11.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">22.6</td>
<td id="S4.T1.st2.10.10.10.11.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.5</td>
<td id="S4.T1.st2.10.10.10.11.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">23.7</td>
<td id="S4.T1.st2.10.10.10.11.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.5</td>
<td id="S4.T1.st2.10.10.10.11.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.9</td>
<td id="S4.T1.st2.10.10.10.11.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20.5</td>
<td id="S4.T1.st2.10.10.10.11.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.5</td>
<td id="S4.T1.st2.10.10.10.11.1.9" class="ltx_td ltx_align_left ltx_border_t">27.4</td>
</tr>
<tr id="S4.T1.st2.10.10.10.12.2" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.12.2.1" class="ltx_td ltx_align_left ltx_border_r">OLNÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.st2.10.10.10.12.2.2" class="ltx_td ltx_align_left ltx_border_r">29.2</td>
<td id="S4.T1.st2.10.10.10.12.2.3" class="ltx_td ltx_align_left ltx_border_r">19.7</td>
<td id="S4.T1.st2.10.10.10.12.2.4" class="ltx_td ltx_align_left ltx_border_r">30.7</td>
<td id="S4.T1.st2.10.10.10.12.2.5" class="ltx_td ltx_align_left ltx_border_r">34.4</td>
<td id="S4.T1.st2.10.10.10.12.2.6" class="ltx_td ltx_align_left ltx_border_r">32.9</td>
<td id="S4.T1.st2.10.10.10.12.2.7" class="ltx_td ltx_align_left ltx_border_r">25.1</td>
<td id="S4.T1.st2.10.10.10.12.2.8" class="ltx_td ltx_align_left ltx_border_r">35.9</td>
<td id="S4.T1.st2.10.10.10.12.2.9" class="ltx_td ltx_align_left">35.6</td>
</tr>
<tr id="S4.T1.st2.10.10.10.13.3" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.13.3.1" class="ltx_td ltx_align_left ltx_border_r">GGNÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.st2.10.10.10.13.3.2" class="ltx_td ltx_align_left ltx_border_r">27.0</td>
<td id="S4.T1.st2.10.10.10.13.3.3" class="ltx_td ltx_align_left ltx_border_r">16.9</td>
<td id="S4.T1.st2.10.10.10.13.3.4" class="ltx_td ltx_align_left ltx_border_r">27.5</td>
<td id="S4.T1.st2.10.10.10.13.3.5" class="ltx_td ltx_align_left ltx_border_r">33.6</td>
<td id="S4.T1.st2.10.10.10.13.3.6" class="ltx_td ltx_align_left ltx_border_r">29.8</td>
<td id="S4.T1.st2.10.10.10.13.3.7" class="ltx_td ltx_align_left ltx_border_r">18.9</td>
<td id="S4.T1.st2.10.10.10.13.3.8" class="ltx_td ltx_align_left ltx_border_r">29.1</td>
<td id="S4.T1.st2.10.10.10.13.3.9" class="ltx_td ltx_align_left">38.2</td>
</tr>
<tr id="S4.T1.st2.10.10.10.14.4" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.14.4.1" class="ltx_td ltx_align_left ltx_border_r">SelfTrain-RGB</td>
<td id="S4.T1.st2.10.10.10.14.4.2" class="ltx_td ltx_align_left ltx_border_r">27.7</td>
<td id="S4.T1.st2.10.10.10.14.4.3" class="ltx_td ltx_align_left ltx_border_r">18.4</td>
<td id="S4.T1.st2.10.10.10.14.4.4" class="ltx_td ltx_align_left ltx_border_r">29.7</td>
<td id="S4.T1.st2.10.10.10.14.4.5" class="ltx_td ltx_align_left ltx_border_r">32.4</td>
<td id="S4.T1.st2.10.10.10.14.4.6" class="ltx_td ltx_align_left ltx_border_r">33.8</td>
<td id="S4.T1.st2.10.10.10.14.4.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.st2.10.10.10.14.4.7.1" class="ltx_text ltx_font_bold">26.5</span></td>
<td id="S4.T1.st2.10.10.10.14.4.8" class="ltx_td ltx_align_left ltx_border_r">37.6</td>
<td id="S4.T1.st2.10.10.10.14.4.9" class="ltx_td ltx_align_left">35.4</td>
</tr>
<tr id="S4.T1.st2.10.10.10.15.5" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.15.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Depth</td>
<td id="S4.T1.st2.10.10.10.15.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">33.9</td>
<td id="S4.T1.st2.10.10.10.15.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.1</td>
<td id="S4.T1.st2.10.10.10.15.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.9</td>
<td id="S4.T1.st2.10.10.10.15.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">41.2</td>
<td id="S4.T1.st2.10.10.10.15.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st2.10.10.10.15.5.6.1" class="ltx_text ltx_font_bold">35.3</span></td>
<td id="S4.T1.st2.10.10.10.15.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.7</td>
<td id="S4.T1.st2.10.10.10.15.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.0</td>
<td id="S4.T1.st2.10.10.10.15.5.9" class="ltx_td ltx_align_left ltx_border_t">39.6</td>
</tr>
<tr id="S4.T1.st2.10.10.10.16.6" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.16.6.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Normal</td>
<td id="S4.T1.st2.10.10.10.16.6.2" class="ltx_td ltx_align_left ltx_border_r">33.4</td>
<td id="S4.T1.st2.10.10.10.16.6.3" class="ltx_td ltx_align_left ltx_border_r">22.0</td>
<td id="S4.T1.st2.10.10.10.16.6.4" class="ltx_td ltx_align_left ltx_border_r">36.2</td>
<td id="S4.T1.st2.10.10.10.16.6.5" class="ltx_td ltx_align_left ltx_border_r">38.8</td>
<td id="S4.T1.st2.10.10.10.16.6.6" class="ltx_td ltx_align_left ltx_border_r">33.5</td>
<td id="S4.T1.st2.10.10.10.16.6.7" class="ltx_td ltx_align_left ltx_border_r">25.7</td>
<td id="S4.T1.st2.10.10.10.16.6.8" class="ltx_td ltx_align_left ltx_border_r">37.1</td>
<td id="S4.T1.st2.10.10.10.16.6.9" class="ltx_td ltx_align_left">35.5</td>
</tr>
<tr id="S4.T1.st2.10.10.10.17.7" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.17.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="S4.T1.st2.10.10.10.17.7.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.2.1" class="ltx_text ltx_font_bold">34.0</span></td>
<td id="S4.T1.st2.10.10.10.17.7.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.9</td>
<td id="S4.T1.st2.10.10.10.17.7.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.4.1" class="ltx_text ltx_font_bold">37.0</span></td>
<td id="S4.T1.st2.10.10.10.17.7.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.5.1" class="ltx_text ltx_font_bold">39.9</span></td>
<td id="S4.T1.st2.10.10.10.17.7.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.6.1" class="ltx_text ltx_font_bold">35.3</span></td>
<td id="S4.T1.st2.10.10.10.17.7.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">25.1</td>
<td id="S4.T1.st2.10.10.10.17.7.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">38.2</td>
<td id="S4.T1.st2.10.10.10.17.7.9" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T1.st2.10.10.10.17.7.9.1" class="ltx_text ltx_font_bold">39.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(b) </span><span id="S4.T1.st2.12.1" class="ltx_text ltx_font_bold">Cross-dataset benchmarks</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S4.T1.15.1" class="ltx_text ltx_font_bold">Detecting unknown objects in an open world.</span> <math id="S4.T1.7.m1.1" class="ltx_Math" alttext="\mathrm{FRCNN\text{ }(oracle)}" display="inline"><semantics id="S4.T1.7.m1.1b"><mrow id="S4.T1.7.m1.1.2" xref="S4.T1.7.m1.1.2.cmml"><mi id="S4.T1.7.m1.1.2.2" xref="S4.T1.7.m1.1.2.2.cmml">FRCNN</mi><mo lspace="0em" rspace="0em" id="S4.T1.7.m1.1.2.1" xref="S4.T1.7.m1.1.2.1.cmml">â€‹</mo><mtext id="S4.T1.7.m1.1.2.3" xref="S4.T1.7.m1.1.2.3a.cmml">Â </mtext><mo lspace="0em" rspace="0em" id="S4.T1.7.m1.1.2.1b" xref="S4.T1.7.m1.1.2.1.cmml">â€‹</mo><mrow id="S4.T1.7.m1.1.2.4.2" xref="S4.T1.7.m1.1.2.cmml"><mo stretchy="false" id="S4.T1.7.m1.1.2.4.2.1" xref="S4.T1.7.m1.1.2.cmml">(</mo><mi id="S4.T1.7.m1.1.1" xref="S4.T1.7.m1.1.1.cmml">oracle</mi><mo stretchy="false" id="S4.T1.7.m1.1.2.4.2.2" xref="S4.T1.7.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.m1.1c"><apply id="S4.T1.7.m1.1.2.cmml" xref="S4.T1.7.m1.1.2"><times id="S4.T1.7.m1.1.2.1.cmml" xref="S4.T1.7.m1.1.2.1"></times><ci id="S4.T1.7.m1.1.2.2.cmml" xref="S4.T1.7.m1.1.2.2">FRCNN</ci><ci id="S4.T1.7.m1.1.2.3a.cmml" xref="S4.T1.7.m1.1.2.3"><mtext id="S4.T1.7.m1.1.2.3.cmml" xref="S4.T1.7.m1.1.2.3">Â </mtext></ci><ci id="S4.T1.7.m1.1.1.cmml" xref="S4.T1.7.m1.1.1">oracle</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.m1.1d">\mathrm{FRCNN\text{ }(oracle)}</annotation></semantics></math> is a standard Faster R-CNN detector trained on all COCO classes and serves as a performance upper bound on the cross-category benchmarks.
<math id="S4.T1.8.m2.1" class="ltx_Math" alttext="\mathrm{FRCNN\text{ }(cls\text{-}agn)}" display="inline"><semantics id="S4.T1.8.m2.1b"><mrow id="S4.T1.8.m2.1.1" xref="S4.T1.8.m2.1.1.cmml"><mi id="S4.T1.8.m2.1.1.3" xref="S4.T1.8.m2.1.1.3.cmml">FRCNN</mi><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.2" xref="S4.T1.8.m2.1.1.2.cmml">â€‹</mo><mtext id="S4.T1.8.m2.1.1.4" xref="S4.T1.8.m2.1.1.4a.cmml">Â </mtext><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.2b" xref="S4.T1.8.m2.1.1.2.cmml">â€‹</mo><mrow id="S4.T1.8.m2.1.1.1.1" xref="S4.T1.8.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.T1.8.m2.1.1.1.1.2" xref="S4.T1.8.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.T1.8.m2.1.1.1.1.1" xref="S4.T1.8.m2.1.1.1.1.1.cmml"><mi id="S4.T1.8.m2.1.1.1.1.1.2" xref="S4.T1.8.m2.1.1.1.1.1.2.cmml">cls</mi><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.1.1.1.1" xref="S4.T1.8.m2.1.1.1.1.1.1.cmml">â€‹</mo><mtext id="S4.T1.8.m2.1.1.1.1.1.3" xref="S4.T1.8.m2.1.1.1.1.1.3a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.1.1.1.1b" xref="S4.T1.8.m2.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S4.T1.8.m2.1.1.1.1.1.4" xref="S4.T1.8.m2.1.1.1.1.1.4.cmml">agn</mi></mrow><mo stretchy="false" id="S4.T1.8.m2.1.1.1.1.3" xref="S4.T1.8.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.m2.1c"><apply id="S4.T1.8.m2.1.1.cmml" xref="S4.T1.8.m2.1.1"><times id="S4.T1.8.m2.1.1.2.cmml" xref="S4.T1.8.m2.1.1.2"></times><ci id="S4.T1.8.m2.1.1.3.cmml" xref="S4.T1.8.m2.1.1.3">FRCNN</ci><ci id="S4.T1.8.m2.1.1.4a.cmml" xref="S4.T1.8.m2.1.1.4"><mtext id="S4.T1.8.m2.1.1.4.cmml" xref="S4.T1.8.m2.1.1.4">Â </mtext></ci><apply id="S4.T1.8.m2.1.1.1.1.1.cmml" xref="S4.T1.8.m2.1.1.1.1"><times id="S4.T1.8.m2.1.1.1.1.1.1.cmml" xref="S4.T1.8.m2.1.1.1.1.1.1"></times><ci id="S4.T1.8.m2.1.1.1.1.1.2.cmml" xref="S4.T1.8.m2.1.1.1.1.1.2">cls</ci><ci id="S4.T1.8.m2.1.1.1.1.1.3a.cmml" xref="S4.T1.8.m2.1.1.1.1.1.3"><mtext id="S4.T1.8.m2.1.1.1.1.1.3.cmml" xref="S4.T1.8.m2.1.1.1.1.1.3">-</mtext></ci><ci id="S4.T1.8.m2.1.1.1.1.1.4.cmml" xref="S4.T1.8.m2.1.1.1.1.1.4">agn</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.m2.1d">\mathrm{FRCNN\text{ }(cls\text{-}agn)}</annotation></semantics></math> is a Faster R-CNN trained in a class-agnostic manner, serving as a baseline for comparison.
Our geometry-guided methods <math id="S4.T1.9.m3.1" class="ltx_Math" alttext="\mathrm{GOOD}" display="inline"><semantics id="S4.T1.9.m3.1b"><mi id="S4.T1.9.m3.1.1" xref="S4.T1.9.m3.1.1.cmml">GOOD</mi><annotation-xml encoding="MathML-Content" id="S4.T1.9.m3.1c"><ci id="S4.T1.9.m3.1.1.cmml" xref="S4.T1.9.m3.1.1">GOOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.m3.1d">\mathrm{GOOD}</annotation></semantics></math>-<math id="S4.T1.10.m4.1" class="ltx_Math" alttext="\mathrm{X}" display="inline"><semantics id="S4.T1.10.m4.1b"><mi mathvariant="normal" id="S4.T1.10.m4.1.1" xref="S4.T1.10.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.T1.10.m4.1c"><ci id="S4.T1.10.m4.1.1.cmml" xref="S4.T1.10.m4.1.1">X</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.m4.1d">\mathrm{X}</annotation></semantics></math>s are compared with SOTA open-world class-agnostic object detectors, i.e., OLN and GGN. <math id="S4.T1.11.m5.1" class="ltx_Math" alttext="\mathrm{SelfTrain\text{-}RGB}" display="inline"><semantics id="S4.T1.11.m5.1b"><mrow id="S4.T1.11.m5.1.1" xref="S4.T1.11.m5.1.1.cmml"><mi id="S4.T1.11.m5.1.1.2" xref="S4.T1.11.m5.1.1.2.cmml">SelfTrain</mi><mo lspace="0em" rspace="0em" id="S4.T1.11.m5.1.1.1" xref="S4.T1.11.m5.1.1.1.cmml">â€‹</mo><mtext id="S4.T1.11.m5.1.1.3" xref="S4.T1.11.m5.1.1.3a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S4.T1.11.m5.1.1.1b" xref="S4.T1.11.m5.1.1.1.cmml">â€‹</mo><mi id="S4.T1.11.m5.1.1.4" xref="S4.T1.11.m5.1.1.4.cmml">RGB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.11.m5.1c"><apply id="S4.T1.11.m5.1.1.cmml" xref="S4.T1.11.m5.1.1"><times id="S4.T1.11.m5.1.1.1.cmml" xref="S4.T1.11.m5.1.1.1"></times><ci id="S4.T1.11.m5.1.1.2.cmml" xref="S4.T1.11.m5.1.1.2">SelfTrain</ci><ci id="S4.T1.11.m5.1.1.3a.cmml" xref="S4.T1.11.m5.1.1.3"><mtext id="S4.T1.11.m5.1.1.3.cmml" xref="S4.T1.11.m5.1.1.3">-</mtext></ci><ci id="S4.T1.11.m5.1.1.4.cmml" xref="S4.T1.11.m5.1.1.4">RGB</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.m5.1d">\mathrm{SelfTrain\text{-}RGB}</annotation></semantics></math> is RGB-based self-training, i.e., using the RGB image instead of geometric cues for pseudo labeling. We only report AR<sub id="S4.T1.16.2" class="ltx_sub"><span id="S4.T1.16.2.1" class="ltx_text ltx_font_italic">A</span></sub> in b) as the classes in ADE20K do not exactly match those in COCO.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.5" class="ltx_p">On the cross-category benchmarks shown in TableÂ <a href="#S4.T1.st1" title="In Table 1 â€£ 4.1 Detecting unknown objects in an open world â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>, with a single training class â€œpersonâ€ on the COCO dataset, GOOD can surpass SOTA methods by 5.0% AR<sub id="S4.SS1.p2.5.1" class="ltx_sub"><span id="S4.SS1.p2.5.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 on detecting objects from non-person classes, a relative improvement of 24%. With 20 PASCAL-VOC classes for training, GOOD surpasses SOTA methods by 6.1% AR<sub id="S4.SS1.p2.5.2" class="ltx_sub"><span id="S4.SS1.p2.5.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100 in detecting non-VOC classes, a relative improvement over 18%. On the cross-dataset benchmarks, TableÂ <a href="#S4.T1.st2" title="In Table 1 â€£ 4.1 Detecting unknown objects in an open world â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> shows that GOOD achieves 2.4% to 4.7% gain on AR<sub id="S4.SS1.p2.5.3" class="ltx_sub"><span id="S4.SS1.p2.5.3.1" class="ltx_text ltx_font_italic">A</span></sub>@100 in different setups. We observe that GOOD is particularly strong when there are fewer training classes, i.e., person <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mo stretchy="false" id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\rightarrow</annotation></semantics></math> non-person and VOC <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mo stretchy="false" id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><ci id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">\rightarrow</annotation></semantics></math> ADE20k. For RGB-based methods, the overfitting problems become more severe as the object diversity from the base classes reduces. In contrast, the geometric cues can still detect novel-looking objects, which are particularly helpful to training with only a limited number of base class annotations. Finally, ensembling both geometric cues offers additional performance gains.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Advantages of geometric cues</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Geometric cues are less sensitive to appearance shifts across classes.</span>
We first compare per-novel-class AR@5 of the object proposal network trained on geometric cues with that trained on the RGB image. Here, AR@5 is of interest as geometric cues are used to discover novel-looking objects during Phase-I and no more than five pseudo boxes per image will be used in Phase-II, see FigureÂ <a href="#S2.F3" title="Figure 3 â€£ 2 Related work â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that geometric cues can achieve much higher per-novel-class AR@5 than RGB in many categories. An example is the novel supercategory â€œfoodâ€, including classes such as â€œhot dogâ€ and â€œsandwichâ€. The base classes, belonging to the supercategory â€œpersonâ€, â€œanimalâ€, â€œvehicleâ€, and â€œindoorâ€, have very different appearances to the â€œfoodâ€ supercategory. The RGB-based model has difficulty detecting food using appearance cues.
In contrast, the geometric cues can generalize across supercategories.
For categories that geometric cues are worse than RGB, we find that they typically are of small sizes, such as knives, forks, and clocks. This shows that while abstracting away appearance details, geometric cues may also lose some information about small objects. This again shows complementariness of RGB and geometric cues.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2212.11720/assets/iclr2023/figures/fig4/ar5_novel_pseudo_boxes_depth_normal_line_only.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S4.F4.4.1" class="ltx_text ltx_font_bold">Per-novel-class AR@5 difference comparison of pseudo boxes on COCO VOC <math id="S4.F4.4.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F4.4.1.m1.1b"><mo stretchy="false" id="S4.F4.4.1.m1.1.1" xref="S4.F4.4.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.F4.4.1.m1.1c"><ci id="S4.F4.4.1.m1.1.1.cmml" xref="S4.F4.4.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.1.m1.1d">\rightarrow</annotation></semantics></math> Non-VOC</span>. We train the object proposal network on the geometric cues (Phase-I in FigureÂ <a href="#S2.F3" title="Figure 3 â€£ 2 Related work â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) and also directly on the RGB image. We show their per-novel-class AR@5 differences, which is defined as <math id="S4.F4.5.m1.1" class="ltx_Math" alttext="(\text{AR}_{\text{X}}-\text{AR}_{\text{RGB}})/\text{AR}_{\text{RGB}}" display="inline"><semantics id="S4.F4.5.m1.1b"><mrow id="S4.F4.5.m1.1.1" xref="S4.F4.5.m1.1.1.cmml"><mrow id="S4.F4.5.m1.1.1.1.1" xref="S4.F4.5.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.F4.5.m1.1.1.1.1.2" xref="S4.F4.5.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.F4.5.m1.1.1.1.1.1" xref="S4.F4.5.m1.1.1.1.1.1.cmml"><msub id="S4.F4.5.m1.1.1.1.1.1.2" xref="S4.F4.5.m1.1.1.1.1.1.2.cmml"><mtext id="S4.F4.5.m1.1.1.1.1.1.2.2" xref="S4.F4.5.m1.1.1.1.1.1.2.2a.cmml">AR</mtext><mtext id="S4.F4.5.m1.1.1.1.1.1.2.3" xref="S4.F4.5.m1.1.1.1.1.1.2.3a.cmml">X</mtext></msub><mo id="S4.F4.5.m1.1.1.1.1.1.1" xref="S4.F4.5.m1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S4.F4.5.m1.1.1.1.1.1.3" xref="S4.F4.5.m1.1.1.1.1.1.3.cmml"><mtext id="S4.F4.5.m1.1.1.1.1.1.3.2" xref="S4.F4.5.m1.1.1.1.1.1.3.2a.cmml">AR</mtext><mtext id="S4.F4.5.m1.1.1.1.1.1.3.3" xref="S4.F4.5.m1.1.1.1.1.1.3.3a.cmml">RGB</mtext></msub></mrow><mo stretchy="false" id="S4.F4.5.m1.1.1.1.1.3" xref="S4.F4.5.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.F4.5.m1.1.1.2" xref="S4.F4.5.m1.1.1.2.cmml">/</mo><msub id="S4.F4.5.m1.1.1.3" xref="S4.F4.5.m1.1.1.3.cmml"><mtext id="S4.F4.5.m1.1.1.3.2" xref="S4.F4.5.m1.1.1.3.2a.cmml">AR</mtext><mtext id="S4.F4.5.m1.1.1.3.3" xref="S4.F4.5.m1.1.1.3.3a.cmml">RGB</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.5.m1.1c"><apply id="S4.F4.5.m1.1.1.cmml" xref="S4.F4.5.m1.1.1"><divide id="S4.F4.5.m1.1.1.2.cmml" xref="S4.F4.5.m1.1.1.2"></divide><apply id="S4.F4.5.m1.1.1.1.1.1.cmml" xref="S4.F4.5.m1.1.1.1.1"><minus id="S4.F4.5.m1.1.1.1.1.1.1.cmml" xref="S4.F4.5.m1.1.1.1.1.1.1"></minus><apply id="S4.F4.5.m1.1.1.1.1.1.2.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.1.1.1.2.1.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.F4.5.m1.1.1.1.1.1.2.2a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.2"><mtext id="S4.F4.5.m1.1.1.1.1.1.2.2.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.2">AR</mtext></ci><ci id="S4.F4.5.m1.1.1.1.1.1.2.3a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S4.F4.5.m1.1.1.1.1.1.2.3.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.3">X</mtext></ci></apply><apply id="S4.F4.5.m1.1.1.1.1.1.3.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.1.1.1.3.1.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.F4.5.m1.1.1.1.1.1.3.2a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.2"><mtext id="S4.F4.5.m1.1.1.1.1.1.3.2.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.2">AR</mtext></ci><ci id="S4.F4.5.m1.1.1.1.1.1.3.3a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S4.F4.5.m1.1.1.1.1.1.3.3.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.3">RGB</mtext></ci></apply></apply><apply id="S4.F4.5.m1.1.1.3.cmml" xref="S4.F4.5.m1.1.1.3"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.3.1.cmml" xref="S4.F4.5.m1.1.1.3">subscript</csymbol><ci id="S4.F4.5.m1.1.1.3.2a.cmml" xref="S4.F4.5.m1.1.1.3.2"><mtext id="S4.F4.5.m1.1.1.3.2.cmml" xref="S4.F4.5.m1.1.1.3.2">AR</mtext></ci><ci id="S4.F4.5.m1.1.1.3.3a.cmml" xref="S4.F4.5.m1.1.1.3.3"><mtext mathsize="70%" id="S4.F4.5.m1.1.1.3.3.cmml" xref="S4.F4.5.m1.1.1.3.3">RGB</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.5.m1.1d">(\text{AR}_{\text{X}}-\text{AR}_{\text{RGB}})/\text{AR}_{\text{RGB}}</annotation></semantics></math> with <math id="S4.F4.6.m2.2" class="ltx_Math" alttext="\text{X}\in\{\text{Depth},\text{Normal}\}" display="inline"><semantics id="S4.F4.6.m2.2b"><mrow id="S4.F4.6.m2.2.3" xref="S4.F4.6.m2.2.3.cmml"><mtext id="S4.F4.6.m2.2.3.2" xref="S4.F4.6.m2.2.3.2a.cmml">X</mtext><mo id="S4.F4.6.m2.2.3.1" xref="S4.F4.6.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S4.F4.6.m2.2.3.3.2" xref="S4.F4.6.m2.2.3.3.1.cmml"><mo stretchy="false" id="S4.F4.6.m2.2.3.3.2.1" xref="S4.F4.6.m2.2.3.3.1.cmml">{</mo><mtext id="S4.F4.6.m2.1.1" xref="S4.F4.6.m2.1.1a.cmml">Depth</mtext><mo id="S4.F4.6.m2.2.3.3.2.2" xref="S4.F4.6.m2.2.3.3.1.cmml">,</mo><mtext id="S4.F4.6.m2.2.2" xref="S4.F4.6.m2.2.2a.cmml">Normal</mtext><mo stretchy="false" id="S4.F4.6.m2.2.3.3.2.3" xref="S4.F4.6.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.6.m2.2c"><apply id="S4.F4.6.m2.2.3.cmml" xref="S4.F4.6.m2.2.3"><in id="S4.F4.6.m2.2.3.1.cmml" xref="S4.F4.6.m2.2.3.1"></in><ci id="S4.F4.6.m2.2.3.2a.cmml" xref="S4.F4.6.m2.2.3.2"><mtext id="S4.F4.6.m2.2.3.2.cmml" xref="S4.F4.6.m2.2.3.2">X</mtext></ci><set id="S4.F4.6.m2.2.3.3.1.cmml" xref="S4.F4.6.m2.2.3.3.2"><ci id="S4.F4.6.m2.1.1a.cmml" xref="S4.F4.6.m2.1.1"><mtext id="S4.F4.6.m2.1.1.cmml" xref="S4.F4.6.m2.1.1">Depth</mtext></ci><ci id="S4.F4.6.m2.2.2a.cmml" xref="S4.F4.6.m2.2.2"><mtext id="S4.F4.6.m2.2.2.cmml" xref="S4.F4.6.m2.2.2">Normal</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.m2.2d">\text{X}\in\{\text{Depth},\text{Normal}\}</annotation></semantics></math>. The geometric cues outperform the RGB image on those classes above the zero difference line. We also highlight some classes where RGB and geometric cues have big differences.
</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Geometric cues are better than edges and pairwise affinities.</span>
We further compare the geometric cues with two other mid-level representations: 2D edge and PA.
The 2D edge map is extracted using the Holistically-nested Edge Detection (HED) modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Xie &amp; Tu, <a href="#bib.bib45" title="" class="ltx_ref">2015</a>)</cite>, which shows more robust performance across the datasets than more recent methods. The HED model is trained on the Berkeley Segmentation Dataset and Benchmark (BSDS500) datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Arbelaez etÂ al., <a href="#bib.bib3" title="" class="ltx_ref">2011</a>)</cite> which contains 500 images with segmentation annotations. PA can be thought of as a learned object boundary predictor.Â <cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> trained it directly on RGB images and then grouped the predictions into object masks using a combination of traditional grouping methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Shi &amp; Malik, <a href="#bib.bib39" title="" class="ltx_ref">2000</a>; ArbelÃ¡ez, <a href="#bib.bib2" title="" class="ltx_ref">2006</a>; ArbelÃ¡ez etÂ al., <a href="#bib.bib1" title="" class="ltx_ref">2014</a>)</cite>.
We compare these four data modalities as the source of pseudo labeling.
From TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we can see that depth and normals outperform 2D edge and PA on detecting novel objects.
We speculate that this is because 2D edge and PA mainly capture object boundaries, whereas depth and normals have an extra spatial understanding of the scene and can thus better detect objects in complex scenes.
Owing to their better pseudo labels, GOOD-Depth/Normal outperform GOOD-Edge/PA on the final AR<sub id="S4.SS2.p3.1.2" class="ltx_sub"><span id="S4.SS2.p3.1.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100, i.e., 39.0%/38.9% vs. 38.1%/37.1%, see AppendixÂ <a href="#A4" title="Appendix D More discussion on different modalities for GOOD â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.5.5" class="ltx_tr">
<th id="S4.T2.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Modality</th>
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T2.1.1.1.1" class="ltx_sub"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_italic">N</span></sub> @ 1</th>
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T2.2.2.2.1" class="ltx_sub"><span id="S4.T2.2.2.2.1.1" class="ltx_text ltx_font_italic">N</span></sub> @ 5</th>
<th id="S4.T2.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T2.3.3.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><mmultiscripts id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.m1.1.1.2.2" xref="S4.T2.3.3.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T2.3.3.3.m1.1.1a" xref="S4.T2.3.3.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T2.3.3.3.m1.1.1b" xref="S4.T2.3.3.3.m1.1.1.cmml"></mrow><mi id="S4.T2.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.m1.1.1.3.cmml">s</mi><mi id="S4.T2.3.3.3.m1.1.1.2.3" xref="S4.T2.3.3.3.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T2.3.3.3.m1.1.1c" xref="S4.T2.3.3.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">superscript</csymbol><apply id="S4.T2.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.2.1.cmml" xref="S4.T2.3.3.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T2.3.3.3.m1.1.1.2.2.cmml" xref="S4.T2.3.3.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T2.3.3.3.m1.1.1.2.3.cmml" xref="S4.T2.3.3.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T2.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">{}_{N}^{s}</annotation></semantics></math> @ 5</th>
<th id="S4.T2.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T2.4.4.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T2.4.4.4.m1.1a"><mmultiscripts id="S4.T2.4.4.4.m1.1.1" xref="S4.T2.4.4.4.m1.1.1.cmml"><mi id="S4.T2.4.4.4.m1.1.1.2.2" xref="S4.T2.4.4.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T2.4.4.4.m1.1.1a" xref="S4.T2.4.4.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T2.4.4.4.m1.1.1b" xref="S4.T2.4.4.4.m1.1.1.cmml"></mrow><mi id="S4.T2.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.m1.1.1.3.cmml">m</mi><mi id="S4.T2.4.4.4.m1.1.1.2.3" xref="S4.T2.4.4.4.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T2.4.4.4.m1.1.1c" xref="S4.T2.4.4.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">superscript</csymbol><apply id="S4.T2.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.m1.1.1.2.1.cmml" xref="S4.T2.4.4.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T2.4.4.4.m1.1.1.2.2.cmml" xref="S4.T2.4.4.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T2.4.4.4.m1.1.1.2.3.cmml" xref="S4.T2.4.4.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T2.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">{}_{N}^{m}</annotation></semantics></math> @ 5</th>
<th id="S4.T2.5.5.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AR<math id="S4.T2.5.5.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T2.5.5.5.m1.1a"><mmultiscripts id="S4.T2.5.5.5.m1.1.1" xref="S4.T2.5.5.5.m1.1.1.cmml"><mi id="S4.T2.5.5.5.m1.1.1.2.2" xref="S4.T2.5.5.5.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T2.5.5.5.m1.1.1a" xref="S4.T2.5.5.5.m1.1.1.cmml"></mprescripts><mrow id="S4.T2.5.5.5.m1.1.1b" xref="S4.T2.5.5.5.m1.1.1.cmml"></mrow><mi id="S4.T2.5.5.5.m1.1.1.3" xref="S4.T2.5.5.5.m1.1.1.3.cmml">l</mi><mi id="S4.T2.5.5.5.m1.1.1.2.3" xref="S4.T2.5.5.5.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T2.5.5.5.m1.1.1c" xref="S4.T2.5.5.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.m1.1b"><apply id="S4.T2.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.m1.1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1">superscript</csymbol><apply id="S4.T2.5.5.5.m1.1.1.2.cmml" xref="S4.T2.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.m1.1.1.2.1.cmml" xref="S4.T2.5.5.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T2.5.5.5.m1.1.1.2.2.cmml" xref="S4.T2.5.5.5.m1.1.1.2.2">absent</csymbol><ci id="S4.T2.5.5.5.m1.1.1.2.3.cmml" xref="S4.T2.5.5.5.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T2.5.5.5.m1.1.1.3.cmml" xref="S4.T2.5.5.5.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>@5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.5.6.1" class="ltx_tr">
<td id="S4.T2.5.6.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RGB</td>
<td id="S4.T2.5.6.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4.0</td>
<td id="S4.T2.5.6.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.6</td>
<td id="S4.T2.5.6.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T2.5.6.1.4.1" class="ltx_text ltx_font_bold">5.4</span></td>
<td id="S4.T2.5.6.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">16.4</td>
<td id="S4.T2.5.6.1.6" class="ltx_td ltx_align_left ltx_border_t">21.8</td>
</tr>
<tr id="S4.T2.5.7.2" class="ltx_tr">
<td id="S4.T2.5.7.2.1" class="ltx_td ltx_align_left ltx_border_r">Depth</td>
<td id="S4.T2.5.7.2.2" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.5.7.2.2.1" class="ltx_text ltx_font_bold">4.7</span></td>
<td id="S4.T2.5.7.2.3" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.5.7.2.3.1" class="ltx_text ltx_font_bold">13.2</span></td>
<td id="S4.T2.5.7.2.4" class="ltx_td ltx_align_left ltx_border_r">2.4</td>
<td id="S4.T2.5.7.2.5" class="ltx_td ltx_align_left ltx_border_r">16.0</td>
<td id="S4.T2.5.7.2.6" class="ltx_td ltx_align_left"><span id="S4.T2.5.7.2.6.1" class="ltx_text ltx_font_bold">31.6</span></td>
</tr>
<tr id="S4.T2.5.8.3" class="ltx_tr">
<td id="S4.T2.5.8.3.1" class="ltx_td ltx_align_left ltx_border_r">Normal</td>
<td id="S4.T2.5.8.3.2" class="ltx_td ltx_align_left ltx_border_r">4.3</td>
<td id="S4.T2.5.8.3.3" class="ltx_td ltx_align_left ltx_border_r">12.8</td>
<td id="S4.T2.5.8.3.4" class="ltx_td ltx_align_left ltx_border_r">3.0</td>
<td id="S4.T2.5.8.3.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.5.8.3.5.1" class="ltx_text ltx_font_bold">16.6</span></td>
<td id="S4.T2.5.8.3.6" class="ltx_td ltx_align_left">27.7</td>
</tr>
<tr id="S4.T2.5.9.4" class="ltx_tr">
<td id="S4.T2.5.9.4.1" class="ltx_td ltx_align_left ltx_border_r">Edge</td>
<td id="S4.T2.5.9.4.2" class="ltx_td ltx_align_left ltx_border_r">3.2</td>
<td id="S4.T2.5.9.4.3" class="ltx_td ltx_align_left ltx_border_r">10.4</td>
<td id="S4.T2.5.9.4.4" class="ltx_td ltx_align_left ltx_border_r">3.5</td>
<td id="S4.T2.5.9.4.5" class="ltx_td ltx_align_left ltx_border_r">14.5</td>
<td id="S4.T2.5.9.4.6" class="ltx_td ltx_align_left">18.5</td>
</tr>
<tr id="S4.T2.5.10.5" class="ltx_tr">
<td id="S4.T2.5.10.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Pairwise affinity (PA)</td>
<td id="S4.T2.5.10.5.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">3.2</td>
<td id="S4.T2.5.10.5.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">8.1</td>
<td id="S4.T2.5.10.5.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">0.5</td>
<td id="S4.T2.5.10.5.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">9.1</td>
<td id="S4.T2.5.10.5.6" class="ltx_td ltx_align_left ltx_border_bb">30.6</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S4.T2.12.1" class="ltx_text ltx_font_bold">Comparison on different data modalities for pseudo labeling</span>. We report AR<sub id="S4.T2.13.2" class="ltx_sub"><span id="S4.T2.13.2.1" class="ltx_text ltx_font_italic">N</span></sub>@k achieved by the object proposal network trained on different modalities in Phase-I, where the benchmark is VOC <math id="S4.T2.9.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T2.9.m2.1b"><mo stretchy="false" id="S4.T2.9.m2.1.1" xref="S4.T2.9.m2.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.m2.1c"><ci id="S4.T2.9.m2.1.1.cmml" xref="S4.T2.9.m2.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.m2.1d">\rightarrow</annotation></semantics></math> Non-VOC. Geometric cues (depth and normal) are stronger in discovering novel objects than the edge and pairwise affinityÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>.</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S4.T3.7.1" class="ltx_text ltx_font_bold">Comparison of GOOD and two other strategies on VOC to non-VOC</span>. ShapeBias replaced the backbone of SelfTrain-RGB with a stylized ImageNet pre-trained backbone. ScaleAug applied multi-scale augmentation to the RGB input for collecting pseudo boxes at different scales.</figcaption>
<table id="S4.T3.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.5.5" class="ltx_tr">
<th id="S4.T3.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Method</th>
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T3.1.1.1.1" class="ltx_sub"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T3.2.2.2.1" class="ltx_sub"><span id="S4.T3.2.2.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="S4.T3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T3.3.3.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T3.3.3.3.m1.1a"><mmultiscripts id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml"><mi id="S4.T3.3.3.3.m1.1.1.2.2" xref="S4.T3.3.3.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T3.3.3.3.m1.1.1a" xref="S4.T3.3.3.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T3.3.3.3.m1.1.1b" xref="S4.T3.3.3.3.m1.1.1.cmml"></mrow><mi id="S4.T3.3.3.3.m1.1.1.3" xref="S4.T3.3.3.3.m1.1.1.3.cmml">s</mi><mi id="S4.T3.3.3.3.m1.1.1.2.3" xref="S4.T3.3.3.3.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T3.3.3.3.m1.1.1c" xref="S4.T3.3.3.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><apply id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.3.m1.1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">superscript</csymbol><apply id="S4.T3.3.3.3.m1.1.1.2.cmml" xref="S4.T3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.3.m1.1.1.2.1.cmml" xref="S4.T3.3.3.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T3.3.3.3.m1.1.1.2.2.cmml" xref="S4.T3.3.3.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T3.3.3.3.m1.1.1.2.3.cmml" xref="S4.T3.3.3.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T3.3.3.3.m1.1.1.3.cmml" xref="S4.T3.3.3.3.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="S4.T3.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T3.4.4.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T3.4.4.4.m1.1a"><mmultiscripts id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml"><mi id="S4.T3.4.4.4.m1.1.1.2.2" xref="S4.T3.4.4.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T3.4.4.4.m1.1.1a" xref="S4.T3.4.4.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T3.4.4.4.m1.1.1b" xref="S4.T3.4.4.4.m1.1.1.cmml"></mrow><mi id="S4.T3.4.4.4.m1.1.1.3" xref="S4.T3.4.4.4.m1.1.1.3.cmml">m</mi><mi id="S4.T3.4.4.4.m1.1.1.2.3" xref="S4.T3.4.4.4.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T3.4.4.4.m1.1.1c" xref="S4.T3.4.4.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><apply id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.4.m1.1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">superscript</csymbol><apply id="S4.T3.4.4.4.m1.1.1.2.cmml" xref="S4.T3.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.4.m1.1.1.2.1.cmml" xref="S4.T3.4.4.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T3.4.4.4.m1.1.1.2.2.cmml" xref="S4.T3.4.4.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T3.4.4.4.m1.1.1.2.3.cmml" xref="S4.T3.4.4.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T3.4.4.4.m1.1.1.3.cmml" xref="S4.T3.4.4.4.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="S4.T3.5.5.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AR<math id="S4.T3.5.5.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T3.5.5.5.m1.1a"><mmultiscripts id="S4.T3.5.5.5.m1.1.1" xref="S4.T3.5.5.5.m1.1.1.cmml"><mi id="S4.T3.5.5.5.m1.1.1.2.2" xref="S4.T3.5.5.5.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T3.5.5.5.m1.1.1a" xref="S4.T3.5.5.5.m1.1.1.cmml"></mprescripts><mrow id="S4.T3.5.5.5.m1.1.1b" xref="S4.T3.5.5.5.m1.1.1.cmml"></mrow><mi id="S4.T3.5.5.5.m1.1.1.3" xref="S4.T3.5.5.5.m1.1.1.3.cmml">l</mi><mi id="S4.T3.5.5.5.m1.1.1.2.3" xref="S4.T3.5.5.5.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T3.5.5.5.m1.1.1c" xref="S4.T3.5.5.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><apply id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.5.5.5.m1.1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">superscript</csymbol><apply id="S4.T3.5.5.5.m1.1.1.2.cmml" xref="S4.T3.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.5.5.5.m1.1.1.2.1.cmml" xref="S4.T3.5.5.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T3.5.5.5.m1.1.1.2.2.cmml" xref="S4.T3.5.5.5.m1.1.1.2.2">absent</csymbol><ci id="S4.T3.5.5.5.m1.1.1.2.3.cmml" xref="S4.T3.5.5.5.m1.1.1.2.3">ğ‘</ci></apply><ci id="S4.T3.5.5.5.m1.1.1.3.cmml" xref="S4.T3.5.5.5.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
</tr>
<tr id="S4.T3.5.6.1" class="ltx_tr">
<th id="S4.T3.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">SelfTrain-RGB</th>
<th id="S4.T3.5.6.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">48.1</th>
<th id="S4.T3.5.6.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">37.4</th>
<th id="S4.T3.5.6.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.5.6.1.4.1" class="ltx_text ltx_font_bold">22.8</span></th>
<th id="S4.T3.5.6.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">43.9</th>
<th id="S4.T3.5.6.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">57.7</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.5.7.1" class="ltx_tr">
<td id="S4.T3.5.7.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">ShapeBias</td>
<td id="S4.T3.5.7.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.8</td>
<td id="S4.T3.5.7.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">36.5</td>
<td id="S4.T3.5.7.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.4</td>
<td id="S4.T3.5.7.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.5</td>
<td id="S4.T3.5.7.1.6" class="ltx_td ltx_align_left ltx_border_t">58.6</td>
</tr>
<tr id="S4.T3.5.8.2" class="ltx_tr">
<td id="S4.T3.5.8.2.1" class="ltx_td ltx_align_left ltx_border_r">ScaleAug</td>
<td id="S4.T3.5.8.2.2" class="ltx_td ltx_align_left ltx_border_r">48.5</td>
<td id="S4.T3.5.8.2.3" class="ltx_td ltx_align_left ltx_border_r">37.9</td>
<td id="S4.T3.5.8.2.4" class="ltx_td ltx_align_left ltx_border_r">21.2</td>
<td id="S4.T3.5.8.2.5" class="ltx_td ltx_align_left ltx_border_r">44.7</td>
<td id="S4.T3.5.8.2.6" class="ltx_td ltx_align_left">62.2</td>
</tr>
<tr id="S4.T3.5.9.3" class="ltx_tr">
<td id="S4.T3.5.9.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="S4.T3.5.9.3.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T3.5.9.3.2.1" class="ltx_text ltx_font_bold">49.5</span></td>
<td id="S4.T3.5.9.3.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T3.5.9.3.3.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="S4.T3.5.9.3.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.6</td>
<td id="S4.T3.5.9.3.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T3.5.9.3.5.1" class="ltx_text ltx_font_bold">48.2</span></td>
<td id="S4.T3.5.9.3.6" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.5.9.3.6.1" class="ltx_text ltx_font_bold">62.4</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Geometric cues are better than adding shape bias and multi-scale augmentation.</span>
In the previous part, we showed that geometric cues can detect novel objects from very different supercategories, owing to their less sensitivity to detailed appearance changes in objects such as textures. It is thus natural to compare with RGB-based model with inductive shape bias to counteract the texture bias. We adopt the stylized ImageNet pretrained ResNet-50 fromÂ <cite class="ltx_cite ltx_citemacro_citep">(Geirhos etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> as the backbone for SelfTrain-RGB. This backbone is trained using heavy style-based augmentation to mitigate the texture bias, where texture is one of the most discussed appearance features prone to overfit by RGB-based models. It showed performance improvements on the COCO object detection benchmark under the closed-world assumptionÂ <cite class="ltx_cite ltx_citemacro_citep">(Geirhos etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>.
Moreover, we observe from FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that RGB is relatively stronger in detecting smaller objects. This leads to the question of whether augmenting SelfTrain-RGB with pseudo boxes extracted at different input scales can already help this RGB-based method achieve comparable performance to those incorporating geometric cues.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.2" class="ltx_p">From TableÂ <a href="#S4.T3" title="Table 3 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we can see that while the shape bias backbone can improve the AR<sub id="S4.SS2.p5.2.1" class="ltx_sub"><span id="S4.SS2.p5.2.1.1" class="ltx_text ltx_font_italic">A</span></sub> of SelfTrain-RGB, it degrades the performance on novel classes, i.e., AR<sub id="S4.SS2.p5.2.2" class="ltx_sub"><span id="S4.SS2.p5.2.2.1" class="ltx_text ltx_font_italic">N</span></sub>, indicating that shape bias obtained from training on ImageNet may not be very helpful in generalizing to novel objects. As for the multi-scale augmentation, although it can improve the detection recall of medium and large objects, the overall performance is still worse than our models that incorporate geometry cues. Overall, these comparisons show that geometry provides strong cues for object localization.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation studies</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.4" class="ltx_p">In this section, we conduct ablation studies to understand the effectiveness of pseudo-labeling, data augmentation, and the influence of the number of base classes. FigureÂ <a href="#S4.F5.sf1" title="In Figure 5 â€£ 4.3 Ablation studies â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>) shows the AR<sub id="S4.SS3.p1.4.1" class="ltx_sub"><span id="S4.SS3.p1.4.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 achieved by the object proposal network (Phase-I) and the object detector (Phase-II). The latter uses the pseudo boxes generated by the former, where the former can be trained with different data modalities. The RGB-based object proposal network outperforms the depth- and normal-based one on AR<sub id="S4.SS3.p1.4.2" class="ltx_sub"><span id="S4.SS3.p1.4.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100. This indicates that depth and normal maps cannot simply replace RGB image for object detection. As evidenced in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, they are competitive on AR<sub id="S4.SS3.p1.4.3" class="ltx_sub"><span id="S4.SS3.p1.4.3.1" class="ltx_text ltx_font_italic">N</span></sub>@k with <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="\text{k}\leq 5" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mtext id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2a.cmml">k</mtext><mo id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">â‰¤</mo><mn id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><leq id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></leq><ci id="S4.SS3.p1.4.m4.1.1.2a.cmml" xref="S4.SS3.p1.4.m4.1.1.2"><mtext id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">k</mtext></ci><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">\text{k}\leq 5</annotation></semantics></math>, meaning their top predictions are of high quality. Pseudo labeling is thus an effective way for geometry-guided open-world object detector training.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.2" class="ltx_p">We further study the effect of AutoAugmentÂ <cite class="ltx_cite ltx_citemacro_citep">(Cubuk etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>. Using it during Phase-II training, we achieve higher AR<sub id="S4.SS3.p2.2.1" class="ltx_sub"><span id="S4.SS3.p2.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 as shown in FigureÂ <a href="#S4.F5.sf2" title="In Figure 5 â€£ 4.3 Ablation studies â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>). Data augmentation is helpful to counteract the noise in pseudo labels. However, using AutoAugment to train OLN on the ground truth base class annotations, we observe only improvement in recalling the base class objects (from 58.4% to 61.7% AR<sub id="S4.SS3.p2.2.2" class="ltx_sub"><span id="S4.SS3.p2.2.2.1" class="ltx_text ltx_font_italic">Base</span></sub>@100), but degradation in novel object detection. This shows that data augmentation via random resizing, cropping, and flipping cannot improve generalization across categories.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.4" class="ltx_p">Finally, we study the influence of the number of base classes. As shown in TableÂ <a href="#S4.T4" title="Table 4 â€£ 4.3 Ablation studies â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we split the COCO dataset based on the supercategories to create six different splits. We then train GOOD and OLN on these splits and evaluate them on ADE20K. More base classes in training allow object detectors to learn a more generic sense of objectness so that they can better detect novel objects. As shown in FigureÂ <a href="#S4.F5.sf3" title="In Figure 5 â€£ 4.3 Ablation studies â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(c)</span></a>, both GOOD and OLN achieve better AR<sub id="S4.SS3.p3.4.1" class="ltx_sub"><span id="S4.SS3.p3.4.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 along with the number of base classes, and their performance gap reduces. However, the annotation cost also grows along with the number of classes. GOOD can achieve a similar AR<sub id="S4.SS3.p3.4.2" class="ltx_sub"><span id="S4.SS3.p3.4.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100 as OLN with only half the number of base classes, e.g., <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="39" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mn id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">39</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><cn type="integer" id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">39</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">39</annotation></semantics></math> vs. <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mn id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><cn type="integer" id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">80</annotation></semantics></math>. This shows that GOOD is more effective at learning a generic sense of objectness and less prone to overfitting to the base classes.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x3.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="286" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Effectiveness of pseudo labeling.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x4.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="219" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Effectiveness of data augmentation.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x5.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Varying the number of base classes.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S4.F5.2.1" class="ltx_text ltx_font_bold">Ablation studies.</span> (a) and (b) are conducted on COCO VOC to non-VOC benchmark. The study on the number of base classes (c) uses ADE20K as the evaluation benchmark.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:68.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-73.4pt,13.6pt) scale(0.715224525907428,0.715224525907428) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Supercategories</th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Person</th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">+Vehicle</th>
<th id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Outdoor,</td>
</tr>
<tr id="S4.T4.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Animal</td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.5.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Accessory,</td>
</tr>
<tr id="S4.T4.1.1.1.1.5.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Sports</td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.6.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Kitchen,</td>
</tr>
<tr id="S4.T4.1.1.1.1.6.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Food</td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.7.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Furniture, Electronic,</td>
</tr>
<tr id="S4.T4.1.1.1.1.7.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Appliance, Indoor</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.2.1" class="ltx_tr">
<th id="S4.T4.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"># Training classes</th>
<td id="S4.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">9</td>
<td id="S4.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">24</td>
<td id="S4.T4.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">39</td>
<td id="S4.T4.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">56</td>
<td id="S4.T4.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">80</td>
</tr>
<tr id="S4.T4.1.1.3.2" class="ltx_tr">
<th id="S4.T4.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"># Training images</th>
<td id="S4.T4.1.1.3.2.2" class="ltx_td ltx_align_center">64115</td>
<td id="S4.T4.1.1.3.2.3" class="ltx_td ltx_align_center">74152</td>
<td id="S4.T4.1.1.3.2.4" class="ltx_td ltx_align_center">92169</td>
<td id="S4.T4.1.1.3.2.5" class="ltx_td ltx_align_center">93939</td>
<td id="S4.T4.1.1.3.2.6" class="ltx_td ltx_align_center">107036</td>
<td id="S4.T4.1.1.3.2.7" class="ltx_td ltx_align_center">117266</td>
</tr>
<tr id="S4.T4.1.1.4.3" class="ltx_tr">
<th id="S4.T4.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"># Training instances</th>
<td id="S4.T4.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">609666</td>
<td id="S4.T4.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">654460</td>
<td id="S4.T4.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">715582</td>
<td id="S4.T4.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb">727207</td>
<td id="S4.T4.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_bb">824535</td>
<td id="S4.T4.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_bb">860001</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S4.T4.3.1" class="ltx_text ltx_font_bold">Base class choices for studying the influence of the number of base classes.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this paper, we proposed a method GOOD for tackling the challenging problem of open-world class-agnostic object detection. It exploits the easy-to-obtain geometric cues such as depth and normals for detecting unannotated novel objects in the training set. As the geometric cues focus on object shapes and relative spatial locations rather than appearances, they can detect novel objects that RGB-based methods cannot detect. By further involving these novel objects into RGB-based object detector training, GOOD demonstrates strong generalization performance across categories as well as datasets.</p>
</div>
<section id="S5.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Acknowledgment</h3>

<div id="S5.SSx1.p1" class="ltx_para ltx_noindent">
<p id="S5.SSx1.p1.1" class="ltx_p">Haiwen Huang and Dan Zhang were supported by Bosch Industry on Campus Lab at University of TÃ¼bingen. Andreas Geiger was supported by the ERC Starting Grant LEGO-3D (850533) and the DFG EXC number 2064/1 - project number 390727645. Haiwen Huang would like to thank Tianlin Ye for her emotional support throughout the project and Jojumon Kavalan for generously providing access to his Internet during the rebuttal period.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ArbelÃ¡ez etÂ al. (2014)</span>
<span class="ltx_bibblock">
P.Â ArbelÃ¡ez, J.Â Pont-Tuset, J.Â Barron, F.Â Marques, and J.Â Malik.

</span>
<span class="ltx_bibblock">Multiscale combinatorial grouping.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Computer Vision and Pattern Recognition</em>, 2014.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ArbelÃ¡ez (2006)</span>
<span class="ltx_bibblock">
Pablo ArbelÃ¡ez.

</span>
<span class="ltx_bibblock">Boundary extraction in natural images using ultrametric contour maps.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2006 Conference on Computer Vision and Pattern Recognition
Workshop (CVPRWâ€™06)</em>, pp.Â  182â€“182. IEEE, 2006.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arbelaez etÂ al. (2011)</span>
<span class="ltx_bibblock">
Pablo Arbelaez, Michael Maire, Charless Fowlkes, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Contour detection and hierarchical image segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Pattern Anal. Mach. Intell.</em>, 33(5):898â€“916, May 2011.

</span>
<span class="ltx_bibblock">ISSN 0162-8828.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TPAMI.2010.161</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1109/TPAMI.2010.161" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1109/TPAMI.2010.161</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2021)</span>
<span class="ltx_bibblock">
Bryan Chen, Alexander Sax, Francis Lewis, Iro Armeni, Silvio Savarese, Amir
Zamir, Jitendra Malik, and Lerrel Pinto.

</span>
<span class="ltx_bibblock">Robust policies via mid-level visual representations: An experimental
study in manipulation and navigation.

</span>
<span class="ltx_bibblock">In Jens Kober, Fabio Ramos, and Claire Tomlin (eds.),
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Robot Learning</em>, volume 155 of
<em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pp.Â  2328â€“2346. PMLR,
16â€“18 Nov 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v155/chen21f.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v155/chen21f.html</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2019)</span>
<span class="ltx_bibblock">
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, YuÂ Xiong, Xiaoxiao Li,
Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng,
Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu,
Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, ChenÂ Change Loy, and
Dahua Lin.

</span>
<span class="ltx_bibblock">MMDetection: Open mmlab detection toolbox and benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.07155</em>, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cubuk etÂ al. (2019)</span>
<span class="ltx_bibblock">
EkinÂ D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and QuocÂ V Le.

</span>
<span class="ltx_bibblock">Autoaugment: Learning augmentation strategies from data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.Â  113â€“123, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng etÂ al. (2009)</span>
<span class="ltx_bibblock">
J.Â Deng, W.Â Dong, R.Â Socher, L.-J. Li, K.Â Li, and L.Â Fei-Fei.

</span>
<span class="ltx_bibblock">ImageNet: A Large-Scale Hierarchical Image Database.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CVPR09</em>, 2009.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eftekhar etÂ al. (2021)</span>
<span class="ltx_bibblock">
Ainaz Eftekhar, Alexander Sax, Jitendra Malik, and Amir Zamir.

</span>
<span class="ltx_bibblock">Omnidata: A scalable pipeline for making multi-task mid-level vision
datasets from 3d scans.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.Â  10786â€“10796, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eigen &amp; Fergus (2015)</span>
<span class="ltx_bibblock">
David Eigen and Rob Fergus.

</span>
<span class="ltx_bibblock">Predicting depth, surface normals and semantic labels with a common
multi-scale convolutional architecture.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pp.Â  2650â€“2658, 2015.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eigen etÂ al. (2014)</span>
<span class="ltx_bibblock">
David Eigen, Christian Puhrsch, and Rob Fergus.

</span>
<span class="ltx_bibblock">Depth map prediction from a single image using a multi-scale deep
network.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 27, 2014.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Everingham etÂ al. (2010)</span>
<span class="ltx_bibblock">
M.Â Everingham, L.Â VanÂ Gool, C.Â K.Â I. Williams, J.Â Winn, and A.Â Zisserman.

</span>
<span class="ltx_bibblock">The pascal visual object classes (VOC) challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 88(2):303â€“338, June 2010.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geirhos etÂ al. (2019)</span>
<span class="ltx_bibblock">
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, FelixÂ A
Wichmann, and Wieland Brendel.

</span>
<span class="ltx_bibblock">Imagenet-trained CNNs are biased towards texture; increasing shape
bias improves accuracy and robustness.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Bygh9j09KX" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Bygh9j09KX</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geirhos etÂ al. (2020)</span>
<span class="ltx_bibblock">
Robert Geirhos, JÃ¶rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
Wieland Brendel, Matthias Bethge, and FelixÂ A Wichmann.

</span>
<span class="ltx_bibblock">Shortcut learning in deep neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, 2(11):665â€“673, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem etÂ al. (2005a)</span>
<span class="ltx_bibblock">
Derek Hoiem, AlexeiÂ A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Automatic photo pop-up.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ACM SIGGRAPH 2005 Papers</em>, pp.Â  577â€“584.
2005a.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem etÂ al. (2005b)</span>
<span class="ltx_bibblock">
Derek Hoiem, AlexeiÂ A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Geometric context from a single image.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Tenth IEEE International Conference on Computer Vision
(ICCVâ€™05) Volume 1</em>, volumeÂ 1, pp.Â  654â€“661. IEEE, 2005b.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem etÂ al. (2007)</span>
<span class="ltx_bibblock">
Derek Hoiem, AlexeiÂ A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Recovering surface layout from an image.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 75(1):151â€“172, 2007.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem etÂ al. (2008)</span>
<span class="ltx_bibblock">
Derek Hoiem, AlexeiÂ A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Putting objects in perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 80(1):3â€“15, 2008.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaiswal etÂ al. (2021)</span>
<span class="ltx_bibblock">
Ayush Jaiswal, Yue Wu, Pradeep Natarajan, and Premkumar Natarajan.

</span>
<span class="ltx_bibblock">Class-agnostic object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Winter Conference on
Applications of Computer Vision</em>, pp.Â  919â€“928, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Yuqian Jiang, Nick Walker, Justin Hart, and Peter Stone.

</span>
<span class="ltx_bibblock">Open-world reasoning for service robots.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Automated
Planning and Scheduling</em>, volumeÂ 29, pp.Â  725â€“733, 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joseph etÂ al. (2021)</span>
<span class="ltx_bibblock">
K.Â J. Joseph, Salman Khan, FahadÂ Shahbaz Khan, and VineethÂ N. Balasubramanian.

</span>
<span class="ltx_bibblock">Towards Open World Object Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv:2103.02603 [cs]</em>, May 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2103.02603" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2103.02603</a>.

</span>
<span class="ltx_bibblock">arXiv: 2103.02603.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kar etÂ al. (2022)</span>
<span class="ltx_bibblock">
OÄŸuzhanÂ Fatih Kar, Teresa Yeo, Andrei Atanov, and Amir Zamir.

</span>
<span class="ltx_bibblock">3d common corruptions and data augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.Â  18963â€“18974, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2021)</span>
<span class="ltx_bibblock">
Dahun Kim, Tsung-Yi Lin, Anelia Angelova, InÂ So Kweon, and Weicheng Kuo.

</span>
<span class="ltx_bibblock">Learning Open-World Object Proposals without Learning to
Classify.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv:2108.06753 [cs]</em>, August 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2108.06753" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2108.06753</a>.

</span>
<span class="ltx_bibblock">arXiv: 2108.06753.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konan etÂ al. (2022)</span>
<span class="ltx_bibblock">
Sachin Konan, KevinÂ J Liang, and LiÂ Yin.

</span>
<span class="ltx_bibblock">Extending one-stage detection with open-world proposals.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.02302</em>, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2014)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr DollÃ¡r, and C.Â Lawrence Zitnick.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars
(eds.), <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ECCV</em>, pp.Â  740â€“755, 2014.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Bing Liu, Eric Robertson, Scott Grigsby, and Sahisnu Mazumder.

</span>
<span class="ltx_bibblock">Self-initiated open world learning for autonomous ai agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.11385</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yang Liu, IdilÂ Esen Zulfikar, Jonathon Luiten, Achal Dave, Deva Ramanan,
Bastian Leibe, AljoÅ¡a OÅ¡ep, and Laura Leal-TaixÃ©.

</span>
<span class="ltx_bibblock">Opening up open world tracking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.Â  19045â€“19055, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maaz etÂ al. (2022)</span>
<span class="ltx_bibblock">
Muhammad Maaz, Hanoona Rasheed, Salman Khan, FahadÂ Shahbaz Khan, RaoÂ Muhammad
Anwer, and Ming-Hsuan Yang.

</span>
<span class="ltx_bibblock">Class-agnostic object detection with multi-modal transformer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">17th European Conference on Computer Vision</em>. Springer,
2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minderer etÂ al. (2022)</span>
<span class="ltx_bibblock">
Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk
Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa
Dehghani, Zhuoran Shen, etÂ al.

</span>
<span class="ltx_bibblock">Simple open-vocabulary object detection with vision transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.06230</em>, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
etÂ al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language
supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.Â 8748â€“8763. PMLR, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl etÂ al. (2021a)</span>
<span class="ltx_bibblock">
RenÃ© Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Vision transformers for dense prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ArXiv preprint</em>, 2021a.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl etÂ al. (2021b)</span>
<span class="ltx_bibblock">
RenÃ© Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Vision transformers for dense prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, 2021b.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl etÂ al. (2022)</span>
<span class="ltx_bibblock">
RenÃ© Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen
Koltun.

</span>
<span class="ltx_bibblock">Towards robust monocular depth estimation: Mixing datasets for
zero-shot cross-dataset transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 44(3), 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren etÂ al. (2015)</span>
<span class="ltx_bibblock">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.

</span>
<span class="ltx_bibblock">Faster R-CNN: Towards Real-Time Object Detection with
Region Proposal Networks.

</span>
<span class="ltx_bibblock">In C.Â Cortes, N.Â Lawrence, D.Â Lee, M.Â Sugiyama, and R.Â Garnett
(eds.), <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volumeÂ 28. Curran Associates, Inc., 2015.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saito etÂ al. (2021)</span>
<span class="ltx_bibblock">
Kuniaki Saito, Ping Hu, Trevor Darrell, and Kate Saenko.

</span>
<span class="ltx_bibblock">Learning to Detect Every Thing in an Open World.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv:2112.01698 [cs]</em>, December 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2112.01698" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2112.01698</a>.

</span>
<span class="ltx_bibblock">arXiv: 2112.01698 version: 1.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sauer &amp; Geiger (2021)</span>
<span class="ltx_bibblock">
Axel Sauer and Andreas Geiger.

</span>
<span class="ltx_bibblock">Counterfactual generative networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=BXewfAYMmJw" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=BXewfAYMmJw</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena etÂ al. (2005)</span>
<span class="ltx_bibblock">
Ashutosh Saxena, Sung Chung, and Andrew Ng.

</span>
<span class="ltx_bibblock">Learning depth from single monocular images.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 18, 2005.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena etÂ al. (2008a)</span>
<span class="ltx_bibblock">
Ashutosh Saxena, SungÂ H Chung, and AndrewÂ Y Ng.

</span>
<span class="ltx_bibblock">3-d depth reconstruction from a single still image.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">International journal of computer vision</em>, 76(1):53â€“69, 2008a.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena etÂ al. (2008b)</span>
<span class="ltx_bibblock">
Ashutosh Saxena, Min Sun, and AndrewÂ Y Ng.

</span>
<span class="ltx_bibblock">Make3d: Learning 3d scene structure from a single still image.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 31(5):824â€“840, 2008b.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi &amp; Malik (2000)</span>
<span class="ltx_bibblock">
Jianbo Shi and Jitendra Malik.

</span>
<span class="ltx_bibblock">Normalized cuts and image segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on pattern analysis and machine
intelligence</em>, 22(8):888â€“905, 2000.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sohn etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang,
ColinÂ A Raffel, EkinÂ Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li.

</span>
<span class="ltx_bibblock">Fixmatch: Simplifying semi-supervised learning with consistency and
confidence.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
33:596â€“608, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian etÂ al. (2019)</span>
<span class="ltx_bibblock">
Zhi Tian, Chunhua Shen, Hao Chen, and Tong He.

</span>
<span class="ltx_bibblock">FCOS: Fully convolutional one-stage object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Computer Vision (ICCV)</em>, 2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Weiyao Wang, Matt Feiszli, Heng Wang, Jitendra Malik, and DuÂ Tran.

</span>
<span class="ltx_bibblock">Open-world instance segmentation: Exploiting pseudo ground truth from
learned pairwise affinity.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.Â  4422â€“4432, 2022.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yongqin Xiang, Julian Chibane, BharatÂ Lal Bhatnagar, Bernt Schiele, Zeynep
Akata, and Gerard Pons-Moll.

</span>
<span class="ltx_bibblock">Any-shot gin: Generalizing implicit networks for reconstructing novel
classes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">2022 International Conference on 3D Vision (3DV)</em>. IEEE,
2022.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie etÂ al. (2020)</span>
<span class="ltx_bibblock">
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and QuocÂ V Le.

</span>
<span class="ltx_bibblock">Self-training with noisy student improves imagenet classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.Â  10687â€“10698, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie &amp; Tu (2015)</span>
<span class="ltx_bibblock">
Saining Xie and Zhuowen Tu.

</span>
<span class="ltx_bibblock">Holistically-nested edge detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pp.Â  1395â€“1403, 2015.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, Lijuan Wang, Fangyun Wei, Xiang
Bai, and Zicheng Liu.

</span>
<span class="ltx_bibblock">End-to-end semi-supervised object detection with soft teacher.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</em>, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sattler, and Andreas Geiger.

</span>
<span class="ltx_bibblock">Monosdf: Exploring monocular geometric cues for neural implicit
surface reconstruction.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv:2022.00665</em>, 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zamir etÂ al. (2020)</span>
<span class="ltx_bibblock">
AmirÂ R Zamir, Alexander Sax, Nikhil Cheerla, Rohan Suri, Zhangjie Cao, Jitendra
Malik, and LeonidasÂ J Guibas.

</span>
<span class="ltx_bibblock">Robust learning through cross-task consistency.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.Â  11197â€“11206, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2019)</span>
<span class="ltx_bibblock">
Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso,
and Antonio Torralba.

</span>
<span class="ltx_bibblock">Semantic understanding of scenes through the ade20k dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 127(3):302â€“321, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation details</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.3" class="ltx_p">GOOD uses OLNÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> as the architecture for both Phase-I and Phase-II training. OLN is built on top of Faster RCNNÂ <cite class="ltx_cite ltx_citemacro_citep">(Ren etÂ al., <a href="#bib.bib33" title="" class="ltx_ref">2015</a>)</cite>.
For open-world object detection, the classification heads are replaced with the objectness score prediction heads, i.e., predicting the centerness and IoU of each bounding box proposal at the two stages, respectively. We use the objectness score <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="\sqrt{\mathrm{centerness}\times\mathrm{IoU}}" display="inline"><semantics id="A1.p1.1.m1.1a"><msqrt id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mrow id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml"><mi id="A1.p1.1.m1.1.1.2.2" xref="A1.p1.1.m1.1.1.2.2.cmml">centerness</mi><mo lspace="0.222em" rspace="0.222em" id="A1.p1.1.m1.1.1.2.1" xref="A1.p1.1.m1.1.1.2.1.cmml">Ã—</mo><mi id="A1.p1.1.m1.1.1.2.3" xref="A1.p1.1.m1.1.1.2.3.cmml">IoU</mi></mrow></msqrt><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><root id="A1.p1.1.m1.1.1a.cmml" xref="A1.p1.1.m1.1.1"></root><apply id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2"><times id="A1.p1.1.m1.1.1.2.1.cmml" xref="A1.p1.1.m1.1.1.2.1"></times><ci id="A1.p1.1.m1.1.1.2.2.cmml" xref="A1.p1.1.m1.1.1.2.2">centerness</ci><ci id="A1.p1.1.m1.1.1.2.3.cmml" xref="A1.p1.1.m1.1.1.2.3">IoU</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">\sqrt{\mathrm{centerness}\times\mathrm{IoU}}</annotation></semantics></math> for ranking the pseudo boxes and selecting the top <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">k</annotation></semantics></math> pseudo boxes per image.
The optimal <math id="A1.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p1.3.m3.1a"><mi id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><ci id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">k</annotation></semantics></math> choice for GOOD-Depth and GOOD-Normal is 1 and for SelfTrain-RGB is 3.</p>
</div>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.3" class="ltx_p">For Phase-I training, we trained the proposal network with loss as given in Eq.Â <a href="#S3.E2" title="In 3.1 open-world class-agnostic object detection problem â€£ 3 Method â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and used the SGD optimizer with an initial learning rate of 0.01 and batch size of 16 for 8 epochs.
For Phase-II training, unless otherwise stated, we trained the object detector with loss as given in Eq.Â <a href="#S3.E3" title="In 3.3 Pseudo labeling method â€£ 3 Method â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and used SGD optimizer with an initial learning rate of <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A1.p2.1.m1.1a"><mn id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><cn type="float" id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">0.01</annotation></semantics></math> and batch size of <math id="A1.p2.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.p2.2.m2.1a"><mn id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><cn type="integer" id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">16</annotation></semantics></math> for <math id="A1.p2.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.p2.3.m3.1a"><mn id="A1.p2.3.m3.1.1" xref="A1.p2.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.p2.3.m3.1b"><cn type="integer" id="A1.p2.3.m3.1.1.cmml" xref="A1.p2.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.3.m3.1c">16</annotation></semantics></math> epochs with AutoAugment.
For GOOD-Both, we merge the pseudo boxes generated by object proposal networks separately trained on depth and normal maps by filtering out the overlapping boxes. Specifically, if the IoU of two pseudo boxes is larger than 0.5, they are seen as overlapping with each other, and the one with lower objectness score will be filtered out. For other ensembling experiments, if not specified, pseudo boxes are also merged as described above.</p>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.2" class="ltx_p">We use the DPT-Hybrid models from Omnidata repositoryÂ <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> for off-the-shelf inference of geometric cues. The DPT-Hybrid modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ranftl etÂ al., <a href="#bib.bib30" title="" class="ltx_ref">2021a</a>)</cite> have a hybrid architecture of attention layers and convolutional layers. They are trained on the Omnidata Starter DatsetÂ <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> for one week with 2D and 3D data augmentationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Kar etÂ al., <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>, and one week with cross-task consistencyÂ <cite class="ltx_cite ltx_citemacro_citep">(Zamir etÂ al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> on 4 V100 GPUs. To infer on RGB images, we first pad images to sizes divisible by 32 without resizing, then feed them to the DPT-Hybrid model. Note although the original models are trained on 384<math id="A1.p3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.p3.1.m1.1a"><mo id="A1.p3.1.m1.1.1" xref="A1.p3.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="A1.p3.1.m1.1b"><times id="A1.p3.1.m1.1.1.cmml" xref="A1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.1.m1.1c">\times</annotation></semantics></math>384 image patches, we find that inferring on the original resolution of COCO produces better visual results than on the resolution of 384<math id="A1.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.p3.2.m2.1a"><mo id="A1.p3.2.m2.1.1" xref="A1.p3.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="A1.p3.2.m2.1b"><times id="A1.p3.2.m2.1.1.cmml" xref="A1.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.2.m2.1c">\times</annotation></semantics></math>384.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>More benchmarks</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We further evaluate our approach on more benchmarks. Specifically, we evaluated the baselines and GOOD on the cross-category benchmark LVIS COCO to non-COCO and cross-dataset benchmark COCO to UVO. The results are shown in TableÂ <a href="#A2.T5" title="Table 5 â€£ Appendix B More benchmarks â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. As expected, the performance gains are smaller than those observsed on benchmarks with smaller number of base classes such as COCO VOC to non-VOC. But still, GOOD surpasses all the state-of-the-art RGB-based methods. This shows that even in extreme conditions when the number of base classes is large, GOOD can still be helpful in improving the open-world performance.</p>
</div>
<figure id="A2.T5" class="ltx_table">
<div id="A2.T5.11.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:116.1pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,3.0pt) scale(0.95,0.95) ;">
<div id="A2.T5.11.11.11" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:121.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-68.7pt,20.8pt) scale(0.74316562498636,0.74316562498636) ;">
<table id="A2.T5.11.11.11.11" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T5.2.2.2.2.2" class="ltx_tr">
<td id="A2.T5.2.2.2.2.2.3" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="A2.T5.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="5"><span id="A2.T5.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">LVIS COCO<math id="A2.T5.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A2.T5.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A2.T5.1.1.1.1.1.1.1.m1.1.1" xref="A2.T5.1.1.1.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A2.T5.1.1.1.1.1.1.1.m1.1b"><ci id="A2.T5.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A2.T5.1.1.1.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-COCO</span></td>
<td id="A2.T5.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="A2.T5.2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">COCO<math id="A2.T5.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A2.T5.2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="A2.T5.2.2.2.2.2.2.1.m1.1.1" xref="A2.T5.2.2.2.2.2.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A2.T5.2.2.2.2.2.2.1.m1.1b"><ci id="A2.T5.2.2.2.2.2.2.1.m1.1.1.cmml" xref="A2.T5.2.2.2.2.2.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.2.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>UVO</span></td>
</tr>
<tr id="A2.T5.11.11.11.11.11" class="ltx_tr">
<td id="A2.T5.11.11.11.11.11.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="A2.T5.3.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="A2.T5.3.3.3.3.3.1.1" class="ltx_sub"><span id="A2.T5.3.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="A2.T5.4.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="A2.T5.4.4.4.4.4.2.1" class="ltx_sub"><span id="A2.T5.4.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</td>
<td id="A2.T5.5.5.5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.5.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A2.T5.5.5.5.5.5.3.m1.1a"><mmultiscripts id="A2.T5.5.5.5.5.5.3.m1.1.1" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"><mi id="A2.T5.5.5.5.5.5.3.m1.1.1.2.2" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.5.5.5.5.5.3.m1.1.1a" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.5.5.5.5.5.3.m1.1.1b" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="A2.T5.5.5.5.5.5.3.m1.1.1.3" xref="A2.T5.5.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="A2.T5.5.5.5.5.5.3.m1.1.1.2.3" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="A2.T5.5.5.5.5.5.3.m1.1.1c" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.5.5.5.5.5.3.m1.1b"><apply id="A2.T5.5.5.5.5.5.3.m1.1.1.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.5.5.5.5.5.3.m1.1.1.1.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="A2.T5.5.5.5.5.5.3.m1.1.1.2.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.5.5.5.5.5.3.m1.1.1.2.1.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.5.5.5.5.5.3.m1.1.1.2.2.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.5.5.5.5.5.3.m1.1.1.2.3.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="A2.T5.5.5.5.5.5.3.m1.1.1.3.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.5.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</td>
<td id="A2.T5.6.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.6.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A2.T5.6.6.6.6.6.4.m1.1a"><mmultiscripts id="A2.T5.6.6.6.6.6.4.m1.1.1" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"><mi id="A2.T5.6.6.6.6.6.4.m1.1.1.2.2" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.6.6.6.6.6.4.m1.1.1a" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.6.6.6.6.6.4.m1.1.1b" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="A2.T5.6.6.6.6.6.4.m1.1.1.3" xref="A2.T5.6.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="A2.T5.6.6.6.6.6.4.m1.1.1.2.3" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="A2.T5.6.6.6.6.6.4.m1.1.1c" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.6.6.6.6.6.4.m1.1b"><apply id="A2.T5.6.6.6.6.6.4.m1.1.1.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.6.6.6.6.6.4.m1.1.1.1.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="A2.T5.6.6.6.6.6.4.m1.1.1.2.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.6.6.6.6.6.4.m1.1.1.2.1.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.6.6.6.6.6.4.m1.1.1.2.2.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.6.6.6.6.6.4.m1.1.1.2.3.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="A2.T5.6.6.6.6.6.4.m1.1.1.3.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.6.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</td>
<td id="A2.T5.7.7.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.7.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A2.T5.7.7.7.7.7.5.m1.1a"><mmultiscripts id="A2.T5.7.7.7.7.7.5.m1.1.1" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"><mi id="A2.T5.7.7.7.7.7.5.m1.1.1.2.2" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.7.7.7.7.7.5.m1.1.1a" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.7.7.7.7.7.5.m1.1.1b" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="A2.T5.7.7.7.7.7.5.m1.1.1.3" xref="A2.T5.7.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="A2.T5.7.7.7.7.7.5.m1.1.1.2.3" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="A2.T5.7.7.7.7.7.5.m1.1.1c" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.7.7.7.7.7.5.m1.1b"><apply id="A2.T5.7.7.7.7.7.5.m1.1.1.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.7.7.7.7.7.5.m1.1.1.1.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="A2.T5.7.7.7.7.7.5.m1.1.1.2.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.7.7.7.7.7.5.m1.1.1.2.1.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.7.7.7.7.7.5.m1.1.1.2.2.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.7.7.7.7.7.5.m1.1.1.2.3.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.3">ğ‘</ci></apply><ci id="A2.T5.7.7.7.7.7.5.m1.1.1.3.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.7.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</td>
<td id="A2.T5.8.8.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="A2.T5.8.8.8.8.8.6.1" class="ltx_sub"><span id="A2.T5.8.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="A2.T5.9.9.9.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.9.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="A2.T5.9.9.9.9.9.7.m1.1a"><mmultiscripts id="A2.T5.9.9.9.9.9.7.m1.1.1" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"><mi id="A2.T5.9.9.9.9.9.7.m1.1.1.2.2" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.9.9.9.9.9.7.m1.1.1a" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.9.9.9.9.9.7.m1.1.1b" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="A2.T5.9.9.9.9.9.7.m1.1.1.3" xref="A2.T5.9.9.9.9.9.7.m1.1.1.3.cmml">s</mi><mi id="A2.T5.9.9.9.9.9.7.m1.1.1.2.3" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="A2.T5.9.9.9.9.9.7.m1.1.1c" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.9.9.9.9.9.7.m1.1b"><apply id="A2.T5.9.9.9.9.9.7.m1.1.1.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.9.9.9.9.9.7.m1.1.1.1.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="A2.T5.9.9.9.9.9.7.m1.1.1.2.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.9.9.9.9.9.7.m1.1.1.2.1.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.9.9.9.9.9.7.m1.1.1.2.2.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.9.9.9.9.9.7.m1.1.1.2.3.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.3">ğ´</ci></apply><ci id="A2.T5.9.9.9.9.9.7.m1.1.1.3.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.9.9.9.9.9.7.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</td>
<td id="A2.T5.10.10.10.10.10.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.10.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="A2.T5.10.10.10.10.10.8.m1.1a"><mmultiscripts id="A2.T5.10.10.10.10.10.8.m1.1.1" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"><mi id="A2.T5.10.10.10.10.10.8.m1.1.1.2.2" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.10.10.10.10.10.8.m1.1.1a" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.10.10.10.10.10.8.m1.1.1b" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="A2.T5.10.10.10.10.10.8.m1.1.1.3" xref="A2.T5.10.10.10.10.10.8.m1.1.1.3.cmml">m</mi><mi id="A2.T5.10.10.10.10.10.8.m1.1.1.2.3" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="A2.T5.10.10.10.10.10.8.m1.1.1c" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.10.10.10.10.10.8.m1.1b"><apply id="A2.T5.10.10.10.10.10.8.m1.1.1.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.10.10.10.10.10.8.m1.1.1.1.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="A2.T5.10.10.10.10.10.8.m1.1.1.2.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.10.10.10.10.10.8.m1.1.1.2.1.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.10.10.10.10.10.8.m1.1.1.2.2.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.10.10.10.10.10.8.m1.1.1.2.3.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.3">ğ´</ci></apply><ci id="A2.T5.10.10.10.10.10.8.m1.1.1.3.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.10.10.10.10.10.8.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</td>
<td id="A2.T5.11.11.11.11.11.9" class="ltx_td ltx_align_left ltx_border_t">AR<math id="A2.T5.11.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="A2.T5.11.11.11.11.11.9.m1.1a"><mmultiscripts id="A2.T5.11.11.11.11.11.9.m1.1.1" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"><mi id="A2.T5.11.11.11.11.11.9.m1.1.1.2.2" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.11.11.11.11.11.9.m1.1.1a" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.11.11.11.11.11.9.m1.1.1b" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="A2.T5.11.11.11.11.11.9.m1.1.1.3" xref="A2.T5.11.11.11.11.11.9.m1.1.1.3.cmml">l</mi><mi id="A2.T5.11.11.11.11.11.9.m1.1.1.2.3" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.3.cmml">A</mi><mrow id="A2.T5.11.11.11.11.11.9.m1.1.1c" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.11.11.11.11.11.9.m1.1b"><apply id="A2.T5.11.11.11.11.11.9.m1.1.1.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.11.11.11.11.11.9.m1.1.1.1.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="A2.T5.11.11.11.11.11.9.m1.1.1.2.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.11.11.11.11.11.9.m1.1.1.2.1.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.11.11.11.11.11.9.m1.1.1.2.2.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.11.11.11.11.11.9.m1.1.1.2.3.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.3">ğ´</ci></apply><ci id="A2.T5.11.11.11.11.11.9.m1.1.1.3.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.11.11.11.11.11.9.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</td>
</tr>
<tr id="A2.T5.11.11.11.11.12.1" class="ltx_tr">
<td id="A2.T5.11.11.11.11.12.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FRCNN (cls-agn)</td>
<td id="A2.T5.11.11.11.11.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.6</td>
<td id="A2.T5.11.11.11.11.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.0</td>
<td id="A2.T5.11.11.11.11.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14.9</td>
<td id="A2.T5.11.11.11.11.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.7</td>
<td id="A2.T5.11.11.11.11.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">36.2</td>
<td id="A2.T5.11.11.11.11.12.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.3</td>
<td id="A2.T5.11.11.11.11.12.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">22.2</td>
<td id="A2.T5.11.11.11.11.12.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.3</td>
<td id="A2.T5.11.11.11.11.12.1.10" class="ltx_td ltx_align_left ltx_border_t">52.0</td>
</tr>
<tr id="A2.T5.11.11.11.11.13.2" class="ltx_tr">
<td id="A2.T5.11.11.11.11.13.2.1" class="ltx_td ltx_align_left ltx_border_r">OLNÂ <cite class="ltx_cite ltx_citemacro_citep">(Kim etÂ al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A2.T5.11.11.11.11.13.2.2" class="ltx_td ltx_align_left ltx_border_r">32.2</td>
<td id="A2.T5.11.11.11.11.13.2.3" class="ltx_td ltx_align_left ltx_border_r">27.4</td>
<td id="A2.T5.11.11.11.11.13.2.4" class="ltx_td ltx_align_left ltx_border_r">17.9</td>
<td id="A2.T5.11.11.11.11.13.2.5" class="ltx_td ltx_align_left ltx_border_r">44.7</td>
<td id="A2.T5.11.11.11.11.13.2.6" class="ltx_td ltx_align_left ltx_border_r">53.1</td>
<td id="A2.T5.11.11.11.11.13.2.7" class="ltx_td ltx_align_left ltx_border_r">49.2</td>
<td id="A2.T5.11.11.11.11.13.2.8" class="ltx_td ltx_align_left ltx_border_r">35.0</td>
<td id="A2.T5.11.11.11.11.13.2.9" class="ltx_td ltx_align_left ltx_border_r">48.7</td>
<td id="A2.T5.11.11.11.11.13.2.10" class="ltx_td ltx_align_left">55.1</td>
</tr>
<tr id="A2.T5.11.11.11.11.14.3" class="ltx_tr">
<td id="A2.T5.11.11.11.11.14.3.1" class="ltx_td ltx_align_left ltx_border_r">GGNÂ <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="A2.T5.11.11.11.11.14.3.2" class="ltx_td ltx_align_left ltx_border_r">27.1</td>
<td id="A2.T5.11.11.11.11.14.3.3" class="ltx_td ltx_align_left ltx_border_r">22.5</td>
<td id="A2.T5.11.11.11.11.14.3.4" class="ltx_td ltx_align_left ltx_border_r">15.7</td>
<td id="A2.T5.11.11.11.11.14.3.5" class="ltx_td ltx_align_left ltx_border_r">35.5</td>
<td id="A2.T5.11.11.11.11.14.3.6" class="ltx_td ltx_align_left ltx_border_r">38.4</td>
<td id="A2.T5.11.11.11.11.14.3.7" class="ltx_td ltx_align_left ltx_border_r">45.6</td>
<td id="A2.T5.11.11.11.11.14.3.8" class="ltx_td ltx_align_left ltx_border_r">25.6</td>
<td id="A2.T5.11.11.11.11.14.3.9" class="ltx_td ltx_align_left ltx_border_r">43.2</td>
<td id="A2.T5.11.11.11.11.14.3.10" class="ltx_td ltx_align_left">54.9</td>
</tr>
<tr id="A2.T5.11.11.11.11.15.4" class="ltx_tr">
<td id="A2.T5.11.11.11.11.15.4.1" class="ltx_td ltx_align_left ltx_border_r">SelfTrain-RGB</td>
<td id="A2.T5.11.11.11.11.15.4.2" class="ltx_td ltx_align_left ltx_border_r">32.6</td>
<td id="A2.T5.11.11.11.11.15.4.3" class="ltx_td ltx_align_left ltx_border_r">28.3</td>
<td id="A2.T5.11.11.11.11.15.4.4" class="ltx_td ltx_align_left ltx_border_r">19.0</td>
<td id="A2.T5.11.11.11.11.15.4.5" class="ltx_td ltx_align_left ltx_border_r">45.7</td>
<td id="A2.T5.11.11.11.11.15.4.6" class="ltx_td ltx_align_left ltx_border_r">52.2</td>
<td id="A2.T5.11.11.11.11.15.4.7" class="ltx_td ltx_align_left ltx_border_r">48.7</td>
<td id="A2.T5.11.11.11.11.15.4.8" class="ltx_td ltx_align_left ltx_border_r">35.8</td>
<td id="A2.T5.11.11.11.11.15.4.9" class="ltx_td ltx_align_left ltx_border_r">48.8</td>
<td id="A2.T5.11.11.11.11.15.4.10" class="ltx_td ltx_align_left">53.5</td>
</tr>
<tr id="A2.T5.11.11.11.11.16.5" class="ltx_tr">
<td id="A2.T5.11.11.11.11.16.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Depth</td>
<td id="A2.T5.11.11.11.11.16.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.8</td>
<td id="A2.T5.11.11.11.11.16.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.3</td>
<td id="A2.T5.11.11.11.11.16.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.3</td>
<td id="A2.T5.11.11.11.11.16.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">46.8</td>
<td id="A2.T5.11.11.11.11.16.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A2.T5.11.11.11.11.16.5.6.1" class="ltx_text ltx_font_bold">54.1</span></td>
<td id="A2.T5.11.11.11.11.16.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A2.T5.11.11.11.11.16.5.7.1" class="ltx_text ltx_font_bold">50.3</span></td>
<td id="A2.T5.11.11.11.11.16.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.6</td>
<td id="A2.T5.11.11.11.11.16.5.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.9</td>
<td id="A2.T5.11.11.11.11.16.5.10" class="ltx_td ltx_align_left ltx_border_t"><span id="A2.T5.11.11.11.11.16.5.10.1" class="ltx_text ltx_font_bold">56.4</span></td>
</tr>
<tr id="A2.T5.11.11.11.11.17.6" class="ltx_tr">
<td id="A2.T5.11.11.11.11.17.6.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Normal</td>
<td id="A2.T5.11.11.11.11.17.6.2" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.2.1" class="ltx_text ltx_font_bold">33.4</span></td>
<td id="A2.T5.11.11.11.11.17.6.3" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.3.1" class="ltx_text ltx_font_bold">29.2</span></td>
<td id="A2.T5.11.11.11.11.17.6.4" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.4.1" class="ltx_text ltx_font_bold">19.3</span></td>
<td id="A2.T5.11.11.11.11.17.6.5" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.5.1" class="ltx_text ltx_font_bold">49.8</span></td>
<td id="A2.T5.11.11.11.11.17.6.6" class="ltx_td ltx_align_left ltx_border_r">53.3</td>
<td id="A2.T5.11.11.11.11.17.6.7" class="ltx_td ltx_align_left ltx_border_r">49.8</td>
<td id="A2.T5.11.11.11.11.17.6.8" class="ltx_td ltx_align_left ltx_border_r">35.8</td>
<td id="A2.T5.11.11.11.11.17.6.9" class="ltx_td ltx_align_left ltx_border_r">50.0</td>
<td id="A2.T5.11.11.11.11.17.6.10" class="ltx_td ltx_align_left">55.0</td>
</tr>
<tr id="A2.T5.11.11.11.11.18.7" class="ltx_tr">
<td id="A2.T5.11.11.11.11.18.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="A2.T5.11.11.11.11.18.7.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">33.2</td>
<td id="A2.T5.11.11.11.11.18.7.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">29.0</td>
<td id="A2.T5.11.11.11.11.18.7.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">19.0</td>
<td id="A2.T5.11.11.11.11.18.7.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">47.7</td>
<td id="A2.T5.11.11.11.11.18.7.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">53.0</td>
<td id="A2.T5.11.11.11.11.18.7.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A2.T5.11.11.11.11.18.7.7.1" class="ltx_text ltx_font_bold">50.3</span></td>
<td id="A2.T5.11.11.11.11.18.7.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A2.T5.11.11.11.11.18.7.8.1" class="ltx_text ltx_font_bold">36.1</span></td>
<td id="A2.T5.11.11.11.11.18.7.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A2.T5.11.11.11.11.18.7.9.1" class="ltx_text ltx_font_bold">50.2</span></td>
<td id="A2.T5.11.11.11.11.18.7.10" class="ltx_td ltx_align_left ltx_border_bb">55.4</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="A2.T5.13.1" class="ltx_text ltx_font_bold">More benchmarks.</span> The same methods in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.1 Detecting unknown objects in an open world â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> are compared. </figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>More ablation studies</h2>

<figure id="A3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x6.png" id="A3.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Choice of ensembling geometric cues.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x7.png" id="A3.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Fusing inputs: whether to use RGB.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x8.png" id="A3.F6.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="237" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Ensemble pseudo boxes: whether to use RGB.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/appendix/pseudo_boxes_rgb_depth_normal_large_legend.png" id="A3.F6.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="305" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Histograms of top1 pseudo box sizes from models trained on COCO VOC with different modalities.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="A3.F6.2.1" class="ltx_text ltx_font_bold">More ablation studies.</span> </figcaption>
</figure>
<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Ensembling ways of geometric cues</h3>

<div id="A3.SS1.p1" class="ltx_para ltx_noindent">
<p id="A3.SS1.p1.1" class="ltx_p">There are two possible ways to ensemble geometric cues: (1) Stack the two geometric cues together and train a single object proposal network on these stacked inputs in Phase-I; (2) Train two object proposal networks and extract pseudo boxes separately, then merge them into a single pseudo box pool for Phase-II training. The details of the merging process is described in AppendixÂ <a href="#A1" title="Appendix A Implementation details â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. We conduct ablation studies on these two methods. From FigureÂ <a href="#A3.F6.sf1" title="In Figure 6 â€£ Appendix C More ablation studies â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, we demonstrate that empirically, ensembling pseudo labels is slightly better than using stacked inputs for Phase-I training. Throughout the paper, we use the pseudo label ensembling for GOOD-Both.</p>
</div>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>On incorporating RGB in Phase-I</h3>

<div id="A3.SS2.p1" class="ltx_para ltx_noindent">
<p id="A3.SS2.p1.1" class="ltx_p">It is natural to think of incorporating RGB in Phase-I.
To do so, we can also consider the two ways for ensembling geometric cues.
If we stack RGB with geometric cues to train the proposal network, the model will tend to make more use of RGB to optimize the target localization loss. This is because RGB is a much stronger input signal than geometric cues in the closed-world setup â€” AR@100<sub id="A3.SS2.p1.1.1" class="ltx_sub"><span id="A3.SS2.p1.1.1.1" class="ltx_text ltx_font_italic">base</span></sub> is 58.3 for RGB inputs alone and 44.9 when stacking depth and normals on COCO VOC classes. In the extreme case, the model can even completely ignore geometric cues. This reliance on RGB inputs prevents the model from making the best use of geometric cues to discover novel objects in Phase-I, which is crucial for open-world object detection.
As shown in FigureÂ <a href="#A3.F6.sf2" title="In Figure 6 â€£ Appendix C More ablation studies â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, stacking RGB with geometric cues leads to inferior performance across many benchmarks.</p>
</div>
<div id="A3.SS2.p2" class="ltx_para ltx_noindent">
<p id="A3.SS2.p2.2" class="ltx_p">Alternatively, we can train a separate object proposal on RGB inputs, extract pseudo boxes, and merge them with those extracted from models trained on geometric cues. We can name this method â€œGOOD-Allâ€. In FigureÂ <a href="#A3.F6.sf3" title="In Figure 6 â€£ Appendix C More ablation studies â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a>, we compare GOOD-All with GOOD-Both and find that adding pseudo boxes from RGB (i.e., GOOD-All) either leads to no performance gains or even worsens the performance on benchmarks like VOC to ADE20K. To understand this, we note that object proposal networks trained on RGB favor smaller detection boxes, as evidenced in our visualizations (FigureÂ <a href="#A5.F10" title="Figure 10 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>,Â <a href="#A5.F11" title="Figure 11 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>) and more quantitatively in histograms (FigureÂ <a href="#A3.F6.sf4" title="In Figure 6 â€£ Appendix C More ablation studies â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(d)</span></a>). These smaller detection boxes can either be small objects or just textures and parts of larger objects, which can potentially hurt the performance of the final detector to detect large objects. This is consistent with our observations in TableÂ <a href="#A3.T6" title="Table 6 â€£ C.2 On incorporating RGB in Phase-I â€£ Appendix C More ablation studies â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Compared to GOOD-Both, the gains in AR<math id="A3.SS2.p2.1.m1.1" class="ltx_Math" alttext="{}_{N(A)}^{s}" display="inline"><semantics id="A3.SS2.p2.1.m1.1a"><mmultiscripts id="A3.SS2.p2.1.m1.1.2" xref="A3.SS2.p2.1.m1.1.2.cmml"><mi id="A3.SS2.p2.1.m1.1.2.2.2" xref="A3.SS2.p2.1.m1.1.2.2.2.cmml"></mi><mprescripts id="A3.SS2.p2.1.m1.1.2a" xref="A3.SS2.p2.1.m1.1.2.cmml"></mprescripts><mrow id="A3.SS2.p2.1.m1.1.2b" xref="A3.SS2.p2.1.m1.1.2.cmml"></mrow><mi id="A3.SS2.p2.1.m1.1.2.3" xref="A3.SS2.p2.1.m1.1.2.3.cmml">s</mi><mrow id="A3.SS2.p2.1.m1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml"><mi id="A3.SS2.p2.1.m1.1.1.1.3" xref="A3.SS2.p2.1.m1.1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="A3.SS2.p2.1.m1.1.1.1.2" xref="A3.SS2.p2.1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="A3.SS2.p2.1.m1.1.1.1.4.2" xref="A3.SS2.p2.1.m1.1.1.1.cmml"><mo stretchy="false" id="A3.SS2.p2.1.m1.1.1.1.4.2.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml">(</mo><mi id="A3.SS2.p2.1.m1.1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.1.cmml">A</mi><mo stretchy="false" id="A3.SS2.p2.1.m1.1.1.1.4.2.2" xref="A3.SS2.p2.1.m1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="A3.SS2.p2.1.m1.1.2c" xref="A3.SS2.p2.1.m1.1.2.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.1.m1.1b"><apply id="A3.SS2.p2.1.m1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.1.m1.1.2.1.cmml" xref="A3.SS2.p2.1.m1.1.2">superscript</csymbol><apply id="A3.SS2.p2.1.m1.1.2.2.cmml" xref="A3.SS2.p2.1.m1.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.1.m1.1.2.2.1.cmml" xref="A3.SS2.p2.1.m1.1.2">subscript</csymbol><csymbol cd="latexml" id="A3.SS2.p2.1.m1.1.2.2.2.cmml" xref="A3.SS2.p2.1.m1.1.2.2.2">absent</csymbol><apply id="A3.SS2.p2.1.m1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1"><times id="A3.SS2.p2.1.m1.1.1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.1.1.2"></times><ci id="A3.SS2.p2.1.m1.1.1.1.3.cmml" xref="A3.SS2.p2.1.m1.1.1.1.3">ğ‘</ci><ci id="A3.SS2.p2.1.m1.1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1.1">ğ´</ci></apply></apply><ci id="A3.SS2.p2.1.m1.1.2.3.cmml" xref="A3.SS2.p2.1.m1.1.2.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.1.m1.1c">{}_{N(A)}^{s}</annotation></semantics></math> are usually too small to compensate for the losses in AR<math id="A3.SS2.p2.2.m2.1" class="ltx_Math" alttext="{}_{N(A)}^{l}" display="inline"><semantics id="A3.SS2.p2.2.m2.1a"><mmultiscripts id="A3.SS2.p2.2.m2.1.2" xref="A3.SS2.p2.2.m2.1.2.cmml"><mi id="A3.SS2.p2.2.m2.1.2.2.2" xref="A3.SS2.p2.2.m2.1.2.2.2.cmml"></mi><mprescripts id="A3.SS2.p2.2.m2.1.2a" xref="A3.SS2.p2.2.m2.1.2.cmml"></mprescripts><mrow id="A3.SS2.p2.2.m2.1.2b" xref="A3.SS2.p2.2.m2.1.2.cmml"></mrow><mi id="A3.SS2.p2.2.m2.1.2.3" xref="A3.SS2.p2.2.m2.1.2.3.cmml">l</mi><mrow id="A3.SS2.p2.2.m2.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml"><mi id="A3.SS2.p2.2.m2.1.1.1.3" xref="A3.SS2.p2.2.m2.1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="A3.SS2.p2.2.m2.1.1.1.2" xref="A3.SS2.p2.2.m2.1.1.1.2.cmml">â€‹</mo><mrow id="A3.SS2.p2.2.m2.1.1.1.4.2" xref="A3.SS2.p2.2.m2.1.1.1.cmml"><mo stretchy="false" id="A3.SS2.p2.2.m2.1.1.1.4.2.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml">(</mo><mi id="A3.SS2.p2.2.m2.1.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.1.cmml">A</mi><mo stretchy="false" id="A3.SS2.p2.2.m2.1.1.1.4.2.2" xref="A3.SS2.p2.2.m2.1.1.1.cmml">)</mo></mrow></mrow><mrow id="A3.SS2.p2.2.m2.1.2c" xref="A3.SS2.p2.2.m2.1.2.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.2.m2.1b"><apply id="A3.SS2.p2.2.m2.1.2.cmml" xref="A3.SS2.p2.2.m2.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.2.m2.1.2.1.cmml" xref="A3.SS2.p2.2.m2.1.2">superscript</csymbol><apply id="A3.SS2.p2.2.m2.1.2.2.cmml" xref="A3.SS2.p2.2.m2.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.2.m2.1.2.2.1.cmml" xref="A3.SS2.p2.2.m2.1.2">subscript</csymbol><csymbol cd="latexml" id="A3.SS2.p2.2.m2.1.2.2.2.cmml" xref="A3.SS2.p2.2.m2.1.2.2.2">absent</csymbol><apply id="A3.SS2.p2.2.m2.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1"><times id="A3.SS2.p2.2.m2.1.1.1.2.cmml" xref="A3.SS2.p2.2.m2.1.1.1.2"></times><ci id="A3.SS2.p2.2.m2.1.1.1.3.cmml" xref="A3.SS2.p2.2.m2.1.1.1.3">ğ‘</ci><ci id="A3.SS2.p2.2.m2.1.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1.1">ğ´</ci></apply></apply><ci id="A3.SS2.p2.2.m2.1.2.3.cmml" xref="A3.SS2.p2.2.m2.1.2.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.2.m2.1c">{}_{N(A)}^{l}</annotation></semantics></math>, leading to the inferior overall performance of GOOD-All.</p>
</div>
<figure id="A3.T6" class="ltx_table">
<div id="A3.T6.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:76.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,2.0pt) scale(0.95,0.95) ;">
<div id="A3.T6.11.11" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:80pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(19.9pt,-4.0pt) scale(1.11103914474269,1.11103914474269) ;">
<table id="A3.T6.11.11.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T6.2.2.2.2" class="ltx_tr">
<th id="A3.T6.2.2.2.2.3" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="A3.T6.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="5"><span id="A3.T6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T6.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T6.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A3.T6.1.1.1.1.1.1.m1.1.1" xref="A3.T6.1.1.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A3.T6.1.1.1.1.1.1.m1.1b"><ci id="A3.T6.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T6.1.1.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-VOC</span></th>
<th id="A3.T6.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="A3.T6.2.2.2.2.2.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T6.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T6.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="A3.T6.2.2.2.2.2.1.m1.1.1" xref="A3.T6.2.2.2.2.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A3.T6.2.2.2.2.2.1.m1.1b"><ci id="A3.T6.2.2.2.2.2.1.m1.1.1.cmml" xref="A3.T6.2.2.2.2.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></th>
</tr>
<tr id="A3.T6.11.11.11.11" class="ltx_tr">
<th id="A3.T6.11.11.11.11.10" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Method</th>
<th id="A3.T6.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T6.3.3.3.3.1.1" class="ltx_sub"><span id="A3.T6.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T6.4.4.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T6.4.4.4.4.2.1" class="ltx_sub"><span id="A3.T6.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="A3.T6.5.5.5.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A3.T6.5.5.5.5.3.m1.1a"><mmultiscripts id="A3.T6.5.5.5.5.3.m1.1.1" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"><mi id="A3.T6.5.5.5.5.3.m1.1.1.2.2" xref="A3.T6.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.5.5.5.5.3.m1.1.1a" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.5.5.5.5.3.m1.1.1b" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="A3.T6.5.5.5.5.3.m1.1.1.3" xref="A3.T6.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="A3.T6.5.5.5.5.3.m1.1.1.2.3" xref="A3.T6.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T6.5.5.5.5.3.m1.1.1c" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.5.5.5.5.3.m1.1b"><apply id="A3.T6.5.5.5.5.3.m1.1.1.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.5.5.5.5.3.m1.1.1.1.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="A3.T6.5.5.5.5.3.m1.1.1.2.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.5.5.5.5.3.m1.1.1.2.1.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.5.5.5.5.3.m1.1.1.2.2.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.5.5.5.5.3.m1.1.1.2.3.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="A3.T6.5.5.5.5.3.m1.1.1.3.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="A3.T6.6.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A3.T6.6.6.6.6.4.m1.1a"><mmultiscripts id="A3.T6.6.6.6.6.4.m1.1.1" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"><mi id="A3.T6.6.6.6.6.4.m1.1.1.2.2" xref="A3.T6.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.6.6.6.6.4.m1.1.1a" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.6.6.6.6.4.m1.1.1b" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="A3.T6.6.6.6.6.4.m1.1.1.3" xref="A3.T6.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="A3.T6.6.6.6.6.4.m1.1.1.2.3" xref="A3.T6.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T6.6.6.6.6.4.m1.1.1c" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.6.6.6.6.4.m1.1b"><apply id="A3.T6.6.6.6.6.4.m1.1.1.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.6.6.6.6.4.m1.1.1.1.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="A3.T6.6.6.6.6.4.m1.1.1.2.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.6.6.6.6.4.m1.1.1.2.1.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.6.6.6.6.4.m1.1.1.2.2.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.6.6.6.6.4.m1.1.1.2.3.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="A3.T6.6.6.6.6.4.m1.1.1.3.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="A3.T6.7.7.7.7.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A3.T6.7.7.7.7.5.m1.1a"><mmultiscripts id="A3.T6.7.7.7.7.5.m1.1.1" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"><mi id="A3.T6.7.7.7.7.5.m1.1.1.2.2" xref="A3.T6.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.7.7.7.7.5.m1.1.1a" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.7.7.7.7.5.m1.1.1b" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="A3.T6.7.7.7.7.5.m1.1.1.3" xref="A3.T6.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="A3.T6.7.7.7.7.5.m1.1.1.2.3" xref="A3.T6.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T6.7.7.7.7.5.m1.1.1c" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.7.7.7.7.5.m1.1b"><apply id="A3.T6.7.7.7.7.5.m1.1.1.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.7.7.7.7.5.m1.1.1.1.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="A3.T6.7.7.7.7.5.m1.1.1.2.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.7.7.7.7.5.m1.1.1.2.1.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.7.7.7.7.5.m1.1.1.2.2.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.7.7.7.7.5.m1.1.1.2.3.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1.2.3">ğ‘</ci></apply><ci id="A3.T6.7.7.7.7.5.m1.1.1.3.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
<th id="A3.T6.8.8.8.8.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T6.8.8.8.8.6.1" class="ltx_sub"><span id="A3.T6.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T6.9.9.9.9.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="A3.T6.9.9.9.9.7.m1.1a"><mmultiscripts id="A3.T6.9.9.9.9.7.m1.1.1" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"><mi id="A3.T6.9.9.9.9.7.m1.1.1.2.2" xref="A3.T6.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.9.9.9.9.7.m1.1.1a" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.9.9.9.9.7.m1.1.1b" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="A3.T6.9.9.9.9.7.m1.1.1.3" xref="A3.T6.9.9.9.9.7.m1.1.1.3.cmml">s</mi><mi id="A3.T6.9.9.9.9.7.m1.1.1.2.3" xref="A3.T6.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T6.9.9.9.9.7.m1.1.1c" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.9.9.9.9.7.m1.1b"><apply id="A3.T6.9.9.9.9.7.m1.1.1.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.9.9.9.9.7.m1.1.1.1.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="A3.T6.9.9.9.9.7.m1.1.1.2.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.9.9.9.9.7.m1.1.1.2.1.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.9.9.9.9.7.m1.1.1.2.2.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.9.9.9.9.7.m1.1.1.2.3.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1.2.3">ğ´</ci></apply><ci id="A3.T6.9.9.9.9.7.m1.1.1.3.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.9.9.9.9.7.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</th>
<th id="A3.T6.10.10.10.10.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="A3.T6.10.10.10.10.8.m1.1a"><mmultiscripts id="A3.T6.10.10.10.10.8.m1.1.1" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"><mi id="A3.T6.10.10.10.10.8.m1.1.1.2.2" xref="A3.T6.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.10.10.10.10.8.m1.1.1a" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.10.10.10.10.8.m1.1.1b" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="A3.T6.10.10.10.10.8.m1.1.1.3" xref="A3.T6.10.10.10.10.8.m1.1.1.3.cmml">m</mi><mi id="A3.T6.10.10.10.10.8.m1.1.1.2.3" xref="A3.T6.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T6.10.10.10.10.8.m1.1.1c" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.10.10.10.10.8.m1.1b"><apply id="A3.T6.10.10.10.10.8.m1.1.1.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.10.10.10.10.8.m1.1.1.1.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="A3.T6.10.10.10.10.8.m1.1.1.2.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.10.10.10.10.8.m1.1.1.2.1.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.10.10.10.10.8.m1.1.1.2.2.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.10.10.10.10.8.m1.1.1.2.3.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1.2.3">ğ´</ci></apply><ci id="A3.T6.10.10.10.10.8.m1.1.1.3.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.10.10.10.10.8.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</th>
<th id="A3.T6.11.11.11.11.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">AR<math id="A3.T6.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="A3.T6.11.11.11.11.9.m1.1a"><mmultiscripts id="A3.T6.11.11.11.11.9.m1.1.1" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"><mi id="A3.T6.11.11.11.11.9.m1.1.1.2.2" xref="A3.T6.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.11.11.11.11.9.m1.1.1a" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.11.11.11.11.9.m1.1.1b" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="A3.T6.11.11.11.11.9.m1.1.1.3" xref="A3.T6.11.11.11.11.9.m1.1.1.3.cmml">l</mi><mi id="A3.T6.11.11.11.11.9.m1.1.1.2.3" xref="A3.T6.11.11.11.11.9.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T6.11.11.11.11.9.m1.1.1c" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.11.11.11.11.9.m1.1b"><apply id="A3.T6.11.11.11.11.9.m1.1.1.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.11.11.11.11.9.m1.1.1.1.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="A3.T6.11.11.11.11.9.m1.1.1.2.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.11.11.11.11.9.m1.1.1.2.1.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.11.11.11.11.9.m1.1.1.2.2.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.11.11.11.11.9.m1.1.1.2.3.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1.2.3">ğ´</ci></apply><ci id="A3.T6.11.11.11.11.9.m1.1.1.3.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.11.11.11.11.9.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T6.11.11.11.12.1" class="ltx_tr">
<td id="A3.T6.11.11.11.12.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Both</td>
<td id="A3.T6.11.11.11.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.2.1" class="ltx_text ltx_font_bold">49.5</span></td>
<td id="A3.T6.11.11.11.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.3.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="A3.T6.11.11.11.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.6</td>
<td id="A3.T6.11.11.11.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.5.1" class="ltx_text ltx_font_bold">48.2</span></td>
<td id="A3.T6.11.11.11.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.6.1" class="ltx_text ltx_font_bold">62.4</span></td>
<td id="A3.T6.11.11.11.12.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.7.1" class="ltx_text ltx_font_bold">34.0</span></td>
<td id="A3.T6.11.11.11.12.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.9</td>
<td id="A3.T6.11.11.11.12.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.9.1" class="ltx_text ltx_font_bold">37.0</span></td>
<td id="A3.T6.11.11.11.12.1.10" class="ltx_td ltx_align_left ltx_border_t"><span id="A3.T6.11.11.11.12.1.10.1" class="ltx_text ltx_font_bold">39.9</span></td>
</tr>
<tr id="A3.T6.11.11.11.13.2" class="ltx_tr">
<td id="A3.T6.11.11.11.13.2.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-All</td>
<td id="A3.T6.11.11.11.13.2.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">48.5</td>
<td id="A3.T6.11.11.11.13.2.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A3.T6.11.11.11.13.2.3.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="A3.T6.11.11.11.13.2.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A3.T6.11.11.11.13.2.4.1" class="ltx_text ltx_font_bold">22.7</span></td>
<td id="A3.T6.11.11.11.13.2.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">47.6</td>
<td id="A3.T6.11.11.11.13.2.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">60.8</td>
<td id="A3.T6.11.11.11.13.2.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">33.3</td>
<td id="A3.T6.11.11.11.13.2.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A3.T6.11.11.11.13.2.8.1" class="ltx_text ltx_font_bold">22.9</span></td>
<td id="A3.T6.11.11.11.13.2.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">36.2</td>
<td id="A3.T6.11.11.11.13.2.10" class="ltx_td ltx_align_left ltx_border_bb">38.0</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span><span id="A3.T6.22.1" class="ltx_text ltx_font_bold">More comparison of GOOD-Both and GOOD-All.</span> For GOOD-All, the performance gains in detecting small objects (AR<sup id="A3.T6.23.2" class="ltx_sup"><span id="A3.T6.23.2.1" class="ltx_text ltx_font_italic">s</span></sup>) are too small to compensate for the losses in detecting larger objects (AR<sup id="A3.T6.24.3" class="ltx_sup"><span id="A3.T6.24.3.1" class="ltx_text ltx_font_italic">m</span></sup> and (AR<sup id="A3.T6.25.4" class="ltx_sup"><span id="A3.T6.25.4.1" class="ltx_text ltx_font_italic">l</span></sup>)), leading to overall inferior performance.</figcaption>
</figure>
</section>
<section id="A3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Architecture choice</h3>

<div id="A3.SS3.p1" class="ltx_para ltx_noindent">
<p id="A3.SS3.p1.1" class="ltx_p">In principle, our approach is model agnostic and is therefore compatible with both proposal-free and proposal-based object detectors. To demonstrate this, besides the two-stage proposal-based detectors in the main paper, we also experiment with a more recent single-stage proposal-free object detector FCOSÂ <cite class="ltx_cite ltx_citemacro_citep">(Tian etÂ al., <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite>.
Specifically, we kept Phase I unchanged, i.e., generating the geometric cue-based pseudo boxes using OLN as the architecture. In Phase II, we train a class-agnostic FCOS using the extracted pseudo boxes together with the groundtruth annotations of the base classes.
The experiment results are shown in TableÂ <a href="#A3.T7" title="Table 7 â€£ C.3 Architecture choice â€£ Appendix C More ablation studies â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We can see that GOOD can significantly improve FCOS in terms of detecting novel objects and OLN is a stronger architecture than FCOS to be used in GOOD.</p>
</div>
<figure id="A3.T7" class="ltx_table">
<div id="A3.T7.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:104pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,2.7pt) scale(0.95,0.95) ;">
<div id="A3.T7.11.11" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:108.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.9pt,-0.2pt) scale(1.00457085249424,1.00457085249424) ;">
<table id="A3.T7.11.11.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T7.2.2.2.2" class="ltx_tr">
<th id="A3.T7.2.2.2.2.3" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="A3.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="5"><span id="A3.T7.1.1.1.1.1.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T7.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T7.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A3.T7.1.1.1.1.1.1.m1.1.1" xref="A3.T7.1.1.1.1.1.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A3.T7.1.1.1.1.1.1.m1.1b"><ci id="A3.T7.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T7.1.1.1.1.1.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-VOC</span></th>
<th id="A3.T7.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="A3.T7.2.2.2.2.2.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T7.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T7.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="A3.T7.2.2.2.2.2.1.m1.1.1" xref="A3.T7.2.2.2.2.2.1.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="A3.T7.2.2.2.2.2.1.m1.1b"><ci id="A3.T7.2.2.2.2.2.1.m1.1.1.cmml" xref="A3.T7.2.2.2.2.2.1.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></th>
</tr>
<tr id="A3.T7.11.11.11.11" class="ltx_tr">
<th id="A3.T7.11.11.11.11.10" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Method</th>
<th id="A3.T7.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T7.3.3.3.3.1.1" class="ltx_sub"><span id="A3.T7.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T7.4.4.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T7.4.4.4.4.2.1" class="ltx_sub"><span id="A3.T7.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="A3.T7.5.5.5.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A3.T7.5.5.5.5.3.m1.1a"><mmultiscripts id="A3.T7.5.5.5.5.3.m1.1.1" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"><mi id="A3.T7.5.5.5.5.3.m1.1.1.2.2" xref="A3.T7.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.5.5.5.5.3.m1.1.1a" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.5.5.5.5.3.m1.1.1b" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="A3.T7.5.5.5.5.3.m1.1.1.3" xref="A3.T7.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="A3.T7.5.5.5.5.3.m1.1.1.2.3" xref="A3.T7.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T7.5.5.5.5.3.m1.1.1c" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.5.5.5.5.3.m1.1b"><apply id="A3.T7.5.5.5.5.3.m1.1.1.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.5.5.5.5.3.m1.1.1.1.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="A3.T7.5.5.5.5.3.m1.1.1.2.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.5.5.5.5.3.m1.1.1.2.1.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.5.5.5.5.3.m1.1.1.2.2.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.5.5.5.5.3.m1.1.1.2.3.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="A3.T7.5.5.5.5.3.m1.1.1.3.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="A3.T7.6.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A3.T7.6.6.6.6.4.m1.1a"><mmultiscripts id="A3.T7.6.6.6.6.4.m1.1.1" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"><mi id="A3.T7.6.6.6.6.4.m1.1.1.2.2" xref="A3.T7.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.6.6.6.6.4.m1.1.1a" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.6.6.6.6.4.m1.1.1b" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="A3.T7.6.6.6.6.4.m1.1.1.3" xref="A3.T7.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="A3.T7.6.6.6.6.4.m1.1.1.2.3" xref="A3.T7.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T7.6.6.6.6.4.m1.1.1c" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.6.6.6.6.4.m1.1b"><apply id="A3.T7.6.6.6.6.4.m1.1.1.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.6.6.6.6.4.m1.1.1.1.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="A3.T7.6.6.6.6.4.m1.1.1.2.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.6.6.6.6.4.m1.1.1.2.1.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.6.6.6.6.4.m1.1.1.2.2.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.6.6.6.6.4.m1.1.1.2.3.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="A3.T7.6.6.6.6.4.m1.1.1.3.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="A3.T7.7.7.7.7.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A3.T7.7.7.7.7.5.m1.1a"><mmultiscripts id="A3.T7.7.7.7.7.5.m1.1.1" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"><mi id="A3.T7.7.7.7.7.5.m1.1.1.2.2" xref="A3.T7.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.7.7.7.7.5.m1.1.1a" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.7.7.7.7.5.m1.1.1b" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="A3.T7.7.7.7.7.5.m1.1.1.3" xref="A3.T7.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="A3.T7.7.7.7.7.5.m1.1.1.2.3" xref="A3.T7.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T7.7.7.7.7.5.m1.1.1c" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.7.7.7.7.5.m1.1b"><apply id="A3.T7.7.7.7.7.5.m1.1.1.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.7.7.7.7.5.m1.1.1.1.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="A3.T7.7.7.7.7.5.m1.1.1.2.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.7.7.7.7.5.m1.1.1.2.1.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.7.7.7.7.5.m1.1.1.2.2.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.7.7.7.7.5.m1.1.1.2.3.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1.2.3">ğ‘</ci></apply><ci id="A3.T7.7.7.7.7.5.m1.1.1.3.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
<th id="A3.T7.8.8.8.8.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T7.8.8.8.8.6.1" class="ltx_sub"><span id="A3.T7.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T7.9.9.9.9.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="A3.T7.9.9.9.9.7.m1.1a"><mmultiscripts id="A3.T7.9.9.9.9.7.m1.1.1" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"><mi id="A3.T7.9.9.9.9.7.m1.1.1.2.2" xref="A3.T7.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.9.9.9.9.7.m1.1.1a" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.9.9.9.9.7.m1.1.1b" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="A3.T7.9.9.9.9.7.m1.1.1.3" xref="A3.T7.9.9.9.9.7.m1.1.1.3.cmml">s</mi><mi id="A3.T7.9.9.9.9.7.m1.1.1.2.3" xref="A3.T7.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T7.9.9.9.9.7.m1.1.1c" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.9.9.9.9.7.m1.1b"><apply id="A3.T7.9.9.9.9.7.m1.1.1.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.9.9.9.9.7.m1.1.1.1.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="A3.T7.9.9.9.9.7.m1.1.1.2.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.9.9.9.9.7.m1.1.1.2.1.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.9.9.9.9.7.m1.1.1.2.2.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.9.9.9.9.7.m1.1.1.2.3.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1.2.3">ğ´</ci></apply><ci id="A3.T7.9.9.9.9.7.m1.1.1.3.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.9.9.9.9.7.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</th>
<th id="A3.T7.10.10.10.10.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="A3.T7.10.10.10.10.8.m1.1a"><mmultiscripts id="A3.T7.10.10.10.10.8.m1.1.1" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"><mi id="A3.T7.10.10.10.10.8.m1.1.1.2.2" xref="A3.T7.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.10.10.10.10.8.m1.1.1a" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.10.10.10.10.8.m1.1.1b" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="A3.T7.10.10.10.10.8.m1.1.1.3" xref="A3.T7.10.10.10.10.8.m1.1.1.3.cmml">m</mi><mi id="A3.T7.10.10.10.10.8.m1.1.1.2.3" xref="A3.T7.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T7.10.10.10.10.8.m1.1.1c" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.10.10.10.10.8.m1.1b"><apply id="A3.T7.10.10.10.10.8.m1.1.1.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.10.10.10.10.8.m1.1.1.1.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="A3.T7.10.10.10.10.8.m1.1.1.2.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.10.10.10.10.8.m1.1.1.2.1.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.10.10.10.10.8.m1.1.1.2.2.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.10.10.10.10.8.m1.1.1.2.3.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1.2.3">ğ´</ci></apply><ci id="A3.T7.10.10.10.10.8.m1.1.1.3.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.10.10.10.10.8.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</th>
<th id="A3.T7.11.11.11.11.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">AR<math id="A3.T7.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="A3.T7.11.11.11.11.9.m1.1a"><mmultiscripts id="A3.T7.11.11.11.11.9.m1.1.1" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"><mi id="A3.T7.11.11.11.11.9.m1.1.1.2.2" xref="A3.T7.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.11.11.11.11.9.m1.1.1a" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.11.11.11.11.9.m1.1.1b" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="A3.T7.11.11.11.11.9.m1.1.1.3" xref="A3.T7.11.11.11.11.9.m1.1.1.3.cmml">l</mi><mi id="A3.T7.11.11.11.11.9.m1.1.1.2.3" xref="A3.T7.11.11.11.11.9.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T7.11.11.11.11.9.m1.1.1c" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.11.11.11.11.9.m1.1b"><apply id="A3.T7.11.11.11.11.9.m1.1.1.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.11.11.11.11.9.m1.1.1.1.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="A3.T7.11.11.11.11.9.m1.1.1.2.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.11.11.11.11.9.m1.1.1.2.1.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.11.11.11.11.9.m1.1.1.2.2.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.11.11.11.11.9.m1.1.1.2.3.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1.2.3">ğ´</ci></apply><ci id="A3.T7.11.11.11.11.9.m1.1.1.3.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.11.11.11.11.9.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T7.11.11.11.12.1" class="ltx_tr">
<td id="A3.T7.11.11.11.12.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FCOS</td>
<td id="A3.T7.11.11.11.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.6</td>
<td id="A3.T7.11.11.11.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.3</td>
<td id="A3.T7.11.11.11.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14.6</td>
<td id="A3.T7.11.11.11.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.7</td>
<td id="A3.T7.11.11.11.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.2</td>
<td id="A3.T7.11.11.11.12.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.6</td>
<td id="A3.T7.11.11.11.12.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">17.2</td>
<td id="A3.T7.11.11.11.12.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.5</td>
<td id="A3.T7.11.11.11.12.1.10" class="ltx_td ltx_align_left ltx_border_t">30.9</td>
</tr>
<tr id="A3.T7.11.11.11.13.2" class="ltx_tr">
<td id="A3.T7.11.11.11.13.2.1" class="ltx_td ltx_align_left ltx_border_r">OLN</td>
<td id="A3.T7.11.11.11.13.2.2" class="ltx_td ltx_align_left ltx_border_r">47.5</td>
<td id="A3.T7.11.11.11.13.2.3" class="ltx_td ltx_align_left ltx_border_r">33.2</td>
<td id="A3.T7.11.11.11.13.2.4" class="ltx_td ltx_align_left ltx_border_r">18.7</td>
<td id="A3.T7.11.11.11.13.2.5" class="ltx_td ltx_align_left ltx_border_r">39.3</td>
<td id="A3.T7.11.11.11.13.2.6" class="ltx_td ltx_align_left ltx_border_r">58.6</td>
<td id="A3.T7.11.11.11.13.2.7" class="ltx_td ltx_align_left ltx_border_r">29.2</td>
<td id="A3.T7.11.11.11.13.2.8" class="ltx_td ltx_align_left ltx_border_r">19.7</td>
<td id="A3.T7.11.11.11.13.2.9" class="ltx_td ltx_align_left ltx_border_r">30.7</td>
<td id="A3.T7.11.11.11.13.2.10" class="ltx_td ltx_align_left">34.4</td>
</tr>
<tr id="A3.T7.11.11.11.14.3" class="ltx_tr">
<td id="A3.T7.11.11.11.14.3.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Both (FCOS)</td>
<td id="A3.T7.11.11.11.14.3.2" class="ltx_td ltx_align_left ltx_border_r">48.4</td>
<td id="A3.T7.11.11.11.14.3.3" class="ltx_td ltx_align_left ltx_border_r">36.3</td>
<td id="A3.T7.11.11.11.14.3.4" class="ltx_td ltx_align_left ltx_border_r">18.4</td>
<td id="A3.T7.11.11.11.14.3.5" class="ltx_td ltx_align_left ltx_border_r">46.5</td>
<td id="A3.T7.11.11.11.14.3.6" class="ltx_td ltx_align_left ltx_border_r">58.0</td>
<td id="A3.T7.11.11.11.14.3.7" class="ltx_td ltx_align_left ltx_border_r">32.5</td>
<td id="A3.T7.11.11.11.14.3.8" class="ltx_td ltx_align_left ltx_border_r">20.1</td>
<td id="A3.T7.11.11.11.14.3.9" class="ltx_td ltx_align_left ltx_border_r">34.5</td>
<td id="A3.T7.11.11.11.14.3.10" class="ltx_td ltx_align_left">39.5</td>
</tr>
<tr id="A3.T7.11.11.11.15.4" class="ltx_tr">
<td id="A3.T7.11.11.11.15.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both (OLN)</td>
<td id="A3.T7.11.11.11.15.4.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">49.5</td>
<td id="A3.T7.11.11.11.15.4.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">39.3</td>
<td id="A3.T7.11.11.11.15.4.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.6</td>
<td id="A3.T7.11.11.11.15.4.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">48.2</td>
<td id="A3.T7.11.11.11.15.4.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">62.4</td>
<td id="A3.T7.11.11.11.15.4.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">34.0</td>
<td id="A3.T7.11.11.11.15.4.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.9</td>
<td id="A3.T7.11.11.11.15.4.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">37.0</td>
<td id="A3.T7.11.11.11.15.4.10" class="ltx_td ltx_align_left ltx_border_bb">39.9</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span><span id="A3.T7.13.1" class="ltx_text ltx_font_bold">Architecture choice.</span> FCOS is a single-stage proposal-free object detector, and OLN is a two-stage proposal-based object detector (modified from Faster R-CNN). GOOD can significantly improve the open-world performance of both architectures.</figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>More discussion on different modalities for GOOD</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p id="A4.p1.1" class="ltx_p">In this section, we further discuss how different modalities behave and can be further ensembled to boost the performance.
We first compare different modalities used for Phase-I training and pseudo labeling in GOOD on the COCO VOC to non-VOC benchmark.
In TableÂ <a href="#A4.T8" title="Table 8 â€£ Appendix D More discussion on different modalities for GOOD â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we show that pseudo-labeling using the geometric cues leads to stronger performances. This agrees with our study in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> where we found that pseudo boxes from proposal networks trained on geometric cues have higher AR<sub id="A4.p1.1.1" class="ltx_sub"><span id="A4.p1.1.1.1" class="ltx_text ltx_font_italic">N</span></sub>@5, indicating that they are of higher quality.</p>
</div>
<figure id="A4.T8" class="ltx_table">
<table id="A4.T8.4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T8.4.4.4" class="ltx_tr">
<th id="A4.T8.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Modality</th>
<th id="A4.T8.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="A4.T8.1.1.1.1.1" class="ltx_sub"><span id="A4.T8.1.1.1.1.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="A4.T8.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="A4.T8.2.2.2.2.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A4.T8.2.2.2.2.m1.1a"><mmultiscripts id="A4.T8.2.2.2.2.m1.1.1" xref="A4.T8.2.2.2.2.m1.1.1.cmml"><mi id="A4.T8.2.2.2.2.m1.1.1.2.2" xref="A4.T8.2.2.2.2.m1.1.1.2.2.cmml"></mi><mprescripts id="A4.T8.2.2.2.2.m1.1.1a" xref="A4.T8.2.2.2.2.m1.1.1.cmml"></mprescripts><mrow id="A4.T8.2.2.2.2.m1.1.1b" xref="A4.T8.2.2.2.2.m1.1.1.cmml"></mrow><mi id="A4.T8.2.2.2.2.m1.1.1.3" xref="A4.T8.2.2.2.2.m1.1.1.3.cmml">s</mi><mi id="A4.T8.2.2.2.2.m1.1.1.2.3" xref="A4.T8.2.2.2.2.m1.1.1.2.3.cmml">N</mi><mrow id="A4.T8.2.2.2.2.m1.1.1c" xref="A4.T8.2.2.2.2.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A4.T8.2.2.2.2.m1.1b"><apply id="A4.T8.2.2.2.2.m1.1.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.2.2.2.2.m1.1.1.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1">superscript</csymbol><apply id="A4.T8.2.2.2.2.m1.1.1.2.cmml" xref="A4.T8.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.2.2.2.2.m1.1.1.2.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A4.T8.2.2.2.2.m1.1.1.2.2.cmml" xref="A4.T8.2.2.2.2.m1.1.1.2.2">absent</csymbol><ci id="A4.T8.2.2.2.2.m1.1.1.2.3.cmml" xref="A4.T8.2.2.2.2.m1.1.1.2.3">ğ‘</ci></apply><ci id="A4.T8.2.2.2.2.m1.1.1.3.cmml" xref="A4.T8.2.2.2.2.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.2.2.2.2.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="A4.T8.3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="A4.T8.3.3.3.3.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A4.T8.3.3.3.3.m1.1a"><mmultiscripts id="A4.T8.3.3.3.3.m1.1.1" xref="A4.T8.3.3.3.3.m1.1.1.cmml"><mi id="A4.T8.3.3.3.3.m1.1.1.2.2" xref="A4.T8.3.3.3.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A4.T8.3.3.3.3.m1.1.1a" xref="A4.T8.3.3.3.3.m1.1.1.cmml"></mprescripts><mrow id="A4.T8.3.3.3.3.m1.1.1b" xref="A4.T8.3.3.3.3.m1.1.1.cmml"></mrow><mi id="A4.T8.3.3.3.3.m1.1.1.3" xref="A4.T8.3.3.3.3.m1.1.1.3.cmml">m</mi><mi id="A4.T8.3.3.3.3.m1.1.1.2.3" xref="A4.T8.3.3.3.3.m1.1.1.2.3.cmml">N</mi><mrow id="A4.T8.3.3.3.3.m1.1.1c" xref="A4.T8.3.3.3.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A4.T8.3.3.3.3.m1.1b"><apply id="A4.T8.3.3.3.3.m1.1.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.3.3.3.3.m1.1.1.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1">superscript</csymbol><apply id="A4.T8.3.3.3.3.m1.1.1.2.cmml" xref="A4.T8.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.3.3.3.3.m1.1.1.2.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A4.T8.3.3.3.3.m1.1.1.2.2.cmml" xref="A4.T8.3.3.3.3.m1.1.1.2.2">absent</csymbol><ci id="A4.T8.3.3.3.3.m1.1.1.2.3.cmml" xref="A4.T8.3.3.3.3.m1.1.1.2.3">ğ‘</ci></apply><ci id="A4.T8.3.3.3.3.m1.1.1.3.cmml" xref="A4.T8.3.3.3.3.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.3.3.3.3.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="A4.T8.4.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AR<math id="A4.T8.4.4.4.4.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A4.T8.4.4.4.4.m1.1a"><mmultiscripts id="A4.T8.4.4.4.4.m1.1.1" xref="A4.T8.4.4.4.4.m1.1.1.cmml"><mi id="A4.T8.4.4.4.4.m1.1.1.2.2" xref="A4.T8.4.4.4.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A4.T8.4.4.4.4.m1.1.1a" xref="A4.T8.4.4.4.4.m1.1.1.cmml"></mprescripts><mrow id="A4.T8.4.4.4.4.m1.1.1b" xref="A4.T8.4.4.4.4.m1.1.1.cmml"></mrow><mi id="A4.T8.4.4.4.4.m1.1.1.3" xref="A4.T8.4.4.4.4.m1.1.1.3.cmml">l</mi><mi id="A4.T8.4.4.4.4.m1.1.1.2.3" xref="A4.T8.4.4.4.4.m1.1.1.2.3.cmml">N</mi><mrow id="A4.T8.4.4.4.4.m1.1.1c" xref="A4.T8.4.4.4.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A4.T8.4.4.4.4.m1.1b"><apply id="A4.T8.4.4.4.4.m1.1.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.4.4.4.4.m1.1.1.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1">superscript</csymbol><apply id="A4.T8.4.4.4.4.m1.1.1.2.cmml" xref="A4.T8.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.4.4.4.4.m1.1.1.2.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A4.T8.4.4.4.4.m1.1.1.2.2.cmml" xref="A4.T8.4.4.4.4.m1.1.1.2.2">absent</csymbol><ci id="A4.T8.4.4.4.4.m1.1.1.2.3.cmml" xref="A4.T8.4.4.4.4.m1.1.1.2.3">ğ‘</ci></apply><ci id="A4.T8.4.4.4.4.m1.1.1.3.cmml" xref="A4.T8.4.4.4.4.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.4.4.4.4.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T8.4.4.5.1" class="ltx_tr">
<td id="A4.T8.4.4.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SelfTrain-RGB</td>
<td id="A4.T8.4.4.5.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.4</td>
<td id="A4.T8.4.4.5.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A4.T8.4.4.5.1.3.1" class="ltx_text ltx_font_bold">22.8</span></td>
<td id="A4.T8.4.4.5.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.9</td>
<td id="A4.T8.4.4.5.1.5" class="ltx_td ltx_align_left ltx_border_t">57.7</td>
</tr>
<tr id="A4.T8.4.4.6.2" class="ltx_tr">
<td id="A4.T8.4.4.6.2.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Edge</td>
<td id="A4.T8.4.4.6.2.2" class="ltx_td ltx_align_left ltx_border_r">38.1</td>
<td id="A4.T8.4.4.6.2.3" class="ltx_td ltx_align_left ltx_border_r">21.8</td>
<td id="A4.T8.4.4.6.2.4" class="ltx_td ltx_align_left ltx_border_r">45.7</td>
<td id="A4.T8.4.4.6.2.5" class="ltx_td ltx_align_left">60.2</td>
</tr>
<tr id="A4.T8.4.4.7.3" class="ltx_tr">
<td id="A4.T8.4.4.7.3.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-PA</td>
<td id="A4.T8.4.4.7.3.2" class="ltx_td ltx_align_left ltx_border_r">37.1</td>
<td id="A4.T8.4.4.7.3.3" class="ltx_td ltx_align_left ltx_border_r">18.6</td>
<td id="A4.T8.4.4.7.3.4" class="ltx_td ltx_align_left ltx_border_r">43.9</td>
<td id="A4.T8.4.4.7.3.5" class="ltx_td ltx_align_left"><span id="A4.T8.4.4.7.3.5.1" class="ltx_text ltx_font_bold">65.3</span></td>
</tr>
<tr id="A4.T8.4.4.8.4" class="ltx_tr">
<td id="A4.T8.4.4.8.4.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Depth</td>
<td id="A4.T8.4.4.8.4.2" class="ltx_td ltx_align_left ltx_border_r"><span id="A4.T8.4.4.8.4.2.1" class="ltx_text ltx_font_bold">39.0</span></td>
<td id="A4.T8.4.4.8.4.3" class="ltx_td ltx_align_left ltx_border_r">21.1</td>
<td id="A4.T8.4.4.8.4.4" class="ltx_td ltx_align_left ltx_border_r">47.5</td>
<td id="A4.T8.4.4.8.4.5" class="ltx_td ltx_align_left">63.2</td>
</tr>
<tr id="A4.T8.4.4.9.5" class="ltx_tr">
<td id="A4.T8.4.4.9.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Normal</td>
<td id="A4.T8.4.4.9.5.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">38.9</td>
<td id="A4.T8.4.4.9.5.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.4</td>
<td id="A4.T8.4.4.9.5.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A4.T8.4.4.9.5.4.1" class="ltx_text ltx_font_bold">47.9</span></td>
<td id="A4.T8.4.4.9.5.5" class="ltx_td ltx_align_left ltx_border_bb">62.4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span><span id="A4.T8.6.1" class="ltx_text ltx_font_bold">Comparison of GOOD using different modalities on COCO VOC to non-VOC benchmark.</span> </figcaption>
</figure>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Complementariness of different modalities</h3>

<div id="A4.SS1.p1" class="ltx_para ltx_noindent">
<p id="A4.SS1.p1.1" class="ltx_p">In the main paper, we have combined the pseudo boxes only from the geometric cues, i.e., depth and normals. GOOD-Both provides additional performance gains over GOOD-Depth and GOOD-Normal. As we have more than two sources of pseudo labeling, it is natural to examine further if they are complementary and thus can be jointly exploited. We first evaluate the overlap of their top-<math id="A4.SS1.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A4.SS1.p1.1.m1.1a"><mn id="A4.SS1.p1.1.m1.1.1" xref="A4.SS1.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A4.SS1.p1.1.m1.1b"><cn type="integer" id="A4.SS1.p1.1.m1.1.1.cmml" xref="A4.SS1.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p1.1.m1.1c">1</annotation></semantics></math> ranked pseudo boxes. Their most confident novel object detections best convey their bias in generalization. We can observe from FigureÂ <a href="#A4.F7.sf1" title="In Figure 7 â€£ D.1 Complementariness of different modalities â€£ Appendix D More discussion on different modalities for GOOD â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a> that the overlap is low across all the input types. TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.2 Advantages of geometric cues â€£ 4 Experiments â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and TableÂ <a href="#A4.T8" title="Table 8 â€£ Appendix D More discussion on different modalities for GOOD â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> further reveal their complementariness in detecting different sizes of objects. Both observations motivate us to ensemble different sources of pseudo boxes, exploiting their diversity for training the object detector.</p>
</div>
<div id="A4.SS1.p2" class="ltx_para ltx_noindent">
<p id="A4.SS1.p2.3" class="ltx_p">To decide which modality to ensemble first, we designed a simple greedy algorithm based on the overlap of pseudo boxes and the potential performance gain of adding the modality to the ensemble.
Specifically, starting with the best-performing modality (depth), we incrementally ensemble more sources of pseudo boxes by selecting the source with the highest <math id="A4.SS1.p2.1.m1.1" class="ltx_Math" alttext="Utility*Uniqueness" display="inline"><semantics id="A4.SS1.p2.1.m1.1a"><mrow id="A4.SS1.p2.1.m1.1.1" xref="A4.SS1.p2.1.m1.1.1.cmml"><mrow id="A4.SS1.p2.1.m1.1.1.2" xref="A4.SS1.p2.1.m1.1.1.2.cmml"><mrow id="A4.SS1.p2.1.m1.1.1.2.2" xref="A4.SS1.p2.1.m1.1.1.2.2.cmml"><mi id="A4.SS1.p2.1.m1.1.1.2.2.2" xref="A4.SS1.p2.1.m1.1.1.2.2.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.3" xref="A4.SS1.p2.1.m1.1.1.2.2.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1a" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.4" xref="A4.SS1.p2.1.m1.1.1.2.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1b" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.5" xref="A4.SS1.p2.1.m1.1.1.2.2.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1c" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.6" xref="A4.SS1.p2.1.m1.1.1.2.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1d" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.7" xref="A4.SS1.p2.1.m1.1.1.2.2.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1e" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.8" xref="A4.SS1.p2.1.m1.1.1.2.2.8.cmml">y</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="A4.SS1.p2.1.m1.1.1.2.1" xref="A4.SS1.p2.1.m1.1.1.2.1.cmml">âˆ—</mo><mi id="A4.SS1.p2.1.m1.1.1.2.3" xref="A4.SS1.p2.1.m1.1.1.2.3.cmml">U</mi></mrow><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.3" xref="A4.SS1.p2.1.m1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1a" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.4" xref="A4.SS1.p2.1.m1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1b" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.5" xref="A4.SS1.p2.1.m1.1.1.5.cmml">q</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1c" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.6" xref="A4.SS1.p2.1.m1.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1d" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.7" xref="A4.SS1.p2.1.m1.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1e" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.8" xref="A4.SS1.p2.1.m1.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1f" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.9" xref="A4.SS1.p2.1.m1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1g" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.10" xref="A4.SS1.p2.1.m1.1.1.10.cmml">s</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1h" xref="A4.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.1.m1.1.1.11" xref="A4.SS1.p2.1.m1.1.1.11.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.1.m1.1b"><apply id="A4.SS1.p2.1.m1.1.1.cmml" xref="A4.SS1.p2.1.m1.1.1"><times id="A4.SS1.p2.1.m1.1.1.1.cmml" xref="A4.SS1.p2.1.m1.1.1.1"></times><apply id="A4.SS1.p2.1.m1.1.1.2.cmml" xref="A4.SS1.p2.1.m1.1.1.2"><times id="A4.SS1.p2.1.m1.1.1.2.1.cmml" xref="A4.SS1.p2.1.m1.1.1.2.1"></times><apply id="A4.SS1.p2.1.m1.1.1.2.2.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2"><times id="A4.SS1.p2.1.m1.1.1.2.2.1.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.1"></times><ci id="A4.SS1.p2.1.m1.1.1.2.2.2.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.2">ğ‘ˆ</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.3.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.3">ğ‘¡</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.4.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.4">ğ‘–</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.5.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.5">ğ‘™</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.6.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.6">ğ‘–</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.7.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.7">ğ‘¡</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.8.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.8">ğ‘¦</ci></apply><ci id="A4.SS1.p2.1.m1.1.1.2.3.cmml" xref="A4.SS1.p2.1.m1.1.1.2.3">ğ‘ˆ</ci></apply><ci id="A4.SS1.p2.1.m1.1.1.3.cmml" xref="A4.SS1.p2.1.m1.1.1.3">ğ‘›</ci><ci id="A4.SS1.p2.1.m1.1.1.4.cmml" xref="A4.SS1.p2.1.m1.1.1.4">ğ‘–</ci><ci id="A4.SS1.p2.1.m1.1.1.5.cmml" xref="A4.SS1.p2.1.m1.1.1.5">ğ‘</ci><ci id="A4.SS1.p2.1.m1.1.1.6.cmml" xref="A4.SS1.p2.1.m1.1.1.6">ğ‘¢</ci><ci id="A4.SS1.p2.1.m1.1.1.7.cmml" xref="A4.SS1.p2.1.m1.1.1.7">ğ‘’</ci><ci id="A4.SS1.p2.1.m1.1.1.8.cmml" xref="A4.SS1.p2.1.m1.1.1.8">ğ‘›</ci><ci id="A4.SS1.p2.1.m1.1.1.9.cmml" xref="A4.SS1.p2.1.m1.1.1.9">ğ‘’</ci><ci id="A4.SS1.p2.1.m1.1.1.10.cmml" xref="A4.SS1.p2.1.m1.1.1.10">ğ‘ </ci><ci id="A4.SS1.p2.1.m1.1.1.11.cmml" xref="A4.SS1.p2.1.m1.1.1.11">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.1.m1.1c">Utility*Uniqueness</annotation></semantics></math> score, where <math id="A4.SS1.p2.2.m2.1" class="ltx_Math" alttext="Utility" display="inline"><semantics id="A4.SS1.p2.2.m2.1a"><mrow id="A4.SS1.p2.2.m2.1.1" xref="A4.SS1.p2.2.m2.1.1.cmml"><mi id="A4.SS1.p2.2.m2.1.1.2" xref="A4.SS1.p2.2.m2.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1" xref="A4.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.2.m2.1.1.3" xref="A4.SS1.p2.2.m2.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1a" xref="A4.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.2.m2.1.1.4" xref="A4.SS1.p2.2.m2.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1b" xref="A4.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.2.m2.1.1.5" xref="A4.SS1.p2.2.m2.1.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1c" xref="A4.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.2.m2.1.1.6" xref="A4.SS1.p2.2.m2.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1d" xref="A4.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.2.m2.1.1.7" xref="A4.SS1.p2.2.m2.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1e" xref="A4.SS1.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.2.m2.1.1.8" xref="A4.SS1.p2.2.m2.1.1.8.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.2.m2.1b"><apply id="A4.SS1.p2.2.m2.1.1.cmml" xref="A4.SS1.p2.2.m2.1.1"><times id="A4.SS1.p2.2.m2.1.1.1.cmml" xref="A4.SS1.p2.2.m2.1.1.1"></times><ci id="A4.SS1.p2.2.m2.1.1.2.cmml" xref="A4.SS1.p2.2.m2.1.1.2">ğ‘ˆ</ci><ci id="A4.SS1.p2.2.m2.1.1.3.cmml" xref="A4.SS1.p2.2.m2.1.1.3">ğ‘¡</ci><ci id="A4.SS1.p2.2.m2.1.1.4.cmml" xref="A4.SS1.p2.2.m2.1.1.4">ğ‘–</ci><ci id="A4.SS1.p2.2.m2.1.1.5.cmml" xref="A4.SS1.p2.2.m2.1.1.5">ğ‘™</ci><ci id="A4.SS1.p2.2.m2.1.1.6.cmml" xref="A4.SS1.p2.2.m2.1.1.6">ğ‘–</ci><ci id="A4.SS1.p2.2.m2.1.1.7.cmml" xref="A4.SS1.p2.2.m2.1.1.7">ğ‘¡</ci><ci id="A4.SS1.p2.2.m2.1.1.8.cmml" xref="A4.SS1.p2.2.m2.1.1.8">ğ‘¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.2.m2.1c">Utility</annotation></semantics></math> is the performance gain against a vanilla OLN, and <math id="A4.SS1.p2.3.m3.1" class="ltx_Math" alttext="Uniqueness" display="inline"><semantics id="A4.SS1.p2.3.m3.1a"><mrow id="A4.SS1.p2.3.m3.1.1" xref="A4.SS1.p2.3.m3.1.1.cmml"><mi id="A4.SS1.p2.3.m3.1.1.2" xref="A4.SS1.p2.3.m3.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.3" xref="A4.SS1.p2.3.m3.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1a" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.4" xref="A4.SS1.p2.3.m3.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1b" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.5" xref="A4.SS1.p2.3.m3.1.1.5.cmml">q</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1c" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.6" xref="A4.SS1.p2.3.m3.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1d" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.7" xref="A4.SS1.p2.3.m3.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1e" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.8" xref="A4.SS1.p2.3.m3.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1f" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.9" xref="A4.SS1.p2.3.m3.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1g" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.10" xref="A4.SS1.p2.3.m3.1.1.10.cmml">s</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1h" xref="A4.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi id="A4.SS1.p2.3.m3.1.1.11" xref="A4.SS1.p2.3.m3.1.1.11.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.3.m3.1b"><apply id="A4.SS1.p2.3.m3.1.1.cmml" xref="A4.SS1.p2.3.m3.1.1"><times id="A4.SS1.p2.3.m3.1.1.1.cmml" xref="A4.SS1.p2.3.m3.1.1.1"></times><ci id="A4.SS1.p2.3.m3.1.1.2.cmml" xref="A4.SS1.p2.3.m3.1.1.2">ğ‘ˆ</ci><ci id="A4.SS1.p2.3.m3.1.1.3.cmml" xref="A4.SS1.p2.3.m3.1.1.3">ğ‘›</ci><ci id="A4.SS1.p2.3.m3.1.1.4.cmml" xref="A4.SS1.p2.3.m3.1.1.4">ğ‘–</ci><ci id="A4.SS1.p2.3.m3.1.1.5.cmml" xref="A4.SS1.p2.3.m3.1.1.5">ğ‘</ci><ci id="A4.SS1.p2.3.m3.1.1.6.cmml" xref="A4.SS1.p2.3.m3.1.1.6">ğ‘¢</ci><ci id="A4.SS1.p2.3.m3.1.1.7.cmml" xref="A4.SS1.p2.3.m3.1.1.7">ğ‘’</ci><ci id="A4.SS1.p2.3.m3.1.1.8.cmml" xref="A4.SS1.p2.3.m3.1.1.8">ğ‘›</ci><ci id="A4.SS1.p2.3.m3.1.1.9.cmml" xref="A4.SS1.p2.3.m3.1.1.9">ğ‘’</ci><ci id="A4.SS1.p2.3.m3.1.1.10.cmml" xref="A4.SS1.p2.3.m3.1.1.10">ğ‘ </ci><ci id="A4.SS1.p2.3.m3.1.1.11.cmml" xref="A4.SS1.p2.3.m3.1.1.11">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.3.m3.1c">Uniqueness</annotation></semantics></math> is the overlap of the pseudo boxes with the current ensemble pseudo boxes. The performance is evaluated on a holdout validation set. The chosen ensemble order for the COCO VOC to non-VOC benchmark is: depth, normal, PA, edge, RGB.</p>
</div>
<div id="A4.SS1.p3" class="ltx_para ltx_noindent">
<p id="A4.SS1.p3.1" class="ltx_p">We show the ensembling results in FigureÂ <a href="#A4.F7.sf2" title="In Figure 7 â€£ D.1 Complementariness of different modalities â€£ Appendix D More discussion on different modalities for GOOD â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a>.
Two baselines for using multiple pseudo boxes from RGB are considered: <span id="A4.SS1.p3.1.1" class="ltx_text ltx_font_bold">SelfTrain-RGB</span> is using the top-k pseudo boxes from a single RGB-based object proposal netowrk for retraining, and <span id="A4.SS1.p3.1.2" class="ltx_text ltx_font_bold">SelfTrain-RGB (ens)</span> is using pseudo boxes extracted and merged from k independently trained RGB-based object proposal networks for retraining. We can see that ensembling pseudo sources from multiple modalities is better than adding more pseudo boxes from a single source (RGB).</p>
</div>
<figure id="A4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/overlap_heatmap_iou07.png" id="A4.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="411" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Overlap of top1 pseudo boxes.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x9.png" id="A4.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="293" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Influence of top-k when ensembling.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="A4.F7.4.1" class="ltx_text ltx_font_bold">Complementariness of different representations.</span> In (b), <span id="A4.F7.5.2" class="ltx_text ltx_font_bold">SelfTrain-RGB</span> is using the top-k pseudo boxes from a single RGB-based object proposal netowrk for retraining, and <span id="A4.F7.6.3" class="ltx_text ltx_font_bold">SelfTrain-RGB (ens)</span> is using pseudo boxes merged from k independently trained RGB-based object proposal netowrks for retraining.</figcaption>
</figure>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>More visualization</h2>

<section id="A5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Visualization of geometric cues</h3>

<div id="A5.SS1.p1" class="ltx_para ltx_noindent">
<p id="A5.SS1.p1.1" class="ltx_p">We visualize more examples of geometric cues in FigureÂ <a href="#A5.F8" title="Figure 8 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> and FigureÂ <a href="#A5.F9" title="Figure 9 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We demonstrate that the inferred geometric cues are of high quality in diverse scenes.</p>
</div>
</section>
<section id="A5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Visualization of pseudo boxes from Phase-I</h3>

<div id="A5.SS2.p1" class="ltx_para ltx_noindent">
<p id="A5.SS2.p1.1" class="ltx_p">We also provide visualization of pseudo boxes in FigureÂ <a href="#A5.F10" title="Figure 10 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and FigureÂ <a href="#A5.F11" title="Figure 11 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.
The pseudo boxes are generated from OLNs trained on RGB, depth, and normals, respectively.
We find that pseudo boxes from RGB-based models generally tend to target small objects, textures, and parts of objects. This again shows that RGB-based models over-rely on appearance cues and can overfit to textures and discriminative parts of the training classes.</p>
</div>
</section>
<section id="A5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.3 </span>Visualization of GOOD detections on novel objects</h3>

<div id="A5.SS3.p1" class="ltx_para ltx_noindent">
<p id="A5.SS3.p1.1" class="ltx_p">We further added more visualization examples of GOOD detection results in FigureÂ <a href="#A5.F12" title="Figure 12 â€£ E.3 Visualization of GOOD detections on novel objects â€£ Appendix E More visualization â€£ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. The test images contain objects that are seen neither in the GOOD training set (COCO) nor the Omnidata model training set. The presented examples include new technology devices, spaceships, dinosaurs, aliens, and sea scenes. We can see that GOOD can still make reasonable object bounding box predictions even though these objects have never appeared in the training set.</p>
</div>
<figure id="A5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/000000000247.jpg" id="A5.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/depth000000000247.jpg" id="A5.F8.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/normal000000000247.jpg" id="A5.F8.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/000000000382.jpg" id="A5.F8.4.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/depth000000000382.jpg" id="A5.F8.5.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/normal000000000382.jpg" id="A5.F8.6.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/000000000785.jpg" id="A5.F8.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/depth000000000785.jpg" id="A5.F8.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/normal000000000785.jpg" id="A5.F8.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000000139.jpg" id="A5.F8.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000000139.jpg" id="A5.F8.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000000139.jpg" id="A5.F8.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.13" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000001000.jpg" id="A5.F8.13.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.14" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000001000.jpg" id="A5.F8.14.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.15" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000001000.jpg" id="A5.F8.15.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.16" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000002149.jpg" id="A5.F8.16.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.17" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000002149.jpg" id="A5.F8.17.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.18" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000002149.jpg" id="A5.F8.18.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="A5.F8.20.1" class="ltx_text ltx_font_bold">Visualization of geometric cues.</span> From left to right: RGB, depth, normals.</figcaption>
</figure>
<figure id="A5.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000007574.jpg" id="A5.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000007574.jpg" id="A5.F9.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000007574.jpg" id="A5.F9.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000009769.jpg" id="A5.F9.4.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000009769.jpg" id="A5.F9.5.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000009769.jpg" id="A5.F9.6.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000011760.jpg" id="A5.F9.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000011760.jpg" id="A5.F9.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000011760.jpg" id="A5.F9.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000563604.jpg" id="A5.F9.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000563604.jpg" id="A5.F9.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000563604.jpg" id="A5.F9.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.13" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000570664.jpg" id="A5.F9.13.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.14" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000570664.jpg" id="A5.F9.14.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.15" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000570664.jpg" id="A5.F9.15.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.16" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000572555.jpg" id="A5.F9.16.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.17" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000572555.jpg" id="A5.F9.17.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.18" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000572555.jpg" id="A5.F9.18.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span><span id="A5.F9.20.1" class="ltx_text ltx_font_bold">Visualization of geometric cues.</span> From left to right: RGB, depth, normals.</figcaption>
</figure>
<figure id="A5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000103806.jpg" id="A5.F10.1.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000103806.jpg" id="A5.F10.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000103806.jpg" id="A5.F10.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000310325.jpg" id="A5.F10.4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000310325.jpg" id="A5.F10.5.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000310325.jpg" id="A5.F10.6.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000503772.jpg" id="A5.F10.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000503772.jpg" id="A5.F10.8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000503772.jpg" id="A5.F10.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000310177.jpg" id="A5.F10.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="367" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000310177.jpg" id="A5.F10.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="367" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000310177.jpg" id="A5.F10.12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="367" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span><span id="A5.F10.14.1" class="ltx_text ltx_font_bold">Top3 pseudo boxes after filtering out those that overlap with known (VOC) class bounding boxes.</span> The pseudo boxes are generated from OLNs trained on RGB, depth, and normals, respectively.
OLN trained on RGB tends to detect small objects and parts of objects.</figcaption>
</figure>
<figure id="A5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000186322.jpg" id="A5.F11.1.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000186322.jpg" id="A5.F11.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000186322.jpg" id="A5.F11.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000410437.jpg" id="A5.F11.4.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000410437.jpg" id="A5.F11.5.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000410437.jpg" id="A5.F11.6.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000577564.jpg" id="A5.F11.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000577564.jpg" id="A5.F11.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000577564.jpg" id="A5.F11.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000199346.jpg" id="A5.F11.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000199346.jpg" id="A5.F11.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000199346.jpg" id="A5.F11.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.13" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000028655.jpg" id="A5.F11.13.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.14" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000028655.jpg" id="A5.F11.14.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.15" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000028655.jpg" id="A5.F11.15.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span><span id="A5.F11.17.1" class="ltx_text ltx_font_bold">Top3 pseudo boxes after filtering out those that overlap with known (VOC) class bounding boxes.</span> The pseudo boxes are generated from OLNs trained on RGB, depth, and normals, respectively.
OLN trained on RGB often detect textures or small parts of the objects.</figcaption>
</figure>
<figure id="A5.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/2.png" id="A5.F12.1.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/spaceship.png" id="A5.F12.2.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/aliens.png" id="A5.F12.3.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/dinosaur.png" id="A5.F12.4.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/transformers.png" id="A5.F12.5.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/dinosaurs.png" id="A5.F12.6.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/avatar.jpeg" id="A5.F12.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="274" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/n_1.png" id="A5.F12.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="309" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/erwater.jpeg" id="A5.F12.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/ron_man.jpeg" id="A5.F12.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="309" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/marvel.png" id="A5.F12.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="412" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/trek.png" id="A5.F12.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="384" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span><span id="A5.F12.14.1" class="ltx_text ltx_font_bold">GOOD detections on novel objects.</span> Only top 20 detection boxes are shown with the images. The novel objects are seen neither in GOOD training, nor in Omnidata training set.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.11719" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.11720" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2212.11720">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.11720" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.11722" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 09:46:25 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
