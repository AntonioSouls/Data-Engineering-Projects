<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.11720] GOOD: Exploring Geometric Cues for Detecting Objects in an Open World</title><meta property="og:description" content="We address the task of open-world class-agnostic object detection, i.e., detecting every object in an image by learning from a limited number of base object classes. State-of-the-art RGB-based models suffer from overfi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GOOD: Exploring Geometric Cues for Detecting Objects in an Open World">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="GOOD: Exploring Geometric Cues for Detecting Objects in an Open World">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.11720">

<!--Generated on Fri Mar  1 09:46:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">GOOD: Exploring Geometric Cues for Detecting Objects in an Open World</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Haiwen Huang<sup id="id8.8.id1" class="ltx_sup"><span id="id8.8.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>   Andreas Geiger<sup id="id9.9.id2" class="ltx_sup"><span id="id9.9.id2.1" class="ltx_text ltx_font_italic">2,3</span></sup>   Dan Zhang<sup id="id10.10.id3" class="ltx_sup"><span id="id10.10.id3.1" class="ltx_text ltx_font_italic">1,4</span></sup> 
<br class="ltx_break"><sup id="id11.11.id4" class="ltx_sup"><span id="id11.11.id4.1" class="ltx_text ltx_font_italic">1</span></sup>Bosch Industry on Campus Lab, University of Tübingen
<br class="ltx_break"><sup id="id12.12.id5" class="ltx_sup"><span id="id12.12.id5.1" class="ltx_text ltx_font_italic">2</span></sup>Autonomous Vision Group, University of Tübingen
<br class="ltx_break"><sup id="id13.13.id6" class="ltx_sup"><span id="id13.13.id6.1" class="ltx_text ltx_font_italic">3</span></sup>Max Planck Institute for Intelligent Systems, Tübingen  
<sup id="id14.14.id7" class="ltx_sup"><span id="id14.14.id7.1" class="ltx_text ltx_font_italic">4</span></sup>Bosch Center for Artificial Intelligence
<br class="ltx_break"><span id="id15.15.id8" class="ltx_text ltx_font_typewriter">{haiwen.huang, a.geiger}@uni-tuebingen.de, Dan.Zhang2@de.bosch.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.id1" class="ltx_p">We address the task of open-world class-agnostic object detection, i.e., detecting every object in an image by learning from a limited number of base object classes. State-of-the-art RGB-based models suffer from overfitting the training classes and often fail at detecting novel-looking objects. This is because RGB-based models primarily rely on appearance similarity to detect novel objects and are also prone to overfitting short-cut cues such as textures and discriminative parts.
To address these shortcomings of RGB-based object detectors, we propose incorporating geometric cues such as depth and normals, predicted by general-purpose monocular estimators.
Specifically, we use the geometric cues to train an object proposal network for pseudo-labeling unannotated novel objects in the training set.
Our resulting Geometry-guided Open-world Object Detector (GOOD) significantly improves detection recall for novel object categories and already performs well with only a few training classes.
Using a single “person” class for training on the COCO dataset, GOOD surpasses SOTA methods by 5.0% AR@100, a relative improvement of 24%.</p>
</div>
<figure id="S0.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/gt/ADE_val_00000669_numbox_20.jpg" id="S0.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="361" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth (20)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/oln/ADE_val_00000669_gtnum20_tpnum13_vis_num13.jpg" id="S0.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>OLN (13)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/ggn/ADE_val_00000669_gtnum20_tpnum14_vis_num14.jpg" id="S0.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>GGN (14)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/midow/ADE_val_00000669_gtnum20_tpnum18_vis_num18.jpg" id="S0.F1.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="369" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>GOOD (18)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/gt/ADE_val_00001463_numbox_22.jpg" id="S0.F1.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="361" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Ground truth (22)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/oln/ADE_val_00001463_gtnum22_tpnum6_vis_num6.jpg" id="S0.F1.sf6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="364" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>OLN (6)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/ggn/ADE_val_00001463_gtnum22_tpnum6_vis_num6.jpg" id="S0.F1.sf7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="364" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(g) </span>GGN (6)</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S0.F1.sf8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/fig1/midow/ADE_val_00001463_gtnum22_tpnum15_vis_num15.jpg" id="S0.F1.sf8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="364" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(h) </span>GOOD (15)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S0.F1.2.1" class="ltx_text ltx_font_bold">Comparison of GOOD with different baselines.</span> Images in the first column are from validation sets of ADE20K <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite>. From the second to fourth columns we show the detection results of three open-world object detection methods: OLN <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>, GGN <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>, and our Geometry-guided Open-world Object Detector (GOOD). The shown detection results are true-positive proposals from the top 100 proposals of each method. The numbers of true positive proposals or ground truth objects are denoted in parentheses. All models are trained on the RGB images from the PASCAL-VOC classes of the COCO dataset <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>, which do not include houses, trees, or kitchen furniture. Both OLN and GGN fail to detect many objects not seen during training. GOOD generalizes better to unseen categories by exploiting the geometric cues.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">The standard object detection task is to detect objects from a predefined class list. However, when deploying the model in the real world, it is rarely the case that the model will only encounter objects from its predefined taxonomy. In the open-world setup, object detectors are required to detect all the objects in the scene even though they have only been trained on objects from a limited number of classes.
Current state-of-the-art object detectors typically struggle in the open-world setup. As a consequence, open-world object detection has gained increased attention over the last few years <cite class="ltx_cite ltx_citemacro_citep">(Jaiswal et al., <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Joseph et al., <a href="#bib.bib20" title="" class="ltx_ref">2021</a>; Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>.
In this work, we specifically address the task of open-world class-agnostic object detection, which is a fundamental task for downstream applications like open-world multi-object tracking <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib26" title="" class="ltx_ref">2022</a>)</cite>, robotics <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite>, and autonomous AI agents <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib25" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">One reason for the failure of current object detectors in the open-world setting is that during training, they are penalized for detecting unlabeled objects in the background and are thus discouraged from detecting them.
Motivated by this, previous works have designed different architectures <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Konan et al., <a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> and training pipelines <cite class="ltx_cite ltx_citemacro_citep">(Saito et al., <a href="#bib.bib34" title="" class="ltx_ref">2021</a>; Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> to avoid suppressing the unannotated objects in the background, which have led to significant performance improvements. However, these methods still suffer from overfitting the training classes.
Training only on RGB images, they mainly rely on appearance cues to detect objects of new categories and have great difficulty generalizing to novel-looking objects.
Also, there are known short-cut learning problems with regard to training on RGB images <cite class="ltx_cite ltx_citemacro_cite">Geirhos et al. (<a href="#bib.bib12" title="" class="ltx_ref">2019</a>; <a href="#bib.bib13" title="" class="ltx_ref">2020</a>); Sauer &amp; Geiger (<a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite> – there is no constraint for overfitting the textures or the discriminative parts of the known classes during training.
In this work, we propose to tackle this challenge by incorporating geometry cues extracted by general-purpose monocular estimators from the RGB images. We show that such cues significantly improve detection recall for novel object categories on challenging benchmarks.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Estimating geometric cues such as depth and normals from a single RGB image has been an active research area for a long time.
Such mid-level representations possess built-in invariance to many changes (e.g., brightness, color) and are more class-agnostic than RGB signals, see Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In other words, there is less discrepancy between known and unknown objects in terms of geometric cues.
In recent years, thanks to stronger architectures and larger datasets <cite class="ltx_cite ltx_citemacro_citep">(Ranftl et al., <a href="#bib.bib31" title="" class="ltx_ref">2021b</a>; <a href="#bib.bib32" title="" class="ltx_ref">2022</a>; Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>, monocular estimators for mid-level representations have significantly advanced in terms of prediction quality and generalization to novel scenes. These models are able to compute high-quality geometric cues efficiently when used off-the-shelf as pre-trained models on new datasets. Therefore, it becomes natural to ask if these models can provide additional knowledge for current RGB-based open-world object detectors to overcome the generalization problem.</p>
</div>
<figure id="S1.F2" class="ltx_figure">
<div id="S1.F2.7" class="ltx_block ltx_parbox ltx_align_center ltx_align_middle" style="width:397.5pt;">
<div id="S1.F2.2.2" class="ltx_block ltx_parbox ltx_align_bottom" style="width:79.5pt;">
<img src="/html/2212.11720/assets/iclr2023/figures/fig2/000000159791.jpg" id="S1.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption"><img src="/html/2212.11720/assets/iclr2023/figures/fig2/000000005802.jpg" id="S1.F2.2.2.g2" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
</div>
<div id="S1.F2.4.4" class="ltx_block ltx_parbox ltx_align_bottom" style="width:79.5pt;">
<img src="/html/2212.11720/assets/iclr2023/figures/fig2/depth000000159791.jpg" id="S1.F2.3.3.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption"><img src="/html/2212.11720/assets/iclr2023/figures/fig2/depth000000005802.jpg" id="S1.F2.4.4.g2" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
</div>
<div id="S1.F2.6.6" class="ltx_block ltx_parbox ltx_align_bottom" style="width:79.5pt;">
<img src="/html/2212.11720/assets/iclr2023/figures/fig2/normal000000159791.jpg" id="S1.F2.5.5.g1" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption"><img src="/html/2212.11720/assets/iclr2023/figures/fig2/normal000000005802.jpg" id="S1.F2.6.6.g2" class="ltx_graphics ltx_img_landscape" width="110" height="83" alt="Refer to caption">
</div>
<div id="S1.F2.7.7" class="ltx_block ltx_parbox ltx_align_bottom" style="width:159.0pt;">
<img src="/html/2212.11720/assets/x1.png" id="S1.F2.7.7.g1" class="ltx_graphics ltx_img_landscape" width="165" height="128" alt="Refer to caption">
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S1.F2.11.1" class="ltx_text ltx_font_bold">Geometry cues are complementary to appearance cues for object localization.</span> The depth and normal cues of the RGB image are extracted using off-the-shelf general-purpose monocular predictors. <span id="S1.F2.12.2" class="ltx_text ltx_font_bold">Left:</span>
Geometric cues abstract away the appearance details and focus on more holistic information such as object shapes and relative spatial locations (depth) and directional changes (normals).
<span id="S1.F2.13.3" class="ltx_text ltx_font_bold">Right:</span>
By incorporating geometric cues, GOODs generalize better than the RGB-based model OLN <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>, i.e., much smaller AR gaps between the base and novel classes.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">In this paper, we propose to use a pseudo-labeling method for incorporating geometric cues into open-world object detector training.
We first train an object proposal network on the predicted depth or normal maps to discover novel unannotated objects in the training set. The top-ranked novel object predictions are used as pseudo boxes for training the open-world object detector on the original RGB input. We observe that incorporating the geometry cues can significantly improve the detection recall of unseen objects, especially those that differ strongly from the training objects, as shown in Figure <a href="#S0.F1" title="Figure 1 ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We speculate that this is due to the complementary nature of geometry cues and the RGB-based detection cues: the geometry cues help discover novel-looking objects that RGB-based detectors cannot detect, and the RGB-based detectors can make use of more annotations with their strong representation learning ability to generalize to novel, unseen categories.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">Our resulting Geometry-guided Open-world Object Detector (GOOD) surpasses the state-of-the-art performance on multiple benchmarks for open-world class-agnostic object detection.
Thanks to the rich geometry information, GOOD can generalize to unseen categories with only a few known classes for training.
Particularly, with a single training class “person” on the COCO dataset <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>, GOOD can surpass SOTA methods by 5.0% AR@100 (a relative improvement of 24%) on detecting objects from non-person classes. With 20 PASCAL-VOC classes for training, GOOD surpasses SOTA methods even by 6.1% AR@100 in detecting non-VOC classes.
Furthermore, we also analyze the advantages of geometric cues and show that they are less sensitive to semantic shifts across classes, and are better than other strategies for improving generalization.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Open-world class-agnostic object detection</span> is the task of localizing all the objects in an image by learning with only a limited number of object classes (base classes).
The core problem with standard object detection training is that the model is trained to classify the unannotated objects as background and thus is suppressed to detect them at inference time.
To solve this issue, <cite class="ltx_cite ltx_citemacro_citet">Kim et al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> proposed object localization network (OLN), which replaces the classification heads of Faster RCNN <cite class="ltx_cite ltx_citemacro_citep">(Ren et al., <a href="#bib.bib33" title="" class="ltx_ref">2015</a>)</cite> with class-agnostic objectness heads so that the training loss is only calculated on positive samples, i.e., known objects, and thus not suppressing the detection of unannotated novel objects.
<cite class="ltx_cite ltx_citemacro_citet">Saito et al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>)</cite> synthesized a training set by copy-pasting known objects onto synthetic backgrounds. However, the model struggles with the synthetic-to-real domain gap in solving the object detection task.
Besides background non-suppression, a more proactive approach is to exploit unannotated objects for training. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> built upon traditional learning-free methods and developed a pairwise affinity predictor to discover unannotated objects. Their object detector, GGN, is then trained using the newly-discovered object masks and ground truth base class annotations as supervision.
Finally, another promising direction is to use open-world knowledge from large pretrained multi-modal models. Recently, <cite class="ltx_cite ltx_citemacro_citet">Minderer et al. (<a href="#bib.bib28" title="" class="ltx_ref">2022</a>); Maaz et al. (<a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite> made use of pretrained language-vision model <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite> to detect open-world objects using text queries. Our work is most related to OLN and GGN. We used the OLN architecture and training loss, but additionally incorporated geometry cues through our pseudo-labeling method. GGN used the pairwise affinity for pseudo labeling. However, since the pairwise affinity is trained on RGB inputs using the base class annotations, GGN still suffers from the overfitting problems of RGB-based methods. Our experiments showed geometric cues as a better source of pseudo boxes.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Incorporating geometric cues for generalization.</span>
The estimation of geometric cues has been an active research area for decades.
With the introduction of deep neural networks, the seminal work by <cite class="ltx_cite ltx_citemacro_citet">Eigen et al. (<a href="#bib.bib10" title="" class="ltx_ref">2014</a>); Eigen &amp; Fergus (<a href="#bib.bib9" title="" class="ltx_ref">2015</a>)</cite> significantly improved over early works <cite class="ltx_cite ltx_citemacro_citep">(Hoiem et al., <a href="#bib.bib14" title="" class="ltx_ref">2005a</a>; <a href="#bib.bib15" title="" class="ltx_ref">b</a>; <a href="#bib.bib16" title="" class="ltx_ref">2007</a>; <a href="#bib.bib17" title="" class="ltx_ref">2008</a>; Saxena et al., <a href="#bib.bib36" title="" class="ltx_ref">2005</a>; <a href="#bib.bib37" title="" class="ltx_ref">2008a</a>; <a href="#bib.bib38" title="" class="ltx_ref">2008b</a>)</cite>. Recent progress in estimating geometric cues can be attributed to the use of modern architectures <cite class="ltx_cite ltx_citemacro_citep">(Ranftl et al., <a href="#bib.bib32" title="" class="ltx_ref">2022</a>)</cite>, stronger training strategies <cite class="ltx_cite ltx_citemacro_citep">(Zamir et al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> and large-scale datasets <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>.
In particular, Omnidata <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> has made significant headway in prediction quality and cross-dataset generalization.
Since geometric cues abstract away the appearance details and retain more holistic information about the objects, such as shapes, they have been incorporated into many applications for generalization.
For example, <cite class="ltx_cite ltx_citemacro_citet">Xiang et al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite> incorporated them into the 3D shape completion pipeline to generalize to novel classes. <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> used them to guide the optimization of neural implicit surface models for tackling scenes captured from sparse viewpoints. <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> applied mid-level visual representations to reinforcement training and gained robustness under domain shifts.
In this work, we propose to incorporate geometric cues through pseudo-labeling and also demonstrate large performance gains on open-world class-agnostic object detection benchmarks.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2212.11720/assets/x2.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S2.F3.2.1" class="ltx_text ltx_font_bold">Overview of the geometry-guided pseudo labeling method.</span> It consists of two training phases. Phase I: the RGB input is firstly preprocessed by the off-the-shelf model to extract the geometry cues, which are then used to train an object proposal network with the base class bounding box annotations. The proposal networks then pseudo-label the training samples, discovering unannotated novel objects. The top-ranked pseudo boxes are added to the annotation pool for Phase II training, i.e., a class-agnostic object detector is directly trained on the RGB input using both the base class and pseudo annotations. At inference time, we only need the model from Phase II.
</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">Our goal is to incorporate geometric cues for an improved open-world class-agnostic object detection performance. Concretely, we propose a pseudo labeling method, which can effectively utilize the geometric cues to detect unannotated novel objects in the training set and then use them for training the object detector. See the overview of our method in Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Related work ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>open-world class-agnostic object detection problem</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.3" class="ltx_p">Current state-of-the-art object detection methods work well under the closed-world assumption. They are trained with a set of object bounding box annotations <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\{t_{i}\}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">{</mo><msub id="S3.SS1.p1.1.m1.1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.1.1.2.cmml">t</mi><mi id="S3.SS1.p1.1.m1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p1.1.m1.1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><set id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1"><apply id="S3.SS1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.2">𝑡</ci><ci id="S3.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.1.1.3">𝑖</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\{t_{i}\}</annotation></semantics></math> from a pre-specified list <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathcal{K}</annotation></semantics></math> of semantic classes, i.e., the base classes. At test time, their generalization is evaluated by detecting the objects from the known base classes. The standard training loss of object detection for an image <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathcal{I}</annotation></semantics></math> has two parts: classification loss and bounding box regression loss</p>
<table id="A5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.2" class="ltx_Math" alttext="\displaystyle\mathcal{L}(\mathcal{I})=\dfrac{1}{N_{cls}}\sum_{i\in\mathcal{B}}\mathcal{L}_{cls}(p_{i},p_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})," display="inline"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.6" xref="S3.E1.m1.2.2.1.1.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.6.2" xref="S3.E1.m1.2.2.1.1.6.2.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.6.1" xref="S3.E1.m1.2.2.1.1.6.1.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.6.3.2" xref="S3.E1.m1.2.2.1.1.6.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.6.3.2.1" xref="S3.E1.m1.2.2.1.1.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ℐ</mi><mo stretchy="false" id="S3.E1.m1.2.2.1.1.6.3.2.2" xref="S3.E1.m1.2.2.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.5" xref="S3.E1.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.4" xref="S3.E1.m1.2.2.1.1.4.cmml"><mrow id="S3.E1.m1.2.2.1.1.2.2" xref="S3.E1.m1.2.2.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.2.2.4" xref="S3.E1.m1.2.2.1.1.2.2.4.cmml"><mfrac id="S3.E1.m1.2.2.1.1.2.2.4a" xref="S3.E1.m1.2.2.1.1.2.2.4.cmml"><mn id="S3.E1.m1.2.2.1.1.2.2.4.2" xref="S3.E1.m1.2.2.1.1.2.2.4.2.cmml">1</mn><msub id="S3.E1.m1.2.2.1.1.2.2.4.3" xref="S3.E1.m1.2.2.1.1.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.2" xref="S3.E1.m1.2.2.1.1.2.2.4.3.2.cmml">N</mi><mrow id="S3.E1.m1.2.2.1.1.2.2.4.3.3" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.3.2" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.4.3.3.1" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.3.3" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.4.3.3.1a" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.2.2.4.3.3.4" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.4.cmml">s</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.cmml"><munder id="S3.E1.m1.2.2.1.1.2.2.2.3a" xref="S3.E1.m1.2.2.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E1.m1.2.2.1.1.2.2.2.3.2" xref="S3.E1.m1.2.2.1.1.2.2.2.3.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.1.1.2.2.2.3.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.3.3.2" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.2.2.2.3.3.1" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.2.2.3.3.3" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.3.cmml">ℬ</mi></mrow></munder></mstyle><mrow id="S3.E1.m1.2.2.1.1.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E1.m1.2.2.1.1.2.2.2.2.4" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1a" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4.cmml">s</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.1.4.5" xref="S3.E1.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S3.E1.m1.2.2.1.1.4.4" xref="S3.E1.m1.2.2.1.1.4.4.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.4.4.4" xref="S3.E1.m1.2.2.1.1.4.4.4.cmml"><mfrac id="S3.E1.m1.2.2.1.1.4.4.4a" xref="S3.E1.m1.2.2.1.1.4.4.4.cmml"><mn id="S3.E1.m1.2.2.1.1.4.4.4.2" xref="S3.E1.m1.2.2.1.1.4.4.4.2.cmml">1</mn><msub id="S3.E1.m1.2.2.1.1.4.4.4.3" xref="S3.E1.m1.2.2.1.1.4.4.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.2" xref="S3.E1.m1.2.2.1.1.4.4.4.3.2.cmml">N</mi><mrow id="S3.E1.m1.2.2.1.1.4.4.4.3.3" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.3.2" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.4.3.3.1" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.3.3" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.4.3.3.1a" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.4.4.4.3.3.4" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.3" xref="S3.E1.m1.2.2.1.1.4.4.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.4.4.2" xref="S3.E1.m1.2.2.1.1.4.4.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.2.2.1.1.4.4.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.cmml"><munder id="S3.E1.m1.2.2.1.1.4.4.2.3a" xref="S3.E1.m1.2.2.1.1.4.4.2.3.cmml"><mo movablelimits="false" id="S3.E1.m1.2.2.1.1.4.4.2.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.3.2.cmml">∑</mo><mrow id="S3.E1.m1.2.2.1.1.4.4.2.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.2.3.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.4.4.2.3.3.1" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.1.cmml">∈</mo><msub id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3.cmml">𝒦</mi></msub></mrow></munder></mstyle><mrow id="S3.E1.m1.2.2.1.1.4.4.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.cmml"><msub id="S3.E1.m1.2.2.1.1.4.4.2.2.4" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1a" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">​</mo><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.4.4.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.3.cmml">​</mo><mrow id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.4" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.5" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.5.cmml" xref="S3.E1.m1.2.2.1.1.5"></eq><apply id="S3.E1.m1.2.2.1.1.6.cmml" xref="S3.E1.m1.2.2.1.1.6"><times id="S3.E1.m1.2.2.1.1.6.1.cmml" xref="S3.E1.m1.2.2.1.1.6.1"></times><ci id="S3.E1.m1.2.2.1.1.6.2.cmml" xref="S3.E1.m1.2.2.1.1.6.2">ℒ</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ℐ</ci></apply><apply id="S3.E1.m1.2.2.1.1.4.cmml" xref="S3.E1.m1.2.2.1.1.4"><plus id="S3.E1.m1.2.2.1.1.4.5.cmml" xref="S3.E1.m1.2.2.1.1.4.5"></plus><apply id="S3.E1.m1.2.2.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2"><times id="S3.E1.m1.2.2.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.3"></times><apply id="S3.E1.m1.2.2.1.1.2.2.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4"><divide id="S3.E1.m1.2.2.1.1.2.2.4.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4"></divide><cn type="integer" id="S3.E1.m1.2.2.1.1.2.2.4.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.2">1</cn><apply id="S3.E1.m1.2.2.1.1.2.2.4.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.2">𝑁</ci><apply id="S3.E1.m1.2.2.1.1.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3"><times id="S3.E1.m1.2.2.1.1.2.2.4.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.1"></times><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.2">𝑐</ci><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.3">𝑙</ci><ci id="S3.E1.m1.2.2.1.1.2.2.4.3.3.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.4.3.3.4">𝑠</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2"><apply id="S3.E1.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E1.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.2"></sum><apply id="S3.E1.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3"><in id="S3.E1.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.1"></in><ci id="S3.E1.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.2">𝑖</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.3.3.3">ℬ</ci></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2"><times id="S3.E1.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.3"></times><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.2.4.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.2">ℒ</ci><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3"><times id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.1"></times><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.2">𝑐</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.3">𝑙</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.4.3.4">𝑠</ci></apply></apply><interval closure="open" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.2">𝑝</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.2">𝑝</ci><ci id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.4.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4"><times id="S3.E1.m1.2.2.1.1.4.4.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.3"></times><apply id="S3.E1.m1.2.2.1.1.4.4.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4"><divide id="S3.E1.m1.2.2.1.1.4.4.4.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4"></divide><cn type="integer" id="S3.E1.m1.2.2.1.1.4.4.4.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.2">1</cn><apply id="S3.E1.m1.2.2.1.1.4.4.4.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.2">𝑁</ci><apply id="S3.E1.m1.2.2.1.1.4.4.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3"><times id="S3.E1.m1.2.2.1.1.4.4.4.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.1"></times><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.2">𝑟</ci><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.3">𝑒</ci><ci id="S3.E1.m1.2.2.1.1.4.4.4.3.3.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.4.3.3.4">𝑔</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.4.4.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2"><apply id="S3.E1.m1.2.2.1.1.4.4.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3">subscript</csymbol><sum id="S3.E1.m1.2.2.1.1.4.4.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.2"></sum><apply id="S3.E1.m1.2.2.1.1.4.4.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3"><in id="S3.E1.m1.2.2.1.1.4.4.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.1"></in><ci id="S3.E1.m1.2.2.1.1.4.4.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.2">𝑖</ci><apply id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.2">ℬ</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.3.3.3.3">𝒦</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2"><times id="S3.E1.m1.2.2.1.1.4.4.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.3"></times><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.2.4.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.2">ℒ</ci><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3"><times id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.1"></times><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.2">𝑟</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.3">𝑒</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.4.3.4">𝑔</ci></apply></apply><interval closure="open" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2"><apply id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.2">𝑡</ci><ci id="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3.3.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.2">𝑡</ci><ci id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.4.4.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">\displaystyle\mathcal{L}(\mathcal{I})=\dfrac{1}{N_{cls}}\sum_{i\in\mathcal{B}}\mathcal{L}_{cls}(p_{i},p_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.17" class="ltx_p">where <math id="S3.SS1.p1.4.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p1.4.m1.1a"><mi id="S3.SS1.p1.4.m1.1.1" xref="S3.SS1.p1.4.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m1.1b"><ci id="S3.SS1.p1.4.m1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m1.1c">i</annotation></semantics></math> is the index of an anchor from the candidate set <math id="S3.SS1.p1.5.m2.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p1.5.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.5.m2.1.1" xref="S3.SS1.p1.5.m2.1.1.cmml">ℬ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m2.1b"><ci id="S3.SS1.p1.5.m2.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1">ℬ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m2.1c">\mathcal{B}</annotation></semantics></math>, <math id="S3.SS1.p1.6.m3.2" class="ltx_Math" alttext="\{p_{i},t_{i}\}" display="inline"><semantics id="S3.SS1.p1.6.m3.2a"><mrow id="S3.SS1.p1.6.m3.2.2.2" xref="S3.SS1.p1.6.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.6.m3.2.2.2.3" xref="S3.SS1.p1.6.m3.2.2.3.cmml">{</mo><msub id="S3.SS1.p1.6.m3.1.1.1.1" xref="S3.SS1.p1.6.m3.1.1.1.1.cmml"><mi id="S3.SS1.p1.6.m3.1.1.1.1.2" xref="S3.SS1.p1.6.m3.1.1.1.1.2.cmml">p</mi><mi id="S3.SS1.p1.6.m3.1.1.1.1.3" xref="S3.SS1.p1.6.m3.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.p1.6.m3.2.2.2.4" xref="S3.SS1.p1.6.m3.2.2.3.cmml">,</mo><msub id="S3.SS1.p1.6.m3.2.2.2.2" xref="S3.SS1.p1.6.m3.2.2.2.2.cmml"><mi id="S3.SS1.p1.6.m3.2.2.2.2.2" xref="S3.SS1.p1.6.m3.2.2.2.2.2.cmml">t</mi><mi id="S3.SS1.p1.6.m3.2.2.2.2.3" xref="S3.SS1.p1.6.m3.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.p1.6.m3.2.2.2.5" xref="S3.SS1.p1.6.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m3.2b"><set id="S3.SS1.p1.6.m3.2.2.3.cmml" xref="S3.SS1.p1.6.m3.2.2.2"><apply id="S3.SS1.p1.6.m3.1.1.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m3.1.1.1.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m3.1.1.1.1.2.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1.2">𝑝</ci><ci id="S3.SS1.p1.6.m3.1.1.1.1.3.cmml" xref="S3.SS1.p1.6.m3.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.p1.6.m3.2.2.2.2.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m3.2.2.2.2.1.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.6.m3.2.2.2.2.2.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2.2">𝑡</ci><ci id="S3.SS1.p1.6.m3.2.2.2.2.3.cmml" xref="S3.SS1.p1.6.m3.2.2.2.2.3">𝑖</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m3.2c">\{p_{i},t_{i}\}</annotation></semantics></math> are the predicted label and bounding box coordinates, and <math id="S3.SS1.p1.7.m4.2" class="ltx_Math" alttext="\{p_{i}^{*},t_{i}^{*}\}" display="inline"><semantics id="S3.SS1.p1.7.m4.2a"><mrow id="S3.SS1.p1.7.m4.2.2.2" xref="S3.SS1.p1.7.m4.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.7.m4.2.2.2.3" xref="S3.SS1.p1.7.m4.2.2.3.cmml">{</mo><msubsup id="S3.SS1.p1.7.m4.1.1.1.1" xref="S3.SS1.p1.7.m4.1.1.1.1.cmml"><mi id="S3.SS1.p1.7.m4.1.1.1.1.2.2" xref="S3.SS1.p1.7.m4.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p1.7.m4.1.1.1.1.2.3" xref="S3.SS1.p1.7.m4.1.1.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p1.7.m4.1.1.1.1.3" xref="S3.SS1.p1.7.m4.1.1.1.1.3.cmml">∗</mo></msubsup><mo id="S3.SS1.p1.7.m4.2.2.2.4" xref="S3.SS1.p1.7.m4.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p1.7.m4.2.2.2.2" xref="S3.SS1.p1.7.m4.2.2.2.2.cmml"><mi id="S3.SS1.p1.7.m4.2.2.2.2.2.2" xref="S3.SS1.p1.7.m4.2.2.2.2.2.2.cmml">t</mi><mi id="S3.SS1.p1.7.m4.2.2.2.2.2.3" xref="S3.SS1.p1.7.m4.2.2.2.2.2.3.cmml">i</mi><mo id="S3.SS1.p1.7.m4.2.2.2.2.3" xref="S3.SS1.p1.7.m4.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.SS1.p1.7.m4.2.2.2.5" xref="S3.SS1.p1.7.m4.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m4.2b"><set id="S3.SS1.p1.7.m4.2.2.3.cmml" xref="S3.SS1.p1.7.m4.2.2.2"><apply id="S3.SS1.p1.7.m4.1.1.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.7.m4.1.1.1.1.2.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m4.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1.2.2">𝑝</ci><ci id="S3.SS1.p1.7.m4.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1.2.3">𝑖</ci></apply><times id="S3.SS1.p1.7.m4.1.1.1.1.3.cmml" xref="S3.SS1.p1.7.m4.1.1.1.1.3"></times></apply><apply id="S3.SS1.p1.7.m4.2.2.2.2.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p1.7.m4.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.7.m4.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2.2.2">𝑡</ci><ci id="S3.SS1.p1.7.m4.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.SS1.p1.7.m4.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.m4.2.2.2.2.3"></times></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m4.2c">\{p_{i}^{*},t_{i}^{*}\}</annotation></semantics></math> are the corresponding ground truths. <math id="S3.SS1.p1.8.m5.1" class="ltx_Math" alttext="N_{cls}" display="inline"><semantics id="S3.SS1.p1.8.m5.1a"><msub id="S3.SS1.p1.8.m5.1.1" xref="S3.SS1.p1.8.m5.1.1.cmml"><mi id="S3.SS1.p1.8.m5.1.1.2" xref="S3.SS1.p1.8.m5.1.1.2.cmml">N</mi><mrow id="S3.SS1.p1.8.m5.1.1.3" xref="S3.SS1.p1.8.m5.1.1.3.cmml"><mi id="S3.SS1.p1.8.m5.1.1.3.2" xref="S3.SS1.p1.8.m5.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.8.m5.1.1.3.1" xref="S3.SS1.p1.8.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.8.m5.1.1.3.3" xref="S3.SS1.p1.8.m5.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.8.m5.1.1.3.1a" xref="S3.SS1.p1.8.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.8.m5.1.1.3.4" xref="S3.SS1.p1.8.m5.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m5.1b"><apply id="S3.SS1.p1.8.m5.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m5.1.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m5.1.1.2.cmml" xref="S3.SS1.p1.8.m5.1.1.2">𝑁</ci><apply id="S3.SS1.p1.8.m5.1.1.3.cmml" xref="S3.SS1.p1.8.m5.1.1.3"><times id="S3.SS1.p1.8.m5.1.1.3.1.cmml" xref="S3.SS1.p1.8.m5.1.1.3.1"></times><ci id="S3.SS1.p1.8.m5.1.1.3.2.cmml" xref="S3.SS1.p1.8.m5.1.1.3.2">𝑐</ci><ci id="S3.SS1.p1.8.m5.1.1.3.3.cmml" xref="S3.SS1.p1.8.m5.1.1.3.3">𝑙</ci><ci id="S3.SS1.p1.8.m5.1.1.3.4.cmml" xref="S3.SS1.p1.8.m5.1.1.3.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m5.1c">N_{cls}</annotation></semantics></math> is the total number of anchors in the candidate set <math id="S3.SS1.p1.9.m6.1" class="ltx_Math" alttext="\mathcal{B}" display="inline"><semantics id="S3.SS1.p1.9.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.9.m6.1.1" xref="S3.SS1.p1.9.m6.1.1.cmml">ℬ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m6.1b"><ci id="S3.SS1.p1.9.m6.1.1.cmml" xref="S3.SS1.p1.9.m6.1.1">ℬ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m6.1c">\mathcal{B}</annotation></semantics></math>. <math id="S3.SS1.p1.10.m7.1" class="ltx_Math" alttext="N_{reg}" display="inline"><semantics id="S3.SS1.p1.10.m7.1a"><msub id="S3.SS1.p1.10.m7.1.1" xref="S3.SS1.p1.10.m7.1.1.cmml"><mi id="S3.SS1.p1.10.m7.1.1.2" xref="S3.SS1.p1.10.m7.1.1.2.cmml">N</mi><mrow id="S3.SS1.p1.10.m7.1.1.3" xref="S3.SS1.p1.10.m7.1.1.3.cmml"><mi id="S3.SS1.p1.10.m7.1.1.3.2" xref="S3.SS1.p1.10.m7.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m7.1.1.3.1" xref="S3.SS1.p1.10.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.10.m7.1.1.3.3" xref="S3.SS1.p1.10.m7.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m7.1.1.3.1a" xref="S3.SS1.p1.10.m7.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.10.m7.1.1.3.4" xref="S3.SS1.p1.10.m7.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m7.1b"><apply id="S3.SS1.p1.10.m7.1.1.cmml" xref="S3.SS1.p1.10.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m7.1.1.1.cmml" xref="S3.SS1.p1.10.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.10.m7.1.1.2.cmml" xref="S3.SS1.p1.10.m7.1.1.2">𝑁</ci><apply id="S3.SS1.p1.10.m7.1.1.3.cmml" xref="S3.SS1.p1.10.m7.1.1.3"><times id="S3.SS1.p1.10.m7.1.1.3.1.cmml" xref="S3.SS1.p1.10.m7.1.1.3.1"></times><ci id="S3.SS1.p1.10.m7.1.1.3.2.cmml" xref="S3.SS1.p1.10.m7.1.1.3.2">𝑟</ci><ci id="S3.SS1.p1.10.m7.1.1.3.3.cmml" xref="S3.SS1.p1.10.m7.1.1.3.3">𝑒</ci><ci id="S3.SS1.p1.10.m7.1.1.3.4.cmml" xref="S3.SS1.p1.10.m7.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m7.1c">N_{reg}</annotation></semantics></math> is the size of the subset <math id="S3.SS1.p1.11.m8.1" class="ltx_Math" alttext="\mathcal{B}_{\mathcal{K}}" display="inline"><semantics id="S3.SS1.p1.11.m8.1a"><msub id="S3.SS1.p1.11.m8.1.1" xref="S3.SS1.p1.11.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.11.m8.1.1.2" xref="S3.SS1.p1.11.m8.1.1.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.11.m8.1.1.3" xref="S3.SS1.p1.11.m8.1.1.3.cmml">𝒦</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m8.1b"><apply id="S3.SS1.p1.11.m8.1.1.cmml" xref="S3.SS1.p1.11.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m8.1.1.1.cmml" xref="S3.SS1.p1.11.m8.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m8.1.1.2.cmml" xref="S3.SS1.p1.11.m8.1.1.2">ℬ</ci><ci id="S3.SS1.p1.11.m8.1.1.3.cmml" xref="S3.SS1.p1.11.m8.1.1.3">𝒦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m8.1c">\mathcal{B}_{\mathcal{K}}</annotation></semantics></math>, which only contains the anchors with the ground truth label <math id="S3.SS1.p1.12.m9.1" class="ltx_Math" alttext="p_{i}^{*}=1" display="inline"><semantics id="S3.SS1.p1.12.m9.1a"><mrow id="S3.SS1.p1.12.m9.1.1" xref="S3.SS1.p1.12.m9.1.1.cmml"><msubsup id="S3.SS1.p1.12.m9.1.1.2" xref="S3.SS1.p1.12.m9.1.1.2.cmml"><mi id="S3.SS1.p1.12.m9.1.1.2.2.2" xref="S3.SS1.p1.12.m9.1.1.2.2.2.cmml">p</mi><mi id="S3.SS1.p1.12.m9.1.1.2.2.3" xref="S3.SS1.p1.12.m9.1.1.2.2.3.cmml">i</mi><mo id="S3.SS1.p1.12.m9.1.1.2.3" xref="S3.SS1.p1.12.m9.1.1.2.3.cmml">∗</mo></msubsup><mo id="S3.SS1.p1.12.m9.1.1.1" xref="S3.SS1.p1.12.m9.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.12.m9.1.1.3" xref="S3.SS1.p1.12.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m9.1b"><apply id="S3.SS1.p1.12.m9.1.1.cmml" xref="S3.SS1.p1.12.m9.1.1"><eq id="S3.SS1.p1.12.m9.1.1.1.cmml" xref="S3.SS1.p1.12.m9.1.1.1"></eq><apply id="S3.SS1.p1.12.m9.1.1.2.cmml" xref="S3.SS1.p1.12.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m9.1.1.2.1.cmml" xref="S3.SS1.p1.12.m9.1.1.2">superscript</csymbol><apply id="S3.SS1.p1.12.m9.1.1.2.2.cmml" xref="S3.SS1.p1.12.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.12.m9.1.1.2.2.1.cmml" xref="S3.SS1.p1.12.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.12.m9.1.1.2.2.2.cmml" xref="S3.SS1.p1.12.m9.1.1.2.2.2">𝑝</ci><ci id="S3.SS1.p1.12.m9.1.1.2.2.3.cmml" xref="S3.SS1.p1.12.m9.1.1.2.2.3">𝑖</ci></apply><times id="S3.SS1.p1.12.m9.1.1.2.3.cmml" xref="S3.SS1.p1.12.m9.1.1.2.3"></times></apply><cn type="integer" id="S3.SS1.p1.12.m9.1.1.3.cmml" xref="S3.SS1.p1.12.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m9.1c">p_{i}^{*}=1</annotation></semantics></math>. Note <math id="S3.SS1.p1.13.m10.1" class="ltx_Math" alttext="p_{i}^{*}" display="inline"><semantics id="S3.SS1.p1.13.m10.1a"><msubsup id="S3.SS1.p1.13.m10.1.1" xref="S3.SS1.p1.13.m10.1.1.cmml"><mi id="S3.SS1.p1.13.m10.1.1.2.2" xref="S3.SS1.p1.13.m10.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p1.13.m10.1.1.2.3" xref="S3.SS1.p1.13.m10.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p1.13.m10.1.1.3" xref="S3.SS1.p1.13.m10.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m10.1b"><apply id="S3.SS1.p1.13.m10.1.1.cmml" xref="S3.SS1.p1.13.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m10.1.1.1.cmml" xref="S3.SS1.p1.13.m10.1.1">superscript</csymbol><apply id="S3.SS1.p1.13.m10.1.1.2.cmml" xref="S3.SS1.p1.13.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.13.m10.1.1.2.1.cmml" xref="S3.SS1.p1.13.m10.1.1">subscript</csymbol><ci id="S3.SS1.p1.13.m10.1.1.2.2.cmml" xref="S3.SS1.p1.13.m10.1.1.2.2">𝑝</ci><ci id="S3.SS1.p1.13.m10.1.1.2.3.cmml" xref="S3.SS1.p1.13.m10.1.1.2.3">𝑖</ci></apply><times id="S3.SS1.p1.13.m10.1.1.3.cmml" xref="S3.SS1.p1.13.m10.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m10.1c">p_{i}^{*}</annotation></semantics></math> equals <math id="S3.SS1.p1.14.m11.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS1.p1.14.m11.1a"><mn id="S3.SS1.p1.14.m11.1.1" xref="S3.SS1.p1.14.m11.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m11.1b"><cn type="integer" id="S3.SS1.p1.14.m11.1.1.cmml" xref="S3.SS1.p1.14.m11.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m11.1c">1</annotation></semantics></math> only when the anchor <math id="S3.SS1.p1.15.m12.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p1.15.m12.1a"><mi id="S3.SS1.p1.15.m12.1.1" xref="S3.SS1.p1.15.m12.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.15.m12.1b"><ci id="S3.SS1.p1.15.m12.1.1.cmml" xref="S3.SS1.p1.15.m12.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.15.m12.1c">i</annotation></semantics></math> can be associated to an annotated object bounding box from the known classes <math id="S3.SS1.p1.16.m13.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p1.16.m13.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.16.m13.1.1" xref="S3.SS1.p1.16.m13.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.16.m13.1b"><ci id="S3.SS1.p1.16.m13.1.1.cmml" xref="S3.SS1.p1.16.m13.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.16.m13.1c">\mathcal{K}</annotation></semantics></math>; otherwise it equals <math id="S3.SS1.p1.17.m14.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS1.p1.17.m14.1a"><mn id="S3.SS1.p1.17.m14.1.1" xref="S3.SS1.p1.17.m14.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.17.m14.1b"><cn type="integer" id="S3.SS1.p1.17.m14.1.1.cmml" xref="S3.SS1.p1.17.m14.1.1">0</cn></annotation-xml></semantics></math> (background).</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">From the closed-world to the open-world setup, the generalization goal extends to localizing every object in the image, which can belong to an unknown novel class <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">u</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">𝒰</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><in id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></in><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑢</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">𝒰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">u\in\mathcal{U}</annotation></semantics></math>. Under the training loss in (<a href="#S3.E1" title="In 3.1 open-world class-agnostic object detection problem ‣ 3 Method ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), an unannotated object will be classified as “background”. As a result, the model will treat similar types of objects as “background” at inference time. To avoid suppressing the detection of novel objects in the background, <cite class="ltx_cite ltx_citemacro_citet">Kim et al. (<a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> proposed to replace the classification loss in (<a href="#S3.E1" title="In 3.1 open-world class-agnostic object detection problem ‣ 3 Method ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) by the objectness score prediction loss, yielding</p>
<table id="A5.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{OLN}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*})," display="inline"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.6" xref="S3.E2.m1.2.2.1.1.6.cmml"><msub id="S3.E2.m1.2.2.1.1.6.2" xref="S3.E2.m1.2.2.1.1.6.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.6.2.2" xref="S3.E2.m1.2.2.1.1.6.2.2.cmml">ℒ</mi><mrow id="S3.E2.m1.2.2.1.1.6.2.3" xref="S3.E2.m1.2.2.1.1.6.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.6.2.3.2" xref="S3.E2.m1.2.2.1.1.6.2.3.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.2.3.1" xref="S3.E2.m1.2.2.1.1.6.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.6.2.3.3" xref="S3.E2.m1.2.2.1.1.6.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.2.3.1a" xref="S3.E2.m1.2.2.1.1.6.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.6.2.3.4" xref="S3.E2.m1.2.2.1.1.6.2.3.4.cmml">N</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.6.1" xref="S3.E2.m1.2.2.1.1.6.1.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.6.3.2" xref="S3.E2.m1.2.2.1.1.6.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.6.3.2.1" xref="S3.E2.m1.2.2.1.1.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">ℐ</mi><mo stretchy="false" id="S3.E2.m1.2.2.1.1.6.3.2.2" xref="S3.E2.m1.2.2.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.5" xref="S3.E2.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.4" xref="S3.E2.m1.2.2.1.1.4.cmml"><mrow id="S3.E2.m1.2.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.4.cmml"><mfrac id="S3.E2.m1.2.2.1.1.2.2.4a" xref="S3.E2.m1.2.2.1.1.2.2.4.cmml"><mn id="S3.E2.m1.2.2.1.1.2.2.4.2" xref="S3.E2.m1.2.2.1.1.2.2.4.2.cmml">1</mn><msub id="S3.E2.m1.2.2.1.1.2.2.4.3" xref="S3.E2.m1.2.2.1.1.2.2.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.2" xref="S3.E2.m1.2.2.1.1.2.2.4.3.2.cmml">N</mi><mrow id="S3.E2.m1.2.2.1.1.2.2.4.3.3" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.4.3.3.1" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.3.3" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.4.3.3.1a" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.2.2.4.3.3.4" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.3.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.cmml"><munder id="S3.E2.m1.2.2.1.1.2.2.2.3a" xref="S3.E2.m1.2.2.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E2.m1.2.2.1.1.2.2.2.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.3.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.2.2.2.3.3.1" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.1.cmml">∈</mo><msub id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3.cmml">𝒦</mi></msub></mrow></munder></mstyle><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E2.m1.2.2.1.1.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1a" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.4.5" xref="S3.E2.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S3.E2.m1.2.2.1.1.4.4" xref="S3.E2.m1.2.2.1.1.4.4.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.4.4.4" xref="S3.E2.m1.2.2.1.1.4.4.4.cmml"><mfrac id="S3.E2.m1.2.2.1.1.4.4.4a" xref="S3.E2.m1.2.2.1.1.4.4.4.cmml"><mn id="S3.E2.m1.2.2.1.1.4.4.4.2" xref="S3.E2.m1.2.2.1.1.4.4.4.2.cmml">1</mn><msub id="S3.E2.m1.2.2.1.1.4.4.4.3" xref="S3.E2.m1.2.2.1.1.4.4.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.2" xref="S3.E2.m1.2.2.1.1.4.4.4.3.2.cmml">N</mi><mrow id="S3.E2.m1.2.2.1.1.4.4.4.3.3" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.3.2" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.4.3.3.1" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.3.3" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.4.3.3.1a" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.4.4.4.3.3.4" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.3" xref="S3.E2.m1.2.2.1.1.4.4.3.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.4.4.2" xref="S3.E2.m1.2.2.1.1.4.4.2.cmml"><mstyle displaystyle="true" id="S3.E2.m1.2.2.1.1.4.4.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.cmml"><munder id="S3.E2.m1.2.2.1.1.4.4.2.3a" xref="S3.E2.m1.2.2.1.1.4.4.2.3.cmml"><mo movablelimits="false" id="S3.E2.m1.2.2.1.1.4.4.2.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.3.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.1.1.4.4.2.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.2.3.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.4.4.2.3.3.1" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.1.cmml">∈</mo><msub id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3.cmml">𝒦</mi></msub></mrow></munder></mstyle><mrow id="S3.E2.m1.2.2.1.1.4.4.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.cmml"><msub id="S3.E2.m1.2.2.1.1.4.4.2.2.4" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1a" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.4.4.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.3.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml">o</mi><mi id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.4" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml">o</mi><mi id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.5" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.5.cmml" xref="S3.E2.m1.2.2.1.1.5"></eq><apply id="S3.E2.m1.2.2.1.1.6.cmml" xref="S3.E2.m1.2.2.1.1.6"><times id="S3.E2.m1.2.2.1.1.6.1.cmml" xref="S3.E2.m1.2.2.1.1.6.1"></times><apply id="S3.E2.m1.2.2.1.1.6.2.cmml" xref="S3.E2.m1.2.2.1.1.6.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.6.2.1.cmml" xref="S3.E2.m1.2.2.1.1.6.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.6.2.2.cmml" xref="S3.E2.m1.2.2.1.1.6.2.2">ℒ</ci><apply id="S3.E2.m1.2.2.1.1.6.2.3.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3"><times id="S3.E2.m1.2.2.1.1.6.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.1"></times><ci id="S3.E2.m1.2.2.1.1.6.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.2">𝑂</ci><ci id="S3.E2.m1.2.2.1.1.6.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.3">𝐿</ci><ci id="S3.E2.m1.2.2.1.1.6.2.3.4.cmml" xref="S3.E2.m1.2.2.1.1.6.2.3.4">𝑁</ci></apply></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ℐ</ci></apply><apply id="S3.E2.m1.2.2.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.4"><plus id="S3.E2.m1.2.2.1.1.4.5.cmml" xref="S3.E2.m1.2.2.1.1.4.5"></plus><apply id="S3.E2.m1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2"><times id="S3.E2.m1.2.2.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.3"></times><apply id="S3.E2.m1.2.2.1.1.2.2.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4"><divide id="S3.E2.m1.2.2.1.1.2.2.4.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4"></divide><cn type="integer" id="S3.E2.m1.2.2.1.1.2.2.4.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.2">1</cn><apply id="S3.E2.m1.2.2.1.1.2.2.4.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.2">𝑁</ci><apply id="S3.E2.m1.2.2.1.1.2.2.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3"><times id="S3.E2.m1.2.2.1.1.2.2.4.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.2">𝑟</ci><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.3">𝑒</ci><ci id="S3.E2.m1.2.2.1.1.2.2.4.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.4.3.3.4">𝑔</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2"><apply id="S3.E2.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.2"></sum><apply id="S3.E2.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3"><in id="S3.E2.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.1"></in><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.2">𝑖</ci><apply id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.2">ℬ</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.3.3.3.3">𝒦</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2"><times id="S3.E2.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.3"></times><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.4.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.2">ℒ</ci><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3"><times id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.1"></times><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.2">𝑟</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.3">𝑒</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.4.3.4">𝑔</ci></apply></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.2">𝑡</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.2">𝑡</ci><ci id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.4.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4"><times id="S3.E2.m1.2.2.1.1.4.4.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.3"></times><apply id="S3.E2.m1.2.2.1.1.4.4.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4"><divide id="S3.E2.m1.2.2.1.1.4.4.4.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4"></divide><cn type="integer" id="S3.E2.m1.2.2.1.1.4.4.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.2">1</cn><apply id="S3.E2.m1.2.2.1.1.4.4.4.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.2">𝑁</ci><apply id="S3.E2.m1.2.2.1.1.4.4.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3"><times id="S3.E2.m1.2.2.1.1.4.4.4.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.1"></times><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.2">𝑟</ci><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.3">𝑒</ci><ci id="S3.E2.m1.2.2.1.1.4.4.4.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.4.3.3.4">𝑔</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.4.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2"><apply id="S3.E2.m1.2.2.1.1.4.4.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3">subscript</csymbol><sum id="S3.E2.m1.2.2.1.1.4.4.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.2"></sum><apply id="S3.E2.m1.2.2.1.1.4.4.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3"><in id="S3.E2.m1.2.2.1.1.4.4.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.1"></in><ci id="S3.E2.m1.2.2.1.1.4.4.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.2">𝑖</ci><apply id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.2">ℬ</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.3.3.3.3">𝒦</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2"><times id="S3.E2.m1.2.2.1.1.4.4.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.3"></times><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.2.4.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.2">ℒ</ci><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3"><times id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.1"></times><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.2">𝑜</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.3">𝑏</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.4.3.4">𝑗</ci></apply></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2"><apply id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.2">𝑜</ci><ci id="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.2">𝑜</ci><ci id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.4.4.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\displaystyle\mathcal{L}_{OLN}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.5" class="ltx_p">where <math id="S3.SS1.p2.2.m1.1" class="ltx_Math" alttext="o_{i}" display="inline"><semantics id="S3.SS1.p2.2.m1.1a"><msub id="S3.SS1.p2.2.m1.1.1" xref="S3.SS1.p2.2.m1.1.1.cmml"><mi id="S3.SS1.p2.2.m1.1.1.2" xref="S3.SS1.p2.2.m1.1.1.2.cmml">o</mi><mi id="S3.SS1.p2.2.m1.1.1.3" xref="S3.SS1.p2.2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m1.1b"><apply id="S3.SS1.p2.2.m1.1.1.cmml" xref="S3.SS1.p2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m1.1.1.1.cmml" xref="S3.SS1.p2.2.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m1.1.1.2.cmml" xref="S3.SS1.p2.2.m1.1.1.2">𝑜</ci><ci id="S3.SS1.p2.2.m1.1.1.3.cmml" xref="S3.SS1.p2.2.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m1.1c">o_{i}</annotation></semantics></math> and <math id="S3.SS1.p2.3.m2.1" class="ltx_Math" alttext="o_{i}^{*}" display="inline"><semantics id="S3.SS1.p2.3.m2.1a"><msubsup id="S3.SS1.p2.3.m2.1.1" xref="S3.SS1.p2.3.m2.1.1.cmml"><mi id="S3.SS1.p2.3.m2.1.1.2.2" xref="S3.SS1.p2.3.m2.1.1.2.2.cmml">o</mi><mi id="S3.SS1.p2.3.m2.1.1.2.3" xref="S3.SS1.p2.3.m2.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p2.3.m2.1.1.3" xref="S3.SS1.p2.3.m2.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m2.1b"><apply id="S3.SS1.p2.3.m2.1.1.cmml" xref="S3.SS1.p2.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m2.1.1.1.cmml" xref="S3.SS1.p2.3.m2.1.1">superscript</csymbol><apply id="S3.SS1.p2.3.m2.1.1.2.cmml" xref="S3.SS1.p2.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m2.1.1.2.1.cmml" xref="S3.SS1.p2.3.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m2.1.1.2.2.cmml" xref="S3.SS1.p2.3.m2.1.1.2.2">𝑜</ci><ci id="S3.SS1.p2.3.m2.1.1.2.3.cmml" xref="S3.SS1.p2.3.m2.1.1.2.3">𝑖</ci></apply><times id="S3.SS1.p2.3.m2.1.1.3.cmml" xref="S3.SS1.p2.3.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m2.1c">o_{i}^{*}</annotation></semantics></math> are the predicted objectness score and its ground truth of anchor <math id="S3.SS1.p2.4.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p2.4.m3.1a"><mi id="S3.SS1.p2.4.m3.1.1" xref="S3.SS1.p2.4.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m3.1b"><ci id="S3.SS1.p2.4.m3.1.1.cmml" xref="S3.SS1.p2.4.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m3.1c">i</annotation></semantics></math>. In doing so, only the anchors with <math id="S3.SS1.p2.5.m4.1" class="ltx_Math" alttext="p_{i}^{*}=1" display="inline"><semantics id="S3.SS1.p2.5.m4.1a"><mrow id="S3.SS1.p2.5.m4.1.1" xref="S3.SS1.p2.5.m4.1.1.cmml"><msubsup id="S3.SS1.p2.5.m4.1.1.2" xref="S3.SS1.p2.5.m4.1.1.2.cmml"><mi id="S3.SS1.p2.5.m4.1.1.2.2.2" xref="S3.SS1.p2.5.m4.1.1.2.2.2.cmml">p</mi><mi id="S3.SS1.p2.5.m4.1.1.2.2.3" xref="S3.SS1.p2.5.m4.1.1.2.2.3.cmml">i</mi><mo id="S3.SS1.p2.5.m4.1.1.2.3" xref="S3.SS1.p2.5.m4.1.1.2.3.cmml">∗</mo></msubsup><mo id="S3.SS1.p2.5.m4.1.1.1" xref="S3.SS1.p2.5.m4.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.5.m4.1.1.3" xref="S3.SS1.p2.5.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m4.1b"><apply id="S3.SS1.p2.5.m4.1.1.cmml" xref="S3.SS1.p2.5.m4.1.1"><eq id="S3.SS1.p2.5.m4.1.1.1.cmml" xref="S3.SS1.p2.5.m4.1.1.1"></eq><apply id="S3.SS1.p2.5.m4.1.1.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m4.1.1.2.1.cmml" xref="S3.SS1.p2.5.m4.1.1.2">superscript</csymbol><apply id="S3.SS1.p2.5.m4.1.1.2.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m4.1.1.2.2.1.cmml" xref="S3.SS1.p2.5.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.5.m4.1.1.2.2.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2.2.2">𝑝</ci><ci id="S3.SS1.p2.5.m4.1.1.2.2.3.cmml" xref="S3.SS1.p2.5.m4.1.1.2.2.3">𝑖</ci></apply><times id="S3.SS1.p2.5.m4.1.1.2.3.cmml" xref="S3.SS1.p2.5.m4.1.1.2.3"></times></apply><cn type="integer" id="S3.SS1.p2.5.m4.1.1.3.cmml" xref="S3.SS1.p2.5.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m4.1c">p_{i}^{*}=1</annotation></semantics></math> are involved in training, completely removing any “background” prediction. At inference time, the objectness score is used to rank the detections. However, since these anchors only capture the annotated objects from the base classes, this loss modification cannot effectively mitigate the overfitting to the base classes. We further resort to adding additional “objects” into training, especially novel ones with very different appearances than objects from the base classes.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Exploiting geometric cues</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">Models trained on RGB images tend to over-rely on the appearance cues for object detection. Therefore, it is hard for them to detect novel objects that appear very differently from the base classes. For instance, a model trained on cars is likely to detect trucks, but unlikely to also detect sandwiches. Involving such novel objects, e.g., food, into training is then an effective way to mitigate the appearance bias towards the base classes, e.g., vehicles. To this end, we exploit two types of geometric cues, i.e., depth and normals, for detecting unannotated novel objects in the training set, see some examples in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Both of them are common geometric cues that capture local information. Depth focuses on the relative spatial difference of objects and abstracts away the details on the object surfaces. Surface normals focus on the directional difference and remain the same on flat surfaces. Compared with the original RGB image, they discard most appearance details and focus on the geometry information such as object shapes and relative spatial locations. Models trained with them can thus discover many novel-looking objects that RGB-based ones cannot detect.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p">We use off-the-shelf pretrained models to extract geometric cues. Specifically, we use Omnidata models <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> trained using cross-task consistency <cite class="ltx_cite ltx_citemacro_citep">(Zamir et al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> and 2D/3D data augmentations <cite class="ltx_cite ltx_citemacro_citep">(Kar et al., <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.
The training dataset for the models is the Omnidata Starter Dataset (OSD) <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> which contains 2200 real and rendered scenes.
Despite the difference between the OSD to the object detection benchmark datasets, the Omnidata model can produce high-quality results, implying that the invariances behind these geometric cues are robust.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Pseudo labeling method</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.2" class="ltx_p">To use the geometric cues to discover unannotated novel objects in the training set, we first train an object proposal network on the depth or normal input using the same training loss as in (<a href="#S3.E2" title="In 3.1 open-world class-agnostic object detection problem ‣ 3 Method ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), i.e., Phase-I training in Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Related work ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
Then, this object proposal network will pseudo-label the training images using its detected bounding boxes.
After filtering out the detected bounding boxes which overlap with the base class annotations, we then add the remaining top-<math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">k</annotation></semantics></math> boxes to the ground truth annotations.
Here <math id="S3.SS3.p1.2.m2.3" class="ltx_Math" alttext="k\in\{1,2,3\}" display="inline"><semantics id="S3.SS3.p1.2.m2.3a"><mrow id="S3.SS3.p1.2.m2.3.4" xref="S3.SS3.p1.2.m2.3.4.cmml"><mi id="S3.SS3.p1.2.m2.3.4.2" xref="S3.SS3.p1.2.m2.3.4.2.cmml">k</mi><mo id="S3.SS3.p1.2.m2.3.4.1" xref="S3.SS3.p1.2.m2.3.4.1.cmml">∈</mo><mrow id="S3.SS3.p1.2.m2.3.4.3.2" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.3.4.3.2.1" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">{</mo><mn id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">1</mn><mo id="S3.SS3.p1.2.m2.3.4.3.2.2" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.2.2" xref="S3.SS3.p1.2.m2.2.2.cmml">2</mn><mo id="S3.SS3.p1.2.m2.3.4.3.2.3" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.3.3" xref="S3.SS3.p1.2.m2.3.3.cmml">3</mn><mo stretchy="false" id="S3.SS3.p1.2.m2.3.4.3.2.4" xref="S3.SS3.p1.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.3b"><apply id="S3.SS3.p1.2.m2.3.4.cmml" xref="S3.SS3.p1.2.m2.3.4"><in id="S3.SS3.p1.2.m2.3.4.1.cmml" xref="S3.SS3.p1.2.m2.3.4.1"></in><ci id="S3.SS3.p1.2.m2.3.4.2.cmml" xref="S3.SS3.p1.2.m2.3.4.2">𝑘</ci><set id="S3.SS3.p1.2.m2.3.4.3.1.cmml" xref="S3.SS3.p1.2.m2.3.4.3.2"><cn type="integer" id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">1</cn><cn type="integer" id="S3.SS3.p1.2.m2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2">2</cn><cn type="integer" id="S3.SS3.p1.2.m2.3.3.cmml" xref="S3.SS3.p1.2.m2.3.3">3</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.3c">k\in\{1,2,3\}</annotation></semantics></math> is determined for each detector on a small holdout validation set. Finally, we train a new class-agnostic object detector using the RGB image as input and the extended bounding box annotation pool as ground truth, i.e., Phase-II in Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Related work ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The training loss is</p>
<table id="A5.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.2" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{GOOD}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*})." display="inline"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1.6" xref="S3.E3.m1.2.2.1.1.6.cmml"><msub id="S3.E3.m1.2.2.1.1.6.2" xref="S3.E3.m1.2.2.1.1.6.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.6.2.2" xref="S3.E3.m1.2.2.1.1.6.2.2.cmml">ℒ</mi><mrow id="S3.E3.m1.2.2.1.1.6.2.3" xref="S3.E3.m1.2.2.1.1.6.2.3.cmml"><mi id="S3.E3.m1.2.2.1.1.6.2.3.2" xref="S3.E3.m1.2.2.1.1.6.2.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.2.3.1" xref="S3.E3.m1.2.2.1.1.6.2.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.6.2.3.3" xref="S3.E3.m1.2.2.1.1.6.2.3.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.2.3.1a" xref="S3.E3.m1.2.2.1.1.6.2.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.6.2.3.4" xref="S3.E3.m1.2.2.1.1.6.2.3.4.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.2.3.1b" xref="S3.E3.m1.2.2.1.1.6.2.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.6.2.3.5" xref="S3.E3.m1.2.2.1.1.6.2.3.5.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.6.1" xref="S3.E3.m1.2.2.1.1.6.1.cmml">​</mo><mrow id="S3.E3.m1.2.2.1.1.6.3.2" xref="S3.E3.m1.2.2.1.1.6.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.6.3.2.1" xref="S3.E3.m1.2.2.1.1.6.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">ℐ</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.1.6.3.2.2" xref="S3.E3.m1.2.2.1.1.6.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.5" xref="S3.E3.m1.2.2.1.1.5.cmml">=</mo><mrow id="S3.E3.m1.2.2.1.1.4" xref="S3.E3.m1.2.2.1.1.4.cmml"><mrow id="S3.E3.m1.2.2.1.1.2.2" xref="S3.E3.m1.2.2.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.2.2.4" xref="S3.E3.m1.2.2.1.1.2.2.4.cmml"><mfrac id="S3.E3.m1.2.2.1.1.2.2.4a" xref="S3.E3.m1.2.2.1.1.2.2.4.cmml"><mn id="S3.E3.m1.2.2.1.1.2.2.4.2" xref="S3.E3.m1.2.2.1.1.2.2.4.2.cmml">1</mn><msub id="S3.E3.m1.2.2.1.1.2.2.4.3" xref="S3.E3.m1.2.2.1.1.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.2" xref="S3.E3.m1.2.2.1.1.2.2.4.3.2.cmml">N</mi><mrow id="S3.E3.m1.2.2.1.1.2.2.4.3.3" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.4.3.3.1" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.4.3.3.1a" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.2.2.4.3.3.4" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.3.cmml">​</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.cmml"><munder id="S3.E3.m1.2.2.1.1.2.2.2.3a" xref="S3.E3.m1.2.2.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.2.2.1.1.2.2.2.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.2.cmml">∑</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.2.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.2.2.2.3.3.1" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.1.cmml">∈</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.cmml"><msub id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3.cmml">𝒦</mi></msub><mo id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1.cmml">∪</mo><msub id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3.cmml">𝒩</mi></msub></mrow></mrow></munder></mstyle><mrow id="S3.E3.m1.2.2.1.1.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.cmml"><msub id="S3.E3.m1.2.2.1.1.2.2.2.2.4" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1a" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4.cmml">g</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.3.cmml">​</mo><mrow id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">t</mi><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.4" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml">t</mi><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.5" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.2.2.1.1.4.5" xref="S3.E3.m1.2.2.1.1.4.5.cmml">+</mo><mrow id="S3.E3.m1.2.2.1.1.4.4" xref="S3.E3.m1.2.2.1.1.4.4.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.4.4.4" xref="S3.E3.m1.2.2.1.1.4.4.4.cmml"><mfrac id="S3.E3.m1.2.2.1.1.4.4.4a" xref="S3.E3.m1.2.2.1.1.4.4.4.cmml"><mn id="S3.E3.m1.2.2.1.1.4.4.4.2" xref="S3.E3.m1.2.2.1.1.4.4.4.2.cmml">1</mn><msub id="S3.E3.m1.2.2.1.1.4.4.4.3" xref="S3.E3.m1.2.2.1.1.4.4.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.2" xref="S3.E3.m1.2.2.1.1.4.4.4.3.2.cmml">N</mi><mrow id="S3.E3.m1.2.2.1.1.4.4.4.3.3" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.4.3.3.1" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.4.3.3.1a" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.4.4.4.3.3.4" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.4.cmml">g</mi></mrow></msub></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.3" xref="S3.E3.m1.2.2.1.1.4.4.3.cmml">​</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2" xref="S3.E3.m1.2.2.1.1.4.4.2.cmml"><mstyle displaystyle="true" id="S3.E3.m1.2.2.1.1.4.4.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.cmml"><munder id="S3.E3.m1.2.2.1.1.4.4.2.3a" xref="S3.E3.m1.2.2.1.1.4.4.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.2.2.1.1.4.4.2.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.2.cmml">∑</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.2.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.2.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.4.4.2.3.3.1" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.1.cmml">∈</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.cmml"><msub id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3.cmml">𝒦</mi></msub><mo id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1.cmml">∪</mo><msub id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3.cmml">𝒩</mi></msub></mrow></mrow></munder></mstyle><mrow id="S3.E3.m1.2.2.1.1.4.4.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.cmml"><msub id="S3.E3.m1.2.2.1.1.4.4.2.2.4" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.2.cmml">ℒ</mi><mrow id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1a" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1.cmml">​</mo><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.4.4.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.3.cmml">​</mo><mrow id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml">o</mi><mi id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.4" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml">,</mo><msubsup id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml">o</mi><mi id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml">i</mi><mo id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml">∗</mo></msubsup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.5" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><eq id="S3.E3.m1.2.2.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.5"></eq><apply id="S3.E3.m1.2.2.1.1.6.cmml" xref="S3.E3.m1.2.2.1.1.6"><times id="S3.E3.m1.2.2.1.1.6.1.cmml" xref="S3.E3.m1.2.2.1.1.6.1"></times><apply id="S3.E3.m1.2.2.1.1.6.2.cmml" xref="S3.E3.m1.2.2.1.1.6.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.6.2.1.cmml" xref="S3.E3.m1.2.2.1.1.6.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.6.2.2.cmml" xref="S3.E3.m1.2.2.1.1.6.2.2">ℒ</ci><apply id="S3.E3.m1.2.2.1.1.6.2.3.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3"><times id="S3.E3.m1.2.2.1.1.6.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.1"></times><ci id="S3.E3.m1.2.2.1.1.6.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.2">𝐺</ci><ci id="S3.E3.m1.2.2.1.1.6.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.3">𝑂</ci><ci id="S3.E3.m1.2.2.1.1.6.2.3.4.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.4">𝑂</ci><ci id="S3.E3.m1.2.2.1.1.6.2.3.5.cmml" xref="S3.E3.m1.2.2.1.1.6.2.3.5">𝐷</ci></apply></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ℐ</ci></apply><apply id="S3.E3.m1.2.2.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.4"><plus id="S3.E3.m1.2.2.1.1.4.5.cmml" xref="S3.E3.m1.2.2.1.1.4.5"></plus><apply id="S3.E3.m1.2.2.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2"><times id="S3.E3.m1.2.2.1.1.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.3"></times><apply id="S3.E3.m1.2.2.1.1.2.2.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4"><divide id="S3.E3.m1.2.2.1.1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4"></divide><cn type="integer" id="S3.E3.m1.2.2.1.1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.2">1</cn><apply id="S3.E3.m1.2.2.1.1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.2">𝑁</ci><apply id="S3.E3.m1.2.2.1.1.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3"><times id="S3.E3.m1.2.2.1.1.2.2.4.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.1"></times><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.2">𝑟</ci><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.3">𝑒</ci><ci id="S3.E3.m1.2.2.1.1.2.2.4.3.3.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.4.3.3.4">𝑔</ci></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2"><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E3.m1.2.2.1.1.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.2"></sum><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3"><in id="S3.E3.m1.2.2.1.1.2.2.2.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.1"></in><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.2">𝑖</ci><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3"><union id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.1"></union><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.2">ℬ</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.2.3">𝒦</ci></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.2">ℬ</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3.3.3.3.3">𝒩</ci></apply></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2"><times id="S3.E3.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.3"></times><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.4.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.2">ℒ</ci><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3"><times id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.1"></times><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.2">𝑟</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.3">𝑒</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.4.3.4">𝑔</ci></apply></apply><interval closure="open" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2"><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.2">𝑡</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.2">𝑡</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4"><times id="S3.E3.m1.2.2.1.1.4.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.3"></times><apply id="S3.E3.m1.2.2.1.1.4.4.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4"><divide id="S3.E3.m1.2.2.1.1.4.4.4.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4"></divide><cn type="integer" id="S3.E3.m1.2.2.1.1.4.4.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.2">1</cn><apply id="S3.E3.m1.2.2.1.1.4.4.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.2">𝑁</ci><apply id="S3.E3.m1.2.2.1.1.4.4.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3"><times id="S3.E3.m1.2.2.1.1.4.4.4.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.1"></times><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.2">𝑟</ci><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.3">𝑒</ci><ci id="S3.E3.m1.2.2.1.1.4.4.4.3.3.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.4.3.3.4">𝑔</ci></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2"><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3">subscript</csymbol><sum id="S3.E3.m1.2.2.1.1.4.4.2.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.2"></sum><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3"><in id="S3.E3.m1.2.2.1.1.4.4.2.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.1"></in><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.2">𝑖</ci><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3"><union id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.1"></union><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.2">ℬ</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.2.3">𝒦</ci></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.2">ℬ</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.3.3.3.3.3">𝒩</ci></apply></apply></apply></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2"><times id="S3.E3.m1.2.2.1.1.4.4.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.3"></times><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.2.4.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.2">ℒ</ci><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3"><times id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.1"></times><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.2">𝑜</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.3">𝑏</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.4.3.4">𝑗</ci></apply></apply><interval closure="open" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2"><apply id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.2">𝑜</ci><ci id="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.2">𝑜</ci><ci id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.2.3">𝑖</ci></apply><times id="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.4.4.2.2.2.2.2.3"></times></apply></interval></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\displaystyle\mathcal{L}_{GOOD}(\mathcal{I})=\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{reg}(t_{i},t_{i}^{*})+\dfrac{1}{N_{reg}}\sum_{i\in\mathcal{B}_{\mathcal{K}}\cup\mathcal{B}_{\mathcal{N}}}\mathcal{L}_{obj}(o_{i},o_{i}^{*}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.8" class="ltx_p">Compared with (<a href="#S3.E2" title="In 3.1 open-world class-agnostic object detection problem ‣ 3 Method ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), the anchors that overlap with the pseudo boxes of the detected novel objects, i.e., <math id="S3.SS3.p1.3.m1.1" class="ltx_Math" alttext="i\in\mathcal{B}_{\mathcal{N}}" display="inline"><semantics id="S3.SS3.p1.3.m1.1a"><mrow id="S3.SS3.p1.3.m1.1.1" xref="S3.SS3.p1.3.m1.1.1.cmml"><mi id="S3.SS3.p1.3.m1.1.1.2" xref="S3.SS3.p1.3.m1.1.1.2.cmml">i</mi><mo id="S3.SS3.p1.3.m1.1.1.1" xref="S3.SS3.p1.3.m1.1.1.1.cmml">∈</mo><msub id="S3.SS3.p1.3.m1.1.1.3" xref="S3.SS3.p1.3.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.3.m1.1.1.3.2" xref="S3.SS3.p1.3.m1.1.1.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.3.m1.1.1.3.3" xref="S3.SS3.p1.3.m1.1.1.3.3.cmml">𝒩</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m1.1b"><apply id="S3.SS3.p1.3.m1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1"><in id="S3.SS3.p1.3.m1.1.1.1.cmml" xref="S3.SS3.p1.3.m1.1.1.1"></in><ci id="S3.SS3.p1.3.m1.1.1.2.cmml" xref="S3.SS3.p1.3.m1.1.1.2">𝑖</ci><apply id="S3.SS3.p1.3.m1.1.1.3.cmml" xref="S3.SS3.p1.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m1.1.1.3.1.cmml" xref="S3.SS3.p1.3.m1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.3.m1.1.1.3.2.cmml" xref="S3.SS3.p1.3.m1.1.1.3.2">ℬ</ci><ci id="S3.SS3.p1.3.m1.1.1.3.3.cmml" xref="S3.SS3.p1.3.m1.1.1.3.3">𝒩</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m1.1c">i\in\mathcal{B}_{\mathcal{N}}</annotation></semantics></math>, are also involved in training.
The pseudo boxes can be acquired from a single source, i.e., one of the geometric cues, and from both, i.e., pseudo label ensembling. We name our method <math id="S3.SS3.p1.4.m2.1" class="ltx_Math" alttext="\mathrm{GOOD}" display="inline"><semantics id="S3.SS3.p1.4.m2.1a"><mi id="S3.SS3.p1.4.m2.1.1" xref="S3.SS3.p1.4.m2.1.1.cmml">GOOD</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m2.1b"><ci id="S3.SS3.p1.4.m2.1.1.cmml" xref="S3.SS3.p1.4.m2.1.1">GOOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m2.1c">\mathrm{GOOD}</annotation></semantics></math>-<math id="S3.SS3.p1.5.m3.1" class="ltx_Math" alttext="\mathrm{X}" display="inline"><semantics id="S3.SS3.p1.5.m3.1a"><mi mathvariant="normal" id="S3.SS3.p1.5.m3.1.1" xref="S3.SS3.p1.5.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m3.1b"><ci id="S3.SS3.p1.5.m3.1.1.cmml" xref="S3.SS3.p1.5.m3.1.1">X</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m3.1c">\mathrm{X}</annotation></semantics></math> when using a specific geometric cue <math id="S3.SS3.p1.6.m4.1" class="ltx_Math" alttext="\mathrm{X}" display="inline"><semantics id="S3.SS3.p1.6.m4.1a"><mi mathvariant="normal" id="S3.SS3.p1.6.m4.1.1" xref="S3.SS3.p1.6.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m4.1b"><ci id="S3.SS3.p1.6.m4.1.1.cmml" xref="S3.SS3.p1.6.m4.1.1">X</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m4.1c">\mathrm{X}</annotation></semantics></math> as the pseudo labeling source, whereas <math id="S3.SS3.p1.7.m5.1" class="ltx_Math" alttext="\mathrm{GOOD}" display="inline"><semantics id="S3.SS3.p1.7.m5.1a"><mi id="S3.SS3.p1.7.m5.1.1" xref="S3.SS3.p1.7.m5.1.1.cmml">GOOD</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m5.1b"><ci id="S3.SS3.p1.7.m5.1.1.cmml" xref="S3.SS3.p1.7.m5.1.1">GOOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m5.1c">\mathrm{GOOD}</annotation></semantics></math>-<math id="S3.SS3.p1.8.m6.1" class="ltx_Math" alttext="\mathrm{Both}" display="inline"><semantics id="S3.SS3.p1.8.m6.1a"><mi id="S3.SS3.p1.8.m6.1.1" xref="S3.SS3.p1.8.m6.1.1.cmml">Both</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m6.1b"><ci id="S3.SS3.p1.8.m6.1.1.cmml" xref="S3.SS3.p1.8.m6.1.1">Both</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m6.1c">\mathrm{Both}</annotation></semantics></math> stands for ensembling the pseudo labels from both the depth and normals.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p">Inspired by previous works in self-training <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a href="#bib.bib44" title="" class="ltx_ref">2020</a>; Sohn et al., <a href="#bib.bib40" title="" class="ltx_ref">2020</a>; Xu et al., <a href="#bib.bib46" title="" class="ltx_ref">2021</a>)</cite>, we use strong data augmentation during Phase-II to counteract the noise in pseudo boxes and further boost the performance of GOOD.
Specifically, for Phase-II training, we use AutoAugment <cite class="ltx_cite ltx_citemacro_citep">(Cubuk et al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite> which includes random resizing, flip, and cropping.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.5" class="ltx_p"><span id="S4.p1.5.1" class="ltx_text ltx_font_bold">Benchmarks.</span>
We target two major challenges of open-world class-agnostic object detection: <span id="S4.p1.5.2" class="ltx_text ltx_font_italic">cross-category and cross-dataset generalization</span>.
For the cross-category evaluation, we follow the common practice in the literature <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> to split the class category list into two parts. One is used as the base class for training, whereas the other is reserved only for testing cross-category generalization. Specifically, we adopt two splits of the <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">80</annotation></semantics></math> classes in the COCO dataset <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>.
The first benchmark splits the COCO classes into a single “person” class and 79 non-person classes. This is to stress-test the generalization ability of the methods. We follow <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> to choose the “person” category as the training class because it contains diverse viewpoints and shapes. The second benchmark splits the COCO classes into <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">20</annotation></semantics></math> PASCAL-VOC <cite class="ltx_cite ltx_citemacro_citep">(Everingham et al., <a href="#bib.bib11" title="" class="ltx_ref">2010</a>)</cite> classes for training and the other <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="60" display="inline"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn type="integer" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">60</annotation></semantics></math> for testing.
For the cross-dataset evaluation, we use the ADE20K dataset <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib49" title="" class="ltx_ref">2019</a>)</cite> for testing. We compare models trained using only <math id="S4.p1.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.p1.4.m4.1a"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><cn type="integer" id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">20</annotation></semantics></math> PASCAL-VOC classes or all <math id="S4.p1.5.m5.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.p1.5.m5.1a"><mn id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><cn type="integer" id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">80</annotation></semantics></math> COCO classes on detecting objects in ADE20K.
This is to evaluate open-world class-agnostic object detectors when used in the wild.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.5" class="ltx_p"><span id="S4.p2.5.1" class="ltx_text ltx_font_bold">Implementation.</span>
We use the same architecture as OLN in <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> for both Phase I and Phase II training. OLN is built on top of a standard Faster RCNN <cite class="ltx_cite ltx_citemacro_citep">(Ren et al., <a href="#bib.bib33" title="" class="ltx_ref">2015</a>)</cite> architecture with a ResNet-50 backbone pretrained on ImageNet <cite class="ltx_cite ltx_citemacro_citep">(Deng et al., <a href="#bib.bib7" title="" class="ltx_ref">2009</a>)</cite>. We implement our method using MMDetection framework <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite> and use the SGD optimizer with an initial learning rate of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="float" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">0.01</annotation></semantics></math> and batch size of <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p2.2.m2.1a"><mn id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><cn type="integer" id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">16</annotation></semantics></math>. The models with data augmentation are all trained for <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p2.3.m3.1a"><mn id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><cn type="integer" id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">16</annotation></semantics></math> epochs. Other models are trained for <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.p2.4.m4.1a"><mn id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><cn type="integer" id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">8</annotation></semantics></math> epochs.
We did not find training for longer epochs beneficial for models without data augmentation.
The optimal number of pseudo boxes, i.e., <math id="S4.p2.5.m5.3" class="ltx_Math" alttext="k\in\{1,2,3\}" display="inline"><semantics id="S4.p2.5.m5.3a"><mrow id="S4.p2.5.m5.3.4" xref="S4.p2.5.m5.3.4.cmml"><mi id="S4.p2.5.m5.3.4.2" xref="S4.p2.5.m5.3.4.2.cmml">k</mi><mo id="S4.p2.5.m5.3.4.1" xref="S4.p2.5.m5.3.4.1.cmml">∈</mo><mrow id="S4.p2.5.m5.3.4.3.2" xref="S4.p2.5.m5.3.4.3.1.cmml"><mo stretchy="false" id="S4.p2.5.m5.3.4.3.2.1" xref="S4.p2.5.m5.3.4.3.1.cmml">{</mo><mn id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">1</mn><mo id="S4.p2.5.m5.3.4.3.2.2" xref="S4.p2.5.m5.3.4.3.1.cmml">,</mo><mn id="S4.p2.5.m5.2.2" xref="S4.p2.5.m5.2.2.cmml">2</mn><mo id="S4.p2.5.m5.3.4.3.2.3" xref="S4.p2.5.m5.3.4.3.1.cmml">,</mo><mn id="S4.p2.5.m5.3.3" xref="S4.p2.5.m5.3.3.cmml">3</mn><mo stretchy="false" id="S4.p2.5.m5.3.4.3.2.4" xref="S4.p2.5.m5.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.3b"><apply id="S4.p2.5.m5.3.4.cmml" xref="S4.p2.5.m5.3.4"><in id="S4.p2.5.m5.3.4.1.cmml" xref="S4.p2.5.m5.3.4.1"></in><ci id="S4.p2.5.m5.3.4.2.cmml" xref="S4.p2.5.m5.3.4.2">𝑘</ci><set id="S4.p2.5.m5.3.4.3.1.cmml" xref="S4.p2.5.m5.3.4.3.2"><cn type="integer" id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">1</cn><cn type="integer" id="S4.p2.5.m5.2.2.cmml" xref="S4.p2.5.m5.2.2">2</cn><cn type="integer" id="S4.p2.5.m5.3.3.cmml" xref="S4.p2.5.m5.3.3">3</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.3c">k\in\{1,2,3\}</annotation></semantics></math>, varies across input types and is determined on a small holdout validation set.
See Appendix <a href="#A1" title="Appendix A Implementation details ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for further details.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.5" class="ltx_p"><span id="S4.p3.5.1" class="ltx_text ltx_font_bold">Evaluation metrics.</span>
Following <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>, we use Average Recall (AR@k) over multiple IoU thresholds (0.5:0.95), and set the detection budget k as <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S4.p3.1.m1.1a"><mn id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><cn type="integer" id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">100</annotation></semantics></math> by default. All ARs are shown in percentage. AR<sub id="S4.p3.5.2" class="ltx_sub"><span id="S4.p3.5.2.1" class="ltx_text ltx_font_italic">A</span></sub> and AR<sub id="S4.p3.5.3" class="ltx_sub"><span id="S4.p3.5.3.1" class="ltx_text ltx_font_italic">N</span></sub> respectively denote the AR score on detecting all classes (including the base and novel ones) and on detecting the novel classes. To evaluate AR<sub id="S4.p3.5.4" class="ltx_sub"><span id="S4.p3.5.4.1" class="ltx_text ltx_font_italic">N</span></sub>, we do not count the boxes associated to the base classes into the budget k. The same protocol is applied when evaluating per-class ARs and ARs for small, medium and large size of objects, i.e., AR<math id="S4.p3.5.m5.1" class="ltx_Math" alttext="{}_{\cdot}^{s/m/l}" display="inline"><semantics id="S4.p3.5.m5.1a"><mmultiscripts id="S4.p3.5.m5.1.1" xref="S4.p3.5.m5.1.1.cmml"><mi id="S4.p3.5.m5.1.1.2.2" xref="S4.p3.5.m5.1.1.2.2.cmml"></mi><mprescripts id="S4.p3.5.m5.1.1a" xref="S4.p3.5.m5.1.1.cmml"></mprescripts><mrow id="S4.p3.5.m5.1.1b" xref="S4.p3.5.m5.1.1.cmml"></mrow><mrow id="S4.p3.5.m5.1.1.3" xref="S4.p3.5.m5.1.1.3.cmml"><mi id="S4.p3.5.m5.1.1.3.2" xref="S4.p3.5.m5.1.1.3.2.cmml">s</mi><mo id="S4.p3.5.m5.1.1.3.1" xref="S4.p3.5.m5.1.1.3.1.cmml">/</mo><mi id="S4.p3.5.m5.1.1.3.3" xref="S4.p3.5.m5.1.1.3.3.cmml">m</mi><mo id="S4.p3.5.m5.1.1.3.1a" xref="S4.p3.5.m5.1.1.3.1.cmml">/</mo><mi id="S4.p3.5.m5.1.1.3.4" xref="S4.p3.5.m5.1.1.3.4.cmml">l</mi></mrow><mo id="S4.p3.5.m5.1.1.2.3" xref="S4.p3.5.m5.1.1.2.3.cmml">⋅</mo><mrow id="S4.p3.5.m5.1.1c" xref="S4.p3.5.m5.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.p3.5.m5.1b"><apply id="S4.p3.5.m5.1.1.cmml" xref="S4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p3.5.m5.1.1.1.cmml" xref="S4.p3.5.m5.1.1">superscript</csymbol><apply id="S4.p3.5.m5.1.1.2.cmml" xref="S4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p3.5.m5.1.1.2.1.cmml" xref="S4.p3.5.m5.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.p3.5.m5.1.1.2.2.cmml" xref="S4.p3.5.m5.1.1.2.2">absent</csymbol><ci id="S4.p3.5.m5.1.1.2.3.cmml" xref="S4.p3.5.m5.1.1.2.3">⋅</ci></apply><apply id="S4.p3.5.m5.1.1.3.cmml" xref="S4.p3.5.m5.1.1.3"><divide id="S4.p3.5.m5.1.1.3.1.cmml" xref="S4.p3.5.m5.1.1.3.1"></divide><ci id="S4.p3.5.m5.1.1.3.2.cmml" xref="S4.p3.5.m5.1.1.3.2">𝑠</ci><ci id="S4.p3.5.m5.1.1.3.3.cmml" xref="S4.p3.5.m5.1.1.3.3">𝑚</ci><ci id="S4.p3.5.m5.1.1.3.4.cmml" xref="S4.p3.5.m5.1.1.3.4">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.5.m5.1c">{}_{\cdot}^{s/m/l}</annotation></semantics></math>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Detecting unknown objects in an open world</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.1" class="ltx_p">Table <a href="#S4.T1.st1" title="In Table 1 ‣ 4.1 Detecting unknown objects in an open world ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> and <a href="#S4.T1.st2" title="In Table 1 ‣ 4.1 Detecting unknown objects in an open world ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> compare open-world class-agnostic object detectors on two cross-category benchmarks and two cross-dataset benchmarks, respectively. Our method GOOD, which incorporates geometric cues, considerably outperforms state-of-the-art RGB-based open-world class-agnostic object detection methods, i.e., OLN <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> and GGN <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>. OLN did not involve any novel object into training. Although GGN proposed to use an intermediate pairwise affinity (PA) representation for pseudo labeling, the PA predictor is still trained on the RGB images, therefore it still has the bias towards the known classes as other RGB-based methods.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T1.st1" class="ltx_table ltx_figure_panel">
<div id="S4.T1.st1.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:120.9pt;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,3.1pt) scale(0.95,0.95) ;">
<div id="S4.T1.st1.12.12" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:126.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-86.0pt,27.2pt) scale(0.697887023566809,0.697887023566809) ;">
<table id="S4.T1.st1.12.12.12" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.st1.2.2.2.2" class="ltx_tr">
<td id="S4.T1.st1.2.2.2.2.3" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.T1.st1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="5"><span id="S4.T1.st1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Person<math id="S4.T1.st1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.st1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.st1.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.st1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.st1.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-Person</span></td>
<td id="S4.T1.st1.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="5"><span id="S4.T1.st1.2.2.2.2.2.1" class="ltx_text ltx_font_bold">VOC<math id="S4.T1.st1.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st1.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T1.st1.2.2.2.2.2.1.m1.1.1" xref="S4.T1.st1.2.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st1.2.2.2.2.2.1.m1.1b"><ci id="S4.T1.st1.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.st1.2.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>Non-VOC</span></td>
</tr>
<tr id="S4.T1.st1.12.12.12.12" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.12.11" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="S4.T1.st1.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.3.3.3.3.1.1" class="ltx_sub"><span id="S4.T1.st1.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st1.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.4.4.4.4.2.1" class="ltx_sub"><span id="S4.T1.st1.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</td>
<td id="S4.T1.st1.5.5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T1.st1.5.5.5.5.3.m1.1a"><mmultiscripts id="S4.T1.st1.5.5.5.5.3.m1.1.1" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"><mi id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.5.5.5.5.3.m1.1.1a" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.5.5.5.5.3.m1.1.1b" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.5.5.5.5.3.m1.1.1.3" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.5.5.5.5.3.m1.1.1c" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.5.5.5.5.3.m1.1b"><apply id="S4.T1.st1.5.5.5.5.3.m1.1.1.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.5.5.5.5.3.m1.1.1.1.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.1.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T1.st1.5.5.5.5.3.m1.1.1.3.cmml" xref="S4.T1.st1.5.5.5.5.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T1.st1.6.6.6.6.4.m1.1a"><mmultiscripts id="S4.T1.st1.6.6.6.6.4.m1.1.1" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"><mi id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.6.6.6.6.4.m1.1.1a" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.6.6.6.6.4.m1.1.1b" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.6.6.6.6.4.m1.1.1.3" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.6.6.6.6.4.m1.1.1c" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.6.6.6.6.4.m1.1b"><apply id="S4.T1.st1.6.6.6.6.4.m1.1.1.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.6.6.6.6.4.m1.1.1.1.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.1.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T1.st1.6.6.6.6.4.m1.1.1.3.cmml" xref="S4.T1.st1.6.6.6.6.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.7.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T1.st1.7.7.7.7.5.m1.1a"><mmultiscripts id="S4.T1.st1.7.7.7.7.5.m1.1.1" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"><mi id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.7.7.7.7.5.m1.1.1a" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.7.7.7.7.5.m1.1.1b" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.7.7.7.7.5.m1.1.1.3" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.7.7.7.7.5.m1.1.1c" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.7.7.7.7.5.m1.1b"><apply id="S4.T1.st1.7.7.7.7.5.m1.1.1.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.7.7.7.7.5.m1.1.1.1.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.1.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T1.st1.7.7.7.7.5.m1.1.1.3.cmml" xref="S4.T1.st1.7.7.7.7.5.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.8.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.8.8.8.8.6.1" class="ltx_sub"><span id="S4.T1.st1.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st1.9.9.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st1.9.9.9.9.7.1" class="ltx_sub"><span id="S4.T1.st1.9.9.9.9.7.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</td>
<td id="S4.T1.st1.10.10.10.10.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T1.st1.10.10.10.10.8.m1.1a"><mmultiscripts id="S4.T1.st1.10.10.10.10.8.m1.1.1" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"><mi id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.10.10.10.10.8.m1.1.1a" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.10.10.10.10.8.m1.1.1b" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.10.10.10.10.8.m1.1.1.3" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.10.10.10.10.8.m1.1.1c" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.10.10.10.10.8.m1.1b"><apply id="S4.T1.st1.10.10.10.10.8.m1.1.1.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.10.10.10.10.8.m1.1.1.1.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.1.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T1.st1.10.10.10.10.8.m1.1.1.3.cmml" xref="S4.T1.st1.10.10.10.10.8.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.10.10.10.10.8.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.11.11.11.11.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st1.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T1.st1.11.11.11.11.9.m1.1a"><mmultiscripts id="S4.T1.st1.11.11.11.11.9.m1.1.1" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"><mi id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.11.11.11.11.9.m1.1.1a" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.11.11.11.11.9.m1.1.1b" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.11.11.11.11.9.m1.1.1.3" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.11.11.11.11.9.m1.1.1c" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.11.11.11.11.9.m1.1b"><apply id="S4.T1.st1.11.11.11.11.9.m1.1.1.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.11.11.11.11.9.m1.1.1.1.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.1.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T1.st1.11.11.11.11.9.m1.1.1.3.cmml" xref="S4.T1.st1.11.11.11.11.9.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.11.11.11.11.9.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st1.12.12.12.12.10" class="ltx_td ltx_align_left ltx_border_t">AR<math id="S4.T1.st1.12.12.12.12.10.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T1.st1.12.12.12.12.10.m1.1a"><mmultiscripts id="S4.T1.st1.12.12.12.12.10.m1.1.1" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"><mi id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st1.12.12.12.12.10.m1.1.1a" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st1.12.12.12.12.10.m1.1.1b" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"></mrow><mi id="S4.T1.st1.12.12.12.12.10.m1.1.1.3" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T1.st1.12.12.12.12.10.m1.1.1c" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st1.12.12.12.12.10.m1.1b"><apply id="S4.T1.st1.12.12.12.12.10.m1.1.1.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.12.12.12.12.10.m1.1.1.1.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1">superscript</csymbol><apply id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.1.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T1.st1.12.12.12.12.10.m1.1.1.3.cmml" xref="S4.T1.st1.12.12.12.12.10.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st1.12.12.12.12.10.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.st1.12.12.12.13.1" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.13.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.1.1" class="ltx_text" style="color:#808080;">FRCNN (oracle)</span></td>
<td id="S4.T1.st1.12.12.12.13.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.2.1" class="ltx_text" style="color:#808080;">55.9</span></td>
<td id="S4.T1.st1.12.12.12.13.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.3.1" class="ltx_text" style="color:#808080;">53.4</span></td>
<td id="S4.T1.st1.12.12.12.13.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.4.1" class="ltx_text" style="color:#808080;">37.9</span></td>
<td id="S4.T1.st1.12.12.12.13.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.5.1" class="ltx_text" style="color:#808080;">59.5</span></td>
<td id="S4.T1.st1.12.12.12.13.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.6.1" class="ltx_text" style="color:#808080;">73.0</span></td>
<td id="S4.T1.st1.12.12.12.13.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.7.1" class="ltx_text" style="color:#808080;">55.9</span></td>
<td id="S4.T1.st1.12.12.12.13.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.8.1" class="ltx_text" style="color:#808080;">52.6</span></td>
<td id="S4.T1.st1.12.12.12.13.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.9.1" class="ltx_text" style="color:#808080;">37.1</span></td>
<td id="S4.T1.st1.12.12.12.13.1.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.10.1" class="ltx_text" style="color:#808080;">60.0</span></td>
<td id="S4.T1.st1.12.12.12.13.1.11" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.st1.12.12.12.13.1.11.1" class="ltx_text" style="color:#808080;">73.1</span></td>
</tr>
<tr id="S4.T1.st1.12.12.12.14.2" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.14.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FRCNN (cls-agn)</td>
<td id="S4.T1.st1.12.12.12.14.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.7</td>
<td id="S4.T1.st1.12.12.12.14.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.2</td>
<td id="S4.T1.st1.12.12.12.14.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8.7</td>
<td id="S4.T1.st1.12.12.12.14.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.4</td>
<td id="S4.T1.st1.12.12.12.14.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.2</td>
<td id="S4.T1.st1.12.12.12.14.2.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.5</td>
<td id="S4.T1.st1.12.12.12.14.2.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">27.3</td>
<td id="S4.T1.st1.12.12.12.14.2.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">10.8</td>
<td id="S4.T1.st1.12.12.12.14.2.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">30.2</td>
<td id="S4.T1.st1.12.12.12.14.2.11" class="ltx_td ltx_align_left ltx_border_t">55.8</td>
</tr>
<tr id="S4.T1.st1.12.12.12.15.3" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.15.3.1" class="ltx_td ltx_align_left ltx_border_r">OLN <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.st1.12.12.12.15.3.2" class="ltx_td ltx_align_left ltx_border_r">30.9</td>
<td id="S4.T1.st1.12.12.12.15.3.3" class="ltx_td ltx_align_left ltx_border_r">16.5</td>
<td id="S4.T1.st1.12.12.12.15.3.4" class="ltx_td ltx_align_left ltx_border_r">8.7</td>
<td id="S4.T1.st1.12.12.12.15.3.5" class="ltx_td ltx_align_left ltx_border_r">14.7</td>
<td id="S4.T1.st1.12.12.12.15.3.6" class="ltx_td ltx_align_left ltx_border_r">33.4</td>
<td id="S4.T1.st1.12.12.12.15.3.7" class="ltx_td ltx_align_left ltx_border_r">47.5</td>
<td id="S4.T1.st1.12.12.12.15.3.8" class="ltx_td ltx_align_left ltx_border_r">33.2</td>
<td id="S4.T1.st1.12.12.12.15.3.9" class="ltx_td ltx_align_left ltx_border_r">18.7</td>
<td id="S4.T1.st1.12.12.12.15.3.10" class="ltx_td ltx_align_left ltx_border_r">39.3</td>
<td id="S4.T1.st1.12.12.12.15.3.11" class="ltx_td ltx_align_left">58.6</td>
</tr>
<tr id="S4.T1.st1.12.12.12.16.4" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.16.4.1" class="ltx_td ltx_align_left ltx_border_r">GGN <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.st1.12.12.12.16.4.2" class="ltx_td ltx_align_left ltx_border_r">30.3</td>
<td id="S4.T1.st1.12.12.12.16.4.3" class="ltx_td ltx_align_left ltx_border_r">20.7</td>
<td id="S4.T1.st1.12.12.12.16.4.4" class="ltx_td ltx_align_left ltx_border_r">12.0</td>
<td id="S4.T1.st1.12.12.12.16.4.5" class="ltx_td ltx_align_left ltx_border_r">25.6</td>
<td id="S4.T1.st1.12.12.12.16.4.6" class="ltx_td ltx_align_left ltx_border_r">29.6</td>
<td id="S4.T1.st1.12.12.12.16.4.7" class="ltx_td ltx_align_left ltx_border_r">39.8</td>
<td id="S4.T1.st1.12.12.12.16.4.8" class="ltx_td ltx_align_left ltx_border_r">31.5</td>
<td id="S4.T1.st1.12.12.12.16.4.9" class="ltx_td ltx_align_left ltx_border_r">11.8</td>
<td id="S4.T1.st1.12.12.12.16.4.10" class="ltx_td ltx_align_left ltx_border_r">37.4</td>
<td id="S4.T1.st1.12.12.12.16.4.11" class="ltx_td ltx_align_left"><span id="S4.T1.st1.12.12.12.16.4.11.1" class="ltx_text ltx_font_bold">63.8</span></td>
</tr>
<tr id="S4.T1.st1.12.12.12.17.5" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.17.5.1" class="ltx_td ltx_align_left ltx_border_r">SelfTrain-RGB</td>
<td id="S4.T1.st1.12.12.12.17.5.2" class="ltx_td ltx_align_left ltx_border_r">32.5</td>
<td id="S4.T1.st1.12.12.12.17.5.3" class="ltx_td ltx_align_left ltx_border_r">18.7</td>
<td id="S4.T1.st1.12.12.12.17.5.4" class="ltx_td ltx_align_left ltx_border_r">11.3</td>
<td id="S4.T1.st1.12.12.12.17.5.5" class="ltx_td ltx_align_left ltx_border_r">18.6</td>
<td id="S4.T1.st1.12.12.12.17.5.6" class="ltx_td ltx_align_left ltx_border_r">32.6</td>
<td id="S4.T1.st1.12.12.12.17.5.7" class="ltx_td ltx_align_left ltx_border_r">48.1</td>
<td id="S4.T1.st1.12.12.12.17.5.8" class="ltx_td ltx_align_left ltx_border_r">37.4</td>
<td id="S4.T1.st1.12.12.12.17.5.9" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.st1.12.12.12.17.5.9.1" class="ltx_text ltx_font_bold">22.8</span></td>
<td id="S4.T1.st1.12.12.12.17.5.10" class="ltx_td ltx_align_left ltx_border_r">43.9</td>
<td id="S4.T1.st1.12.12.12.17.5.11" class="ltx_td ltx_align_left">57.7</td>
</tr>
<tr id="S4.T1.st1.12.12.12.18.6" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.18.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Depth</td>
<td id="S4.T1.st1.12.12.12.18.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.0</td>
<td id="S4.T1.st1.12.12.12.18.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.6</td>
<td id="S4.T1.st1.12.12.12.18.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.8</td>
<td id="S4.T1.st1.12.12.12.18.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">30.4</td>
<td id="S4.T1.st1.12.12.12.18.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.18.6.6.1" class="ltx_text ltx_font_bold">42.4</span></td>
<td id="S4.T1.st1.12.12.12.18.6.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st1.12.12.12.18.6.7.1" class="ltx_text ltx_font_bold">49.6</span></td>
<td id="S4.T1.st1.12.12.12.18.6.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">39.0</td>
<td id="S4.T1.st1.12.12.12.18.6.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.1</td>
<td id="S4.T1.st1.12.12.12.18.6.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.5</td>
<td id="S4.T1.st1.12.12.12.18.6.11" class="ltx_td ltx_align_left ltx_border_t">63.2</td>
</tr>
<tr id="S4.T1.st1.12.12.12.19.7" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.19.7.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Normal</td>
<td id="S4.T1.st1.12.12.12.19.7.2" class="ltx_td ltx_align_left ltx_border_r">35.6</td>
<td id="S4.T1.st1.12.12.12.19.7.3" class="ltx_td ltx_align_left ltx_border_r">23.7</td>
<td id="S4.T1.st1.12.12.12.19.7.4" class="ltx_td ltx_align_left ltx_border_r">13.9</td>
<td id="S4.T1.st1.12.12.12.19.7.5" class="ltx_td ltx_align_left ltx_border_r">27.6</td>
<td id="S4.T1.st1.12.12.12.19.7.6" class="ltx_td ltx_align_left ltx_border_r">36.0</td>
<td id="S4.T1.st1.12.12.12.19.7.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.st1.12.12.12.19.7.7.1" class="ltx_text ltx_font_bold">49.6</span></td>
<td id="S4.T1.st1.12.12.12.19.7.8" class="ltx_td ltx_align_left ltx_border_r">38.9</td>
<td id="S4.T1.st1.12.12.12.19.7.9" class="ltx_td ltx_align_left ltx_border_r">21.2</td>
<td id="S4.T1.st1.12.12.12.19.7.10" class="ltx_td ltx_align_left ltx_border_r">47.9</td>
<td id="S4.T1.st1.12.12.12.19.7.11" class="ltx_td ltx_align_left">62.0</td>
</tr>
<tr id="S4.T1.st1.12.12.12.20.8" class="ltx_tr">
<td id="S4.T1.st1.12.12.12.20.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="S4.T1.st1.12.12.12.20.8.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.2.1" class="ltx_text ltx_font_bold">37.3</span></td>
<td id="S4.T1.st1.12.12.12.20.8.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.3.1" class="ltx_text ltx_font_bold">25.9</span></td>
<td id="S4.T1.st1.12.12.12.20.8.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.4.1" class="ltx_text ltx_font_bold">14.2</span></td>
<td id="S4.T1.st1.12.12.12.20.8.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.5.1" class="ltx_text ltx_font_bold">32.6</span></td>
<td id="S4.T1.st1.12.12.12.20.8.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">38.9</td>
<td id="S4.T1.st1.12.12.12.20.8.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">49.5</td>
<td id="S4.T1.st1.12.12.12.20.8.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.8.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="S4.T1.st1.12.12.12.20.8.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.6</td>
<td id="S4.T1.st1.12.12.12.20.8.10" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st1.12.12.12.20.8.10.1" class="ltx_text ltx_font_bold">48.2</span></td>
<td id="S4.T1.st1.12.12.12.20.8.11" class="ltx_td ltx_align_left ltx_border_bb">62.4</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(a) </span><span id="S4.T1.st1.14.1" class="ltx_text ltx_font_bold">Cross-category benchmarks</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T1.st2" class="ltx_table ltx_figure_panel">
<div id="S4.T1.st2.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:320.7pt;height:104.4pt;vertical-align:-1.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.1pt,12.9pt) scale(0.8,0.8) ;">
<div id="S4.T1.st2.10.10" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:129.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-51.3pt,16.6pt) scale(0.794727172432763,0.794727172432763) ;">
<table id="S4.T1.st2.10.10.10" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.st2.2.2.2.2" class="ltx_tr">
<td id="S4.T1.st2.2.2.2.2.3" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S4.T1.st2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span id="S4.T1.st2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">VOC<math id="S4.T1.st2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st2.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.st2.1.1.1.1.1.1.m1.1.1" xref="S4.T1.st2.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st2.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.st2.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.st2.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></td>
<td id="S4.T1.st2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S4.T1.st2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">COCO<math id="S4.T1.st2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.st2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T1.st2.2.2.2.2.2.1.m1.1.1" xref="S4.T1.st2.2.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.st2.2.2.2.2.2.1.m1.1b"><ci id="S4.T1.st2.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.st2.2.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></td>
</tr>
<tr id="S4.T1.st2.10.10.10.10" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.10.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="S4.T1.st2.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st2.3.3.3.3.1.1" class="ltx_sub"><span id="S4.T1.st2.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st2.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.4.4.4.4.2.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="S4.T1.st2.4.4.4.4.2.m1.1a"><mmultiscripts id="S4.T1.st2.4.4.4.4.2.m1.1.1" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"><mi id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.4.4.4.4.2.m1.1.1a" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.4.4.4.4.2.m1.1.1b" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.4.4.4.4.2.m1.1.1.3" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.4.4.4.4.2.m1.1.1c" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.4.4.4.4.2.m1.1b"><apply id="S4.T1.st2.4.4.4.4.2.m1.1.1.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.4.4.4.4.2.m1.1.1.1.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.1.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.2.3">𝐴</ci></apply><ci id="S4.T1.st2.4.4.4.4.2.m1.1.1.3.cmml" xref="S4.T1.st2.4.4.4.4.2.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.4.4.4.4.2.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.5.5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="S4.T1.st2.5.5.5.5.3.m1.1a"><mmultiscripts id="S4.T1.st2.5.5.5.5.3.m1.1.1" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"><mi id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.5.5.5.5.3.m1.1.1a" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.5.5.5.5.3.m1.1.1b" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.5.5.5.5.3.m1.1.1.3" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.5.5.5.5.3.m1.1.1c" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.5.5.5.5.3.m1.1b"><apply id="S4.T1.st2.5.5.5.5.3.m1.1.1.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.5.5.5.5.3.m1.1.1.1.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.1.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.2.3">𝐴</ci></apply><ci id="S4.T1.st2.5.5.5.5.3.m1.1.1.3.cmml" xref="S4.T1.st2.5.5.5.5.3.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.5.5.5.5.3.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="S4.T1.st2.6.6.6.6.4.m1.1a"><mmultiscripts id="S4.T1.st2.6.6.6.6.4.m1.1.1" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"><mi id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.6.6.6.6.4.m1.1.1a" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.6.6.6.6.4.m1.1.1b" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.6.6.6.6.4.m1.1.1.3" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.6.6.6.6.4.m1.1.1c" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.6.6.6.6.4.m1.1b"><apply id="S4.T1.st2.6.6.6.6.4.m1.1.1.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.6.6.6.6.4.m1.1.1.1.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.1.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.2.3">𝐴</ci></apply><ci id="S4.T1.st2.6.6.6.6.4.m1.1.1.3.cmml" xref="S4.T1.st2.6.6.6.6.4.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.6.6.6.6.4.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.7.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="S4.T1.st2.7.7.7.7.5.1" class="ltx_sub"><span id="S4.T1.st2.7.7.7.7.5.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="S4.T1.st2.8.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.8.8.8.8.6.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="S4.T1.st2.8.8.8.8.6.m1.1a"><mmultiscripts id="S4.T1.st2.8.8.8.8.6.m1.1.1" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"><mi id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.8.8.8.8.6.m1.1.1a" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.8.8.8.8.6.m1.1.1b" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.8.8.8.8.6.m1.1.1.3" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.3.cmml">s</mi><mi id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.8.8.8.8.6.m1.1.1c" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.8.8.8.8.6.m1.1b"><apply id="S4.T1.st2.8.8.8.8.6.m1.1.1.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.8.8.8.8.6.m1.1.1.1.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.1.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.2.3">𝐴</ci></apply><ci id="S4.T1.st2.8.8.8.8.6.m1.1.1.3.cmml" xref="S4.T1.st2.8.8.8.8.6.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.8.8.8.8.6.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.9.9.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="S4.T1.st2.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="S4.T1.st2.9.9.9.9.7.m1.1a"><mmultiscripts id="S4.T1.st2.9.9.9.9.7.m1.1.1" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"><mi id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.9.9.9.9.7.m1.1.1a" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.9.9.9.9.7.m1.1.1b" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.9.9.9.9.7.m1.1.1.3" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.3.cmml">m</mi><mi id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.9.9.9.9.7.m1.1.1c" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.9.9.9.9.7.m1.1b"><apply id="S4.T1.st2.9.9.9.9.7.m1.1.1.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.9.9.9.9.7.m1.1.1.1.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.1.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.2.3">𝐴</ci></apply><ci id="S4.T1.st2.9.9.9.9.7.m1.1.1.3.cmml" xref="S4.T1.st2.9.9.9.9.7.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.9.9.9.9.7.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</td>
<td id="S4.T1.st2.10.10.10.10.8" class="ltx_td ltx_align_left ltx_border_t">AR<math id="S4.T1.st2.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="S4.T1.st2.10.10.10.10.8.m1.1a"><mmultiscripts id="S4.T1.st2.10.10.10.10.8.m1.1.1" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"><mi id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T1.st2.10.10.10.10.8.m1.1.1a" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="S4.T1.st2.10.10.10.10.8.m1.1.1b" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="S4.T1.st2.10.10.10.10.8.m1.1.1.3" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.3.cmml">l</mi><mi id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="S4.T1.st2.10.10.10.10.8.m1.1.1c" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T1.st2.10.10.10.10.8.m1.1b"><apply id="S4.T1.st2.10.10.10.10.8.m1.1.1.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.10.10.10.10.8.m1.1.1.1.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.1.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.2.3">𝐴</ci></apply><ci id="S4.T1.st2.10.10.10.10.8.m1.1.1.3.cmml" xref="S4.T1.st2.10.10.10.10.8.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.st2.10.10.10.10.8.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.st2.10.10.10.11.1" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.11.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FRCNN (cls-agn)</td>
<td id="S4.T1.st2.10.10.10.11.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">22.6</td>
<td id="S4.T1.st2.10.10.10.11.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.5</td>
<td id="S4.T1.st2.10.10.10.11.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">23.7</td>
<td id="S4.T1.st2.10.10.10.11.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.5</td>
<td id="S4.T1.st2.10.10.10.11.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.9</td>
<td id="S4.T1.st2.10.10.10.11.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20.5</td>
<td id="S4.T1.st2.10.10.10.11.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.5</td>
<td id="S4.T1.st2.10.10.10.11.1.9" class="ltx_td ltx_align_left ltx_border_t">27.4</td>
</tr>
<tr id="S4.T1.st2.10.10.10.12.2" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.12.2.1" class="ltx_td ltx_align_left ltx_border_r">OLN <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.st2.10.10.10.12.2.2" class="ltx_td ltx_align_left ltx_border_r">29.2</td>
<td id="S4.T1.st2.10.10.10.12.2.3" class="ltx_td ltx_align_left ltx_border_r">19.7</td>
<td id="S4.T1.st2.10.10.10.12.2.4" class="ltx_td ltx_align_left ltx_border_r">30.7</td>
<td id="S4.T1.st2.10.10.10.12.2.5" class="ltx_td ltx_align_left ltx_border_r">34.4</td>
<td id="S4.T1.st2.10.10.10.12.2.6" class="ltx_td ltx_align_left ltx_border_r">32.9</td>
<td id="S4.T1.st2.10.10.10.12.2.7" class="ltx_td ltx_align_left ltx_border_r">25.1</td>
<td id="S4.T1.st2.10.10.10.12.2.8" class="ltx_td ltx_align_left ltx_border_r">35.9</td>
<td id="S4.T1.st2.10.10.10.12.2.9" class="ltx_td ltx_align_left">35.6</td>
</tr>
<tr id="S4.T1.st2.10.10.10.13.3" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.13.3.1" class="ltx_td ltx_align_left ltx_border_r">GGN <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="S4.T1.st2.10.10.10.13.3.2" class="ltx_td ltx_align_left ltx_border_r">27.0</td>
<td id="S4.T1.st2.10.10.10.13.3.3" class="ltx_td ltx_align_left ltx_border_r">16.9</td>
<td id="S4.T1.st2.10.10.10.13.3.4" class="ltx_td ltx_align_left ltx_border_r">27.5</td>
<td id="S4.T1.st2.10.10.10.13.3.5" class="ltx_td ltx_align_left ltx_border_r">33.6</td>
<td id="S4.T1.st2.10.10.10.13.3.6" class="ltx_td ltx_align_left ltx_border_r">29.8</td>
<td id="S4.T1.st2.10.10.10.13.3.7" class="ltx_td ltx_align_left ltx_border_r">18.9</td>
<td id="S4.T1.st2.10.10.10.13.3.8" class="ltx_td ltx_align_left ltx_border_r">29.1</td>
<td id="S4.T1.st2.10.10.10.13.3.9" class="ltx_td ltx_align_left">38.2</td>
</tr>
<tr id="S4.T1.st2.10.10.10.14.4" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.14.4.1" class="ltx_td ltx_align_left ltx_border_r">SelfTrain-RGB</td>
<td id="S4.T1.st2.10.10.10.14.4.2" class="ltx_td ltx_align_left ltx_border_r">27.7</td>
<td id="S4.T1.st2.10.10.10.14.4.3" class="ltx_td ltx_align_left ltx_border_r">18.4</td>
<td id="S4.T1.st2.10.10.10.14.4.4" class="ltx_td ltx_align_left ltx_border_r">29.7</td>
<td id="S4.T1.st2.10.10.10.14.4.5" class="ltx_td ltx_align_left ltx_border_r">32.4</td>
<td id="S4.T1.st2.10.10.10.14.4.6" class="ltx_td ltx_align_left ltx_border_r">33.8</td>
<td id="S4.T1.st2.10.10.10.14.4.7" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T1.st2.10.10.10.14.4.7.1" class="ltx_text ltx_font_bold">26.5</span></td>
<td id="S4.T1.st2.10.10.10.14.4.8" class="ltx_td ltx_align_left ltx_border_r">37.6</td>
<td id="S4.T1.st2.10.10.10.14.4.9" class="ltx_td ltx_align_left">35.4</td>
</tr>
<tr id="S4.T1.st2.10.10.10.15.5" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.15.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Depth</td>
<td id="S4.T1.st2.10.10.10.15.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">33.9</td>
<td id="S4.T1.st2.10.10.10.15.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.1</td>
<td id="S4.T1.st2.10.10.10.15.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.9</td>
<td id="S4.T1.st2.10.10.10.15.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">41.2</td>
<td id="S4.T1.st2.10.10.10.15.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.st2.10.10.10.15.5.6.1" class="ltx_text ltx_font_bold">35.3</span></td>
<td id="S4.T1.st2.10.10.10.15.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.7</td>
<td id="S4.T1.st2.10.10.10.15.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.0</td>
<td id="S4.T1.st2.10.10.10.15.5.9" class="ltx_td ltx_align_left ltx_border_t">39.6</td>
</tr>
<tr id="S4.T1.st2.10.10.10.16.6" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.16.6.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Normal</td>
<td id="S4.T1.st2.10.10.10.16.6.2" class="ltx_td ltx_align_left ltx_border_r">33.4</td>
<td id="S4.T1.st2.10.10.10.16.6.3" class="ltx_td ltx_align_left ltx_border_r">22.0</td>
<td id="S4.T1.st2.10.10.10.16.6.4" class="ltx_td ltx_align_left ltx_border_r">36.2</td>
<td id="S4.T1.st2.10.10.10.16.6.5" class="ltx_td ltx_align_left ltx_border_r">38.8</td>
<td id="S4.T1.st2.10.10.10.16.6.6" class="ltx_td ltx_align_left ltx_border_r">33.5</td>
<td id="S4.T1.st2.10.10.10.16.6.7" class="ltx_td ltx_align_left ltx_border_r">25.7</td>
<td id="S4.T1.st2.10.10.10.16.6.8" class="ltx_td ltx_align_left ltx_border_r">37.1</td>
<td id="S4.T1.st2.10.10.10.16.6.9" class="ltx_td ltx_align_left">35.5</td>
</tr>
<tr id="S4.T1.st2.10.10.10.17.7" class="ltx_tr">
<td id="S4.T1.st2.10.10.10.17.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="S4.T1.st2.10.10.10.17.7.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.2.1" class="ltx_text ltx_font_bold">34.0</span></td>
<td id="S4.T1.st2.10.10.10.17.7.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.9</td>
<td id="S4.T1.st2.10.10.10.17.7.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.4.1" class="ltx_text ltx_font_bold">37.0</span></td>
<td id="S4.T1.st2.10.10.10.17.7.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.5.1" class="ltx_text ltx_font_bold">39.9</span></td>
<td id="S4.T1.st2.10.10.10.17.7.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T1.st2.10.10.10.17.7.6.1" class="ltx_text ltx_font_bold">35.3</span></td>
<td id="S4.T1.st2.10.10.10.17.7.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">25.1</td>
<td id="S4.T1.st2.10.10.10.17.7.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">38.2</td>
<td id="S4.T1.st2.10.10.10.17.7.9" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T1.st2.10.10.10.17.7.9.1" class="ltx_text ltx_font_bold">39.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">(b) </span><span id="S4.T1.st2.12.1" class="ltx_text ltx_font_bold">Cross-dataset benchmarks</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S4.T1.15.1" class="ltx_text ltx_font_bold">Detecting unknown objects in an open world.</span> <math id="S4.T1.7.m1.1" class="ltx_Math" alttext="\mathrm{FRCNN\text{ }(oracle)}" display="inline"><semantics id="S4.T1.7.m1.1b"><mrow id="S4.T1.7.m1.1.2" xref="S4.T1.7.m1.1.2.cmml"><mi id="S4.T1.7.m1.1.2.2" xref="S4.T1.7.m1.1.2.2.cmml">FRCNN</mi><mo lspace="0em" rspace="0em" id="S4.T1.7.m1.1.2.1" xref="S4.T1.7.m1.1.2.1.cmml">​</mo><mtext id="S4.T1.7.m1.1.2.3" xref="S4.T1.7.m1.1.2.3a.cmml"> </mtext><mo lspace="0em" rspace="0em" id="S4.T1.7.m1.1.2.1b" xref="S4.T1.7.m1.1.2.1.cmml">​</mo><mrow id="S4.T1.7.m1.1.2.4.2" xref="S4.T1.7.m1.1.2.cmml"><mo stretchy="false" id="S4.T1.7.m1.1.2.4.2.1" xref="S4.T1.7.m1.1.2.cmml">(</mo><mi id="S4.T1.7.m1.1.1" xref="S4.T1.7.m1.1.1.cmml">oracle</mi><mo stretchy="false" id="S4.T1.7.m1.1.2.4.2.2" xref="S4.T1.7.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.m1.1c"><apply id="S4.T1.7.m1.1.2.cmml" xref="S4.T1.7.m1.1.2"><times id="S4.T1.7.m1.1.2.1.cmml" xref="S4.T1.7.m1.1.2.1"></times><ci id="S4.T1.7.m1.1.2.2.cmml" xref="S4.T1.7.m1.1.2.2">FRCNN</ci><ci id="S4.T1.7.m1.1.2.3a.cmml" xref="S4.T1.7.m1.1.2.3"><mtext id="S4.T1.7.m1.1.2.3.cmml" xref="S4.T1.7.m1.1.2.3"> </mtext></ci><ci id="S4.T1.7.m1.1.1.cmml" xref="S4.T1.7.m1.1.1">oracle</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.m1.1d">\mathrm{FRCNN\text{ }(oracle)}</annotation></semantics></math> is a standard Faster R-CNN detector trained on all COCO classes and serves as a performance upper bound on the cross-category benchmarks.
<math id="S4.T1.8.m2.1" class="ltx_Math" alttext="\mathrm{FRCNN\text{ }(cls\text{-}agn)}" display="inline"><semantics id="S4.T1.8.m2.1b"><mrow id="S4.T1.8.m2.1.1" xref="S4.T1.8.m2.1.1.cmml"><mi id="S4.T1.8.m2.1.1.3" xref="S4.T1.8.m2.1.1.3.cmml">FRCNN</mi><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.2" xref="S4.T1.8.m2.1.1.2.cmml">​</mo><mtext id="S4.T1.8.m2.1.1.4" xref="S4.T1.8.m2.1.1.4a.cmml"> </mtext><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.2b" xref="S4.T1.8.m2.1.1.2.cmml">​</mo><mrow id="S4.T1.8.m2.1.1.1.1" xref="S4.T1.8.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.T1.8.m2.1.1.1.1.2" xref="S4.T1.8.m2.1.1.1.1.1.cmml">(</mo><mrow id="S4.T1.8.m2.1.1.1.1.1" xref="S4.T1.8.m2.1.1.1.1.1.cmml"><mi id="S4.T1.8.m2.1.1.1.1.1.2" xref="S4.T1.8.m2.1.1.1.1.1.2.cmml">cls</mi><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.1.1.1.1" xref="S4.T1.8.m2.1.1.1.1.1.1.cmml">​</mo><mtext id="S4.T1.8.m2.1.1.1.1.1.3" xref="S4.T1.8.m2.1.1.1.1.1.3a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S4.T1.8.m2.1.1.1.1.1.1b" xref="S4.T1.8.m2.1.1.1.1.1.1.cmml">​</mo><mi id="S4.T1.8.m2.1.1.1.1.1.4" xref="S4.T1.8.m2.1.1.1.1.1.4.cmml">agn</mi></mrow><mo stretchy="false" id="S4.T1.8.m2.1.1.1.1.3" xref="S4.T1.8.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.m2.1c"><apply id="S4.T1.8.m2.1.1.cmml" xref="S4.T1.8.m2.1.1"><times id="S4.T1.8.m2.1.1.2.cmml" xref="S4.T1.8.m2.1.1.2"></times><ci id="S4.T1.8.m2.1.1.3.cmml" xref="S4.T1.8.m2.1.1.3">FRCNN</ci><ci id="S4.T1.8.m2.1.1.4a.cmml" xref="S4.T1.8.m2.1.1.4"><mtext id="S4.T1.8.m2.1.1.4.cmml" xref="S4.T1.8.m2.1.1.4"> </mtext></ci><apply id="S4.T1.8.m2.1.1.1.1.1.cmml" xref="S4.T1.8.m2.1.1.1.1"><times id="S4.T1.8.m2.1.1.1.1.1.1.cmml" xref="S4.T1.8.m2.1.1.1.1.1.1"></times><ci id="S4.T1.8.m2.1.1.1.1.1.2.cmml" xref="S4.T1.8.m2.1.1.1.1.1.2">cls</ci><ci id="S4.T1.8.m2.1.1.1.1.1.3a.cmml" xref="S4.T1.8.m2.1.1.1.1.1.3"><mtext id="S4.T1.8.m2.1.1.1.1.1.3.cmml" xref="S4.T1.8.m2.1.1.1.1.1.3">-</mtext></ci><ci id="S4.T1.8.m2.1.1.1.1.1.4.cmml" xref="S4.T1.8.m2.1.1.1.1.1.4">agn</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.m2.1d">\mathrm{FRCNN\text{ }(cls\text{-}agn)}</annotation></semantics></math> is a Faster R-CNN trained in a class-agnostic manner, serving as a baseline for comparison.
Our geometry-guided methods <math id="S4.T1.9.m3.1" class="ltx_Math" alttext="\mathrm{GOOD}" display="inline"><semantics id="S4.T1.9.m3.1b"><mi id="S4.T1.9.m3.1.1" xref="S4.T1.9.m3.1.1.cmml">GOOD</mi><annotation-xml encoding="MathML-Content" id="S4.T1.9.m3.1c"><ci id="S4.T1.9.m3.1.1.cmml" xref="S4.T1.9.m3.1.1">GOOD</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.m3.1d">\mathrm{GOOD}</annotation></semantics></math>-<math id="S4.T1.10.m4.1" class="ltx_Math" alttext="\mathrm{X}" display="inline"><semantics id="S4.T1.10.m4.1b"><mi mathvariant="normal" id="S4.T1.10.m4.1.1" xref="S4.T1.10.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.T1.10.m4.1c"><ci id="S4.T1.10.m4.1.1.cmml" xref="S4.T1.10.m4.1.1">X</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.m4.1d">\mathrm{X}</annotation></semantics></math>s are compared with SOTA open-world class-agnostic object detectors, i.e., OLN and GGN. <math id="S4.T1.11.m5.1" class="ltx_Math" alttext="\mathrm{SelfTrain\text{-}RGB}" display="inline"><semantics id="S4.T1.11.m5.1b"><mrow id="S4.T1.11.m5.1.1" xref="S4.T1.11.m5.1.1.cmml"><mi id="S4.T1.11.m5.1.1.2" xref="S4.T1.11.m5.1.1.2.cmml">SelfTrain</mi><mo lspace="0em" rspace="0em" id="S4.T1.11.m5.1.1.1" xref="S4.T1.11.m5.1.1.1.cmml">​</mo><mtext id="S4.T1.11.m5.1.1.3" xref="S4.T1.11.m5.1.1.3a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S4.T1.11.m5.1.1.1b" xref="S4.T1.11.m5.1.1.1.cmml">​</mo><mi id="S4.T1.11.m5.1.1.4" xref="S4.T1.11.m5.1.1.4.cmml">RGB</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.11.m5.1c"><apply id="S4.T1.11.m5.1.1.cmml" xref="S4.T1.11.m5.1.1"><times id="S4.T1.11.m5.1.1.1.cmml" xref="S4.T1.11.m5.1.1.1"></times><ci id="S4.T1.11.m5.1.1.2.cmml" xref="S4.T1.11.m5.1.1.2">SelfTrain</ci><ci id="S4.T1.11.m5.1.1.3a.cmml" xref="S4.T1.11.m5.1.1.3"><mtext id="S4.T1.11.m5.1.1.3.cmml" xref="S4.T1.11.m5.1.1.3">-</mtext></ci><ci id="S4.T1.11.m5.1.1.4.cmml" xref="S4.T1.11.m5.1.1.4">RGB</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.m5.1d">\mathrm{SelfTrain\text{-}RGB}</annotation></semantics></math> is RGB-based self-training, i.e., using the RGB image instead of geometric cues for pseudo labeling. We only report AR<sub id="S4.T1.16.2" class="ltx_sub"><span id="S4.T1.16.2.1" class="ltx_text ltx_font_italic">A</span></sub> in b) as the classes in ADE20K do not exactly match those in COCO.</figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.5" class="ltx_p">On the cross-category benchmarks shown in Table <a href="#S4.T1.st1" title="In Table 1 ‣ 4.1 Detecting unknown objects in an open world ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a>, with a single training class “person” on the COCO dataset, GOOD can surpass SOTA methods by 5.0% AR<sub id="S4.SS1.p2.5.1" class="ltx_sub"><span id="S4.SS1.p2.5.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 on detecting objects from non-person classes, a relative improvement of 24%. With 20 PASCAL-VOC classes for training, GOOD surpasses SOTA methods by 6.1% AR<sub id="S4.SS1.p2.5.2" class="ltx_sub"><span id="S4.SS1.p2.5.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100 in detecting non-VOC classes, a relative improvement over 18%. On the cross-dataset benchmarks, Table <a href="#S4.T1.st2" title="In Table 1 ‣ 4.1 Detecting unknown objects in an open world ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> shows that GOOD achieves 2.4% to 4.7% gain on AR<sub id="S4.SS1.p2.5.3" class="ltx_sub"><span id="S4.SS1.p2.5.3.1" class="ltx_text ltx_font_italic">A</span></sub>@100 in different setups. We observe that GOOD is particularly strong when there are fewer training classes, i.e., person <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mo stretchy="false" id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\rightarrow</annotation></semantics></math> non-person and VOC <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mo stretchy="false" id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><ci id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">\rightarrow</annotation></semantics></math> ADE20k. For RGB-based methods, the overfitting problems become more severe as the object diversity from the base classes reduces. In contrast, the geometric cues can still detect novel-looking objects, which are particularly helpful to training with only a limited number of base class annotations. Finally, ensembling both geometric cues offers additional performance gains.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Advantages of geometric cues</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Geometric cues are less sensitive to appearance shifts across classes.</span>
We first compare per-novel-class AR@5 of the object proposal network trained on geometric cues with that trained on the RGB image. Here, AR@5 is of interest as geometric cues are used to discover novel-looking objects during Phase-I and no more than five pseudo boxes per image will be used in Phase-II, see Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Related work ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p">Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that geometric cues can achieve much higher per-novel-class AR@5 than RGB in many categories. An example is the novel supercategory “food”, including classes such as “hot dog” and “sandwich”. The base classes, belonging to the supercategory “person”, “animal”, “vehicle”, and “indoor”, have very different appearances to the “food” supercategory. The RGB-based model has difficulty detecting food using appearance cues.
In contrast, the geometric cues can generalize across supercategories.
For categories that geometric cues are worse than RGB, we find that they typically are of small sizes, such as knives, forks, and clocks. This shows that while abstracting away appearance details, geometric cues may also lose some information about small objects. This again shows complementariness of RGB and geometric cues.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2212.11720/assets/iclr2023/figures/fig4/ar5_novel_pseudo_boxes_depth_normal_line_only.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S4.F4.4.1" class="ltx_text ltx_font_bold">Per-novel-class AR@5 difference comparison of pseudo boxes on COCO VOC <math id="S4.F4.4.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.F4.4.1.m1.1b"><mo stretchy="false" id="S4.F4.4.1.m1.1.1" xref="S4.F4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.F4.4.1.m1.1c"><ci id="S4.F4.4.1.m1.1.1.cmml" xref="S4.F4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.1.m1.1d">\rightarrow</annotation></semantics></math> Non-VOC</span>. We train the object proposal network on the geometric cues (Phase-I in Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Related work ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) and also directly on the RGB image. We show their per-novel-class AR@5 differences, which is defined as <math id="S4.F4.5.m1.1" class="ltx_Math" alttext="(\text{AR}_{\text{X}}-\text{AR}_{\text{RGB}})/\text{AR}_{\text{RGB}}" display="inline"><semantics id="S4.F4.5.m1.1b"><mrow id="S4.F4.5.m1.1.1" xref="S4.F4.5.m1.1.1.cmml"><mrow id="S4.F4.5.m1.1.1.1.1" xref="S4.F4.5.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.F4.5.m1.1.1.1.1.2" xref="S4.F4.5.m1.1.1.1.1.1.cmml">(</mo><mrow id="S4.F4.5.m1.1.1.1.1.1" xref="S4.F4.5.m1.1.1.1.1.1.cmml"><msub id="S4.F4.5.m1.1.1.1.1.1.2" xref="S4.F4.5.m1.1.1.1.1.1.2.cmml"><mtext id="S4.F4.5.m1.1.1.1.1.1.2.2" xref="S4.F4.5.m1.1.1.1.1.1.2.2a.cmml">AR</mtext><mtext id="S4.F4.5.m1.1.1.1.1.1.2.3" xref="S4.F4.5.m1.1.1.1.1.1.2.3a.cmml">X</mtext></msub><mo id="S4.F4.5.m1.1.1.1.1.1.1" xref="S4.F4.5.m1.1.1.1.1.1.1.cmml">−</mo><msub id="S4.F4.5.m1.1.1.1.1.1.3" xref="S4.F4.5.m1.1.1.1.1.1.3.cmml"><mtext id="S4.F4.5.m1.1.1.1.1.1.3.2" xref="S4.F4.5.m1.1.1.1.1.1.3.2a.cmml">AR</mtext><mtext id="S4.F4.5.m1.1.1.1.1.1.3.3" xref="S4.F4.5.m1.1.1.1.1.1.3.3a.cmml">RGB</mtext></msub></mrow><mo stretchy="false" id="S4.F4.5.m1.1.1.1.1.3" xref="S4.F4.5.m1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.F4.5.m1.1.1.2" xref="S4.F4.5.m1.1.1.2.cmml">/</mo><msub id="S4.F4.5.m1.1.1.3" xref="S4.F4.5.m1.1.1.3.cmml"><mtext id="S4.F4.5.m1.1.1.3.2" xref="S4.F4.5.m1.1.1.3.2a.cmml">AR</mtext><mtext id="S4.F4.5.m1.1.1.3.3" xref="S4.F4.5.m1.1.1.3.3a.cmml">RGB</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.5.m1.1c"><apply id="S4.F4.5.m1.1.1.cmml" xref="S4.F4.5.m1.1.1"><divide id="S4.F4.5.m1.1.1.2.cmml" xref="S4.F4.5.m1.1.1.2"></divide><apply id="S4.F4.5.m1.1.1.1.1.1.cmml" xref="S4.F4.5.m1.1.1.1.1"><minus id="S4.F4.5.m1.1.1.1.1.1.1.cmml" xref="S4.F4.5.m1.1.1.1.1.1.1"></minus><apply id="S4.F4.5.m1.1.1.1.1.1.2.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.1.1.1.2.1.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.F4.5.m1.1.1.1.1.1.2.2a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.2"><mtext id="S4.F4.5.m1.1.1.1.1.1.2.2.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.2">AR</mtext></ci><ci id="S4.F4.5.m1.1.1.1.1.1.2.3a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S4.F4.5.m1.1.1.1.1.1.2.3.cmml" xref="S4.F4.5.m1.1.1.1.1.1.2.3">X</mtext></ci></apply><apply id="S4.F4.5.m1.1.1.1.1.1.3.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.1.1.1.3.1.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.F4.5.m1.1.1.1.1.1.3.2a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.2"><mtext id="S4.F4.5.m1.1.1.1.1.1.3.2.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.2">AR</mtext></ci><ci id="S4.F4.5.m1.1.1.1.1.1.3.3a.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S4.F4.5.m1.1.1.1.1.1.3.3.cmml" xref="S4.F4.5.m1.1.1.1.1.1.3.3">RGB</mtext></ci></apply></apply><apply id="S4.F4.5.m1.1.1.3.cmml" xref="S4.F4.5.m1.1.1.3"><csymbol cd="ambiguous" id="S4.F4.5.m1.1.1.3.1.cmml" xref="S4.F4.5.m1.1.1.3">subscript</csymbol><ci id="S4.F4.5.m1.1.1.3.2a.cmml" xref="S4.F4.5.m1.1.1.3.2"><mtext id="S4.F4.5.m1.1.1.3.2.cmml" xref="S4.F4.5.m1.1.1.3.2">AR</mtext></ci><ci id="S4.F4.5.m1.1.1.3.3a.cmml" xref="S4.F4.5.m1.1.1.3.3"><mtext mathsize="70%" id="S4.F4.5.m1.1.1.3.3.cmml" xref="S4.F4.5.m1.1.1.3.3">RGB</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.5.m1.1d">(\text{AR}_{\text{X}}-\text{AR}_{\text{RGB}})/\text{AR}_{\text{RGB}}</annotation></semantics></math> with <math id="S4.F4.6.m2.2" class="ltx_Math" alttext="\text{X}\in\{\text{Depth},\text{Normal}\}" display="inline"><semantics id="S4.F4.6.m2.2b"><mrow id="S4.F4.6.m2.2.3" xref="S4.F4.6.m2.2.3.cmml"><mtext id="S4.F4.6.m2.2.3.2" xref="S4.F4.6.m2.2.3.2a.cmml">X</mtext><mo id="S4.F4.6.m2.2.3.1" xref="S4.F4.6.m2.2.3.1.cmml">∈</mo><mrow id="S4.F4.6.m2.2.3.3.2" xref="S4.F4.6.m2.2.3.3.1.cmml"><mo stretchy="false" id="S4.F4.6.m2.2.3.3.2.1" xref="S4.F4.6.m2.2.3.3.1.cmml">{</mo><mtext id="S4.F4.6.m2.1.1" xref="S4.F4.6.m2.1.1a.cmml">Depth</mtext><mo id="S4.F4.6.m2.2.3.3.2.2" xref="S4.F4.6.m2.2.3.3.1.cmml">,</mo><mtext id="S4.F4.6.m2.2.2" xref="S4.F4.6.m2.2.2a.cmml">Normal</mtext><mo stretchy="false" id="S4.F4.6.m2.2.3.3.2.3" xref="S4.F4.6.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.6.m2.2c"><apply id="S4.F4.6.m2.2.3.cmml" xref="S4.F4.6.m2.2.3"><in id="S4.F4.6.m2.2.3.1.cmml" xref="S4.F4.6.m2.2.3.1"></in><ci id="S4.F4.6.m2.2.3.2a.cmml" xref="S4.F4.6.m2.2.3.2"><mtext id="S4.F4.6.m2.2.3.2.cmml" xref="S4.F4.6.m2.2.3.2">X</mtext></ci><set id="S4.F4.6.m2.2.3.3.1.cmml" xref="S4.F4.6.m2.2.3.3.2"><ci id="S4.F4.6.m2.1.1a.cmml" xref="S4.F4.6.m2.1.1"><mtext id="S4.F4.6.m2.1.1.cmml" xref="S4.F4.6.m2.1.1">Depth</mtext></ci><ci id="S4.F4.6.m2.2.2a.cmml" xref="S4.F4.6.m2.2.2"><mtext id="S4.F4.6.m2.2.2.cmml" xref="S4.F4.6.m2.2.2">Normal</mtext></ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.6.m2.2d">\text{X}\in\{\text{Depth},\text{Normal}\}</annotation></semantics></math>. The geometric cues outperform the RGB image on those classes above the zero difference line. We also highlight some classes where RGB and geometric cues have big differences.
</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Geometric cues are better than edges and pairwise affinities.</span>
We further compare the geometric cues with two other mid-level representations: 2D edge and PA.
The 2D edge map is extracted using the Holistically-nested Edge Detection (HED) model <cite class="ltx_cite ltx_citemacro_citep">(Xie &amp; Tu, <a href="#bib.bib45" title="" class="ltx_ref">2015</a>)</cite>, which shows more robust performance across the datasets than more recent methods. The HED model is trained on the Berkeley Segmentation Dataset and Benchmark (BSDS500) dataset <cite class="ltx_cite ltx_citemacro_citep">(Arbelaez et al., <a href="#bib.bib3" title="" class="ltx_ref">2011</a>)</cite> which contains 500 images with segmentation annotations. PA can be thought of as a learned object boundary predictor. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite> trained it directly on RGB images and then grouped the predictions into object masks using a combination of traditional grouping methods <cite class="ltx_cite ltx_citemacro_citep">(Shi &amp; Malik, <a href="#bib.bib39" title="" class="ltx_ref">2000</a>; Arbeláez, <a href="#bib.bib2" title="" class="ltx_ref">2006</a>; Arbeláez et al., <a href="#bib.bib1" title="" class="ltx_ref">2014</a>)</cite>.
We compare these four data modalities as the source of pseudo labeling.
From Table <a href="#S4.T2" title="Table 2 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we can see that depth and normals outperform 2D edge and PA on detecting novel objects.
We speculate that this is because 2D edge and PA mainly capture object boundaries, whereas depth and normals have an extra spatial understanding of the scene and can thus better detect objects in complex scenes.
Owing to their better pseudo labels, GOOD-Depth/Normal outperform GOOD-Edge/PA on the final AR<sub id="S4.SS2.p3.1.2" class="ltx_sub"><span id="S4.SS2.p3.1.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100, i.e., 39.0%/38.9% vs. 38.1%/37.1%, see Appendix <a href="#A4" title="Appendix D More discussion on different modalities for GOOD ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.5.5" class="ltx_tr">
<th id="S4.T2.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Modality</th>
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T2.1.1.1.1" class="ltx_sub"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_italic">N</span></sub> @ 1</th>
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T2.2.2.2.1" class="ltx_sub"><span id="S4.T2.2.2.2.1.1" class="ltx_text ltx_font_italic">N</span></sub> @ 5</th>
<th id="S4.T2.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T2.3.3.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><mmultiscripts id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.m1.1.1.2.2" xref="S4.T2.3.3.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T2.3.3.3.m1.1.1a" xref="S4.T2.3.3.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T2.3.3.3.m1.1.1b" xref="S4.T2.3.3.3.m1.1.1.cmml"></mrow><mi id="S4.T2.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.m1.1.1.3.cmml">s</mi><mi id="S4.T2.3.3.3.m1.1.1.2.3" xref="S4.T2.3.3.3.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T2.3.3.3.m1.1.1c" xref="S4.T2.3.3.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">superscript</csymbol><apply id="S4.T2.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.m1.1.1.2.1.cmml" xref="S4.T2.3.3.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T2.3.3.3.m1.1.1.2.2.cmml" xref="S4.T2.3.3.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T2.3.3.3.m1.1.1.2.3.cmml" xref="S4.T2.3.3.3.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T2.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">{}_{N}^{s}</annotation></semantics></math> @ 5</th>
<th id="S4.T2.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T2.4.4.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T2.4.4.4.m1.1a"><mmultiscripts id="S4.T2.4.4.4.m1.1.1" xref="S4.T2.4.4.4.m1.1.1.cmml"><mi id="S4.T2.4.4.4.m1.1.1.2.2" xref="S4.T2.4.4.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T2.4.4.4.m1.1.1a" xref="S4.T2.4.4.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T2.4.4.4.m1.1.1b" xref="S4.T2.4.4.4.m1.1.1.cmml"></mrow><mi id="S4.T2.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.m1.1.1.3.cmml">m</mi><mi id="S4.T2.4.4.4.m1.1.1.2.3" xref="S4.T2.4.4.4.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T2.4.4.4.m1.1.1c" xref="S4.T2.4.4.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">superscript</csymbol><apply id="S4.T2.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.m1.1.1.2.1.cmml" xref="S4.T2.4.4.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T2.4.4.4.m1.1.1.2.2.cmml" xref="S4.T2.4.4.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T2.4.4.4.m1.1.1.2.3.cmml" xref="S4.T2.4.4.4.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T2.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">{}_{N}^{m}</annotation></semantics></math> @ 5</th>
<th id="S4.T2.5.5.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AR<math id="S4.T2.5.5.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T2.5.5.5.m1.1a"><mmultiscripts id="S4.T2.5.5.5.m1.1.1" xref="S4.T2.5.5.5.m1.1.1.cmml"><mi id="S4.T2.5.5.5.m1.1.1.2.2" xref="S4.T2.5.5.5.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T2.5.5.5.m1.1.1a" xref="S4.T2.5.5.5.m1.1.1.cmml"></mprescripts><mrow id="S4.T2.5.5.5.m1.1.1b" xref="S4.T2.5.5.5.m1.1.1.cmml"></mrow><mi id="S4.T2.5.5.5.m1.1.1.3" xref="S4.T2.5.5.5.m1.1.1.3.cmml">l</mi><mi id="S4.T2.5.5.5.m1.1.1.2.3" xref="S4.T2.5.5.5.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T2.5.5.5.m1.1.1c" xref="S4.T2.5.5.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.m1.1b"><apply id="S4.T2.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.m1.1.1.1.cmml" xref="S4.T2.5.5.5.m1.1.1">superscript</csymbol><apply id="S4.T2.5.5.5.m1.1.1.2.cmml" xref="S4.T2.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.m1.1.1.2.1.cmml" xref="S4.T2.5.5.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T2.5.5.5.m1.1.1.2.2.cmml" xref="S4.T2.5.5.5.m1.1.1.2.2">absent</csymbol><ci id="S4.T2.5.5.5.m1.1.1.2.3.cmml" xref="S4.T2.5.5.5.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T2.5.5.5.m1.1.1.3.cmml" xref="S4.T2.5.5.5.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>@5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.5.6.1" class="ltx_tr">
<td id="S4.T2.5.6.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RGB</td>
<td id="S4.T2.5.6.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4.0</td>
<td id="S4.T2.5.6.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12.6</td>
<td id="S4.T2.5.6.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T2.5.6.1.4.1" class="ltx_text ltx_font_bold">5.4</span></td>
<td id="S4.T2.5.6.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">16.4</td>
<td id="S4.T2.5.6.1.6" class="ltx_td ltx_align_left ltx_border_t">21.8</td>
</tr>
<tr id="S4.T2.5.7.2" class="ltx_tr">
<td id="S4.T2.5.7.2.1" class="ltx_td ltx_align_left ltx_border_r">Depth</td>
<td id="S4.T2.5.7.2.2" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.5.7.2.2.1" class="ltx_text ltx_font_bold">4.7</span></td>
<td id="S4.T2.5.7.2.3" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.5.7.2.3.1" class="ltx_text ltx_font_bold">13.2</span></td>
<td id="S4.T2.5.7.2.4" class="ltx_td ltx_align_left ltx_border_r">2.4</td>
<td id="S4.T2.5.7.2.5" class="ltx_td ltx_align_left ltx_border_r">16.0</td>
<td id="S4.T2.5.7.2.6" class="ltx_td ltx_align_left"><span id="S4.T2.5.7.2.6.1" class="ltx_text ltx_font_bold">31.6</span></td>
</tr>
<tr id="S4.T2.5.8.3" class="ltx_tr">
<td id="S4.T2.5.8.3.1" class="ltx_td ltx_align_left ltx_border_r">Normal</td>
<td id="S4.T2.5.8.3.2" class="ltx_td ltx_align_left ltx_border_r">4.3</td>
<td id="S4.T2.5.8.3.3" class="ltx_td ltx_align_left ltx_border_r">12.8</td>
<td id="S4.T2.5.8.3.4" class="ltx_td ltx_align_left ltx_border_r">3.0</td>
<td id="S4.T2.5.8.3.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T2.5.8.3.5.1" class="ltx_text ltx_font_bold">16.6</span></td>
<td id="S4.T2.5.8.3.6" class="ltx_td ltx_align_left">27.7</td>
</tr>
<tr id="S4.T2.5.9.4" class="ltx_tr">
<td id="S4.T2.5.9.4.1" class="ltx_td ltx_align_left ltx_border_r">Edge</td>
<td id="S4.T2.5.9.4.2" class="ltx_td ltx_align_left ltx_border_r">3.2</td>
<td id="S4.T2.5.9.4.3" class="ltx_td ltx_align_left ltx_border_r">10.4</td>
<td id="S4.T2.5.9.4.4" class="ltx_td ltx_align_left ltx_border_r">3.5</td>
<td id="S4.T2.5.9.4.5" class="ltx_td ltx_align_left ltx_border_r">14.5</td>
<td id="S4.T2.5.9.4.6" class="ltx_td ltx_align_left">18.5</td>
</tr>
<tr id="S4.T2.5.10.5" class="ltx_tr">
<td id="S4.T2.5.10.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">Pairwise affinity (PA)</td>
<td id="S4.T2.5.10.5.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">3.2</td>
<td id="S4.T2.5.10.5.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">8.1</td>
<td id="S4.T2.5.10.5.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">0.5</td>
<td id="S4.T2.5.10.5.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">9.1</td>
<td id="S4.T2.5.10.5.6" class="ltx_td ltx_align_left ltx_border_bb">30.6</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S4.T2.12.1" class="ltx_text ltx_font_bold">Comparison on different data modalities for pseudo labeling</span>. We report AR<sub id="S4.T2.13.2" class="ltx_sub"><span id="S4.T2.13.2.1" class="ltx_text ltx_font_italic">N</span></sub>@k achieved by the object proposal network trained on different modalities in Phase-I, where the benchmark is VOC <math id="S4.T2.9.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T2.9.m2.1b"><mo stretchy="false" id="S4.T2.9.m2.1.1" xref="S4.T2.9.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.m2.1c"><ci id="S4.T2.9.m2.1.1.cmml" xref="S4.T2.9.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.m2.1d">\rightarrow</annotation></semantics></math> Non-VOC. Geometric cues (depth and normal) are stronger in discovering novel objects than the edge and pairwise affinity <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>.</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S4.T3.7.1" class="ltx_text ltx_font_bold">Comparison of GOOD and two other strategies on VOC to non-VOC</span>. ShapeBias replaced the backbone of SelfTrain-RGB with a stylized ImageNet pre-trained backbone. ScaleAug applied multi-scale augmentation to the RGB input for collecting pseudo boxes at different scales.</figcaption>
<table id="S4.T3.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.5.5" class="ltx_tr">
<th id="S4.T3.5.5.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Method</th>
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T3.1.1.1.1" class="ltx_sub"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="S4.T3.2.2.2.1" class="ltx_sub"><span id="S4.T3.2.2.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="S4.T3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T3.3.3.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="S4.T3.3.3.3.m1.1a"><mmultiscripts id="S4.T3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.m1.1.1.cmml"><mi id="S4.T3.3.3.3.m1.1.1.2.2" xref="S4.T3.3.3.3.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T3.3.3.3.m1.1.1a" xref="S4.T3.3.3.3.m1.1.1.cmml"></mprescripts><mrow id="S4.T3.3.3.3.m1.1.1b" xref="S4.T3.3.3.3.m1.1.1.cmml"></mrow><mi id="S4.T3.3.3.3.m1.1.1.3" xref="S4.T3.3.3.3.m1.1.1.3.cmml">s</mi><mi id="S4.T3.3.3.3.m1.1.1.2.3" xref="S4.T3.3.3.3.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T3.3.3.3.m1.1.1c" xref="S4.T3.3.3.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><apply id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.3.m1.1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">superscript</csymbol><apply id="S4.T3.3.3.3.m1.1.1.2.cmml" xref="S4.T3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.3.m1.1.1.2.1.cmml" xref="S4.T3.3.3.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T3.3.3.3.m1.1.1.2.2.cmml" xref="S4.T3.3.3.3.m1.1.1.2.2">absent</csymbol><ci id="S4.T3.3.3.3.m1.1.1.2.3.cmml" xref="S4.T3.3.3.3.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T3.3.3.3.m1.1.1.3.cmml" xref="S4.T3.3.3.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="S4.T3.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="S4.T3.4.4.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="S4.T3.4.4.4.m1.1a"><mmultiscripts id="S4.T3.4.4.4.m1.1.1" xref="S4.T3.4.4.4.m1.1.1.cmml"><mi id="S4.T3.4.4.4.m1.1.1.2.2" xref="S4.T3.4.4.4.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T3.4.4.4.m1.1.1a" xref="S4.T3.4.4.4.m1.1.1.cmml"></mprescripts><mrow id="S4.T3.4.4.4.m1.1.1b" xref="S4.T3.4.4.4.m1.1.1.cmml"></mrow><mi id="S4.T3.4.4.4.m1.1.1.3" xref="S4.T3.4.4.4.m1.1.1.3.cmml">m</mi><mi id="S4.T3.4.4.4.m1.1.1.2.3" xref="S4.T3.4.4.4.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T3.4.4.4.m1.1.1c" xref="S4.T3.4.4.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><apply id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.4.m1.1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">superscript</csymbol><apply id="S4.T3.4.4.4.m1.1.1.2.cmml" xref="S4.T3.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.4.m1.1.1.2.1.cmml" xref="S4.T3.4.4.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T3.4.4.4.m1.1.1.2.2.cmml" xref="S4.T3.4.4.4.m1.1.1.2.2">absent</csymbol><ci id="S4.T3.4.4.4.m1.1.1.2.3.cmml" xref="S4.T3.4.4.4.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T3.4.4.4.m1.1.1.3.cmml" xref="S4.T3.4.4.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="S4.T3.5.5.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AR<math id="S4.T3.5.5.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="S4.T3.5.5.5.m1.1a"><mmultiscripts id="S4.T3.5.5.5.m1.1.1" xref="S4.T3.5.5.5.m1.1.1.cmml"><mi id="S4.T3.5.5.5.m1.1.1.2.2" xref="S4.T3.5.5.5.m1.1.1.2.2.cmml"></mi><mprescripts id="S4.T3.5.5.5.m1.1.1a" xref="S4.T3.5.5.5.m1.1.1.cmml"></mprescripts><mrow id="S4.T3.5.5.5.m1.1.1b" xref="S4.T3.5.5.5.m1.1.1.cmml"></mrow><mi id="S4.T3.5.5.5.m1.1.1.3" xref="S4.T3.5.5.5.m1.1.1.3.cmml">l</mi><mi id="S4.T3.5.5.5.m1.1.1.2.3" xref="S4.T3.5.5.5.m1.1.1.2.3.cmml">N</mi><mrow id="S4.T3.5.5.5.m1.1.1c" xref="S4.T3.5.5.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><apply id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.5.5.5.m1.1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">superscript</csymbol><apply id="S4.T3.5.5.5.m1.1.1.2.cmml" xref="S4.T3.5.5.5.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.5.5.5.m1.1.1.2.1.cmml" xref="S4.T3.5.5.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S4.T3.5.5.5.m1.1.1.2.2.cmml" xref="S4.T3.5.5.5.m1.1.1.2.2">absent</csymbol><ci id="S4.T3.5.5.5.m1.1.1.2.3.cmml" xref="S4.T3.5.5.5.m1.1.1.2.3">𝑁</ci></apply><ci id="S4.T3.5.5.5.m1.1.1.3.cmml" xref="S4.T3.5.5.5.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
</tr>
<tr id="S4.T3.5.6.1" class="ltx_tr">
<th id="S4.T3.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">SelfTrain-RGB</th>
<th id="S4.T3.5.6.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">48.1</th>
<th id="S4.T3.5.6.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">37.4</th>
<th id="S4.T3.5.6.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.5.6.1.4.1" class="ltx_text ltx_font_bold">22.8</span></th>
<th id="S4.T3.5.6.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">43.9</th>
<th id="S4.T3.5.6.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">57.7</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.5.7.1" class="ltx_tr">
<td id="S4.T3.5.7.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">ShapeBias</td>
<td id="S4.T3.5.7.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.8</td>
<td id="S4.T3.5.7.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">36.5</td>
<td id="S4.T3.5.7.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.4</td>
<td id="S4.T3.5.7.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.5</td>
<td id="S4.T3.5.7.1.6" class="ltx_td ltx_align_left ltx_border_t">58.6</td>
</tr>
<tr id="S4.T3.5.8.2" class="ltx_tr">
<td id="S4.T3.5.8.2.1" class="ltx_td ltx_align_left ltx_border_r">ScaleAug</td>
<td id="S4.T3.5.8.2.2" class="ltx_td ltx_align_left ltx_border_r">48.5</td>
<td id="S4.T3.5.8.2.3" class="ltx_td ltx_align_left ltx_border_r">37.9</td>
<td id="S4.T3.5.8.2.4" class="ltx_td ltx_align_left ltx_border_r">21.2</td>
<td id="S4.T3.5.8.2.5" class="ltx_td ltx_align_left ltx_border_r">44.7</td>
<td id="S4.T3.5.8.2.6" class="ltx_td ltx_align_left">62.2</td>
</tr>
<tr id="S4.T3.5.9.3" class="ltx_tr">
<td id="S4.T3.5.9.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="S4.T3.5.9.3.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T3.5.9.3.2.1" class="ltx_text ltx_font_bold">49.5</span></td>
<td id="S4.T3.5.9.3.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T3.5.9.3.3.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="S4.T3.5.9.3.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.6</td>
<td id="S4.T3.5.9.3.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="S4.T3.5.9.3.5.1" class="ltx_text ltx_font_bold">48.2</span></td>
<td id="S4.T3.5.9.3.6" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T3.5.9.3.6.1" class="ltx_text ltx_font_bold">62.4</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Geometric cues are better than adding shape bias and multi-scale augmentation.</span>
In the previous part, we showed that geometric cues can detect novel objects from very different supercategories, owing to their less sensitivity to detailed appearance changes in objects such as textures. It is thus natural to compare with RGB-based model with inductive shape bias to counteract the texture bias. We adopt the stylized ImageNet pretrained ResNet-50 from <cite class="ltx_cite ltx_citemacro_citep">(Geirhos et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite> as the backbone for SelfTrain-RGB. This backbone is trained using heavy style-based augmentation to mitigate the texture bias, where texture is one of the most discussed appearance features prone to overfit by RGB-based models. It showed performance improvements on the COCO object detection benchmark under the closed-world assumption <cite class="ltx_cite ltx_citemacro_citep">(Geirhos et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>.
Moreover, we observe from Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that RGB is relatively stronger in detecting smaller objects. This leads to the question of whether augmenting SelfTrain-RGB with pseudo boxes extracted at different input scales can already help this RGB-based method achieve comparable performance to those incorporating geometric cues.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.2" class="ltx_p">From Table <a href="#S4.T3" title="Table 3 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we can see that while the shape bias backbone can improve the AR<sub id="S4.SS2.p5.2.1" class="ltx_sub"><span id="S4.SS2.p5.2.1.1" class="ltx_text ltx_font_italic">A</span></sub> of SelfTrain-RGB, it degrades the performance on novel classes, i.e., AR<sub id="S4.SS2.p5.2.2" class="ltx_sub"><span id="S4.SS2.p5.2.2.1" class="ltx_text ltx_font_italic">N</span></sub>, indicating that shape bias obtained from training on ImageNet may not be very helpful in generalizing to novel objects. As for the multi-scale augmentation, although it can improve the detection recall of medium and large objects, the overall performance is still worse than our models that incorporate geometry cues. Overall, these comparisons show that geometry provides strong cues for object localization.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation studies</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p id="S4.SS3.p1.4" class="ltx_p">In this section, we conduct ablation studies to understand the effectiveness of pseudo-labeling, data augmentation, and the influence of the number of base classes. Figure <a href="#S4.F5.sf1" title="In Figure 5 ‣ 4.3 Ablation studies ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>) shows the AR<sub id="S4.SS3.p1.4.1" class="ltx_sub"><span id="S4.SS3.p1.4.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 achieved by the object proposal network (Phase-I) and the object detector (Phase-II). The latter uses the pseudo boxes generated by the former, where the former can be trained with different data modalities. The RGB-based object proposal network outperforms the depth- and normal-based one on AR<sub id="S4.SS3.p1.4.2" class="ltx_sub"><span id="S4.SS3.p1.4.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100. This indicates that depth and normal maps cannot simply replace RGB image for object detection. As evidenced in Table <a href="#S4.T2" title="Table 2 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, they are competitive on AR<sub id="S4.SS3.p1.4.3" class="ltx_sub"><span id="S4.SS3.p1.4.3.1" class="ltx_text ltx_font_italic">N</span></sub>@k with <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="\text{k}\leq 5" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mtext id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2a.cmml">k</mtext><mo id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">≤</mo><mn id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><leq id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></leq><ci id="S4.SS3.p1.4.m4.1.1.2a.cmml" xref="S4.SS3.p1.4.m4.1.1.2"><mtext id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">k</mtext></ci><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">\text{k}\leq 5</annotation></semantics></math>, meaning their top predictions are of high quality. Pseudo labeling is thus an effective way for geometry-guided open-world object detector training.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para ltx_noindent">
<p id="S4.SS3.p2.2" class="ltx_p">We further study the effect of AutoAugment <cite class="ltx_cite ltx_citemacro_citep">(Cubuk et al., <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite>. Using it during Phase-II training, we achieve higher AR<sub id="S4.SS3.p2.2.1" class="ltx_sub"><span id="S4.SS3.p2.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 as shown in Figure <a href="#S4.F5.sf2" title="In Figure 5 ‣ 4.3 Ablation studies ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>). Data augmentation is helpful to counteract the noise in pseudo labels. However, using AutoAugment to train OLN on the ground truth base class annotations, we observe only improvement in recalling the base class objects (from 58.4% to 61.7% AR<sub id="S4.SS3.p2.2.2" class="ltx_sub"><span id="S4.SS3.p2.2.2.1" class="ltx_text ltx_font_italic">Base</span></sub>@100), but degradation in novel object detection. This shows that data augmentation via random resizing, cropping, and flipping cannot improve generalization across categories.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para ltx_noindent">
<p id="S4.SS3.p3.4" class="ltx_p">Finally, we study the influence of the number of base classes. As shown in Table <a href="#S4.T4" title="Table 4 ‣ 4.3 Ablation studies ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we split the COCO dataset based on the supercategories to create six different splits. We then train GOOD and OLN on these splits and evaluate them on ADE20K. More base classes in training allow object detectors to learn a more generic sense of objectness so that they can better detect novel objects. As shown in Figure <a href="#S4.F5.sf3" title="In Figure 5 ‣ 4.3 Ablation studies ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(c)</span></a>, both GOOD and OLN achieve better AR<sub id="S4.SS3.p3.4.1" class="ltx_sub"><span id="S4.SS3.p3.4.1.1" class="ltx_text ltx_font_italic">N</span></sub>@100 along with the number of base classes, and their performance gap reduces. However, the annotation cost also grows along with the number of classes. GOOD can achieve a similar AR<sub id="S4.SS3.p3.4.2" class="ltx_sub"><span id="S4.SS3.p3.4.2.1" class="ltx_text ltx_font_italic">N</span></sub>@100 as OLN with only half the number of base classes, e.g., <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="39" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mn id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml">39</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><cn type="integer" id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1">39</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">39</annotation></semantics></math> vs. <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mn id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><cn type="integer" id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">80</annotation></semantics></math>. This shows that GOOD is more effective at learning a generic sense of objectness and less prone to overfitting to the base classes.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x3.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="286" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Effectiveness of pseudo labeling.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x4.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="219" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Effectiveness of data augmentation.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x5.png" id="S4.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Varying the number of base classes.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S4.F5.2.1" class="ltx_text ltx_font_bold">Ablation studies.</span> (a) and (b) are conducted on COCO VOC to non-VOC benchmark. The study on the number of base classes (c) uses ADE20K as the evaluation benchmark.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:68.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-73.4pt,13.6pt) scale(0.715224525907428,0.715224525907428) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Supercategories</th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Person</th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">+Vehicle</th>
<th id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Outdoor,</td>
</tr>
<tr id="S4.T4.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Animal</td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.5.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Accessory,</td>
</tr>
<tr id="S4.T4.1.1.1.1.5.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Sports</td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.6.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Kitchen,</td>
</tr>
<tr id="S4.T4.1.1.1.1.6.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Food</td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<table id="S4.T4.1.1.1.1.7.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.7.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">+Furniture, Electronic,</td>
</tr>
<tr id="S4.T4.1.1.1.1.7.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Appliance, Indoor</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.2.1" class="ltx_tr">
<th id="S4.T4.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"># Training classes</th>
<td id="S4.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">9</td>
<td id="S4.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">24</td>
<td id="S4.T4.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">39</td>
<td id="S4.T4.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">56</td>
<td id="S4.T4.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">80</td>
</tr>
<tr id="S4.T4.1.1.3.2" class="ltx_tr">
<th id="S4.T4.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"># Training images</th>
<td id="S4.T4.1.1.3.2.2" class="ltx_td ltx_align_center">64115</td>
<td id="S4.T4.1.1.3.2.3" class="ltx_td ltx_align_center">74152</td>
<td id="S4.T4.1.1.3.2.4" class="ltx_td ltx_align_center">92169</td>
<td id="S4.T4.1.1.3.2.5" class="ltx_td ltx_align_center">93939</td>
<td id="S4.T4.1.1.3.2.6" class="ltx_td ltx_align_center">107036</td>
<td id="S4.T4.1.1.3.2.7" class="ltx_td ltx_align_center">117266</td>
</tr>
<tr id="S4.T4.1.1.4.3" class="ltx_tr">
<th id="S4.T4.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"># Training instances</th>
<td id="S4.T4.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">609666</td>
<td id="S4.T4.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">654460</td>
<td id="S4.T4.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">715582</td>
<td id="S4.T4.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb">727207</td>
<td id="S4.T4.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_bb">824535</td>
<td id="S4.T4.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_bb">860001</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="S4.T4.3.1" class="ltx_text ltx_font_bold">Base class choices for studying the influence of the number of base classes.</span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">In this paper, we proposed a method GOOD for tackling the challenging problem of open-world class-agnostic object detection. It exploits the easy-to-obtain geometric cues such as depth and normals for detecting unannotated novel objects in the training set. As the geometric cues focus on object shapes and relative spatial locations rather than appearances, they can detect novel objects that RGB-based methods cannot detect. By further involving these novel objects into RGB-based object detector training, GOOD demonstrates strong generalization performance across categories as well as datasets.</p>
</div>
<section id="S5.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Acknowledgment</h3>

<div id="S5.SSx1.p1" class="ltx_para ltx_noindent">
<p id="S5.SSx1.p1.1" class="ltx_p">Haiwen Huang and Dan Zhang were supported by Bosch Industry on Campus Lab at University of Tübingen. Andreas Geiger was supported by the ERC Starting Grant LEGO-3D (850533) and the DFG EXC number 2064/1 - project number 390727645. Haiwen Huang would like to thank Tianlin Ye for her emotional support throughout the project and Jojumon Kavalan for generously providing access to his Internet during the rebuttal period.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arbeláez et al. (2014)</span>
<span class="ltx_bibblock">
P. Arbeláez, J. Pont-Tuset, J. Barron, F. Marques, and J. Malik.

</span>
<span class="ltx_bibblock">Multiscale combinatorial grouping.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Computer Vision and Pattern Recognition</em>, 2014.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arbeláez (2006)</span>
<span class="ltx_bibblock">
Pablo Arbeláez.

</span>
<span class="ltx_bibblock">Boundary extraction in natural images using ultrametric contour maps.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">2006 Conference on Computer Vision and Pattern Recognition
Workshop (CVPRW’06)</em>, pp.  182–182. IEEE, 2006.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arbelaez et al. (2011)</span>
<span class="ltx_bibblock">
Pablo Arbelaez, Michael Maire, Charless Fowlkes, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Contour detection and hierarchical image segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Pattern Anal. Mach. Intell.</em>, 33(5):898–916, May 2011.

</span>
<span class="ltx_bibblock">ISSN 0162-8828.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TPAMI.2010.161</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.1109/TPAMI.2010.161" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.1109/TPAMI.2010.161</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Bryan Chen, Alexander Sax, Francis Lewis, Iro Armeni, Silvio Savarese, Amir
Zamir, Jitendra Malik, and Lerrel Pinto.

</span>
<span class="ltx_bibblock">Robust policies via mid-level visual representations: An experimental
study in manipulation and navigation.

</span>
<span class="ltx_bibblock">In Jens Kober, Fabio Ramos, and Claire Tomlin (eds.),
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Robot Learning</em>, volume 155 of
<em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pp.  2328–2346. PMLR,
16–18 Nov 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v155/chen21f.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v155/chen21f.html</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2019)</span>
<span class="ltx_bibblock">
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li,
Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng,
Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu,
Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen Change Loy, and
Dahua Lin.

</span>
<span class="ltx_bibblock">MMDetection: Open mmlab detection toolbox and benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.07155</em>, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cubuk et al. (2019)</span>
<span class="ltx_bibblock">
Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le.

</span>
<span class="ltx_bibblock">Autoaugment: Learning augmentation strategies from data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  113–123, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. (2009)</span>
<span class="ltx_bibblock">
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei.

</span>
<span class="ltx_bibblock">ImageNet: A Large-Scale Hierarchical Image Database.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CVPR09</em>, 2009.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eftekhar et al. (2021)</span>
<span class="ltx_bibblock">
Ainaz Eftekhar, Alexander Sax, Jitendra Malik, and Amir Zamir.

</span>
<span class="ltx_bibblock">Omnidata: A scalable pipeline for making multi-task mid-level vision
datasets from 3d scans.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pp.  10786–10796, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eigen &amp; Fergus (2015)</span>
<span class="ltx_bibblock">
David Eigen and Rob Fergus.

</span>
<span class="ltx_bibblock">Predicting depth, surface normals and semantic labels with a common
multi-scale convolutional architecture.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pp.  2650–2658, 2015.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eigen et al. (2014)</span>
<span class="ltx_bibblock">
David Eigen, Christian Puhrsch, and Rob Fergus.

</span>
<span class="ltx_bibblock">Depth map prediction from a single image using a multi-scale deep
network.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 27, 2014.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Everingham et al. (2010)</span>
<span class="ltx_bibblock">
M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman.

</span>
<span class="ltx_bibblock">The pascal visual object classes (VOC) challenge.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 88(2):303–338, June 2010.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geirhos et al. (2019)</span>
<span class="ltx_bibblock">
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A
Wichmann, and Wieland Brendel.

</span>
<span class="ltx_bibblock">Imagenet-trained CNNs are biased towards texture; increasing shape
bias improves accuracy and robustness.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Bygh9j09KX" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Bygh9j09KX</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geirhos et al. (2020)</span>
<span class="ltx_bibblock">
Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
Wieland Brendel, Matthias Bethge, and Felix A Wichmann.

</span>
<span class="ltx_bibblock">Shortcut learning in deep neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>, 2(11):665–673, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem et al. (2005a)</span>
<span class="ltx_bibblock">
Derek Hoiem, Alexei A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Automatic photo pop-up.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ACM SIGGRAPH 2005 Papers</em>, pp.  577–584.
2005a.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem et al. (2005b)</span>
<span class="ltx_bibblock">
Derek Hoiem, Alexei A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Geometric context from a single image.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Tenth IEEE International Conference on Computer Vision
(ICCV’05) Volume 1</em>, volume 1, pp.  654–661. IEEE, 2005b.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem et al. (2007)</span>
<span class="ltx_bibblock">
Derek Hoiem, Alexei A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Recovering surface layout from an image.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 75(1):151–172, 2007.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoiem et al. (2008)</span>
<span class="ltx_bibblock">
Derek Hoiem, Alexei A Efros, and Martial Hebert.

</span>
<span class="ltx_bibblock">Putting objects in perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 80(1):3–15, 2008.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaiswal et al. (2021)</span>
<span class="ltx_bibblock">
Ayush Jaiswal, Yue Wu, Pradeep Natarajan, and Premkumar Natarajan.

</span>
<span class="ltx_bibblock">Class-agnostic object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Winter Conference on
Applications of Computer Vision</em>, pp.  919–928, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2019)</span>
<span class="ltx_bibblock">
Yuqian Jiang, Nick Walker, Justin Hart, and Peter Stone.

</span>
<span class="ltx_bibblock">Open-world reasoning for service robots.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Automated
Planning and Scheduling</em>, volume 29, pp.  725–733, 2019.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joseph et al. (2021)</span>
<span class="ltx_bibblock">
K. J. Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N. Balasubramanian.

</span>
<span class="ltx_bibblock">Towards Open World Object Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv:2103.02603 [cs]</em>, May 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2103.02603" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2103.02603</a>.

</span>
<span class="ltx_bibblock">arXiv: 2103.02603.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kar et al. (2022)</span>
<span class="ltx_bibblock">
Oğuzhan Fatih Kar, Teresa Yeo, Andrei Atanov, and Amir Zamir.

</span>
<span class="ltx_bibblock">3d common corruptions and data augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  18963–18974, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2021)</span>
<span class="ltx_bibblock">
Dahun Kim, Tsung-Yi Lin, Anelia Angelova, In So Kweon, and Weicheng Kuo.

</span>
<span class="ltx_bibblock">Learning Open-World Object Proposals without Learning to
Classify.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv:2108.06753 [cs]</em>, August 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2108.06753" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2108.06753</a>.

</span>
<span class="ltx_bibblock">arXiv: 2108.06753.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konan et al. (2022)</span>
<span class="ltx_bibblock">
Sachin Konan, Kevin J Liang, and Li Yin.

</span>
<span class="ltx_bibblock">Extending one-stage detection with open-world proposals.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.02302</em>, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2014)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C. Lawrence Zitnick.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars
(eds.), <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ECCV</em>, pp.  740–755, 2014.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Bing Liu, Eric Robertson, Scott Grigsby, and Sahisnu Mazumder.

</span>
<span class="ltx_bibblock">Self-initiated open world learning for autonomous ai agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.11385</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2022)</span>
<span class="ltx_bibblock">
Yang Liu, Idil Esen Zulfikar, Jonathon Luiten, Achal Dave, Deva Ramanan,
Bastian Leibe, Aljoša Ošep, and Laura Leal-Taixé.

</span>
<span class="ltx_bibblock">Opening up open world tracking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  19045–19055, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maaz et al. (2022)</span>
<span class="ltx_bibblock">
Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad Shahbaz Khan, Rao Muhammad
Anwer, and Ming-Hsuan Yang.

</span>
<span class="ltx_bibblock">Class-agnostic object detection with multi-modal transformer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">17th European Conference on Computer Vision</em>. Springer,
2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minderer et al. (2022)</span>
<span class="ltx_bibblock">
Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk
Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa
Dehghani, Zhuoran Shen, et al.

</span>
<span class="ltx_bibblock">Simple open-vocabulary object detection with vision transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.06230</em>, 2022.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language
supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp. 8748–8763. PMLR, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl et al. (2021a)</span>
<span class="ltx_bibblock">
René Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Vision transformers for dense prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ArXiv preprint</em>, 2021a.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl et al. (2021b)</span>
<span class="ltx_bibblock">
René Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Vision transformers for dense prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">ICCV</em>, 2021b.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ranftl et al. (2022)</span>
<span class="ltx_bibblock">
René Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen
Koltun.

</span>
<span class="ltx_bibblock">Towards robust monocular depth estimation: Mixing datasets for
zero-shot cross-dataset transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 44(3), 2022.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al. (2015)</span>
<span class="ltx_bibblock">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.

</span>
<span class="ltx_bibblock">Faster R-CNN: Towards Real-Time Object Detection with
Region Proposal Networks.

</span>
<span class="ltx_bibblock">In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett
(eds.), <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volume 28. Curran Associates, Inc., 2015.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saito et al. (2021)</span>
<span class="ltx_bibblock">
Kuniaki Saito, Ping Hu, Trevor Darrell, and Kate Saenko.

</span>
<span class="ltx_bibblock">Learning to Detect Every Thing in an Open World.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv:2112.01698 [cs]</em>, December 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/2112.01698" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/2112.01698</a>.

</span>
<span class="ltx_bibblock">arXiv: 2112.01698 version: 1.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sauer &amp; Geiger (2021)</span>
<span class="ltx_bibblock">
Axel Sauer and Andreas Geiger.

</span>
<span class="ltx_bibblock">Counterfactual generative networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=BXewfAYMmJw" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=BXewfAYMmJw</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena et al. (2005)</span>
<span class="ltx_bibblock">
Ashutosh Saxena, Sung Chung, and Andrew Ng.

</span>
<span class="ltx_bibblock">Learning depth from single monocular images.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 18, 2005.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena et al. (2008a)</span>
<span class="ltx_bibblock">
Ashutosh Saxena, Sung H Chung, and Andrew Y Ng.

</span>
<span class="ltx_bibblock">3-d depth reconstruction from a single still image.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">International journal of computer vision</em>, 76(1):53–69, 2008a.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxena et al. (2008b)</span>
<span class="ltx_bibblock">
Ashutosh Saxena, Min Sun, and Andrew Y Ng.

</span>
<span class="ltx_bibblock">Make3d: Learning 3d scene structure from a single still image.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 31(5):824–840, 2008b.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi &amp; Malik (2000)</span>
<span class="ltx_bibblock">
Jianbo Shi and Jitendra Malik.

</span>
<span class="ltx_bibblock">Normalized cuts and image segmentation.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on pattern analysis and machine
intelligence</em>, 22(8):888–905, 2000.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sohn et al. (2020)</span>
<span class="ltx_bibblock">
Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang,
Colin A Raffel, Ekin Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li.

</span>
<span class="ltx_bibblock">Fixmatch: Simplifying semi-supervised learning with consistency and
confidence.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
33:596–608, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2019)</span>
<span class="ltx_bibblock">
Zhi Tian, Chunhua Shen, Hao Chen, and Tong He.

</span>
<span class="ltx_bibblock">FCOS: Fully convolutional one-stage object detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Computer Vision (ICCV)</em>, 2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Weiyao Wang, Matt Feiszli, Heng Wang, Jitendra Malik, and Du Tran.

</span>
<span class="ltx_bibblock">Open-world instance segmentation: Exploiting pseudo ground truth from
learned pairwise affinity.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  4422–4432, 2022.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang et al. (2022)</span>
<span class="ltx_bibblock">
Yongqin Xiang, Julian Chibane, Bharat Lal Bhatnagar, Bernt Schiele, Zeynep
Akata, and Gerard Pons-Moll.

</span>
<span class="ltx_bibblock">Any-shot gin: Generalizing implicit networks for reconstructing novel
classes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">2022 International Conference on 3D Vision (3DV)</em>. IEEE,
2022.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2020)</span>
<span class="ltx_bibblock">
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le.

</span>
<span class="ltx_bibblock">Self-training with noisy student improves imagenet classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition</em>, pp.  10687–10698, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie &amp; Tu (2015)</span>
<span class="ltx_bibblock">
Saining Xie and Zhuowen Tu.

</span>
<span class="ltx_bibblock">Holistically-nested edge detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pp.  1395–1403, 2015.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2021)</span>
<span class="ltx_bibblock">
Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, Lijuan Wang, Fangyun Wei, Xiang
Bai, and Zicheng Liu.

</span>
<span class="ltx_bibblock">End-to-end semi-supervised object detection with soft teacher.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</em>, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Zehao Yu, Songyou Peng, Michael Niemeyer, Torsten Sattler, and Andreas Geiger.

</span>
<span class="ltx_bibblock">Monosdf: Exploring monocular geometric cues for neural implicit
surface reconstruction.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv:2022.00665</em>, 2022.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zamir et al. (2020)</span>
<span class="ltx_bibblock">
Amir R Zamir, Alexander Sax, Nikhil Cheerla, Rohan Suri, Zhangjie Cao, Jitendra
Malik, and Leonidas J Guibas.

</span>
<span class="ltx_bibblock">Robust learning through cross-task consistency.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pp.  11197–11206, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2019)</span>
<span class="ltx_bibblock">
Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso,
and Antonio Torralba.

</span>
<span class="ltx_bibblock">Semantic understanding of scenes through the ade20k dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 127(3):302–321, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation details</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.3" class="ltx_p">GOOD uses OLN <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> as the architecture for both Phase-I and Phase-II training. OLN is built on top of Faster RCNN <cite class="ltx_cite ltx_citemacro_citep">(Ren et al., <a href="#bib.bib33" title="" class="ltx_ref">2015</a>)</cite>.
For open-world object detection, the classification heads are replaced with the objectness score prediction heads, i.e., predicting the centerness and IoU of each bounding box proposal at the two stages, respectively. We use the objectness score <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="\sqrt{\mathrm{centerness}\times\mathrm{IoU}}" display="inline"><semantics id="A1.p1.1.m1.1a"><msqrt id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mrow id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml"><mi id="A1.p1.1.m1.1.1.2.2" xref="A1.p1.1.m1.1.1.2.2.cmml">centerness</mi><mo lspace="0.222em" rspace="0.222em" id="A1.p1.1.m1.1.1.2.1" xref="A1.p1.1.m1.1.1.2.1.cmml">×</mo><mi id="A1.p1.1.m1.1.1.2.3" xref="A1.p1.1.m1.1.1.2.3.cmml">IoU</mi></mrow></msqrt><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><root id="A1.p1.1.m1.1.1a.cmml" xref="A1.p1.1.m1.1.1"></root><apply id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2"><times id="A1.p1.1.m1.1.1.2.1.cmml" xref="A1.p1.1.m1.1.1.2.1"></times><ci id="A1.p1.1.m1.1.1.2.2.cmml" xref="A1.p1.1.m1.1.1.2.2">centerness</ci><ci id="A1.p1.1.m1.1.1.2.3.cmml" xref="A1.p1.1.m1.1.1.2.3">IoU</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">\sqrt{\mathrm{centerness}\times\mathrm{IoU}}</annotation></semantics></math> for ranking the pseudo boxes and selecting the top <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">k</annotation></semantics></math> pseudo boxes per image.
The optimal <math id="A1.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p1.3.m3.1a"><mi id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><ci id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">k</annotation></semantics></math> choice for GOOD-Depth and GOOD-Normal is 1 and for SelfTrain-RGB is 3.</p>
</div>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.3" class="ltx_p">For Phase-I training, we trained the proposal network with loss as given in Eq. <a href="#S3.E2" title="In 3.1 open-world class-agnostic object detection problem ‣ 3 Method ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and used the SGD optimizer with an initial learning rate of 0.01 and batch size of 16 for 8 epochs.
For Phase-II training, unless otherwise stated, we trained the object detector with loss as given in Eq. <a href="#S3.E3" title="In 3.3 Pseudo labeling method ‣ 3 Method ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and used SGD optimizer with an initial learning rate of <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A1.p2.1.m1.1a"><mn id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><cn type="float" id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">0.01</annotation></semantics></math> and batch size of <math id="A1.p2.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.p2.2.m2.1a"><mn id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><cn type="integer" id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">16</annotation></semantics></math> for <math id="A1.p2.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.p2.3.m3.1a"><mn id="A1.p2.3.m3.1.1" xref="A1.p2.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.p2.3.m3.1b"><cn type="integer" id="A1.p2.3.m3.1.1.cmml" xref="A1.p2.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.3.m3.1c">16</annotation></semantics></math> epochs with AutoAugment.
For GOOD-Both, we merge the pseudo boxes generated by object proposal networks separately trained on depth and normal maps by filtering out the overlapping boxes. Specifically, if the IoU of two pseudo boxes is larger than 0.5, they are seen as overlapping with each other, and the one with lower objectness score will be filtered out. For other ensembling experiments, if not specified, pseudo boxes are also merged as described above.</p>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.2" class="ltx_p">We use the DPT-Hybrid models from Omnidata repository <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> for off-the-shelf inference of geometric cues. The DPT-Hybrid models <cite class="ltx_cite ltx_citemacro_citep">(Ranftl et al., <a href="#bib.bib30" title="" class="ltx_ref">2021a</a>)</cite> have a hybrid architecture of attention layers and convolutional layers. They are trained on the Omnidata Starter Datset <cite class="ltx_cite ltx_citemacro_citep">(Eftekhar et al., <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite> for one week with 2D and 3D data augmentations <cite class="ltx_cite ltx_citemacro_citep">(Kar et al., <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>, and one week with cross-task consistency <cite class="ltx_cite ltx_citemacro_citep">(Zamir et al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> on 4 V100 GPUs. To infer on RGB images, we first pad images to sizes divisible by 32 without resizing, then feed them to the DPT-Hybrid model. Note although the original models are trained on 384<math id="A1.p3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.p3.1.m1.1a"><mo id="A1.p3.1.m1.1.1" xref="A1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.p3.1.m1.1b"><times id="A1.p3.1.m1.1.1.cmml" xref="A1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.1.m1.1c">\times</annotation></semantics></math>384 image patches, we find that inferring on the original resolution of COCO produces better visual results than on the resolution of 384<math id="A1.p3.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.p3.2.m2.1a"><mo id="A1.p3.2.m2.1.1" xref="A1.p3.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.p3.2.m2.1b"><times id="A1.p3.2.m2.1.1.cmml" xref="A1.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.2.m2.1c">\times</annotation></semantics></math>384.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>More benchmarks</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We further evaluate our approach on more benchmarks. Specifically, we evaluated the baselines and GOOD on the cross-category benchmark LVIS COCO to non-COCO and cross-dataset benchmark COCO to UVO. The results are shown in Table <a href="#A2.T5" title="Table 5 ‣ Appendix B More benchmarks ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. As expected, the performance gains are smaller than those observsed on benchmarks with smaller number of base classes such as COCO VOC to non-VOC. But still, GOOD surpasses all the state-of-the-art RGB-based methods. This shows that even in extreme conditions when the number of base classes is large, GOOD can still be helpful in improving the open-world performance.</p>
</div>
<figure id="A2.T5" class="ltx_table">
<div id="A2.T5.11.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:116.1pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,3.0pt) scale(0.95,0.95) ;">
<div id="A2.T5.11.11.11" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:121.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-68.7pt,20.8pt) scale(0.74316562498636,0.74316562498636) ;">
<table id="A2.T5.11.11.11.11" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T5.2.2.2.2.2" class="ltx_tr">
<td id="A2.T5.2.2.2.2.2.3" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="A2.T5.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="5"><span id="A2.T5.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">LVIS COCO<math id="A2.T5.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A2.T5.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A2.T5.1.1.1.1.1.1.1.m1.1.1" xref="A2.T5.1.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.T5.1.1.1.1.1.1.1.m1.1b"><ci id="A2.T5.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A2.T5.1.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-COCO</span></td>
<td id="A2.T5.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="A2.T5.2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">COCO<math id="A2.T5.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A2.T5.2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="A2.T5.2.2.2.2.2.2.1.m1.1.1" xref="A2.T5.2.2.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A2.T5.2.2.2.2.2.2.1.m1.1b"><ci id="A2.T5.2.2.2.2.2.2.1.m1.1.1.cmml" xref="A2.T5.2.2.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.2.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>UVO</span></td>
</tr>
<tr id="A2.T5.11.11.11.11.11" class="ltx_tr">
<td id="A2.T5.11.11.11.11.11.10" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Method</td>
<td id="A2.T5.3.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="A2.T5.3.3.3.3.3.1.1" class="ltx_sub"><span id="A2.T5.3.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="A2.T5.4.4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="A2.T5.4.4.4.4.4.2.1" class="ltx_sub"><span id="A2.T5.4.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</td>
<td id="A2.T5.5.5.5.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.5.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A2.T5.5.5.5.5.5.3.m1.1a"><mmultiscripts id="A2.T5.5.5.5.5.5.3.m1.1.1" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"><mi id="A2.T5.5.5.5.5.5.3.m1.1.1.2.2" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.5.5.5.5.5.3.m1.1.1a" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.5.5.5.5.5.3.m1.1.1b" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="A2.T5.5.5.5.5.5.3.m1.1.1.3" xref="A2.T5.5.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="A2.T5.5.5.5.5.5.3.m1.1.1.2.3" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="A2.T5.5.5.5.5.5.3.m1.1.1c" xref="A2.T5.5.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.5.5.5.5.5.3.m1.1b"><apply id="A2.T5.5.5.5.5.5.3.m1.1.1.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.5.5.5.5.5.3.m1.1.1.1.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="A2.T5.5.5.5.5.5.3.m1.1.1.2.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.5.5.5.5.5.3.m1.1.1.2.1.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.5.5.5.5.5.3.m1.1.1.2.2.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.5.5.5.5.5.3.m1.1.1.2.3.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1.2.3">𝑁</ci></apply><ci id="A2.T5.5.5.5.5.5.3.m1.1.1.3.cmml" xref="A2.T5.5.5.5.5.5.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.5.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</td>
<td id="A2.T5.6.6.6.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.6.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A2.T5.6.6.6.6.6.4.m1.1a"><mmultiscripts id="A2.T5.6.6.6.6.6.4.m1.1.1" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"><mi id="A2.T5.6.6.6.6.6.4.m1.1.1.2.2" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.6.6.6.6.6.4.m1.1.1a" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.6.6.6.6.6.4.m1.1.1b" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="A2.T5.6.6.6.6.6.4.m1.1.1.3" xref="A2.T5.6.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="A2.T5.6.6.6.6.6.4.m1.1.1.2.3" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="A2.T5.6.6.6.6.6.4.m1.1.1c" xref="A2.T5.6.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.6.6.6.6.6.4.m1.1b"><apply id="A2.T5.6.6.6.6.6.4.m1.1.1.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.6.6.6.6.6.4.m1.1.1.1.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="A2.T5.6.6.6.6.6.4.m1.1.1.2.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.6.6.6.6.6.4.m1.1.1.2.1.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.6.6.6.6.6.4.m1.1.1.2.2.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.6.6.6.6.6.4.m1.1.1.2.3.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1.2.3">𝑁</ci></apply><ci id="A2.T5.6.6.6.6.6.4.m1.1.1.3.cmml" xref="A2.T5.6.6.6.6.6.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.6.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</td>
<td id="A2.T5.7.7.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.7.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A2.T5.7.7.7.7.7.5.m1.1a"><mmultiscripts id="A2.T5.7.7.7.7.7.5.m1.1.1" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"><mi id="A2.T5.7.7.7.7.7.5.m1.1.1.2.2" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.7.7.7.7.7.5.m1.1.1a" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.7.7.7.7.7.5.m1.1.1b" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="A2.T5.7.7.7.7.7.5.m1.1.1.3" xref="A2.T5.7.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="A2.T5.7.7.7.7.7.5.m1.1.1.2.3" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="A2.T5.7.7.7.7.7.5.m1.1.1c" xref="A2.T5.7.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.7.7.7.7.7.5.m1.1b"><apply id="A2.T5.7.7.7.7.7.5.m1.1.1.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.7.7.7.7.7.5.m1.1.1.1.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="A2.T5.7.7.7.7.7.5.m1.1.1.2.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.7.7.7.7.7.5.m1.1.1.2.1.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.7.7.7.7.7.5.m1.1.1.2.2.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.7.7.7.7.7.5.m1.1.1.2.3.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1.2.3">𝑁</ci></apply><ci id="A2.T5.7.7.7.7.7.5.m1.1.1.3.cmml" xref="A2.T5.7.7.7.7.7.5.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.7.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</td>
<td id="A2.T5.8.8.8.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<sub id="A2.T5.8.8.8.8.8.6.1" class="ltx_sub"><span id="A2.T5.8.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</td>
<td id="A2.T5.9.9.9.9.9.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.9.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="A2.T5.9.9.9.9.9.7.m1.1a"><mmultiscripts id="A2.T5.9.9.9.9.9.7.m1.1.1" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"><mi id="A2.T5.9.9.9.9.9.7.m1.1.1.2.2" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.9.9.9.9.9.7.m1.1.1a" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.9.9.9.9.9.7.m1.1.1b" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="A2.T5.9.9.9.9.9.7.m1.1.1.3" xref="A2.T5.9.9.9.9.9.7.m1.1.1.3.cmml">s</mi><mi id="A2.T5.9.9.9.9.9.7.m1.1.1.2.3" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="A2.T5.9.9.9.9.9.7.m1.1.1c" xref="A2.T5.9.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.9.9.9.9.9.7.m1.1b"><apply id="A2.T5.9.9.9.9.9.7.m1.1.1.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.9.9.9.9.9.7.m1.1.1.1.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="A2.T5.9.9.9.9.9.7.m1.1.1.2.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.9.9.9.9.9.7.m1.1.1.2.1.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.9.9.9.9.9.7.m1.1.1.2.2.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.9.9.9.9.9.7.m1.1.1.2.3.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1.2.3">𝐴</ci></apply><ci id="A2.T5.9.9.9.9.9.7.m1.1.1.3.cmml" xref="A2.T5.9.9.9.9.9.7.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.9.9.9.9.9.7.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</td>
<td id="A2.T5.10.10.10.10.10.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">AR<math id="A2.T5.10.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="A2.T5.10.10.10.10.10.8.m1.1a"><mmultiscripts id="A2.T5.10.10.10.10.10.8.m1.1.1" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"><mi id="A2.T5.10.10.10.10.10.8.m1.1.1.2.2" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.10.10.10.10.10.8.m1.1.1a" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.10.10.10.10.10.8.m1.1.1b" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="A2.T5.10.10.10.10.10.8.m1.1.1.3" xref="A2.T5.10.10.10.10.10.8.m1.1.1.3.cmml">m</mi><mi id="A2.T5.10.10.10.10.10.8.m1.1.1.2.3" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="A2.T5.10.10.10.10.10.8.m1.1.1c" xref="A2.T5.10.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.10.10.10.10.10.8.m1.1b"><apply id="A2.T5.10.10.10.10.10.8.m1.1.1.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.10.10.10.10.10.8.m1.1.1.1.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="A2.T5.10.10.10.10.10.8.m1.1.1.2.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.10.10.10.10.10.8.m1.1.1.2.1.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.10.10.10.10.10.8.m1.1.1.2.2.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.10.10.10.10.10.8.m1.1.1.2.3.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1.2.3">𝐴</ci></apply><ci id="A2.T5.10.10.10.10.10.8.m1.1.1.3.cmml" xref="A2.T5.10.10.10.10.10.8.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.10.10.10.10.10.8.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</td>
<td id="A2.T5.11.11.11.11.11.9" class="ltx_td ltx_align_left ltx_border_t">AR<math id="A2.T5.11.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="A2.T5.11.11.11.11.11.9.m1.1a"><mmultiscripts id="A2.T5.11.11.11.11.11.9.m1.1.1" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"><mi id="A2.T5.11.11.11.11.11.9.m1.1.1.2.2" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="A2.T5.11.11.11.11.11.9.m1.1.1a" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="A2.T5.11.11.11.11.11.9.m1.1.1b" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="A2.T5.11.11.11.11.11.9.m1.1.1.3" xref="A2.T5.11.11.11.11.11.9.m1.1.1.3.cmml">l</mi><mi id="A2.T5.11.11.11.11.11.9.m1.1.1.2.3" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.3.cmml">A</mi><mrow id="A2.T5.11.11.11.11.11.9.m1.1.1c" xref="A2.T5.11.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A2.T5.11.11.11.11.11.9.m1.1b"><apply id="A2.T5.11.11.11.11.11.9.m1.1.1.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.11.11.11.11.11.9.m1.1.1.1.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="A2.T5.11.11.11.11.11.9.m1.1.1.2.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A2.T5.11.11.11.11.11.9.m1.1.1.2.1.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A2.T5.11.11.11.11.11.9.m1.1.1.2.2.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="A2.T5.11.11.11.11.11.9.m1.1.1.2.3.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1.2.3">𝐴</ci></apply><ci id="A2.T5.11.11.11.11.11.9.m1.1.1.3.cmml" xref="A2.T5.11.11.11.11.11.9.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T5.11.11.11.11.11.9.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</td>
</tr>
<tr id="A2.T5.11.11.11.11.12.1" class="ltx_tr">
<td id="A2.T5.11.11.11.11.12.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FRCNN (cls-agn)</td>
<td id="A2.T5.11.11.11.11.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.6</td>
<td id="A2.T5.11.11.11.11.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.0</td>
<td id="A2.T5.11.11.11.11.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14.9</td>
<td id="A2.T5.11.11.11.11.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.7</td>
<td id="A2.T5.11.11.11.11.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">36.2</td>
<td id="A2.T5.11.11.11.11.12.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.3</td>
<td id="A2.T5.11.11.11.11.12.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">22.2</td>
<td id="A2.T5.11.11.11.11.12.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.3</td>
<td id="A2.T5.11.11.11.11.12.1.10" class="ltx_td ltx_align_left ltx_border_t">52.0</td>
</tr>
<tr id="A2.T5.11.11.11.11.13.2" class="ltx_tr">
<td id="A2.T5.11.11.11.11.13.2.1" class="ltx_td ltx_align_left ltx_border_r">OLN <cite class="ltx_cite ltx_citemacro_citep">(Kim et al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="A2.T5.11.11.11.11.13.2.2" class="ltx_td ltx_align_left ltx_border_r">32.2</td>
<td id="A2.T5.11.11.11.11.13.2.3" class="ltx_td ltx_align_left ltx_border_r">27.4</td>
<td id="A2.T5.11.11.11.11.13.2.4" class="ltx_td ltx_align_left ltx_border_r">17.9</td>
<td id="A2.T5.11.11.11.11.13.2.5" class="ltx_td ltx_align_left ltx_border_r">44.7</td>
<td id="A2.T5.11.11.11.11.13.2.6" class="ltx_td ltx_align_left ltx_border_r">53.1</td>
<td id="A2.T5.11.11.11.11.13.2.7" class="ltx_td ltx_align_left ltx_border_r">49.2</td>
<td id="A2.T5.11.11.11.11.13.2.8" class="ltx_td ltx_align_left ltx_border_r">35.0</td>
<td id="A2.T5.11.11.11.11.13.2.9" class="ltx_td ltx_align_left ltx_border_r">48.7</td>
<td id="A2.T5.11.11.11.11.13.2.10" class="ltx_td ltx_align_left">55.1</td>
</tr>
<tr id="A2.T5.11.11.11.11.14.3" class="ltx_tr">
<td id="A2.T5.11.11.11.11.14.3.1" class="ltx_td ltx_align_left ltx_border_r">GGN <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a href="#bib.bib42" title="" class="ltx_ref">2022</a>)</cite>
</td>
<td id="A2.T5.11.11.11.11.14.3.2" class="ltx_td ltx_align_left ltx_border_r">27.1</td>
<td id="A2.T5.11.11.11.11.14.3.3" class="ltx_td ltx_align_left ltx_border_r">22.5</td>
<td id="A2.T5.11.11.11.11.14.3.4" class="ltx_td ltx_align_left ltx_border_r">15.7</td>
<td id="A2.T5.11.11.11.11.14.3.5" class="ltx_td ltx_align_left ltx_border_r">35.5</td>
<td id="A2.T5.11.11.11.11.14.3.6" class="ltx_td ltx_align_left ltx_border_r">38.4</td>
<td id="A2.T5.11.11.11.11.14.3.7" class="ltx_td ltx_align_left ltx_border_r">45.6</td>
<td id="A2.T5.11.11.11.11.14.3.8" class="ltx_td ltx_align_left ltx_border_r">25.6</td>
<td id="A2.T5.11.11.11.11.14.3.9" class="ltx_td ltx_align_left ltx_border_r">43.2</td>
<td id="A2.T5.11.11.11.11.14.3.10" class="ltx_td ltx_align_left">54.9</td>
</tr>
<tr id="A2.T5.11.11.11.11.15.4" class="ltx_tr">
<td id="A2.T5.11.11.11.11.15.4.1" class="ltx_td ltx_align_left ltx_border_r">SelfTrain-RGB</td>
<td id="A2.T5.11.11.11.11.15.4.2" class="ltx_td ltx_align_left ltx_border_r">32.6</td>
<td id="A2.T5.11.11.11.11.15.4.3" class="ltx_td ltx_align_left ltx_border_r">28.3</td>
<td id="A2.T5.11.11.11.11.15.4.4" class="ltx_td ltx_align_left ltx_border_r">19.0</td>
<td id="A2.T5.11.11.11.11.15.4.5" class="ltx_td ltx_align_left ltx_border_r">45.7</td>
<td id="A2.T5.11.11.11.11.15.4.6" class="ltx_td ltx_align_left ltx_border_r">52.2</td>
<td id="A2.T5.11.11.11.11.15.4.7" class="ltx_td ltx_align_left ltx_border_r">48.7</td>
<td id="A2.T5.11.11.11.11.15.4.8" class="ltx_td ltx_align_left ltx_border_r">35.8</td>
<td id="A2.T5.11.11.11.11.15.4.9" class="ltx_td ltx_align_left ltx_border_r">48.8</td>
<td id="A2.T5.11.11.11.11.15.4.10" class="ltx_td ltx_align_left">53.5</td>
</tr>
<tr id="A2.T5.11.11.11.11.16.5" class="ltx_tr">
<td id="A2.T5.11.11.11.11.16.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Depth</td>
<td id="A2.T5.11.11.11.11.16.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.8</td>
<td id="A2.T5.11.11.11.11.16.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.3</td>
<td id="A2.T5.11.11.11.11.16.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.3</td>
<td id="A2.T5.11.11.11.11.16.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">46.8</td>
<td id="A2.T5.11.11.11.11.16.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A2.T5.11.11.11.11.16.5.6.1" class="ltx_text ltx_font_bold">54.1</span></td>
<td id="A2.T5.11.11.11.11.16.5.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A2.T5.11.11.11.11.16.5.7.1" class="ltx_text ltx_font_bold">50.3</span></td>
<td id="A2.T5.11.11.11.11.16.5.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.6</td>
<td id="A2.T5.11.11.11.11.16.5.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.9</td>
<td id="A2.T5.11.11.11.11.16.5.10" class="ltx_td ltx_align_left ltx_border_t"><span id="A2.T5.11.11.11.11.16.5.10.1" class="ltx_text ltx_font_bold">56.4</span></td>
</tr>
<tr id="A2.T5.11.11.11.11.17.6" class="ltx_tr">
<td id="A2.T5.11.11.11.11.17.6.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Normal</td>
<td id="A2.T5.11.11.11.11.17.6.2" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.2.1" class="ltx_text ltx_font_bold">33.4</span></td>
<td id="A2.T5.11.11.11.11.17.6.3" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.3.1" class="ltx_text ltx_font_bold">29.2</span></td>
<td id="A2.T5.11.11.11.11.17.6.4" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.4.1" class="ltx_text ltx_font_bold">19.3</span></td>
<td id="A2.T5.11.11.11.11.17.6.5" class="ltx_td ltx_align_left ltx_border_r"><span id="A2.T5.11.11.11.11.17.6.5.1" class="ltx_text ltx_font_bold">49.8</span></td>
<td id="A2.T5.11.11.11.11.17.6.6" class="ltx_td ltx_align_left ltx_border_r">53.3</td>
<td id="A2.T5.11.11.11.11.17.6.7" class="ltx_td ltx_align_left ltx_border_r">49.8</td>
<td id="A2.T5.11.11.11.11.17.6.8" class="ltx_td ltx_align_left ltx_border_r">35.8</td>
<td id="A2.T5.11.11.11.11.17.6.9" class="ltx_td ltx_align_left ltx_border_r">50.0</td>
<td id="A2.T5.11.11.11.11.17.6.10" class="ltx_td ltx_align_left">55.0</td>
</tr>
<tr id="A2.T5.11.11.11.11.18.7" class="ltx_tr">
<td id="A2.T5.11.11.11.11.18.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both</td>
<td id="A2.T5.11.11.11.11.18.7.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">33.2</td>
<td id="A2.T5.11.11.11.11.18.7.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">29.0</td>
<td id="A2.T5.11.11.11.11.18.7.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">19.0</td>
<td id="A2.T5.11.11.11.11.18.7.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">47.7</td>
<td id="A2.T5.11.11.11.11.18.7.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">53.0</td>
<td id="A2.T5.11.11.11.11.18.7.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A2.T5.11.11.11.11.18.7.7.1" class="ltx_text ltx_font_bold">50.3</span></td>
<td id="A2.T5.11.11.11.11.18.7.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A2.T5.11.11.11.11.18.7.8.1" class="ltx_text ltx_font_bold">36.1</span></td>
<td id="A2.T5.11.11.11.11.18.7.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A2.T5.11.11.11.11.18.7.9.1" class="ltx_text ltx_font_bold">50.2</span></td>
<td id="A2.T5.11.11.11.11.18.7.10" class="ltx_td ltx_align_left ltx_border_bb">55.4</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="A2.T5.13.1" class="ltx_text ltx_font_bold">More benchmarks.</span> The same methods in Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Detecting unknown objects in an open world ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> are compared. </figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>More ablation studies</h2>

<figure id="A3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x6.png" id="A3.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Choice of ensembling geometric cues.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x7.png" id="A3.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Fusing inputs: whether to use RGB.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x8.png" id="A3.F6.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="237" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Ensemble pseudo boxes: whether to use RGB.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/appendix/pseudo_boxes_rgb_depth_normal_large_legend.png" id="A3.F6.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="305" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Histograms of top1 pseudo box sizes from models trained on COCO VOC with different modalities.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="A3.F6.2.1" class="ltx_text ltx_font_bold">More ablation studies.</span> </figcaption>
</figure>
<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Ensembling ways of geometric cues</h3>

<div id="A3.SS1.p1" class="ltx_para ltx_noindent">
<p id="A3.SS1.p1.1" class="ltx_p">There are two possible ways to ensemble geometric cues: (1) Stack the two geometric cues together and train a single object proposal network on these stacked inputs in Phase-I; (2) Train two object proposal networks and extract pseudo boxes separately, then merge them into a single pseudo box pool for Phase-II training. The details of the merging process is described in Appendix <a href="#A1" title="Appendix A Implementation details ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. We conduct ablation studies on these two methods. From Figure <a href="#A3.F6.sf1" title="In Figure 6 ‣ Appendix C More ablation studies ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>, we demonstrate that empirically, ensembling pseudo labels is slightly better than using stacked inputs for Phase-I training. Throughout the paper, we use the pseudo label ensembling for GOOD-Both.</p>
</div>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>On incorporating RGB in Phase-I</h3>

<div id="A3.SS2.p1" class="ltx_para ltx_noindent">
<p id="A3.SS2.p1.1" class="ltx_p">It is natural to think of incorporating RGB in Phase-I.
To do so, we can also consider the two ways for ensembling geometric cues.
If we stack RGB with geometric cues to train the proposal network, the model will tend to make more use of RGB to optimize the target localization loss. This is because RGB is a much stronger input signal than geometric cues in the closed-world setup — AR@100<sub id="A3.SS2.p1.1.1" class="ltx_sub"><span id="A3.SS2.p1.1.1.1" class="ltx_text ltx_font_italic">base</span></sub> is 58.3 for RGB inputs alone and 44.9 when stacking depth and normals on COCO VOC classes. In the extreme case, the model can even completely ignore geometric cues. This reliance on RGB inputs prevents the model from making the best use of geometric cues to discover novel objects in Phase-I, which is crucial for open-world object detection.
As shown in Figure <a href="#A3.F6.sf2" title="In Figure 6 ‣ Appendix C More ablation studies ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>, stacking RGB with geometric cues leads to inferior performance across many benchmarks.</p>
</div>
<div id="A3.SS2.p2" class="ltx_para ltx_noindent">
<p id="A3.SS2.p2.2" class="ltx_p">Alternatively, we can train a separate object proposal on RGB inputs, extract pseudo boxes, and merge them with those extracted from models trained on geometric cues. We can name this method “GOOD-All”. In Figure <a href="#A3.F6.sf3" title="In Figure 6 ‣ Appendix C More ablation studies ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(c)</span></a>, we compare GOOD-All with GOOD-Both and find that adding pseudo boxes from RGB (i.e., GOOD-All) either leads to no performance gains or even worsens the performance on benchmarks like VOC to ADE20K. To understand this, we note that object proposal networks trained on RGB favor smaller detection boxes, as evidenced in our visualizations (Figure <a href="#A5.F10" title="Figure 10 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, <a href="#A5.F11" title="Figure 11 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>) and more quantitatively in histograms (Figure <a href="#A3.F6.sf4" title="In Figure 6 ‣ Appendix C More ablation studies ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(d)</span></a>). These smaller detection boxes can either be small objects or just textures and parts of larger objects, which can potentially hurt the performance of the final detector to detect large objects. This is consistent with our observations in Table <a href="#A3.T6" title="Table 6 ‣ C.2 On incorporating RGB in Phase-I ‣ Appendix C More ablation studies ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Compared to GOOD-Both, the gains in AR<math id="A3.SS2.p2.1.m1.1" class="ltx_Math" alttext="{}_{N(A)}^{s}" display="inline"><semantics id="A3.SS2.p2.1.m1.1a"><mmultiscripts id="A3.SS2.p2.1.m1.1.2" xref="A3.SS2.p2.1.m1.1.2.cmml"><mi id="A3.SS2.p2.1.m1.1.2.2.2" xref="A3.SS2.p2.1.m1.1.2.2.2.cmml"></mi><mprescripts id="A3.SS2.p2.1.m1.1.2a" xref="A3.SS2.p2.1.m1.1.2.cmml"></mprescripts><mrow id="A3.SS2.p2.1.m1.1.2b" xref="A3.SS2.p2.1.m1.1.2.cmml"></mrow><mi id="A3.SS2.p2.1.m1.1.2.3" xref="A3.SS2.p2.1.m1.1.2.3.cmml">s</mi><mrow id="A3.SS2.p2.1.m1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml"><mi id="A3.SS2.p2.1.m1.1.1.1.3" xref="A3.SS2.p2.1.m1.1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="A3.SS2.p2.1.m1.1.1.1.2" xref="A3.SS2.p2.1.m1.1.1.1.2.cmml">​</mo><mrow id="A3.SS2.p2.1.m1.1.1.1.4.2" xref="A3.SS2.p2.1.m1.1.1.1.cmml"><mo stretchy="false" id="A3.SS2.p2.1.m1.1.1.1.4.2.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml">(</mo><mi id="A3.SS2.p2.1.m1.1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.1.cmml">A</mi><mo stretchy="false" id="A3.SS2.p2.1.m1.1.1.1.4.2.2" xref="A3.SS2.p2.1.m1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="A3.SS2.p2.1.m1.1.2c" xref="A3.SS2.p2.1.m1.1.2.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.1.m1.1b"><apply id="A3.SS2.p2.1.m1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.1.m1.1.2.1.cmml" xref="A3.SS2.p2.1.m1.1.2">superscript</csymbol><apply id="A3.SS2.p2.1.m1.1.2.2.cmml" xref="A3.SS2.p2.1.m1.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.1.m1.1.2.2.1.cmml" xref="A3.SS2.p2.1.m1.1.2">subscript</csymbol><csymbol cd="latexml" id="A3.SS2.p2.1.m1.1.2.2.2.cmml" xref="A3.SS2.p2.1.m1.1.2.2.2">absent</csymbol><apply id="A3.SS2.p2.1.m1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1"><times id="A3.SS2.p2.1.m1.1.1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.1.1.2"></times><ci id="A3.SS2.p2.1.m1.1.1.1.3.cmml" xref="A3.SS2.p2.1.m1.1.1.1.3">𝑁</ci><ci id="A3.SS2.p2.1.m1.1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1.1">𝐴</ci></apply></apply><ci id="A3.SS2.p2.1.m1.1.2.3.cmml" xref="A3.SS2.p2.1.m1.1.2.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.1.m1.1c">{}_{N(A)}^{s}</annotation></semantics></math> are usually too small to compensate for the losses in AR<math id="A3.SS2.p2.2.m2.1" class="ltx_Math" alttext="{}_{N(A)}^{l}" display="inline"><semantics id="A3.SS2.p2.2.m2.1a"><mmultiscripts id="A3.SS2.p2.2.m2.1.2" xref="A3.SS2.p2.2.m2.1.2.cmml"><mi id="A3.SS2.p2.2.m2.1.2.2.2" xref="A3.SS2.p2.2.m2.1.2.2.2.cmml"></mi><mprescripts id="A3.SS2.p2.2.m2.1.2a" xref="A3.SS2.p2.2.m2.1.2.cmml"></mprescripts><mrow id="A3.SS2.p2.2.m2.1.2b" xref="A3.SS2.p2.2.m2.1.2.cmml"></mrow><mi id="A3.SS2.p2.2.m2.1.2.3" xref="A3.SS2.p2.2.m2.1.2.3.cmml">l</mi><mrow id="A3.SS2.p2.2.m2.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml"><mi id="A3.SS2.p2.2.m2.1.1.1.3" xref="A3.SS2.p2.2.m2.1.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="A3.SS2.p2.2.m2.1.1.1.2" xref="A3.SS2.p2.2.m2.1.1.1.2.cmml">​</mo><mrow id="A3.SS2.p2.2.m2.1.1.1.4.2" xref="A3.SS2.p2.2.m2.1.1.1.cmml"><mo stretchy="false" id="A3.SS2.p2.2.m2.1.1.1.4.2.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml">(</mo><mi id="A3.SS2.p2.2.m2.1.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.1.cmml">A</mi><mo stretchy="false" id="A3.SS2.p2.2.m2.1.1.1.4.2.2" xref="A3.SS2.p2.2.m2.1.1.1.cmml">)</mo></mrow></mrow><mrow id="A3.SS2.p2.2.m2.1.2c" xref="A3.SS2.p2.2.m2.1.2.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.2.m2.1b"><apply id="A3.SS2.p2.2.m2.1.2.cmml" xref="A3.SS2.p2.2.m2.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.2.m2.1.2.1.cmml" xref="A3.SS2.p2.2.m2.1.2">superscript</csymbol><apply id="A3.SS2.p2.2.m2.1.2.2.cmml" xref="A3.SS2.p2.2.m2.1.2"><csymbol cd="ambiguous" id="A3.SS2.p2.2.m2.1.2.2.1.cmml" xref="A3.SS2.p2.2.m2.1.2">subscript</csymbol><csymbol cd="latexml" id="A3.SS2.p2.2.m2.1.2.2.2.cmml" xref="A3.SS2.p2.2.m2.1.2.2.2">absent</csymbol><apply id="A3.SS2.p2.2.m2.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1"><times id="A3.SS2.p2.2.m2.1.1.1.2.cmml" xref="A3.SS2.p2.2.m2.1.1.1.2"></times><ci id="A3.SS2.p2.2.m2.1.1.1.3.cmml" xref="A3.SS2.p2.2.m2.1.1.1.3">𝑁</ci><ci id="A3.SS2.p2.2.m2.1.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1.1">𝐴</ci></apply></apply><ci id="A3.SS2.p2.2.m2.1.2.3.cmml" xref="A3.SS2.p2.2.m2.1.2.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.2.m2.1c">{}_{N(A)}^{l}</annotation></semantics></math>, leading to the inferior overall performance of GOOD-All.</p>
</div>
<figure id="A3.T6" class="ltx_table">
<div id="A3.T6.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:76.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,2.0pt) scale(0.95,0.95) ;">
<div id="A3.T6.11.11" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:80pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(19.9pt,-4.0pt) scale(1.11103914474269,1.11103914474269) ;">
<table id="A3.T6.11.11.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T6.2.2.2.2" class="ltx_tr">
<th id="A3.T6.2.2.2.2.3" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="A3.T6.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="5"><span id="A3.T6.1.1.1.1.1.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T6.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T6.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A3.T6.1.1.1.1.1.1.m1.1.1" xref="A3.T6.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.T6.1.1.1.1.1.1.m1.1b"><ci id="A3.T6.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T6.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-VOC</span></th>
<th id="A3.T6.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="A3.T6.2.2.2.2.2.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T6.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T6.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="A3.T6.2.2.2.2.2.1.m1.1.1" xref="A3.T6.2.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.T6.2.2.2.2.2.1.m1.1b"><ci id="A3.T6.2.2.2.2.2.1.m1.1.1.cmml" xref="A3.T6.2.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></th>
</tr>
<tr id="A3.T6.11.11.11.11" class="ltx_tr">
<th id="A3.T6.11.11.11.11.10" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Method</th>
<th id="A3.T6.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T6.3.3.3.3.1.1" class="ltx_sub"><span id="A3.T6.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T6.4.4.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T6.4.4.4.4.2.1" class="ltx_sub"><span id="A3.T6.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="A3.T6.5.5.5.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A3.T6.5.5.5.5.3.m1.1a"><mmultiscripts id="A3.T6.5.5.5.5.3.m1.1.1" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"><mi id="A3.T6.5.5.5.5.3.m1.1.1.2.2" xref="A3.T6.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.5.5.5.5.3.m1.1.1a" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.5.5.5.5.3.m1.1.1b" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="A3.T6.5.5.5.5.3.m1.1.1.3" xref="A3.T6.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="A3.T6.5.5.5.5.3.m1.1.1.2.3" xref="A3.T6.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T6.5.5.5.5.3.m1.1.1c" xref="A3.T6.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.5.5.5.5.3.m1.1b"><apply id="A3.T6.5.5.5.5.3.m1.1.1.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.5.5.5.5.3.m1.1.1.1.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="A3.T6.5.5.5.5.3.m1.1.1.2.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.5.5.5.5.3.m1.1.1.2.1.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.5.5.5.5.3.m1.1.1.2.2.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.5.5.5.5.3.m1.1.1.2.3.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1.2.3">𝑁</ci></apply><ci id="A3.T6.5.5.5.5.3.m1.1.1.3.cmml" xref="A3.T6.5.5.5.5.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="A3.T6.6.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A3.T6.6.6.6.6.4.m1.1a"><mmultiscripts id="A3.T6.6.6.6.6.4.m1.1.1" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"><mi id="A3.T6.6.6.6.6.4.m1.1.1.2.2" xref="A3.T6.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.6.6.6.6.4.m1.1.1a" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.6.6.6.6.4.m1.1.1b" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="A3.T6.6.6.6.6.4.m1.1.1.3" xref="A3.T6.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="A3.T6.6.6.6.6.4.m1.1.1.2.3" xref="A3.T6.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T6.6.6.6.6.4.m1.1.1c" xref="A3.T6.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.6.6.6.6.4.m1.1b"><apply id="A3.T6.6.6.6.6.4.m1.1.1.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.6.6.6.6.4.m1.1.1.1.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="A3.T6.6.6.6.6.4.m1.1.1.2.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.6.6.6.6.4.m1.1.1.2.1.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.6.6.6.6.4.m1.1.1.2.2.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.6.6.6.6.4.m1.1.1.2.3.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1.2.3">𝑁</ci></apply><ci id="A3.T6.6.6.6.6.4.m1.1.1.3.cmml" xref="A3.T6.6.6.6.6.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="A3.T6.7.7.7.7.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A3.T6.7.7.7.7.5.m1.1a"><mmultiscripts id="A3.T6.7.7.7.7.5.m1.1.1" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"><mi id="A3.T6.7.7.7.7.5.m1.1.1.2.2" xref="A3.T6.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.7.7.7.7.5.m1.1.1a" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.7.7.7.7.5.m1.1.1b" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="A3.T6.7.7.7.7.5.m1.1.1.3" xref="A3.T6.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="A3.T6.7.7.7.7.5.m1.1.1.2.3" xref="A3.T6.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T6.7.7.7.7.5.m1.1.1c" xref="A3.T6.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.7.7.7.7.5.m1.1b"><apply id="A3.T6.7.7.7.7.5.m1.1.1.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.7.7.7.7.5.m1.1.1.1.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="A3.T6.7.7.7.7.5.m1.1.1.2.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.7.7.7.7.5.m1.1.1.2.1.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.7.7.7.7.5.m1.1.1.2.2.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.7.7.7.7.5.m1.1.1.2.3.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1.2.3">𝑁</ci></apply><ci id="A3.T6.7.7.7.7.5.m1.1.1.3.cmml" xref="A3.T6.7.7.7.7.5.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
<th id="A3.T6.8.8.8.8.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T6.8.8.8.8.6.1" class="ltx_sub"><span id="A3.T6.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T6.9.9.9.9.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="A3.T6.9.9.9.9.7.m1.1a"><mmultiscripts id="A3.T6.9.9.9.9.7.m1.1.1" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"><mi id="A3.T6.9.9.9.9.7.m1.1.1.2.2" xref="A3.T6.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.9.9.9.9.7.m1.1.1a" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.9.9.9.9.7.m1.1.1b" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="A3.T6.9.9.9.9.7.m1.1.1.3" xref="A3.T6.9.9.9.9.7.m1.1.1.3.cmml">s</mi><mi id="A3.T6.9.9.9.9.7.m1.1.1.2.3" xref="A3.T6.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T6.9.9.9.9.7.m1.1.1c" xref="A3.T6.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.9.9.9.9.7.m1.1b"><apply id="A3.T6.9.9.9.9.7.m1.1.1.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.9.9.9.9.7.m1.1.1.1.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="A3.T6.9.9.9.9.7.m1.1.1.2.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.9.9.9.9.7.m1.1.1.2.1.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.9.9.9.9.7.m1.1.1.2.2.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.9.9.9.9.7.m1.1.1.2.3.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1.2.3">𝐴</ci></apply><ci id="A3.T6.9.9.9.9.7.m1.1.1.3.cmml" xref="A3.T6.9.9.9.9.7.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.9.9.9.9.7.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</th>
<th id="A3.T6.10.10.10.10.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T6.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="A3.T6.10.10.10.10.8.m1.1a"><mmultiscripts id="A3.T6.10.10.10.10.8.m1.1.1" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"><mi id="A3.T6.10.10.10.10.8.m1.1.1.2.2" xref="A3.T6.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.10.10.10.10.8.m1.1.1a" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.10.10.10.10.8.m1.1.1b" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="A3.T6.10.10.10.10.8.m1.1.1.3" xref="A3.T6.10.10.10.10.8.m1.1.1.3.cmml">m</mi><mi id="A3.T6.10.10.10.10.8.m1.1.1.2.3" xref="A3.T6.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T6.10.10.10.10.8.m1.1.1c" xref="A3.T6.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.10.10.10.10.8.m1.1b"><apply id="A3.T6.10.10.10.10.8.m1.1.1.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.10.10.10.10.8.m1.1.1.1.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="A3.T6.10.10.10.10.8.m1.1.1.2.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.10.10.10.10.8.m1.1.1.2.1.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.10.10.10.10.8.m1.1.1.2.2.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.10.10.10.10.8.m1.1.1.2.3.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1.2.3">𝐴</ci></apply><ci id="A3.T6.10.10.10.10.8.m1.1.1.3.cmml" xref="A3.T6.10.10.10.10.8.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.10.10.10.10.8.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</th>
<th id="A3.T6.11.11.11.11.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">AR<math id="A3.T6.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="A3.T6.11.11.11.11.9.m1.1a"><mmultiscripts id="A3.T6.11.11.11.11.9.m1.1.1" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"><mi id="A3.T6.11.11.11.11.9.m1.1.1.2.2" xref="A3.T6.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T6.11.11.11.11.9.m1.1.1a" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="A3.T6.11.11.11.11.9.m1.1.1b" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="A3.T6.11.11.11.11.9.m1.1.1.3" xref="A3.T6.11.11.11.11.9.m1.1.1.3.cmml">l</mi><mi id="A3.T6.11.11.11.11.9.m1.1.1.2.3" xref="A3.T6.11.11.11.11.9.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T6.11.11.11.11.9.m1.1.1c" xref="A3.T6.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T6.11.11.11.11.9.m1.1b"><apply id="A3.T6.11.11.11.11.9.m1.1.1.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.11.11.11.11.9.m1.1.1.1.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="A3.T6.11.11.11.11.9.m1.1.1.2.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T6.11.11.11.11.9.m1.1.1.2.1.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T6.11.11.11.11.9.m1.1.1.2.2.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="A3.T6.11.11.11.11.9.m1.1.1.2.3.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1.2.3">𝐴</ci></apply><ci id="A3.T6.11.11.11.11.9.m1.1.1.3.cmml" xref="A3.T6.11.11.11.11.9.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T6.11.11.11.11.9.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T6.11.11.11.12.1" class="ltx_tr">
<td id="A3.T6.11.11.11.12.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GOOD-Both</td>
<td id="A3.T6.11.11.11.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.2.1" class="ltx_text ltx_font_bold">49.5</span></td>
<td id="A3.T6.11.11.11.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.3.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="A3.T6.11.11.11.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.6</td>
<td id="A3.T6.11.11.11.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.5.1" class="ltx_text ltx_font_bold">48.2</span></td>
<td id="A3.T6.11.11.11.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.6.1" class="ltx_text ltx_font_bold">62.4</span></td>
<td id="A3.T6.11.11.11.12.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.7.1" class="ltx_text ltx_font_bold">34.0</span></td>
<td id="A3.T6.11.11.11.12.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.9</td>
<td id="A3.T6.11.11.11.12.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A3.T6.11.11.11.12.1.9.1" class="ltx_text ltx_font_bold">37.0</span></td>
<td id="A3.T6.11.11.11.12.1.10" class="ltx_td ltx_align_left ltx_border_t"><span id="A3.T6.11.11.11.12.1.10.1" class="ltx_text ltx_font_bold">39.9</span></td>
</tr>
<tr id="A3.T6.11.11.11.13.2" class="ltx_tr">
<td id="A3.T6.11.11.11.13.2.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-All</td>
<td id="A3.T6.11.11.11.13.2.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">48.5</td>
<td id="A3.T6.11.11.11.13.2.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A3.T6.11.11.11.13.2.3.1" class="ltx_text ltx_font_bold">39.3</span></td>
<td id="A3.T6.11.11.11.13.2.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A3.T6.11.11.11.13.2.4.1" class="ltx_text ltx_font_bold">22.7</span></td>
<td id="A3.T6.11.11.11.13.2.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">47.6</td>
<td id="A3.T6.11.11.11.13.2.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">60.8</td>
<td id="A3.T6.11.11.11.13.2.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">33.3</td>
<td id="A3.T6.11.11.11.13.2.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A3.T6.11.11.11.13.2.8.1" class="ltx_text ltx_font_bold">22.9</span></td>
<td id="A3.T6.11.11.11.13.2.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">36.2</td>
<td id="A3.T6.11.11.11.13.2.10" class="ltx_td ltx_align_left ltx_border_bb">38.0</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span><span id="A3.T6.22.1" class="ltx_text ltx_font_bold">More comparison of GOOD-Both and GOOD-All.</span> For GOOD-All, the performance gains in detecting small objects (AR<sup id="A3.T6.23.2" class="ltx_sup"><span id="A3.T6.23.2.1" class="ltx_text ltx_font_italic">s</span></sup>) are too small to compensate for the losses in detecting larger objects (AR<sup id="A3.T6.24.3" class="ltx_sup"><span id="A3.T6.24.3.1" class="ltx_text ltx_font_italic">m</span></sup> and (AR<sup id="A3.T6.25.4" class="ltx_sup"><span id="A3.T6.25.4.1" class="ltx_text ltx_font_italic">l</span></sup>)), leading to overall inferior performance.</figcaption>
</figure>
</section>
<section id="A3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Architecture choice</h3>

<div id="A3.SS3.p1" class="ltx_para ltx_noindent">
<p id="A3.SS3.p1.1" class="ltx_p">In principle, our approach is model agnostic and is therefore compatible with both proposal-free and proposal-based object detectors. To demonstrate this, besides the two-stage proposal-based detectors in the main paper, we also experiment with a more recent single-stage proposal-free object detector FCOS <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite>.
Specifically, we kept Phase I unchanged, i.e., generating the geometric cue-based pseudo boxes using OLN as the architecture. In Phase II, we train a class-agnostic FCOS using the extracted pseudo boxes together with the groundtruth annotations of the base classes.
The experiment results are shown in Table <a href="#A3.T7" title="Table 7 ‣ C.3 Architecture choice ‣ Appendix C More ablation studies ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We can see that GOOD can significantly improve FCOS in terms of detecting novel objects and OLN is a stronger architecture than FCOS to be used in GOOD.</p>
</div>
<figure id="A3.T7" class="ltx_table">
<div id="A3.T7.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:380.8pt;height:104pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.0pt,2.7pt) scale(0.95,0.95) ;">
<div id="A3.T7.11.11" class="ltx_inline-block ltx_transformed_outer" style="width:397.5pt;height:108.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.9pt,-0.2pt) scale(1.00457085249424,1.00457085249424) ;">
<table id="A3.T7.11.11.11" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T7.2.2.2.2" class="ltx_tr">
<th id="A3.T7.2.2.2.2.3" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="A3.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="5"><span id="A3.T7.1.1.1.1.1.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T7.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T7.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="A3.T7.1.1.1.1.1.1.m1.1.1" xref="A3.T7.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.T7.1.1.1.1.1.1.m1.1b"><ci id="A3.T7.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T7.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.1.1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math>Non-VOC</span></th>
<th id="A3.T7.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4"><span id="A3.T7.2.2.2.2.2.1" class="ltx_text ltx_font_bold">VOC<math id="A3.T7.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="A3.T7.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="A3.T7.2.2.2.2.2.1.m1.1.1" xref="A3.T7.2.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A3.T7.2.2.2.2.2.1.m1.1b"><ci id="A3.T7.2.2.2.2.2.1.m1.1.1.cmml" xref="A3.T7.2.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.2.2.2.2.2.1.m1.1c">\rightarrow</annotation></semantics></math>ADE20K</span></th>
</tr>
<tr id="A3.T7.11.11.11.11" class="ltx_tr">
<th id="A3.T7.11.11.11.11.10" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Method</th>
<th id="A3.T7.3.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T7.3.3.3.3.1.1" class="ltx_sub"><span id="A3.T7.3.3.3.3.1.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T7.4.4.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T7.4.4.4.4.2.1" class="ltx_sub"><span id="A3.T7.4.4.4.4.2.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="A3.T7.5.5.5.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.5.5.5.5.3.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A3.T7.5.5.5.5.3.m1.1a"><mmultiscripts id="A3.T7.5.5.5.5.3.m1.1.1" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"><mi id="A3.T7.5.5.5.5.3.m1.1.1.2.2" xref="A3.T7.5.5.5.5.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.5.5.5.5.3.m1.1.1a" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.5.5.5.5.3.m1.1.1b" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"></mrow><mi id="A3.T7.5.5.5.5.3.m1.1.1.3" xref="A3.T7.5.5.5.5.3.m1.1.1.3.cmml">s</mi><mi id="A3.T7.5.5.5.5.3.m1.1.1.2.3" xref="A3.T7.5.5.5.5.3.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T7.5.5.5.5.3.m1.1.1c" xref="A3.T7.5.5.5.5.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.5.5.5.5.3.m1.1b"><apply id="A3.T7.5.5.5.5.3.m1.1.1.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.5.5.5.5.3.m1.1.1.1.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1">superscript</csymbol><apply id="A3.T7.5.5.5.5.3.m1.1.1.2.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.5.5.5.5.3.m1.1.1.2.1.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.5.5.5.5.3.m1.1.1.2.2.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.5.5.5.5.3.m1.1.1.2.3.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1.2.3">𝑁</ci></apply><ci id="A3.T7.5.5.5.5.3.m1.1.1.3.cmml" xref="A3.T7.5.5.5.5.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.5.5.5.5.3.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="A3.T7.6.6.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.6.6.6.6.4.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A3.T7.6.6.6.6.4.m1.1a"><mmultiscripts id="A3.T7.6.6.6.6.4.m1.1.1" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"><mi id="A3.T7.6.6.6.6.4.m1.1.1.2.2" xref="A3.T7.6.6.6.6.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.6.6.6.6.4.m1.1.1a" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.6.6.6.6.4.m1.1.1b" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"></mrow><mi id="A3.T7.6.6.6.6.4.m1.1.1.3" xref="A3.T7.6.6.6.6.4.m1.1.1.3.cmml">m</mi><mi id="A3.T7.6.6.6.6.4.m1.1.1.2.3" xref="A3.T7.6.6.6.6.4.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T7.6.6.6.6.4.m1.1.1c" xref="A3.T7.6.6.6.6.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.6.6.6.6.4.m1.1b"><apply id="A3.T7.6.6.6.6.4.m1.1.1.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.6.6.6.6.4.m1.1.1.1.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1">superscript</csymbol><apply id="A3.T7.6.6.6.6.4.m1.1.1.2.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.6.6.6.6.4.m1.1.1.2.1.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.6.6.6.6.4.m1.1.1.2.2.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.6.6.6.6.4.m1.1.1.2.3.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1.2.3">𝑁</ci></apply><ci id="A3.T7.6.6.6.6.4.m1.1.1.3.cmml" xref="A3.T7.6.6.6.6.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.6.6.6.6.4.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="A3.T7.7.7.7.7.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.7.7.7.7.5.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A3.T7.7.7.7.7.5.m1.1a"><mmultiscripts id="A3.T7.7.7.7.7.5.m1.1.1" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"><mi id="A3.T7.7.7.7.7.5.m1.1.1.2.2" xref="A3.T7.7.7.7.7.5.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.7.7.7.7.5.m1.1.1a" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.7.7.7.7.5.m1.1.1b" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"></mrow><mi id="A3.T7.7.7.7.7.5.m1.1.1.3" xref="A3.T7.7.7.7.7.5.m1.1.1.3.cmml">l</mi><mi id="A3.T7.7.7.7.7.5.m1.1.1.2.3" xref="A3.T7.7.7.7.7.5.m1.1.1.2.3.cmml">N</mi><mrow id="A3.T7.7.7.7.7.5.m1.1.1c" xref="A3.T7.7.7.7.7.5.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.7.7.7.7.5.m1.1b"><apply id="A3.T7.7.7.7.7.5.m1.1.1.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.7.7.7.7.5.m1.1.1.1.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1">superscript</csymbol><apply id="A3.T7.7.7.7.7.5.m1.1.1.2.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.7.7.7.7.5.m1.1.1.2.1.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.7.7.7.7.5.m1.1.1.2.2.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.7.7.7.7.5.m1.1.1.2.3.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1.2.3">𝑁</ci></apply><ci id="A3.T7.7.7.7.7.5.m1.1.1.3.cmml" xref="A3.T7.7.7.7.7.5.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.7.7.7.7.5.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
<th id="A3.T7.8.8.8.8.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<sub id="A3.T7.8.8.8.8.6.1" class="ltx_sub"><span id="A3.T7.8.8.8.8.6.1.1" class="ltx_text ltx_font_italic">A</span></sub>
</th>
<th id="A3.T7.9.9.9.9.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.9.9.9.9.7.m1.1" class="ltx_Math" alttext="{}_{A}^{s}" display="inline"><semantics id="A3.T7.9.9.9.9.7.m1.1a"><mmultiscripts id="A3.T7.9.9.9.9.7.m1.1.1" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"><mi id="A3.T7.9.9.9.9.7.m1.1.1.2.2" xref="A3.T7.9.9.9.9.7.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.9.9.9.9.7.m1.1.1a" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.9.9.9.9.7.m1.1.1b" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"></mrow><mi id="A3.T7.9.9.9.9.7.m1.1.1.3" xref="A3.T7.9.9.9.9.7.m1.1.1.3.cmml">s</mi><mi id="A3.T7.9.9.9.9.7.m1.1.1.2.3" xref="A3.T7.9.9.9.9.7.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T7.9.9.9.9.7.m1.1.1c" xref="A3.T7.9.9.9.9.7.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.9.9.9.9.7.m1.1b"><apply id="A3.T7.9.9.9.9.7.m1.1.1.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.9.9.9.9.7.m1.1.1.1.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1">superscript</csymbol><apply id="A3.T7.9.9.9.9.7.m1.1.1.2.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.9.9.9.9.7.m1.1.1.2.1.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.9.9.9.9.7.m1.1.1.2.2.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.9.9.9.9.7.m1.1.1.2.3.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1.2.3">𝐴</ci></apply><ci id="A3.T7.9.9.9.9.7.m1.1.1.3.cmml" xref="A3.T7.9.9.9.9.7.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.9.9.9.9.7.m1.1c">{}_{A}^{s}</annotation></semantics></math>
</th>
<th id="A3.T7.10.10.10.10.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">AR<math id="A3.T7.10.10.10.10.8.m1.1" class="ltx_Math" alttext="{}_{A}^{m}" display="inline"><semantics id="A3.T7.10.10.10.10.8.m1.1a"><mmultiscripts id="A3.T7.10.10.10.10.8.m1.1.1" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"><mi id="A3.T7.10.10.10.10.8.m1.1.1.2.2" xref="A3.T7.10.10.10.10.8.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.10.10.10.10.8.m1.1.1a" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.10.10.10.10.8.m1.1.1b" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"></mrow><mi id="A3.T7.10.10.10.10.8.m1.1.1.3" xref="A3.T7.10.10.10.10.8.m1.1.1.3.cmml">m</mi><mi id="A3.T7.10.10.10.10.8.m1.1.1.2.3" xref="A3.T7.10.10.10.10.8.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T7.10.10.10.10.8.m1.1.1c" xref="A3.T7.10.10.10.10.8.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.10.10.10.10.8.m1.1b"><apply id="A3.T7.10.10.10.10.8.m1.1.1.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.10.10.10.10.8.m1.1.1.1.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1">superscript</csymbol><apply id="A3.T7.10.10.10.10.8.m1.1.1.2.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.10.10.10.10.8.m1.1.1.2.1.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.10.10.10.10.8.m1.1.1.2.2.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.10.10.10.10.8.m1.1.1.2.3.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1.2.3">𝐴</ci></apply><ci id="A3.T7.10.10.10.10.8.m1.1.1.3.cmml" xref="A3.T7.10.10.10.10.8.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.10.10.10.10.8.m1.1c">{}_{A}^{m}</annotation></semantics></math>
</th>
<th id="A3.T7.11.11.11.11.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">AR<math id="A3.T7.11.11.11.11.9.m1.1" class="ltx_Math" alttext="{}_{A}^{l}" display="inline"><semantics id="A3.T7.11.11.11.11.9.m1.1a"><mmultiscripts id="A3.T7.11.11.11.11.9.m1.1.1" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"><mi id="A3.T7.11.11.11.11.9.m1.1.1.2.2" xref="A3.T7.11.11.11.11.9.m1.1.1.2.2.cmml"></mi><mprescripts id="A3.T7.11.11.11.11.9.m1.1.1a" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"></mprescripts><mrow id="A3.T7.11.11.11.11.9.m1.1.1b" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"></mrow><mi id="A3.T7.11.11.11.11.9.m1.1.1.3" xref="A3.T7.11.11.11.11.9.m1.1.1.3.cmml">l</mi><mi id="A3.T7.11.11.11.11.9.m1.1.1.2.3" xref="A3.T7.11.11.11.11.9.m1.1.1.2.3.cmml">A</mi><mrow id="A3.T7.11.11.11.11.9.m1.1.1c" xref="A3.T7.11.11.11.11.9.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A3.T7.11.11.11.11.9.m1.1b"><apply id="A3.T7.11.11.11.11.9.m1.1.1.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.11.11.11.11.9.m1.1.1.1.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1">superscript</csymbol><apply id="A3.T7.11.11.11.11.9.m1.1.1.2.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1"><csymbol cd="ambiguous" id="A3.T7.11.11.11.11.9.m1.1.1.2.1.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A3.T7.11.11.11.11.9.m1.1.1.2.2.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1.2.2">absent</csymbol><ci id="A3.T7.11.11.11.11.9.m1.1.1.2.3.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1.2.3">𝐴</ci></apply><ci id="A3.T7.11.11.11.11.9.m1.1.1.3.cmml" xref="A3.T7.11.11.11.11.9.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.11.11.11.11.9.m1.1c">{}_{A}^{l}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T7.11.11.11.12.1" class="ltx_tr">
<td id="A3.T7.11.11.11.12.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">FCOS</td>
<td id="A3.T7.11.11.11.12.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.6</td>
<td id="A3.T7.11.11.11.12.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.3</td>
<td id="A3.T7.11.11.11.12.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14.6</td>
<td id="A3.T7.11.11.11.12.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.7</td>
<td id="A3.T7.11.11.11.12.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.2</td>
<td id="A3.T7.11.11.11.12.1.7" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.6</td>
<td id="A3.T7.11.11.11.12.1.8" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">17.2</td>
<td id="A3.T7.11.11.11.12.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.5</td>
<td id="A3.T7.11.11.11.12.1.10" class="ltx_td ltx_align_left ltx_border_t">30.9</td>
</tr>
<tr id="A3.T7.11.11.11.13.2" class="ltx_tr">
<td id="A3.T7.11.11.11.13.2.1" class="ltx_td ltx_align_left ltx_border_r">OLN</td>
<td id="A3.T7.11.11.11.13.2.2" class="ltx_td ltx_align_left ltx_border_r">47.5</td>
<td id="A3.T7.11.11.11.13.2.3" class="ltx_td ltx_align_left ltx_border_r">33.2</td>
<td id="A3.T7.11.11.11.13.2.4" class="ltx_td ltx_align_left ltx_border_r">18.7</td>
<td id="A3.T7.11.11.11.13.2.5" class="ltx_td ltx_align_left ltx_border_r">39.3</td>
<td id="A3.T7.11.11.11.13.2.6" class="ltx_td ltx_align_left ltx_border_r">58.6</td>
<td id="A3.T7.11.11.11.13.2.7" class="ltx_td ltx_align_left ltx_border_r">29.2</td>
<td id="A3.T7.11.11.11.13.2.8" class="ltx_td ltx_align_left ltx_border_r">19.7</td>
<td id="A3.T7.11.11.11.13.2.9" class="ltx_td ltx_align_left ltx_border_r">30.7</td>
<td id="A3.T7.11.11.11.13.2.10" class="ltx_td ltx_align_left">34.4</td>
</tr>
<tr id="A3.T7.11.11.11.14.3" class="ltx_tr">
<td id="A3.T7.11.11.11.14.3.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Both (FCOS)</td>
<td id="A3.T7.11.11.11.14.3.2" class="ltx_td ltx_align_left ltx_border_r">48.4</td>
<td id="A3.T7.11.11.11.14.3.3" class="ltx_td ltx_align_left ltx_border_r">36.3</td>
<td id="A3.T7.11.11.11.14.3.4" class="ltx_td ltx_align_left ltx_border_r">18.4</td>
<td id="A3.T7.11.11.11.14.3.5" class="ltx_td ltx_align_left ltx_border_r">46.5</td>
<td id="A3.T7.11.11.11.14.3.6" class="ltx_td ltx_align_left ltx_border_r">58.0</td>
<td id="A3.T7.11.11.11.14.3.7" class="ltx_td ltx_align_left ltx_border_r">32.5</td>
<td id="A3.T7.11.11.11.14.3.8" class="ltx_td ltx_align_left ltx_border_r">20.1</td>
<td id="A3.T7.11.11.11.14.3.9" class="ltx_td ltx_align_left ltx_border_r">34.5</td>
<td id="A3.T7.11.11.11.14.3.10" class="ltx_td ltx_align_left">39.5</td>
</tr>
<tr id="A3.T7.11.11.11.15.4" class="ltx_tr">
<td id="A3.T7.11.11.11.15.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Both (OLN)</td>
<td id="A3.T7.11.11.11.15.4.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">49.5</td>
<td id="A3.T7.11.11.11.15.4.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">39.3</td>
<td id="A3.T7.11.11.11.15.4.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.6</td>
<td id="A3.T7.11.11.11.15.4.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">48.2</td>
<td id="A3.T7.11.11.11.15.4.6" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">62.4</td>
<td id="A3.T7.11.11.11.15.4.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">34.0</td>
<td id="A3.T7.11.11.11.15.4.8" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.9</td>
<td id="A3.T7.11.11.11.15.4.9" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">37.0</td>
<td id="A3.T7.11.11.11.15.4.10" class="ltx_td ltx_align_left ltx_border_bb">39.9</td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span><span id="A3.T7.13.1" class="ltx_text ltx_font_bold">Architecture choice.</span> FCOS is a single-stage proposal-free object detector, and OLN is a two-stage proposal-based object detector (modified from Faster R-CNN). GOOD can significantly improve the open-world performance of both architectures.</figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>More discussion on different modalities for GOOD</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p id="A4.p1.1" class="ltx_p">In this section, we further discuss how different modalities behave and can be further ensembled to boost the performance.
We first compare different modalities used for Phase-I training and pseudo labeling in GOOD on the COCO VOC to non-VOC benchmark.
In Table <a href="#A4.T8" title="Table 8 ‣ Appendix D More discussion on different modalities for GOOD ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we show that pseudo-labeling using the geometric cues leads to stronger performances. This agrees with our study in Table <a href="#S4.T2" title="Table 2 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> where we found that pseudo boxes from proposal networks trained on geometric cues have higher AR<sub id="A4.p1.1.1" class="ltx_sub"><span id="A4.p1.1.1.1" class="ltx_text ltx_font_italic">N</span></sub>@5, indicating that they are of higher quality.</p>
</div>
<figure id="A4.T8" class="ltx_table">
<table id="A4.T8.4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T8.4.4.4" class="ltx_tr">
<th id="A4.T8.4.4.4.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Modality</th>
<th id="A4.T8.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<sub id="A4.T8.1.1.1.1.1" class="ltx_sub"><span id="A4.T8.1.1.1.1.1.1" class="ltx_text ltx_font_italic">N</span></sub>
</th>
<th id="A4.T8.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="A4.T8.2.2.2.2.m1.1" class="ltx_Math" alttext="{}_{N}^{s}" display="inline"><semantics id="A4.T8.2.2.2.2.m1.1a"><mmultiscripts id="A4.T8.2.2.2.2.m1.1.1" xref="A4.T8.2.2.2.2.m1.1.1.cmml"><mi id="A4.T8.2.2.2.2.m1.1.1.2.2" xref="A4.T8.2.2.2.2.m1.1.1.2.2.cmml"></mi><mprescripts id="A4.T8.2.2.2.2.m1.1.1a" xref="A4.T8.2.2.2.2.m1.1.1.cmml"></mprescripts><mrow id="A4.T8.2.2.2.2.m1.1.1b" xref="A4.T8.2.2.2.2.m1.1.1.cmml"></mrow><mi id="A4.T8.2.2.2.2.m1.1.1.3" xref="A4.T8.2.2.2.2.m1.1.1.3.cmml">s</mi><mi id="A4.T8.2.2.2.2.m1.1.1.2.3" xref="A4.T8.2.2.2.2.m1.1.1.2.3.cmml">N</mi><mrow id="A4.T8.2.2.2.2.m1.1.1c" xref="A4.T8.2.2.2.2.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A4.T8.2.2.2.2.m1.1b"><apply id="A4.T8.2.2.2.2.m1.1.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.2.2.2.2.m1.1.1.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1">superscript</csymbol><apply id="A4.T8.2.2.2.2.m1.1.1.2.cmml" xref="A4.T8.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.2.2.2.2.m1.1.1.2.1.cmml" xref="A4.T8.2.2.2.2.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A4.T8.2.2.2.2.m1.1.1.2.2.cmml" xref="A4.T8.2.2.2.2.m1.1.1.2.2">absent</csymbol><ci id="A4.T8.2.2.2.2.m1.1.1.2.3.cmml" xref="A4.T8.2.2.2.2.m1.1.1.2.3">𝑁</ci></apply><ci id="A4.T8.2.2.2.2.m1.1.1.3.cmml" xref="A4.T8.2.2.2.2.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.2.2.2.2.m1.1c">{}_{N}^{s}</annotation></semantics></math>
</th>
<th id="A4.T8.3.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">AR<math id="A4.T8.3.3.3.3.m1.1" class="ltx_Math" alttext="{}_{N}^{m}" display="inline"><semantics id="A4.T8.3.3.3.3.m1.1a"><mmultiscripts id="A4.T8.3.3.3.3.m1.1.1" xref="A4.T8.3.3.3.3.m1.1.1.cmml"><mi id="A4.T8.3.3.3.3.m1.1.1.2.2" xref="A4.T8.3.3.3.3.m1.1.1.2.2.cmml"></mi><mprescripts id="A4.T8.3.3.3.3.m1.1.1a" xref="A4.T8.3.3.3.3.m1.1.1.cmml"></mprescripts><mrow id="A4.T8.3.3.3.3.m1.1.1b" xref="A4.T8.3.3.3.3.m1.1.1.cmml"></mrow><mi id="A4.T8.3.3.3.3.m1.1.1.3" xref="A4.T8.3.3.3.3.m1.1.1.3.cmml">m</mi><mi id="A4.T8.3.3.3.3.m1.1.1.2.3" xref="A4.T8.3.3.3.3.m1.1.1.2.3.cmml">N</mi><mrow id="A4.T8.3.3.3.3.m1.1.1c" xref="A4.T8.3.3.3.3.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A4.T8.3.3.3.3.m1.1b"><apply id="A4.T8.3.3.3.3.m1.1.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.3.3.3.3.m1.1.1.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1">superscript</csymbol><apply id="A4.T8.3.3.3.3.m1.1.1.2.cmml" xref="A4.T8.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.3.3.3.3.m1.1.1.2.1.cmml" xref="A4.T8.3.3.3.3.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A4.T8.3.3.3.3.m1.1.1.2.2.cmml" xref="A4.T8.3.3.3.3.m1.1.1.2.2">absent</csymbol><ci id="A4.T8.3.3.3.3.m1.1.1.2.3.cmml" xref="A4.T8.3.3.3.3.m1.1.1.2.3">𝑁</ci></apply><ci id="A4.T8.3.3.3.3.m1.1.1.3.cmml" xref="A4.T8.3.3.3.3.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.3.3.3.3.m1.1c">{}_{N}^{m}</annotation></semantics></math>
</th>
<th id="A4.T8.4.4.4.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">AR<math id="A4.T8.4.4.4.4.m1.1" class="ltx_Math" alttext="{}_{N}^{l}" display="inline"><semantics id="A4.T8.4.4.4.4.m1.1a"><mmultiscripts id="A4.T8.4.4.4.4.m1.1.1" xref="A4.T8.4.4.4.4.m1.1.1.cmml"><mi id="A4.T8.4.4.4.4.m1.1.1.2.2" xref="A4.T8.4.4.4.4.m1.1.1.2.2.cmml"></mi><mprescripts id="A4.T8.4.4.4.4.m1.1.1a" xref="A4.T8.4.4.4.4.m1.1.1.cmml"></mprescripts><mrow id="A4.T8.4.4.4.4.m1.1.1b" xref="A4.T8.4.4.4.4.m1.1.1.cmml"></mrow><mi id="A4.T8.4.4.4.4.m1.1.1.3" xref="A4.T8.4.4.4.4.m1.1.1.3.cmml">l</mi><mi id="A4.T8.4.4.4.4.m1.1.1.2.3" xref="A4.T8.4.4.4.4.m1.1.1.2.3.cmml">N</mi><mrow id="A4.T8.4.4.4.4.m1.1.1c" xref="A4.T8.4.4.4.4.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="A4.T8.4.4.4.4.m1.1b"><apply id="A4.T8.4.4.4.4.m1.1.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.4.4.4.4.m1.1.1.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1">superscript</csymbol><apply id="A4.T8.4.4.4.4.m1.1.1.2.cmml" xref="A4.T8.4.4.4.4.m1.1.1"><csymbol cd="ambiguous" id="A4.T8.4.4.4.4.m1.1.1.2.1.cmml" xref="A4.T8.4.4.4.4.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="A4.T8.4.4.4.4.m1.1.1.2.2.cmml" xref="A4.T8.4.4.4.4.m1.1.1.2.2">absent</csymbol><ci id="A4.T8.4.4.4.4.m1.1.1.2.3.cmml" xref="A4.T8.4.4.4.4.m1.1.1.2.3">𝑁</ci></apply><ci id="A4.T8.4.4.4.4.m1.1.1.3.cmml" xref="A4.T8.4.4.4.4.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T8.4.4.4.4.m1.1c">{}_{N}^{l}</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T8.4.4.5.1" class="ltx_tr">
<td id="A4.T8.4.4.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SelfTrain-RGB</td>
<td id="A4.T8.4.4.5.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.4</td>
<td id="A4.T8.4.4.5.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="A4.T8.4.4.5.1.3.1" class="ltx_text ltx_font_bold">22.8</span></td>
<td id="A4.T8.4.4.5.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.9</td>
<td id="A4.T8.4.4.5.1.5" class="ltx_td ltx_align_left ltx_border_t">57.7</td>
</tr>
<tr id="A4.T8.4.4.6.2" class="ltx_tr">
<td id="A4.T8.4.4.6.2.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Edge</td>
<td id="A4.T8.4.4.6.2.2" class="ltx_td ltx_align_left ltx_border_r">38.1</td>
<td id="A4.T8.4.4.6.2.3" class="ltx_td ltx_align_left ltx_border_r">21.8</td>
<td id="A4.T8.4.4.6.2.4" class="ltx_td ltx_align_left ltx_border_r">45.7</td>
<td id="A4.T8.4.4.6.2.5" class="ltx_td ltx_align_left">60.2</td>
</tr>
<tr id="A4.T8.4.4.7.3" class="ltx_tr">
<td id="A4.T8.4.4.7.3.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-PA</td>
<td id="A4.T8.4.4.7.3.2" class="ltx_td ltx_align_left ltx_border_r">37.1</td>
<td id="A4.T8.4.4.7.3.3" class="ltx_td ltx_align_left ltx_border_r">18.6</td>
<td id="A4.T8.4.4.7.3.4" class="ltx_td ltx_align_left ltx_border_r">43.9</td>
<td id="A4.T8.4.4.7.3.5" class="ltx_td ltx_align_left"><span id="A4.T8.4.4.7.3.5.1" class="ltx_text ltx_font_bold">65.3</span></td>
</tr>
<tr id="A4.T8.4.4.8.4" class="ltx_tr">
<td id="A4.T8.4.4.8.4.1" class="ltx_td ltx_align_left ltx_border_r">GOOD-Depth</td>
<td id="A4.T8.4.4.8.4.2" class="ltx_td ltx_align_left ltx_border_r"><span id="A4.T8.4.4.8.4.2.1" class="ltx_text ltx_font_bold">39.0</span></td>
<td id="A4.T8.4.4.8.4.3" class="ltx_td ltx_align_left ltx_border_r">21.1</td>
<td id="A4.T8.4.4.8.4.4" class="ltx_td ltx_align_left ltx_border_r">47.5</td>
<td id="A4.T8.4.4.8.4.5" class="ltx_td ltx_align_left">63.2</td>
</tr>
<tr id="A4.T8.4.4.9.5" class="ltx_tr">
<td id="A4.T8.4.4.9.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">GOOD-Normal</td>
<td id="A4.T8.4.4.9.5.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">38.9</td>
<td id="A4.T8.4.4.9.5.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">21.4</td>
<td id="A4.T8.4.4.9.5.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="A4.T8.4.4.9.5.4.1" class="ltx_text ltx_font_bold">47.9</span></td>
<td id="A4.T8.4.4.9.5.5" class="ltx_td ltx_align_left ltx_border_bb">62.4</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span><span id="A4.T8.6.1" class="ltx_text ltx_font_bold">Comparison of GOOD using different modalities on COCO VOC to non-VOC benchmark.</span> </figcaption>
</figure>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Complementariness of different modalities</h3>

<div id="A4.SS1.p1" class="ltx_para ltx_noindent">
<p id="A4.SS1.p1.1" class="ltx_p">In the main paper, we have combined the pseudo boxes only from the geometric cues, i.e., depth and normals. GOOD-Both provides additional performance gains over GOOD-Depth and GOOD-Normal. As we have more than two sources of pseudo labeling, it is natural to examine further if they are complementary and thus can be jointly exploited. We first evaluate the overlap of their top-<math id="A4.SS1.p1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A4.SS1.p1.1.m1.1a"><mn id="A4.SS1.p1.1.m1.1.1" xref="A4.SS1.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A4.SS1.p1.1.m1.1b"><cn type="integer" id="A4.SS1.p1.1.m1.1.1.cmml" xref="A4.SS1.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p1.1.m1.1c">1</annotation></semantics></math> ranked pseudo boxes. Their most confident novel object detections best convey their bias in generalization. We can observe from Figure <a href="#A4.F7.sf1" title="In Figure 7 ‣ D.1 Complementariness of different modalities ‣ Appendix D More discussion on different modalities for GOOD ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(a)</span></a> that the overlap is low across all the input types. Table <a href="#S4.T2" title="Table 2 ‣ 4.2 Advantages of geometric cues ‣ 4 Experiments ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a href="#A4.T8" title="Table 8 ‣ Appendix D More discussion on different modalities for GOOD ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> further reveal their complementariness in detecting different sizes of objects. Both observations motivate us to ensemble different sources of pseudo boxes, exploiting their diversity for training the object detector.</p>
</div>
<div id="A4.SS1.p2" class="ltx_para ltx_noindent">
<p id="A4.SS1.p2.3" class="ltx_p">To decide which modality to ensemble first, we designed a simple greedy algorithm based on the overlap of pseudo boxes and the potential performance gain of adding the modality to the ensemble.
Specifically, starting with the best-performing modality (depth), we incrementally ensemble more sources of pseudo boxes by selecting the source with the highest <math id="A4.SS1.p2.1.m1.1" class="ltx_Math" alttext="Utility*Uniqueness" display="inline"><semantics id="A4.SS1.p2.1.m1.1a"><mrow id="A4.SS1.p2.1.m1.1.1" xref="A4.SS1.p2.1.m1.1.1.cmml"><mrow id="A4.SS1.p2.1.m1.1.1.2" xref="A4.SS1.p2.1.m1.1.1.2.cmml"><mrow id="A4.SS1.p2.1.m1.1.1.2.2" xref="A4.SS1.p2.1.m1.1.1.2.2.cmml"><mi id="A4.SS1.p2.1.m1.1.1.2.2.2" xref="A4.SS1.p2.1.m1.1.1.2.2.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.3" xref="A4.SS1.p2.1.m1.1.1.2.2.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1a" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.4" xref="A4.SS1.p2.1.m1.1.1.2.2.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1b" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.5" xref="A4.SS1.p2.1.m1.1.1.2.2.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1c" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.6" xref="A4.SS1.p2.1.m1.1.1.2.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1d" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.7" xref="A4.SS1.p2.1.m1.1.1.2.2.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.2.2.1e" xref="A4.SS1.p2.1.m1.1.1.2.2.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.2.2.8" xref="A4.SS1.p2.1.m1.1.1.2.2.8.cmml">y</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="A4.SS1.p2.1.m1.1.1.2.1" xref="A4.SS1.p2.1.m1.1.1.2.1.cmml">∗</mo><mi id="A4.SS1.p2.1.m1.1.1.2.3" xref="A4.SS1.p2.1.m1.1.1.2.3.cmml">U</mi></mrow><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.3" xref="A4.SS1.p2.1.m1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1a" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.4" xref="A4.SS1.p2.1.m1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1b" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.5" xref="A4.SS1.p2.1.m1.1.1.5.cmml">q</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1c" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.6" xref="A4.SS1.p2.1.m1.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1d" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.7" xref="A4.SS1.p2.1.m1.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1e" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.8" xref="A4.SS1.p2.1.m1.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1f" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.9" xref="A4.SS1.p2.1.m1.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1g" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.10" xref="A4.SS1.p2.1.m1.1.1.10.cmml">s</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.1.m1.1.1.1h" xref="A4.SS1.p2.1.m1.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.1.m1.1.1.11" xref="A4.SS1.p2.1.m1.1.1.11.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.1.m1.1b"><apply id="A4.SS1.p2.1.m1.1.1.cmml" xref="A4.SS1.p2.1.m1.1.1"><times id="A4.SS1.p2.1.m1.1.1.1.cmml" xref="A4.SS1.p2.1.m1.1.1.1"></times><apply id="A4.SS1.p2.1.m1.1.1.2.cmml" xref="A4.SS1.p2.1.m1.1.1.2"><times id="A4.SS1.p2.1.m1.1.1.2.1.cmml" xref="A4.SS1.p2.1.m1.1.1.2.1"></times><apply id="A4.SS1.p2.1.m1.1.1.2.2.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2"><times id="A4.SS1.p2.1.m1.1.1.2.2.1.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.1"></times><ci id="A4.SS1.p2.1.m1.1.1.2.2.2.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.2">𝑈</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.3.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.3">𝑡</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.4.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.4">𝑖</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.5.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.5">𝑙</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.6.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.6">𝑖</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.7.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.7">𝑡</ci><ci id="A4.SS1.p2.1.m1.1.1.2.2.8.cmml" xref="A4.SS1.p2.1.m1.1.1.2.2.8">𝑦</ci></apply><ci id="A4.SS1.p2.1.m1.1.1.2.3.cmml" xref="A4.SS1.p2.1.m1.1.1.2.3">𝑈</ci></apply><ci id="A4.SS1.p2.1.m1.1.1.3.cmml" xref="A4.SS1.p2.1.m1.1.1.3">𝑛</ci><ci id="A4.SS1.p2.1.m1.1.1.4.cmml" xref="A4.SS1.p2.1.m1.1.1.4">𝑖</ci><ci id="A4.SS1.p2.1.m1.1.1.5.cmml" xref="A4.SS1.p2.1.m1.1.1.5">𝑞</ci><ci id="A4.SS1.p2.1.m1.1.1.6.cmml" xref="A4.SS1.p2.1.m1.1.1.6">𝑢</ci><ci id="A4.SS1.p2.1.m1.1.1.7.cmml" xref="A4.SS1.p2.1.m1.1.1.7">𝑒</ci><ci id="A4.SS1.p2.1.m1.1.1.8.cmml" xref="A4.SS1.p2.1.m1.1.1.8">𝑛</ci><ci id="A4.SS1.p2.1.m1.1.1.9.cmml" xref="A4.SS1.p2.1.m1.1.1.9">𝑒</ci><ci id="A4.SS1.p2.1.m1.1.1.10.cmml" xref="A4.SS1.p2.1.m1.1.1.10">𝑠</ci><ci id="A4.SS1.p2.1.m1.1.1.11.cmml" xref="A4.SS1.p2.1.m1.1.1.11">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.1.m1.1c">Utility*Uniqueness</annotation></semantics></math> score, where <math id="A4.SS1.p2.2.m2.1" class="ltx_Math" alttext="Utility" display="inline"><semantics id="A4.SS1.p2.2.m2.1a"><mrow id="A4.SS1.p2.2.m2.1.1" xref="A4.SS1.p2.2.m2.1.1.cmml"><mi id="A4.SS1.p2.2.m2.1.1.2" xref="A4.SS1.p2.2.m2.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1" xref="A4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.2.m2.1.1.3" xref="A4.SS1.p2.2.m2.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1a" xref="A4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.2.m2.1.1.4" xref="A4.SS1.p2.2.m2.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1b" xref="A4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.2.m2.1.1.5" xref="A4.SS1.p2.2.m2.1.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1c" xref="A4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.2.m2.1.1.6" xref="A4.SS1.p2.2.m2.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1d" xref="A4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.2.m2.1.1.7" xref="A4.SS1.p2.2.m2.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.2.m2.1.1.1e" xref="A4.SS1.p2.2.m2.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.2.m2.1.1.8" xref="A4.SS1.p2.2.m2.1.1.8.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.2.m2.1b"><apply id="A4.SS1.p2.2.m2.1.1.cmml" xref="A4.SS1.p2.2.m2.1.1"><times id="A4.SS1.p2.2.m2.1.1.1.cmml" xref="A4.SS1.p2.2.m2.1.1.1"></times><ci id="A4.SS1.p2.2.m2.1.1.2.cmml" xref="A4.SS1.p2.2.m2.1.1.2">𝑈</ci><ci id="A4.SS1.p2.2.m2.1.1.3.cmml" xref="A4.SS1.p2.2.m2.1.1.3">𝑡</ci><ci id="A4.SS1.p2.2.m2.1.1.4.cmml" xref="A4.SS1.p2.2.m2.1.1.4">𝑖</ci><ci id="A4.SS1.p2.2.m2.1.1.5.cmml" xref="A4.SS1.p2.2.m2.1.1.5">𝑙</ci><ci id="A4.SS1.p2.2.m2.1.1.6.cmml" xref="A4.SS1.p2.2.m2.1.1.6">𝑖</ci><ci id="A4.SS1.p2.2.m2.1.1.7.cmml" xref="A4.SS1.p2.2.m2.1.1.7">𝑡</ci><ci id="A4.SS1.p2.2.m2.1.1.8.cmml" xref="A4.SS1.p2.2.m2.1.1.8">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.2.m2.1c">Utility</annotation></semantics></math> is the performance gain against a vanilla OLN, and <math id="A4.SS1.p2.3.m3.1" class="ltx_Math" alttext="Uniqueness" display="inline"><semantics id="A4.SS1.p2.3.m3.1a"><mrow id="A4.SS1.p2.3.m3.1.1" xref="A4.SS1.p2.3.m3.1.1.cmml"><mi id="A4.SS1.p2.3.m3.1.1.2" xref="A4.SS1.p2.3.m3.1.1.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.3" xref="A4.SS1.p2.3.m3.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1a" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.4" xref="A4.SS1.p2.3.m3.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1b" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.5" xref="A4.SS1.p2.3.m3.1.1.5.cmml">q</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1c" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.6" xref="A4.SS1.p2.3.m3.1.1.6.cmml">u</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1d" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.7" xref="A4.SS1.p2.3.m3.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1e" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.8" xref="A4.SS1.p2.3.m3.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1f" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.9" xref="A4.SS1.p2.3.m3.1.1.9.cmml">e</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1g" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.10" xref="A4.SS1.p2.3.m3.1.1.10.cmml">s</mi><mo lspace="0em" rspace="0em" id="A4.SS1.p2.3.m3.1.1.1h" xref="A4.SS1.p2.3.m3.1.1.1.cmml">​</mo><mi id="A4.SS1.p2.3.m3.1.1.11" xref="A4.SS1.p2.3.m3.1.1.11.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.SS1.p2.3.m3.1b"><apply id="A4.SS1.p2.3.m3.1.1.cmml" xref="A4.SS1.p2.3.m3.1.1"><times id="A4.SS1.p2.3.m3.1.1.1.cmml" xref="A4.SS1.p2.3.m3.1.1.1"></times><ci id="A4.SS1.p2.3.m3.1.1.2.cmml" xref="A4.SS1.p2.3.m3.1.1.2">𝑈</ci><ci id="A4.SS1.p2.3.m3.1.1.3.cmml" xref="A4.SS1.p2.3.m3.1.1.3">𝑛</ci><ci id="A4.SS1.p2.3.m3.1.1.4.cmml" xref="A4.SS1.p2.3.m3.1.1.4">𝑖</ci><ci id="A4.SS1.p2.3.m3.1.1.5.cmml" xref="A4.SS1.p2.3.m3.1.1.5">𝑞</ci><ci id="A4.SS1.p2.3.m3.1.1.6.cmml" xref="A4.SS1.p2.3.m3.1.1.6">𝑢</ci><ci id="A4.SS1.p2.3.m3.1.1.7.cmml" xref="A4.SS1.p2.3.m3.1.1.7">𝑒</ci><ci id="A4.SS1.p2.3.m3.1.1.8.cmml" xref="A4.SS1.p2.3.m3.1.1.8">𝑛</ci><ci id="A4.SS1.p2.3.m3.1.1.9.cmml" xref="A4.SS1.p2.3.m3.1.1.9">𝑒</ci><ci id="A4.SS1.p2.3.m3.1.1.10.cmml" xref="A4.SS1.p2.3.m3.1.1.10">𝑠</ci><ci id="A4.SS1.p2.3.m3.1.1.11.cmml" xref="A4.SS1.p2.3.m3.1.1.11">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p2.3.m3.1c">Uniqueness</annotation></semantics></math> is the overlap of the pseudo boxes with the current ensemble pseudo boxes. The performance is evaluated on a holdout validation set. The chosen ensemble order for the COCO VOC to non-VOC benchmark is: depth, normal, PA, edge, RGB.</p>
</div>
<div id="A4.SS1.p3" class="ltx_para ltx_noindent">
<p id="A4.SS1.p3.1" class="ltx_p">We show the ensembling results in Figure <a href="#A4.F7.sf2" title="In Figure 7 ‣ D.1 Complementariness of different modalities ‣ Appendix D More discussion on different modalities for GOOD ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7(b)</span></a>.
Two baselines for using multiple pseudo boxes from RGB are considered: <span id="A4.SS1.p3.1.1" class="ltx_text ltx_font_bold">SelfTrain-RGB</span> is using the top-k pseudo boxes from a single RGB-based object proposal netowrk for retraining, and <span id="A4.SS1.p3.1.2" class="ltx_text ltx_font_bold">SelfTrain-RGB (ens)</span> is using pseudo boxes extracted and merged from k independently trained RGB-based object proposal networks for retraining. We can see that ensembling pseudo sources from multiple modalities is better than adding more pseudo boxes from a single source (RGB).</p>
</div>
<figure id="A4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/overlap_heatmap_iou07.png" id="A4.F7.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="411" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Overlap of top1 pseudo boxes.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/x9.png" id="A4.F7.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="422" height="293" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Influence of top-k when ensembling.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="A4.F7.4.1" class="ltx_text ltx_font_bold">Complementariness of different representations.</span> In (b), <span id="A4.F7.5.2" class="ltx_text ltx_font_bold">SelfTrain-RGB</span> is using the top-k pseudo boxes from a single RGB-based object proposal netowrk for retraining, and <span id="A4.F7.6.3" class="ltx_text ltx_font_bold">SelfTrain-RGB (ens)</span> is using pseudo boxes merged from k independently trained RGB-based object proposal netowrks for retraining.</figcaption>
</figure>
</section>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>More visualization</h2>

<section id="A5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Visualization of geometric cues</h3>

<div id="A5.SS1.p1" class="ltx_para ltx_noindent">
<p id="A5.SS1.p1.1" class="ltx_p">We visualize more examples of geometric cues in Figure <a href="#A5.F8" title="Figure 8 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> and Figure <a href="#A5.F9" title="Figure 9 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We demonstrate that the inferred geometric cues are of high quality in diverse scenes.</p>
</div>
</section>
<section id="A5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Visualization of pseudo boxes from Phase-I</h3>

<div id="A5.SS2.p1" class="ltx_para ltx_noindent">
<p id="A5.SS2.p1.1" class="ltx_p">We also provide visualization of pseudo boxes in Figure <a href="#A5.F10" title="Figure 10 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> and Figure <a href="#A5.F11" title="Figure 11 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.
The pseudo boxes are generated from OLNs trained on RGB, depth, and normals, respectively.
We find that pseudo boxes from RGB-based models generally tend to target small objects, textures, and parts of objects. This again shows that RGB-based models over-rely on appearance cues and can overfit to textures and discriminative parts of the training classes.</p>
</div>
</section>
<section id="A5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.3 </span>Visualization of GOOD detections on novel objects</h3>

<div id="A5.SS3.p1" class="ltx_para ltx_noindent">
<p id="A5.SS3.p1.1" class="ltx_p">We further added more visualization examples of GOOD detection results in Figure <a href="#A5.F12" title="Figure 12 ‣ E.3 Visualization of GOOD detections on novel objects ‣ Appendix E More visualization ‣ GOOD: Exploring Geometric Cues for Detecting Objects in an Open World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. The test images contain objects that are seen neither in the GOOD training set (COCO) nor the Omnidata model training set. The presented examples include new technology devices, spaceships, dinosaurs, aliens, and sea scenes. We can see that GOOD can still make reasonable object bounding box predictions even though these objects have never appeared in the training set.</p>
</div>
<figure id="A5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/000000000247.jpg" id="A5.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/depth000000000247.jpg" id="A5.F8.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/normal000000000247.jpg" id="A5.F8.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/000000000382.jpg" id="A5.F8.4.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/depth000000000382.jpg" id="A5.F8.5.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/normal000000000382.jpg" id="A5.F8.6.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/000000000785.jpg" id="A5.F8.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/depth000000000785.jpg" id="A5.F8.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-mid/normal000000000785.jpg" id="A5.F8.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000000139.jpg" id="A5.F8.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000000139.jpg" id="A5.F8.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000000139.jpg" id="A5.F8.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.13" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000001000.jpg" id="A5.F8.13.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.14" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000001000.jpg" id="A5.F8.14.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.15" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000001000.jpg" id="A5.F8.15.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.16" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000002149.jpg" id="A5.F8.16.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.17" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000002149.jpg" id="A5.F8.17.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F8.18" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000002149.jpg" id="A5.F8.18.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="A5.F8.20.1" class="ltx_text ltx_font_bold">Visualization of geometric cues.</span> From left to right: RGB, depth, normals.</figcaption>
</figure>
<figure id="A5.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000007574.jpg" id="A5.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000007574.jpg" id="A5.F9.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000007574.jpg" id="A5.F9.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000009769.jpg" id="A5.F9.4.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000009769.jpg" id="A5.F9.5.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000009769.jpg" id="A5.F9.6.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000011760.jpg" id="A5.F9.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000011760.jpg" id="A5.F9.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000011760.jpg" id="A5.F9.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000563604.jpg" id="A5.F9.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000563604.jpg" id="A5.F9.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000563604.jpg" id="A5.F9.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.13" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000570664.jpg" id="A5.F9.13.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.14" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000570664.jpg" id="A5.F9.14.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.15" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000570664.jpg" id="A5.F9.15.g1" class="ltx_graphics ltx_img_landscape" width="548" height="365" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.16" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/rgb/000000572555.jpg" id="A5.F9.16.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.17" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/depth/000000572555.jpg" id="A5.F9.17.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F9.18" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-geo/normal/000000572555.jpg" id="A5.F9.18.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span><span id="A5.F9.20.1" class="ltx_text ltx_font_bold">Visualization of geometric cues.</span> From left to right: RGB, depth, normals.</figcaption>
</figure>
<figure id="A5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000103806.jpg" id="A5.F10.1.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000103806.jpg" id="A5.F10.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000103806.jpg" id="A5.F10.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000310325.jpg" id="A5.F10.4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000310325.jpg" id="A5.F10.5.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000310325.jpg" id="A5.F10.6.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000503772.jpg" id="A5.F10.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000503772.jpg" id="A5.F10.8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000503772.jpg" id="A5.F10.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="411" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000310177.jpg" id="A5.F10.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="367" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000310177.jpg" id="A5.F10.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="367" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F10.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000310177.jpg" id="A5.F10.12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="367" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span><span id="A5.F10.14.1" class="ltx_text ltx_font_bold">Top3 pseudo boxes after filtering out those that overlap with known (VOC) class bounding boxes.</span> The pseudo boxes are generated from OLNs trained on RGB, depth, and normals, respectively.
OLN trained on RGB tends to detect small objects and parts of objects.</figcaption>
</figure>
<figure id="A5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000186322.jpg" id="A5.F11.1.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000186322.jpg" id="A5.F11.2.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000186322.jpg" id="A5.F11.3.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000410437.jpg" id="A5.F11.4.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000410437.jpg" id="A5.F11.5.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000410437.jpg" id="A5.F11.6.g1" class="ltx_graphics ltx_img_landscape" width="548" height="364" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000577564.jpg" id="A5.F11.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000577564.jpg" id="A5.F11.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000577564.jpg" id="A5.F11.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000199346.jpg" id="A5.F11.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000199346.jpg" id="A5.F11.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000199346.jpg" id="A5.F11.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="368" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.13" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/rgb/000000028655.jpg" id="A5.F11.13.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.14" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/depth/000000028655.jpg" id="A5.F11.14.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F11.15" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/vis-pseudo/normal/000000028655.jpg" id="A5.F11.15.g1" class="ltx_graphics ltx_img_portrait" width="548" height="731" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span><span id="A5.F11.17.1" class="ltx_text ltx_font_bold">Top3 pseudo boxes after filtering out those that overlap with known (VOC) class bounding boxes.</span> The pseudo boxes are generated from OLNs trained on RGB, depth, and normals, respectively.
OLN trained on RGB often detect textures or small parts of the objects.</figcaption>
</figure>
<figure id="A5.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/2.png" id="A5.F12.1.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/spaceship.png" id="A5.F12.2.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/aliens.png" id="A5.F12.3.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/dinosaur.png" id="A5.F12.4.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/transformers.png" id="A5.F12.5.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/dinosaurs.png" id="A5.F12.6.g1" class="ltx_graphics ltx_img_square" width="548" height="548" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/avatar.jpeg" id="A5.F12.7.g1" class="ltx_graphics ltx_img_landscape" width="548" height="274" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/n_1.png" id="A5.F12.8.g1" class="ltx_graphics ltx_img_landscape" width="548" height="309" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.9" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/erwater.jpeg" id="A5.F12.9.g1" class="ltx_graphics ltx_img_landscape" width="548" height="366" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.10" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/ron_man.jpeg" id="A5.F12.10.g1" class="ltx_graphics ltx_img_landscape" width="548" height="309" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.11" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/marvel.png" id="A5.F12.11.g1" class="ltx_graphics ltx_img_landscape" width="548" height="412" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="A5.F12.12" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.11720/assets/iclr2023/figures/good_detections/trek.png" id="A5.F12.12.g1" class="ltx_graphics ltx_img_landscape" width="548" height="384" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span><span id="A5.F12.14.1" class="ltx_text ltx_font_bold">GOOD detections on novel objects.</span> Only top 20 detection boxes are shown with the images. The novel objects are seen neither in GOOD training, nor in Omnidata training set.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.11719" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.11720" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2212.11720">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.11720" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.11722" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 09:46:25 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
