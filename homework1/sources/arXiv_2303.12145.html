<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.12145] Efficient Feature Distillation for Zero-shot Annotation Object Detection</title><meta property="og:description" content="We propose a new setting for detecting unseen objects called Zero-shot Annotation object Detection (ZAD).
It expands the zero-shot object detection setting by allowing the novel objects to exist in the training images
…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Efficient Feature Distillation for Zero-shot Annotation Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Efficient Feature Distillation for Zero-shot Annotation Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.12145">

<!--Generated on Thu Feb 29 19:10:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Efficient Feature Distillation for Zero-shot Annotation Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhuoming Liu, Xuefeng Hu<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>, Ram Nevatia 
<br class="ltx_break">University of Southern California
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{liuzhuom, xuefengh, nevatia}@usc.edu</span>
</span><span class="ltx_author_notes">Equal contribution.Corresponding author</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">We propose a new setting for detecting unseen objects called Zero-shot Annotation object Detection (ZAD).
It expands the zero-shot object detection setting by allowing the novel objects to exist in the training images
and restricts the additional information the detector uses to novel category names.
Recently, to detect unseen objects, large-scale vision-language models (e.g., CLIP) are leveraged by different methods.
The distillation-based methods have good overall performance but suffer from a long training schedule caused by two factors.
First, existing work creates distillation regions biased to the base categories, which limits the distillation of novel category information.
Second, directly using the raw feature from CLIP for distillation neglects the domain gap between the training data of CLIP and the detection datasets, which makes it difficult to learn the mapping from the image region to the vision-language feature space.
To solve these problems, we propose Efficient feature distillation for Zero-shot Annotation object Detection (EZAD).
Firstly, EZAD adapts the CLIP’s feature space to the target detection domain by re-normalizing CLIP;
Secondly, EZAD uses CLIP to generate distillation proposals with potential novel category names to avoid the distillation being overly biased toward the base categories.
Finally, EZAD takes advantage of semantic meaning for regression to further improve the model performance.
As a result, EZAD outperforms the previous distillation-based methods in COCO by 4% with a much shorter training schedule and achieves a 3% improvement on the LVIS dataset. Our code is available at <a target="_blank" href="https://github.com/dragonlzm/EZAD" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/dragonlzm/EZAD</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Object detection is a fundamental task in computer vision.
Typically, an object detector is trained on a dataset with specific categories and can’t be extended to new categories.
To detect instances of categories not seen during training, researchers started studying Zero-Shot object Detection (ZSD) and Open-Vocabulary object Detection (OVD).
In both ZSD and OVD settings, a set of ”base” categories is provided with annotated training examples (bounding boxes), and the rest, called ”novel” categories, are not provided with any annotated examples. In ZSD, the names of the novel categories are known at training time, but it is further posited<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> that the training data should not have any instances of the novel categories; this is very restrictive and requires training data to be screened for novel categories which defeats the purpose of the user adding categories at will. OVD does not impose this restriction but assumes that the novel category names are unavailable during training and may be added freely at inference time. Also, to detect more novel categories, the training of OVD sometimes needs additional images or captions.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2303.12145/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="120" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">The difference between our zero-shot annotation object detection (ZAD), zero-shot object detection (ZSD), and open-vocabulary detection (OVD). Our ZAD can have novel instances in training images and novel category names, but no additional annotations are allowed.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">We propose an alternate setting that we call <span id="S1.p2.1.1" class="ltx_text ltx_font_bold">Z</span>ero-shot <span id="S1.p2.1.2" class="ltx_text ltx_font_bold">A</span>nnotation object <span id="S1.p2.1.3" class="ltx_text ltx_font_bold">D</span>etection (<span id="S1.p2.1.4" class="ltx_text ltx_font_bold">ZAD</span>) task, which allows the training data to contain unannotated novel category instances and a model to mine this information at training time if novel category names are available in advance. However, additional category names may be added at inference time, as in OVD.
Thus, ZAD falls in between ZSD and OVD, as Fig <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows. We believe ZAD is closer to a real-life setting: when no additional data or annotation is provided, a user wanting to add categories not considered at annotation time but exploiting the latent information as novel category names are added at the training time.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To recognize novel instances when only their name is available, it is natural to consider a vision-language feature space.
In recent years, some large-scale vision-language classification models trained on millions of image-text pairs, for instance, CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, ALIGN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> have become available.
Different solutions are proposed to leverage these models to enable a detector to detect novel objects.
Some researchers<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> use these models to generate pseudo-label and train their model with pseudo-label and the image-caption pair, while other trains a prompt<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to turn the CLIP into a detector.
However, all these methods need additional captions or images, which are unavailable in our ZAD setting.
In contrast, pure distillation-based methods<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> learn a mapping from image regions to CLIP feature space by distillation for detecting the novel object, which is applicable when no additional data is provided.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To know how good the features are for distillation, we first apply CLIP to classify the instances in the COCO<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> dataset.
We found that the classification accuracy (ACC) is only 46% which is much lower than the ACC of the classifier in Faster R-CNN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> (about 90%). This indicates the domain gap between the training data of CLIP and the detection dataset, making the mapping from the image region to the vision-language feature space harder to learn.
In addition, since the distillation is conducted on some specific image regions, how to select such a region is an important question.
ViLD<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> trains an RPN with base category annotations and applies the RPN to the training image again to generate proposals as distillation regions.
As table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows, these proposals are biased toward the region with base categories instances, which limits the novel information obtained by the detector and harms the distillation efficiency.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To address these problems, we propose <span id="S1.p5.1.1" class="ltx_text ltx_font_bold">E</span>fficient Feature Distillation for <span id="S1.p5.1.2" class="ltx_text ltx_font_bold">Z</span>ero-shot <span id="S1.p5.1.3" class="ltx_text ltx_font_bold">A</span>nnotation object <span id="S1.p5.1.4" class="ltx_text ltx_font_bold">D</span>etection (<span id="S1.p5.1.5" class="ltx_text ltx_font_bold">EZAD</span>).
For bridging the domain gap, we find that simply finetuning the LayerNorm layers in the CLIP with the base category instances significantly improves the ACC on both base and novel (Fig <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, 1).
For the distillation regions, we expect these regions could contain novel objects so that some novel category information can be introduced into the detector.
To make the best use of the only information we have in the ZAD setting, the name of novel categories, we decided to use CLIP to select these regions with the help of the novel category names.
The selected regions are named CLIP Proposals, in which CLIP believes there is a novel category instance(Fig <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, 2).</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">After adapting the feature space and generating the CLIP Proposals, EZAD learns a mapping from the image regions to the vision-language feature space by distillation, which is achieved by minimizing the L1 loss between the features of the CLIP Proposals from the CLIP, and the one from our model (Fig <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, 3).
Once the model is trained, in all potential regions given by the RPN, EZAD recognizes the novel objects by using the novel category name’s text embedding, which has a high cosine similarity score with the image feature of the novel objects (Fig <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, 4).
To further improve the model performance, we introduce a semantic-based regressor, which takes the text embedding as additional information for regression.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">By only providing the name of the novel categories to EZAD, EZAD can outperform ViLD by 4% in novel categories with a much shorter training schedule in COCO. On the LVIS dataset, our method achieves better performance than ViLD on both base and novel categories. This indicates that the adapted feature and CLIP Proposals benefit both distillation quality and training efficiency.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2303.12145/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="344" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.3.2" class="ltx_text" style="font-size:90%;">Overview of our method. The key contributions of EZAD are we bridge the domain gap and create better distillation regions (CLIP proposals).</span></figcaption>
</figure>
<figure id="S1.T1" class="ltx_table">
<table id="S1.T1.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.2.1.1" class="ltx_tr">
<th id="S1.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Dataset</th>
<th id="S1.T1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Eval On</th>
<th id="S1.T1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AR@100</th>
<th id="S1.T1.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AR@300</th>
<th id="S1.T1.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AR@1000</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.2.2.1" class="ltx_tr">
<th id="S1.T1.2.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S1.T1.2.2.1.1.1" class="ltx_text">COCO</span></th>
<th id="S1.T1.2.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Base</th>
<td id="S1.T1.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.2.2.1.3.1" class="ltx_text ltx_font_bold">56.69</span></td>
<td id="S1.T1.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.2.2.1.4.1" class="ltx_text ltx_font_bold">61.45</span></td>
<td id="S1.T1.2.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.2.2.1.5.1" class="ltx_text ltx_font_bold">64.32</span></td>
</tr>
<tr id="S1.T1.2.3.2" class="ltx_tr">
<th id="S1.T1.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Novel</th>
<td id="S1.T1.2.3.2.2" class="ltx_td ltx_align_center">34.66</td>
<td id="S1.T1.2.3.2.3" class="ltx_td ltx_align_center">43.62</td>
<td id="S1.T1.2.3.2.4" class="ltx_td ltx_align_center">51.34</td>
</tr>
<tr id="S1.T1.2.4.3" class="ltx_tr">
<th id="S1.T1.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S1.T1.2.4.3.1.1" class="ltx_text">LVIS</span></th>
<th id="S1.T1.2.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Base</th>
<td id="S1.T1.2.4.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.2.4.3.3.1" class="ltx_text ltx_font_bold">42.14</span></td>
<td id="S1.T1.2.4.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.2.4.3.4.1" class="ltx_text ltx_font_bold">49.84</span></td>
<td id="S1.T1.2.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.2.4.3.5.1" class="ltx_text ltx_font_bold">55.09</span></td>
</tr>
<tr id="S1.T1.2.5.4" class="ltx_tr">
<th id="S1.T1.2.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Novel</th>
<td id="S1.T1.2.5.4.2" class="ltx_td ltx_align_center ltx_border_b">35.63</td>
<td id="S1.T1.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b">45.07</td>
<td id="S1.T1.2.5.4.4" class="ltx_td ltx_align_center ltx_border_b">51.82</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S1.T1.4.2" class="ltx_text" style="font-size:90%;">The Recall of RPN on Novel and Base categories on COCO or LVIS training set. The RPN biases to the base category.</span></figcaption>
</figure>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2303.12145/assets/x3.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="83" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S1.F3.3.2" class="ltx_text" style="font-size:90%;">The pipeline of CLIP Proposals generation. The CLIP Proposals and their feature are generated before the detector training.</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">The Large-scale Pretraining</span> already exist in Vision (MOCO<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, MOCOv2<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, etc.) and Language (BERT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, GPT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, etc.) for a long time.
Recently, there is a trend to use free-form supervision (raw text) to train the vision model which has evolved to large-scale vision-language pre-trained models.
For instance, the CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and ALIGN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> are trained with a large-scale dataset with hundreds of millions of image-text pairs using contrastive learning.
GLIP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> is pre-trained at an object-level with a large-scale grounding dataset.
These multi-modal models’ feature space and their knowledge are useful and can be applied to many other tasks, such as zero-shot classification and zero-shot detection.
However, the training data of these models are usually noisy and there is a domain gap between these data and the datasets of downstream tasks.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Domain Adaptation</span> is necessary when we apply a pre-trained model to other datasets.
In computer vision, the most common method for bridging the domain gap is to finetune the whole network on the new dataset or add one extra MLP layer at the end.
In the natural language processing community, Prompt tuning<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> surfaced as an important tool for domain adaptation in recent years.
Besides, the simple renormalization method is found to be effective by Perez<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and Lu<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.
For adapting the large-scale multi-modal model, Kim et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> discuss the effectiveness of different ways in adapting the CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> to new classification datasets. As far as we know, no paper discusses bridging the domain gap between image-level and instance-level tasks.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Zero-shot Detection object (ZSD) and Open Vocabulary object Detection (OVD)</span> aim to learn knowledge from the base categories and to generalize the knowledge to the novel categories, enabling the model to detect novel objects.
Bansal et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, Zhu et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, Rahman et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, and Xie et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> focus on ZSD, in which novel instances cannot exist in the training image.
However, in most object detection datasets, not all the instances on the image will be annotated.
This makes the ZSD setting too restricted.
Zhong et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, Zhou et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> and Zareian et al<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> pre-train their model with image-caption pair to learn the vision-language feature space for open vocabulary detection.
Gao et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, Long et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, Wang et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> Zhao et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> train its model with pseudo-label.
Feng et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, Kuo et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and Wu et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> design a prompt to make use of CLIP for detection.
Ma et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and Gu et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> distill visual features from CLIP, enabling object detectors to detect novel instances.
Wang et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> propose CondHead which can be added to different OVD models to further improve their performance.
All these methods aim to solve the OVD problem, and most of them need additional training data except the distillation-based<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and some prompt-based methods<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.
The distillation-based and prompt-based methods can fit in with our ZAD setting, while the distillation-based method has better overall performance.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2303.12145/assets/x4.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S2.F4.3.2" class="ltx_text" style="font-size:90%;">The training and inference of our model. The figure presents the model structures in the RoI head of the two-stage detector. We use the per CLIP Proposal distillation weight and semantic-based regressor to further improve the model performance.</span></figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p"><span id="S3.p1.2.1" class="ltx_text ltx_font_bold">Setting definition.</span> Our method aims to handle the <span id="S3.p1.2.2" class="ltx_text ltx_font_bold">Z</span>ero-shot <span id="S3.p1.2.3" class="ltx_text ltx_font_bold">A</span>nnotation object <span id="S3.p1.2.4" class="ltx_text ltx_font_bold">D</span>etection (<span id="S3.p1.2.5" class="ltx_text ltx_font_bold">ZAD</span>).
In ZAD, all categories are divided into two parts: the base categories <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="C_{b}" display="inline"><semantics id="S3.p1.1.m1.1a"><msub id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">C</mi><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">𝐶</ci><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">C_{b}</annotation></semantics></math> and the novel categories <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="C_{n}" display="inline"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">C</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">𝐶</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">C_{n}</annotation></semantics></math>.
The name of the base and expected novel category are known before model training.
The training image may have novel category instances, but only the base category will be annotated.
No additional data will be available for the training except the training image and the base categories annotations.
The model is trained on a set of base classes and tested on both base and novel classes.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Method Overview.</span>
Inspired by the previous paper ViLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, our proposed method, <span id="S3.p2.1.2" class="ltx_text ltx_font_bold">E</span>fficient Feature Distillation for <span id="S3.p2.1.3" class="ltx_text ltx_font_bold">Z</span>ero-shot <span id="S3.p2.1.4" class="ltx_text ltx_font_bold">A</span>nnotation object <span id="S3.p2.1.5" class="ltx_text ltx_font_bold">D</span>etection (<span id="S3.p2.1.6" class="ltx_text ltx_font_bold">EZAD</span>), map the image feature to the CLIP’s multi-modal feature space.
The <span id="S3.p2.1.7" class="ltx_text ltx_font_bold ltx_font_italic">mapping</span> is learned by distilling the knowledge from CLIP in some selected <span id="S3.p2.1.8" class="ltx_text ltx_font_bold ltx_font_italic">distillation regions</span> of each training image.
The knowledge distillation is conducted by optimizing the L1 loss between the <span id="S3.p2.1.9" class="ltx_text ltx_font_bold ltx_font_italic">feature from CLIP</span> and the feature from our model in the selected regions.
After learning the mapping, given the proposal from the RPN, our model can recognize and detect novel objects by using the text embedding of the novel categories.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In Section <a href="#S3.SS1" title="3.1 Adapt Vision-language Model Feature ‣ 3 Method ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, we describe how to adapt the <span id="S3.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">feature from CLIP</span> to the domain of detection datasets.
In Section <a href="#S3.SS2" title="3.2 Generate CLIP Proposals ‣ 3 Method ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we demonstrate how to select the <span id="S3.p3.1.2" class="ltx_text ltx_font_bold ltx_font_italic">distillation regions</span> on each image.
In Section <a href="#S3.SS3" title="3.3 Model Structure ‣ 3 Method ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>, we discuss our model structure and how to train our model and learn the <span id="S3.p3.1.3" class="ltx_text ltx_font_bold ltx_font_italic">mapping</span> with the adapted feature from the selected regions.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Adapt Vision-language Model Feature</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.7" class="ltx_p">To understand how good the image feature from CLIP is, we first apply the CLIP to classify the instances in the COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> dataset.
We first extract the feature for each instance from the vision encoder of the CLIP.
The feature of the instance <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">i</annotation></semantics></math> can be expressed as: <math id="S3.SS1.p1.2.m2.1" class="ltx_math_unparsed" alttext="ins_{i}=V(Crop(I," display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1b"><mi id="S3.SS1.p1.2.m2.1.1">i</mi><mi id="S3.SS1.p1.2.m2.1.2">n</mi><msub id="S3.SS1.p1.2.m2.1.3"><mi id="S3.SS1.p1.2.m2.1.3.2">s</mi><mi id="S3.SS1.p1.2.m2.1.3.3">i</mi></msub><mo id="S3.SS1.p1.2.m2.1.4">=</mo><mi id="S3.SS1.p1.2.m2.1.5">V</mi><mrow id="S3.SS1.p1.2.m2.1.6"><mo stretchy="false" id="S3.SS1.p1.2.m2.1.6.1">(</mo><mi id="S3.SS1.p1.2.m2.1.6.2">C</mi><mi id="S3.SS1.p1.2.m2.1.6.3">r</mi><mi id="S3.SS1.p1.2.m2.1.6.4">o</mi><mi id="S3.SS1.p1.2.m2.1.6.5">p</mi><mrow id="S3.SS1.p1.2.m2.1.6.6"><mo stretchy="false" id="S3.SS1.p1.2.m2.1.6.6.1">(</mo><mi id="S3.SS1.p1.2.m2.1.6.6.2">I</mi><mo id="S3.SS1.p1.2.m2.1.6.6.3">,</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">ins_{i}=V(Crop(I,</annotation></semantics></math> <math id="S3.SS1.p1.3.m3.1" class="ltx_math_unparsed" alttext="GT_{i(1.2x)}))" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1b"><mrow id="S3.SS1.p1.3.m3.1.2"><mi id="S3.SS1.p1.3.m3.1.2.1">G</mi><msub id="S3.SS1.p1.3.m3.1.2.2"><mi id="S3.SS1.p1.3.m3.1.2.2.2">T</mi><mrow id="S3.SS1.p1.3.m3.1.1.1"><mi id="S3.SS1.p1.3.m3.1.1.1.3">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.1.1.1.2">​</mo><mrow id="S3.SS1.p1.3.m3.1.1.1.1.1"><mo stretchy="false" id="S3.SS1.p1.3.m3.1.1.1.1.1.2">(</mo><mrow id="S3.SS1.p1.3.m3.1.1.1.1.1.1"><mn id="S3.SS1.p1.3.m3.1.1.1.1.1.1.2">1.2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.1.1.1.1.1.1.1">​</mo><mi id="S3.SS1.p1.3.m3.1.1.1.1.1.1.3">x</mi></mrow><mo stretchy="false" id="S3.SS1.p1.3.m3.1.1.1.1.1.3">)</mo></mrow></mrow></msub><mo stretchy="false" id="S3.SS1.p1.3.m3.1.2.3">)</mo></mrow><mo stretchy="false" id="S3.SS1.p1.3.m3.1.3">)</mo></mrow><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">GT_{i(1.2x)}))</annotation></semantics></math>, where <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">V</annotation></semantics></math> is the vision encoder of the CLIP and <math id="S3.SS1.p1.5.m5.3" class="ltx_Math" alttext="Crop(I,GT_{i(1.2x)})" display="inline"><semantics id="S3.SS1.p1.5.m5.3a"><mrow id="S3.SS1.p1.5.m5.3.3" xref="S3.SS1.p1.5.m5.3.3.cmml"><mi id="S3.SS1.p1.5.m5.3.3.3" xref="S3.SS1.p1.5.m5.3.3.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.3.3.2" xref="S3.SS1.p1.5.m5.3.3.2.cmml">​</mo><mi id="S3.SS1.p1.5.m5.3.3.4" xref="S3.SS1.p1.5.m5.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.3.3.2a" xref="S3.SS1.p1.5.m5.3.3.2.cmml">​</mo><mi id="S3.SS1.p1.5.m5.3.3.5" xref="S3.SS1.p1.5.m5.3.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.3.3.2b" xref="S3.SS1.p1.5.m5.3.3.2.cmml">​</mo><mi id="S3.SS1.p1.5.m5.3.3.6" xref="S3.SS1.p1.5.m5.3.3.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.3.3.2c" xref="S3.SS1.p1.5.m5.3.3.2.cmml">​</mo><mrow id="S3.SS1.p1.5.m5.3.3.1.1" xref="S3.SS1.p1.5.m5.3.3.1.2.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.3.3.1.1.2" xref="S3.SS1.p1.5.m5.3.3.1.2.cmml">(</mo><mi id="S3.SS1.p1.5.m5.2.2" xref="S3.SS1.p1.5.m5.2.2.cmml">I</mi><mo id="S3.SS1.p1.5.m5.3.3.1.1.3" xref="S3.SS1.p1.5.m5.3.3.1.2.cmml">,</mo><mrow id="S3.SS1.p1.5.m5.3.3.1.1.1" xref="S3.SS1.p1.5.m5.3.3.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.3.3.1.1.1.2" xref="S3.SS1.p1.5.m5.3.3.1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.3.3.1.1.1.1" xref="S3.SS1.p1.5.m5.3.3.1.1.1.1.cmml">​</mo><msub id="S3.SS1.p1.5.m5.3.3.1.1.1.3" xref="S3.SS1.p1.5.m5.3.3.1.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.3.3.1.1.1.3.2" xref="S3.SS1.p1.5.m5.3.3.1.1.1.3.2.cmml">T</mi><mrow id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.5.m5.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.5.m5.1.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.5.m5.1.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml"><mn id="S3.SS1.p1.5.m5.1.1.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.2.cmml">1.2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.1.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.SS1.p1.5.m5.1.1.1.1.1.3" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow><mo stretchy="false" id="S3.SS1.p1.5.m5.3.3.1.1.4" xref="S3.SS1.p1.5.m5.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.3b"><apply id="S3.SS1.p1.5.m5.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3"><times id="S3.SS1.p1.5.m5.3.3.2.cmml" xref="S3.SS1.p1.5.m5.3.3.2"></times><ci id="S3.SS1.p1.5.m5.3.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3.3">𝐶</ci><ci id="S3.SS1.p1.5.m5.3.3.4.cmml" xref="S3.SS1.p1.5.m5.3.3.4">𝑟</ci><ci id="S3.SS1.p1.5.m5.3.3.5.cmml" xref="S3.SS1.p1.5.m5.3.3.5">𝑜</ci><ci id="S3.SS1.p1.5.m5.3.3.6.cmml" xref="S3.SS1.p1.5.m5.3.3.6">𝑝</ci><interval closure="open" id="S3.SS1.p1.5.m5.3.3.1.2.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1"><ci id="S3.SS1.p1.5.m5.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2">𝐼</ci><apply id="S3.SS1.p1.5.m5.3.3.1.1.1.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1.1"><times id="S3.SS1.p1.5.m5.3.3.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1.1.1"></times><ci id="S3.SS1.p1.5.m5.3.3.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1.1.2">𝐺</ci><apply id="S3.SS1.p1.5.m5.3.3.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.3.3.1.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.5.m5.3.3.1.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.3.3.1.1.1.3.2">𝑇</ci><apply id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"><times id="S3.SS1.p1.5.m5.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.2"></times><ci id="S3.SS1.p1.5.m5.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.3">𝑖</ci><apply id="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1"><times id="S3.SS1.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.1"></times><cn type="float" id="S3.SS1.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.2">1.2</cn><ci id="S3.SS1.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.3c">Crop(I,GT_{i(1.2x)})</annotation></semantics></math> means cropping the region from Image <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">I</annotation></semantics></math> base on 1.2x enlarged GT bboxes <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="GT_{i(1.2x)}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.2" xref="S3.SS1.p1.7.m7.1.2.cmml"><mi id="S3.SS1.p1.7.m7.1.2.2" xref="S3.SS1.p1.7.m7.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.7.m7.1.2.1" xref="S3.SS1.p1.7.m7.1.2.1.cmml">​</mo><msub id="S3.SS1.p1.7.m7.1.2.3" xref="S3.SS1.p1.7.m7.1.2.3.cmml"><mi id="S3.SS1.p1.7.m7.1.2.3.2" xref="S3.SS1.p1.7.m7.1.2.3.2.cmml">T</mi><mrow id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.1.3" xref="S3.SS1.p1.7.m7.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.7.m7.1.1.1.2" xref="S3.SS1.p1.7.m7.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.7.m7.1.1.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.7.m7.1.1.1.1.1.2" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.7.m7.1.1.1.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.cmml"><mn id="S3.SS1.p1.7.m7.1.1.1.1.1.1.2" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.2.cmml">1.2</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.7.m7.1.1.1.1.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS1.p1.7.m7.1.1.1.1.1.1.3" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.SS1.p1.7.m7.1.1.1.1.1.3" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.2.cmml" xref="S3.SS1.p1.7.m7.1.2"><times id="S3.SS1.p1.7.m7.1.2.1.cmml" xref="S3.SS1.p1.7.m7.1.2.1"></times><ci id="S3.SS1.p1.7.m7.1.2.2.cmml" xref="S3.SS1.p1.7.m7.1.2.2">𝐺</ci><apply id="S3.SS1.p1.7.m7.1.2.3.cmml" xref="S3.SS1.p1.7.m7.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.2.3.1.cmml" xref="S3.SS1.p1.7.m7.1.2.3">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.2.3.2.cmml" xref="S3.SS1.p1.7.m7.1.2.3.2">𝑇</ci><apply id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"><times id="S3.SS1.p1.7.m7.1.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.1.2"></times><ci id="S3.SS1.p1.7.m7.1.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.1.3">𝑖</ci><apply id="S3.SS1.p1.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1.1.1"><times id="S3.SS1.p1.7.m7.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.1"></times><cn type="float" id="S3.SS1.p1.7.m7.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.2">1.2</cn><ci id="S3.SS1.p1.7.m7.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">GT_{i(1.2x)}</annotation></semantics></math>.
We use the 1.2x enlarged bboxes since the enlarged bboxes help CLIP yield the best classification accuracy.
We present more details in the supplementary material.
We generate the text embedding for each COCO category from the text encoder of the CLIP.
We calculate the cosine similarity between the image feature and text embeddings and select the category with the highest cosine score as the predicted category.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We notice that when directly applying the CLIP to classify the COCO instances, the classification accuracy (ACC) is only about 50% which is much lower than the ACC of the classifier in a well-trained detector, indicating that there is a huge distribution gap between the training data of the CLIP and detection datasets.
To bridge the gap, inspired by<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, we simply fine-tune the CLIP’s layer of normalization layers by minimizing the cross-entropy loss, using all base categories instances in the detection dataset.
This simple method boosts the ACC on COCO to about 80%.
Also, using the adapted CLIP feature for distillation helps improve detection results.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Generate CLIP Proposals</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To obtain useful information for the novel categories, we need to select some meaningful image regions for distillation.
we expect these regions to contain some novel category objects,
and introduce information of the novel categories.
ViLD trains an RPN with base category annotations and uses the proposals from this RPN as the distillation regions.
However, since the RPN is trained to predict base categories, which makes the proposals bias toward the areas that contain the base categories and ignore the areas that potentially have the novel category instance.
Instead of using the RPN to determine where to distill, we decided to use CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
Trained with 400 million image and text pairs collected from the internet, CLIP is trained to discriminate a large number of categories.
Therefore, if the region contains a novel object, the CLIP should yield high confidence in it.
We name these regions CLIP Proposals.
Fig <a href="#S1.F3" title="Figure 3 ‣ 1 Introduction ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates how to generate CLIP Proposal.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">To select image regions as the CLIP Proposals, we first generate anchors over the image <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">I</annotation></semantics></math>.
Then we crop the image based on the anchors and extract the feature for these anchors from CLIP’s vision encoder.
We generate the text embeddings <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="T_{i}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">T</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑇</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">T_{i}</annotation></semantics></math> for a given dictionary from the CLIP’s text encoder.
In addition to the information of the novel categories, we also need knowledge of the base categories. Thus, we use all category names as the dictionary.
We classify each anchor by calculating the cosine similarity score between its image feature and all text embeddings.
We use the score after the softmax of the predicted category as the objectness score <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="o_{i}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">o</mi><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">𝑜</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">o_{i}</annotation></semantics></math> of the anchor.
We finally select the anchors with high objectness scores after the Non-Maximum Suppression (NMS) as CLIP Proposals.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.7" class="ltx_p">All the CLIP Proposals <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">C</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝐶</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">C_{i}</annotation></semantics></math> and their feature from CLIP <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">c</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝑐</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">c_{i}</annotation></semantics></math> are generated offline.
The <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">c</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝑐</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">c_{i}</annotation></semantics></math> can be expressed like this: <math id="S3.SS2.p3.4.m4.2" class="ltx_Math" alttext="V(Crop(I,C_{i}))" display="inline"><semantics id="S3.SS2.p3.4.m4.2a"><mrow id="S3.SS2.p3.4.m4.2.2" xref="S3.SS2.p3.4.m4.2.2.cmml"><mi id="S3.SS2.p3.4.m4.2.2.3" xref="S3.SS2.p3.4.m4.2.2.3.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.2.2.2" xref="S3.SS2.p3.4.m4.2.2.2.cmml">​</mo><mrow id="S3.SS2.p3.4.m4.2.2.1.1" xref="S3.SS2.p3.4.m4.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m4.2.2.1.1.2" xref="S3.SS2.p3.4.m4.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.4.m4.2.2.1.1.1" xref="S3.SS2.p3.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.2.2.1.1.1.3" xref="S3.SS2.p3.4.m4.2.2.1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.2.2.1.1.1.2" xref="S3.SS2.p3.4.m4.2.2.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p3.4.m4.2.2.1.1.1.4" xref="S3.SS2.p3.4.m4.2.2.1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.2.2.1.1.1.2a" xref="S3.SS2.p3.4.m4.2.2.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p3.4.m4.2.2.1.1.1.5" xref="S3.SS2.p3.4.m4.2.2.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.2.2.1.1.1.2b" xref="S3.SS2.p3.4.m4.2.2.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p3.4.m4.2.2.1.1.1.6" xref="S3.SS2.p3.4.m4.2.2.1.1.1.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.2.2.1.1.1.2c" xref="S3.SS2.p3.4.m4.2.2.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.2.cmml">(</mo><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">I</mi><mo id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.2.cmml">,</mo><msub id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.2" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.2.cmml">C</mi><mi id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.3" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.4" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.p3.4.m4.2.2.1.1.3" xref="S3.SS2.p3.4.m4.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.2b"><apply id="S3.SS2.p3.4.m4.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2"><times id="S3.SS2.p3.4.m4.2.2.2.cmml" xref="S3.SS2.p3.4.m4.2.2.2"></times><ci id="S3.SS2.p3.4.m4.2.2.3.cmml" xref="S3.SS2.p3.4.m4.2.2.3">𝑉</ci><apply id="S3.SS2.p3.4.m4.2.2.1.1.1.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1"><times id="S3.SS2.p3.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.2"></times><ci id="S3.SS2.p3.4.m4.2.2.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.3">𝐶</ci><ci id="S3.SS2.p3.4.m4.2.2.1.1.1.4.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.4">𝑟</ci><ci id="S3.SS2.p3.4.m4.2.2.1.1.1.5.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.5">𝑜</ci><ci id="S3.SS2.p3.4.m4.2.2.1.1.1.6.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.6">𝑝</ci><interval closure="open" id="S3.SS2.p3.4.m4.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐼</ci><apply id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.2">𝐶</ci><ci id="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.4.m4.2.2.1.1.1.1.1.1.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.2c">V(Crop(I,C_{i}))</annotation></semantics></math>, where <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">V</annotation></semantics></math> and <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="Crop" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mrow id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m6.1.1.1" xref="S3.SS2.p3.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m6.1.1.1a" xref="S3.SS2.p3.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.6.m6.1.1.4" xref="S3.SS2.p3.6.m6.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.6.m6.1.1.1b" xref="S3.SS2.p3.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.6.m6.1.1.5" xref="S3.SS2.p3.6.m6.1.1.5.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><times id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1.1"></times><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝐶</ci><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">𝑟</ci><ci id="S3.SS2.p3.6.m6.1.1.4.cmml" xref="S3.SS2.p3.6.m6.1.1.4">𝑜</ci><ci id="S3.SS2.p3.6.m6.1.1.5.cmml" xref="S3.SS2.p3.6.m6.1.1.5">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">Crop</annotation></semantics></math> are the same as those in <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="ins_{i}" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.1a" xref="S3.SS2.p3.7.m7.1.1.1.cmml">​</mo><msub id="S3.SS2.p3.7.m7.1.1.4" xref="S3.SS2.p3.7.m7.1.1.4.cmml"><mi id="S3.SS2.p3.7.m7.1.1.4.2" xref="S3.SS2.p3.7.m7.1.1.4.2.cmml">s</mi><mi id="S3.SS2.p3.7.m7.1.1.4.3" xref="S3.SS2.p3.7.m7.1.1.4.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><times id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1"></times><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">𝑖</ci><ci id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3">𝑛</ci><apply id="S3.SS2.p3.7.m7.1.1.4.cmml" xref="S3.SS2.p3.7.m7.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.4.1.cmml" xref="S3.SS2.p3.7.m7.1.1.4">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.4.2.cmml" xref="S3.SS2.p3.7.m7.1.1.4.2">𝑠</ci><ci id="S3.SS2.p3.7.m7.1.1.4.3.cmml" xref="S3.SS2.p3.7.m7.1.1.4.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">ins_{i}</annotation></semantics></math> definition.
We also add 1.2x enlarged base categories’ GT bbox as part of the CLIP Proposals.
Our experiments show that even though these CLIP Proposals are noisy, they are still meaningful regions for distillation and help our detector perform better on novel categories.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Model Structure</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Compared with the traditional two-stage detector, our model structure has three main differences: CLIP Proposals’ feature distillation, cosine-similarity-based classifier, and semantic-based regressor.
The model structure overview is shown in Fig <a href="#S2.F4" title="Figure 4 ‣ 2 Related Work ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.10" class="ltx_p"><span id="S3.SS3.p2.10.1" class="ltx_text ltx_font_bold">Proposals’ Feature Distillation.</span>
To obtain knowledge from CLIP and map the image feature from our model into the CLIP’s feature space, we distill the knowledge from CLIP by minimizing the L1 loss between the CLIP Proposals’ feature from the CLIP’s vision encoder <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="c_{i}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">c</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝑐</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">c_{i}</annotation></semantics></math> and the one from our model <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="c^{{}^{\prime}}_{i}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msubsup id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2.2" xref="S3.SS3.p2.2.m2.1.1.2.2.cmml">c</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">i</mi><msup id="S3.SS3.p2.2.m2.1.1.2.3" xref="S3.SS3.p2.2.m2.1.1.2.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2.3a" xref="S3.SS3.p2.2.m2.1.1.2.3.cmml"></mi><mo id="S3.SS3.p2.2.m2.1.1.2.3.1" xref="S3.SS3.p2.2.m2.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><apply id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS3.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2.2">𝑐</ci><apply id="S3.SS3.p2.2.m2.1.1.2.3.cmml" xref="S3.SS3.p2.2.m2.1.1.2.3"><ci id="S3.SS3.p2.2.m2.1.1.2.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.2.3.1">′</ci></apply></apply><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">c^{{}^{\prime}}_{i}</annotation></semantics></math>.
The <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="c^{{}^{\prime}}_{i}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><msubsup id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2.2" xref="S3.SS3.p2.3.m3.1.1.2.2.cmml">c</mi><mi id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">i</mi><msup id="S3.SS3.p2.3.m3.1.1.2.3" xref="S3.SS3.p2.3.m3.1.1.2.3.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2.3a" xref="S3.SS3.p2.3.m3.1.1.2.3.cmml"></mi><mo id="S3.SS3.p2.3.m3.1.1.2.3.1" xref="S3.SS3.p2.3.m3.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><apply id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.2.1.cmml" xref="S3.SS3.p2.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2.2">𝑐</ci><apply id="S3.SS3.p2.3.m3.1.1.2.3.cmml" xref="S3.SS3.p2.3.m3.1.1.2.3"><ci id="S3.SS3.p2.3.m3.1.1.2.3.1.cmml" xref="S3.SS3.p2.3.m3.1.1.2.3.1">′</ci></apply></apply><ci id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">c^{{}^{\prime}}_{i}</annotation></semantics></math> can be expressed as <math id="S3.SS3.p2.4.m4.2" class="ltx_Math" alttext="Conv_{c}(Align(Bbone(I),C_{i}))" display="inline"><semantics id="S3.SS3.p2.4.m4.2a"><mrow id="S3.SS3.p2.4.m4.2.2" xref="S3.SS3.p2.4.m4.2.2.cmml"><mi id="S3.SS3.p2.4.m4.2.2.3" xref="S3.SS3.p2.4.m4.2.2.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.2" xref="S3.SS3.p2.4.m4.2.2.2.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.4" xref="S3.SS3.p2.4.m4.2.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.2a" xref="S3.SS3.p2.4.m4.2.2.2.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.5" xref="S3.SS3.p2.4.m4.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.2b" xref="S3.SS3.p2.4.m4.2.2.2.cmml">​</mo><msub id="S3.SS3.p2.4.m4.2.2.6" xref="S3.SS3.p2.4.m4.2.2.6.cmml"><mi id="S3.SS3.p2.4.m4.2.2.6.2" xref="S3.SS3.p2.4.m4.2.2.6.2.cmml">v</mi><mi id="S3.SS3.p2.4.m4.2.2.6.3" xref="S3.SS3.p2.4.m4.2.2.6.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.2c" xref="S3.SS3.p2.4.m4.2.2.2.cmml">​</mo><mrow id="S3.SS3.p2.4.m4.2.2.1.1" xref="S3.SS3.p2.4.m4.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p2.4.m4.2.2.1.1.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS3.p2.4.m4.2.2.1.1.1" xref="S3.SS3.p2.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.4" xref="S3.SS3.p2.4.m4.2.2.1.1.1.4.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.3" xref="S3.SS3.p2.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.5" xref="S3.SS3.p2.4.m4.2.2.1.1.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.3a" xref="S3.SS3.p2.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.6" xref="S3.SS3.p2.4.m4.2.2.1.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.3b" xref="S3.SS3.p2.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.7" xref="S3.SS3.p2.4.m4.2.2.1.1.1.7.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.3c" xref="S3.SS3.p2.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.8" xref="S3.SS3.p2.4.m4.2.2.1.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.3d" xref="S3.SS3.p2.4.m4.2.2.1.1.1.3.cmml">​</mo><mrow id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.3" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.3.cmml">(</mo><mrow id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.3" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1a" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.4" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1b" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.5" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1c" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.6" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1d" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.7.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.7.2.1" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.cmml">(</mo><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">I</mi><mo stretchy="false" id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.7.2.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.4" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.3.cmml">,</mo><msub id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.cmml"><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.2" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.2.cmml">C</mi><mi id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.3" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.5" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p2.4.m4.2.2.1.1.3" xref="S3.SS3.p2.4.m4.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.2b"><apply id="S3.SS3.p2.4.m4.2.2.cmml" xref="S3.SS3.p2.4.m4.2.2"><times id="S3.SS3.p2.4.m4.2.2.2.cmml" xref="S3.SS3.p2.4.m4.2.2.2"></times><ci id="S3.SS3.p2.4.m4.2.2.3.cmml" xref="S3.SS3.p2.4.m4.2.2.3">𝐶</ci><ci id="S3.SS3.p2.4.m4.2.2.4.cmml" xref="S3.SS3.p2.4.m4.2.2.4">𝑜</ci><ci id="S3.SS3.p2.4.m4.2.2.5.cmml" xref="S3.SS3.p2.4.m4.2.2.5">𝑛</ci><apply id="S3.SS3.p2.4.m4.2.2.6.cmml" xref="S3.SS3.p2.4.m4.2.2.6"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.2.2.6.1.cmml" xref="S3.SS3.p2.4.m4.2.2.6">subscript</csymbol><ci id="S3.SS3.p2.4.m4.2.2.6.2.cmml" xref="S3.SS3.p2.4.m4.2.2.6.2">𝑣</ci><ci id="S3.SS3.p2.4.m4.2.2.6.3.cmml" xref="S3.SS3.p2.4.m4.2.2.6.3">𝑐</ci></apply><apply id="S3.SS3.p2.4.m4.2.2.1.1.1.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1"><times id="S3.SS3.p2.4.m4.2.2.1.1.1.3.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.3"></times><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.4.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.4">𝐴</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.5.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.5">𝑙</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.6.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.6">𝑖</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.7.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.7">𝑔</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.8.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.8">𝑛</ci><interval closure="open" id="S3.SS3.p2.4.m4.2.2.1.1.1.2.3.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2"><apply id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1"><times id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.1"></times><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.2">𝐵</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.3">𝑏</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.4.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.4">𝑜</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.5.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.5">𝑛</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.6.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.1.1.1.6">𝑒</ci><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">𝐼</ci></apply><apply id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.2">𝐶</ci><ci id="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.3.cmml" xref="S3.SS3.p2.4.m4.2.2.1.1.1.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.2c">Conv_{c}(Align(Bbone(I),C_{i}))</annotation></semantics></math>, where <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="Bbone(I)" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1.2" xref="S3.SS3.p2.5.m5.1.2.cmml"><mi id="S3.SS3.p2.5.m5.1.2.2" xref="S3.SS3.p2.5.m5.1.2.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.2.1" xref="S3.SS3.p2.5.m5.1.2.1.cmml">​</mo><mi id="S3.SS3.p2.5.m5.1.2.3" xref="S3.SS3.p2.5.m5.1.2.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.2.1a" xref="S3.SS3.p2.5.m5.1.2.1.cmml">​</mo><mi id="S3.SS3.p2.5.m5.1.2.4" xref="S3.SS3.p2.5.m5.1.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.2.1b" xref="S3.SS3.p2.5.m5.1.2.1.cmml">​</mo><mi id="S3.SS3.p2.5.m5.1.2.5" xref="S3.SS3.p2.5.m5.1.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.2.1c" xref="S3.SS3.p2.5.m5.1.2.1.cmml">​</mo><mi id="S3.SS3.p2.5.m5.1.2.6" xref="S3.SS3.p2.5.m5.1.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.5.m5.1.2.1d" xref="S3.SS3.p2.5.m5.1.2.1.cmml">​</mo><mrow id="S3.SS3.p2.5.m5.1.2.7.2" xref="S3.SS3.p2.5.m5.1.2.cmml"><mo stretchy="false" id="S3.SS3.p2.5.m5.1.2.7.2.1" xref="S3.SS3.p2.5.m5.1.2.cmml">(</mo><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">I</mi><mo stretchy="false" id="S3.SS3.p2.5.m5.1.2.7.2.2" xref="S3.SS3.p2.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.2.cmml" xref="S3.SS3.p2.5.m5.1.2"><times id="S3.SS3.p2.5.m5.1.2.1.cmml" xref="S3.SS3.p2.5.m5.1.2.1"></times><ci id="S3.SS3.p2.5.m5.1.2.2.cmml" xref="S3.SS3.p2.5.m5.1.2.2">𝐵</ci><ci id="S3.SS3.p2.5.m5.1.2.3.cmml" xref="S3.SS3.p2.5.m5.1.2.3">𝑏</ci><ci id="S3.SS3.p2.5.m5.1.2.4.cmml" xref="S3.SS3.p2.5.m5.1.2.4">𝑜</ci><ci id="S3.SS3.p2.5.m5.1.2.5.cmml" xref="S3.SS3.p2.5.m5.1.2.5">𝑛</ci><ci id="S3.SS3.p2.5.m5.1.2.6.cmml" xref="S3.SS3.p2.5.m5.1.2.6">𝑒</ci><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">Bbone(I)</annotation></semantics></math> means getting the feature map by passing the image <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><mi id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><ci id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">I</annotation></semantics></math> through the backbone <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="Bbone" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mrow id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><mi id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.1" xref="S3.SS3.p2.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.1a" xref="S3.SS3.p2.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.7.m7.1.1.4" xref="S3.SS3.p2.7.m7.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.1b" xref="S3.SS3.p2.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.7.m7.1.1.5" xref="S3.SS3.p2.7.m7.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.7.m7.1.1.1c" xref="S3.SS3.p2.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.7.m7.1.1.6" xref="S3.SS3.p2.7.m7.1.1.6.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><times id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1.1"></times><ci id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2">𝐵</ci><ci id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3">𝑏</ci><ci id="S3.SS3.p2.7.m7.1.1.4.cmml" xref="S3.SS3.p2.7.m7.1.1.4">𝑜</ci><ci id="S3.SS3.p2.7.m7.1.1.5.cmml" xref="S3.SS3.p2.7.m7.1.1.5">𝑛</ci><ci id="S3.SS3.p2.7.m7.1.1.6.cmml" xref="S3.SS3.p2.7.m7.1.1.6">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">Bbone</annotation></semantics></math>, and <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="Align" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><mrow id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2" xref="S3.SS3.p2.8.m8.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.1" xref="S3.SS3.p2.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.1a" xref="S3.SS3.p2.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.8.m8.1.1.4" xref="S3.SS3.p2.8.m8.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.1b" xref="S3.SS3.p2.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.8.m8.1.1.5" xref="S3.SS3.p2.8.m8.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.8.m8.1.1.1c" xref="S3.SS3.p2.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.8.m8.1.1.6" xref="S3.SS3.p2.8.m8.1.1.6.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><times id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1.1"></times><ci id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2">𝐴</ci><ci id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3">𝑙</ci><ci id="S3.SS3.p2.8.m8.1.1.4.cmml" xref="S3.SS3.p2.8.m8.1.1.4">𝑖</ci><ci id="S3.SS3.p2.8.m8.1.1.5.cmml" xref="S3.SS3.p2.8.m8.1.1.5">𝑔</ci><ci id="S3.SS3.p2.8.m8.1.1.6.cmml" xref="S3.SS3.p2.8.m8.1.1.6">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">Align</annotation></semantics></math> means doing the RoIAlign base on the CLIP Proposal <math id="S3.SS3.p2.9.m9.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S3.SS3.p2.9.m9.1a"><msub id="S3.SS3.p2.9.m9.1.1" xref="S3.SS3.p2.9.m9.1.1.cmml"><mi id="S3.SS3.p2.9.m9.1.1.2" xref="S3.SS3.p2.9.m9.1.1.2.cmml">C</mi><mi id="S3.SS3.p2.9.m9.1.1.3" xref="S3.SS3.p2.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m9.1b"><apply id="S3.SS3.p2.9.m9.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.9.m9.1.1.1.cmml" xref="S3.SS3.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.p2.9.m9.1.1.2.cmml" xref="S3.SS3.p2.9.m9.1.1.2">𝐶</ci><ci id="S3.SS3.p2.9.m9.1.1.3.cmml" xref="S3.SS3.p2.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m9.1c">C_{i}</annotation></semantics></math> on the feature map.
<math id="S3.SS3.p2.10.m10.1" class="ltx_Math" alttext="Conv_{c}" display="inline"><semantics id="S3.SS3.p2.10.m10.1a"><mrow id="S3.SS3.p2.10.m10.1.1" xref="S3.SS3.p2.10.m10.1.1.cmml"><mi id="S3.SS3.p2.10.m10.1.1.2" xref="S3.SS3.p2.10.m10.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.10.m10.1.1.1" xref="S3.SS3.p2.10.m10.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.10.m10.1.1.3" xref="S3.SS3.p2.10.m10.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.10.m10.1.1.1a" xref="S3.SS3.p2.10.m10.1.1.1.cmml">​</mo><mi id="S3.SS3.p2.10.m10.1.1.4" xref="S3.SS3.p2.10.m10.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.10.m10.1.1.1b" xref="S3.SS3.p2.10.m10.1.1.1.cmml">​</mo><msub id="S3.SS3.p2.10.m10.1.1.5" xref="S3.SS3.p2.10.m10.1.1.5.cmml"><mi id="S3.SS3.p2.10.m10.1.1.5.2" xref="S3.SS3.p2.10.m10.1.1.5.2.cmml">v</mi><mi id="S3.SS3.p2.10.m10.1.1.5.3" xref="S3.SS3.p2.10.m10.1.1.5.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m10.1b"><apply id="S3.SS3.p2.10.m10.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1"><times id="S3.SS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.p2.10.m10.1.1.1"></times><ci id="S3.SS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.p2.10.m10.1.1.2">𝐶</ci><ci id="S3.SS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.p2.10.m10.1.1.3">𝑜</ci><ci id="S3.SS3.p2.10.m10.1.1.4.cmml" xref="S3.SS3.p2.10.m10.1.1.4">𝑛</ci><apply id="S3.SS3.p2.10.m10.1.1.5.cmml" xref="S3.SS3.p2.10.m10.1.1.5"><csymbol cd="ambiguous" id="S3.SS3.p2.10.m10.1.1.5.1.cmml" xref="S3.SS3.p2.10.m10.1.1.5">subscript</csymbol><ci id="S3.SS3.p2.10.m10.1.1.5.2.cmml" xref="S3.SS3.p2.10.m10.1.1.5.2">𝑣</ci><ci id="S3.SS3.p2.10.m10.1.1.5.3.cmml" xref="S3.SS3.p2.10.m10.1.1.5.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m10.1c">Conv_{c}</annotation></semantics></math> means passing the feature after the RoIAlign through the convolution and linear layers in the classification branch.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.4" class="ltx_p">In the CLIP Proposal generation, we know the objectness score of each proposal.
For the proposal with a higher objectness score, it has a higher probability of having an object in it.
Therefore, we should assign a higher weight to these proposals.
We directly use the objectness score as the weight, and the distillation loss is formulated like this:</p>
<table id="S3.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle L_{dist}=\frac{1}{M}\sum_{i=1}^{M}o_{i}|c_{i}-c^{{}^{\prime}}_{i}|_{1}" display="inline"><semantics id="S3.E1X.2.1.1.m1.1a"><mrow id="S3.E1X.2.1.1.m1.1.1" xref="S3.E1X.2.1.1.m1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.3.2.cmml">L</mi><mrow id="S3.E1X.2.1.1.m1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.3.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.3.3.2" xref="S3.E1X.2.1.1.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E1X.2.1.1.m1.1.1.3.3.1" xref="S3.E1X.2.1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S3.E1X.2.1.1.m1.1.1.3.3.3" xref="S3.E1X.2.1.1.m1.1.1.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E1X.2.1.1.m1.1.1.3.3.1a" xref="S3.E1X.2.1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S3.E1X.2.1.1.m1.1.1.3.3.4" xref="S3.E1X.2.1.1.m1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1X.2.1.1.m1.1.1.3.3.1b" xref="S3.E1X.2.1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S3.E1X.2.1.1.m1.1.1.3.3.5" xref="S3.E1X.2.1.1.m1.1.1.3.3.5.cmml">t</mi></mrow></msub><mo id="S3.E1X.2.1.1.m1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.2.cmml">=</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E1X.2.1.1.m1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.3.cmml"><mfrac id="S3.E1X.2.1.1.m1.1.1.1.3a" xref="S3.E1X.2.1.1.m1.1.1.1.3.cmml"><mn id="S3.E1X.2.1.1.m1.1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.3.2.cmml">1</mn><mi id="S3.E1X.2.1.1.m1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.3.3.cmml">M</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E1X.2.1.1.m1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.2.cmml">​</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E1X.2.1.1.m1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml"><munderover id="S3.E1X.2.1.1.m1.1.1.1.1.2a" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1X.2.1.1.m1.1.1.1.1.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.3.cmml">M</mi></munderover></mstyle><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2.cmml">o</mi><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml">​</mo><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">c</mi><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msubsup id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">c</mi><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi><msup id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3a" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml"></mi><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">′</mo></msup></msubsup></mrow><mo stretchy="false" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mn id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.2.1.1.m1.1b"><apply id="S3.E1X.2.1.1.m1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1"><eq id="S3.E1X.2.1.1.m1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.2"></eq><apply id="S3.E1X.2.1.1.m1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.2">𝐿</ci><apply id="S3.E1X.2.1.1.m1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.3"><times id="S3.E1X.2.1.1.m1.1.1.3.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.3.1"></times><ci id="S3.E1X.2.1.1.m1.1.1.3.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.3.2">𝑑</ci><ci id="S3.E1X.2.1.1.m1.1.1.3.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.3.3">𝑖</ci><ci id="S3.E1X.2.1.1.m1.1.1.3.3.4.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.3.4">𝑠</ci><ci id="S3.E1X.2.1.1.m1.1.1.3.3.5.cmml" xref="S3.E1X.2.1.1.m1.1.1.3.3.5">𝑡</ci></apply></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1"><times id="S3.E1X.2.1.1.m1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.2"></times><apply id="S3.E1X.2.1.1.m1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.3"><divide id="S3.E1X.2.1.1.m1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.3"></divide><cn type="integer" id="S3.E1X.2.1.1.m1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.3.2">1</cn><ci id="S3.E1X.2.1.1.m1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.3.3">𝑀</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1"><apply id="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3"><eq id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1X.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.3">𝑀</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1"><times id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2"></times><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2">𝑜</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1"><abs id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2"></abs><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2">𝑐</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.2">𝑐</ci><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3"><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.2.3.1">′</ci></apply></apply><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><cn type="integer" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.2.1.1.m1.1c">\displaystyle L_{dist}=\frac{1}{M}\sum_{i=1}^{M}o_{i}|c_{i}-c^{{}^{\prime}}_{i}|_{1}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.p3.3" class="ltx_p">where <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="o_{i}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">o</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝑜</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">o_{i}</annotation></semantics></math> is the objectness score of the CLIP Proposal <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝐶</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">C_{i}</annotation></semantics></math> and <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mi id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><ci id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">M</annotation></semantics></math> is the number of the CLIP Proposal on one image.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.9" class="ltx_p"><span id="S3.SS3.p4.9.1" class="ltx_text ltx_font_bold">Cosine-similarity-based Classifier.</span>
By distilling the knowledge from CLIP, we are able to map the image feature of our model to CLIP feature space.
Instead of using a learnable linear layer as the classifier, we use text embedding generated from CLIP’s text encoder. In the training phase, we only need the name of the base categories, which are then converted into text embedding <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="B_{i}" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">B</mi><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">𝐵</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">B_{i}</annotation></semantics></math>.
For each proposal <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><msub id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">P</mi><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">𝑃</ci><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">P_{i}</annotation></semantics></math> given by the Region Proposal Network(RPN), we generate its feature <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><msub id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mi id="S3.SS3.p4.3.m3.1.1.2" xref="S3.SS3.p4.3.m3.1.1.2.cmml">p</mi><mi id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2">𝑝</ci><ci id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">p_{i}</annotation></semantics></math>. The <math id="S3.SS3.p4.4.m4.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS3.p4.4.m4.1a"><msub id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml">p</mi><mi id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2">𝑝</ci><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">p_{i}</annotation></semantics></math> can be expressed as: <math id="S3.SS3.p4.5.m5.2" class="ltx_Math" alttext="p_{i}=Conv_{c}(Align(Bbone(I),P_{i}))" display="inline"><semantics id="S3.SS3.p4.5.m5.2a"><mrow id="S3.SS3.p4.5.m5.2.2" xref="S3.SS3.p4.5.m5.2.2.cmml"><msub id="S3.SS3.p4.5.m5.2.2.3" xref="S3.SS3.p4.5.m5.2.2.3.cmml"><mi id="S3.SS3.p4.5.m5.2.2.3.2" xref="S3.SS3.p4.5.m5.2.2.3.2.cmml">p</mi><mi id="S3.SS3.p4.5.m5.2.2.3.3" xref="S3.SS3.p4.5.m5.2.2.3.3.cmml">i</mi></msub><mo id="S3.SS3.p4.5.m5.2.2.2" xref="S3.SS3.p4.5.m5.2.2.2.cmml">=</mo><mrow id="S3.SS3.p4.5.m5.2.2.1" xref="S3.SS3.p4.5.m5.2.2.1.cmml"><mi id="S3.SS3.p4.5.m5.2.2.1.3" xref="S3.SS3.p4.5.m5.2.2.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.2" xref="S3.SS3.p4.5.m5.2.2.1.2.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.4" xref="S3.SS3.p4.5.m5.2.2.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.2a" xref="S3.SS3.p4.5.m5.2.2.1.2.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.5" xref="S3.SS3.p4.5.m5.2.2.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.2b" xref="S3.SS3.p4.5.m5.2.2.1.2.cmml">​</mo><msub id="S3.SS3.p4.5.m5.2.2.1.6" xref="S3.SS3.p4.5.m5.2.2.1.6.cmml"><mi id="S3.SS3.p4.5.m5.2.2.1.6.2" xref="S3.SS3.p4.5.m5.2.2.1.6.2.cmml">v</mi><mi id="S3.SS3.p4.5.m5.2.2.1.6.3" xref="S3.SS3.p4.5.m5.2.2.1.6.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.2c" xref="S3.SS3.p4.5.m5.2.2.1.2.cmml">​</mo><mrow id="S3.SS3.p4.5.m5.2.2.1.1.1" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.5.m5.2.2.1.1.1.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.5.m5.2.2.1.1.1.1" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.cmml"><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.4" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.4.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.3" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.5" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.3a" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.6" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.3b" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.7" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.7.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.3c" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.8" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.3d" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.3.cmml">​</mo><mrow id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.3" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.3.cmml">(</mo><mrow id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.3" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1a" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.4" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1b" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.5" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1c" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.6" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1d" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.7.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.7.2.1" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">I</mi><mo stretchy="false" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.7.2.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.4" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.3.cmml">,</mo><msub id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.cmml"><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.2" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.2.cmml">P</mi><mi id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.3" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.5" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p4.5.m5.2.2.1.1.1.3" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.2b"><apply id="S3.SS3.p4.5.m5.2.2.cmml" xref="S3.SS3.p4.5.m5.2.2"><eq id="S3.SS3.p4.5.m5.2.2.2.cmml" xref="S3.SS3.p4.5.m5.2.2.2"></eq><apply id="S3.SS3.p4.5.m5.2.2.3.cmml" xref="S3.SS3.p4.5.m5.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.2.2.3.1.cmml" xref="S3.SS3.p4.5.m5.2.2.3">subscript</csymbol><ci id="S3.SS3.p4.5.m5.2.2.3.2.cmml" xref="S3.SS3.p4.5.m5.2.2.3.2">𝑝</ci><ci id="S3.SS3.p4.5.m5.2.2.3.3.cmml" xref="S3.SS3.p4.5.m5.2.2.3.3">𝑖</ci></apply><apply id="S3.SS3.p4.5.m5.2.2.1.cmml" xref="S3.SS3.p4.5.m5.2.2.1"><times id="S3.SS3.p4.5.m5.2.2.1.2.cmml" xref="S3.SS3.p4.5.m5.2.2.1.2"></times><ci id="S3.SS3.p4.5.m5.2.2.1.3.cmml" xref="S3.SS3.p4.5.m5.2.2.1.3">𝐶</ci><ci id="S3.SS3.p4.5.m5.2.2.1.4.cmml" xref="S3.SS3.p4.5.m5.2.2.1.4">𝑜</ci><ci id="S3.SS3.p4.5.m5.2.2.1.5.cmml" xref="S3.SS3.p4.5.m5.2.2.1.5">𝑛</ci><apply id="S3.SS3.p4.5.m5.2.2.1.6.cmml" xref="S3.SS3.p4.5.m5.2.2.1.6"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.2.2.1.6.1.cmml" xref="S3.SS3.p4.5.m5.2.2.1.6">subscript</csymbol><ci id="S3.SS3.p4.5.m5.2.2.1.6.2.cmml" xref="S3.SS3.p4.5.m5.2.2.1.6.2">𝑣</ci><ci id="S3.SS3.p4.5.m5.2.2.1.6.3.cmml" xref="S3.SS3.p4.5.m5.2.2.1.6.3">𝑐</ci></apply><apply id="S3.SS3.p4.5.m5.2.2.1.1.1.1.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1"><times id="S3.SS3.p4.5.m5.2.2.1.1.1.1.3.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.3"></times><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.4.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.4">𝐴</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.5.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.5">𝑙</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.6.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.6">𝑖</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.7.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.7">𝑔</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.8.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.8">𝑛</ci><interval closure="open" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2"><apply id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1"><times id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.1"></times><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.2">𝐵</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.3">𝑏</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.4.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.4">𝑜</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.5.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.5">𝑛</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.6.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.1.1.1.6">𝑒</ci><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">𝐼</ci></apply><apply id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.2">𝑃</ci><ci id="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.3.cmml" xref="S3.SS3.p4.5.m5.2.2.1.1.1.1.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.2c">p_{i}=Conv_{c}(Align(Bbone(I),P_{i}))</annotation></semantics></math>, where <math id="S3.SS3.p4.6.m6.1" class="ltx_Math" alttext="Conv_{c}" display="inline"><semantics id="S3.SS3.p4.6.m6.1a"><mrow id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml"><mi id="S3.SS3.p4.6.m6.1.1.2" xref="S3.SS3.p4.6.m6.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.1.1.1" xref="S3.SS3.p4.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.6.m6.1.1.3" xref="S3.SS3.p4.6.m6.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.1.1.1a" xref="S3.SS3.p4.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.6.m6.1.1.4" xref="S3.SS3.p4.6.m6.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.6.m6.1.1.1b" xref="S3.SS3.p4.6.m6.1.1.1.cmml">​</mo><msub id="S3.SS3.p4.6.m6.1.1.5" xref="S3.SS3.p4.6.m6.1.1.5.cmml"><mi id="S3.SS3.p4.6.m6.1.1.5.2" xref="S3.SS3.p4.6.m6.1.1.5.2.cmml">v</mi><mi id="S3.SS3.p4.6.m6.1.1.5.3" xref="S3.SS3.p4.6.m6.1.1.5.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><apply id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1"><times id="S3.SS3.p4.6.m6.1.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1.1"></times><ci id="S3.SS3.p4.6.m6.1.1.2.cmml" xref="S3.SS3.p4.6.m6.1.1.2">𝐶</ci><ci id="S3.SS3.p4.6.m6.1.1.3.cmml" xref="S3.SS3.p4.6.m6.1.1.3">𝑜</ci><ci id="S3.SS3.p4.6.m6.1.1.4.cmml" xref="S3.SS3.p4.6.m6.1.1.4">𝑛</ci><apply id="S3.SS3.p4.6.m6.1.1.5.cmml" xref="S3.SS3.p4.6.m6.1.1.5"><csymbol cd="ambiguous" id="S3.SS3.p4.6.m6.1.1.5.1.cmml" xref="S3.SS3.p4.6.m6.1.1.5">subscript</csymbol><ci id="S3.SS3.p4.6.m6.1.1.5.2.cmml" xref="S3.SS3.p4.6.m6.1.1.5.2">𝑣</ci><ci id="S3.SS3.p4.6.m6.1.1.5.3.cmml" xref="S3.SS3.p4.6.m6.1.1.5.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">Conv_{c}</annotation></semantics></math>, <math id="S3.SS3.p4.7.m7.1" class="ltx_Math" alttext="Align" display="inline"><semantics id="S3.SS3.p4.7.m7.1a"><mrow id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml"><mi id="S3.SS3.p4.7.m7.1.1.2" xref="S3.SS3.p4.7.m7.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.7.m7.1.1.1" xref="S3.SS3.p4.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.7.m7.1.1.3" xref="S3.SS3.p4.7.m7.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.7.m7.1.1.1a" xref="S3.SS3.p4.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.7.m7.1.1.4" xref="S3.SS3.p4.7.m7.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.7.m7.1.1.1b" xref="S3.SS3.p4.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.7.m7.1.1.5" xref="S3.SS3.p4.7.m7.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.7.m7.1.1.1c" xref="S3.SS3.p4.7.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.7.m7.1.1.6" xref="S3.SS3.p4.7.m7.1.1.6.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><apply id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1"><times id="S3.SS3.p4.7.m7.1.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1.1"></times><ci id="S3.SS3.p4.7.m7.1.1.2.cmml" xref="S3.SS3.p4.7.m7.1.1.2">𝐴</ci><ci id="S3.SS3.p4.7.m7.1.1.3.cmml" xref="S3.SS3.p4.7.m7.1.1.3">𝑙</ci><ci id="S3.SS3.p4.7.m7.1.1.4.cmml" xref="S3.SS3.p4.7.m7.1.1.4">𝑖</ci><ci id="S3.SS3.p4.7.m7.1.1.5.cmml" xref="S3.SS3.p4.7.m7.1.1.5">𝑔</ci><ci id="S3.SS3.p4.7.m7.1.1.6.cmml" xref="S3.SS3.p4.7.m7.1.1.6">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">Align</annotation></semantics></math>, and <math id="S3.SS3.p4.8.m8.1" class="ltx_Math" alttext="Bbone" display="inline"><semantics id="S3.SS3.p4.8.m8.1a"><mrow id="S3.SS3.p4.8.m8.1.1" xref="S3.SS3.p4.8.m8.1.1.cmml"><mi id="S3.SS3.p4.8.m8.1.1.2" xref="S3.SS3.p4.8.m8.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.8.m8.1.1.1" xref="S3.SS3.p4.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.8.m8.1.1.3" xref="S3.SS3.p4.8.m8.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.8.m8.1.1.1a" xref="S3.SS3.p4.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.8.m8.1.1.4" xref="S3.SS3.p4.8.m8.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.8.m8.1.1.1b" xref="S3.SS3.p4.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.8.m8.1.1.5" xref="S3.SS3.p4.8.m8.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.8.m8.1.1.1c" xref="S3.SS3.p4.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.8.m8.1.1.6" xref="S3.SS3.p4.8.m8.1.1.6.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.8.m8.1b"><apply id="S3.SS3.p4.8.m8.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1"><times id="S3.SS3.p4.8.m8.1.1.1.cmml" xref="S3.SS3.p4.8.m8.1.1.1"></times><ci id="S3.SS3.p4.8.m8.1.1.2.cmml" xref="S3.SS3.p4.8.m8.1.1.2">𝐵</ci><ci id="S3.SS3.p4.8.m8.1.1.3.cmml" xref="S3.SS3.p4.8.m8.1.1.3">𝑏</ci><ci id="S3.SS3.p4.8.m8.1.1.4.cmml" xref="S3.SS3.p4.8.m8.1.1.4">𝑜</ci><ci id="S3.SS3.p4.8.m8.1.1.5.cmml" xref="S3.SS3.p4.8.m8.1.1.5">𝑛</ci><ci id="S3.SS3.p4.8.m8.1.1.6.cmml" xref="S3.SS3.p4.8.m8.1.1.6">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.8.m8.1c">Bbone</annotation></semantics></math> are the same as those in <math id="S3.SS3.p4.9.m9.1" class="ltx_Math" alttext="c^{{}^{\prime}}_{i}" display="inline"><semantics id="S3.SS3.p4.9.m9.1a"><msubsup id="S3.SS3.p4.9.m9.1.1" xref="S3.SS3.p4.9.m9.1.1.cmml"><mi id="S3.SS3.p4.9.m9.1.1.2.2" xref="S3.SS3.p4.9.m9.1.1.2.2.cmml">c</mi><mi id="S3.SS3.p4.9.m9.1.1.3" xref="S3.SS3.p4.9.m9.1.1.3.cmml">i</mi><msup id="S3.SS3.p4.9.m9.1.1.2.3" xref="S3.SS3.p4.9.m9.1.1.2.3.cmml"><mi id="S3.SS3.p4.9.m9.1.1.2.3a" xref="S3.SS3.p4.9.m9.1.1.2.3.cmml"></mi><mo id="S3.SS3.p4.9.m9.1.1.2.3.1" xref="S3.SS3.p4.9.m9.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.9.m9.1b"><apply id="S3.SS3.p4.9.m9.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.9.m9.1.1.1.cmml" xref="S3.SS3.p4.9.m9.1.1">subscript</csymbol><apply id="S3.SS3.p4.9.m9.1.1.2.cmml" xref="S3.SS3.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.9.m9.1.1.2.1.cmml" xref="S3.SS3.p4.9.m9.1.1">superscript</csymbol><ci id="S3.SS3.p4.9.m9.1.1.2.2.cmml" xref="S3.SS3.p4.9.m9.1.1.2.2">𝑐</ci><apply id="S3.SS3.p4.9.m9.1.1.2.3.cmml" xref="S3.SS3.p4.9.m9.1.1.2.3"><ci id="S3.SS3.p4.9.m9.1.1.2.3.1.cmml" xref="S3.SS3.p4.9.m9.1.1.2.3.1">′</ci></apply></apply><ci id="S3.SS3.p4.9.m9.1.1.3.cmml" xref="S3.SS3.p4.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.9.m9.1c">c^{{}^{\prime}}_{i}</annotation></semantics></math> definition. The classification loss is given by:</p>
<table id="S3.E2" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E2X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle L_{cls}=\frac{1}{N}\sum_{i=1}^{N}L_{CE}(softmax(\boldsymbol{cos_{i}}),y_{i})" display="inline"><semantics id="S3.E2X.2.1.1.m1.2a"><mrow id="S3.E2X.2.1.1.m1.2.2" xref="S3.E2X.2.1.1.m1.2.2.cmml"><msub id="S3.E2X.2.1.1.m1.2.2.4" xref="S3.E2X.2.1.1.m1.2.2.4.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.4.2" xref="S3.E2X.2.1.1.m1.2.2.4.2.cmml">L</mi><mrow id="S3.E2X.2.1.1.m1.2.2.4.3" xref="S3.E2X.2.1.1.m1.2.2.4.3.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.4.3.2" xref="S3.E2X.2.1.1.m1.2.2.4.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.2.2.4.3.1" xref="S3.E2X.2.1.1.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.2.2.4.3.3" xref="S3.E2X.2.1.1.m1.2.2.4.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.2.2.4.3.1a" xref="S3.E2X.2.1.1.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.2.2.4.3.4" xref="S3.E2X.2.1.1.m1.2.2.4.3.4.cmml">s</mi></mrow></msub><mo id="S3.E2X.2.1.1.m1.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E2X.2.1.1.m1.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E2X.2.1.1.m1.2.2.2.4" xref="S3.E2X.2.1.1.m1.2.2.2.4.cmml"><mfrac id="S3.E2X.2.1.1.m1.2.2.2.4a" xref="S3.E2X.2.1.1.m1.2.2.2.4.cmml"><mn id="S3.E2X.2.1.1.m1.2.2.2.4.2" xref="S3.E2X.2.1.1.m1.2.2.2.4.2.cmml">1</mn><mi id="S3.E2X.2.1.1.m1.2.2.2.4.3" xref="S3.E2X.2.1.1.m1.2.2.2.4.3.cmml">N</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E2X.2.1.1.m1.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E2X.2.1.1.m1.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.cmml"><munderover id="S3.E2X.2.1.1.m1.2.2.2.2.3a" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.1" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E2X.2.1.1.m1.2.2.2.2.3.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.3.cmml">N</mi></munderover></mstyle><mrow id="S3.E2X.2.1.1.m1.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.cmml"><msub id="S3.E2X.2.1.1.m1.2.2.2.2.2.4" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.2.cmml">L</mi><mrow id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.1" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.1.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.2.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3.cmml">​</mo><mrow id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.3.cmml">(</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.4" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2a" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.5" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2b" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.6" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2c" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.7" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2d" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.8" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2e" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.9" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.9.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2f" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝒄</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">𝒐</mi><mo lspace="0em" rspace="0em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.2.cmml">𝒔</mi><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.3.cmml">𝒊</mi></msub></mrow><mo stretchy="false" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.4" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.5" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2X.2.1.1.m1.2b"><apply id="S3.E2X.2.1.1.m1.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2"><eq id="S3.E2X.2.1.1.m1.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.3"></eq><apply id="S3.E2X.2.1.1.m1.2.2.4.cmml" xref="S3.E2X.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.4.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.4">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.2.2.4.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.2">𝐿</ci><apply id="S3.E2X.2.1.1.m1.2.2.4.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.3"><times id="S3.E2X.2.1.1.m1.2.2.4.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.3.1"></times><ci id="S3.E2X.2.1.1.m1.2.2.4.3.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.3.2">𝑐</ci><ci id="S3.E2X.2.1.1.m1.2.2.4.3.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.3.3">𝑙</ci><ci id="S3.E2X.2.1.1.m1.2.2.4.3.4.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.3.4">𝑠</ci></apply></apply><apply id="S3.E2X.2.1.1.m1.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2"><times id="S3.E2X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.3"></times><apply id="S3.E2X.2.1.1.m1.2.2.2.4.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.4"><divide id="S3.E2X.2.1.1.m1.2.2.2.4.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.4"></divide><cn type="integer" id="S3.E2X.2.1.1.m1.2.2.2.4.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.4.2">1</cn><ci id="S3.E2X.2.1.1.m1.2.2.2.4.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.4.3">𝑁</ci></apply><apply id="S3.E2X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2"><apply id="S3.E2X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.2.2.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3">superscript</csymbol><apply id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3">subscript</csymbol><sum id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.2"></sum><apply id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3"><eq id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.1"></eq><ci id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E2X.2.1.1.m1.2.2.2.2.3.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3.3">𝑁</ci></apply><apply id="S3.E2X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2"><times id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3"></times><apply id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.2">𝐿</ci><apply id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3"><times id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.1"></times><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.2">𝐶</ci><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.4.3.3">𝐸</ci></apply></apply><interval closure="open" id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2"><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1"><times id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝑠</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.4">𝑜</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.5">𝑓</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.6">𝑡</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.7.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.7">𝑚</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.8.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.8">𝑎</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.9.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.9">𝑥</ci><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2">𝒄</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝒐</ci><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.2">𝒔</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.3">𝒊</ci></apply></apply></apply><apply id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.2">𝑦</ci><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2X.2.1.1.m1.2c">\displaystyle L_{cls}=\frac{1}{N}\sum_{i=1}^{N}L_{CE}(softmax(\boldsymbol{cos_{i}}),y_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.p4.17" class="ltx_p">where N is total number of proposals, <math id="S3.SS3.p4.10.m1.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.SS3.p4.10.m1.1a"><msub id="S3.SS3.p4.10.m1.1.1" xref="S3.SS3.p4.10.m1.1.1.cmml"><mi id="S3.SS3.p4.10.m1.1.1.2" xref="S3.SS3.p4.10.m1.1.1.2.cmml">y</mi><mi id="S3.SS3.p4.10.m1.1.1.3" xref="S3.SS3.p4.10.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.10.m1.1b"><apply id="S3.SS3.p4.10.m1.1.1.cmml" xref="S3.SS3.p4.10.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.10.m1.1.1.1.cmml" xref="S3.SS3.p4.10.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.10.m1.1.1.2.cmml" xref="S3.SS3.p4.10.m1.1.1.2">𝑦</ci><ci id="S3.SS3.p4.10.m1.1.1.3.cmml" xref="S3.SS3.p4.10.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.10.m1.1c">y_{i}</annotation></semantics></math> is the assigned label for the proposal <math id="S3.SS3.p4.11.m2.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.SS3.p4.11.m2.1a"><msub id="S3.SS3.p4.11.m2.1.1" xref="S3.SS3.p4.11.m2.1.1.cmml"><mi id="S3.SS3.p4.11.m2.1.1.2" xref="S3.SS3.p4.11.m2.1.1.2.cmml">P</mi><mi id="S3.SS3.p4.11.m2.1.1.3" xref="S3.SS3.p4.11.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.11.m2.1b"><apply id="S3.SS3.p4.11.m2.1.1.cmml" xref="S3.SS3.p4.11.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.11.m2.1.1.1.cmml" xref="S3.SS3.p4.11.m2.1.1">subscript</csymbol><ci id="S3.SS3.p4.11.m2.1.1.2.cmml" xref="S3.SS3.p4.11.m2.1.1.2">𝑃</ci><ci id="S3.SS3.p4.11.m2.1.1.3.cmml" xref="S3.SS3.p4.11.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.11.m2.1c">P_{i}</annotation></semantics></math>.
The vector <math id="S3.SS3.p4.12.m3.1" class="ltx_Math" alttext="\boldsymbol{cos_{i}}" display="inline"><semantics id="S3.SS3.p4.12.m3.1a"><mrow id="S3.SS3.p4.12.m3.1.1" xref="S3.SS3.p4.12.m3.1.1.cmml"><mi id="S3.SS3.p4.12.m3.1.1.2" xref="S3.SS3.p4.12.m3.1.1.2.cmml">𝒄</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.12.m3.1.1.1" xref="S3.SS3.p4.12.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.12.m3.1.1.3" xref="S3.SS3.p4.12.m3.1.1.3.cmml">𝒐</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.12.m3.1.1.1a" xref="S3.SS3.p4.12.m3.1.1.1.cmml">​</mo><msub id="S3.SS3.p4.12.m3.1.1.4" xref="S3.SS3.p4.12.m3.1.1.4.cmml"><mi id="S3.SS3.p4.12.m3.1.1.4.2" xref="S3.SS3.p4.12.m3.1.1.4.2.cmml">𝒔</mi><mi id="S3.SS3.p4.12.m3.1.1.4.3" xref="S3.SS3.p4.12.m3.1.1.4.3.cmml">𝒊</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.12.m3.1b"><apply id="S3.SS3.p4.12.m3.1.1.cmml" xref="S3.SS3.p4.12.m3.1.1"><times id="S3.SS3.p4.12.m3.1.1.1.cmml" xref="S3.SS3.p4.12.m3.1.1.1"></times><ci id="S3.SS3.p4.12.m3.1.1.2.cmml" xref="S3.SS3.p4.12.m3.1.1.2">𝒄</ci><ci id="S3.SS3.p4.12.m3.1.1.3.cmml" xref="S3.SS3.p4.12.m3.1.1.3">𝒐</ci><apply id="S3.SS3.p4.12.m3.1.1.4.cmml" xref="S3.SS3.p4.12.m3.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p4.12.m3.1.1.4.1.cmml" xref="S3.SS3.p4.12.m3.1.1.4">subscript</csymbol><ci id="S3.SS3.p4.12.m3.1.1.4.2.cmml" xref="S3.SS3.p4.12.m3.1.1.4.2">𝒔</ci><ci id="S3.SS3.p4.12.m3.1.1.4.3.cmml" xref="S3.SS3.p4.12.m3.1.1.4.3">𝒊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.12.m3.1c">\boldsymbol{cos_{i}}</annotation></semantics></math> for the proposal <math id="S3.SS3.p4.13.m4.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.SS3.p4.13.m4.1a"><msub id="S3.SS3.p4.13.m4.1.1" xref="S3.SS3.p4.13.m4.1.1.cmml"><mi id="S3.SS3.p4.13.m4.1.1.2" xref="S3.SS3.p4.13.m4.1.1.2.cmml">P</mi><mi id="S3.SS3.p4.13.m4.1.1.3" xref="S3.SS3.p4.13.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.13.m4.1b"><apply id="S3.SS3.p4.13.m4.1.1.cmml" xref="S3.SS3.p4.13.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.13.m4.1.1.1.cmml" xref="S3.SS3.p4.13.m4.1.1">subscript</csymbol><ci id="S3.SS3.p4.13.m4.1.1.2.cmml" xref="S3.SS3.p4.13.m4.1.1.2">𝑃</ci><ci id="S3.SS3.p4.13.m4.1.1.3.cmml" xref="S3.SS3.p4.13.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.13.m4.1c">P_{i}</annotation></semantics></math> is defined as <math id="S3.SS3.p4.14.m5.4" class="ltx_Math" alttext="[cos(p_{i},B_{1}),\dots,cos(p_{i},B_{n}),cos(p_{i},BG)]" display="inline"><semantics id="S3.SS3.p4.14.m5.4a"><mrow id="S3.SS3.p4.14.m5.4.4.3" xref="S3.SS3.p4.14.m5.4.4.4.cmml"><mo stretchy="false" id="S3.SS3.p4.14.m5.4.4.3.4" xref="S3.SS3.p4.14.m5.4.4.4.cmml">[</mo><mrow id="S3.SS3.p4.14.m5.2.2.1.1" xref="S3.SS3.p4.14.m5.2.2.1.1.cmml"><mi id="S3.SS3.p4.14.m5.2.2.1.1.4" xref="S3.SS3.p4.14.m5.2.2.1.1.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.2.2.1.1.3" xref="S3.SS3.p4.14.m5.2.2.1.1.3.cmml">​</mo><mi id="S3.SS3.p4.14.m5.2.2.1.1.5" xref="S3.SS3.p4.14.m5.2.2.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.2.2.1.1.3a" xref="S3.SS3.p4.14.m5.2.2.1.1.3.cmml">​</mo><mi id="S3.SS3.p4.14.m5.2.2.1.1.6" xref="S3.SS3.p4.14.m5.2.2.1.1.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.2.2.1.1.3b" xref="S3.SS3.p4.14.m5.2.2.1.1.3.cmml">​</mo><mrow id="S3.SS3.p4.14.m5.2.2.1.1.2.2" xref="S3.SS3.p4.14.m5.2.2.1.1.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.14.m5.2.2.1.1.2.2.3" xref="S3.SS3.p4.14.m5.2.2.1.1.2.3.cmml">(</mo><msub id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.cmml"><mi id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.2" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.2.cmml">p</mi><mi id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.3" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p4.14.m5.2.2.1.1.2.2.4" xref="S3.SS3.p4.14.m5.2.2.1.1.2.3.cmml">,</mo><msub id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.cmml"><mi id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.2" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.2.cmml">B</mi><mn id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.3" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S3.SS3.p4.14.m5.2.2.1.1.2.2.5" xref="S3.SS3.p4.14.m5.2.2.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.14.m5.4.4.3.5" xref="S3.SS3.p4.14.m5.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.p4.14.m5.1.1" xref="S3.SS3.p4.14.m5.1.1.cmml">…</mi><mo id="S3.SS3.p4.14.m5.4.4.3.6" xref="S3.SS3.p4.14.m5.4.4.4.cmml">,</mo><mrow id="S3.SS3.p4.14.m5.3.3.2.2" xref="S3.SS3.p4.14.m5.3.3.2.2.cmml"><mi id="S3.SS3.p4.14.m5.3.3.2.2.4" xref="S3.SS3.p4.14.m5.3.3.2.2.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.3.3.2.2.3" xref="S3.SS3.p4.14.m5.3.3.2.2.3.cmml">​</mo><mi id="S3.SS3.p4.14.m5.3.3.2.2.5" xref="S3.SS3.p4.14.m5.3.3.2.2.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.3.3.2.2.3a" xref="S3.SS3.p4.14.m5.3.3.2.2.3.cmml">​</mo><mi id="S3.SS3.p4.14.m5.3.3.2.2.6" xref="S3.SS3.p4.14.m5.3.3.2.2.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.3.3.2.2.3b" xref="S3.SS3.p4.14.m5.3.3.2.2.3.cmml">​</mo><mrow id="S3.SS3.p4.14.m5.3.3.2.2.2.2" xref="S3.SS3.p4.14.m5.3.3.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.14.m5.3.3.2.2.2.2.3" xref="S3.SS3.p4.14.m5.3.3.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.cmml"><mi id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.2" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.2.cmml">p</mi><mi id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.3" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p4.14.m5.3.3.2.2.2.2.4" xref="S3.SS3.p4.14.m5.3.3.2.2.2.3.cmml">,</mo><msub id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.cmml"><mi id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.2" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.2.cmml">B</mi><mi id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.3" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS3.p4.14.m5.3.3.2.2.2.2.5" xref="S3.SS3.p4.14.m5.3.3.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p4.14.m5.4.4.3.7" xref="S3.SS3.p4.14.m5.4.4.4.cmml">,</mo><mrow id="S3.SS3.p4.14.m5.4.4.3.3" xref="S3.SS3.p4.14.m5.4.4.3.3.cmml"><mi id="S3.SS3.p4.14.m5.4.4.3.3.4" xref="S3.SS3.p4.14.m5.4.4.3.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.4.4.3.3.3" xref="S3.SS3.p4.14.m5.4.4.3.3.3.cmml">​</mo><mi id="S3.SS3.p4.14.m5.4.4.3.3.5" xref="S3.SS3.p4.14.m5.4.4.3.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.4.4.3.3.3a" xref="S3.SS3.p4.14.m5.4.4.3.3.3.cmml">​</mo><mi id="S3.SS3.p4.14.m5.4.4.3.3.6" xref="S3.SS3.p4.14.m5.4.4.3.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.4.4.3.3.3b" xref="S3.SS3.p4.14.m5.4.4.3.3.3.cmml">​</mo><mrow id="S3.SS3.p4.14.m5.4.4.3.3.2.2" xref="S3.SS3.p4.14.m5.4.4.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS3.p4.14.m5.4.4.3.3.2.2.3" xref="S3.SS3.p4.14.m5.4.4.3.3.2.3.cmml">(</mo><msub id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.cmml"><mi id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.2" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.2.cmml">p</mi><mi id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.3" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p4.14.m5.4.4.3.3.2.2.4" xref="S3.SS3.p4.14.m5.4.4.3.3.2.3.cmml">,</mo><mrow id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.cmml"><mi id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.2" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.1" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.1.cmml">​</mo><mi id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.3" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.3.cmml">G</mi></mrow><mo stretchy="false" id="S3.SS3.p4.14.m5.4.4.3.3.2.2.5" xref="S3.SS3.p4.14.m5.4.4.3.3.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p4.14.m5.4.4.3.8" xref="S3.SS3.p4.14.m5.4.4.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.14.m5.4b"><list id="S3.SS3.p4.14.m5.4.4.4.cmml" xref="S3.SS3.p4.14.m5.4.4.3"><apply id="S3.SS3.p4.14.m5.2.2.1.1.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1"><times id="S3.SS3.p4.14.m5.2.2.1.1.3.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.3"></times><ci id="S3.SS3.p4.14.m5.2.2.1.1.4.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.4">𝑐</ci><ci id="S3.SS3.p4.14.m5.2.2.1.1.5.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.5">𝑜</ci><ci id="S3.SS3.p4.14.m5.2.2.1.1.6.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.6">𝑠</ci><interval closure="open" id="S3.SS3.p4.14.m5.2.2.1.1.2.3.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2"><apply id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.2">𝑝</ci><ci id="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.1.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.2.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.2">𝐵</ci><cn type="integer" id="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.3.cmml" xref="S3.SS3.p4.14.m5.2.2.1.1.2.2.2.3">1</cn></apply></interval></apply><ci id="S3.SS3.p4.14.m5.1.1.cmml" xref="S3.SS3.p4.14.m5.1.1">…</ci><apply id="S3.SS3.p4.14.m5.3.3.2.2.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2"><times id="S3.SS3.p4.14.m5.3.3.2.2.3.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.3"></times><ci id="S3.SS3.p4.14.m5.3.3.2.2.4.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.4">𝑐</ci><ci id="S3.SS3.p4.14.m5.3.3.2.2.5.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.5">𝑜</ci><ci id="S3.SS3.p4.14.m5.3.3.2.2.6.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.6">𝑠</ci><interval closure="open" id="S3.SS3.p4.14.m5.3.3.2.2.2.3.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2"><apply id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.1.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.2.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.2">𝑝</ci><ci id="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.3.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.1.1.1.3">𝑖</ci></apply><apply id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.1.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.2.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.2">𝐵</ci><ci id="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.3.cmml" xref="S3.SS3.p4.14.m5.3.3.2.2.2.2.2.3">𝑛</ci></apply></interval></apply><apply id="S3.SS3.p4.14.m5.4.4.3.3.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3"><times id="S3.SS3.p4.14.m5.4.4.3.3.3.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.3"></times><ci id="S3.SS3.p4.14.m5.4.4.3.3.4.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.4">𝑐</ci><ci id="S3.SS3.p4.14.m5.4.4.3.3.5.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.5">𝑜</ci><ci id="S3.SS3.p4.14.m5.4.4.3.3.6.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.6">𝑠</ci><interval closure="open" id="S3.SS3.p4.14.m5.4.4.3.3.2.3.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2"><apply id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.1.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1">subscript</csymbol><ci id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.2.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.2">𝑝</ci><ci id="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.3.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.1.1.1.3">𝑖</ci></apply><apply id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2"><times id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.1.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.1"></times><ci id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.2.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.2">𝐵</ci><ci id="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.3.cmml" xref="S3.SS3.p4.14.m5.4.4.3.3.2.2.2.3">𝐺</ci></apply></interval></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.14.m5.4c">[cos(p_{i},B_{1}),\dots,cos(p_{i},B_{n}),cos(p_{i},BG)]</annotation></semantics></math> in which <math id="S3.SS3.p4.15.m6.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p4.15.m6.1a"><mi id="S3.SS3.p4.15.m6.1.1" xref="S3.SS3.p4.15.m6.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.15.m6.1b"><ci id="S3.SS3.p4.15.m6.1.1.cmml" xref="S3.SS3.p4.15.m6.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.15.m6.1c">n</annotation></semantics></math> is number of base categories, <math id="S3.SS3.p4.16.m7.1" class="ltx_Math" alttext="cos" display="inline"><semantics id="S3.SS3.p4.16.m7.1a"><mrow id="S3.SS3.p4.16.m7.1.1" xref="S3.SS3.p4.16.m7.1.1.cmml"><mi id="S3.SS3.p4.16.m7.1.1.2" xref="S3.SS3.p4.16.m7.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.16.m7.1.1.1" xref="S3.SS3.p4.16.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.16.m7.1.1.3" xref="S3.SS3.p4.16.m7.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.16.m7.1.1.1a" xref="S3.SS3.p4.16.m7.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.16.m7.1.1.4" xref="S3.SS3.p4.16.m7.1.1.4.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.16.m7.1b"><apply id="S3.SS3.p4.16.m7.1.1.cmml" xref="S3.SS3.p4.16.m7.1.1"><times id="S3.SS3.p4.16.m7.1.1.1.cmml" xref="S3.SS3.p4.16.m7.1.1.1"></times><ci id="S3.SS3.p4.16.m7.1.1.2.cmml" xref="S3.SS3.p4.16.m7.1.1.2">𝑐</ci><ci id="S3.SS3.p4.16.m7.1.1.3.cmml" xref="S3.SS3.p4.16.m7.1.1.3">𝑜</ci><ci id="S3.SS3.p4.16.m7.1.1.4.cmml" xref="S3.SS3.p4.16.m7.1.1.4">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.16.m7.1c">cos</annotation></semantics></math> is the cosine similarity score, and <math id="S3.SS3.p4.17.m8.1" class="ltx_Math" alttext="BG" display="inline"><semantics id="S3.SS3.p4.17.m8.1a"><mrow id="S3.SS3.p4.17.m8.1.1" xref="S3.SS3.p4.17.m8.1.1.cmml"><mi id="S3.SS3.p4.17.m8.1.1.2" xref="S3.SS3.p4.17.m8.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p4.17.m8.1.1.1" xref="S3.SS3.p4.17.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p4.17.m8.1.1.3" xref="S3.SS3.p4.17.m8.1.1.3.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.17.m8.1b"><apply id="S3.SS3.p4.17.m8.1.1.cmml" xref="S3.SS3.p4.17.m8.1.1"><times id="S3.SS3.p4.17.m8.1.1.1.cmml" xref="S3.SS3.p4.17.m8.1.1.1"></times><ci id="S3.SS3.p4.17.m8.1.1.2.cmml" xref="S3.SS3.p4.17.m8.1.1.2">𝐵</ci><ci id="S3.SS3.p4.17.m8.1.1.3.cmml" xref="S3.SS3.p4.17.m8.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.17.m8.1c">BG</annotation></semantics></math> is a learnable vector for background.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.5" class="ltx_p">At inference time, we also need to detect the novel categories.
We generate the text embedding for both the base <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="B_{i}" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><msub id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mi id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">B</mi><mi id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">𝐵</ci><ci id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">B_{i}</annotation></semantics></math> and the novel <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="N_{i}" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><msub id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml"><mi id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">N</mi><mi id="S3.SS3.p5.2.m2.1.1.3" xref="S3.SS3.p5.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2">𝑁</ci><ci id="S3.SS3.p5.2.m2.1.1.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">N_{i}</annotation></semantics></math>.
The vector <math id="S3.SS3.p5.3.m3.1" class="ltx_Math" alttext="\boldsymbol{cos_{i}}" display="inline"><semantics id="S3.SS3.p5.3.m3.1a"><mrow id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml"><mi id="S3.SS3.p5.3.m3.1.1.2" xref="S3.SS3.p5.3.m3.1.1.2.cmml">𝒄</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.3.m3.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p5.3.m3.1.1.3" xref="S3.SS3.p5.3.m3.1.1.3.cmml">𝒐</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p5.3.m3.1.1.1a" xref="S3.SS3.p5.3.m3.1.1.1.cmml">​</mo><msub id="S3.SS3.p5.3.m3.1.1.4" xref="S3.SS3.p5.3.m3.1.1.4.cmml"><mi id="S3.SS3.p5.3.m3.1.1.4.2" xref="S3.SS3.p5.3.m3.1.1.4.2.cmml">𝒔</mi><mi id="S3.SS3.p5.3.m3.1.1.4.3" xref="S3.SS3.p5.3.m3.1.1.4.3.cmml">𝒊</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><apply id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1"><times id="S3.SS3.p5.3.m3.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1"></times><ci id="S3.SS3.p5.3.m3.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1.2">𝒄</ci><ci id="S3.SS3.p5.3.m3.1.1.3.cmml" xref="S3.SS3.p5.3.m3.1.1.3">𝒐</ci><apply id="S3.SS3.p5.3.m3.1.1.4.cmml" xref="S3.SS3.p5.3.m3.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p5.3.m3.1.1.4.1.cmml" xref="S3.SS3.p5.3.m3.1.1.4">subscript</csymbol><ci id="S3.SS3.p5.3.m3.1.1.4.2.cmml" xref="S3.SS3.p5.3.m3.1.1.4.2">𝒔</ci><ci id="S3.SS3.p5.3.m3.1.1.4.3.cmml" xref="S3.SS3.p5.3.m3.1.1.4.3">𝒊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">\boldsymbol{cos_{i}}</annotation></semantics></math> become <math id="S3.SS3.p5.4.m4.2" class="ltx_math_unparsed" alttext="[cos(p_{i},B_{1}),\dots,cos(p_{i},B_{n}),cos(p_{i},N_{1}),\dots,cos(p_{i},N_{k})," display="inline"><semantics id="S3.SS3.p5.4.m4.2a"><mrow id="S3.SS3.p5.4.m4.2b"><mo stretchy="false" id="S3.SS3.p5.4.m4.2.3">[</mo><mi id="S3.SS3.p5.4.m4.2.4">c</mi><mi id="S3.SS3.p5.4.m4.2.5">o</mi><mi id="S3.SS3.p5.4.m4.2.6">s</mi><mrow id="S3.SS3.p5.4.m4.2.7"><mo stretchy="false" id="S3.SS3.p5.4.m4.2.7.1">(</mo><msub id="S3.SS3.p5.4.m4.2.7.2"><mi id="S3.SS3.p5.4.m4.2.7.2.2">p</mi><mi id="S3.SS3.p5.4.m4.2.7.2.3">i</mi></msub><mo id="S3.SS3.p5.4.m4.2.7.3">,</mo><msub id="S3.SS3.p5.4.m4.2.7.4"><mi id="S3.SS3.p5.4.m4.2.7.4.2">B</mi><mn id="S3.SS3.p5.4.m4.2.7.4.3">1</mn></msub><mo stretchy="false" id="S3.SS3.p5.4.m4.2.7.5">)</mo></mrow><mo id="S3.SS3.p5.4.m4.2.8">,</mo><mi mathvariant="normal" id="S3.SS3.p5.4.m4.1.1">…</mi><mo id="S3.SS3.p5.4.m4.2.9">,</mo><mi id="S3.SS3.p5.4.m4.2.10">c</mi><mi id="S3.SS3.p5.4.m4.2.11">o</mi><mi id="S3.SS3.p5.4.m4.2.12">s</mi><mrow id="S3.SS3.p5.4.m4.2.13"><mo stretchy="false" id="S3.SS3.p5.4.m4.2.13.1">(</mo><msub id="S3.SS3.p5.4.m4.2.13.2"><mi id="S3.SS3.p5.4.m4.2.13.2.2">p</mi><mi id="S3.SS3.p5.4.m4.2.13.2.3">i</mi></msub><mo id="S3.SS3.p5.4.m4.2.13.3">,</mo><msub id="S3.SS3.p5.4.m4.2.13.4"><mi id="S3.SS3.p5.4.m4.2.13.4.2">B</mi><mi id="S3.SS3.p5.4.m4.2.13.4.3">n</mi></msub><mo stretchy="false" id="S3.SS3.p5.4.m4.2.13.5">)</mo></mrow><mo id="S3.SS3.p5.4.m4.2.14">,</mo><mi id="S3.SS3.p5.4.m4.2.15">c</mi><mi id="S3.SS3.p5.4.m4.2.16">o</mi><mi id="S3.SS3.p5.4.m4.2.17">s</mi><mrow id="S3.SS3.p5.4.m4.2.18"><mo stretchy="false" id="S3.SS3.p5.4.m4.2.18.1">(</mo><msub id="S3.SS3.p5.4.m4.2.18.2"><mi id="S3.SS3.p5.4.m4.2.18.2.2">p</mi><mi id="S3.SS3.p5.4.m4.2.18.2.3">i</mi></msub><mo id="S3.SS3.p5.4.m4.2.18.3">,</mo><msub id="S3.SS3.p5.4.m4.2.18.4"><mi id="S3.SS3.p5.4.m4.2.18.4.2">N</mi><mn id="S3.SS3.p5.4.m4.2.18.4.3">1</mn></msub><mo stretchy="false" id="S3.SS3.p5.4.m4.2.18.5">)</mo></mrow><mo id="S3.SS3.p5.4.m4.2.19">,</mo><mi mathvariant="normal" id="S3.SS3.p5.4.m4.2.2">…</mi><mo id="S3.SS3.p5.4.m4.2.20">,</mo><mi id="S3.SS3.p5.4.m4.2.21">c</mi><mi id="S3.SS3.p5.4.m4.2.22">o</mi><mi id="S3.SS3.p5.4.m4.2.23">s</mi><mrow id="S3.SS3.p5.4.m4.2.24"><mo stretchy="false" id="S3.SS3.p5.4.m4.2.24.1">(</mo><msub id="S3.SS3.p5.4.m4.2.24.2"><mi id="S3.SS3.p5.4.m4.2.24.2.2">p</mi><mi id="S3.SS3.p5.4.m4.2.24.2.3">i</mi></msub><mo id="S3.SS3.p5.4.m4.2.24.3">,</mo><msub id="S3.SS3.p5.4.m4.2.24.4"><mi id="S3.SS3.p5.4.m4.2.24.4.2">N</mi><mi id="S3.SS3.p5.4.m4.2.24.4.3">k</mi></msub><mo stretchy="false" id="S3.SS3.p5.4.m4.2.24.5">)</mo></mrow><mo id="S3.SS3.p5.4.m4.2.25">,</mo></mrow><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m4.2c">[cos(p_{i},B_{1}),\dots,cos(p_{i},B_{n}),cos(p_{i},N_{1}),\dots,cos(p_{i},N_{k}),</annotation></semantics></math> <math id="S3.SS3.p5.5.m5.1" class="ltx_math_unparsed" alttext="cos(p_{i},BG)]" display="inline"><semantics id="S3.SS3.p5.5.m5.1a"><mrow id="S3.SS3.p5.5.m5.1b"><mi id="S3.SS3.p5.5.m5.1.1">c</mi><mi id="S3.SS3.p5.5.m5.1.2">o</mi><mi id="S3.SS3.p5.5.m5.1.3">s</mi><mrow id="S3.SS3.p5.5.m5.1.4"><mo stretchy="false" id="S3.SS3.p5.5.m5.1.4.1">(</mo><msub id="S3.SS3.p5.5.m5.1.4.2"><mi id="S3.SS3.p5.5.m5.1.4.2.2">p</mi><mi id="S3.SS3.p5.5.m5.1.4.2.3">i</mi></msub><mo id="S3.SS3.p5.5.m5.1.4.3">,</mo><mi id="S3.SS3.p5.5.m5.1.4.4">B</mi><mi id="S3.SS3.p5.5.m5.1.4.5">G</mi><mo stretchy="false" id="S3.SS3.p5.5.m5.1.4.6">)</mo></mrow><mo stretchy="false" id="S3.SS3.p5.5.m5.1.5">]</mo></mrow><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m5.1c">cos(p_{i},BG)]</annotation></semantics></math> where k is the number of the novel categories.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.8" class="ltx_p"><span id="S3.SS3.p6.8.1" class="ltx_text ltx_font_bold">Semantic-based Regressor.</span>
To improve the performance of the regression module, we add the semantic information of each category into consideration. We concatenate the text embedding with the proposal feature to predict the bbox.
For each foreground proposal <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><msub id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mi id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml">P</mi><mi id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2">𝑃</ci><ci id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">P_{i}</annotation></semantics></math> given by the Region Proposal Network(RPN), we generate its feature for regression <math id="S3.SS3.p6.2.m2.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="S3.SS3.p6.2.m2.1a"><msub id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml"><mi id="S3.SS3.p6.2.m2.1.1.2" xref="S3.SS3.p6.2.m2.1.1.2.cmml">r</mi><mi id="S3.SS3.p6.2.m2.1.1.3" xref="S3.SS3.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><apply id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.2.m2.1.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p6.2.m2.1.1.2.cmml" xref="S3.SS3.p6.2.m2.1.1.2">𝑟</ci><ci id="S3.SS3.p6.2.m2.1.1.3.cmml" xref="S3.SS3.p6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">r_{i}</annotation></semantics></math>. The <math id="S3.SS3.p6.3.m3.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="S3.SS3.p6.3.m3.1a"><msub id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml"><mi id="S3.SS3.p6.3.m3.1.1.2" xref="S3.SS3.p6.3.m3.1.1.2.cmml">r</mi><mi id="S3.SS3.p6.3.m3.1.1.3" xref="S3.SS3.p6.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><apply id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.3.m3.1.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p6.3.m3.1.1.2.cmml" xref="S3.SS3.p6.3.m3.1.1.2">𝑟</ci><ci id="S3.SS3.p6.3.m3.1.1.3.cmml" xref="S3.SS3.p6.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">r_{i}</annotation></semantics></math> can be expressed as <math id="S3.SS3.p6.4.m4.2" class="ltx_Math" alttext="Conv_{r}(Align(Bbone(I),P_{i}))" display="inline"><semantics id="S3.SS3.p6.4.m4.2a"><mrow id="S3.SS3.p6.4.m4.2.2" xref="S3.SS3.p6.4.m4.2.2.cmml"><mi id="S3.SS3.p6.4.m4.2.2.3" xref="S3.SS3.p6.4.m4.2.2.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.2" xref="S3.SS3.p6.4.m4.2.2.2.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.4" xref="S3.SS3.p6.4.m4.2.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.2a" xref="S3.SS3.p6.4.m4.2.2.2.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.5" xref="S3.SS3.p6.4.m4.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.2b" xref="S3.SS3.p6.4.m4.2.2.2.cmml">​</mo><msub id="S3.SS3.p6.4.m4.2.2.6" xref="S3.SS3.p6.4.m4.2.2.6.cmml"><mi id="S3.SS3.p6.4.m4.2.2.6.2" xref="S3.SS3.p6.4.m4.2.2.6.2.cmml">v</mi><mi id="S3.SS3.p6.4.m4.2.2.6.3" xref="S3.SS3.p6.4.m4.2.2.6.3.cmml">r</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.2c" xref="S3.SS3.p6.4.m4.2.2.2.cmml">​</mo><mrow id="S3.SS3.p6.4.m4.2.2.1.1" xref="S3.SS3.p6.4.m4.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p6.4.m4.2.2.1.1.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS3.p6.4.m4.2.2.1.1.1" xref="S3.SS3.p6.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.4" xref="S3.SS3.p6.4.m4.2.2.1.1.1.4.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.3" xref="S3.SS3.p6.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.5" xref="S3.SS3.p6.4.m4.2.2.1.1.1.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.3a" xref="S3.SS3.p6.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.6" xref="S3.SS3.p6.4.m4.2.2.1.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.3b" xref="S3.SS3.p6.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.7" xref="S3.SS3.p6.4.m4.2.2.1.1.1.7.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.3c" xref="S3.SS3.p6.4.m4.2.2.1.1.1.3.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.8" xref="S3.SS3.p6.4.m4.2.2.1.1.1.8.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.3d" xref="S3.SS3.p6.4.m4.2.2.1.1.1.3.cmml">​</mo><mrow id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.3" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.3.cmml">(</mo><mrow id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.3" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1a" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.4" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1b" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.5" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1c" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.6" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1d" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.7.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.7.2.1" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.cmml">(</mo><mi id="S3.SS3.p6.4.m4.1.1" xref="S3.SS3.p6.4.m4.1.1.cmml">I</mi><mo stretchy="false" id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.7.2.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.4" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.3.cmml">,</mo><msub id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.cmml"><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.2" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.2.cmml">P</mi><mi id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.3" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.5" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p6.4.m4.2.2.1.1.3" xref="S3.SS3.p6.4.m4.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.4.m4.2b"><apply id="S3.SS3.p6.4.m4.2.2.cmml" xref="S3.SS3.p6.4.m4.2.2"><times id="S3.SS3.p6.4.m4.2.2.2.cmml" xref="S3.SS3.p6.4.m4.2.2.2"></times><ci id="S3.SS3.p6.4.m4.2.2.3.cmml" xref="S3.SS3.p6.4.m4.2.2.3">𝐶</ci><ci id="S3.SS3.p6.4.m4.2.2.4.cmml" xref="S3.SS3.p6.4.m4.2.2.4">𝑜</ci><ci id="S3.SS3.p6.4.m4.2.2.5.cmml" xref="S3.SS3.p6.4.m4.2.2.5">𝑛</ci><apply id="S3.SS3.p6.4.m4.2.2.6.cmml" xref="S3.SS3.p6.4.m4.2.2.6"><csymbol cd="ambiguous" id="S3.SS3.p6.4.m4.2.2.6.1.cmml" xref="S3.SS3.p6.4.m4.2.2.6">subscript</csymbol><ci id="S3.SS3.p6.4.m4.2.2.6.2.cmml" xref="S3.SS3.p6.4.m4.2.2.6.2">𝑣</ci><ci id="S3.SS3.p6.4.m4.2.2.6.3.cmml" xref="S3.SS3.p6.4.m4.2.2.6.3">𝑟</ci></apply><apply id="S3.SS3.p6.4.m4.2.2.1.1.1.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1"><times id="S3.SS3.p6.4.m4.2.2.1.1.1.3.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.3"></times><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.4.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.4">𝐴</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.5.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.5">𝑙</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.6.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.6">𝑖</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.7.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.7">𝑔</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.8.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.8">𝑛</ci><interval closure="open" id="S3.SS3.p6.4.m4.2.2.1.1.1.2.3.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2"><apply id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1"><times id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.1"></times><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.2">𝐵</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.3">𝑏</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.4.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.4">𝑜</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.5.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.5">𝑛</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.6.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.1.1.1.6">𝑒</ci><ci id="S3.SS3.p6.4.m4.1.1.cmml" xref="S3.SS3.p6.4.m4.1.1">𝐼</ci></apply><apply id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.2">𝑃</ci><ci id="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.3.cmml" xref="S3.SS3.p6.4.m4.2.2.1.1.1.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.4.m4.2c">Conv_{r}(Align(Bbone(I),P_{i}))</annotation></semantics></math>, where <math id="S3.SS3.p6.5.m5.1" class="ltx_Math" alttext="Align" display="inline"><semantics id="S3.SS3.p6.5.m5.1a"><mrow id="S3.SS3.p6.5.m5.1.1" xref="S3.SS3.p6.5.m5.1.1.cmml"><mi id="S3.SS3.p6.5.m5.1.1.2" xref="S3.SS3.p6.5.m5.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.5.m5.1.1.1" xref="S3.SS3.p6.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.5.m5.1.1.3" xref="S3.SS3.p6.5.m5.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.5.m5.1.1.1a" xref="S3.SS3.p6.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.5.m5.1.1.4" xref="S3.SS3.p6.5.m5.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.5.m5.1.1.1b" xref="S3.SS3.p6.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.5.m5.1.1.5" xref="S3.SS3.p6.5.m5.1.1.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.5.m5.1.1.1c" xref="S3.SS3.p6.5.m5.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.5.m5.1.1.6" xref="S3.SS3.p6.5.m5.1.1.6.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.5.m5.1b"><apply id="S3.SS3.p6.5.m5.1.1.cmml" xref="S3.SS3.p6.5.m5.1.1"><times id="S3.SS3.p6.5.m5.1.1.1.cmml" xref="S3.SS3.p6.5.m5.1.1.1"></times><ci id="S3.SS3.p6.5.m5.1.1.2.cmml" xref="S3.SS3.p6.5.m5.1.1.2">𝐴</ci><ci id="S3.SS3.p6.5.m5.1.1.3.cmml" xref="S3.SS3.p6.5.m5.1.1.3">𝑙</ci><ci id="S3.SS3.p6.5.m5.1.1.4.cmml" xref="S3.SS3.p6.5.m5.1.1.4">𝑖</ci><ci id="S3.SS3.p6.5.m5.1.1.5.cmml" xref="S3.SS3.p6.5.m5.1.1.5">𝑔</ci><ci id="S3.SS3.p6.5.m5.1.1.6.cmml" xref="S3.SS3.p6.5.m5.1.1.6">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.5.m5.1c">Align</annotation></semantics></math> and <math id="S3.SS3.p6.6.m6.1" class="ltx_Math" alttext="Bbone" display="inline"><semantics id="S3.SS3.p6.6.m6.1a"><mrow id="S3.SS3.p6.6.m6.1.1" xref="S3.SS3.p6.6.m6.1.1.cmml"><mi id="S3.SS3.p6.6.m6.1.1.2" xref="S3.SS3.p6.6.m6.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.1.1.1" xref="S3.SS3.p6.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.6.m6.1.1.3" xref="S3.SS3.p6.6.m6.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.1.1.1a" xref="S3.SS3.p6.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.6.m6.1.1.4" xref="S3.SS3.p6.6.m6.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.1.1.1b" xref="S3.SS3.p6.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.6.m6.1.1.5" xref="S3.SS3.p6.6.m6.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.6.m6.1.1.1c" xref="S3.SS3.p6.6.m6.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.6.m6.1.1.6" xref="S3.SS3.p6.6.m6.1.1.6.cmml">e</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.6.m6.1b"><apply id="S3.SS3.p6.6.m6.1.1.cmml" xref="S3.SS3.p6.6.m6.1.1"><times id="S3.SS3.p6.6.m6.1.1.1.cmml" xref="S3.SS3.p6.6.m6.1.1.1"></times><ci id="S3.SS3.p6.6.m6.1.1.2.cmml" xref="S3.SS3.p6.6.m6.1.1.2">𝐵</ci><ci id="S3.SS3.p6.6.m6.1.1.3.cmml" xref="S3.SS3.p6.6.m6.1.1.3">𝑏</ci><ci id="S3.SS3.p6.6.m6.1.1.4.cmml" xref="S3.SS3.p6.6.m6.1.1.4">𝑜</ci><ci id="S3.SS3.p6.6.m6.1.1.5.cmml" xref="S3.SS3.p6.6.m6.1.1.5">𝑛</ci><ci id="S3.SS3.p6.6.m6.1.1.6.cmml" xref="S3.SS3.p6.6.m6.1.1.6">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.6.m6.1c">Bbone</annotation></semantics></math> are the same as those in <math id="S3.SS3.p6.7.m7.1" class="ltx_Math" alttext="c^{{}^{\prime}}_{i}" display="inline"><semantics id="S3.SS3.p6.7.m7.1a"><msubsup id="S3.SS3.p6.7.m7.1.1" xref="S3.SS3.p6.7.m7.1.1.cmml"><mi id="S3.SS3.p6.7.m7.1.1.2.2" xref="S3.SS3.p6.7.m7.1.1.2.2.cmml">c</mi><mi id="S3.SS3.p6.7.m7.1.1.3" xref="S3.SS3.p6.7.m7.1.1.3.cmml">i</mi><msup id="S3.SS3.p6.7.m7.1.1.2.3" xref="S3.SS3.p6.7.m7.1.1.2.3.cmml"><mi id="S3.SS3.p6.7.m7.1.1.2.3a" xref="S3.SS3.p6.7.m7.1.1.2.3.cmml"></mi><mo id="S3.SS3.p6.7.m7.1.1.2.3.1" xref="S3.SS3.p6.7.m7.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.7.m7.1b"><apply id="S3.SS3.p6.7.m7.1.1.cmml" xref="S3.SS3.p6.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.7.m7.1.1.1.cmml" xref="S3.SS3.p6.7.m7.1.1">subscript</csymbol><apply id="S3.SS3.p6.7.m7.1.1.2.cmml" xref="S3.SS3.p6.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.7.m7.1.1.2.1.cmml" xref="S3.SS3.p6.7.m7.1.1">superscript</csymbol><ci id="S3.SS3.p6.7.m7.1.1.2.2.cmml" xref="S3.SS3.p6.7.m7.1.1.2.2">𝑐</ci><apply id="S3.SS3.p6.7.m7.1.1.2.3.cmml" xref="S3.SS3.p6.7.m7.1.1.2.3"><ci id="S3.SS3.p6.7.m7.1.1.2.3.1.cmml" xref="S3.SS3.p6.7.m7.1.1.2.3.1">′</ci></apply></apply><ci id="S3.SS3.p6.7.m7.1.1.3.cmml" xref="S3.SS3.p6.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.7.m7.1c">c^{{}^{\prime}}_{i}</annotation></semantics></math> definition, and <math id="S3.SS3.p6.8.m8.1" class="ltx_Math" alttext="Conv_{r}" display="inline"><semantics id="S3.SS3.p6.8.m8.1a"><mrow id="S3.SS3.p6.8.m8.1.1" xref="S3.SS3.p6.8.m8.1.1.cmml"><mi id="S3.SS3.p6.8.m8.1.1.2" xref="S3.SS3.p6.8.m8.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.8.m8.1.1.1" xref="S3.SS3.p6.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.8.m8.1.1.3" xref="S3.SS3.p6.8.m8.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.8.m8.1.1.1a" xref="S3.SS3.p6.8.m8.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.8.m8.1.1.4" xref="S3.SS3.p6.8.m8.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.8.m8.1.1.1b" xref="S3.SS3.p6.8.m8.1.1.1.cmml">​</mo><msub id="S3.SS3.p6.8.m8.1.1.5" xref="S3.SS3.p6.8.m8.1.1.5.cmml"><mi id="S3.SS3.p6.8.m8.1.1.5.2" xref="S3.SS3.p6.8.m8.1.1.5.2.cmml">v</mi><mi id="S3.SS3.p6.8.m8.1.1.5.3" xref="S3.SS3.p6.8.m8.1.1.5.3.cmml">r</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.8.m8.1b"><apply id="S3.SS3.p6.8.m8.1.1.cmml" xref="S3.SS3.p6.8.m8.1.1"><times id="S3.SS3.p6.8.m8.1.1.1.cmml" xref="S3.SS3.p6.8.m8.1.1.1"></times><ci id="S3.SS3.p6.8.m8.1.1.2.cmml" xref="S3.SS3.p6.8.m8.1.1.2">𝐶</ci><ci id="S3.SS3.p6.8.m8.1.1.3.cmml" xref="S3.SS3.p6.8.m8.1.1.3">𝑜</ci><ci id="S3.SS3.p6.8.m8.1.1.4.cmml" xref="S3.SS3.p6.8.m8.1.1.4">𝑛</ci><apply id="S3.SS3.p6.8.m8.1.1.5.cmml" xref="S3.SS3.p6.8.m8.1.1.5"><csymbol cd="ambiguous" id="S3.SS3.p6.8.m8.1.1.5.1.cmml" xref="S3.SS3.p6.8.m8.1.1.5">subscript</csymbol><ci id="S3.SS3.p6.8.m8.1.1.5.2.cmml" xref="S3.SS3.p6.8.m8.1.1.5.2">𝑣</ci><ci id="S3.SS3.p6.8.m8.1.1.5.3.cmml" xref="S3.SS3.p6.8.m8.1.1.5.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.8.m8.1c">Conv_{r}</annotation></semantics></math> means passing the feature after the RoIAlign through the convolution layers and linear layers in the regression branch. The regression loss is defined as:</p>
<table id="S3.E3" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E3X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle L_{reg}=\frac{1}{K}\sum_{i=1}^{K}L_{1}(Linear(Cat(r_{i},B_{y_{i}})),a_{i})" display="inline"><semantics id="S3.E3X.2.1.1.m1.2a"><mrow id="S3.E3X.2.1.1.m1.2.2" xref="S3.E3X.2.1.1.m1.2.2.cmml"><msub id="S3.E3X.2.1.1.m1.2.2.4" xref="S3.E3X.2.1.1.m1.2.2.4.cmml"><mi id="S3.E3X.2.1.1.m1.2.2.4.2" xref="S3.E3X.2.1.1.m1.2.2.4.2.cmml">L</mi><mrow id="S3.E3X.2.1.1.m1.2.2.4.3" xref="S3.E3X.2.1.1.m1.2.2.4.3.cmml"><mi id="S3.E3X.2.1.1.m1.2.2.4.3.2" xref="S3.E3X.2.1.1.m1.2.2.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.2.2.4.3.1" xref="S3.E3X.2.1.1.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.2.2.4.3.3" xref="S3.E3X.2.1.1.m1.2.2.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.2.2.4.3.1a" xref="S3.E3X.2.1.1.m1.2.2.4.3.1.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.2.2.4.3.4" xref="S3.E3X.2.1.1.m1.2.2.4.3.4.cmml">g</mi></mrow></msub><mo id="S3.E3X.2.1.1.m1.2.2.3" xref="S3.E3X.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E3X.2.1.1.m1.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E3X.2.1.1.m1.2.2.2.4" xref="S3.E3X.2.1.1.m1.2.2.2.4.cmml"><mfrac id="S3.E3X.2.1.1.m1.2.2.2.4a" xref="S3.E3X.2.1.1.m1.2.2.2.4.cmml"><mn id="S3.E3X.2.1.1.m1.2.2.2.4.2" xref="S3.E3X.2.1.1.m1.2.2.2.4.2.cmml">1</mn><mi id="S3.E3X.2.1.1.m1.2.2.2.4.3" xref="S3.E3X.2.1.1.m1.2.2.2.4.3.cmml">K</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.2.2.2.3" xref="S3.E3X.2.1.1.m1.2.2.2.3.cmml">​</mo><mrow id="S3.E3X.2.1.1.m1.2.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E3X.2.1.1.m1.2.2.2.2.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.cmml"><munderover id="S3.E3X.2.1.1.m1.2.2.2.2.3a" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.cmml"><mi id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.1" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E3X.2.1.1.m1.2.2.2.2.3.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.3.cmml">K</mi></munderover></mstyle><mrow id="S3.E3X.2.1.1.m1.2.2.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.cmml"><msub id="S3.E3X.2.1.1.m1.2.2.2.2.2.4" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4.cmml"><mi id="S3.E3X.2.1.1.m1.2.2.2.2.2.4.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4.2.cmml">L</mi><mn id="S3.E3X.2.1.1.m1.2.2.2.2.2.4.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.2.2.2.2.2.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.3.cmml">​</mo><mrow id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.3.cmml">(</mo><mrow id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.4" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2a" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.5" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2b" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.6" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2c" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.7" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2d" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.8" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.8.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2e" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3a" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">​</mo><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.6" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3b" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">​</mo><mrow id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">r</mi><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.4" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">B</mi><msub id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.2" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml">y</mi><mi id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml">i</mi></msub></msub><mo stretchy="false" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.5" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.4" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.2" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.2.cmml">a</mi><mi id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.3" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.5" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3X.2.1.1.m1.2b"><apply id="S3.E3X.2.1.1.m1.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2"><eq id="S3.E3X.2.1.1.m1.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.3"></eq><apply id="S3.E3X.2.1.1.m1.2.2.4.cmml" xref="S3.E3X.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.2.2.4.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.4">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.2.2.4.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.4.2">𝐿</ci><apply id="S3.E3X.2.1.1.m1.2.2.4.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.4.3"><times id="S3.E3X.2.1.1.m1.2.2.4.3.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.4.3.1"></times><ci id="S3.E3X.2.1.1.m1.2.2.4.3.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.4.3.2">𝑟</ci><ci id="S3.E3X.2.1.1.m1.2.2.4.3.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.4.3.3">𝑒</ci><ci id="S3.E3X.2.1.1.m1.2.2.4.3.4.cmml" xref="S3.E3X.2.1.1.m1.2.2.4.3.4">𝑔</ci></apply></apply><apply id="S3.E3X.2.1.1.m1.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2"><times id="S3.E3X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.3"></times><apply id="S3.E3X.2.1.1.m1.2.2.2.4.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.4"><divide id="S3.E3X.2.1.1.m1.2.2.2.4.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.4"></divide><cn type="integer" id="S3.E3X.2.1.1.m1.2.2.2.4.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.4.2">1</cn><ci id="S3.E3X.2.1.1.m1.2.2.2.4.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.4.3">𝐾</ci></apply><apply id="S3.E3X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2"><apply id="S3.E3X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.2.2.2.2.3.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3">superscript</csymbol><apply id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3">subscript</csymbol><sum id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.2"></sum><apply id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3"><eq id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.1"></eq><ci id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.2">𝑖</ci><cn type="integer" id="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E3X.2.1.1.m1.2.2.2.2.3.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.3.3">𝐾</ci></apply><apply id="S3.E3X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2"><times id="S3.E3X.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.3"></times><apply id="S3.E3X.2.1.1.m1.2.2.2.2.2.4.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.2.2.2.2.2.4.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.2.2.2.2.2.4.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4.2">𝐿</ci><cn type="integer" id="S3.E3X.2.1.1.m1.2.2.2.2.2.4.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.4.3">1</cn></apply><interval closure="open" id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2"><apply id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1"><times id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.3">𝐿</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.4">𝑖</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.5">𝑛</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.6">𝑒</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.7.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.7">𝑎</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.8.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.8">𝑟</ci><apply id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3"></times><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.4">𝐶</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.5">𝑎</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.6">𝑡</ci><interval closure="open" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2"><apply id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑟</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.2">𝐵</ci><apply id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.2">𝑦</ci><ci id="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.2.3.3">𝑖</ci></apply></apply></interval></apply></apply><apply id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.2">𝑎</ci><ci id="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E3X.2.1.1.m1.2.2.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3X.2.1.1.m1.2c">\displaystyle L_{reg}=\frac{1}{K}\sum_{i=1}^{K}L_{1}(Linear(Cat(r_{i},B_{y_{i}})),a_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(3)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.p6.21" class="ltx_p">where <math id="S3.SS3.p6.9.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p6.9.m1.1a"><mi id="S3.SS3.p6.9.m1.1.1" xref="S3.SS3.p6.9.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.9.m1.1b"><ci id="S3.SS3.p6.9.m1.1.1.cmml" xref="S3.SS3.p6.9.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.9.m1.1c">K</annotation></semantics></math> is the total number of the foreground proposals, <math id="S3.SS3.p6.10.m2.1" class="ltx_Math" alttext="Linear" display="inline"><semantics id="S3.SS3.p6.10.m2.1a"><mrow id="S3.SS3.p6.10.m2.1.1" xref="S3.SS3.p6.10.m2.1.1.cmml"><mi id="S3.SS3.p6.10.m2.1.1.2" xref="S3.SS3.p6.10.m2.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.10.m2.1.1.1" xref="S3.SS3.p6.10.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.10.m2.1.1.3" xref="S3.SS3.p6.10.m2.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.10.m2.1.1.1a" xref="S3.SS3.p6.10.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.10.m2.1.1.4" xref="S3.SS3.p6.10.m2.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.10.m2.1.1.1b" xref="S3.SS3.p6.10.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.10.m2.1.1.5" xref="S3.SS3.p6.10.m2.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.10.m2.1.1.1c" xref="S3.SS3.p6.10.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.10.m2.1.1.6" xref="S3.SS3.p6.10.m2.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.10.m2.1.1.1d" xref="S3.SS3.p6.10.m2.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.10.m2.1.1.7" xref="S3.SS3.p6.10.m2.1.1.7.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.10.m2.1b"><apply id="S3.SS3.p6.10.m2.1.1.cmml" xref="S3.SS3.p6.10.m2.1.1"><times id="S3.SS3.p6.10.m2.1.1.1.cmml" xref="S3.SS3.p6.10.m2.1.1.1"></times><ci id="S3.SS3.p6.10.m2.1.1.2.cmml" xref="S3.SS3.p6.10.m2.1.1.2">𝐿</ci><ci id="S3.SS3.p6.10.m2.1.1.3.cmml" xref="S3.SS3.p6.10.m2.1.1.3">𝑖</ci><ci id="S3.SS3.p6.10.m2.1.1.4.cmml" xref="S3.SS3.p6.10.m2.1.1.4">𝑛</ci><ci id="S3.SS3.p6.10.m2.1.1.5.cmml" xref="S3.SS3.p6.10.m2.1.1.5">𝑒</ci><ci id="S3.SS3.p6.10.m2.1.1.6.cmml" xref="S3.SS3.p6.10.m2.1.1.6">𝑎</ci><ci id="S3.SS3.p6.10.m2.1.1.7.cmml" xref="S3.SS3.p6.10.m2.1.1.7">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.10.m2.1c">Linear</annotation></semantics></math> is the linear layer for bbox prediction, <math id="S3.SS3.p6.11.m3.1" class="ltx_Math" alttext="Cat" display="inline"><semantics id="S3.SS3.p6.11.m3.1a"><mrow id="S3.SS3.p6.11.m3.1.1" xref="S3.SS3.p6.11.m3.1.1.cmml"><mi id="S3.SS3.p6.11.m3.1.1.2" xref="S3.SS3.p6.11.m3.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.11.m3.1.1.1" xref="S3.SS3.p6.11.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.11.m3.1.1.3" xref="S3.SS3.p6.11.m3.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.11.m3.1.1.1a" xref="S3.SS3.p6.11.m3.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.11.m3.1.1.4" xref="S3.SS3.p6.11.m3.1.1.4.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.11.m3.1b"><apply id="S3.SS3.p6.11.m3.1.1.cmml" xref="S3.SS3.p6.11.m3.1.1"><times id="S3.SS3.p6.11.m3.1.1.1.cmml" xref="S3.SS3.p6.11.m3.1.1.1"></times><ci id="S3.SS3.p6.11.m3.1.1.2.cmml" xref="S3.SS3.p6.11.m3.1.1.2">𝐶</ci><ci id="S3.SS3.p6.11.m3.1.1.3.cmml" xref="S3.SS3.p6.11.m3.1.1.3">𝑎</ci><ci id="S3.SS3.p6.11.m3.1.1.4.cmml" xref="S3.SS3.p6.11.m3.1.1.4">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.11.m3.1c">Cat</annotation></semantics></math> mean concatenation, <math id="S3.SS3.p6.12.m4.1" class="ltx_Math" alttext="B_{y_{i}}" display="inline"><semantics id="S3.SS3.p6.12.m4.1a"><msub id="S3.SS3.p6.12.m4.1.1" xref="S3.SS3.p6.12.m4.1.1.cmml"><mi id="S3.SS3.p6.12.m4.1.1.2" xref="S3.SS3.p6.12.m4.1.1.2.cmml">B</mi><msub id="S3.SS3.p6.12.m4.1.1.3" xref="S3.SS3.p6.12.m4.1.1.3.cmml"><mi id="S3.SS3.p6.12.m4.1.1.3.2" xref="S3.SS3.p6.12.m4.1.1.3.2.cmml">y</mi><mi id="S3.SS3.p6.12.m4.1.1.3.3" xref="S3.SS3.p6.12.m4.1.1.3.3.cmml">i</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.12.m4.1b"><apply id="S3.SS3.p6.12.m4.1.1.cmml" xref="S3.SS3.p6.12.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.12.m4.1.1.1.cmml" xref="S3.SS3.p6.12.m4.1.1">subscript</csymbol><ci id="S3.SS3.p6.12.m4.1.1.2.cmml" xref="S3.SS3.p6.12.m4.1.1.2">𝐵</ci><apply id="S3.SS3.p6.12.m4.1.1.3.cmml" xref="S3.SS3.p6.12.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p6.12.m4.1.1.3.1.cmml" xref="S3.SS3.p6.12.m4.1.1.3">subscript</csymbol><ci id="S3.SS3.p6.12.m4.1.1.3.2.cmml" xref="S3.SS3.p6.12.m4.1.1.3.2">𝑦</ci><ci id="S3.SS3.p6.12.m4.1.1.3.3.cmml" xref="S3.SS3.p6.12.m4.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.12.m4.1c">B_{y_{i}}</annotation></semantics></math> means the text embedding of the assigned GT label <math id="S3.SS3.p6.13.m5.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.SS3.p6.13.m5.1a"><msub id="S3.SS3.p6.13.m5.1.1" xref="S3.SS3.p6.13.m5.1.1.cmml"><mi id="S3.SS3.p6.13.m5.1.1.2" xref="S3.SS3.p6.13.m5.1.1.2.cmml">y</mi><mi id="S3.SS3.p6.13.m5.1.1.3" xref="S3.SS3.p6.13.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.13.m5.1b"><apply id="S3.SS3.p6.13.m5.1.1.cmml" xref="S3.SS3.p6.13.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.13.m5.1.1.1.cmml" xref="S3.SS3.p6.13.m5.1.1">subscript</csymbol><ci id="S3.SS3.p6.13.m5.1.1.2.cmml" xref="S3.SS3.p6.13.m5.1.1.2">𝑦</ci><ci id="S3.SS3.p6.13.m5.1.1.3.cmml" xref="S3.SS3.p6.13.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.13.m5.1c">y_{i}</annotation></semantics></math> for the proposal <math id="S3.SS3.p6.14.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS3.p6.14.m6.1a"><mi id="S3.SS3.p6.14.m6.1.1" xref="S3.SS3.p6.14.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.14.m6.1b"><ci id="S3.SS3.p6.14.m6.1.1.cmml" xref="S3.SS3.p6.14.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.14.m6.1c">i</annotation></semantics></math>, and <math id="S3.SS3.p6.15.m7.1" class="ltx_Math" alttext="a_{i}" display="inline"><semantics id="S3.SS3.p6.15.m7.1a"><msub id="S3.SS3.p6.15.m7.1.1" xref="S3.SS3.p6.15.m7.1.1.cmml"><mi id="S3.SS3.p6.15.m7.1.1.2" xref="S3.SS3.p6.15.m7.1.1.2.cmml">a</mi><mi id="S3.SS3.p6.15.m7.1.1.3" xref="S3.SS3.p6.15.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.15.m7.1b"><apply id="S3.SS3.p6.15.m7.1.1.cmml" xref="S3.SS3.p6.15.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.15.m7.1.1.1.cmml" xref="S3.SS3.p6.15.m7.1.1">subscript</csymbol><ci id="S3.SS3.p6.15.m7.1.1.2.cmml" xref="S3.SS3.p6.15.m7.1.1.2">𝑎</ci><ci id="S3.SS3.p6.15.m7.1.1.3.cmml" xref="S3.SS3.p6.15.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.15.m7.1c">a_{i}</annotation></semantics></math> is the GT bbox for the proposal <math id="S3.SS3.p6.16.m8.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.SS3.p6.16.m8.1a"><msub id="S3.SS3.p6.16.m8.1.1" xref="S3.SS3.p6.16.m8.1.1.cmml"><mi id="S3.SS3.p6.16.m8.1.1.2" xref="S3.SS3.p6.16.m8.1.1.2.cmml">P</mi><mi id="S3.SS3.p6.16.m8.1.1.3" xref="S3.SS3.p6.16.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.16.m8.1b"><apply id="S3.SS3.p6.16.m8.1.1.cmml" xref="S3.SS3.p6.16.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.16.m8.1.1.1.cmml" xref="S3.SS3.p6.16.m8.1.1">subscript</csymbol><ci id="S3.SS3.p6.16.m8.1.1.2.cmml" xref="S3.SS3.p6.16.m8.1.1.2">𝑃</ci><ci id="S3.SS3.p6.16.m8.1.1.3.cmml" xref="S3.SS3.p6.16.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.16.m8.1c">P_{i}</annotation></semantics></math>.
At inference time, since we no longer have the GT label. We concatenate the <math id="S3.SS3.p6.17.m9.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="S3.SS3.p6.17.m9.1a"><msub id="S3.SS3.p6.17.m9.1.1" xref="S3.SS3.p6.17.m9.1.1.cmml"><mi id="S3.SS3.p6.17.m9.1.1.2" xref="S3.SS3.p6.17.m9.1.1.2.cmml">r</mi><mi id="S3.SS3.p6.17.m9.1.1.3" xref="S3.SS3.p6.17.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.17.m9.1b"><apply id="S3.SS3.p6.17.m9.1.1.cmml" xref="S3.SS3.p6.17.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.17.m9.1.1.1.cmml" xref="S3.SS3.p6.17.m9.1.1">subscript</csymbol><ci id="S3.SS3.p6.17.m9.1.1.2.cmml" xref="S3.SS3.p6.17.m9.1.1.2">𝑟</ci><ci id="S3.SS3.p6.17.m9.1.1.3.cmml" xref="S3.SS3.p6.17.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.17.m9.1c">r_{i}</annotation></semantics></math> with the text embedding <math id="S3.SS3.p6.18.m10.1" class="ltx_Math" alttext="B_{pred_{i}}" display="inline"><semantics id="S3.SS3.p6.18.m10.1a"><msub id="S3.SS3.p6.18.m10.1.1" xref="S3.SS3.p6.18.m10.1.1.cmml"><mi id="S3.SS3.p6.18.m10.1.1.2" xref="S3.SS3.p6.18.m10.1.1.2.cmml">B</mi><mrow id="S3.SS3.p6.18.m10.1.1.3" xref="S3.SS3.p6.18.m10.1.1.3.cmml"><mi id="S3.SS3.p6.18.m10.1.1.3.2" xref="S3.SS3.p6.18.m10.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.18.m10.1.1.3.1" xref="S3.SS3.p6.18.m10.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p6.18.m10.1.1.3.3" xref="S3.SS3.p6.18.m10.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.18.m10.1.1.3.1a" xref="S3.SS3.p6.18.m10.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p6.18.m10.1.1.3.4" xref="S3.SS3.p6.18.m10.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.18.m10.1.1.3.1b" xref="S3.SS3.p6.18.m10.1.1.3.1.cmml">​</mo><msub id="S3.SS3.p6.18.m10.1.1.3.5" xref="S3.SS3.p6.18.m10.1.1.3.5.cmml"><mi id="S3.SS3.p6.18.m10.1.1.3.5.2" xref="S3.SS3.p6.18.m10.1.1.3.5.2.cmml">d</mi><mi id="S3.SS3.p6.18.m10.1.1.3.5.3" xref="S3.SS3.p6.18.m10.1.1.3.5.3.cmml">i</mi></msub></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.18.m10.1b"><apply id="S3.SS3.p6.18.m10.1.1.cmml" xref="S3.SS3.p6.18.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.18.m10.1.1.1.cmml" xref="S3.SS3.p6.18.m10.1.1">subscript</csymbol><ci id="S3.SS3.p6.18.m10.1.1.2.cmml" xref="S3.SS3.p6.18.m10.1.1.2">𝐵</ci><apply id="S3.SS3.p6.18.m10.1.1.3.cmml" xref="S3.SS3.p6.18.m10.1.1.3"><times id="S3.SS3.p6.18.m10.1.1.3.1.cmml" xref="S3.SS3.p6.18.m10.1.1.3.1"></times><ci id="S3.SS3.p6.18.m10.1.1.3.2.cmml" xref="S3.SS3.p6.18.m10.1.1.3.2">𝑝</ci><ci id="S3.SS3.p6.18.m10.1.1.3.3.cmml" xref="S3.SS3.p6.18.m10.1.1.3.3">𝑟</ci><ci id="S3.SS3.p6.18.m10.1.1.3.4.cmml" xref="S3.SS3.p6.18.m10.1.1.3.4">𝑒</ci><apply id="S3.SS3.p6.18.m10.1.1.3.5.cmml" xref="S3.SS3.p6.18.m10.1.1.3.5"><csymbol cd="ambiguous" id="S3.SS3.p6.18.m10.1.1.3.5.1.cmml" xref="S3.SS3.p6.18.m10.1.1.3.5">subscript</csymbol><ci id="S3.SS3.p6.18.m10.1.1.3.5.2.cmml" xref="S3.SS3.p6.18.m10.1.1.3.5.2">𝑑</ci><ci id="S3.SS3.p6.18.m10.1.1.3.5.3.cmml" xref="S3.SS3.p6.18.m10.1.1.3.5.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.18.m10.1c">B_{pred_{i}}</annotation></semantics></math> or <math id="S3.SS3.p6.19.m11.1" class="ltx_Math" alttext="N_{pred_{i}}" display="inline"><semantics id="S3.SS3.p6.19.m11.1a"><msub id="S3.SS3.p6.19.m11.1.1" xref="S3.SS3.p6.19.m11.1.1.cmml"><mi id="S3.SS3.p6.19.m11.1.1.2" xref="S3.SS3.p6.19.m11.1.1.2.cmml">N</mi><mrow id="S3.SS3.p6.19.m11.1.1.3" xref="S3.SS3.p6.19.m11.1.1.3.cmml"><mi id="S3.SS3.p6.19.m11.1.1.3.2" xref="S3.SS3.p6.19.m11.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.19.m11.1.1.3.1" xref="S3.SS3.p6.19.m11.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p6.19.m11.1.1.3.3" xref="S3.SS3.p6.19.m11.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.19.m11.1.1.3.1a" xref="S3.SS3.p6.19.m11.1.1.3.1.cmml">​</mo><mi id="S3.SS3.p6.19.m11.1.1.3.4" xref="S3.SS3.p6.19.m11.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.19.m11.1.1.3.1b" xref="S3.SS3.p6.19.m11.1.1.3.1.cmml">​</mo><msub id="S3.SS3.p6.19.m11.1.1.3.5" xref="S3.SS3.p6.19.m11.1.1.3.5.cmml"><mi id="S3.SS3.p6.19.m11.1.1.3.5.2" xref="S3.SS3.p6.19.m11.1.1.3.5.2.cmml">d</mi><mi id="S3.SS3.p6.19.m11.1.1.3.5.3" xref="S3.SS3.p6.19.m11.1.1.3.5.3.cmml">i</mi></msub></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.19.m11.1b"><apply id="S3.SS3.p6.19.m11.1.1.cmml" xref="S3.SS3.p6.19.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.19.m11.1.1.1.cmml" xref="S3.SS3.p6.19.m11.1.1">subscript</csymbol><ci id="S3.SS3.p6.19.m11.1.1.2.cmml" xref="S3.SS3.p6.19.m11.1.1.2">𝑁</ci><apply id="S3.SS3.p6.19.m11.1.1.3.cmml" xref="S3.SS3.p6.19.m11.1.1.3"><times id="S3.SS3.p6.19.m11.1.1.3.1.cmml" xref="S3.SS3.p6.19.m11.1.1.3.1"></times><ci id="S3.SS3.p6.19.m11.1.1.3.2.cmml" xref="S3.SS3.p6.19.m11.1.1.3.2">𝑝</ci><ci id="S3.SS3.p6.19.m11.1.1.3.3.cmml" xref="S3.SS3.p6.19.m11.1.1.3.3">𝑟</ci><ci id="S3.SS3.p6.19.m11.1.1.3.4.cmml" xref="S3.SS3.p6.19.m11.1.1.3.4">𝑒</ci><apply id="S3.SS3.p6.19.m11.1.1.3.5.cmml" xref="S3.SS3.p6.19.m11.1.1.3.5"><csymbol cd="ambiguous" id="S3.SS3.p6.19.m11.1.1.3.5.1.cmml" xref="S3.SS3.p6.19.m11.1.1.3.5">subscript</csymbol><ci id="S3.SS3.p6.19.m11.1.1.3.5.2.cmml" xref="S3.SS3.p6.19.m11.1.1.3.5.2">𝑑</ci><ci id="S3.SS3.p6.19.m11.1.1.3.5.3.cmml" xref="S3.SS3.p6.19.m11.1.1.3.5.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.19.m11.1c">N_{pred_{i}}</annotation></semantics></math> of the predicted category of the proposal <math id="S3.SS3.p6.20.m12.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S3.SS3.p6.20.m12.1a"><msub id="S3.SS3.p6.20.m12.1.1" xref="S3.SS3.p6.20.m12.1.1.cmml"><mi id="S3.SS3.p6.20.m12.1.1.2" xref="S3.SS3.p6.20.m12.1.1.2.cmml">P</mi><mi id="S3.SS3.p6.20.m12.1.1.3" xref="S3.SS3.p6.20.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.20.m12.1b"><apply id="S3.SS3.p6.20.m12.1.1.cmml" xref="S3.SS3.p6.20.m12.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.20.m12.1.1.1.cmml" xref="S3.SS3.p6.20.m12.1.1">subscript</csymbol><ci id="S3.SS3.p6.20.m12.1.1.2.cmml" xref="S3.SS3.p6.20.m12.1.1.2">𝑃</ci><ci id="S3.SS3.p6.20.m12.1.1.3.cmml" xref="S3.SS3.p6.20.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.20.m12.1c">P_{i}</annotation></semantics></math>, where <math id="S3.SS3.p6.21.m13.2" class="ltx_Math" alttext="pred_{i}=\arg\max(\boldsymbol{cos_{i}})" display="inline"><semantics id="S3.SS3.p6.21.m13.2a"><mrow id="S3.SS3.p6.21.m13.2.2" xref="S3.SS3.p6.21.m13.2.2.cmml"><mrow id="S3.SS3.p6.21.m13.2.2.3" xref="S3.SS3.p6.21.m13.2.2.3.cmml"><mi id="S3.SS3.p6.21.m13.2.2.3.2" xref="S3.SS3.p6.21.m13.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.21.m13.2.2.3.1" xref="S3.SS3.p6.21.m13.2.2.3.1.cmml">​</mo><mi id="S3.SS3.p6.21.m13.2.2.3.3" xref="S3.SS3.p6.21.m13.2.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.21.m13.2.2.3.1a" xref="S3.SS3.p6.21.m13.2.2.3.1.cmml">​</mo><mi id="S3.SS3.p6.21.m13.2.2.3.4" xref="S3.SS3.p6.21.m13.2.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.21.m13.2.2.3.1b" xref="S3.SS3.p6.21.m13.2.2.3.1.cmml">​</mo><msub id="S3.SS3.p6.21.m13.2.2.3.5" xref="S3.SS3.p6.21.m13.2.2.3.5.cmml"><mi id="S3.SS3.p6.21.m13.2.2.3.5.2" xref="S3.SS3.p6.21.m13.2.2.3.5.2.cmml">d</mi><mi id="S3.SS3.p6.21.m13.2.2.3.5.3" xref="S3.SS3.p6.21.m13.2.2.3.5.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p6.21.m13.2.2.2" xref="S3.SS3.p6.21.m13.2.2.2.cmml">=</mo><mrow id="S3.SS3.p6.21.m13.2.2.1" xref="S3.SS3.p6.21.m13.2.2.1.cmml"><mi id="S3.SS3.p6.21.m13.2.2.1.2" xref="S3.SS3.p6.21.m13.2.2.1.2.cmml">arg</mi><mo lspace="0.167em" id="S3.SS3.p6.21.m13.2.2.1a" xref="S3.SS3.p6.21.m13.2.2.1.cmml">⁡</mo><mrow id="S3.SS3.p6.21.m13.2.2.1.1.1" xref="S3.SS3.p6.21.m13.2.2.1.1.2.cmml"><mi id="S3.SS3.p6.21.m13.1.1" xref="S3.SS3.p6.21.m13.1.1.cmml">max</mi><mo id="S3.SS3.p6.21.m13.2.2.1.1.1a" xref="S3.SS3.p6.21.m13.2.2.1.1.2.cmml">⁡</mo><mrow id="S3.SS3.p6.21.m13.2.2.1.1.1.1" xref="S3.SS3.p6.21.m13.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p6.21.m13.2.2.1.1.1.1.2" xref="S3.SS3.p6.21.m13.2.2.1.1.2.cmml">(</mo><mrow id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.cmml"><mi id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.2" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.2.cmml">𝒄</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.1" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.3" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.3.cmml">𝒐</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.1a" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.1.cmml">​</mo><msub id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.cmml"><mi id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.2" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.2.cmml">𝒔</mi><mi id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.3" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.3.cmml">𝒊</mi></msub></mrow><mo stretchy="false" id="S3.SS3.p6.21.m13.2.2.1.1.1.1.3" xref="S3.SS3.p6.21.m13.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.21.m13.2b"><apply id="S3.SS3.p6.21.m13.2.2.cmml" xref="S3.SS3.p6.21.m13.2.2"><eq id="S3.SS3.p6.21.m13.2.2.2.cmml" xref="S3.SS3.p6.21.m13.2.2.2"></eq><apply id="S3.SS3.p6.21.m13.2.2.3.cmml" xref="S3.SS3.p6.21.m13.2.2.3"><times id="S3.SS3.p6.21.m13.2.2.3.1.cmml" xref="S3.SS3.p6.21.m13.2.2.3.1"></times><ci id="S3.SS3.p6.21.m13.2.2.3.2.cmml" xref="S3.SS3.p6.21.m13.2.2.3.2">𝑝</ci><ci id="S3.SS3.p6.21.m13.2.2.3.3.cmml" xref="S3.SS3.p6.21.m13.2.2.3.3">𝑟</ci><ci id="S3.SS3.p6.21.m13.2.2.3.4.cmml" xref="S3.SS3.p6.21.m13.2.2.3.4">𝑒</ci><apply id="S3.SS3.p6.21.m13.2.2.3.5.cmml" xref="S3.SS3.p6.21.m13.2.2.3.5"><csymbol cd="ambiguous" id="S3.SS3.p6.21.m13.2.2.3.5.1.cmml" xref="S3.SS3.p6.21.m13.2.2.3.5">subscript</csymbol><ci id="S3.SS3.p6.21.m13.2.2.3.5.2.cmml" xref="S3.SS3.p6.21.m13.2.2.3.5.2">𝑑</ci><ci id="S3.SS3.p6.21.m13.2.2.3.5.3.cmml" xref="S3.SS3.p6.21.m13.2.2.3.5.3">𝑖</ci></apply></apply><apply id="S3.SS3.p6.21.m13.2.2.1.cmml" xref="S3.SS3.p6.21.m13.2.2.1"><arg id="S3.SS3.p6.21.m13.2.2.1.2.cmml" xref="S3.SS3.p6.21.m13.2.2.1.2"></arg><apply id="S3.SS3.p6.21.m13.2.2.1.1.2.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1"><max id="S3.SS3.p6.21.m13.1.1.cmml" xref="S3.SS3.p6.21.m13.1.1"></max><apply id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1"><times id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.1"></times><ci id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.2.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.2">𝒄</ci><ci id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.3.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.3">𝒐</ci><apply id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.1.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4">subscript</csymbol><ci id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.2.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.2">𝒔</ci><ci id="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.3.cmml" xref="S3.SS3.p6.21.m13.2.2.1.1.1.1.1.4.3">𝒊</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.21.m13.2c">pred_{i}=\arg\max(\boldsymbol{cos_{i}})</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">Finally, our overall loss function is given by:</p>
<table id="S3.E4" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E4X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle L=L_{dist}+L_{cls}+L_{reg}" display="inline"><semantics id="S3.E4X.2.1.1.m1.1a"><mrow id="S3.E4X.2.1.1.m1.1.1" xref="S3.E4X.2.1.1.m1.1.1.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.2" xref="S3.E4X.2.1.1.m1.1.1.2.cmml">L</mi><mo id="S3.E4X.2.1.1.m1.1.1.1" xref="S3.E4X.2.1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.E4X.2.1.1.m1.1.1.3" xref="S3.E4X.2.1.1.m1.1.1.3.cmml"><msub id="S3.E4X.2.1.1.m1.1.1.3.2" xref="S3.E4X.2.1.1.m1.1.1.3.2.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.3.2.2" xref="S3.E4X.2.1.1.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.E4X.2.1.1.m1.1.1.3.2.3" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.3.2.3.2" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.2.3.1" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.2.3.3" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.2.3.1a" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.2.3.4" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.2.3.1b" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.2.3.5" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.5.cmml">t</mi></mrow></msub><mo id="S3.E4X.2.1.1.m1.1.1.3.1" xref="S3.E4X.2.1.1.m1.1.1.3.1.cmml">+</mo><msub id="S3.E4X.2.1.1.m1.1.1.3.3" xref="S3.E4X.2.1.1.m1.1.1.3.3.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.3.3.2" xref="S3.E4X.2.1.1.m1.1.1.3.3.2.cmml">L</mi><mrow id="S3.E4X.2.1.1.m1.1.1.3.3.3" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.3.3.3.2" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.3.3.1" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.3.3.3" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.3.3.1a" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.3.3.4" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.4.cmml">s</mi></mrow></msub><mo id="S3.E4X.2.1.1.m1.1.1.3.1a" xref="S3.E4X.2.1.1.m1.1.1.3.1.cmml">+</mo><msub id="S3.E4X.2.1.1.m1.1.1.3.4" xref="S3.E4X.2.1.1.m1.1.1.3.4.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.3.4.2" xref="S3.E4X.2.1.1.m1.1.1.3.4.2.cmml">L</mi><mrow id="S3.E4X.2.1.1.m1.1.1.3.4.3" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.cmml"><mi id="S3.E4X.2.1.1.m1.1.1.3.4.3.2" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.4.3.1" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.4.3.3" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4X.2.1.1.m1.1.1.3.4.3.1a" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.1.cmml">​</mo><mi id="S3.E4X.2.1.1.m1.1.1.3.4.3.4" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.4.cmml">g</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4X.2.1.1.m1.1b"><apply id="S3.E4X.2.1.1.m1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1"><eq id="S3.E4X.2.1.1.m1.1.1.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.1"></eq><ci id="S3.E4X.2.1.1.m1.1.1.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.2">𝐿</ci><apply id="S3.E4X.2.1.1.m1.1.1.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3"><plus id="S3.E4X.2.1.1.m1.1.1.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.1"></plus><apply id="S3.E4X.2.1.1.m1.1.1.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.3.2.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2">subscript</csymbol><ci id="S3.E4X.2.1.1.m1.1.1.3.2.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.2">𝐿</ci><apply id="S3.E4X.2.1.1.m1.1.1.3.2.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.3"><times id="S3.E4X.2.1.1.m1.1.1.3.2.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.1"></times><ci id="S3.E4X.2.1.1.m1.1.1.3.2.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.2">𝑑</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.2.3.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.3">𝑖</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.2.3.4.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.4">𝑠</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.2.3.5.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.2.3.5">𝑡</ci></apply></apply><apply id="S3.E4X.2.1.1.m1.1.1.3.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.3.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3">subscript</csymbol><ci id="S3.E4X.2.1.1.m1.1.1.3.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3.2">𝐿</ci><apply id="S3.E4X.2.1.1.m1.1.1.3.3.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3.3"><times id="S3.E4X.2.1.1.m1.1.1.3.3.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.1"></times><ci id="S3.E4X.2.1.1.m1.1.1.3.3.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.2">𝑐</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.3.3.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.3">𝑙</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.3.3.4.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.3.3.4">𝑠</ci></apply></apply><apply id="S3.E4X.2.1.1.m1.1.1.3.4.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E4X.2.1.1.m1.1.1.3.4.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4">subscript</csymbol><ci id="S3.E4X.2.1.1.m1.1.1.3.4.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4.2">𝐿</ci><apply id="S3.E4X.2.1.1.m1.1.1.3.4.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4.3"><times id="S3.E4X.2.1.1.m1.1.1.3.4.3.1.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.1"></times><ci id="S3.E4X.2.1.1.m1.1.1.3.4.3.2.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.2">𝑟</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.4.3.3.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.3">𝑒</ci><ci id="S3.E4X.2.1.1.m1.1.1.3.4.3.4.cmml" xref="S3.E4X.2.1.1.m1.1.1.3.4.3.4">𝑔</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4X.2.1.1.m1.1c">\displaystyle L=L_{dist}+L_{cls}+L_{reg}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
</tbody>
</table>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.2.1.1" class="ltx_tr">
<th id="S3.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S3.T2.2.1.1.1.1" class="ltx_text">Method</span></th>
<th id="S3.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S3.T2.2.1.1.2.1" class="ltx_text">Mask</span></th>
<th id="S3.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S3.T2.2.1.1.3.1" class="ltx_text">Epoch</span></th>
<th id="S3.T2.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S3.T2.2.1.1.4.1" class="ltx_text">Novel Category Knowledge Source</span></th>
<th id="S3.T2.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3">AP50</th>
</tr>
<tr id="S3.T2.2.2.2" class="ltx_tr">
<th id="S3.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Base</th>
<th id="S3.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Novel</th>
<th id="S3.T2.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.2.3.1" class="ltx_tr">
<td id="S3.T2.2.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ZSD-YOLO<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S3.T2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✗</td>
<td id="S3.T2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50</td>
<td id="S3.T2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CLIP’s feature</td>
<td id="S3.T2.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">31.7</td>
<td id="S3.T2.2.3.1.6" class="ltx_td ltx_align_center ltx_border_t">13.6</td>
<td id="S3.T2.2.3.1.7" class="ltx_td ltx_align_center ltx_border_t">19.0</td>
</tr>
<tr id="S3.T2.2.4.2" class="ltx_tr">
<td id="S3.T2.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r">CORA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
<td id="S3.T2.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r">5</td>
<td id="S3.T2.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r">CLIP</td>
<td id="S3.T2.2.4.2.5" class="ltx_td ltx_align_center">35.5</td>
<td id="S3.T2.2.4.2.6" class="ltx_td ltx_align_center"><span id="S3.T2.2.4.2.6.1" class="ltx_text ltx_font_bold">35.1</span></td>
<td id="S3.T2.2.4.2.7" class="ltx_td ltx_align_center">35.4</td>
</tr>
<tr id="S3.T2.2.5.3" class="ltx_tr">
<td id="S3.T2.2.5.3.1" class="ltx_td ltx_align_center ltx_border_r">F-VLM<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S3.T2.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r">6</td>
<td id="S3.T2.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r">CLIP</td>
<td id="S3.T2.2.5.3.5" class="ltx_td ltx_align_center">-</td>
<td id="S3.T2.2.5.3.6" class="ltx_td ltx_align_center">28.0</td>
<td id="S3.T2.2.5.3.7" class="ltx_td ltx_align_center">38.0</td>
</tr>
<tr id="S3.T2.2.6.4" class="ltx_tr">
<td id="S3.T2.2.6.4.1" class="ltx_td ltx_align_center ltx_border_r">PBBL<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S3.T2.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r">ALBEF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, CLIP, Pseudo-label</td>
<td id="S3.T2.2.6.4.5" class="ltx_td ltx_align_center">46.1</td>
<td id="S3.T2.2.6.4.6" class="ltx_td ltx_align_center">30.8</td>
<td id="S3.T2.2.6.4.7" class="ltx_td ltx_align_center">42.1</td>
</tr>
<tr id="S3.T2.2.7.5" class="ltx_tr">
<td id="S3.T2.2.7.5.1" class="ltx_td ltx_align_center ltx_border_r">OVOS<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S3.T2.2.7.5.2" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T2.2.7.5.3" class="ltx_td ltx_align_center ltx_border_r">36</td>
<td id="S3.T2.2.7.5.4" class="ltx_td ltx_align_center ltx_border_r">CLIP’s feature</td>
<td id="S3.T2.2.7.5.5" class="ltx_td ltx_align_center">51.3</td>
<td id="S3.T2.2.7.5.6" class="ltx_td ltx_align_center">20.3</td>
<td id="S3.T2.2.7.5.7" class="ltx_td ltx_align_center">43.2</td>
</tr>
<tr id="S3.T2.2.8.6" class="ltx_tr">
<td id="S3.T2.2.8.6.1" class="ltx_td ltx_align_center ltx_border_r">VTP-OVD<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</td>
<td id="S3.T2.2.8.6.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T2.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T2.2.8.6.4" class="ltx_td ltx_align_center ltx_border_r">CLIP’s feature, Pseudo-label</td>
<td id="S3.T2.2.8.6.5" class="ltx_td ltx_align_center">31.5</td>
<td id="S3.T2.2.8.6.6" class="ltx_td ltx_align_center">29.8</td>
<td id="S3.T2.2.8.6.7" class="ltx_td ltx_align_center">46.1</td>
</tr>
<tr id="S3.T2.2.9.7" class="ltx_tr">
<td id="S3.T2.2.9.7.1" class="ltx_td ltx_align_center ltx_border_r">OADP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S3.T2.2.9.7.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T2.2.9.7.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S3.T2.2.9.7.4" class="ltx_td ltx_align_center ltx_border_r">CLIP’s feature, Pseudo-label</td>
<td id="S3.T2.2.9.7.5" class="ltx_td ltx_align_center">53.3</td>
<td id="S3.T2.2.9.7.6" class="ltx_td ltx_align_center">30.0</td>
<td id="S3.T2.2.9.7.7" class="ltx_td ltx_align_center">47.2</td>
</tr>
<tr id="S3.T2.2.10.8" class="ltx_tr">
<td id="S3.T2.2.10.8.1" class="ltx_td ltx_align_center ltx_border_r">CondHead<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="S3.T2.2.10.8.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T2.2.10.8.3" class="ltx_td ltx_align_center ltx_border_r">107</td>
<td id="S3.T2.2.10.8.4" class="ltx_td ltx_align_center ltx_border_r">CLIP’s feature</td>
<td id="S3.T2.2.10.8.5" class="ltx_td ltx_align_center">60.8</td>
<td id="S3.T2.2.10.8.6" class="ltx_td ltx_align_center">29.8</td>
<td id="S3.T2.2.10.8.7" class="ltx_td ltx_align_center"><span id="S3.T2.2.10.8.7.1" class="ltx_text ltx_font_bold">52.7</span></td>
</tr>
<tr id="S3.T2.2.11.9" class="ltx_tr">
<td id="S3.T2.2.11.9.1" class="ltx_td ltx_align_center ltx_border_r">OV-DETR<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
<td id="S3.T2.2.11.9.2" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S3.T2.2.11.9.3" class="ltx_td ltx_align_center ltx_border_r">50</td>
<td id="S3.T2.2.11.9.4" class="ltx_td ltx_align_center ltx_border_r">CLIP’s feature</td>
<td id="S3.T2.2.11.9.5" class="ltx_td ltx_align_center"><span id="S3.T2.2.11.9.5.1" class="ltx_text ltx_font_bold">61.0</span></td>
<td id="S3.T2.2.11.9.6" class="ltx_td ltx_align_center">29.4</td>
<td id="S3.T2.2.11.9.7" class="ltx_td ltx_align_center"><span id="S3.T2.2.11.9.7.1" class="ltx_text ltx_font_bold">52.7</span></td>
</tr>
<tr id="S3.T2.2.12.10" class="ltx_tr">
<td id="S3.T2.2.12.10.1" class="ltx_td ltx_align_center ltx_border_r">ViLD<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</td>
<td id="S3.T2.2.12.10.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S3.T2.2.12.10.3" class="ltx_td ltx_align_center ltx_border_r">107</td>
<td id="S3.T2.2.12.10.4" class="ltx_td ltx_align_center ltx_border_r">CLIP’s feature</td>
<td id="S3.T2.2.12.10.5" class="ltx_td ltx_align_center">59.5</td>
<td id="S3.T2.2.12.10.6" class="ltx_td ltx_align_center">27.6</td>
<td id="S3.T2.2.12.10.7" class="ltx_td ltx_align_center">51.3</td>
</tr>
<tr id="S3.T2.2.13.11" class="ltx_tr">
<td id="S3.T2.2.13.11.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Ours</td>
<td id="S3.T2.2.13.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">✓</td>
<td id="S3.T2.2.13.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">36</td>
<td id="S3.T2.2.13.11.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">CLIP’s feature, Novel Category Name</td>
<td id="S3.T2.2.13.11.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">59.9</td>
<td id="S3.T2.2.13.11.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">31.6</td>
<td id="S3.T2.2.13.11.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">52.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.4.2" class="ltx_text" style="font-size:90%;">Evaluation results on COCO benchmark. All the models are trained with the ResNet-50 backbone. Mask indicates whether the model is trained with Mask annotations. Our model achieves 4% improvement on Novel with 1/3 training time of ViLD.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We first present our model result on COCO<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and LVIS<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> detection benchmark in section <a href="#S4.SS1" title="4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
In section <a href="#S4.SS2" title="4.2 Efficiency Evaluation ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> we compare our method with ViLD to show the efficiency of our method.
Finally, we conduct the ablation study with visualization analysis.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Implementation Details.</span>
We use the publicly available pre-trained CLIP model ViT-B/32 as the open-vocabulary classification model, with an input size of 224<math id="S4.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.p2.1.m1.1a"><mo id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><times id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">\times</annotation></semantics></math>224.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We finetune the LayerNorm layers in the CLIP with base categories instances in COCO or LVIS based on the setting and maintain all other parameters fixed.
All the instances are cropped by 1.2x enlarged GT bboxes.
We use an AdamW optimizer with a learning rate of 0.0001 and clip the L2 norm of the gradients when larger than 0.1.
We finetune the model for 12 epochs.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">For CLIP Proposal generation, we first resize the image with the image ratio maintained.
We generate the anchors on each image with a stride of 32 pixels and with 5 different sizes (32, 64, 128, 256, 512), and 3 different ratios (1:1, 2:1, 1:2).
We select the top 1000 anchors after NMS as CLIP Proposals on each image.
If we will use the adapted CLIP features to train our detector we use the adapted CLIP to generate the CLIP Proposals.
Otherwise, we use the unadapted CLIP for CLIP Proposal generation.
In model training, we randomly select a fixed subset with 200 CLIP Proposals on each image for training.
We provide more implementation details in the supplementary material.
</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Comparison with Current Methods</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In this section, we evaluate EZAD in the COCO and LVIS detection benchmarks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Datasets and Evaluation Metrics.</span>
We evaluate EZAD on COCO and LVIS(v1).
For the COCO dataset, we use train2017 for training and val2017 for validation.
Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, we divide COCO into 48 base and 17 novel categories.
For the LVIS dataset, we use the training/validation images for training/evaluation.
Previous work uses Frequent and Common categories as the base (866 categories), and Rare categories as the novel (337 categories).
We argue that in this split, the rare category objects are so sparse (less than 0.5% annotations in the validation set) that the model’s performance on it is not representative.
Therefore, we propose a new split called LVIS-Fbase, which uses the Frequent categories as the base (405 categories), and both Common and Rare categories as the novel (common has 461 categories).
On COCO, AP50 is used as the evaluation metric, while on LVIS the AP is used.
</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Model.</span>
We train a Mask R-CNN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> model with ResNet-50<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> FPN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> backbone. The backbone is pre-trained on ImageNet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. We use SGD as the optimizer with batch size 4, learning rate 0.005, momentum 0.9, and weight decay 0.0001. We adopt linear warmup for the first 500 iterations, with a warm-up ratio is 0.001.
On COCO, we train our model with 36 epochs and divide the learning rate by 10 at epoch 27 and epoch 33.
On LVIS, We train our model with 48 epochs and divide the learning rate by 10 at epoch 32 and epoch 44.
We train our model with multi-scale train-time augmentation.
<span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_bold">Baselines.</span>
We compare our method with different Zero-Shot Detection (ZSD) and Open-Vocabulary Detection (OVD) methods, which do not use additional datasets so that they can fit in the Zero-shot Annotation Detection (ZAD) setting.
We mainly compare EZAD with ViLD<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and CondHead<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, which uses distillation to obtain information on the novel categories from CLIP.
They have the best overall performance on the COCO dataset.
However, it uses the data augmentation of large-scale jittering<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> with an extremely long training schedule.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.1.1" class="ltx_tr">
<th id="S4.T3.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.2.1.1.1.1" class="ltx_text">Method</span></th>
<th id="S4.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T3.2.1.1.2.1" class="ltx_text">Epoch</span></th>
<th id="S4.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">AP</th>
</tr>
<tr id="S4.T3.2.2.2" class="ltx_tr">
<th id="S4.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Freq</th>
<th id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Comm</th>
<th id="S4.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Rare</th>
<th id="S4.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">All</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.3.1" class="ltx_tr">
<th id="S4.T3.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">ViLD*</th>
<th id="S4.T3.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">24</th>
<td id="S4.T3.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">24.9</td>
<td id="S4.T3.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">12.2</td>
<td id="S4.T3.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">11.2</td>
<td id="S4.T3.2.3.1.6" class="ltx_td ltx_align_center ltx_border_t">17.5</td>
</tr>
<tr id="S4.T3.2.4.2" class="ltx_tr">
<th id="S4.T3.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Ours</th>
<th id="S4.T3.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">24</th>
<td id="S4.T3.2.4.2.3" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.2.3.1" class="ltx_text ltx_font_bold">30.9</span></td>
<td id="S4.T3.2.4.2.4" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.2.4.1" class="ltx_text ltx_font_bold">14.3</span></td>
<td id="S4.T3.2.4.2.5" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.2.5.1" class="ltx_text ltx_font_bold">12.5</span></td>
<td id="S4.T3.2.4.2.6" class="ltx_td ltx_align_center"><span id="S4.T3.2.4.2.6.1" class="ltx_text ltx_font_bold">20.5</span></td>
</tr>
<tr id="S4.T3.2.5.3" class="ltx_tr">
<th id="S4.T3.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">ViLD*</th>
<th id="S4.T3.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">48</th>
<td id="S4.T3.2.5.3.3" class="ltx_td ltx_align_center">26.4</td>
<td id="S4.T3.2.5.3.4" class="ltx_td ltx_align_center">13.2</td>
<td id="S4.T3.2.5.3.5" class="ltx_td ltx_align_center">11.3</td>
<td id="S4.T3.2.5.3.6" class="ltx_td ltx_align_center">18.5</td>
</tr>
<tr id="S4.T3.2.6.4" class="ltx_tr">
<th id="S4.T3.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Ours</th>
<th id="S4.T3.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">48</th>
<td id="S4.T3.2.6.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.2.6.4.3.1" class="ltx_text ltx_font_bold">31.9</span></td>
<td id="S4.T3.2.6.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.2.6.4.4.1" class="ltx_text ltx_font_bold">15.2</span></td>
<td id="S4.T3.2.6.4.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.2.6.4.5.1" class="ltx_text ltx_font_bold">13.1</span></td>
<td id="S4.T3.2.6.4.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T3.2.6.4.6.1" class="ltx_text ltx_font_bold">21.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.4.2" class="ltx_text" style="font-size:90%;">Evaluation results on LVIS-Fbase benchmark. The ViLD* is our reproduced result of ViLD with a shorter training schedule. EZAD outperforms ViLD in both 2x and 4x settings due to the efficient feature distillation.</span></figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T4.2.1.1.1.1" class="ltx_text">Method</span></th>
<th id="S4.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T4.2.1.1.2.1" class="ltx_text">Epoch</span></th>
<th id="S4.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3">AP50</th>
</tr>
<tr id="S4.T4.2.2.2" class="ltx_tr">
<th id="S4.T4.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Base</th>
<th id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Novel</th>
<th id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.2.3.1" class="ltx_tr">
<th id="S4.T4.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">ViLD*</th>
<th id="S4.T4.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">12</th>
<td id="S4.T4.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">48.3</td>
<td id="S4.T4.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">17.2</td>
<td id="S4.T4.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">40.2</td>
</tr>
<tr id="S4.T4.2.4.2" class="ltx_tr">
<th id="S4.T4.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Ours</th>
<th id="S4.T4.2.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">12</th>
<td id="S4.T4.2.4.2.3" class="ltx_td ltx_align_center"><span id="S4.T4.2.4.2.3.1" class="ltx_text ltx_font_bold">55.7</span></td>
<td id="S4.T4.2.4.2.4" class="ltx_td ltx_align_center"><span id="S4.T4.2.4.2.4.1" class="ltx_text ltx_font_bold">30.4</span></td>
<td id="S4.T4.2.4.2.5" class="ltx_td ltx_align_center"><span id="S4.T4.2.4.2.5.1" class="ltx_text ltx_font_bold">49.0</span></td>
</tr>
<tr id="S4.T4.2.5.3" class="ltx_tr">
<th id="S4.T4.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">ViLD*</th>
<th id="S4.T4.2.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">36</th>
<td id="S4.T4.2.5.3.3" class="ltx_td ltx_align_center">56.0</td>
<td id="S4.T4.2.5.3.4" class="ltx_td ltx_align_center">24.2</td>
<td id="S4.T4.2.5.3.5" class="ltx_td ltx_align_center">48.5</td>
</tr>
<tr id="S4.T4.2.6.4" class="ltx_tr">
<th id="S4.T4.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Ours</th>
<th id="S4.T4.2.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">36</th>
<td id="S4.T4.2.6.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T4.2.6.4.3.1" class="ltx_text ltx_font_bold">59.9</span></td>
<td id="S4.T4.2.6.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T4.2.6.4.4.1" class="ltx_text ltx_font_bold">31.6</span></td>
<td id="S4.T4.2.6.4.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T4.2.6.4.5.1" class="ltx_text ltx_font_bold">52.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.4.2" class="ltx_text" style="font-size:90%;">Evaluation results on COCO. EZAD outperforms ViLD in both 1x and 3x settings, showing our distillation is more efficient.</span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.2.1.1" class="ltx_tr">
<th id="S4.T5.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T5.2.1.1.1.1" class="ltx_text">Method</span></th>
<th id="S4.T5.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="4">Base</th>
<th id="S4.T5.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="4">Novel</th>
<th id="S4.T5.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">General</th>
</tr>
<tr id="S4.T5.2.2.2" class="ltx_tr">
<th id="S4.T5.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">L</th>
<th id="S4.T5.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">M</th>
<th id="S4.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">S</th>
<th id="S4.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Avg</th>
<th id="S4.T5.2.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">L</th>
<th id="S4.T5.2.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">M</th>
<th id="S4.T5.2.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">S</th>
<th id="S4.T5.2.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Avg</th>
<th id="S4.T5.2.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">L</th>
<th id="S4.T5.2.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">M</th>
<th id="S4.T5.2.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">S</th>
<th id="S4.T5.2.2.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Avg</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.2.3.1" class="ltx_tr">
<th id="S4.T5.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">w/o Adaptation</th>
<td id="S4.T5.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">69.9</td>
<td id="S4.T5.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">70.2</td>
<td id="S4.T5.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">46.6</td>
<td id="S4.T5.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.8</td>
<td id="S4.T5.2.3.1.6" class="ltx_td ltx_align_center ltx_border_t">90.7</td>
<td id="S4.T5.2.3.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.2.3.1.7.1" class="ltx_text ltx_font_bold">82.3</span></td>
<td id="S4.T5.2.3.1.8" class="ltx_td ltx_align_center ltx_border_t">48.5</td>
<td id="S4.T5.2.3.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.7</td>
<td id="S4.T5.2.3.1.10" class="ltx_td ltx_align_center ltx_border_t">61.3</td>
<td id="S4.T5.2.3.1.11" class="ltx_td ltx_align_center ltx_border_t">62.2</td>
<td id="S4.T5.2.3.1.12" class="ltx_td ltx_align_center ltx_border_t">36.9</td>
<td id="S4.T5.2.3.1.13" class="ltx_td ltx_align_center ltx_border_t">53.9</td>
</tr>
<tr id="S4.T5.2.4.2" class="ltx_tr">
<th id="S4.T5.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">w/ Adaptation</th>
<td id="S4.T5.2.4.2.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.2.1" class="ltx_text ltx_font_bold">92.5</span></td>
<td id="S4.T5.2.4.2.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.3.1" class="ltx_text ltx_font_bold">89.5</span></td>
<td id="S4.T5.2.4.2.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.4.1" class="ltx_text ltx_font_bold">80.3</span></td>
<td id="S4.T5.2.4.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T5.2.4.2.5.1" class="ltx_text ltx_font_bold">87.5</span></td>
<td id="S4.T5.2.4.2.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.6.1" class="ltx_text ltx_font_bold">91.1</span></td>
<td id="S4.T5.2.4.2.7" class="ltx_td ltx_align_center ltx_border_b">81.6</td>
<td id="S4.T5.2.4.2.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.8.1" class="ltx_text ltx_font_bold">66.3</span></td>
<td id="S4.T5.2.4.2.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T5.2.4.2.9.1" class="ltx_text ltx_font_bold">81.9</span></td>
<td id="S4.T5.2.4.2.10" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.10.1" class="ltx_text ltx_font_bold">84.8</span></td>
<td id="S4.T5.2.4.2.11" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.11.1" class="ltx_text ltx_font_bold">80.7</span></td>
<td id="S4.T5.2.4.2.12" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.12.1" class="ltx_text ltx_font_bold">68.8</span></td>
<td id="S4.T5.2.4.2.13" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T5.2.4.2.13.1" class="ltx_text ltx_font_bold">78.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.4.2" class="ltx_text" style="font-size:90%;">Adapting CLIP to the detection dataset’s domain. The table presents the classification accuracy (ACC) of CLIP(w/ or w/o adaptation) when it is applied to classify the COCO dataset’s instance. The ACC is aggregated based on the size of the instances. After the adaptation, the ACC is improved by a huge margin in three different settings, especially for small objects.</span></figcaption>
</figure>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Results.</span>
Table <a href="#S3.T2" title="Table 2 ‣ 3.3 Model Structure ‣ 3 Method ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of EZAD in the COCO detection benchmark.
Both the CORA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> and F-VLM<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> are prompt-base methods. Although they need less training time and have strong novel category performance, their performance in the base categories is much worse than other methods.
ZSD-YOLO<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and OVOS<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> use a one-stage detector and suffer from high false positives in the detection results, which causes low AP in novel categories.
PBBL, VTP-OVD, and OADP are trained with pseudo-labels, introducing noise and harming the model performance on base categories.
OV-DETR<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, CondHead<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and ViLD<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> are pure distillation-based method. While the OV-DETR uses the transformer architecture which is heavier and has a better result than ViLD, the CondHead proposes a new detection head that can improve ViLD performance.
Our EZAD achieves 59.9% and 31.6% on base and novel, respectively. Its performance is 4% better than ViLD in the novel and has a better performance in base and overall settings, with the use of 1/3 of ViLD’s training time.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of EZAD in our LVIS-Fbase benchmark.
The ViLD is trained 468 epochs on LVIS, which is too long to be fully reproduced.
We reproduce the ViLD with 24 and 48 epochs.
Our method uses ViLD’s model structure and distillation pipeline, and the improvement of our method comes from the distillation feature and distillation region.
Therefore, reproducing the ViLD with a shorter training schedule will not affect the fairness of the comparison.
With 48 epochs, our method shows a 5% improvement in Freq and 2% improvement in both Comm and Rare over the ViLD with the same training schedule.
In the CLIP proposals generation, EZAD only uses frequent and common object names to generate proposals. Therefore, EZAD does not take advantage of the category name on the Rare.
We believe that the enhancement in performance for the rare and frequent categories can be attributed to eliminating the domain gap, whereas the improvement in common categories results from both the CLIP proposals and domain adaptation.
</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">Because we have utilized the ZAD setting, there are novel instances present in our training images. This enables us to effectively leverage the information from these novel instances, thus achieving better performance than existing methods. However, the same cannot be achieved with Zero-Shot Detection (ZSD). On the other hand, we don’t need additional annotations like many OVD methods do, meaning our ZAD setting can be applied to more real-life settings.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.2.1.1" class="ltx_tr">
<th id="S4.T6.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">CLIP Feature</th>
<th id="S4.T6.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Distill Region</th>
<th id="S4.T6.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Base</th>
<th id="S4.T6.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Novel</th>
<th id="S4.T6.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.2.2.1" class="ltx_tr">
<th id="S4.T6.2.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Raw</th>
<th id="S4.T6.2.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">RPN Proposal</th>
<td id="S4.T6.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t">48.8</td>
<td id="S4.T6.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t">17.5</td>
<td id="S4.T6.2.2.1.5" class="ltx_td ltx_align_center ltx_border_t">40.6</td>
</tr>
<tr id="S4.T6.2.3.2" class="ltx_tr">
<th id="S4.T6.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Adapted</th>
<th id="S4.T6.2.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">RPN Proposal</th>
<td id="S4.T6.2.3.2.3" class="ltx_td ltx_align_center">56.9</td>
<td id="S4.T6.2.3.2.4" class="ltx_td ltx_align_center">24.6</td>
<td id="S4.T6.2.3.2.5" class="ltx_td ltx_align_center">48.5</td>
</tr>
<tr id="S4.T6.2.4.3" class="ltx_tr">
<th id="S4.T6.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Raw</th>
<th id="S4.T6.2.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">CLIP Proposal</th>
<td id="S4.T6.2.4.3.3" class="ltx_td ltx_align_center">48.7</td>
<td id="S4.T6.2.4.3.4" class="ltx_td ltx_align_center">19.3</td>
<td id="S4.T6.2.4.3.5" class="ltx_td ltx_align_center">41.7</td>
</tr>
<tr id="S4.T6.2.5.4" class="ltx_tr">
<th id="S4.T6.2.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Adapted</th>
<th id="S4.T6.2.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">CLIP Proposal</th>
<td id="S4.T6.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b">55.7</td>
<td id="S4.T6.2.5.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T6.2.5.4.4.1" class="ltx_text ltx_font_bold">30.4</span></td>
<td id="S4.T6.2.5.4.5" class="ltx_td ltx_align_center ltx_border_b">49.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.3.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.4.2" class="ltx_text" style="font-size:90%;">Ablation study on CLIP’s feature adaptation and CLIP Proposal using COCO detection benchmark.</span></figcaption>
</figure>
<figure id="S4.T7" class="ltx_table">
<table id="S4.T7.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.2.1.1" class="ltx_tr">
<th id="S4.T7.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">SB Reg</th>
<th id="S4.T7.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">PPDW</th>
<th id="S4.T7.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Base</th>
<th id="S4.T7.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Novel</th>
<th id="S4.T7.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.2.2.1" class="ltx_tr">
<th id="S4.T7.2.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="S4.T7.2.2.1.2" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="S4.T7.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t">55.5</td>
<td id="S4.T7.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t">28.2</td>
<td id="S4.T7.2.2.1.5" class="ltx_td ltx_align_center ltx_border_t">48.3</td>
</tr>
<tr id="S4.T7.2.3.2" class="ltx_tr">
<th id="S4.T7.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">✓</th>
<th id="S4.T7.2.3.2.2" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S4.T7.2.3.2.3" class="ltx_td ltx_align_center">55.8</td>
<td id="S4.T7.2.3.2.4" class="ltx_td ltx_align_center">29.8</td>
<td id="S4.T7.2.3.2.5" class="ltx_td ltx_align_center">48.5</td>
</tr>
<tr id="S4.T7.2.4.3" class="ltx_tr">
<th id="S4.T7.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">✓</th>
<th id="S4.T7.2.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">✓</th>
<td id="S4.T7.2.4.3.3" class="ltx_td ltx_align_center ltx_border_b">55.7</td>
<td id="S4.T7.2.4.3.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.2.4.3.4.1" class="ltx_text ltx_font_bold">30.4</span></td>
<td id="S4.T7.2.4.3.5" class="ltx_td ltx_align_center ltx_border_b">49.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.3.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T7.4.2" class="ltx_text" style="font-size:90%;">Ablation study on Semantic-based regressor and per CLIP Proposal distillation weight using COCO detection benchmark. SB Reg means the Semantic-based regressor, and PPDW means the per CLIP Proposal distillation weight.</span></figcaption>
</figure>
<figure id="S4.T8" class="ltx_table">
<table id="S4.T8.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T8.2.2" class="ltx_tr">
<th id="S4.T8.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Proposal</th>
<th id="S4.T8.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">IoGT</th>
<th id="S4.T8.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">#(IoGT<math id="S4.T8.1.1.1.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S4.T8.1.1.1.m1.1a"><mo id="S4.T8.1.1.1.m1.1.1" xref="S4.T8.1.1.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.m1.1b"><geq id="S4.T8.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.m1.1c">\geq</annotation></semantics></math>0.8)</th>
<th id="S4.T8.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">#(IoGT<math id="S4.T8.2.2.2.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S4.T8.2.2.2.m1.1a"><mo id="S4.T8.2.2.2.m1.1.1" xref="S4.T8.2.2.2.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.m1.1b"><geq id="S4.T8.2.2.2.m1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.m1.1c">\geq</annotation></semantics></math>0.5)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T8.2.3.1" class="ltx_tr">
<th id="S4.T8.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">RPN</th>
<td id="S4.T8.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">0.340</td>
<td id="S4.T8.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">362818 (9%)</td>
<td id="S4.T8.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">610157 (15%)</td>
</tr>
<tr id="S4.T8.2.4.2" class="ltx_tr">
<th id="S4.T8.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">CLIP(Ours)</th>
<td id="S4.T8.2.4.2.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T8.2.4.2.2.1" class="ltx_text ltx_font_bold">0.365</span></td>
<td id="S4.T8.2.4.2.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T8.2.4.2.3.1" class="ltx_text ltx_font_bold">563799 (14%)</span></td>
<td id="S4.T8.2.4.2.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T8.2.4.2.4.1" class="ltx_text ltx_font_bold">870830 (21%)</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T8.11.3.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="S4.T8.6.2" class="ltx_text" style="font-size:90%;">The effective distillation region of different proposals. The table presents the <span id="S4.T8.6.2.1" class="ltx_text ltx_font_bold">I</span>ntersection between the proposal and the novel GT bboxes <span id="S4.T8.6.2.2" class="ltx_text ltx_font_bold">o</span>ver novel <span id="S4.T8.6.2.3" class="ltx_text ltx_font_bold">GT</span> bboxes (IoGT), the number of proposals that have high IoGT (IoGT<math id="S4.T8.5.1.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S4.T8.5.1.m1.1b"><mo id="S4.T8.5.1.m1.1.1" xref="S4.T8.5.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S4.T8.5.1.m1.1c"><geq id="S4.T8.5.1.m1.1.1.cmml" xref="S4.T8.5.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.1.m1.1d">\geq</annotation></semantics></math>0.8, IoGT<math id="S4.T8.6.2.m2.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S4.T8.6.2.m2.1b"><mo id="S4.T8.6.2.m2.1.1" xref="S4.T8.6.2.m2.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S4.T8.6.2.m2.1c"><geq id="S4.T8.6.2.m2.1.1.cmml" xref="S4.T8.6.2.m2.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.2.m2.1d">\geq</annotation></semantics></math>0.5), and the percentage of these proposals in all proposals. Our CLIP proposals can cover more novel categories instances thus improving the distillation efficiency.</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Efficiency Evaluation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In this section, we compare EZAD with our reproduced ViLD to show the efficiency of our method. In Table <a href="#S4.T4" title="Table 4 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we present our model and our reproduced ViLD on COCO with 1x and 3x training schedules. Our method is consistently better than ViLD in two different settings. Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows EZAD and our reproduced ViLD on the LVIS dataset with 2x and 4x training schedules. Our method shows substantial improvement over the ViLD with the same training schedule.
These results suggest that the adapted feature space and the CLIP Proposals improve the distillation quality and efficiency. Thus, the model performance is improved.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Study and Visualization</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we conduct ablation studies using the COCO detection benchmark. All the experiment details are the same as mentioned in section <a href="#S4.SS1" title="4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. We train our detector for 12 epochs in all experiments of this section.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2303.12145/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="140" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">The visualization result on the COCO. The first row presents the results of the model trained with the adapted CLIP features from CLIP Proposals. The second row presents the results of the model trained with raw CLIP features from RPN proposals.</span></figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">CLIP’s Feature Adaptation and CLIP Proposal.</span>
Table <a href="#S4.T5" title="Table 5 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the classification result of adapting the CLIP to the COCO dataset’s domain.
We evaluate the classification accuracy(ACC) on the instances in the COCO validation set.
We use the splits in Section <a href="#S4.SS1" title="4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
Since the novel setting is a 17-ways classification which is easier than the other two settings, the ACC in the novel setting is much higher than the one in the other two.
</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Before the adaptation, the ACC in the general setting is only about 53.9%, which is much lower than the ACC of the classifier in a well-trained detector.
This phenomenon indicates that there is a huge domain gap between the training data of CLIP and the detection dataset.
While the objects in CLIP’s training image are clear and large and at the center of the image, the objects in the detection dataset might be small and occluded.
Although we only fine-tuned the CLIP on base categories instances, we observed a huge improvement in all three settings, especially for the small objects.
The average ACC reaches 87.5%, 81.9%, and 78.3% in the Base, Novel, and General settings, respectively.
The ACC for the small objects improved by 33.7%, 17.8%, and 31.9% in three different settings.
This indicates that the simple fine-tuning method can effectively bridge the domain gap and make the feature more discriminating.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">Table <a href="#S4.T6" title="Table 6 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the effectiveness of the CLIP Proposals and the CLIP’s feature adaptation in the detection setting.
Using the adapted CLIP’s feature for distillation can consistently improve both base and novel categories performance, no matter which kinds of distillation regions we use.
Our model performance on novel benefits from using CLIP Proposals as distillation regions (30.4% vs. 24.6% with adapted CLIP features and 19.3% vs 17.5% with raw CLIP features).
We believe that the adaptation of the CLIP and CLIP Proposal are complementary to each other, which makes the improvement given by CLIP Proposals with adapted CLIP (5.8%) larger than CLIP Proposals with raw CLIP (1.8%).
</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">The performance on base categories of models trained with CLIP Proposals is slightly worse than those trained with RPN proposals since the CLIP Proposals focus more on the regions with novel categories.
Our experiment results show that with a longer training schedule, the performance gap on the base categories can be eliminated while the advantage on the novel will be maintained. We will provide these results in the supplementary material.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p"><span id="S4.SS3.p6.1.1" class="ltx_text ltx_font_bold">Semantic-based Regressor and Per CLIP Proposal Distillation Weight.</span>
Table <a href="#S4.T7" title="Table 7 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the effects of semantic-base regressor and per CLIP Proposal distillation weight.
All experiments use adapted CLIP’s features and CLIP Proposals as distillation regions.
The semantic-base regressor helps the model perform better on both base and novel categories, showing that the semantic meaning of the categories does provide useful information to the regressor.
Combining the semantic-base regressor and per CLIP Proposal distillation weight, the AP50 on novel reaches 30.4%.
This indicates the reweighting of different distillation boxes further improves the distillation quality.</p>
</div>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p"><span id="S4.SS3.p7.1.1" class="ltx_text ltx_font_bold">Statistic and Visualization Analysis.</span>
To compare which proposals can provide more meaningful novel categories information, we compare the effective distillation region of different proposals in an 8000 images subset of COCO training set in Table <a href="#S4.T8" title="Table 8 ‣ 4.1 Comparison with Current Methods ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
We calculate the <span id="S4.SS3.p7.1.2" class="ltx_text ltx_font_bold">I</span>ntersection between the proposal and the novel GT bboxes <span id="S4.SS3.p7.1.3" class="ltx_text ltx_font_bold">o</span>ver novel <span id="S4.SS3.p7.1.4" class="ltx_text ltx_font_bold">GT</span> bboxes (IoGT) and present the number and the percentage of the proposals that have high IoGT in all proposals.
Our CLIP proposals are 6% higher than the RPN proposal in the percentage of the high IoGT proposals, meaning that the CLIP proposal can cover more potential novel instances and improve the distillation efficiency.</p>
</div>
<div id="S4.SS3.p8" class="ltx_para">
<p id="S4.SS3.p8.1" class="ltx_p">Figure <a href="#S4.F5" title="Figure 5 ‣ 4.3 Ablation Study and Visualization ‣ 4 Experiments ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> provides some visualizations of the detected novel objects on the COCO benchmark.
The first row presents the results from the model trained with the adapted CLIP features from CLIP Proposals (AFCP).
The second row presents the results from the model trained with raw CLIP features from the RPN proposal (RFRP).
The results show that though two models can localize the object correctly, the AFCP model has a higher classification accuracy than the RFRP model thanks to the adapted features and the more meaningful distillation regions.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We propose a new setting for detecting novel instances, called Zero-shot Annotation object Detection (ZAD), to move one step closer to the real-life scenario.
Our method Efficient Feature Distillation for Zero-shot Annotation Detection (EZAD) in this paper.
EZAD successfully bridging the domain gap between the classification and detection datasets, and selecting the meaningful distillation regions (CLIP Proposals) for obtaining knowledge from CLIP.
Benefiting from these two improvements, EZAD outperforms previous distillation-based work in both COCO and LVIS with a much shorter training schedule.
We believe our work provides a solid solution for applying zero-shot annotation detection in real life, and we hope our method can inspire other works in the future.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This material is based on research sponsored by Air Force Research Laboratory (AFRL) under agreement number FA8750-19-1-1000. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation therein. The
views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Air Force Laboratory, DARPA or the U.S. Government.
<span id="Sx1.p1.1.1" class="ltx_text" style="font-size:90%;"></span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Ankan Bansal, Karan Sikka, Gaurav Sharma, Rama Chellappa, and Ajay Divakaran.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Zero-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 384–400, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Language models are few-shot learners.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">,
33:1877–1901, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Improved baselines with momentum contrastive learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2003.04297</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2009 IEEE conference on computer vision and pattern
recognition</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 248–255. Ieee, 2009.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Bert: Pre-training of deep bidirectional transformers for language
understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1810.04805</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Chengjian Feng, Yujie Zhong, Zequn Jie, Xiangxiang Chu, Haibing Ren, Xiaolin
Wei, Weidi Xie, and Lin Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Promptdet: Expand your detector vocabulary with uncurated images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.16513</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Mingfei Gao, Chen Xing, Juan Carlos Niebles, Junnan Li, Ran Xu, Wenhao Liu, and
Caiming Xiong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Towards open vocabulary object detection without human-provided
bounding boxes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.09452</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung-Yi Lin, Ekin D Cubuk,
Quoc V Le, and Barret Zoph.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Simple copy-paste is a strong data augmentation method for instance
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, pages 2918–2928, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, and Yin Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary object detection via vision and language knowledge
distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.13921</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Agrim Gupta, Piotr Dollar, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Lvis: A dataset for large vocabulary instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, pages 5356–5364, 2019.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Guangxing Han, Shiyuan Huang, Jiawei Ma, Yicheng He, and Shih-Fu Chang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Meta faster r-cnn: Towards accurate few-shot object detection with
attentive feature alignment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, volume 36, pages 780–789, 2022.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Momentum contrast for unsupervised visual representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 9729–9738, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Mask r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 2961–2969, 2017.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 770–778, 2016.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Scaling up visual and vision-language representation learning with
noisy text supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages
4904–4916. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Konwoo Kim, Michael Laskin, Igor Mordatch, and Deepak Pathak.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">How to adapt your large-scale vision-and-language model, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Weicheng Kuo, Yin Cui, Xiuye Gu, AJ Piergiovanni, and Anelia Angelova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">F-vlm: Open-vocabulary object detection upon frozen vision and
language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2209.15639</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Brian Lester, Rami Al-Rfou, and Noah Constant.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">The power of scale for parameter-efficient prompt tuning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.08691</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong,
and Steven Chu Hong Hoi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Align before fuse: Vision and language representation learning with
momentum distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">,
34:9694–9705, 2021.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Liunian Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li,
Yiwu Zhong, Lijuan Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Grounded language-image pre-training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 10965–10975, 2022.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Xiang Lisa Li and Percy Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Prefix-tuning: Optimizing continuous prompts for generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2101.00190</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan,
and Serge Belongie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Feature pyramid networks for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 2117–2125, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 740–755.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Yanxin Long, Jianhua Han, Runhui Huang, Xu Hang, Yi Zhu, Chunjing Xu, and
Xiaodan Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Povd: Fine-grained visual-text prompt-driven self-training for
open-vocabulary object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.00849</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Kevin Lu, Aditya Grover, Pieter Abbeel, and Igor Mordatch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Pretrained transformers as universal computation engines.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2103.05247</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Zongyang Ma, Guan Luo, Jin Gao, Liang Li, Yuxin Chen, Shaoru Wang, Congxuan
Zhang, and Weiming Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary one-stage detection with hierarchical visual-language
knowledge distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 14074–14083, June 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron
Courville.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Film: Visual reasoning with a general conditioning layer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, volume 32, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Learning transferable visual models from natural language
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages
8748–8763. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Shafin Rahman, Salman Khan, and Nick Barnes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Improved visual-semantic alignment for zero-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, volume 34, pages 11932–11939, 2020.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 28, 2015.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Luting Wang, Yi Liu, Penghui Du, Zihan Ding, Yue Liao, Qiaosong Qi, Biaolong
Chen, and Si Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Object-aware distillation pyramid for open-vocabulary object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 11186–11196, 2023.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Tao Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Learning to detect and segment for open vocabulary object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 7051–7060, 2023.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Xin Wang, Thomas E Huang, Trevor Darrell, Joseph E Gonzalez, and Fisher Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Frustratingly simple few-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2003.06957</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Xiaoshi Wu, Feng Zhu, Rui Zhao, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Cora: Adapting clip for open-vocabulary detection with region
prompting and anchor pre-matching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 7031–7040, 2023.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Johnathan Xie and Shuai Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Zero-shot object detection through vision-language embedding
alignment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE International Conference on Data Mining Workshops
(ICDMW)</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 1–15. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Yuhang Zang, Wei Li, Kaiyang Zhou, Chen Huang, and Chen Change Loy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary detr with conditional matching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 106–122.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Alireza Zareian, Kevin Dela Rosa, Derek Hao Hu, and Shih-Fu Chang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary object detection using captions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages 14393–14402, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Shiyu Zhao, Zhixing Zhang, Samuel Schulter, Long Zhao, BG Vijay Kumar,
Anastasis Stathopoulos, Manmohan Chandraker, and Dimitris N Metaxas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Exploiting unlabeled data with vision and language models for object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages 159–175.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Yiwu Zhong, Jianwei Yang, Pengchuan Zhang, Chunyuan Li, Noel Codella,
Liunian Harold Li, Luowei Zhou, Xiyang Dai, Lu Yuan, Yin Li, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Regionclip: Region-based language-image pretraining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 16793–16803, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Xingyi Zhou, Rohit Girdhar, Armand Joulin, Philipp Krähenbühl, and
Ishan Misra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Detecting twenty-thousand classes using image-level supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2022: 17th European Conference, Tel
Aviv, Israel, October 23–27, 2022, Proceedings, Part IX</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, pages 350–368.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Pengkai Zhu, Hanxiao Wang, and Venkatesh Saligrama.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Don’t even look once: Synthesizing features for zero-shot detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, pages 11693–11702, 2020.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">We include all implementation details in this section.</p>
</div>
<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Adapt Image-language Model Feature</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">We use the publicly available pretrained CLIP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> model ViT-B/32 as the open-vocabulary classification model, with an input size of 224<math id="A1.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A1.SS1.p1.1.m1.1a"><mo id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><times id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">\times</annotation></semantics></math>224.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">Based on the detection setting we use for training and evaluating our detector, we adapt the CLIP to two detection domains: COCO<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> detection domain, LVIS detection domain<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
We finetune the layer normalization layers in the CLIP with base category instances in COCO or LVIS based on the detection setting we use and maintain all other parameters fixed.
All base category instances are cropped by 1.2x enlarged GT bboxes.
We conduct the zero padding to convert each cropped region to the square and apply the default preprocessing pipeline of the CLIP.</p>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p id="A1.SS1.p3.1" class="ltx_p">We use CLIP to predict the category of each cropped region and calculate the cross-entropy loss with the GT label of each region.
We finetune the model by optimizing the Cross-Entropy Loss.
We use AdamW optimizer with a learning rate of 0.0001, batch size 4 and clip the L2 norm of the gradients when larger than 0.1.
We finetune the model for 12 epochs.</p>
</div>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Generate CLIP Proposals</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">When generating the CLIP Proposals, we still use the CLIP model we mentioned in section <a href="#A1.SS1" title="A.1 Adapt Image-language Model Feature ‣ Appendix A Implementation Details ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a> as a classifier to select the distillation regions. If we will use the adapted CLIP’s feature to train the detector, we will use the adapted CLIP to generate the CLIP Proposals. Otherwise, we use the unadapted CLIP to generate CLIP Proposals.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<p id="A1.SS2.p2.1" class="ltx_p">We generate the CLIP proposals on all the training images of the detection dataset base on the detection setting we use.
We first resize the image with the image ratio maintained.
The long edge of the image will be resized into 1333 as width or 800 as height.</p>
</div>
<div id="A1.SS2.p3" class="ltx_para">
<p id="A1.SS2.p3.1" class="ltx_p">We generate the anchors on each image with a stride of 32 pixels and with 5 different sizes (32, 64, 128, 256, 512), and 3 different ratios (1:1, 2:1, 1:2).
We select the top 1000 anchors after NMS as CLIP Proposals on each image.
We filter out the anchors which have high IoU with the base category GT bboxes to reduce the redundancy since we will add 1.2x enlarged base category GT bbox as part of the CLIP Proposals.
In model training, we randomly select a fixed subset with 200 CLIP Proposals on each image for training.
</p>
</div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Detection Setting</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">In COCO detection setting, the dataset is divided into 48 base categories and 17 novel categories.
15 categories without a synset in the WordNet hierarchy are removed.</p>
</div>
<div id="A1.SS3.p2" class="ltx_para">
<p id="A1.SS3.p2.1" class="ltx_p">We filter out the training images which do not have base category annotation.
Following the setting in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, we filter out the images that have neither the base category instances nor the novel category instances in the validation set.
The training set contains 107761 images and 665387 base category instances.
The validation set contains 4836 images and 28538 base category instances and 33152 novel category instances.
We evaluate the model in a generalized setting, which evaluates the base and novel categories at the same time.
AP50 is used as the evaluation metric.</p>
</div>
<div id="A1.SS3.p3" class="ltx_para">
<p id="A1.SS3.p3.1" class="ltx_p">In LVIS detection setting, the dataset is divided into 866 base categories (containing 405 frequent categories and 461 common categories) and 337 novel categories (337 rare categories).
Our LVIS-Fbase split uses the frequent categories as the base(405 categories), common and rare categories as the novel(common has 461 categories, rare has 405 categories).
The training set contains 98531 images and 1200258 base category instances.
The validation set contains 19442 images and 230427 base category instances and 14280 novel category instances.
We aggregate the model performance in frequent, common, and rare categories separately.
AP is used as the evaluation metric.</p>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experiments in Few-shot Detection Settings</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">In few-shot object detection, the model is trained on the base category’s annotations and evaluated on novel categories.
The only difference is that in few-shot detection, each novel category has the same number of annotated objects(i.e, K-shot), which can be used to improve the model performance on the novel before the model is evaluated.
We directly evaluate our model in the few-shot benchmark, without using this K-shot additional information.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p"><span id="A2.p2.1.1" class="ltx_text ltx_font_bold">Datasets and Evaluation Metrics.</span>
We evaluate our approach on PASCAL VOC 2007+2012 and COCO.
For the few-shot PASCAL VOC dataset, we combine the trainval set of 2007 with the one of 2012 as training data.
PASCAL VOC 2007 test set is used for evaluation.
The 20 classes are divided into 15 base classes and 5 novel classes.
We evaluate our model in three different base/novel splits used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
Split 1 has 14631 training images with 41084 base category instances, and the validation set has 4952 images, 10552 base category instances, and 1480 novel instances.
Split 2 has 14779 training images with 40397 base category instances, and the validation set has 4952 images, 10447 base category instances, and 1585 novel instances.
Split 3 has 14318 training images with 40511 base category instances, and the validation set has 4952 images, 10605 base category instances, and 1427 novel instances.</p>
</div>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">For the few-shot COCO dataset, we use the COCO train2017 as training data and evaluate our model on the COCO val2017.
The 20 categories that exist in PASCAL VOC are used as the novel categories, while the rest of the 60 categories are used as the base categories.
The training set has 98459 images and 367189 base category instances.
The validation set has 5000 images and 15831 base category instances and 36781 novel category instances.</p>
</div>
<div id="A2.p4" class="ltx_para">
<p id="A2.p4.1" class="ltx_p">AP50 is used as the evaluation metric in PASCAL VOC, while AP and AP50 are used in COCO.</p>
</div>
<div id="A2.p5" class="ltx_para">
<p id="A2.p5.1" class="ltx_p"><span id="A2.p5.1.1" class="ltx_text ltx_font_bold">Model.</span>
Following previous work in few-shot detection, we train a Faster R-CNN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> model with ResNet-101 FPN backbone.
The backbone is pretrained on ImageNet.
We use SGD as the optimizer with batch size 4, learning rate 0.005, momentum 0.9, and weight decay 0.0001.
We also adopt linear warmup for the first 500 iterations, with a warm up ratio is 0.001.
We apply multi-scale train-time augmentation.
For the PASCAL VOC dataset, we train the model for 21 epochs and divide the learning rate by 10 at epoch 15 and epoch 18.
For the COCO dataset, we train the model for 18 epochs and divide the learning rate by 10 at epoch 14 and epoch 16.</p>
</div>
<div id="A2.p6" class="ltx_para">
<p id="A2.p6.1" class="ltx_p"><span id="A2.p6.1.1" class="ltx_text ltx_font_bold">Baselines.</span>
We compare EZAD’s performance with two few-shot detection models, TFA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> and Meta Faster R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> as the baselines. The TFA model with linear layer as the classifier is noted as <span id="A2.p6.1.2" class="ltx_text ltx_font_italic">TFA w/fc</span>, while the model with cosine classifier is noted as <span id="A2.p6.1.3" class="ltx_text ltx_font_italic">TFA w/cos</span>.</p>
</div>
<div id="A2.p7" class="ltx_para">
<p id="A2.p7.1" class="ltx_p"><span id="A2.p7.1.1" class="ltx_text ltx_font_bold">Results.</span>
Table <a href="#A2.T9" title="Table 9 ‣ Appendix B Experiments in Few-shot Detection Settings ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows the results on the PASCAL dataset.
EZAD achieves 40.9% in novel AP50 averaged over three different splits.
EZAD’s performance matches the TFA 3-shot performance in split1 and split2 and is 4.7% higher than TFA in split3.
Compared with the TFA’s performance on base, EZAD is 1.8% higher.
For Meta Faster R-CNN, it generates proposals for each category on each image, which needs multiple forward passes.
Its inference time will be much slower if the dataset has a large number of novel categories.
Compared with the Meta Faster R-CNN, EZAD outperforms it without using any additional annotations by a 1.6%, 3%, and 6.9% in three different splits, respectively.
Table <a href="#A2.T10" title="Table 10 ‣ Appendix B Experiments in Few-shot Detection Settings ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows the results on the COCO dataset.
EZAD achieves 10.2% and 22.2% in AP and AP50, respectively, matching TFA’s 10-shot performance and 2.6% and 5.9% higher than the Meta Faster R-CNN’s 2-shot performance in AP and AP50, respectively.
Our model zero-shot performance on the few-shot setting shows the power of adapted multi-modal feature space and validates the effectiveness of using CLIP Proposals as distillation regions.</p>
</div>
<figure id="A2.T9" class="ltx_table">
<table id="A2.T9.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T9.2.1.1" class="ltx_tr">
<th id="A2.T9.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="A2.T9.2.1.1.1.1" class="ltx_text">Method</span></th>
<th id="A2.T9.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="A2.T9.2.1.1.2.1" class="ltx_text">Shot</span></th>
<td id="A2.T9.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="4">Novel AP50</td>
</tr>
<tr id="A2.T9.2.2.2" class="ltx_tr">
<td id="A2.T9.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Split1</td>
<td id="A2.T9.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Split2</td>
<td id="A2.T9.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Split 3</td>
<td id="A2.T9.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Avg</td>
</tr>
<tr id="A2.T9.2.3.3" class="ltx_tr">
<th id="A2.T9.2.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">TFA w/fc</th>
<th id="A2.T9.2.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">1</th>
<td id="A2.T9.2.3.3.3" class="ltx_td ltx_align_center ltx_border_t">36.8</td>
<td id="A2.T9.2.3.3.4" class="ltx_td ltx_align_center ltx_border_t">18.2</td>
<td id="A2.T9.2.3.3.5" class="ltx_td ltx_align_center ltx_border_t">27.7</td>
<td id="A2.T9.2.3.3.6" class="ltx_td ltx_align_center ltx_border_t">27.6</td>
</tr>
<tr id="A2.T9.2.4.4" class="ltx_tr">
<th id="A2.T9.2.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TFA w/fc</th>
<th id="A2.T9.2.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="A2.T9.2.4.4.3" class="ltx_td ltx_align_center">29.1</td>
<td id="A2.T9.2.4.4.4" class="ltx_td ltx_align_center">29.0</td>
<td id="A2.T9.2.4.4.5" class="ltx_td ltx_align_center">33.6</td>
<td id="A2.T9.2.4.4.6" class="ltx_td ltx_align_center">30.6</td>
</tr>
<tr id="A2.T9.2.5.5" class="ltx_tr">
<th id="A2.T9.2.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TFA w/fc</th>
<th id="A2.T9.2.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<td id="A2.T9.2.5.5.3" class="ltx_td ltx_align_center">43.6</td>
<td id="A2.T9.2.5.5.4" class="ltx_td ltx_align_center">33.4</td>
<td id="A2.T9.2.5.5.5" class="ltx_td ltx_align_center">42.5</td>
<td id="A2.T9.2.5.5.6" class="ltx_td ltx_align_center">39.8</td>
</tr>
<tr id="A2.T9.2.6.6" class="ltx_tr">
<th id="A2.T9.2.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TFA w/cos</th>
<th id="A2.T9.2.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1</th>
<td id="A2.T9.2.6.6.3" class="ltx_td ltx_align_center">39.8</td>
<td id="A2.T9.2.6.6.4" class="ltx_td ltx_align_center">23.5</td>
<td id="A2.T9.2.6.6.5" class="ltx_td ltx_align_center">30.8</td>
<td id="A2.T9.2.6.6.6" class="ltx_td ltx_align_center">31.4</td>
</tr>
<tr id="A2.T9.2.7.7" class="ltx_tr">
<th id="A2.T9.2.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TFA w/cos</th>
<th id="A2.T9.2.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="A2.T9.2.7.7.3" class="ltx_td ltx_align_center">36.1</td>
<td id="A2.T9.2.7.7.4" class="ltx_td ltx_align_center">26.9</td>
<td id="A2.T9.2.7.7.5" class="ltx_td ltx_align_center">34.8</td>
<td id="A2.T9.2.7.7.6" class="ltx_td ltx_align_center">32.6</td>
</tr>
<tr id="A2.T9.2.8.8" class="ltx_tr">
<th id="A2.T9.2.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TFA w/cos</th>
<th id="A2.T9.2.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<td id="A2.T9.2.8.8.3" class="ltx_td ltx_align_center"><span id="A2.T9.2.8.8.3.1" class="ltx_text ltx_font_bold">44.7</span></td>
<td id="A2.T9.2.8.8.4" class="ltx_td ltx_align_center"><span id="A2.T9.2.8.8.4.1" class="ltx_text ltx_font_bold">34.1</span></td>
<td id="A2.T9.2.8.8.5" class="ltx_td ltx_align_center">42.8</td>
<td id="A2.T9.2.8.8.6" class="ltx_td ltx_align_center">40.5</td>
</tr>
<tr id="A2.T9.2.9.9" class="ltx_tr">
<th id="A2.T9.2.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">MF R-CNN</th>
<th id="A2.T9.2.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1</th>
<td id="A2.T9.2.9.9.3" class="ltx_td ltx_align_center">43.0</td>
<td id="A2.T9.2.9.9.4" class="ltx_td ltx_align_center">27.7</td>
<td id="A2.T9.2.9.9.5" class="ltx_td ltx_align_center">40.6</td>
<td id="A2.T9.2.9.9.6" class="ltx_td ltx_align_center">37.1</td>
</tr>
<tr id="A2.T9.2.10.10" class="ltx_tr">
<th id="A2.T9.2.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Ours</th>
<th id="A2.T9.2.10.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">0</th>
<td id="A2.T9.2.10.10.3" class="ltx_td ltx_align_center ltx_border_t">44.6</td>
<td id="A2.T9.2.10.10.4" class="ltx_td ltx_align_center ltx_border_t">30.7</td>
<td id="A2.T9.2.10.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T9.2.10.10.5.1" class="ltx_text ltx_font_bold">47.5</span></td>
<td id="A2.T9.2.10.10.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A2.T9.2.10.10.6.1" class="ltx_text ltx_font_bold">40.9</span></td>
</tr>
</tbody>
<tfoot class="ltx_tfoot">
<tr id="A2.T9.2.11.1" class="ltx_tr">
<th id="A2.T9.2.11.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t" colspan="6"><span id="A2.T9.2.11.1.1.1" class="ltx_text ltx_font_bold">Split1 Base(AP50): TFA (3-Shot)=79.1, Ours=80.8</span></th>
</tr>
</tfoot>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T9.3.1.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="A2.T9.4.2" class="ltx_text" style="font-size:90%;">Evaluation results on the novel categories of PASCAL VOC few-shot benchmark. MF R-CNN means Meta Faster R-CNN. Our model zero-shot performance on the novel match the TFA’s performance in its 3-shot setting. Our model also has a better performance on base.</span></figcaption>
</figure>
<figure id="A2.T10" class="ltx_table">
<table id="A2.T10.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T10.2.1.1" class="ltx_tr">
<th id="A2.T10.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Method</th>
<th id="A2.T10.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Shot</th>
<th id="A2.T10.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP</th>
<th id="A2.T10.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AP50</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T10.2.2.1" class="ltx_tr">
<th id="A2.T10.2.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">TFA w/fc</th>
<th id="A2.T10.2.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">10</th>
<td id="A2.T10.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t">10.0</td>
<td id="A2.T10.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t">19.2</td>
</tr>
<tr id="A2.T10.2.3.2" class="ltx_tr">
<th id="A2.T10.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">TFA w/cos</th>
<th id="A2.T10.2.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">10</th>
<td id="A2.T10.2.3.2.3" class="ltx_td ltx_align_center">10.0</td>
<td id="A2.T10.2.3.2.4" class="ltx_td ltx_align_center">19.1</td>
</tr>
<tr id="A2.T10.2.4.3" class="ltx_tr">
<th id="A2.T10.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">MF R-CNN</th>
<th id="A2.T10.2.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="A2.T10.2.4.3.3" class="ltx_td ltx_align_center">7.6</td>
<td id="A2.T10.2.4.3.4" class="ltx_td ltx_align_center">16.3</td>
</tr>
<tr id="A2.T10.2.5.4" class="ltx_tr">
<th id="A2.T10.2.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">Ours</th>
<th id="A2.T10.2.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">0</th>
<td id="A2.T10.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="A2.T10.2.5.4.3.1" class="ltx_text ltx_font_bold">11.0</span></td>
<td id="A2.T10.2.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="A2.T10.2.5.4.4.1" class="ltx_text ltx_font_bold">23.5</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T10.3.1.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="A2.T10.4.2" class="ltx_text" style="font-size:90%;">Evaluation results on novel categories of COCO few-shot benchmark. MF R-CNN means Meta Faster R-CNN. Our model zero-shot performance on the novel match the TFA’s performance in its 10-shot setting.</span></figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional Ablation Study</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Table <a href="#A3.T11" title="Table 11 ‣ Appendix C Additional Ablation Study ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> presents the experimental results on how the size of the bounding box (bbox) that we use to crop the instances in the COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> dataset affects the classification accuracy (ACC) of the unadapted CLIP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
For the large objects, the more accurate bbox provided the higher ACC CLIP can achieve. For the small objects, CLIP needs more background information to be correctly classified. In all settings, the average ACC over all three sizes of the bbox is still much lower than the classifier of the well-trained detector, indicating the domain gap between the training data of the CLIP and the detection dataset exists. We use the 1.2x GT bbox to crop the base GT instance since it has the highest average ACC.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">We provide an additional ablation study in Table <a href="#A3.T12" title="Table 12 ‣ Appendix C Additional Ablation Study ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. We train all models with the adapted CLIP features. For the models trained with 12 epochs, the performance on novel categories of the model trained with the RPN proposals is 5.8% lower than the one of the model trained with the CLIP proposals, though the former has slightly better performance on base categories. For the models trained with 36 epochs, two models (RPN proposal and CLIP proposal) has similar performance on base categories, and the model trained with the CLIP proposal features still have much better novel category performance. This indicates that the negative effect on model performance on base categories caused by the CLIP proposal is negligible and can be alleviated by a longer training schedule.
It also shows that the information of base categories provided by the distillation has redundancy, which may accelerate the model convergence on base, but may not improve the model performance.</p>
</div>
<figure id="A3.T11" class="ltx_table">
<table id="A3.T11.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T11.2.1.1" class="ltx_tr">
<th id="A3.T11.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="A3.T11.2.1.1.1.1" class="ltx_text">Bbox Size</span></th>
<th id="A3.T11.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">General</th>
</tr>
<tr id="A3.T11.2.2.2" class="ltx_tr">
<th id="A3.T11.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">L</th>
<th id="A3.T11.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">M</th>
<th id="A3.T11.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">S</th>
<th id="A3.T11.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Avg</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T11.2.3.1" class="ltx_tr">
<th id="A3.T11.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">0.8x GT</th>
<td id="A3.T11.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">62.3</td>
<td id="A3.T11.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">54.0</td>
<td id="A3.T11.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">23.2</td>
<td id="A3.T11.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">47.1</td>
</tr>
<tr id="A3.T11.2.4.2" class="ltx_tr">
<th id="A3.T11.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.0x GT</th>
<td id="A3.T11.2.4.2.2" class="ltx_td ltx_align_center"><span id="A3.T11.2.4.2.2.1" class="ltx_text ltx_font_bold">64.0</span></td>
<td id="A3.T11.2.4.2.3" class="ltx_td ltx_align_center">61.9</td>
<td id="A3.T11.2.4.2.4" class="ltx_td ltx_align_center">32.9</td>
<td id="A3.T11.2.4.2.5" class="ltx_td ltx_align_center">53.4</td>
</tr>
<tr id="A3.T11.2.5.3" class="ltx_tr">
<th id="A3.T11.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.2x GT</th>
<td id="A3.T11.2.5.3.2" class="ltx_td ltx_align_center">61.3</td>
<td id="A3.T11.2.5.3.3" class="ltx_td ltx_align_center"><span id="A3.T11.2.5.3.3.1" class="ltx_text ltx_font_bold">62.2</span></td>
<td id="A3.T11.2.5.3.4" class="ltx_td ltx_align_center">36.9</td>
<td id="A3.T11.2.5.3.5" class="ltx_td ltx_align_center"><span id="A3.T11.2.5.3.5.1" class="ltx_text ltx_font_bold">53.9</span></td>
</tr>
<tr id="A3.T11.2.6.4" class="ltx_tr">
<th id="A3.T11.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.5x GT</th>
<td id="A3.T11.2.6.4.2" class="ltx_td ltx_align_center">56.7</td>
<td id="A3.T11.2.6.4.3" class="ltx_td ltx_align_center">59.5</td>
<td id="A3.T11.2.6.4.4" class="ltx_td ltx_align_center">40.6</td>
<td id="A3.T11.2.6.4.5" class="ltx_td ltx_align_center">52.6</td>
</tr>
<tr id="A3.T11.2.7.5" class="ltx_tr">
<th id="A3.T11.2.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">2.0x GT</th>
<td id="A3.T11.2.7.5.2" class="ltx_td ltx_align_center ltx_border_b">50.5</td>
<td id="A3.T11.2.7.5.3" class="ltx_td ltx_align_center ltx_border_b">52.6</td>
<td id="A3.T11.2.7.5.4" class="ltx_td ltx_align_center ltx_border_b"><span id="A3.T11.2.7.5.4.1" class="ltx_text ltx_font_bold">42.9</span></td>
<td id="A3.T11.2.7.5.5" class="ltx_td ltx_align_center ltx_border_b">48.9</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A3.T11.3.1.1" class="ltx_text" style="font-size:90%;">Table 11</span>: </span><span id="A3.T11.4.2" class="ltx_text" style="font-size:90%;">The classification accuracy (ACC) of the unadapted CLIP on COCO instances with different sizes of the GT bboxes to crop the instances. We decide to use the 1.2x enlarged GT bbox to crop the instance since it has the best average ACC.</span></figcaption>
</figure>
<figure id="A3.T12" class="ltx_table">
<table id="A3.T12.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T12.2.1.1" class="ltx_tr">
<th id="A3.T12.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Epoch</th>
<th id="A3.T12.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Distill Region</th>
<th id="A3.T12.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Base</th>
<th id="A3.T12.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Novel</th>
<th id="A3.T12.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T12.2.2.1" class="ltx_tr">
<th id="A3.T12.2.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">12</th>
<th id="A3.T12.2.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">RPN Proposal</th>
<td id="A3.T12.2.2.1.3" class="ltx_td ltx_align_center ltx_border_t">56.9</td>
<td id="A3.T12.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t">24.6</td>
<td id="A3.T12.2.2.1.5" class="ltx_td ltx_align_center ltx_border_t">48.5</td>
</tr>
<tr id="A3.T12.2.3.2" class="ltx_tr">
<th id="A3.T12.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">12</th>
<th id="A3.T12.2.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">CLIP Proposal</th>
<td id="A3.T12.2.3.2.3" class="ltx_td ltx_align_center">55.7</td>
<td id="A3.T12.2.3.2.4" class="ltx_td ltx_align_center">30.4</td>
<td id="A3.T12.2.3.2.5" class="ltx_td ltx_align_center">49.0</td>
</tr>
<tr id="A3.T12.2.4.3" class="ltx_tr">
<th id="A3.T12.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">36</th>
<th id="A3.T12.2.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">RPN Proposal</th>
<td id="A3.T12.2.4.3.3" class="ltx_td ltx_align_center"><span id="A3.T12.2.4.3.3.1" class="ltx_text ltx_font_bold">60.2</span></td>
<td id="A3.T12.2.4.3.4" class="ltx_td ltx_align_center">24.3</td>
<td id="A3.T12.2.4.3.5" class="ltx_td ltx_align_center">50.8</td>
</tr>
<tr id="A3.T12.2.5.4" class="ltx_tr">
<th id="A3.T12.2.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">36</th>
<th id="A3.T12.2.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">CLIP Proposal</th>
<td id="A3.T12.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b">59.9</td>
<td id="A3.T12.2.5.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="A3.T12.2.5.4.4.1" class="ltx_text ltx_font_bold">31.6</span></td>
<td id="A3.T12.2.5.4.5" class="ltx_td ltx_align_center ltx_border_b"><span id="A3.T12.2.5.4.5.1" class="ltx_text ltx_font_bold">52.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A3.T12.3.1.1" class="ltx_text" style="font-size:90%;">Table 12</span>: </span><span id="A3.T12.4.2" class="ltx_text" style="font-size:90%;">Ablation study on using CLIP Proposals as distillation in COCO benchmark. The model trained with CLIP Proposals has much better performance on novel categories.</span></figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional Visualizations</h2>

<figure id="A4.F6" class="ltx_figure"><img src="/html/2303.12145/assets/x6.png" id="A4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="159" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="A4.F6.3.2" class="ltx_text" style="font-size:90%;">Visualization of using CLIP Proposals or RPN proposals as distillation regions in COCO setting. The blue boxes and green boxes represent the GT bboxes of the novel and base categories. The red boxes represent the CLIP proposals or the RPN proposals with the highest IoU with the novel GT bboxes. The visualization shows the CLIP proposals can cover more novel objects even though the box may not accurate.</span></figcaption>
</figure>
<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">Fig <a href="#A4.F6" title="Figure 6 ‣ Appendix D Additional Visualizations ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the visualization of using CLIP Proposals and RPN proposals as distillation regions in the COCO setting.
The blue boxes and green boxes represent the GT bboxes of the novel and base categories.
The red boxes represent the CLIP Proposals or the RPN proposals with the highest IoU with the novel GT bboxes.
The three images on the left show that the CLIP Proposals can cover most of the novel category objects although the boxes may not accurate, while the RPN regards some of the novel objects as background and just ignores them.
Although the CLIP proposals are not accurate, the features extracted from these boxes are accurate and meaningful.
This phenomenon is also proved by the experiments in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Therefore, using the CLIP Proposals as distillation regions provides more novel category information and improve the detector’s performance on the novel.</p>
</div>
<figure id="A4.F7" class="ltx_figure"><img src="/html/2303.12145/assets/x7.png" id="A4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A4.F7.3.2" class="ltx_text" style="font-size:90%;">The tSNE embeddings of the COCO GT instance feature from the unadapted CLIP and adapted CLIP. The GT features from the adapted CLIP form more dense clusters, indicating that the features become more discriminating and the CLIP is adapted into the detection dataset domain.</span></figcaption>
</figure>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p">Fig <a href="#A4.F7" title="Figure 7 ‣ Appendix D Additional Visualizations ‣ Efficient Feature Distillation for Zero-shot Annotation Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the tSNE embeddings of the COCO instance features of the unadapted CLIP and the adapted CLIP.
We collect 20 GT instances for each base and novel category in COCO setting and extract their features from unadapted CLIP or adapted CLIP, and then generate the tSNE embeddings with these features.
The GT instances in the adapted CLIP feature space form some dense clusters. This indicates that the CLIP’s feature space has been adapted in the COCO dataset domain and the features become more discriminating after adaptation, improving the classification accuracy.
The dots do not form a dense cluster mostly come from the ”person” category. Since the instances of the person usually show up with other categories instances and occluded by other objects, therefore the person categories features are more scattered.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.12144" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.12145" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.12145">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.12145" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.12146" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 19:10:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
