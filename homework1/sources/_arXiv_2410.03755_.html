<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Denoising with a Joint-Embedding Predictive Architecture</title>
<!--Generated on Wed Oct  2 05:55:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03755v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S1" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.SS0.SSS0.Px1" title="In 2 Background ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Joint-embedding predictive architectures (JEPAs).</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.SS0.SSS0.Px2" title="In 2 Background ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Diffusion models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.SS0.SSS0.Px3" title="In 2 Background ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Generalized next-token prediction.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS1" title="In 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Tokenization and Masking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS2" title="In 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Representation Learning with JEPAs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS3" title="In 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Diffusion Learning with a Denoising MLP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS4" title="In 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Training with D-JEPA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS5" title="In 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Sampling in Next Set-of-Tokens Prediction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1" title="In 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Image Synthetis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1.SSS0.Px1" title="In 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Quantitative analysis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1.SSS0.Px2" title="In 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Qualitative analysis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1.SSS0.Px3" title="In 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Scaling law of D-JEPA.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS2" title="In 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Comprehensive Experiments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S5" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A1" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A1.SS0.SSS0.Px1" title="In Appendix A Related Work ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Self-supervised learning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A1.SS0.SSS0.Px2" title="In Appendix A Related Work ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Generative modeling.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2.SS0.SSS0.Px1" title="In Appendix B Experimental Setup ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Network configuration.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2.SS0.SSS0.Px2" title="In Appendix B Experimental Setup ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Training.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2.SS0.SSS0.Px3" title="In Appendix B Experimental Setup ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Evaluation metrics.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Sampling with generalized next token prediction</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS1" title="In Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Grid searching for optimal classifier-free guidance scale and temperature</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS1.SSS0.Px1" title="In C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Coarse searching.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS1.SSS0.Px2" title="In C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Fine searching.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="In Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Abalation on auto-regressive steps</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2.SSS0.Px1" title="In C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Sampling efficiency.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Additional results on ImageNet</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS1" title="In Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>Full comparison on ImageNet</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS2" title="In Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>Training curve</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS3" title="In Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.3 </span>Inpainting and Outpainting</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>D-JEPA for representation learning</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS1" title="In Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Theoretical motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2" title="In Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Image classification</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px1" title="In E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Experiment settings.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px2" title="In E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Linear probing.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px3" title="In E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Fine-tuning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px4" title="In E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis on raw pixel space and semantic token space.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Flow Matching Loss</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.SS0.SSS0.Px1" title="In Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis of flow matching loss</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Comprehensive Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS1" title="In Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.1 </span>Text-to-Audio Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS1.SSS0.Px1" title="In G.1 Text-to-Audio Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS2" title="In Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.2 </span>Text-to-Image Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS2.SSS0.Px1" title="In G.2 Text-to-Image Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS3" title="In Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.3 </span>Class Conditioned Video Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS3.SSS0.Px1" title="In G.3 Class Conditioned Video Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS4" title="In Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.4 </span>Multi-Modal Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A8" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Limitations</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A8.SS0.SSS0.Px1" title="In Appendix H Limitations ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Potential performance bottleneck from denoising MLP.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A8.SS0.SSS0.Px2" title="In Appendix H Limitations ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Efficiency issues due to bi-directional attention.</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Denoising with a Joint-Embedding Predictive Architecture</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dengsheng Chen 
<br class="ltx_break"/>Meituan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">chendengsheng@meituan.com</span>
<br class="ltx_break"/>&amp;Jie Hu 
<br class="ltx_break"/>Meituan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">hujie39@meituan.com</span>
<br class="ltx_break"/>&amp;Xiaoming Wei 
<br class="ltx_break"/>Meituan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">weixiaoming@meituan.com</span>
<br class="ltx_break"/>&amp;Enhua Wu
<br class="ltx_break"/>SKLCS, Institute of Software, Chinese Academy of Sciences
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id4">weh@ios.ac.cn</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Joint-embedding predictive architectures (JEPAs) have shown substantial promise in self-supervised representation learning, yet their application in generative modeling remains underexplored. Conversely, diffusion models have demonstrated significant efficacy in modeling arbitrary probability distributions. In this paper, we introduce Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), pioneering the integration of JEPA within generative modeling. By recognizing JEPA as a form of masked image modeling, we reinterpret it as a generalized next-token prediction strategy, facilitating data generation in an auto-regressive manner. Furthermore, we incorporate diffusion loss to model the per-token probability distribution, enabling data generation in a continuous space. We also adapt flow matching loss as an alternative to diffusion loss, thereby enhancing the flexibility of D-JEPA. Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability. Our base, large, and huge models outperform all previous generative models across all scales on class-conditional ImageNet benchmarks. Beyond image generation, D-JEPA is well-suited for other continuous data modeling, including video and audio.</p>
<p class="ltx_p" id="id6.id2">Project page: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://d-jepa.github.io/" title="">https://d-jepa.github.io/</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The extraordinary success of generative language models <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib83" title="">2018</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib84" title="">2019</a>; Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib14" title="">2020</a>)</cite>, which excel in next-token prediction, has spurred efforts to adapt autoregressive models for other domains, notably image generation <cite class="ltx_cite ltx_citemacro_citep">(Kilian et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib56" title="">2024</a>; Zeng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib122" title="">2021</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>; Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib31" title="">2021</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>. Typically, this involves discretizing visual data into token sequences <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib108" title="">2017</a>)</cite>, a process that can sometimes degrade image quality. Despite this, the technique has gained substantial interest due to its powerful capabilities  <cite class="ltx_cite ltx_citemacro_citep">(Razavi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib88" title="">2019</a>; Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib82" title="">2021</a>; Yan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib113" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recently, diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>; Song et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib95" title="">2020</a>; Nichol &amp; Dhariwal, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib75" title="">2021</a>)</cite> have emerged as a dominant force in generative modeling, surpassing generative adversarial networks (GANs) <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib36" title="">2014</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib109" title="">2017</a>; Goodfellow et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib35" title="">2020</a>)</cite> with their superior performance in producing high-fidelity images. Concurrently, significant advancements have been made in self-supervised representation learning, particularly through masked image modeling <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib112" title="">2022</a>; Baevski et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>; Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>; He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> and invariance-based techniques <cite class="ltx_cite ltx_citemacro_citep">(Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib3" title="">2022</a>; Caron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib15" title="">2021</a>; Chen &amp; He, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib22" title="">2021</a>; Grill et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>; Zbontar et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib121" title="">2021</a>)</cite>. However, generative modeling and representation learning development has largely progressed in isolation, with limited cross-fertilization <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recent efforts have sought to integrate diffusion models within an autoregressive framework, such as MAR <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> and Transfusion <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite>. These models, however, primarily focus on enhancing generative model performance from the perspective of generation alone, often overlooking advancements in representation learning. Conversely, within the realm of representation learning, researchers tend to emphasize model performance on downstream tasks  <cite class="ltx_cite ltx_citemacro_citep">(Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, neglecting the potential for these models to excel in generative modeling.
To bridge this gap, we propose a novel framework, termed “Denoising with a Joint-Embedding Predictive Architecture” (D-JEPA), that effectively leverages next-token prediction from a representation learning perspective. Specifically, we adopt the joint-embedding predictive architecture as the core of our design, enabling us to reframe masked image modeling methods into a generalized next-token prediction strategy, thus facilitating autoregressive data generation. Additionally, we incorporate a diffusion loss (or flow matching loss) to model the per-token probability distribution, allowing for data generation in a continuous space.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.12">Specifically, D-JEPA consists of three identical visual transformer backbones <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>: a context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><mi id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.1d">italic_ϕ</annotation></semantics></math>, a target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S1.p4.2.m2.1"><semantics id="S1.p4.2.m2.1a"><mover accent="true" id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml">ϕ</mi><mo id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><ci id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1">¯</ci><ci id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.2.m2.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math>, and a feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S1.p4.3.m3.1"><semantics id="S1.p4.3.m3.1a"><mi id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><ci id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S1.p4.3.m3.1d">italic_γ</annotation></semantics></math>. It employs two loss functions: diffusion loss (<math alttext="\mathcal{L}_{d}" class="ltx_Math" display="inline" id="S1.p4.4.m4.1"><semantics id="S1.p4.4.m4.1a"><msub id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.p4.4.m4.1.1.2" xref="S1.p4.4.m4.1.1.2.cmml">ℒ</mi><mi id="S1.p4.4.m4.1.1.3" xref="S1.p4.4.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.1b"><apply id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S1.p4.4.m4.1.1.1.cmml" xref="S1.p4.4.m4.1.1">subscript</csymbol><ci id="S1.p4.4.m4.1.1.2.cmml" xref="S1.p4.4.m4.1.1.2">ℒ</ci><ci id="S1.p4.4.m4.1.1.3.cmml" xref="S1.p4.4.m4.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">\mathcal{L}_{d}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>) and prediction loss (<math alttext="\mathcal{L}_{p}" class="ltx_Math" display="inline" id="S1.p4.5.m5.1"><semantics id="S1.p4.5.m5.1a"><msub id="S1.p4.5.m5.1.1" xref="S1.p4.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.p4.5.m5.1.1.2" xref="S1.p4.5.m5.1.1.2.cmml">ℒ</mi><mi id="S1.p4.5.m5.1.1.3" xref="S1.p4.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.1b"><apply id="S1.p4.5.m5.1.1.cmml" xref="S1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S1.p4.5.m5.1.1.1.cmml" xref="S1.p4.5.m5.1.1">subscript</csymbol><ci id="S1.p4.5.m5.1.1.2.cmml" xref="S1.p4.5.m5.1.1.2">ℒ</ci><ci id="S1.p4.5.m5.1.1.3.cmml" xref="S1.p4.5.m5.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m5.1c">\mathcal{L}_{p}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.5.m5.1d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>), both involving a multi-layer perceptron (MLP) network. The denoising MLP, used in diffusion loss, is applied to each masked token <math alttext="x_{i}" class="ltx_Math" display="inline" id="S1.p4.6.m6.1"><semantics id="S1.p4.6.m6.1a"><msub id="S1.p4.6.m6.1.1" xref="S1.p4.6.m6.1.1.cmml"><mi id="S1.p4.6.m6.1.1.2" xref="S1.p4.6.m6.1.1.2.cmml">x</mi><mi id="S1.p4.6.m6.1.1.3" xref="S1.p4.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.6.m6.1b"><apply id="S1.p4.6.m6.1.1.cmml" xref="S1.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S1.p4.6.m6.1.1.1.cmml" xref="S1.p4.6.m6.1.1">subscript</csymbol><ci id="S1.p4.6.m6.1.1.2.cmml" xref="S1.p4.6.m6.1.1.2">𝑥</ci><ci id="S1.p4.6.m6.1.1.3.cmml" xref="S1.p4.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.6.m6.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.6.m6.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, modeling the conditional probability distribution <math alttext="p(x_{i}\mid z_{i})" class="ltx_Math" display="inline" id="S1.p4.7.m7.1"><semantics id="S1.p4.7.m7.1a"><mrow id="S1.p4.7.m7.1.1" xref="S1.p4.7.m7.1.1.cmml"><mi id="S1.p4.7.m7.1.1.3" xref="S1.p4.7.m7.1.1.3.cmml">p</mi><mo id="S1.p4.7.m7.1.1.2" xref="S1.p4.7.m7.1.1.2.cmml">⁢</mo><mrow id="S1.p4.7.m7.1.1.1.1" xref="S1.p4.7.m7.1.1.1.1.1.cmml"><mo id="S1.p4.7.m7.1.1.1.1.2" stretchy="false" xref="S1.p4.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S1.p4.7.m7.1.1.1.1.1" xref="S1.p4.7.m7.1.1.1.1.1.cmml"><msub id="S1.p4.7.m7.1.1.1.1.1.2" xref="S1.p4.7.m7.1.1.1.1.1.2.cmml"><mi id="S1.p4.7.m7.1.1.1.1.1.2.2" xref="S1.p4.7.m7.1.1.1.1.1.2.2.cmml">x</mi><mi id="S1.p4.7.m7.1.1.1.1.1.2.3" xref="S1.p4.7.m7.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S1.p4.7.m7.1.1.1.1.1.1" xref="S1.p4.7.m7.1.1.1.1.1.1.cmml">∣</mo><msub id="S1.p4.7.m7.1.1.1.1.1.3" xref="S1.p4.7.m7.1.1.1.1.1.3.cmml"><mi id="S1.p4.7.m7.1.1.1.1.1.3.2" xref="S1.p4.7.m7.1.1.1.1.1.3.2.cmml">z</mi><mi id="S1.p4.7.m7.1.1.1.1.1.3.3" xref="S1.p4.7.m7.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S1.p4.7.m7.1.1.1.1.3" stretchy="false" xref="S1.p4.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.7.m7.1b"><apply id="S1.p4.7.m7.1.1.cmml" xref="S1.p4.7.m7.1.1"><times id="S1.p4.7.m7.1.1.2.cmml" xref="S1.p4.7.m7.1.1.2"></times><ci id="S1.p4.7.m7.1.1.3.cmml" xref="S1.p4.7.m7.1.1.3">𝑝</ci><apply id="S1.p4.7.m7.1.1.1.1.1.cmml" xref="S1.p4.7.m7.1.1.1.1"><csymbol cd="latexml" id="S1.p4.7.m7.1.1.1.1.1.1.cmml" xref="S1.p4.7.m7.1.1.1.1.1.1">conditional</csymbol><apply id="S1.p4.7.m7.1.1.1.1.1.2.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S1.p4.7.m7.1.1.1.1.1.2.1.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2">subscript</csymbol><ci id="S1.p4.7.m7.1.1.1.1.1.2.2.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2.2">𝑥</ci><ci id="S1.p4.7.m7.1.1.1.1.1.2.3.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S1.p4.7.m7.1.1.1.1.1.3.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S1.p4.7.m7.1.1.1.1.1.3.1.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3">subscript</csymbol><ci id="S1.p4.7.m7.1.1.1.1.1.3.2.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3.2">𝑧</ci><ci id="S1.p4.7.m7.1.1.1.1.1.3.3.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.7.m7.1c">p(x_{i}\mid z_{i})</annotation><annotation encoding="application/x-llamapun" id="S1.p4.7.m7.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∣ italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> and evaluating the predicted latent variable <math alttext="z_{i}" class="ltx_Math" display="inline" id="S1.p4.8.m8.1"><semantics id="S1.p4.8.m8.1a"><msub id="S1.p4.8.m8.1.1" xref="S1.p4.8.m8.1.1.cmml"><mi id="S1.p4.8.m8.1.1.2" xref="S1.p4.8.m8.1.1.2.cmml">z</mi><mi id="S1.p4.8.m8.1.1.3" xref="S1.p4.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.8.m8.1b"><apply id="S1.p4.8.m8.1.1.cmml" xref="S1.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S1.p4.8.m8.1.1.1.cmml" xref="S1.p4.8.m8.1.1">subscript</csymbol><ci id="S1.p4.8.m8.1.1.2.cmml" xref="S1.p4.8.m8.1.1.2">𝑧</ci><ci id="S1.p4.8.m8.1.1.3.cmml" xref="S1.p4.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.8.m8.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.8.m8.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> generated by the feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S1.p4.9.m9.1"><semantics id="S1.p4.9.m9.1a"><mi id="S1.p4.9.m9.1.1" xref="S1.p4.9.m9.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S1.p4.9.m9.1b"><ci id="S1.p4.9.m9.1.1.cmml" xref="S1.p4.9.m9.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.9.m9.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S1.p4.9.m9.1d">italic_γ</annotation></semantics></math>. The prediction loss (<math alttext="\mathcal{L}_{p}" class="ltx_Math" display="inline" id="S1.p4.10.m10.1"><semantics id="S1.p4.10.m10.1a"><msub id="S1.p4.10.m10.1.1" xref="S1.p4.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.p4.10.m10.1.1.2" xref="S1.p4.10.m10.1.1.2.cmml">ℒ</mi><mi id="S1.p4.10.m10.1.1.3" xref="S1.p4.10.m10.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.10.m10.1b"><apply id="S1.p4.10.m10.1.1.cmml" xref="S1.p4.10.m10.1.1"><csymbol cd="ambiguous" id="S1.p4.10.m10.1.1.1.cmml" xref="S1.p4.10.m10.1.1">subscript</csymbol><ci id="S1.p4.10.m10.1.1.2.cmml" xref="S1.p4.10.m10.1.1.2">ℒ</ci><ci id="S1.p4.10.m10.1.1.3.cmml" xref="S1.p4.10.m10.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.10.m10.1c">\mathcal{L}_{p}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.10.m10.1d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>), using a smooth loss function <math alttext="l_{1}" class="ltx_Math" display="inline" id="S1.p4.11.m11.1"><semantics id="S1.p4.11.m11.1a"><msub id="S1.p4.11.m11.1.1" xref="S1.p4.11.m11.1.1.cmml"><mi id="S1.p4.11.m11.1.1.2" xref="S1.p4.11.m11.1.1.2.cmml">l</mi><mn id="S1.p4.11.m11.1.1.3" xref="S1.p4.11.m11.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S1.p4.11.m11.1b"><apply id="S1.p4.11.m11.1.1.cmml" xref="S1.p4.11.m11.1.1"><csymbol cd="ambiguous" id="S1.p4.11.m11.1.1.1.cmml" xref="S1.p4.11.m11.1.1">subscript</csymbol><ci id="S1.p4.11.m11.1.1.2.cmml" xref="S1.p4.11.m11.1.1.2">𝑙</ci><cn id="S1.p4.11.m11.1.1.3.cmml" type="integer" xref="S1.p4.11.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.11.m11.1c">l_{1}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.11.m11.1d">italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, facilitates the latent variables <math alttext="z_{i}" class="ltx_Math" display="inline" id="S1.p4.12.m12.1"><semantics id="S1.p4.12.m12.1a"><msub id="S1.p4.12.m12.1.1" xref="S1.p4.12.m12.1.1.cmml"><mi id="S1.p4.12.m12.1.1.2" xref="S1.p4.12.m12.1.1.2.cmml">z</mi><mi id="S1.p4.12.m12.1.1.3" xref="S1.p4.12.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.12.m12.1b"><apply id="S1.p4.12.m12.1.1.cmml" xref="S1.p4.12.m12.1.1"><csymbol cd="ambiguous" id="S1.p4.12.m12.1.1.1.cmml" xref="S1.p4.12.m12.1.1">subscript</csymbol><ci id="S1.p4.12.m12.1.1.2.cmml" xref="S1.p4.12.m12.1.1.2">𝑧</ci><ci id="S1.p4.12.m12.1.1.3.cmml" xref="S1.p4.12.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.12.m12.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.12.m12.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to capture high-level semantic information.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Empirically, D-JEPA exhibits a consistent decrease in FID scores as GFLOPs increase, achieving these results with fewer training epochs, indicating its good scalability. Our base, large, and huge variants outperform all previously generative models across different scales on class-conditional ImageNet benchmarks. In our comprehensive experiments, we further advanced the field of generative models by substituting the diffusion loss with flow matching loss <cite class="ltx_cite ltx_citemacro_citep">(Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>. This substitution enables D-JEPA to excel in image generation and modeling other types of continuous data, including video and audio. Moreover, D-JEPA exhibits remarkable flexibility, extending seamlessly to text-conditioned and multi-modal generations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our contributions are threefold. <span class="ltx_text ltx_font_italic" id="S1.p6.1.1">Firstly</span>, we successfully integrate advancements in representation learning into generative modeling, achieving state-of-the-art performance on the ImageNet benchmark. <span class="ltx_text ltx_font_italic" id="S1.p6.1.2">Secondly</span>, we validate the effectiveness of the generalized next-token prediction approach in generative modeling, demonstrating superior scalability, which establishes a robust foundation for developing more powerful text-conditioned models. <span class="ltx_text ltx_font_italic" id="S1.p6.1.3">Lastly</span>, D-JEPA exhibits impressive extensibility, directly applicable to generate images, videos, audio, and more, providing theoretical support for constructing unified multi-modal models.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="239" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data flow during D-JEPA training. Initially, the training data is divided into non-overlapping semantic tokens, which can be either in the raw space or in the latent space obtained after VAE encoding. A random subset of these input tokens is then masked. The feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S2.F1.4.m1.1"><semantics id="S2.F1.4.m1.1b"><mi id="S2.F1.4.m1.1.1" xref="S2.F1.4.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S2.F1.4.m1.1c"><ci id="S2.F1.4.m1.1.1.cmml" xref="S2.F1.4.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.4.m1.1d">\gamma</annotation><annotation encoding="application/x-llamapun" id="S2.F1.4.m1.1e">italic_γ</annotation></semantics></math> is employed to predict features for these masked tokens, utilizing the unmasked tokens as contextual information. Each masked token is concurrently subjected to a diffusion loss (or flow matching loss) to learn the distribution of each token <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S2.F1.5.m2.1"><semantics id="S2.F1.5.m2.1b"><mrow id="S2.F1.5.m2.1.1" xref="S2.F1.5.m2.1.1.cmml"><mi id="S2.F1.5.m2.1.1.3" xref="S2.F1.5.m2.1.1.3.cmml">p</mi><mo id="S2.F1.5.m2.1.1.2" xref="S2.F1.5.m2.1.1.2.cmml">⁢</mo><mrow id="S2.F1.5.m2.1.1.1.1" xref="S2.F1.5.m2.1.1.1.1.1.cmml"><mo id="S2.F1.5.m2.1.1.1.1.2" stretchy="false" xref="S2.F1.5.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.F1.5.m2.1.1.1.1.1" xref="S2.F1.5.m2.1.1.1.1.1.cmml"><msub id="S2.F1.5.m2.1.1.1.1.1.2" xref="S2.F1.5.m2.1.1.1.1.1.2.cmml"><mi id="S2.F1.5.m2.1.1.1.1.1.2.2" xref="S2.F1.5.m2.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.F1.5.m2.1.1.1.1.1.2.3" xref="S2.F1.5.m2.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.F1.5.m2.1.1.1.1.1.1" xref="S2.F1.5.m2.1.1.1.1.1.1.cmml">|</mo><msub id="S2.F1.5.m2.1.1.1.1.1.3" xref="S2.F1.5.m2.1.1.1.1.1.3.cmml"><mi id="S2.F1.5.m2.1.1.1.1.1.3.2" xref="S2.F1.5.m2.1.1.1.1.1.3.2.cmml">z</mi><mi id="S2.F1.5.m2.1.1.1.1.1.3.3" xref="S2.F1.5.m2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.F1.5.m2.1.1.1.1.3" stretchy="false" xref="S2.F1.5.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.5.m2.1c"><apply id="S2.F1.5.m2.1.1.cmml" xref="S2.F1.5.m2.1.1"><times id="S2.F1.5.m2.1.1.2.cmml" xref="S2.F1.5.m2.1.1.2"></times><ci id="S2.F1.5.m2.1.1.3.cmml" xref="S2.F1.5.m2.1.1.3">𝑝</ci><apply id="S2.F1.5.m2.1.1.1.1.1.cmml" xref="S2.F1.5.m2.1.1.1.1"><csymbol cd="latexml" id="S2.F1.5.m2.1.1.1.1.1.1.cmml" xref="S2.F1.5.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S2.F1.5.m2.1.1.1.1.1.2.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.F1.5.m2.1.1.1.1.1.2.1.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.F1.5.m2.1.1.1.1.1.2.2.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.F1.5.m2.1.1.1.1.1.2.3.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.F1.5.m2.1.1.1.1.1.3.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.F1.5.m2.1.1.1.1.1.3.1.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.F1.5.m2.1.1.1.1.1.3.2.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3.2">𝑧</ci><ci id="S2.F1.5.m2.1.1.1.1.1.3.3.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.5.m2.1d">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.F1.5.m2.1e">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, independently. Additionally, a prediction loss is applied, compelling each masked token to regress towards the target tokens <math alttext="g_{i}" class="ltx_Math" display="inline" id="S2.F1.6.m3.1"><semantics id="S2.F1.6.m3.1b"><msub id="S2.F1.6.m3.1.1" xref="S2.F1.6.m3.1.1.cmml"><mi id="S2.F1.6.m3.1.1.2" xref="S2.F1.6.m3.1.1.2.cmml">g</mi><mi id="S2.F1.6.m3.1.1.3" xref="S2.F1.6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F1.6.m3.1c"><apply id="S2.F1.6.m3.1.1.cmml" xref="S2.F1.6.m3.1.1"><csymbol cd="ambiguous" id="S2.F1.6.m3.1.1.1.cmml" xref="S2.F1.6.m3.1.1">subscript</csymbol><ci id="S2.F1.6.m3.1.1.2.cmml" xref="S2.F1.6.m3.1.1.2">𝑔</ci><ci id="S2.F1.6.m3.1.1.3.cmml" xref="S2.F1.6.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.6.m3.1d">g_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.F1.6.m3.1e">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">D-JEPA is grounded in the principles of joint-embedding predictive architectures (JEPAs) and diffusion models. We provide an overview of these methodologies alongside a generalized next-token prediction strategy to facilitate an understanding of our approach.</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Joint-embedding predictive architectures (JEPAs).</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Self-supervised learning has transformed representation learning by enabling systems to uncover autonomously and model relationships within their inputs <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib63" title="">2006</a>)</cite>. Among these methods, joint-embedding predictive architectures (JEPAs)<cite class="ltx_cite ltx_citemacro_citep">(LeCun, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>; Bardes et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib11" title="">b</a>; Guetschel et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib39" title="">2024</a>)</cite> have gained prominence. JEPAs are designed to predict the embeddings of a target signal using a context signal processed through a predictor network, which is conditioned on an additional (potentially latent) variable, such as class labels.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.2">A significant challenge in deploying JEPAs is representation collapse, which occurs when the energy landscape flattens, causing the encoder to produce uniform outputs regardless of the inputs. This uniformity negates the advantages of learned representations <cite class="ltx_cite ltx_citemacro_citep">(Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>. Various strategies have been proposed to address this issue. Contrastive losses <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib42" title="">2019</a>; Chen &amp; He, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib22" title="">2021</a>)</cite> work by explicitly separating the embeddings of negative samples. Non-contrastive losses <cite class="ltx_cite ltx_citemacro_citep">(Zbontar et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib121" title="">2021</a>; Bardes et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib9" title="">2021</a>)</cite> aims to reduce redundancies between embeddings, thereby improving robustness. Clustering-based methods <cite class="ltx_cite ltx_citemacro_citep">(Caron et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib15" title="">2021</a>; Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib2" title="">2021</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib3" title="">2022</a>)</cite> increase the entropy of the aggregate embedding to maintain diversity. Additionally, heuristic approaches <cite class="ltx_cite ltx_citemacro_citep">(Chen &amp; He, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib22" title="">2021</a>; Grill et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>; Baevski et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>; Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite> often utilize asymmetric architectural designs between the context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.p2.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.1.m1.1d">italic_ϕ</annotation></semantics></math> and the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.p2.2.m2.1a"><mover accent="true" id="S2.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2.cmml">ϕ</mi><mo id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.2.m2.1b"><apply id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1"><ci id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1">¯</ci><ci id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.2.m2.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.2.m2.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math> to prevent collapse.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p3.1">However, the issue of representation collapse is effectively mitigated in D-JEPA due to the introduction of an additional diffusion loss for the predicted embeddings. The diffusion loss does not reside in the same energy landscape as JEPAs, thus effectively avoiding model collapse. Consequently, similar to the approach in <cite class="ltx_cite ltx_citemacro_cite">LeCun (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>)</cite>, we can employ two identical networks as the context and target encoders. The parameters of the target encoder are efficiently updated through an exponential moving average method, significantly enhancing training efficiency and reducing the number of parameters that need to be learned. Refer to Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS2" title="3.2 Representation Learning with JEPAs ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.2</span></a> for more details.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Diffusion models.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.9">Denoising diffusion models provide a robust framework for modeling arbitrary distributions <cite class="ltx_cite ltx_citemacro_citep">(Croitoru et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib25" title="">2023</a>)</cite>. Given a ground truth sample <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.1.m1.1d">italic_x</annotation></semantics></math> conditioned on a variable <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S2.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.2.m2.1d">italic_z</annotation></semantics></math>, the objective is to model the conditional probability distribution <math alttext="p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1"><times id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3">𝑝</ci><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3">𝑧</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.1c">p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.3.m3.1d">italic_p ( italic_x | italic_z )</annotation></semantics></math>. The sample <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="S2.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.4.m4.1d">italic_x</annotation></semantics></math> could represent various domains, such as images in pixel space, features in latent space, or control signals in robotic systems <cite class="ltx_cite ltx_citemacro_citep">(Chi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib24" title="">2023</a>; Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib102" title="">2024</a>)</cite>. In our case, <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.5.m5.1"><semantics id="S2.SS0.SSS0.Px2.p1.5.m5.1a"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.5.m5.1b"><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.5.m5.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.5.m5.1d">italic_x</annotation></semantics></math> represents a token, while <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.6.m6.1"><semantics id="S2.SS0.SSS0.Px2.p1.6.m6.1a"><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.6.m6.1b"><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.6.m6.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.6.m6.1d">italic_z</annotation></semantics></math> contains information to aid in reconstructing <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.7.m7.1"><semantics id="S2.SS0.SSS0.Px2.p1.7.m7.1a"><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.7.m7.1b"><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.7.m7.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.7.m7.1d">italic_x</annotation></semantics></math>; here, <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.8.m8.1"><semantics id="S2.SS0.SSS0.Px2.p1.8.m8.1a"><mi id="S2.SS0.SSS0.Px2.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.8.m8.1b"><ci id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.8.m8.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.8.m8.1d">italic_z</annotation></semantics></math> corresponds to the predicted embeddings by feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.9.m9.1"><semantics id="S2.SS0.SSS0.Px2.p1.9.m9.1a"><mi id="S2.SS0.SSS0.Px2.p1.9.m9.1.1" xref="S2.SS0.SSS0.Px2.p1.9.m9.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.9.m9.1b"><ci id="S2.SS0.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.9.m9.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.9.m9.1d">italic_γ</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">Following the formulation presented in <cite class="ltx_cite ltx_citemacro_cite">Dhariwal &amp; Nichol (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>, we define the loss function for modeling the underlying probability distribution <math alttext="p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1"><times id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3">𝑝</ci><apply id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3">𝑧</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p2.1.m1.1c">p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p2.1.m1.1d">italic_p ( italic_x | italic_z )</annotation></semantics></math> using a denoising criterion:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}(z,x)=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-%
\varepsilon_{\theta}(x^{t}|t,z)\right\|^{2}\right]," class="ltx_math_unparsed" display="block" id="S2.E1.m1.6"><semantics id="S2.E1.m1.6a"><mrow id="S2.E1.m1.6b"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.6.7">ℒ</mi><mrow id="S2.E1.m1.6.8"><mo id="S2.E1.m1.6.8.1" stretchy="false">(</mo><mi id="S2.E1.m1.3.3">z</mi><mo id="S2.E1.m1.6.8.2">,</mo><mi id="S2.E1.m1.4.4">x</mi><mo id="S2.E1.m1.6.8.3" stretchy="false">)</mo></mrow><mo id="S2.E1.m1.6.9">=</mo><msub id="S2.E1.m1.6.10"><mi id="S2.E1.m1.6.10.2">𝔼</mi><mrow id="S2.E1.m1.2.2.2.4"><mi id="S2.E1.m1.1.1.1.1">ε</mi><mo id="S2.E1.m1.2.2.2.4.1">,</mo><mi id="S2.E1.m1.2.2.2.2">t</mi></mrow></msub><mrow id="S2.E1.m1.6.11"><mo id="S2.E1.m1.6.11.1">[</mo><mo id="S2.E1.m1.6.11.2" lspace="0em" rspace="0.167em" stretchy="true">∥</mo><mi id="S2.E1.m1.6.11.3">ε</mi><mo id="S2.E1.m1.6.11.4">−</mo><msub id="S2.E1.m1.6.11.5"><mi id="S2.E1.m1.6.11.5.2">ε</mi><mi id="S2.E1.m1.6.11.5.3">θ</mi></msub><mrow id="S2.E1.m1.6.11.6"><mo id="S2.E1.m1.6.11.6.1" stretchy="false">(</mo><msup id="S2.E1.m1.6.11.6.2"><mi id="S2.E1.m1.6.11.6.2.2">x</mi><mi id="S2.E1.m1.6.11.6.2.3">t</mi></msup><mo fence="false" id="S2.E1.m1.6.11.6.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.E1.m1.5.5">t</mi><mo id="S2.E1.m1.6.11.6.4">,</mo><mi id="S2.E1.m1.6.6">z</mi><mo id="S2.E1.m1.6.11.6.5" stretchy="false">)</mo></mrow><msup id="S2.E1.m1.6.11.7"><mo id="S2.E1.m1.6.11.7.2" lspace="0em" rspace="0.167em" stretchy="true">∥</mo><mn id="S2.E1.m1.6.11.7.3">2</mn></msup><mo id="S2.E1.m1.6.11.8">]</mo></mrow><mo id="S2.E1.m1.6.12">,</mo></mrow><annotation encoding="application/x-tex" id="S2.E1.m1.6c">\mathcal{L}(z,x)=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-%
\varepsilon_{\theta}(x^{t}|t,z)\right\|^{2}\right],</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.6d">caligraphic_L ( italic_z , italic_x ) = blackboard_E start_POSTSUBSCRIPT italic_ε , italic_t end_POSTSUBSCRIPT [ ∥ italic_ε - italic_ε start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT | italic_t , italic_z ) ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p3.12">where <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p3.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p3.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p3.1.m1.1.1.cmml">ε</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.1.m1.1.1">𝜀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.1.m1.1d">italic_ε</annotation></semantics></math> represents a noise sample from the normal distribution <math alttext="\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.2.m2.2"><semantics id="S2.SS0.SSS0.Px2.p3.2.m2.2a"><mrow id="S2.SS0.SSS0.Px2.p3.2.m2.2.3" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2.cmml">𝒩</mi><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml">(</mo><mn id="S2.SS0.SSS0.Px2.p3.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p3.2.m2.1.1.cmml">𝟎</mn><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px2.p3.2.m2.2.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.2.cmml">𝐈</mi><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.2.m2.2b"><apply id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3"><times id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1"></times><ci id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2">𝒩</ci><interval closure="open" id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2"><cn id="S2.SS0.SSS0.Px2.p3.2.m2.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p3.2.m2.1.1">0</cn><ci id="S2.SS0.SSS0.Px2.p3.2.m2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.2">𝐈</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.2.m2.2c">\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.2.m2.2d">caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math>. The noise-corrupted sample <math alttext="x^{t}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.3.m3.1"><semantics id="S2.SS0.SSS0.Px2.p3.3.m3.1a"><msup id="S2.SS0.SSS0.Px2.p3.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.3.m3.1b"><apply id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.3.m3.1c">x^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.3.m3.1d">italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> is expressed as <math alttext="x^{t}=\sqrt{\bar{\alpha}_{t}}x+\sqrt{1-\bar{\alpha}_{t}}\varepsilon" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.4.m4.1"><semantics id="S2.SS0.SSS0.Px2.p3.4.m4.1a"><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.cmml"><msup id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3.cmml">t</mi></msup><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1.cmml">=</mo><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.cmml"><msqrt id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.cmml"><msub id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.cmml"><mover accent="true" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2.cmml">α</mi><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1.cmml">¯</mo></mover><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3.cmml">t</mi></msub></msqrt><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1.cmml">⁢</mo><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3.cmml">x</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1.cmml">+</mo><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.cmml"><msqrt id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.cmml"><mn id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2.cmml">1</mn><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1.cmml">−</mo><msub id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2.cmml">α</mi><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1.cmml">¯</mo></mover><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1.cmml">⁢</mo><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3.cmml">ε</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.4.m4.1b"><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1"><eq id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1"></eq><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3">𝑡</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3"><plus id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1"></plus><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2"><times id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1"></times><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2"><root id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2a.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2"></root><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2"><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1">¯</ci><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2">𝛼</ci></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3">𝑡</ci></apply></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3">𝑥</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3"><times id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1"></times><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2"><root id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2a.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2"></root><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2"><minus id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1"></minus><cn id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2">1</cn><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2"><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1">¯</ci><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2">𝛼</ci></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3">𝑡</ci></apply></apply></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3">𝜀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.4.m4.1c">x^{t}=\sqrt{\bar{\alpha}_{t}}x+\sqrt{1-\bar{\alpha}_{t}}\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.4.m4.1d">italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = square-root start_ARG over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_x + square-root start_ARG 1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_ε</annotation></semantics></math>, with <math alttext="\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.5.m5.1"><semantics id="S2.SS0.SSS0.Px2.p3.5.m5.1a"><msub id="S2.SS0.SSS0.Px2.p3.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.cmml"><mover accent="true" id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2.cmml">α</mi><mo id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1.cmml">¯</mo></mover><mi id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.5.m5.1b"><apply id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2"><ci id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1">¯</ci><ci id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2">𝛼</ci></apply><ci id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.5.m5.1c">\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.5.m5.1d">over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> defining a noise schedule <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>; Nichol &amp; Dhariwal, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib75" title="">2021</a>)</cite> and <math alttext="t" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.6.m6.1"><semantics id="S2.SS0.SSS0.Px2.p3.6.m6.1a"><mi id="S2.SS0.SSS0.Px2.p3.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.6.m6.1b"><ci id="S2.SS0.SSS0.Px2.p3.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.6.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.6.m6.1d">italic_t</annotation></semantics></math> indicating a specific time step within this schedule. The function <math alttext="\varepsilon_{\theta}(x^{t}|t,z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.7.m7.3"><semantics id="S2.SS0.SSS0.Px2.p3.7.m7.3a"><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.cmml"><msub id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.cmml"><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2.cmml">ε</mi><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3.cmml">θ</mi></msub><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml"><msup id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3.cmml">t</mi></msup><mo fence="false" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.1.1.cmml">t</mi><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.2.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px2.p3.7.m7.2.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.2.2.cmml">z</mi></mrow></mrow><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.7.m7.3b"><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3"><times id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2"></times><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2">𝜀</ci><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3">𝜃</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1">conditional</csymbol><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3">𝑡</ci></apply><list id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.2"><ci id="S2.SS0.SSS0.Px2.p3.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.1.1">𝑡</ci><ci id="S2.SS0.SSS0.Px2.p3.7.m7.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.2.2">𝑧</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.7.m7.3c">\varepsilon_{\theta}(x^{t}|t,z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.7.m7.3d">italic_ε start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT | italic_t , italic_z )</annotation></semantics></math> denotes the network processing <math alttext="x^{t}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.8.m8.1"><semantics id="S2.SS0.SSS0.Px2.p3.8.m8.1a"><msup id="S2.SS0.SSS0.Px2.p3.8.m8.1.1" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.8.m8.1b"><apply id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.8.m8.1c">x^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.8.m8.1d">italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>, conditioned on both <math alttext="t" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.9.m9.1"><semantics id="S2.SS0.SSS0.Px2.p3.9.m9.1a"><mi id="S2.SS0.SSS0.Px2.p3.9.m9.1.1" xref="S2.SS0.SSS0.Px2.p3.9.m9.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.9.m9.1b"><ci id="S2.SS0.SSS0.Px2.p3.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.9.m9.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.9.m9.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.9.m9.1d">italic_t</annotation></semantics></math> and <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.10.m10.1"><semantics id="S2.SS0.SSS0.Px2.p3.10.m10.1a"><mi id="S2.SS0.SSS0.Px2.p3.10.m10.1.1" xref="S2.SS0.SSS0.Px2.p3.10.m10.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.10.m10.1b"><ci id="S2.SS0.SSS0.Px2.p3.10.m10.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.10.m10.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.10.m10.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.10.m10.1d">italic_z</annotation></semantics></math>. As discussed in <cite class="ltx_cite ltx_citemacro_cite">Song &amp; Ermon (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib96" title="">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Song et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib97" title="">2021</a>)</cite>, Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.E1" title="In Diffusion models. ‣ 2 Background ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> acts as a form of score matching, associated with a loss function regarding the score function of <math alttext="p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.11.m11.1"><semantics id="S2.SS0.SSS0.Px2.p3.11.m11.1a"><mrow id="S2.SS0.SSS0.Px2.p3.11.m11.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.11.m11.1b"><apply id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1"><times id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3">𝑝</ci><apply id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3">𝑧</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.11.m11.1c">p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.11.m11.1d">italic_p ( italic_x | italic_z )</annotation></semantics></math>, represented as <math alttext="\nabla\log_{x}p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.12.m12.1"><semantics id="S2.SS0.SSS0.Px2.p3.12.m12.1a"><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1" rspace="0.167em" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1.cmml">∇</mo><msub id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2.cmml">log</mi><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3.cmml">x</mi></msub></mrow><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3a" lspace="0.167em" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.cmml">⁡</mo><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2.cmml">p</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.12.m12.1b"><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1"><times id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2"></times><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3"><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1"><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1">∇</ci><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2">subscript</csymbol><log id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2"></log><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3">𝑥</ci></apply></apply><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2">𝑝</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3">𝑧</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.12.m12.1c">\nabla\log_{x}p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.12.m12.1d">∇ roman_log start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_p ( italic_x | italic_z )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p4.3">Unlike typical applications of diffusion models that represent the joint distribution of all pixels or tokens, our approach leverages the diffusion model to represent the distribution of individual tokens following <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p4.3.1">i.e.</span>, <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p4.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p4.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2.cmml">⁢</mo><mrow id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml"><msub id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1"><times id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3">𝑝</ci><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2">𝑧</ci><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.1.m1.1c">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.1.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. This allows us to simultaneously apply both diffusion loss and prediction loss to the tokens. Consequently, the noise estimator <math alttext="\varepsilon_{\theta}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.2.m2.1"><semantics id="S2.SS0.SSS0.Px2.p4.2.m2.1a"><msub id="S2.SS0.SSS0.Px2.p4.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2.cmml">ε</mi><mi id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.2.m2.1b"><apply id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2">𝜀</ci><ci id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.2.m2.1c">\varepsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.2.m2.1d">italic_ε start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, parameterized by <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.3.m3.1"><semantics id="S2.SS0.SSS0.Px2.p4.3.m3.1a"><mi id="S2.SS0.SSS0.Px2.p4.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p4.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.3.m3.1b"><ci id="S2.SS0.SSS0.Px2.p4.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.3.m3.1d">italic_θ</annotation></semantics></math>, can be efficiently modeled using a small MLP network in our case. This significantly enhances the efficiency of the denoising process in the continuous space. Further details are provided in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS3" title="3.3 Diffusion Learning with a Denoising MLP ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Generalized next-token prediction.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Next-token prediction, or autoregressive modeling, typically predicts the next token based on preceding tokens, establishing a sequential dependency <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib83" title="">2018</a>)</cite>. Generalized next-token prediction techniques, such as MaskGIT <cite class="ltx_cite ltx_citemacro_citep">(Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite> and MAGE <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>, integrate an MAE-style <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> encoder and decoder with positional embeddings to streamline the prediction process. This approach facilitates interaction among known tokens and accelerates inference by generating multiple tokens per step, as demonstrated in the next set-of-token prediction strategies like MAR <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, even without key-value caching <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib92" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">Our D-JEPA model extends these innovations by integrating the masked image modeling approach as a generalized next-token prediction strategy to facilitate an autoregressive generation manner. We can flexibly adjust the number of tokens predicted in each step by controlling the auto-regressive steps. Contrary to the intuition formed by existing methods <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>, the best performance under the D-JEPA architecture is not achieved when the auto-regressive steps are maximized, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px3.p2.1.1">i.e.</span>, when the generalized next-token prediction predicts only one token at a time. Moreover, as the scale of the model parameters increases, the number of auto-regressive steps required to achieve the best sampling results decreases accordingly. This fully demonstrates that converting the masked image modeling method into a next-token prediction strategy is not only feasible but also highly effective. Refer to the Experiment part in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4" title="4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> for more analysis.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we will first introduce how to convert masked image modeling into the next-token prediction. Following this, we will explain how representation learning and diffusion learning coexist within D-JEPA. Finally, we will describe how to generate samples using the generalized next-token prediction approach. The overall architecture of D-JEPA is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.F1" title="Figure 1 ‣ 2 Background ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.4">For clarity, we denote a sequence of tokens using blackboard bold letters, such as <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">𝕏</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝕏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">blackboard_X</annotation></semantics></math>, with individual tokens represented by lowercase letters with subscripts (<span class="ltx_text ltx_font_italic" id="S3.p2.4.1">e.g.</span>, <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">x</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">𝑥</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as a token in <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="S3.p2.3.m3.1"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">𝕏</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">𝕏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.1d">blackboard_X</annotation></semantics></math>). The notation <math alttext="|\mathbb{X}|" class="ltx_Math" display="inline" id="S3.p2.4.m4.1"><semantics id="S3.p2.4.m4.1a"><mrow id="S3.p2.4.m4.1.2.2" xref="S3.p2.4.m4.1.2.1.cmml"><mo id="S3.p2.4.m4.1.2.2.1" stretchy="false" xref="S3.p2.4.m4.1.2.1.1.cmml">|</mo><mi id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">𝕏</mi><mo id="S3.p2.4.m4.1.2.2.2" stretchy="false" xref="S3.p2.4.m4.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.2.1.cmml" xref="S3.p2.4.m4.1.2.2"><abs id="S3.p2.4.m4.1.2.1.1.cmml" xref="S3.p2.4.m4.1.2.2.1"></abs><ci id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">𝕏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">|\mathbb{X}|</annotation><annotation encoding="application/x-llamapun" id="S3.p2.4.m4.1d">| blackboard_X |</annotation></semantics></math> indicates the number of tokens in the sequence.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Tokenization and Masking</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.3">In masked image modeling, certain image regions are randomly masked during training, prompting the feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_γ</annotation></semantics></math> to predict the content of these masked areas based on the context (unmasked) regions. In representation learning, masking is typically applied directly to raw pixels <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>; Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, and it has been observed that masking contiguous regions significantly enhances the representation learning capability. This is crucial, as it implies that when we patchify an image into tokens, we can randomly mask tokens without degrading performance since each token inherently represents a continuous region. Based on this, we can patchify images into non-overlapping semantic tokens <math alttext="\mathbb{U}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝕌</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝕌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbb{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">blackboard_U</annotation></semantics></math> based on a specific patch size <math alttext="p" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_p</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Although images are directly segmented into patches on raw pixels, which is also the standard practice in visual transformers <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>, recent generative models <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite> tend to first encode images into the latent space using a VAE before performing patchification, arguing that this significantly reduces the training cost of generative models and accelerates the sampling speed. However, we found that this approach noticeably degrades D-JEPA’s performance in representation tasks.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>More analysis about D-JEPA’s performance in representation tasks have been listed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2" title="E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">E.2</span></a>.</span></span></span> Since the primary goal of this work is to ensure that D-JEPA functions as an outstanding generative model, we adopted the latent space modeling strategy initially proposed by <cite class="ltx_cite ltx_citemacro_cite">Rombach et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite>. (It is important to note that <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">training in latent space is not a necessity for D-JEPA</span>; it can be trained in raw space and still achieve excellent results.)</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.3">Subsequently, we perform random masking on these tokens. Masking ratios <math alttext="r_{mask}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">r</mi><mrow id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS1.p3.1.m1.1.1.3.2" xref="S3.SS1.p3.1.m1.1.1.3.2.cmml">m</mi><mo id="S3.SS1.p3.1.m1.1.1.3.1" xref="S3.SS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.1.m1.1.1.3.3" xref="S3.SS1.p3.1.m1.1.1.3.3.cmml">a</mi><mo id="S3.SS1.p3.1.m1.1.1.3.1a" xref="S3.SS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.1.m1.1.1.3.4" xref="S3.SS1.p3.1.m1.1.1.3.4.cmml">s</mi><mo id="S3.SS1.p3.1.m1.1.1.3.1b" xref="S3.SS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.1.m1.1.1.3.5" xref="S3.SS1.p3.1.m1.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝑟</ci><apply id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3"><times id="S3.SS1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS1.p3.1.m1.1.1.3.1"></times><ci id="S3.SS1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS1.p3.1.m1.1.1.3.2">𝑚</ci><ci id="S3.SS1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3">𝑎</ci><ci id="S3.SS1.p3.1.m1.1.1.3.4.cmml" xref="S3.SS1.p3.1.m1.1.1.3.4">𝑠</ci><ci id="S3.SS1.p3.1.m1.1.1.3.5.cmml" xref="S3.SS1.p3.1.m1.1.1.3.5">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">r_{mask}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_r start_POSTSUBSCRIPT italic_m italic_a italic_s italic_k end_POSTSUBSCRIPT</annotation></semantics></math> are sampled from a truncated normal distribution with a mean of 1.0, a standard deviation of 0.25, and a lower bound of 0.7. Consequently, more than 70% of the tokens are randomly masked. This results in a sequence of randomly masked tokens of length <math alttext="\lceil r_{mask}\cdot|\mathbb{U}|\rceil" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.2"><semantics id="S3.SS1.p3.2.m2.2a"><mrow id="S3.SS1.p3.2.m2.2.2.1" xref="S3.SS1.p3.2.m2.2.2.2.cmml"><mo id="S3.SS1.p3.2.m2.2.2.1.2" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.2.1.cmml">⌈</mo><mrow id="S3.SS1.p3.2.m2.2.2.1.1" xref="S3.SS1.p3.2.m2.2.2.1.1.cmml"><msub id="S3.SS1.p3.2.m2.2.2.1.1.2" xref="S3.SS1.p3.2.m2.2.2.1.1.2.cmml"><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.2" xref="S3.SS1.p3.2.m2.2.2.1.1.2.2.cmml">r</mi><mrow id="S3.SS1.p3.2.m2.2.2.1.1.2.3" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.cmml"><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.2" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.2.cmml">m</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.3" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.3.cmml">a</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1a" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.4" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.4.cmml">s</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1b" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.5" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.5.cmml">k</mi></mrow></msub><mo id="S3.SS1.p3.2.m2.2.2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p3.2.m2.2.2.1.1.1.cmml">⋅</mo><mrow id="S3.SS1.p3.2.m2.2.2.1.1.3.2" xref="S3.SS1.p3.2.m2.2.2.1.1.3.1.cmml"><mo id="S3.SS1.p3.2.m2.2.2.1.1.3.2.1" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.1.1.3.1.1.cmml">|</mo><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">𝕌</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.3.2.2" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.1.1.3.1.1.cmml">|</mo></mrow></mrow><mo id="S3.SS1.p3.2.m2.2.2.1.3" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.2.1.cmml">⌉</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.2b"><apply id="S3.SS1.p3.2.m2.2.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1"><ceiling id="S3.SS1.p3.2.m2.2.2.2.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.2"></ceiling><apply id="S3.SS1.p3.2.m2.2.2.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1"><ci id="S3.SS1.p3.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.1">⋅</ci><apply id="S3.SS1.p3.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.2.2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.2">𝑟</ci><apply id="S3.SS1.p3.2.m2.2.2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3"><times id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1"></times><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.2">𝑚</ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.3.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.3">𝑎</ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.4.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.4">𝑠</ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.5.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.5">𝑘</ci></apply></apply><apply id="S3.SS1.p3.2.m2.2.2.1.1.3.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.3.2"><abs id="S3.SS1.p3.2.m2.2.2.1.1.3.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.3.2.1"></abs><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝕌</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.2c">\lceil r_{mask}\cdot|\mathbb{U}|\rceil</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.2d">⌈ italic_r start_POSTSUBSCRIPT italic_m italic_a italic_s italic_k end_POSTSUBSCRIPT ⋅ | blackboard_U | ⌉</annotation></semantics></math>, and a sequence of remaining unmasked tokens, <math alttext="\mathbb{Y}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">𝕐</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">𝕐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathbb{Y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">blackboard_Y</annotation></semantics></math>. Masking a substantial portion of tokens reduces both pre-training time and memory usage while improving performance, consistent with findings in previous works<cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; Assran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Representation Learning with JEPAs</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Earlier masked image modeling methods, such as MAE <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>, directly use a decoder network to predict the missing raw pixels. This approach gives these models some outpainting capabilities (i.e., completing missing parts of an image), but they still cannot directly generate high-quality images. Subsequent works, such as DiffMAE <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib110" title="">2023</a>)</cite>, attempted to leverage diffusion models within MAE to enhance the image generation capabilities of these models, but the results were limited. Moreover, this direct raw pixel prediction approach severely restricts the model’s representation ability, especially compared to models like CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib85" title="">2021</a>)</cite>, which use contrastive learning on massive datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.6">Meanwhile, a new architecture called JEPA has gained widespread attention and was successfully applied to representation learning on ImageNet by <cite class="ltx_cite ltx_citemacro_cite">Assran et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, achieving excellent results. JEPA does not directly predict the missing raw pixels; instead, it uses a separate feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_γ</annotation></semantics></math> to predict the target embedding <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝑧</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> corresponding to the missing parts. The target embedding <math alttext="g_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">𝑔</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">g_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, generated by the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><mover accent="true" id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">ϕ</mi><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><ci id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1">¯</ci><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math> by feeding all tokens (<math alttext="\mathbb{U}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">𝕌</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">𝕌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\mathbb{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">blackboard_U</annotation></semantics></math>), is used as the ground truth for <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><msub id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">z</mi><mi id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">𝑧</ci><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.8">The prediction loss objective for unsupervised representation learning on each masked token is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{p}=\mathbb{E}_{z_{i}=\psi(c_{i}),g_{i}}\left[\mathcal{D}(u_{%
\theta}(z_{i}),g_{i})\right]," class="ltx_Math" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.3.2" xref="S3.E2.m1.3.3.1.1.3.2.cmml">ℒ</mi><mi id="S3.E2.m1.3.3.1.1.3.3" xref="S3.E2.m1.3.3.1.1.3.3.cmml">p</mi></msub><mo id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.3.2.cmml">𝔼</mi><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><msub id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml"><mi id="S3.E2.m1.2.2.2.4.2" xref="S3.E2.m1.2.2.2.4.2.cmml">z</mi><mi id="S3.E2.m1.2.2.2.4.3" xref="S3.E2.m1.2.2.2.4.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">=</mo><mrow id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">ψ</mi><mo id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.2.cmml">g</mi><mi id="S3.E2.m1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.2.3.cmml">i</mi></msub></mrow></mrow></msub><mo id="S3.E2.m1.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.1.1.1.1.4" xref="S3.E2.m1.3.3.1.1.1.1.1.1.4.cmml">𝒟</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">u</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.4" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml">g</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.5" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"></eq><apply id="S3.E2.m1.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2">ℒ</ci><ci id="S3.E2.m1.3.3.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.3.3">𝑝</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"></times><apply id="S3.E2.m1.3.3.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.3.2">𝔼</ci><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><eq id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></eq><apply id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.4.1.cmml" xref="S3.E2.m1.2.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.2.4.2.cmml" xref="S3.E2.m1.2.2.2.4.2">𝑧</ci><ci id="S3.E2.m1.2.2.2.4.3.cmml" xref="S3.E2.m1.2.2.2.4.3">𝑖</ci></apply><list id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">𝜓</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.2">𝑔</ci><ci id="S3.E2.m1.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3">𝑖</ci></apply></list></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3"></times><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.4">𝒟</ci><interval closure="open" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2"><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">𝑢</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2">𝑔</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\mathcal{L}_{p}=\mathbb{E}_{z_{i}=\psi(c_{i}),g_{i}}\left[\mathcal{D}(u_{%
\theta}(z_{i}),g_{i})\right],</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_ψ ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ caligraphic_D ( italic_u start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.7">where <math alttext="\mathcal{D}(u_{\theta}(z_{i}),g_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.2"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.1.m1.2.2.4" xref="S3.SS2.p3.1.m1.2.2.4.cmml">𝒟</mi><mo id="S3.SS2.p3.1.m1.2.2.3" xref="S3.SS2.p3.1.m1.2.2.3.cmml">⁢</mo><mrow id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml"><mo id="S3.SS2.p3.1.m1.2.2.2.2.3" stretchy="false" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">(</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.2.cmml">u</mi><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.1.m1.2.2.2.2.4" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.cmml">g</mi><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p3.1.m1.2.2.2.2.5" stretchy="false" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><apply id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2"><times id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.3"></times><ci id="S3.SS2.p3.1.m1.2.2.4.cmml" xref="S3.SS2.p3.1.m1.2.2.4">𝒟</ci><interval closure="open" id="S3.SS2.p3.1.m1.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2"></times><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.2">𝑢</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2">𝑔</ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">\mathcal{D}(u_{\theta}(z_{i}),g_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.2d">caligraphic_D ( italic_u start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is a distance measure function, and <math alttext="u_{\theta}(z_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><msub id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">u</mi><mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">θ</mi></msub><mo id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">⁢</mo><mrow id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><times id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"></times><apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">𝑢</ci><ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">𝜃</ci></apply><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">𝑧</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">u_{\theta}(z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_u start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is the projection feature of <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">z</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝑧</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> using a two-layer MLP <math alttext="u_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">u</mi><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝑢</ci><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">u_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_u start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. This loss is optimized exclusively for masked tokens, as optimizing for all tokens has been shown to diminish both generative and representational performance, as noted in <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>. In fact, the choice of distance measure function <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">caligraphic_D</annotation></semantics></math> in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a> is relatively flexible. In <cite class="ltx_cite ltx_citemacro_cite">Assran et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, the MSE function was chosen, while <cite class="ltx_cite ltx_citemacro_cite">Bardes et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>)</cite> used the <math alttext="l_{1}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">l</mi><mn id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝑙</ci><cn id="S3.SS2.p3.6.m6.1.1.3.cmml" type="integer" xref="S3.SS2.p3.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">l_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> function. Here, we use the smoothed <math alttext="l_{1}" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><msub id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">l</mi><mn id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">𝑙</ci><cn id="S3.SS2.p3.7.m7.1.1.3.cmml" type="integer" xref="S3.SS2.p3.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">l_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> function, following <cite class="ltx_cite ltx_citemacro_cite">Baevski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>)</cite>, which we found to be more stable.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Since JEPA predicts feature embeddings, they cannot be directly used for generation tasks or even outpainting. Experiments show that token embeddings trained with JEPA can only reconstruct image content somewhat related to the surrounding context and are almost incapable of generating high-quality images <cite class="ltx_cite ltx_citemacro_citep">(Bardes et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>)</cite>. This further diminishes the consideration of JEPA architecture as a generative model. Here, we surprisingly find that as long as the JEPA training process also includes generative task training, excellent generative results can be achieved, which will be elaborated on in the next section.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.5">We use three identical visual transformers as the context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_ϕ</annotation></semantics></math>, target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mover accent="true" id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml">ϕ</mi><mo id="S3.SS2.p5.2.m2.1.1.1" xref="S3.SS2.p5.2.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"><ci id="S3.SS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1">¯</ci><ci id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math>, and feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.p5.3.m3.1"><semantics id="S3.SS2.p5.3.m3.1a"><mi id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><ci id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.3.m3.1d">italic_γ</annotation></semantics></math>. The parameters of <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS2.p5.4.m4.1"><semantics id="S3.SS2.p5.4.m4.1a"><mi id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><ci id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.4.m4.1d">italic_ϕ</annotation></semantics></math> and <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.p5.5.m5.1"><semantics id="S3.SS2.p5.5.m5.1a"><mi id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><ci id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.5.m5.1d">italic_γ</annotation></semantics></math> are randomly initialized and then updated with a gradient descent method. The parameters of the target encoder are initialized identically to the context encoder and then updated via an exponentially moving average of the context encoder parameters:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bar{\phi}\leftarrow\alpha\bar{\phi}+(1-\alpha)\phi," class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">ϕ</mi><mo id="S3.E3.m1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.3.1.cmml">¯</mo></mover><mo id="S3.E3.m1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.2.cmml">←</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.3.2.cmml">α</mi><mo id="S3.E3.m1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.3.1.cmml">⁢</mo><mover accent="true" id="S3.E3.m1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.3.3.2.cmml">ϕ</mi><mo id="S3.E3.m1.1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.1.3.3.1.cmml">¯</mo></mover></mrow><mo id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml">α</mi></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">ϕ</mi></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><ci id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2">←</ci><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><ci id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.1">¯</ci><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">italic-ϕ</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2"></plus><apply id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2">𝛼</ci><apply id="S3.E3.m1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3"><ci id="S3.E3.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.1">¯</ci><ci id="S3.E3.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.2">italic-ϕ</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3">𝛼</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">italic-ϕ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\bar{\phi}\leftarrow\alpha\bar{\phi}+(1-\alpha)\phi,</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">over¯ start_ARG italic_ϕ end_ARG ← italic_α over¯ start_ARG italic_ϕ end_ARG + ( 1 - italic_α ) italic_ϕ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p5.8">where <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.p5.6.m1.1"><semantics id="S3.SS2.p5.6.m1.1a"><mi id="S3.SS2.p5.6.m1.1.1" xref="S3.SS2.p5.6.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.6.m1.1b"><ci id="S3.SS2.p5.6.m1.1.1.cmml" xref="S3.SS2.p5.6.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.6.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.6.m1.1d">italic_α</annotation></semantics></math> controls the update frequency. In <cite class="ltx_cite ltx_citemacro_cite">Bardes et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Assran et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, a linear warmup is applied to gradually increase <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.p5.7.m2.1"><semantics id="S3.SS2.p5.7.m2.1a"><mi id="S3.SS2.p5.7.m2.1.1" xref="S3.SS2.p5.7.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.7.m2.1b"><ci id="S3.SS2.p5.7.m2.1.1.cmml" xref="S3.SS2.p5.7.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.7.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.7.m2.1d">italic_α</annotation></semantics></math> from a smaller value to a larger one to effectively control the update speed of the target encoder, thereby preventing the model collapse. Thanks to the constraint of diffusion loss, for D-JEPA, we simply use a constant <math alttext="\alpha=0.9999" class="ltx_Math" display="inline" id="S3.SS2.p5.8.m3.1"><semantics id="S3.SS2.p5.8.m3.1a"><mrow id="S3.SS2.p5.8.m3.1.1" xref="S3.SS2.p5.8.m3.1.1.cmml"><mi id="S3.SS2.p5.8.m3.1.1.2" xref="S3.SS2.p5.8.m3.1.1.2.cmml">α</mi><mo id="S3.SS2.p5.8.m3.1.1.1" xref="S3.SS2.p5.8.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p5.8.m3.1.1.3" xref="S3.SS2.p5.8.m3.1.1.3.cmml">0.9999</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.8.m3.1b"><apply id="S3.SS2.p5.8.m3.1.1.cmml" xref="S3.SS2.p5.8.m3.1.1"><eq id="S3.SS2.p5.8.m3.1.1.1.cmml" xref="S3.SS2.p5.8.m3.1.1.1"></eq><ci id="S3.SS2.p5.8.m3.1.1.2.cmml" xref="S3.SS2.p5.8.m3.1.1.2">𝛼</ci><cn id="S3.SS2.p5.8.m3.1.1.3.cmml" type="float" xref="S3.SS2.p5.8.m3.1.1.3">0.9999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.8.m3.1c">\alpha=0.9999</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.8.m3.1d">italic_α = 0.9999</annotation></semantics></math>, which is sufficient.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.3">In Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, <math alttext="g_{i}=\text{sg}(\bar{\phi}(\mathbb{U}))" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.2"><semantics id="S3.SS2.p6.1.m1.2a"><mrow id="S3.SS2.p6.1.m1.2.2" xref="S3.SS2.p6.1.m1.2.2.cmml"><msub id="S3.SS2.p6.1.m1.2.2.3" xref="S3.SS2.p6.1.m1.2.2.3.cmml"><mi id="S3.SS2.p6.1.m1.2.2.3.2" xref="S3.SS2.p6.1.m1.2.2.3.2.cmml">g</mi><mi id="S3.SS2.p6.1.m1.2.2.3.3" xref="S3.SS2.p6.1.m1.2.2.3.3.cmml">i</mi></msub><mo id="S3.SS2.p6.1.m1.2.2.2" xref="S3.SS2.p6.1.m1.2.2.2.cmml">=</mo><mrow id="S3.SS2.p6.1.m1.2.2.1" xref="S3.SS2.p6.1.m1.2.2.1.cmml"><mtext id="S3.SS2.p6.1.m1.2.2.1.3" xref="S3.SS2.p6.1.m1.2.2.1.3a.cmml">sg</mtext><mo id="S3.SS2.p6.1.m1.2.2.1.2" xref="S3.SS2.p6.1.m1.2.2.1.2.cmml">⁢</mo><mrow id="S3.SS2.p6.1.m1.2.2.1.1.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml"><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.2" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p6.1.m1.2.2.1.1.1.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml"><mover accent="true" id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2.cmml">ϕ</mi><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1.cmml">¯</mo></mover><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.1.cmml">⁢</mo><mrow id="S3.SS2.p6.1.m1.2.2.1.1.1.1.3.2" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml"><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.3.2.1" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">𝕌</mi><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.3.2.2" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.3" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.2b"><apply id="S3.SS2.p6.1.m1.2.2.cmml" xref="S3.SS2.p6.1.m1.2.2"><eq id="S3.SS2.p6.1.m1.2.2.2.cmml" xref="S3.SS2.p6.1.m1.2.2.2"></eq><apply id="S3.SS2.p6.1.m1.2.2.3.cmml" xref="S3.SS2.p6.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p6.1.m1.2.2.3.1.cmml" xref="S3.SS2.p6.1.m1.2.2.3">subscript</csymbol><ci id="S3.SS2.p6.1.m1.2.2.3.2.cmml" xref="S3.SS2.p6.1.m1.2.2.3.2">𝑔</ci><ci id="S3.SS2.p6.1.m1.2.2.3.3.cmml" xref="S3.SS2.p6.1.m1.2.2.3.3">𝑖</ci></apply><apply id="S3.SS2.p6.1.m1.2.2.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1"><times id="S3.SS2.p6.1.m1.2.2.1.2.cmml" xref="S3.SS2.p6.1.m1.2.2.1.2"></times><ci id="S3.SS2.p6.1.m1.2.2.1.3a.cmml" xref="S3.SS2.p6.1.m1.2.2.1.3"><mtext id="S3.SS2.p6.1.m1.2.2.1.3.cmml" xref="S3.SS2.p6.1.m1.2.2.1.3">sg</mtext></ci><apply id="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1"><times id="S3.SS2.p6.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.1"></times><apply id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2"><ci id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1">¯</ci><ci id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2">italic-ϕ</ci></apply><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">𝕌</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.2c">g_{i}=\text{sg}(\bar{\phi}(\mathbb{U}))</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.2d">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = sg ( over¯ start_ARG italic_ϕ end_ARG ( blackboard_U ) )</annotation></semantics></math>, where <math alttext="\text{sg}(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mrow id="S3.SS2.p6.2.m2.1.2" xref="S3.SS2.p6.2.m2.1.2.cmml"><mtext id="S3.SS2.p6.2.m2.1.2.2" xref="S3.SS2.p6.2.m2.1.2.2a.cmml">sg</mtext><mo id="S3.SS2.p6.2.m2.1.2.1" xref="S3.SS2.p6.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS2.p6.2.m2.1.2.3.2" xref="S3.SS2.p6.2.m2.1.2.cmml"><mo id="S3.SS2.p6.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS2.p6.2.m2.1.2.cmml">(</mo><mo id="S3.SS2.p6.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p6.2.m2.1.1.cmml">⋅</mo><mo id="S3.SS2.p6.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS2.p6.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><apply id="S3.SS2.p6.2.m2.1.2.cmml" xref="S3.SS2.p6.2.m2.1.2"><times id="S3.SS2.p6.2.m2.1.2.1.cmml" xref="S3.SS2.p6.2.m2.1.2.1"></times><ci id="S3.SS2.p6.2.m2.1.2.2a.cmml" xref="S3.SS2.p6.2.m2.1.2.2"><mtext id="S3.SS2.p6.2.m2.1.2.2.cmml" xref="S3.SS2.p6.2.m2.1.2.2">sg</mtext></ci><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">\text{sg}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">sg ( ⋅ )</annotation></semantics></math> denotes a stop-gradient operation, which does not backpropagate through its argument. This ensures that the parameters of the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><mover accent="true" id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml"><mi id="S3.SS2.p6.3.m3.1.1.2" xref="S3.SS2.p6.3.m3.1.1.2.cmml">ϕ</mi><mo id="S3.SS2.p6.3.m3.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><apply id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1"><ci id="S3.SS2.p6.3.m3.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1">¯</ci><ci id="S3.SS2.p6.3.m3.1.1.2.cmml" xref="S3.SS2.p6.3.m3.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math> are updated only through exponentially moving average , <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.3.1">i.e.</span>, Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E3" title="In 3.2 Representation Learning with JEPAs ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3</span></a>, a strategy that has been used to prevent collapse in image pre-training <cite class="ltx_cite ltx_citemacro_citep">(Grill et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>)</cite>, and studied empirically <cite class="ltx_cite ltx_citemacro_citep">(Xie et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib112" title="">2022</a>)</cite> and theoretically <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib104" title="">2021</a>)</cite> <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>A theoretical motivation for the effectiveness of this collapse prevention strategy is proposed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS1" title="E.1 Theoretical motivation ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">E.1</span></a>.</span></span></span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Diffusion Learning with a Denoising MLP</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">Our method diverges from traditional approaches by focusing on learning the conditional distribution <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">p</mi><mo id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS3.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p1.1.m1.1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><times id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"></times><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">𝑝</ci><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.2">𝑧</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> for each token, given <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝑧</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, rather than capturing the distribution of entire images. This approach eliminates the need to denoise the entire JEPA model, as some prior works require <cite class="ltx_cite ltx_citemacro_cite">Hatamizadeh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib40" title="">2023</a>); Peebles &amp; Xie (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>); Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib110" title="">2023</a>)</cite>, allowing us to utilize a significantly smaller network to model each token individually.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.6">Hence, the denoising loss objective can be formulated by slightly modifying Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.E1" title="In Diffusion models. ‣ 2 Background ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> to model the token distribution as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{d}=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-\varepsilon%
_{\theta}(x_{i}^{t}|t,z_{i})\right\|^{2}\right]." class="ltx_math_unparsed" display="block" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3b"><msub id="S3.E4.m1.3.4"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.3.4.2">ℒ</mi><mi id="S3.E4.m1.3.4.3">d</mi></msub><mo id="S3.E4.m1.3.5">=</mo><msub id="S3.E4.m1.3.6"><mi id="S3.E4.m1.3.6.2">𝔼</mi><mrow id="S3.E4.m1.2.2.2.4"><mi id="S3.E4.m1.1.1.1.1">ε</mi><mo id="S3.E4.m1.2.2.2.4.1">,</mo><mi id="S3.E4.m1.2.2.2.2">t</mi></mrow></msub><mrow id="S3.E4.m1.3.7"><mo id="S3.E4.m1.3.7.1">[</mo><mo id="S3.E4.m1.3.7.2" lspace="0em" rspace="0.167em" stretchy="true">∥</mo><mi id="S3.E4.m1.3.7.3">ε</mi><mo id="S3.E4.m1.3.7.4">−</mo><msub id="S3.E4.m1.3.7.5"><mi id="S3.E4.m1.3.7.5.2">ε</mi><mi id="S3.E4.m1.3.7.5.3">θ</mi></msub><mrow id="S3.E4.m1.3.7.6"><mo id="S3.E4.m1.3.7.6.1" stretchy="false">(</mo><msubsup id="S3.E4.m1.3.7.6.2"><mi id="S3.E4.m1.3.7.6.2.2.2">x</mi><mi id="S3.E4.m1.3.7.6.2.2.3">i</mi><mi id="S3.E4.m1.3.7.6.2.3">t</mi></msubsup><mo fence="false" id="S3.E4.m1.3.7.6.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E4.m1.3.3">t</mi><mo id="S3.E4.m1.3.7.6.4">,</mo><msub id="S3.E4.m1.3.7.6.5"><mi id="S3.E4.m1.3.7.6.5.2">z</mi><mi id="S3.E4.m1.3.7.6.5.3">i</mi></msub><mo id="S3.E4.m1.3.7.6.6" stretchy="false">)</mo></mrow><msup id="S3.E4.m1.3.7.7"><mo id="S3.E4.m1.3.7.7.2" lspace="0em" rspace="0.167em" stretchy="true">∥</mo><mn id="S3.E4.m1.3.7.7.3">2</mn></msup><mo id="S3.E4.m1.3.7.8">]</mo></mrow><mo id="S3.E4.m1.3.8" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\mathcal{L}_{d}=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-\varepsilon%
_{\theta}(x_{i}^{t}|t,z_{i})\right\|^{2}\right].</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_ε , italic_t end_POSTSUBSCRIPT [ ∥ italic_ε - italic_ε start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT | italic_t , italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p2.5">For denoising, we employ a compact multi-layer perceptron (MLP) comprising a few residual blocks <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib41" title="">2016</a>)</cite> as <math alttext="\varepsilon_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">ε</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝜀</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\varepsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_ε start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>. Each block sequentially applies LayerNorm (LN) <cite class="ltx_cite ltx_citemacro_citep">(Ba et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib5" title="">2016</a>)</cite>, a linear layer, the SiLU activation function <cite class="ltx_cite ltx_citemacro_citep">(Elfwing et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib30" title="">2018</a>)</cite>, and another linear layer, integrated with a residual connection, following <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>.
<math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">𝑧</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is added to the time embedding of the noise schedule time-step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_t</annotation></semantics></math>, then conditions the MLP in the LN layers via AdaLN <cite class="ltx_cite ltx_citemacro_citep">(Peebles &amp; Xie, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>. During training, we independently sample <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">italic_t</annotation></semantics></math> four times for each token to maximize the utilization of the diffusion loss without recomputing <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m5.1"><semantics id="S3.SS3.p2.5.m5.1a"><msub id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">z</mi><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">𝑧</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">At inference time, it is required to draw samples from the distribution <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">p</mi><mo id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p3.1.m1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS3.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p3.1.m1.1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS3.p3.1.m1.1.1.1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.2.2" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.2.3" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p3.1.m1.1.1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p3.1.m1.1.1.1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.3.2" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.3.3" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><times id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2"></times><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑝</ci><apply id="S3.SS3.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.2">𝑧</ci><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. Sampling is done via a reverse diffusion procedure <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x^{i}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(x^{i}_{t}-\frac{1-\alpha_{t}}{%
\sqrt{1-\bar{\alpha}_{t}}}\varepsilon_{\theta}(x^{i}_{t}|t,z_{i})\right)+%
\sigma_{t}\delta," class="ltx_Math" display="block" id="S3.Ex1.m1.2"><semantics id="S3.Ex1.m1.2a"><mrow id="S3.Ex1.m1.2.2.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><msubsup id="S3.Ex1.m1.2.2.1.1.3" xref="S3.Ex1.m1.2.2.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.3.2.2.cmml">x</mi><mrow id="S3.Ex1.m1.2.2.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.3.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.3.3.2" xref="S3.Ex1.m1.2.2.1.1.3.3.2.cmml">t</mi><mo id="S3.Ex1.m1.2.2.1.1.3.3.1" xref="S3.Ex1.m1.2.2.1.1.3.3.1.cmml">−</mo><mn id="S3.Ex1.m1.2.2.1.1.3.3.3" xref="S3.Ex1.m1.2.2.1.1.3.3.3.cmml">1</mn></mrow><mi id="S3.Ex1.m1.2.2.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.Ex1.m1.2.2.1.1.2" xref="S3.Ex1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.2.2.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.cmml"><mfrac id="S3.Ex1.m1.2.2.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.3.cmml"><mn id="S3.Ex1.m1.2.2.1.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.3.2.cmml">1</mn><msqrt id="S3.Ex1.m1.2.2.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.cmml"><msub id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2.cmml">α</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3.cmml">t</mi></msub></msqrt></mfrac><mo id="S3.Ex1.m1.2.2.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml"><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">t</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mfrac id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml"><mn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml">1</mn><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml">−</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2.cmml">α</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3.cmml">t</mi></msub></mrow><msqrt id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml"><mn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2.cmml">1</mn><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1.cmml">−</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.cmml"><mover accent="true" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2.cmml">α</mi><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1.cmml">¯</mo></mover><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3.cmml">t</mi></msub></mrow></msqrt></mfrac><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml">ε</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml">θ</mi></msub><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2a" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msubsup><mo fence="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">t</mi><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.2.cmml">+</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.3.cmml"><msub id="S3.Ex1.m1.2.2.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2.cmml">σ</mi><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.Ex1.m1.2.2.1.1.1.3.1" xref="S3.Ex1.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.Ex1.m1.2.2.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.3.3.cmml">δ</mi></mrow></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.2" xref="S3.Ex1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.2b"><apply id="S3.Ex1.m1.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.1"><eq id="S3.Ex1.m1.2.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.2"></eq><apply id="S3.Ex1.m1.2.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3.2.2">𝑥</ci><ci id="S3.Ex1.m1.2.2.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3.2.3">𝑖</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3"><minus id="S3.Ex1.m1.2.2.1.1.3.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3.1"></minus><ci id="S3.Ex1.m1.2.2.1.1.3.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3.2">𝑡</ci><cn id="S3.Ex1.m1.2.2.1.1.3.3.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.3.3.3">1</cn></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1"><plus id="S3.Ex1.m1.2.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.2"></plus><apply id="S3.Ex1.m1.2.2.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.2"></times><apply id="S3.Ex1.m1.2.2.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3"><divide id="S3.Ex1.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3"></divide><cn id="S3.Ex1.m1.2.2.1.1.1.1.3.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.1.1.3.2">1</cn><apply id="S3.Ex1.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3"><root id="S3.Ex1.m1.2.2.1.1.1.1.3.3a.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3"></root><apply id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2">𝛼</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3">𝑡</ci></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2"></minus><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2">𝑥</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2"></times><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3"><divide id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3"></divide><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1"></minus><cn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2">1</cn><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2">𝛼</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3">𝑡</ci></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3"><root id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3a.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3"></root><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1"></minus><cn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2">1</cn><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2"><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1">¯</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2">𝛼</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2">𝜀</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3">𝜃</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2">𝑥</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><list id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">𝑡</ci><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></list></apply></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3"><times id="S3.Ex1.m1.2.2.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.1"></times><apply id="S3.Ex1.m1.2.2.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2">𝜎</ci><ci id="S3.Ex1.m1.2.2.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.3">𝑡</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.3">𝛿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.2c">x^{i}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(x^{i}_{t}-\frac{1-\alpha_{t}}{%
\sqrt{1-\bar{\alpha}_{t}}}\varepsilon_{\theta}(x^{i}_{t}|t,z_{i})\right)+%
\sigma_{t}\delta,</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.2d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG ( italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 - italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_ε start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_t , italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) + italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_δ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p3.8">where <math alttext="\delta" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m1.1"><semantics id="S3.SS3.p3.2.m1.1a"><mi id="S3.SS3.p3.2.m1.1.1" xref="S3.SS3.p3.2.m1.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m1.1b"><ci id="S3.SS3.p3.2.m1.1.1.cmml" xref="S3.SS3.p3.2.m1.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m1.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m1.1d">italic_δ</annotation></semantics></math> is sampled from the Gaussian distribution <math alttext="\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m2.2"><semantics id="S3.SS3.p3.3.m2.2a"><mrow id="S3.SS3.p3.3.m2.2.3" xref="S3.SS3.p3.3.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m2.2.3.2" xref="S3.SS3.p3.3.m2.2.3.2.cmml">𝒩</mi><mo id="S3.SS3.p3.3.m2.2.3.1" xref="S3.SS3.p3.3.m2.2.3.1.cmml">⁢</mo><mrow id="S3.SS3.p3.3.m2.2.3.3.2" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml"><mo id="S3.SS3.p3.3.m2.2.3.3.2.1" stretchy="false" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml">(</mo><mn id="S3.SS3.p3.3.m2.1.1" xref="S3.SS3.p3.3.m2.1.1.cmml">𝟎</mn><mo id="S3.SS3.p3.3.m2.2.3.3.2.2" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml">,</mo><mi id="S3.SS3.p3.3.m2.2.2" xref="S3.SS3.p3.3.m2.2.2.cmml">𝐈</mi><mo id="S3.SS3.p3.3.m2.2.3.3.2.3" stretchy="false" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m2.2b"><apply id="S3.SS3.p3.3.m2.2.3.cmml" xref="S3.SS3.p3.3.m2.2.3"><times id="S3.SS3.p3.3.m2.2.3.1.cmml" xref="S3.SS3.p3.3.m2.2.3.1"></times><ci id="S3.SS3.p3.3.m2.2.3.2.cmml" xref="S3.SS3.p3.3.m2.2.3.2">𝒩</ci><interval closure="open" id="S3.SS3.p3.3.m2.2.3.3.1.cmml" xref="S3.SS3.p3.3.m2.2.3.3.2"><cn id="S3.SS3.p3.3.m2.1.1.cmml" type="integer" xref="S3.SS3.p3.3.m2.1.1">0</cn><ci id="S3.SS3.p3.3.m2.2.2.cmml" xref="S3.SS3.p3.3.m2.2.2">𝐈</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m2.2c">\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m2.2d">caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math> and <math alttext="\sigma_{t}" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m3.1"><semantics id="S3.SS3.p3.4.m3.1a"><msub id="S3.SS3.p3.4.m3.1.1" xref="S3.SS3.p3.4.m3.1.1.cmml"><mi id="S3.SS3.p3.4.m3.1.1.2" xref="S3.SS3.p3.4.m3.1.1.2.cmml">σ</mi><mi id="S3.SS3.p3.4.m3.1.1.3" xref="S3.SS3.p3.4.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m3.1b"><apply id="S3.SS3.p3.4.m3.1.1.cmml" xref="S3.SS3.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m3.1.1.1.cmml" xref="S3.SS3.p3.4.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m3.1.1.2.cmml" xref="S3.SS3.p3.4.m3.1.1.2">𝜎</ci><ci id="S3.SS3.p3.4.m3.1.1.3.cmml" xref="S3.SS3.p3.4.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m3.1c">\sigma_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m3.1d">italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the noise level at time step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m4.1"><semantics id="S3.SS3.p3.5.m4.1a"><mi id="S3.SS3.p3.5.m4.1.1" xref="S3.SS3.p3.5.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m4.1b"><ci id="S3.SS3.p3.5.m4.1.1.cmml" xref="S3.SS3.p3.5.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m4.1d">italic_t</annotation></semantics></math>. Starting with <math alttext="x^{i}_{T}\sim\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m5.2"><semantics id="S3.SS3.p3.6.m5.2a"><mrow id="S3.SS3.p3.6.m5.2.3" xref="S3.SS3.p3.6.m5.2.3.cmml"><msubsup id="S3.SS3.p3.6.m5.2.3.2" xref="S3.SS3.p3.6.m5.2.3.2.cmml"><mi id="S3.SS3.p3.6.m5.2.3.2.2.2" xref="S3.SS3.p3.6.m5.2.3.2.2.2.cmml">x</mi><mi id="S3.SS3.p3.6.m5.2.3.2.3" xref="S3.SS3.p3.6.m5.2.3.2.3.cmml">T</mi><mi id="S3.SS3.p3.6.m5.2.3.2.2.3" xref="S3.SS3.p3.6.m5.2.3.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS3.p3.6.m5.2.3.1" xref="S3.SS3.p3.6.m5.2.3.1.cmml">∼</mo><mrow id="S3.SS3.p3.6.m5.2.3.3" xref="S3.SS3.p3.6.m5.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.6.m5.2.3.3.2" xref="S3.SS3.p3.6.m5.2.3.3.2.cmml">𝒩</mi><mo id="S3.SS3.p3.6.m5.2.3.3.1" xref="S3.SS3.p3.6.m5.2.3.3.1.cmml">⁢</mo><mrow id="S3.SS3.p3.6.m5.2.3.3.3.2" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml"><mo id="S3.SS3.p3.6.m5.2.3.3.3.2.1" stretchy="false" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml">(</mo><mn id="S3.SS3.p3.6.m5.1.1" xref="S3.SS3.p3.6.m5.1.1.cmml">𝟎</mn><mo id="S3.SS3.p3.6.m5.2.3.3.3.2.2" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml">,</mo><mi id="S3.SS3.p3.6.m5.2.2" xref="S3.SS3.p3.6.m5.2.2.cmml">𝐈</mi><mo id="S3.SS3.p3.6.m5.2.3.3.3.2.3" stretchy="false" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m5.2b"><apply id="S3.SS3.p3.6.m5.2.3.cmml" xref="S3.SS3.p3.6.m5.2.3"><csymbol cd="latexml" id="S3.SS3.p3.6.m5.2.3.1.cmml" xref="S3.SS3.p3.6.m5.2.3.1">similar-to</csymbol><apply id="S3.SS3.p3.6.m5.2.3.2.cmml" xref="S3.SS3.p3.6.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m5.2.3.2.1.cmml" xref="S3.SS3.p3.6.m5.2.3.2">subscript</csymbol><apply id="S3.SS3.p3.6.m5.2.3.2.2.cmml" xref="S3.SS3.p3.6.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m5.2.3.2.2.1.cmml" xref="S3.SS3.p3.6.m5.2.3.2">superscript</csymbol><ci id="S3.SS3.p3.6.m5.2.3.2.2.2.cmml" xref="S3.SS3.p3.6.m5.2.3.2.2.2">𝑥</ci><ci id="S3.SS3.p3.6.m5.2.3.2.2.3.cmml" xref="S3.SS3.p3.6.m5.2.3.2.2.3">𝑖</ci></apply><ci id="S3.SS3.p3.6.m5.2.3.2.3.cmml" xref="S3.SS3.p3.6.m5.2.3.2.3">𝑇</ci></apply><apply id="S3.SS3.p3.6.m5.2.3.3.cmml" xref="S3.SS3.p3.6.m5.2.3.3"><times id="S3.SS3.p3.6.m5.2.3.3.1.cmml" xref="S3.SS3.p3.6.m5.2.3.3.1"></times><ci id="S3.SS3.p3.6.m5.2.3.3.2.cmml" xref="S3.SS3.p3.6.m5.2.3.3.2">𝒩</ci><interval closure="open" id="S3.SS3.p3.6.m5.2.3.3.3.1.cmml" xref="S3.SS3.p3.6.m5.2.3.3.3.2"><cn id="S3.SS3.p3.6.m5.1.1.cmml" type="integer" xref="S3.SS3.p3.6.m5.1.1">0</cn><ci id="S3.SS3.p3.6.m5.2.2.cmml" xref="S3.SS3.p3.6.m5.2.2">𝐈</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m5.2c">x^{i}_{T}\sim\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.6.m5.2d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ∼ caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math>, this procedure produces a sample <math alttext="x^{i}_{0}" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m6.1"><semantics id="S3.SS3.p3.7.m6.1a"><msubsup id="S3.SS3.p3.7.m6.1.1" xref="S3.SS3.p3.7.m6.1.1.cmml"><mi id="S3.SS3.p3.7.m6.1.1.2.2" xref="S3.SS3.p3.7.m6.1.1.2.2.cmml">x</mi><mn id="S3.SS3.p3.7.m6.1.1.3" xref="S3.SS3.p3.7.m6.1.1.3.cmml">0</mn><mi id="S3.SS3.p3.7.m6.1.1.2.3" xref="S3.SS3.p3.7.m6.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m6.1b"><apply id="S3.SS3.p3.7.m6.1.1.cmml" xref="S3.SS3.p3.7.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m6.1.1.1.cmml" xref="S3.SS3.p3.7.m6.1.1">subscript</csymbol><apply id="S3.SS3.p3.7.m6.1.1.2.cmml" xref="S3.SS3.p3.7.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m6.1.1.2.1.cmml" xref="S3.SS3.p3.7.m6.1.1">superscript</csymbol><ci id="S3.SS3.p3.7.m6.1.1.2.2.cmml" xref="S3.SS3.p3.7.m6.1.1.2.2">𝑥</ci><ci id="S3.SS3.p3.7.m6.1.1.2.3.cmml" xref="S3.SS3.p3.7.m6.1.1.2.3">𝑖</ci></apply><cn id="S3.SS3.p3.7.m6.1.1.3.cmml" type="integer" xref="S3.SS3.p3.7.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m6.1c">x^{i}_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.7.m6.1d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> such that <math alttext="x^{i}_{0}\sim p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p3.8.m7.1"><semantics id="S3.SS3.p3.8.m7.1a"><mrow id="S3.SS3.p3.8.m7.1.1" xref="S3.SS3.p3.8.m7.1.1.cmml"><msubsup id="S3.SS3.p3.8.m7.1.1.3" xref="S3.SS3.p3.8.m7.1.1.3.cmml"><mi id="S3.SS3.p3.8.m7.1.1.3.2.2" xref="S3.SS3.p3.8.m7.1.1.3.2.2.cmml">x</mi><mn id="S3.SS3.p3.8.m7.1.1.3.3" xref="S3.SS3.p3.8.m7.1.1.3.3.cmml">0</mn><mi id="S3.SS3.p3.8.m7.1.1.3.2.3" xref="S3.SS3.p3.8.m7.1.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.SS3.p3.8.m7.1.1.2" xref="S3.SS3.p3.8.m7.1.1.2.cmml">∼</mo><mrow id="S3.SS3.p3.8.m7.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.cmml"><mi id="S3.SS3.p3.8.m7.1.1.1.3" xref="S3.SS3.p3.8.m7.1.1.1.3.cmml">p</mi><mo id="S3.SS3.p3.8.m7.1.1.1.2" xref="S3.SS3.p3.8.m7.1.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p3.8.m7.1.1.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml"><mo id="S3.SS3.p3.8.m7.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p3.8.m7.1.1.1.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p3.8.m7.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m7.1b"><apply id="S3.SS3.p3.8.m7.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1"><csymbol cd="latexml" id="S3.SS3.p3.8.m7.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.2">similar-to</csymbol><apply id="S3.SS3.p3.8.m7.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.3.1.cmml" xref="S3.SS3.p3.8.m7.1.1.3">subscript</csymbol><apply id="S3.SS3.p3.8.m7.1.1.3.2.cmml" xref="S3.SS3.p3.8.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.3.2.1.cmml" xref="S3.SS3.p3.8.m7.1.1.3">superscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.3.2.2.cmml" xref="S3.SS3.p3.8.m7.1.1.3.2.2">𝑥</ci><ci id="S3.SS3.p3.8.m7.1.1.3.2.3.cmml" xref="S3.SS3.p3.8.m7.1.1.3.2.3">𝑖</ci></apply><cn id="S3.SS3.p3.8.m7.1.1.3.3.cmml" type="integer" xref="S3.SS3.p3.8.m7.1.1.3.3">0</cn></apply><apply id="S3.SS3.p3.8.m7.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1"><times id="S3.SS3.p3.8.m7.1.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.2"></times><ci id="S3.SS3.p3.8.m7.1.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.3">𝑝</ci><apply id="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2">𝑧</ci><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m7.1c">x^{i}_{0}\sim p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.8.m7.1d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∼ italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.7">We adopt the temperature sampling method presented in <cite class="ltx_cite ltx_citemacro_cite">Dhariwal &amp; Nichol (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>. Conceptually, with a temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_τ</annotation></semantics></math>, one would sample from the (renormalized) probability <math alttext="p(x_{i}|z_{i})^{\frac{1}{\tau}}" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mrow id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">p</mi><mo id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">⁢</mo><msup id="S3.SS3.p4.2.m2.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.cmml"><mrow id="S3.SS3.p4.2.m2.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml"><mo id="S3.SS3.p4.2.m2.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.2.m2.1.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p4.2.m2.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mfrac id="S3.SS3.p4.2.m2.1.1.1.3" xref="S3.SS3.p4.2.m2.1.1.1.3.cmml"><mn id="S3.SS3.p4.2.m2.1.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.1.3.2.cmml">1</mn><mi id="S3.SS3.p4.2.m2.1.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.1.3.3.cmml">τ</mi></mfrac></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><times id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2"></times><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">𝑝</ci><apply id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1">superscript</csymbol><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2">𝑧</ci><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.SS3.p4.2.m2.1.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.3"><divide id="S3.SS3.p4.2.m2.1.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.3"></divide><cn id="S3.SS3.p4.2.m2.1.1.1.3.2.cmml" type="integer" xref="S3.SS3.p4.2.m2.1.1.1.3.2">1</cn><ci id="S3.SS3.p4.2.m2.1.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.3.3">𝜏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">p(x_{i}|z_{i})^{\frac{1}{\tau}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_τ end_ARG end_POSTSUPERSCRIPT</annotation></semantics></math>, whose score function is <math alttext="\frac{1}{\tau}\nabla\log p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p4.3.m3.1"><semantics id="S3.SS3.p4.3.m3.1a"><mrow id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mfrac id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml"><mn id="S3.SS3.p4.3.m3.1.1.3.2" xref="S3.SS3.p4.3.m3.1.1.3.2.cmml">1</mn><mi id="S3.SS3.p4.3.m3.1.1.3.3" xref="S3.SS3.p4.3.m3.1.1.3.3.cmml">τ</mi></mfrac><mo id="S3.SS3.p4.3.m3.1.1.2" lspace="0.167em" xref="S3.SS3.p4.3.m3.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p4.3.m3.1.1.4" xref="S3.SS3.p4.3.m3.1.1.4.cmml"><mrow id="S3.SS3.p4.3.m3.1.1.4.1" xref="S3.SS3.p4.3.m3.1.1.4.1.cmml"><mo id="S3.SS3.p4.3.m3.1.1.4.1.1" rspace="0.167em" xref="S3.SS3.p4.3.m3.1.1.4.1.1.cmml">∇</mo><mi id="S3.SS3.p4.3.m3.1.1.4.1.2" xref="S3.SS3.p4.3.m3.1.1.4.1.2.cmml">log</mi></mrow><mo id="S3.SS3.p4.3.m3.1.1.4a" lspace="0.167em" xref="S3.SS3.p4.3.m3.1.1.4.cmml">⁡</mo><mi id="S3.SS3.p4.3.m3.1.1.4.2" xref="S3.SS3.p4.3.m3.1.1.4.2.cmml">p</mi></mrow><mo id="S3.SS3.p4.3.m3.1.1.2a" xref="S3.SS3.p4.3.m3.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p4.3.m3.1.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS3.p4.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.3.m3.1.1.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml"><msub id="S3.SS3.p4.3.m3.1.1.1.1.1.2" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.2.2" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.2.3" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p4.3.m3.1.1.1.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p4.3.m3.1.1.1.1.1.3" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.3.2" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.3.3" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p4.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><times id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2"></times><apply id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3"><divide id="S3.SS3.p4.3.m3.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3"></divide><cn id="S3.SS3.p4.3.m3.1.1.3.2.cmml" type="integer" xref="S3.SS3.p4.3.m3.1.1.3.2">1</cn><ci id="S3.SS3.p4.3.m3.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3">𝜏</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.4.cmml" xref="S3.SS3.p4.3.m3.1.1.4"><apply id="S3.SS3.p4.3.m3.1.1.4.1.cmml" xref="S3.SS3.p4.3.m3.1.1.4.1"><ci id="S3.SS3.p4.3.m3.1.1.4.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.4.1.1">∇</ci><log id="S3.SS3.p4.3.m3.1.1.4.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.4.1.2"></log></apply><ci id="S3.SS3.p4.3.m3.1.1.4.2.cmml" xref="S3.SS3.p4.3.m3.1.1.4.2">𝑝</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.2">𝑧</ci><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\frac{1}{\tau}\nabla\log p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.3.m3.1d">divide start_ARG 1 end_ARG start_ARG italic_τ end_ARG ∇ roman_log italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. Intuitively, we adjust the noise variance <math alttext="\sigma_{t}\delta" class="ltx_Math" display="inline" id="S3.SS3.p4.4.m4.1"><semantics id="S3.SS3.p4.4.m4.1a"><mrow id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><msub id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2.2" xref="S3.SS3.p4.4.m4.1.1.2.2.cmml">σ</mi><mi id="S3.SS3.p4.4.m4.1.1.2.3" xref="S3.SS3.p4.4.m4.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS3.p4.4.m4.1.1.1" xref="S3.SS3.p4.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">δ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><times id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1.1"></times><apply id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.2.1.cmml" xref="S3.SS3.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2.2">𝜎</ci><ci id="S3.SS3.p4.4.m4.1.1.2.3.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3">𝑡</ci></apply><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">𝛿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\sigma_{t}\delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.4.m4.1d">italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_δ</annotation></semantics></math> in the sampler by <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS3.p4.5.m5.1"><semantics id="S3.SS3.p4.5.m5.1a"><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.5.m5.1d">italic_τ</annotation></semantics></math> to control the sample diversity. Experimentally, <math alttext="\tau=0.98" class="ltx_Math" display="inline" id="S3.SS3.p4.6.m6.1"><semantics id="S3.SS3.p4.6.m6.1a"><mrow id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml"><mi id="S3.SS3.p4.6.m6.1.1.2" xref="S3.SS3.p4.6.m6.1.1.2.cmml">τ</mi><mo id="S3.SS3.p4.6.m6.1.1.1" xref="S3.SS3.p4.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS3.p4.6.m6.1.1.3" xref="S3.SS3.p4.6.m6.1.1.3.cmml">0.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><apply id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1"><eq id="S3.SS3.p4.6.m6.1.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1.1"></eq><ci id="S3.SS3.p4.6.m6.1.1.2.cmml" xref="S3.SS3.p4.6.m6.1.1.2">𝜏</ci><cn id="S3.SS3.p4.6.m6.1.1.3.cmml" type="float" xref="S3.SS3.p4.6.m6.1.1.3">0.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">\tau=0.98</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.6.m6.1d">italic_τ = 0.98</annotation></semantics></math> and <math alttext="\tau=0.94" class="ltx_Math" display="inline" id="S3.SS3.p4.7.m7.1"><semantics id="S3.SS3.p4.7.m7.1a"><mrow id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml"><mi id="S3.SS3.p4.7.m7.1.1.2" xref="S3.SS3.p4.7.m7.1.1.2.cmml">τ</mi><mo id="S3.SS3.p4.7.m7.1.1.1" xref="S3.SS3.p4.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS3.p4.7.m7.1.1.3" xref="S3.SS3.p4.7.m7.1.1.3.cmml">0.94</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><apply id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1"><eq id="S3.SS3.p4.7.m7.1.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1.1"></eq><ci id="S3.SS3.p4.7.m7.1.1.2.cmml" xref="S3.SS3.p4.7.m7.1.1.2">𝜏</ci><cn id="S3.SS3.p4.7.m7.1.1.3.cmml" type="float" xref="S3.SS3.p4.7.m7.1.1.3">0.94</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">\tau=0.94</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.7.m7.1d">italic_τ = 0.94</annotation></semantics></math> are suitable for image generation with and without classifier-free guidance, respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1">Furthermore, we also introduce the recently popular <span class="ltx_text ltx_font_italic" id="S3.SS3.p5.1.1">flow matching loss</span> <cite class="ltx_cite ltx_citemacro_citep">(Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S3.SS3.p5.1.2">i.e.</span>, Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.E7" title="In Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a>, as an alternative to the denoising loss (Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E4" title="In 3.3 Diffusion Learning with a Denoising MLP ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a>). Overall, flow matching achieves faster convergence and generates higher-quality visual content, and it can be more easily adapted to different scenarios. However, for scenarios where the diffusion loss can converge, fully trained diffusion loss can achieve better performance than flow-matching loss. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Here, we discuss flow matching loss and diffusion loss, which are not equivalent to flow matching models and diffusion models. For a detailed analysis, please refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">F</span></a>.</span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Training with D-JEPA</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.2">By choosing different training objectives, D-JEPA can seamlessly transition between representation learning and diffusion learning without any changes to the network architecture. Typically, when faced with multiple training objectives, one needs to carefully balance each component in the final loss objective to ensure the model’s effectivenes <cite class="ltx_cite ltx_citemacro_citep">(Kendall et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib54" title="">2018</a>)</cite>. However, the prediction loss <math alttext="\mathcal{L}_{p}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">ℒ</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">ℒ</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mathcal{L}_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> and the diffusion loss <math alttext="\mathcal{L}_{d}" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">ℒ</mi><mi id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">ℒ</ci><ci id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\mathcal{L}_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> in D-JEPA do not have conflicting or mutually exclusive relationships.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The diffusion loss effectively prevents the potential representation collapse issue faced by the prediction loss, while the prediction loss can provide the diffusion model with higher-level semantic feature information <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">𝑧</ci><ci id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Therefore, the overall loss function can be simply defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=\mathcal{L}_{d}+\mathcal{L}_{p}." class="ltx_Math" display="block" id="S3.Ex2.m1.1"><semantics id="S3.Ex2.m1.1a"><mrow id="S3.Ex2.m1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.cmml"><mrow id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.1.2.cmml">ℒ</mi><mo id="S3.Ex2.m1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.Ex2.m1.1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.1.3.cmml"><msub id="S3.Ex2.m1.1.1.1.1.3.2" xref="S3.Ex2.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.1.1.1.1.3.2.2" xref="S3.Ex2.m1.1.1.1.1.3.2.2.cmml">ℒ</mi><mi id="S3.Ex2.m1.1.1.1.1.3.2.3" xref="S3.Ex2.m1.1.1.1.1.3.2.3.cmml">d</mi></msub><mo id="S3.Ex2.m1.1.1.1.1.3.1" xref="S3.Ex2.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.1.1.1.1.3.3" xref="S3.Ex2.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.1.1.1.1.3.3.2" xref="S3.Ex2.m1.1.1.1.1.3.3.2.cmml">ℒ</mi><mi id="S3.Ex2.m1.1.1.1.1.3.3.3" xref="S3.Ex2.m1.1.1.1.1.3.3.3.cmml">p</mi></msub></mrow></mrow><mo id="S3.Ex2.m1.1.1.1.2" lspace="0em" xref="S3.Ex2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.1b"><apply id="S3.Ex2.m1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1"><eq id="S3.Ex2.m1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1"></eq><ci id="S3.Ex2.m1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1.2">ℒ</ci><apply id="S3.Ex2.m1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3"><plus id="S3.Ex2.m1.1.1.1.1.3.1.cmml" xref="S3.Ex2.m1.1.1.1.1.3.1"></plus><apply id="S3.Ex2.m1.1.1.1.1.3.2.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.1.1.3.2.1.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.Ex2.m1.1.1.1.1.3.2.2.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2.2">ℒ</ci><ci id="S3.Ex2.m1.1.1.1.1.3.2.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2.3">𝑑</ci></apply><apply id="S3.Ex2.m1.1.1.1.1.3.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.1.1.3.3.1.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.Ex2.m1.1.1.1.1.3.3.2.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3.2">ℒ</ci><ci id="S3.Ex2.m1.1.1.1.1.3.3.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.1c">\mathcal{L}=\mathcal{L}_{d}+\mathcal{L}_{p}.</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.1d">caligraphic_L = caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">Experiments show that this approach plays a crucial role in enabling D-JEPA to converge faster and achieve better results when scaling up the model.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Sampling in Next Set-of-Tokens Prediction</h3>
<div class="ltx_para ltx_noindent" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.4">For the evaluation of generative models in generalized next-token prediction, we adopt an <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.4.1">iterative sampling</span> strategy analogous to those used in <cite class="ltx_cite ltx_citemacro_cite">Chang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, as shown in Algo. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#alg1" title="Algorithm 1 ‣ 3.5 Sampling in Next Set-of-Tokens Prediction ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>. This strategy gradually reduces the masking ratio from <math alttext="1.0" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mn id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><cn id="S3.SS5.p1.1.m1.1.1.cmml" type="float" xref="S3.SS5.p1.1.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">1.0</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">1.0</annotation></semantics></math> to <math alttext="0.0" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1"><semantics id="S3.SS5.p1.2.m2.1a"><mn id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><cn id="S3.SS5.p1.2.m2.1.1.cmml" type="float" xref="S3.SS5.p1.2.m2.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">0.0</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.2.m2.1d">0.0</annotation></semantics></math> in accordance with a cosine schedule, typically utilizing <math alttext="64" class="ltx_Math" display="inline" id="S3.SS5.p1.3.m3.1"><semantics id="S3.SS5.p1.3.m3.1a"><mn id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><cn id="S3.SS5.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS5.p1.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">64</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.3.m3.1d">64</annotation></semantics></math> auto-regressive steps. D-JEPA employs fully randomized orderings following <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> to decide the next set of tokens to predict. This design, along with the temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS5.p1.4.m4.1"><semantics id="S3.SS5.p1.4.m4.1a"><mi id="S3.SS5.p1.4.m4.1.1" xref="S3.SS5.p1.4.m4.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.4.m4.1b"><ci id="S3.SS5.p1.4.m4.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.4.m4.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.4.m4.1d">italic_τ</annotation></semantics></math>, effectively enhances the diversity of the generated samples.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.3">When the number of auto-regressive steps <math alttext="T" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.1"><semantics id="S3.SS5.p2.1.m1.1a"><mi id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><ci id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.1.m1.1d">italic_T</annotation></semantics></math> equals the total tokens <math alttext="N" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.1"><semantics id="S3.SS5.p2.2.m2.1a"><mi id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><ci id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.2.m2.1d">italic_N</annotation></semantics></math>, it means that we sample one token at each step. In this case, the <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.1">generalized next-token prediction</span> is equivalent to a <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.2">typical next-token prediction</span>. In another extreme case, <math alttext="T=1" class="ltx_Math" display="inline" id="S3.SS5.p2.3.m3.1"><semantics id="S3.SS5.p2.3.m3.1a"><mrow id="S3.SS5.p2.3.m3.1.1" xref="S3.SS5.p2.3.m3.1.1.cmml"><mi id="S3.SS5.p2.3.m3.1.1.2" xref="S3.SS5.p2.3.m3.1.1.2.cmml">T</mi><mo id="S3.SS5.p2.3.m3.1.1.1" xref="S3.SS5.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS5.p2.3.m3.1.1.3" xref="S3.SS5.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.3.m3.1b"><apply id="S3.SS5.p2.3.m3.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1"><eq id="S3.SS5.p2.3.m3.1.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1.1"></eq><ci id="S3.SS5.p2.3.m3.1.1.2.cmml" xref="S3.SS5.p2.3.m3.1.1.2">𝑇</ci><cn id="S3.SS5.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS5.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.3.m3.1c">T=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.3.m3.1d">italic_T = 1</annotation></semantics></math>, all tokens are sampled in one step, <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.3">i.e.</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.4">one-step generation</span> like <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.1">As analyzed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">C.2</span></a>, for D-JEPA, adopting a more efficient next set-of-tokens prediction strategy often yields better results. Particularly, as the model scale increases, fewer auto-regressive steps are required. Additionally, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F5" title="Figure 5 ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>, one-step generation fails to produce high-quality images, which is a major reason for the subpar performance of MAE <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>. Even with just eight steps of iterative sampling, we can generate clearly recognizable content. This fully demonstrates that D-JEPA’s use of the next set of tokens prediction strategy is key to ensuring its strong generative capabilities.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<div class="ltx_listing ltx_listing" id="alg1.2">
<div class="ltx_listingline" id="alg0.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span><math alttext="T" class="ltx_Math" display="inline" id="alg0.l1.m1.1"><semantics id="alg0.l1.m1.1a"><mi id="alg0.l1.m1.1.1" xref="alg0.l1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg0.l1.m1.1b"><ci id="alg0.l1.m1.1.1.cmml" xref="alg0.l1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="alg0.l1.m1.1d">italic_T</annotation></semantics></math>: Number of auto-regressive steps, <math alttext="N" class="ltx_Math" display="inline" id="alg0.l1.m2.1"><semantics id="alg0.l1.m2.1a"><mi id="alg0.l1.m2.1.1" xref="alg0.l1.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg0.l1.m2.1b"><ci id="alg0.l1.m2.1.1.cmml" xref="alg0.l1.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l1.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="alg0.l1.m2.1d">italic_N</annotation></semantics></math>: Total tokens to sample, <math alttext="\tau" class="ltx_Math" display="inline" id="alg0.l1.m3.1"><semantics id="alg0.l1.m3.1a"><mi id="alg0.l1.m3.1.1" xref="alg0.l1.m3.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="alg0.l1.m3.1b"><ci id="alg0.l1.m3.1.1.cmml" xref="alg0.l1.m3.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l1.m3.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="alg0.l1.m3.1d">italic_τ</annotation></semantics></math>: Temperature to control noise.

</div>
<div class="ltx_listingline" id="alg0.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span><span class="ltx_text ltx_font_bold" id="alg0.l2.1">Initialize:</span> <math alttext="\mathbb{X}\leftarrow\emptyset" class="ltx_Math" display="inline" id="alg0.l2.m1.1"><semantics id="alg0.l2.m1.1a"><mrow id="alg0.l2.m1.1.1" xref="alg0.l2.m1.1.1.cmml"><mi id="alg0.l2.m1.1.1.2" xref="alg0.l2.m1.1.1.2.cmml">𝕏</mi><mo id="alg0.l2.m1.1.1.1" stretchy="false" xref="alg0.l2.m1.1.1.1.cmml">←</mo><mi id="alg0.l2.m1.1.1.3" mathvariant="normal" xref="alg0.l2.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="alg0.l2.m1.1b"><apply id="alg0.l2.m1.1.1.cmml" xref="alg0.l2.m1.1.1"><ci id="alg0.l2.m1.1.1.1.cmml" xref="alg0.l2.m1.1.1.1">←</ci><ci id="alg0.l2.m1.1.1.2.cmml" xref="alg0.l2.m1.1.1.2">𝕏</ci><emptyset id="alg0.l2.m1.1.1.3.cmml" xref="alg0.l2.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l2.m1.1c">\mathbb{X}\leftarrow\emptyset</annotation><annotation encoding="application/x-llamapun" id="alg0.l2.m1.1d">blackboard_X ← ∅</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg0.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span><span class="ltx_text ltx_font_bold" id="alg0.l3.1">for</span> <math alttext="n" class="ltx_Math" display="inline" id="alg0.l3.m1.1"><semantics id="alg0.l3.m1.1a"><mi id="alg0.l3.m1.1.1" xref="alg0.l3.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg0.l3.m1.1b"><ci id="alg0.l3.m1.1.1.cmml" xref="alg0.l3.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l3.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="alg0.l3.m1.1d">italic_n</annotation></semantics></math> in <math alttext="\text{cosine-step-function}(T,N)" class="ltx_Math" display="inline" id="alg0.l3.m2.2"><semantics id="alg0.l3.m2.2a"><mrow id="alg0.l3.m2.2.3" xref="alg0.l3.m2.2.3.cmml"><mtext id="alg0.l3.m2.2.3.2" xref="alg0.l3.m2.2.3.2a.cmml">cosine-step-function</mtext><mo id="alg0.l3.m2.2.3.1" xref="alg0.l3.m2.2.3.1.cmml">⁢</mo><mrow id="alg0.l3.m2.2.3.3.2" xref="alg0.l3.m2.2.3.3.1.cmml"><mo id="alg0.l3.m2.2.3.3.2.1" stretchy="false" xref="alg0.l3.m2.2.3.3.1.cmml">(</mo><mi id="alg0.l3.m2.1.1" xref="alg0.l3.m2.1.1.cmml">T</mi><mo id="alg0.l3.m2.2.3.3.2.2" xref="alg0.l3.m2.2.3.3.1.cmml">,</mo><mi id="alg0.l3.m2.2.2" xref="alg0.l3.m2.2.2.cmml">N</mi><mo id="alg0.l3.m2.2.3.3.2.3" stretchy="false" xref="alg0.l3.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l3.m2.2b"><apply id="alg0.l3.m2.2.3.cmml" xref="alg0.l3.m2.2.3"><times id="alg0.l3.m2.2.3.1.cmml" xref="alg0.l3.m2.2.3.1"></times><ci id="alg0.l3.m2.2.3.2a.cmml" xref="alg0.l3.m2.2.3.2"><mtext id="alg0.l3.m2.2.3.2.cmml" xref="alg0.l3.m2.2.3.2">cosine-step-function</mtext></ci><interval closure="open" id="alg0.l3.m2.2.3.3.1.cmml" xref="alg0.l3.m2.2.3.3.2"><ci id="alg0.l3.m2.1.1.cmml" xref="alg0.l3.m2.1.1">𝑇</ci><ci id="alg0.l3.m2.2.2.cmml" xref="alg0.l3.m2.2.2">𝑁</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l3.m2.2c">\text{cosine-step-function}(T,N)</annotation><annotation encoding="application/x-llamapun" id="alg0.l3.m2.2d">cosine-step-function ( italic_T , italic_N )</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg0.l3.2">do</span>
</div>
<div class="ltx_listingline" id="alg0.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>     <math alttext="\mathbb{C}\leftarrow\phi(\mathbb{X})" class="ltx_Math" display="inline" id="alg0.l4.m1.1"><semantics id="alg0.l4.m1.1a"><mrow id="alg0.l4.m1.1.2" xref="alg0.l4.m1.1.2.cmml"><mi id="alg0.l4.m1.1.2.2" xref="alg0.l4.m1.1.2.2.cmml">ℂ</mi><mo id="alg0.l4.m1.1.2.1" stretchy="false" xref="alg0.l4.m1.1.2.1.cmml">←</mo><mrow id="alg0.l4.m1.1.2.3" xref="alg0.l4.m1.1.2.3.cmml"><mi id="alg0.l4.m1.1.2.3.2" xref="alg0.l4.m1.1.2.3.2.cmml">ϕ</mi><mo id="alg0.l4.m1.1.2.3.1" xref="alg0.l4.m1.1.2.3.1.cmml">⁢</mo><mrow id="alg0.l4.m1.1.2.3.3.2" xref="alg0.l4.m1.1.2.3.cmml"><mo id="alg0.l4.m1.1.2.3.3.2.1" stretchy="false" xref="alg0.l4.m1.1.2.3.cmml">(</mo><mi id="alg0.l4.m1.1.1" xref="alg0.l4.m1.1.1.cmml">𝕏</mi><mo id="alg0.l4.m1.1.2.3.3.2.2" stretchy="false" xref="alg0.l4.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l4.m1.1b"><apply id="alg0.l4.m1.1.2.cmml" xref="alg0.l4.m1.1.2"><ci id="alg0.l4.m1.1.2.1.cmml" xref="alg0.l4.m1.1.2.1">←</ci><ci id="alg0.l4.m1.1.2.2.cmml" xref="alg0.l4.m1.1.2.2">ℂ</ci><apply id="alg0.l4.m1.1.2.3.cmml" xref="alg0.l4.m1.1.2.3"><times id="alg0.l4.m1.1.2.3.1.cmml" xref="alg0.l4.m1.1.2.3.1"></times><ci id="alg0.l4.m1.1.2.3.2.cmml" xref="alg0.l4.m1.1.2.3.2">italic-ϕ</ci><ci id="alg0.l4.m1.1.1.cmml" xref="alg0.l4.m1.1.1">𝕏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l4.m1.1c">\mathbb{C}\leftarrow\phi(\mathbb{X})</annotation><annotation encoding="application/x-llamapun" id="alg0.l4.m1.1d">blackboard_C ← italic_ϕ ( blackboard_X )</annotation></semantics></math> <span class="ltx_text" id="alg0.l4.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l4.1.m1.1"><semantics id="alg0.l4.1.m1.1a"><mo id="alg0.l4.1.m1.1.1" xref="alg0.l4.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg0.l4.1.m1.1b"><ci id="alg0.l4.1.m1.1.1.cmml" xref="alg0.l4.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l4.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l4.1.m1.1d">▷</annotation></semantics></math> Encode the sampled tokens to obtain context features
</span>
</div>
<div class="ltx_listingline" id="alg0.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>     <math alttext="\mathbb{Z}\leftarrow\gamma(\mathbb{C})" class="ltx_Math" display="inline" id="alg0.l5.m1.1"><semantics id="alg0.l5.m1.1a"><mrow id="alg0.l5.m1.1.2" xref="alg0.l5.m1.1.2.cmml"><mi id="alg0.l5.m1.1.2.2" xref="alg0.l5.m1.1.2.2.cmml">ℤ</mi><mo id="alg0.l5.m1.1.2.1" stretchy="false" xref="alg0.l5.m1.1.2.1.cmml">←</mo><mrow id="alg0.l5.m1.1.2.3" xref="alg0.l5.m1.1.2.3.cmml"><mi id="alg0.l5.m1.1.2.3.2" xref="alg0.l5.m1.1.2.3.2.cmml">γ</mi><mo id="alg0.l5.m1.1.2.3.1" xref="alg0.l5.m1.1.2.3.1.cmml">⁢</mo><mrow id="alg0.l5.m1.1.2.3.3.2" xref="alg0.l5.m1.1.2.3.cmml"><mo id="alg0.l5.m1.1.2.3.3.2.1" stretchy="false" xref="alg0.l5.m1.1.2.3.cmml">(</mo><mi id="alg0.l5.m1.1.1" xref="alg0.l5.m1.1.1.cmml">ℂ</mi><mo id="alg0.l5.m1.1.2.3.3.2.2" stretchy="false" xref="alg0.l5.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l5.m1.1b"><apply id="alg0.l5.m1.1.2.cmml" xref="alg0.l5.m1.1.2"><ci id="alg0.l5.m1.1.2.1.cmml" xref="alg0.l5.m1.1.2.1">←</ci><ci id="alg0.l5.m1.1.2.2.cmml" xref="alg0.l5.m1.1.2.2">ℤ</ci><apply id="alg0.l5.m1.1.2.3.cmml" xref="alg0.l5.m1.1.2.3"><times id="alg0.l5.m1.1.2.3.1.cmml" xref="alg0.l5.m1.1.2.3.1"></times><ci id="alg0.l5.m1.1.2.3.2.cmml" xref="alg0.l5.m1.1.2.3.2">𝛾</ci><ci id="alg0.l5.m1.1.1.cmml" xref="alg0.l5.m1.1.1">ℂ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l5.m1.1c">\mathbb{Z}\leftarrow\gamma(\mathbb{C})</annotation><annotation encoding="application/x-llamapun" id="alg0.l5.m1.1d">blackboard_Z ← italic_γ ( blackboard_C )</annotation></semantics></math> <span class="ltx_text" id="alg0.l5.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l5.1.m1.1"><semantics id="alg0.l5.1.m1.1a"><mo id="alg0.l5.1.m1.1.1" xref="alg0.l5.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg0.l5.1.m1.1b"><ci id="alg0.l5.1.m1.1.1.cmml" xref="alg0.l5.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l5.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l5.1.m1.1d">▷</annotation></semantics></math> Predict features of unsampled tokens using the feature predictor
</span>
</div>
<div class="ltx_listingline" id="alg0.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span>     <math alttext="\{z_{0},\ldots,z_{n}\}\sim\mathbb{Z}" class="ltx_Math" display="inline" id="alg0.l6.m1.3"><semantics id="alg0.l6.m1.3a"><mrow id="alg0.l6.m1.3.3" xref="alg0.l6.m1.3.3.cmml"><mrow id="alg0.l6.m1.3.3.2.2" xref="alg0.l6.m1.3.3.2.3.cmml"><mo id="alg0.l6.m1.3.3.2.2.3" stretchy="false" xref="alg0.l6.m1.3.3.2.3.cmml">{</mo><msub id="alg0.l6.m1.2.2.1.1.1" xref="alg0.l6.m1.2.2.1.1.1.cmml"><mi id="alg0.l6.m1.2.2.1.1.1.2" xref="alg0.l6.m1.2.2.1.1.1.2.cmml">z</mi><mn id="alg0.l6.m1.2.2.1.1.1.3" xref="alg0.l6.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="alg0.l6.m1.3.3.2.2.4" xref="alg0.l6.m1.3.3.2.3.cmml">,</mo><mi id="alg0.l6.m1.1.1" mathvariant="normal" xref="alg0.l6.m1.1.1.cmml">…</mi><mo id="alg0.l6.m1.3.3.2.2.5" xref="alg0.l6.m1.3.3.2.3.cmml">,</mo><msub id="alg0.l6.m1.3.3.2.2.2" xref="alg0.l6.m1.3.3.2.2.2.cmml"><mi id="alg0.l6.m1.3.3.2.2.2.2" xref="alg0.l6.m1.3.3.2.2.2.2.cmml">z</mi><mi id="alg0.l6.m1.3.3.2.2.2.3" xref="alg0.l6.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l6.m1.3.3.2.2.6" stretchy="false" xref="alg0.l6.m1.3.3.2.3.cmml">}</mo></mrow><mo id="alg0.l6.m1.3.3.3" xref="alg0.l6.m1.3.3.3.cmml">∼</mo><mi id="alg0.l6.m1.3.3.4" xref="alg0.l6.m1.3.3.4.cmml">ℤ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg0.l6.m1.3b"><apply id="alg0.l6.m1.3.3.cmml" xref="alg0.l6.m1.3.3"><csymbol cd="latexml" id="alg0.l6.m1.3.3.3.cmml" xref="alg0.l6.m1.3.3.3">similar-to</csymbol><set id="alg0.l6.m1.3.3.2.3.cmml" xref="alg0.l6.m1.3.3.2.2"><apply id="alg0.l6.m1.2.2.1.1.1.cmml" xref="alg0.l6.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg0.l6.m1.2.2.1.1.1.1.cmml" xref="alg0.l6.m1.2.2.1.1.1">subscript</csymbol><ci id="alg0.l6.m1.2.2.1.1.1.2.cmml" xref="alg0.l6.m1.2.2.1.1.1.2">𝑧</ci><cn id="alg0.l6.m1.2.2.1.1.1.3.cmml" type="integer" xref="alg0.l6.m1.2.2.1.1.1.3">0</cn></apply><ci id="alg0.l6.m1.1.1.cmml" xref="alg0.l6.m1.1.1">…</ci><apply id="alg0.l6.m1.3.3.2.2.2.cmml" xref="alg0.l6.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg0.l6.m1.3.3.2.2.2.1.cmml" xref="alg0.l6.m1.3.3.2.2.2">subscript</csymbol><ci id="alg0.l6.m1.3.3.2.2.2.2.cmml" xref="alg0.l6.m1.3.3.2.2.2.2">𝑧</ci><ci id="alg0.l6.m1.3.3.2.2.2.3.cmml" xref="alg0.l6.m1.3.3.2.2.2.3">𝑛</ci></apply></set><ci id="alg0.l6.m1.3.3.4.cmml" xref="alg0.l6.m1.3.3.4">ℤ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.m1.3c">\{z_{0},\ldots,z_{n}\}\sim\mathbb{Z}</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.m1.3d">{ italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } ∼ blackboard_Z</annotation></semantics></math> <span class="ltx_text" id="alg0.l6.3" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l6.1.m1.1"><semantics id="alg0.l6.1.m1.1a"><mo id="alg0.l6.1.m1.1.1" xref="alg0.l6.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg0.l6.1.m1.1b"><ci id="alg0.l6.1.m1.1.1.cmml" xref="alg0.l6.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.1.m1.1d">▷</annotation></semantics></math> Randomly select <math alttext="n" class="ltx_Math" display="inline" id="alg0.l6.2.m2.1"><semantics id="alg0.l6.2.m2.1a"><mi id="alg0.l6.2.m2.1.1" xref="alg0.l6.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg0.l6.2.m2.1b"><ci id="alg0.l6.2.m2.1.1.cmml" xref="alg0.l6.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.2.m2.1d">italic_n</annotation></semantics></math> tokens from <math alttext="\mathbb{Z}" class="ltx_Math" display="inline" id="alg0.l6.3.m3.1"><semantics id="alg0.l6.3.m3.1a"><mi id="alg0.l6.3.m3.1.1" xref="alg0.l6.3.m3.1.1.cmml">ℤ</mi><annotation-xml encoding="MathML-Content" id="alg0.l6.3.m3.1b"><ci id="alg0.l6.3.m3.1.1.cmml" xref="alg0.l6.3.m3.1.1">ℤ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.3.m3.1c">\mathbb{Z}</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.3.m3.1d">blackboard_Z</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="alg0.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>     <math alttext="\{x_{0},\ldots,x_{n}\}\leftarrow\text{denoise}(\epsilon_{\theta},\{z_{0},%
\ldots,z_{n}\},\tau)" class="ltx_Math" display="inline" id="alg0.l7.m1.7"><semantics id="alg0.l7.m1.7a"><mrow id="alg0.l7.m1.7.7" xref="alg0.l7.m1.7.7.cmml"><mrow id="alg0.l7.m1.5.5.2.2" xref="alg0.l7.m1.5.5.2.3.cmml"><mo id="alg0.l7.m1.5.5.2.2.3" stretchy="false" xref="alg0.l7.m1.5.5.2.3.cmml">{</mo><msub id="alg0.l7.m1.4.4.1.1.1" xref="alg0.l7.m1.4.4.1.1.1.cmml"><mi id="alg0.l7.m1.4.4.1.1.1.2" xref="alg0.l7.m1.4.4.1.1.1.2.cmml">x</mi><mn id="alg0.l7.m1.4.4.1.1.1.3" xref="alg0.l7.m1.4.4.1.1.1.3.cmml">0</mn></msub><mo id="alg0.l7.m1.5.5.2.2.4" xref="alg0.l7.m1.5.5.2.3.cmml">,</mo><mi id="alg0.l7.m1.1.1" mathvariant="normal" xref="alg0.l7.m1.1.1.cmml">…</mi><mo id="alg0.l7.m1.5.5.2.2.5" xref="alg0.l7.m1.5.5.2.3.cmml">,</mo><msub id="alg0.l7.m1.5.5.2.2.2" xref="alg0.l7.m1.5.5.2.2.2.cmml"><mi id="alg0.l7.m1.5.5.2.2.2.2" xref="alg0.l7.m1.5.5.2.2.2.2.cmml">x</mi><mi id="alg0.l7.m1.5.5.2.2.2.3" xref="alg0.l7.m1.5.5.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l7.m1.5.5.2.2.6" stretchy="false" xref="alg0.l7.m1.5.5.2.3.cmml">}</mo></mrow><mo id="alg0.l7.m1.7.7.5" stretchy="false" xref="alg0.l7.m1.7.7.5.cmml">←</mo><mrow id="alg0.l7.m1.7.7.4" xref="alg0.l7.m1.7.7.4.cmml"><mtext id="alg0.l7.m1.7.7.4.4" xref="alg0.l7.m1.7.7.4.4a.cmml">denoise</mtext><mo id="alg0.l7.m1.7.7.4.3" xref="alg0.l7.m1.7.7.4.3.cmml">⁢</mo><mrow id="alg0.l7.m1.7.7.4.2.2" xref="alg0.l7.m1.7.7.4.2.3.cmml"><mo id="alg0.l7.m1.7.7.4.2.2.3" stretchy="false" xref="alg0.l7.m1.7.7.4.2.3.cmml">(</mo><msub id="alg0.l7.m1.6.6.3.1.1.1" xref="alg0.l7.m1.6.6.3.1.1.1.cmml"><mi id="alg0.l7.m1.6.6.3.1.1.1.2" xref="alg0.l7.m1.6.6.3.1.1.1.2.cmml">ϵ</mi><mi id="alg0.l7.m1.6.6.3.1.1.1.3" xref="alg0.l7.m1.6.6.3.1.1.1.3.cmml">θ</mi></msub><mo id="alg0.l7.m1.7.7.4.2.2.4" xref="alg0.l7.m1.7.7.4.2.3.cmml">,</mo><mrow id="alg0.l7.m1.7.7.4.2.2.2.2" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml"><mo id="alg0.l7.m1.7.7.4.2.2.2.2.3" stretchy="false" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">{</mo><msub id="alg0.l7.m1.7.7.4.2.2.2.1.1" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.cmml"><mi id="alg0.l7.m1.7.7.4.2.2.2.1.1.2" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.2.cmml">z</mi><mn id="alg0.l7.m1.7.7.4.2.2.2.1.1.3" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.3.cmml">0</mn></msub><mo id="alg0.l7.m1.7.7.4.2.2.2.2.4" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">,</mo><mi id="alg0.l7.m1.2.2" mathvariant="normal" xref="alg0.l7.m1.2.2.cmml">…</mi><mo id="alg0.l7.m1.7.7.4.2.2.2.2.5" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">,</mo><msub id="alg0.l7.m1.7.7.4.2.2.2.2.2" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.cmml"><mi id="alg0.l7.m1.7.7.4.2.2.2.2.2.2" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.2.cmml">z</mi><mi id="alg0.l7.m1.7.7.4.2.2.2.2.2.3" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l7.m1.7.7.4.2.2.2.2.6" stretchy="false" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">}</mo></mrow><mo id="alg0.l7.m1.7.7.4.2.2.5" xref="alg0.l7.m1.7.7.4.2.3.cmml">,</mo><mi id="alg0.l7.m1.3.3" xref="alg0.l7.m1.3.3.cmml">τ</mi><mo id="alg0.l7.m1.7.7.4.2.2.6" stretchy="false" xref="alg0.l7.m1.7.7.4.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l7.m1.7b"><apply id="alg0.l7.m1.7.7.cmml" xref="alg0.l7.m1.7.7"><ci id="alg0.l7.m1.7.7.5.cmml" xref="alg0.l7.m1.7.7.5">←</ci><set id="alg0.l7.m1.5.5.2.3.cmml" xref="alg0.l7.m1.5.5.2.2"><apply id="alg0.l7.m1.4.4.1.1.1.cmml" xref="alg0.l7.m1.4.4.1.1.1"><csymbol cd="ambiguous" id="alg0.l7.m1.4.4.1.1.1.1.cmml" xref="alg0.l7.m1.4.4.1.1.1">subscript</csymbol><ci id="alg0.l7.m1.4.4.1.1.1.2.cmml" xref="alg0.l7.m1.4.4.1.1.1.2">𝑥</ci><cn id="alg0.l7.m1.4.4.1.1.1.3.cmml" type="integer" xref="alg0.l7.m1.4.4.1.1.1.3">0</cn></apply><ci id="alg0.l7.m1.1.1.cmml" xref="alg0.l7.m1.1.1">…</ci><apply id="alg0.l7.m1.5.5.2.2.2.cmml" xref="alg0.l7.m1.5.5.2.2.2"><csymbol cd="ambiguous" id="alg0.l7.m1.5.5.2.2.2.1.cmml" xref="alg0.l7.m1.5.5.2.2.2">subscript</csymbol><ci id="alg0.l7.m1.5.5.2.2.2.2.cmml" xref="alg0.l7.m1.5.5.2.2.2.2">𝑥</ci><ci id="alg0.l7.m1.5.5.2.2.2.3.cmml" xref="alg0.l7.m1.5.5.2.2.2.3">𝑛</ci></apply></set><apply id="alg0.l7.m1.7.7.4.cmml" xref="alg0.l7.m1.7.7.4"><times id="alg0.l7.m1.7.7.4.3.cmml" xref="alg0.l7.m1.7.7.4.3"></times><ci id="alg0.l7.m1.7.7.4.4a.cmml" xref="alg0.l7.m1.7.7.4.4"><mtext id="alg0.l7.m1.7.7.4.4.cmml" xref="alg0.l7.m1.7.7.4.4">denoise</mtext></ci><vector id="alg0.l7.m1.7.7.4.2.3.cmml" xref="alg0.l7.m1.7.7.4.2.2"><apply id="alg0.l7.m1.6.6.3.1.1.1.cmml" xref="alg0.l7.m1.6.6.3.1.1.1"><csymbol cd="ambiguous" id="alg0.l7.m1.6.6.3.1.1.1.1.cmml" xref="alg0.l7.m1.6.6.3.1.1.1">subscript</csymbol><ci id="alg0.l7.m1.6.6.3.1.1.1.2.cmml" xref="alg0.l7.m1.6.6.3.1.1.1.2">italic-ϵ</ci><ci id="alg0.l7.m1.6.6.3.1.1.1.3.cmml" xref="alg0.l7.m1.6.6.3.1.1.1.3">𝜃</ci></apply><set id="alg0.l7.m1.7.7.4.2.2.2.3.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2"><apply id="alg0.l7.m1.7.7.4.2.2.2.1.1.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.1.1"><csymbol cd="ambiguous" id="alg0.l7.m1.7.7.4.2.2.2.1.1.1.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.1.1">subscript</csymbol><ci id="alg0.l7.m1.7.7.4.2.2.2.1.1.2.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.2">𝑧</ci><cn id="alg0.l7.m1.7.7.4.2.2.2.1.1.3.cmml" type="integer" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.3">0</cn></apply><ci id="alg0.l7.m1.2.2.cmml" xref="alg0.l7.m1.2.2">…</ci><apply id="alg0.l7.m1.7.7.4.2.2.2.2.2.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2"><csymbol cd="ambiguous" id="alg0.l7.m1.7.7.4.2.2.2.2.2.1.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2">subscript</csymbol><ci id="alg0.l7.m1.7.7.4.2.2.2.2.2.2.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.2">𝑧</ci><ci id="alg0.l7.m1.7.7.4.2.2.2.2.2.3.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.3">𝑛</ci></apply></set><ci id="alg0.l7.m1.3.3.cmml" xref="alg0.l7.m1.3.3">𝜏</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l7.m1.7c">\{x_{0},\ldots,x_{n}\}\leftarrow\text{denoise}(\epsilon_{\theta},\{z_{0},%
\ldots,z_{n}\},\tau)</annotation><annotation encoding="application/x-llamapun" id="alg0.l7.m1.7d">{ italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } ← denoise ( italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT , { italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , italic_τ )</annotation></semantics></math> <span class="ltx_text" id="alg0.l7.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l7.1.m1.1"><semantics id="alg0.l7.1.m1.1a"><mo id="alg0.l7.1.m1.1.1" xref="alg0.l7.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg0.l7.1.m1.1b"><ci id="alg0.l7.1.m1.1.1.cmml" xref="alg0.l7.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l7.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l7.1.m1.1d">▷</annotation></semantics></math> Perform denoising on the selected tokens
</span>
</div>
<div class="ltx_listingline" id="alg0.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>     <math alttext="\mathbb{X}\leftarrow\mathbb{X}\cup\{x_{0},\ldots,x_{n}\}" class="ltx_Math" display="inline" id="alg0.l8.m1.3"><semantics id="alg0.l8.m1.3a"><mrow id="alg0.l8.m1.3.3" xref="alg0.l8.m1.3.3.cmml"><mi id="alg0.l8.m1.3.3.4" xref="alg0.l8.m1.3.3.4.cmml">𝕏</mi><mo id="alg0.l8.m1.3.3.3" stretchy="false" xref="alg0.l8.m1.3.3.3.cmml">←</mo><mrow id="alg0.l8.m1.3.3.2" xref="alg0.l8.m1.3.3.2.cmml"><mi id="alg0.l8.m1.3.3.2.4" xref="alg0.l8.m1.3.3.2.4.cmml">𝕏</mi><mo id="alg0.l8.m1.3.3.2.3" xref="alg0.l8.m1.3.3.2.3.cmml">∪</mo><mrow id="alg0.l8.m1.3.3.2.2.2" xref="alg0.l8.m1.3.3.2.2.3.cmml"><mo id="alg0.l8.m1.3.3.2.2.2.3" stretchy="false" xref="alg0.l8.m1.3.3.2.2.3.cmml">{</mo><msub id="alg0.l8.m1.2.2.1.1.1.1" xref="alg0.l8.m1.2.2.1.1.1.1.cmml"><mi id="alg0.l8.m1.2.2.1.1.1.1.2" xref="alg0.l8.m1.2.2.1.1.1.1.2.cmml">x</mi><mn id="alg0.l8.m1.2.2.1.1.1.1.3" xref="alg0.l8.m1.2.2.1.1.1.1.3.cmml">0</mn></msub><mo id="alg0.l8.m1.3.3.2.2.2.4" xref="alg0.l8.m1.3.3.2.2.3.cmml">,</mo><mi id="alg0.l8.m1.1.1" mathvariant="normal" xref="alg0.l8.m1.1.1.cmml">…</mi><mo id="alg0.l8.m1.3.3.2.2.2.5" xref="alg0.l8.m1.3.3.2.2.3.cmml">,</mo><msub id="alg0.l8.m1.3.3.2.2.2.2" xref="alg0.l8.m1.3.3.2.2.2.2.cmml"><mi id="alg0.l8.m1.3.3.2.2.2.2.2" xref="alg0.l8.m1.3.3.2.2.2.2.2.cmml">x</mi><mi id="alg0.l8.m1.3.3.2.2.2.2.3" xref="alg0.l8.m1.3.3.2.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l8.m1.3.3.2.2.2.6" stretchy="false" xref="alg0.l8.m1.3.3.2.2.3.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l8.m1.3b"><apply id="alg0.l8.m1.3.3.cmml" xref="alg0.l8.m1.3.3"><ci id="alg0.l8.m1.3.3.3.cmml" xref="alg0.l8.m1.3.3.3">←</ci><ci id="alg0.l8.m1.3.3.4.cmml" xref="alg0.l8.m1.3.3.4">𝕏</ci><apply id="alg0.l8.m1.3.3.2.cmml" xref="alg0.l8.m1.3.3.2"><union id="alg0.l8.m1.3.3.2.3.cmml" xref="alg0.l8.m1.3.3.2.3"></union><ci id="alg0.l8.m1.3.3.2.4.cmml" xref="alg0.l8.m1.3.3.2.4">𝕏</ci><set id="alg0.l8.m1.3.3.2.2.3.cmml" xref="alg0.l8.m1.3.3.2.2.2"><apply id="alg0.l8.m1.2.2.1.1.1.1.cmml" xref="alg0.l8.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg0.l8.m1.2.2.1.1.1.1.1.cmml" xref="alg0.l8.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg0.l8.m1.2.2.1.1.1.1.2.cmml" xref="alg0.l8.m1.2.2.1.1.1.1.2">𝑥</ci><cn id="alg0.l8.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="alg0.l8.m1.2.2.1.1.1.1.3">0</cn></apply><ci id="alg0.l8.m1.1.1.cmml" xref="alg0.l8.m1.1.1">…</ci><apply id="alg0.l8.m1.3.3.2.2.2.2.cmml" xref="alg0.l8.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg0.l8.m1.3.3.2.2.2.2.1.cmml" xref="alg0.l8.m1.3.3.2.2.2.2">subscript</csymbol><ci id="alg0.l8.m1.3.3.2.2.2.2.2.cmml" xref="alg0.l8.m1.3.3.2.2.2.2.2">𝑥</ci><ci id="alg0.l8.m1.3.3.2.2.2.2.3.cmml" xref="alg0.l8.m1.3.3.2.2.2.2.3">𝑛</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l8.m1.3c">\mathbb{X}\leftarrow\mathbb{X}\cup\{x_{0},\ldots,x_{n}\}</annotation><annotation encoding="application/x-llamapun" id="alg0.l8.m1.3d">blackboard_X ← blackboard_X ∪ { italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> <span class="ltx_text" id="alg0.l8.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l8.1.m1.1"><semantics id="alg0.l8.1.m1.1a"><mo id="alg0.l8.1.m1.1.1" xref="alg0.l8.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg0.l8.1.m1.1b"><ci id="alg0.l8.1.m1.1.1.cmml" xref="alg0.l8.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l8.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l8.1.m1.1d">▷</annotation></semantics></math> Add the denoised tokens to <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="alg0.l8.2.m2.1"><semantics id="alg0.l8.2.m2.1a"><mi id="alg0.l8.2.m2.1.1" xref="alg0.l8.2.m2.1.1.cmml">𝕏</mi><annotation-xml encoding="MathML-Content" id="alg0.l8.2.m2.1b"><ci id="alg0.l8.2.m2.1.1.cmml" xref="alg0.l8.2.m2.1.1">𝕏</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l8.2.m2.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="alg0.l8.2.m2.1d">blackboard_X</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="alg0.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span><span class="ltx_text ltx_font_bold" id="alg0.l9.1">end</span> <span class="ltx_text ltx_font_bold" id="alg0.l9.2">for</span>
</div>
<div class="ltx_listingline" id="alg0.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span><span class="ltx_text ltx_font_bold" id="alg0.l10.1">Return:</span> <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="alg0.l10.m1.1"><semantics id="alg0.l10.m1.1a"><mi id="alg0.l10.m1.1.1" xref="alg0.l10.m1.1.1.cmml">𝕏</mi><annotation-xml encoding="MathML-Content" id="alg0.l10.m1.1b"><ci id="alg0.l10.m1.1.1.cmml" xref="alg0.l10.m1.1.1">𝕏</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l10.m1.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="alg0.l10.m1.1d">blackboard_X</annotation></semantics></math>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.3.1.1">Algorithm 1</span> </span> Generalized next token prediction with D-JEPA</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To evaluate D-JEPA’s generative performance, we conduct experiments on the ImageNet-1K dataset <cite class="ltx_cite ltx_citemacro_cite">Russakovsky et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib90" title="">2015</a>)</cite> for the task of class-conditional image generation. Please refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2" title="Appendix B Experimental Setup ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">B</span></a> for detailed experimental settings.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Image Synthetis</h3>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.5">
<tr class="ltx_tr" id="S4.T1.4.4">
<td class="ltx_td ltx_border_r" id="S4.T1.4.4.5"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.4.6">#Params</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.4.7">#Epochs</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.1">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.2.2">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.m1.1a"><mo id="S4.T1.2.2.2.m1.1.1" stretchy="false" xref="S4.T1.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.m1.1.1" stretchy="false" xref="S4.T1.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.4">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.4.4.4.m1.1"><semantics id="S4.T1.4.4.4.m1.1a"><mo id="S4.T1.4.4.4.m1.1.1" stretchy="false" xref="S4.T1.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.4.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.6" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="7" id="S4.T1.5.6.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T1.5.6.1.1" style="background-color:#EFEFEF;">Base scale model (less than 300M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.7.1">MAR-B <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.7.2">208M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.7.3">800</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.7.4">3.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.7.5">192.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.7.6">0.78</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.7.7">0.58</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.8.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.8.1.1" style="background-color:#ECF4FF;">D-JEPA-B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.8.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.8.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.8.3"><span class="ltx_text" id="S4.T1.5.8.3.1" style="background-color:#ECF4FF;">1400</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.8.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.8.4.1" style="background-color:#ECF4FF;">3.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.8.5" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.8.5.1" style="background-color:#ECF4FF;">197.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.8.6"><span class="ltx_text" id="S4.T1.5.8.6.1" style="background-color:#ECF4FF;">0.77</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.8.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.8.7.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.9.1">MaskGIT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.9.2">227M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.3">300</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4">6.18</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.5">182.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.9.6.1">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.7">0.51</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.10.1">MAGE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.10.2">230M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.3">1600</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.4">6.93</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.5">195.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="7" id="S4.T1.5.5.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T1.5.5.1.1" style="background-color:#EFEFEF;">Large scale model (300<math alttext="\sim" class="ltx_Math" display="inline" id="S4.T1.5.5.1.1.m1.1" style="background-color:#EFEFEF;"><semantics id="S4.T1.5.5.1.1.m1.1a"><mo id="S4.T1.5.5.1.1.m1.1.1" mathbackground="#EFEFEF" xref="S4.T1.5.5.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.5.5.1.1.m1.1.1.cmml" xref="S4.T1.5.5.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.1.1.m1.1d">∼</annotation></semantics></math>700M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.11.1">GIVT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.11.2">304M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.3">500</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.4">5.67</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6">0.75</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.7">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.12.1">MAGVIT-v2 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.12.2">307M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.3">1080</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.4">3.65</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.5">200.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.13.1">MAR-L <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.13.2">479M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.13.3">800</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.13.4">2.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.13.5">221.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.13.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.13.6.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.13.7">0.60</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.14.1">DiT-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.14.2">675M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.14.3">1400</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.14.4">9.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.14.5">121.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.14.6">0.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.14.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.14.7.1">0.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.15.1">SiT-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.15.2">675M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.15.3">1400</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.15.4">8.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.15.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.15.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.15.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.16.1">MDTv2-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.16.2">676M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.16.3">400</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.16.4">5.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.16.5">155.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.16.6">0.72</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.16.7">0.66</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.17" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.17.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.17.1.1" style="background-color:#ECF4FF;">D-JEPA-L</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.17.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.17.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.17.3"><span class="ltx_text" id="S4.T1.5.17.3.1" style="background-color:#ECF4FF;">480</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.17.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.17.4.1" style="background-color:#ECF4FF;">2.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.17.5" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.17.5.1" style="background-color:#ECF4FF;">233.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.17.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.17.6.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.17.7"><span class="ltx_text" id="S4.T1.5.17.7.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.18" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="7" id="S4.T1.5.18.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T1.5.18.1.1" style="background-color:#EFEFEF;">Huge scale model (900+M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.19">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.19.1">MAR-H <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.19.2">943M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.19.3">800</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.19.4">2.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.19.5">227.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.19.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.19.6.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.19.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.19.7.1">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.20" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.20.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.20.1.1" style="background-color:#ECF4FF;">D-JEPA-H</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.20.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.20.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.20.3"><span class="ltx_text" id="S4.T1.5.20.3.1" style="background-color:#ECF4FF;">320</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.20.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.4.1" style="background-color:#ECF4FF;">2.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.20.5" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.5.1" style="background-color:#ECF4FF;">239.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.20.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.6.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.20.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.7.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.21.1">VDM++ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib57" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.21.2">2.0B</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.21.3">1120</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.21.4">2.40</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.21.5">225.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.21.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.21.7">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>System-level comparison on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="S4.T1.7.m1.1"><semantics id="S4.T1.7.m1.1b"><mrow id="S4.T1.7.m1.1.1" xref="S4.T1.7.m1.1.1.cmml"><mn id="S4.T1.7.m1.1.1.2" xref="S4.T1.7.m1.1.1.2.cmml">256</mn><mo id="S4.T1.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.T1.7.m1.1.1.1.cmml">×</mo><mn id="S4.T1.7.m1.1.1.3" xref="S4.T1.7.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.m1.1c"><apply id="S4.T1.7.m1.1.1.cmml" xref="S4.T1.7.m1.1.1"><times id="S4.T1.7.m1.1.1.1.cmml" xref="S4.T1.7.m1.1.1.1"></times><cn id="S4.T1.7.m1.1.1.2.cmml" type="integer" xref="S4.T1.7.m1.1.1.2">256</cn><cn id="S4.T1.7.m1.1.1.3.cmml" type="integer" xref="S4.T1.7.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.m1.1e">256 × 256</annotation></semantics></math> conditional generation <span class="ltx_text ltx_font_italic" id="S4.T1.9.1">without</span> classifier-free guidance. For ease of comparison, we have omitted earlier works with FID greater than 10. A more detailed table can be found in the appendix.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F2.7">
<tr class="ltx_tr" id="S4.F2.7.7">
<td class="ltx_td ltx_align_center" id="S4.F2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="269" id="S4.F2.1.1.1.g1" src="x2.png" width="448"/></td>
<td class="ltx_td ltx_align_center" id="S4.F2.7.7.7">
<div class="ltx_block ltx_parbox ltx_align_bottom" id="S4.F2.7.7.7.6" style="width:173.4pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_block">Figure 2: </span>FID <span class="ltx_text ltx_font_italic" id="S4.F2.7.7.7.6.8.1">vs</span>. IS under different sampling efficiencies. We can achieve <math alttext="\text{FID}\approx 4.0" class="ltx_Math" display="inline" id="S4.F2.5.5.5.4.4.m1.1"><semantics id="S4.F2.5.5.5.4.4.m1.1a"><mrow id="S4.F2.5.5.5.4.4.m1.1.1" xref="S4.F2.5.5.5.4.4.m1.1.1.cmml"><mtext id="S4.F2.5.5.5.4.4.m1.1.1.2" xref="S4.F2.5.5.5.4.4.m1.1.1.2a.cmml">FID</mtext><mo id="S4.F2.5.5.5.4.4.m1.1.1.1" xref="S4.F2.5.5.5.4.4.m1.1.1.1.cmml">≈</mo><mn id="S4.F2.5.5.5.4.4.m1.1.1.3" xref="S4.F2.5.5.5.4.4.m1.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.5.5.5.4.4.m1.1b"><apply id="S4.F2.5.5.5.4.4.m1.1.1.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1"><approx id="S4.F2.5.5.5.4.4.m1.1.1.1.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1.1"></approx><ci id="S4.F2.5.5.5.4.4.m1.1.1.2a.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1.2"><mtext id="S4.F2.5.5.5.4.4.m1.1.1.2.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1.2">FID</mtext></ci><cn id="S4.F2.5.5.5.4.4.m1.1.1.3.cmml" type="float" xref="S4.F2.5.5.5.4.4.m1.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.5.5.4.4.m1.1c">\text{FID}\approx 4.0</annotation><annotation encoding="application/x-llamapun" id="S4.F2.5.5.5.4.4.m1.1d">FID ≈ 4.0</annotation></semantics></math> within 43 milliseconds (not plotted in the figure for compactness). Additionally, the figure shows that D-JEPA can achieve <math alttext="\text{FID}\approx 2.0" class="ltx_Math" display="inline" id="S4.F2.6.6.6.5.5.m2.1"><semantics id="S4.F2.6.6.6.5.5.m2.1a"><mrow id="S4.F2.6.6.6.5.5.m2.1.1" xref="S4.F2.6.6.6.5.5.m2.1.1.cmml"><mtext id="S4.F2.6.6.6.5.5.m2.1.1.2" xref="S4.F2.6.6.6.5.5.m2.1.1.2a.cmml">FID</mtext><mo id="S4.F2.6.6.6.5.5.m2.1.1.1" xref="S4.F2.6.6.6.5.5.m2.1.1.1.cmml">≈</mo><mn id="S4.F2.6.6.6.5.5.m2.1.1.3" xref="S4.F2.6.6.6.5.5.m2.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.6.6.6.5.5.m2.1b"><apply id="S4.F2.6.6.6.5.5.m2.1.1.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1"><approx id="S4.F2.6.6.6.5.5.m2.1.1.1.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1.1"></approx><ci id="S4.F2.6.6.6.5.5.m2.1.1.2a.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1.2"><mtext id="S4.F2.6.6.6.5.5.m2.1.1.2.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1.2">FID</mtext></ci><cn id="S4.F2.6.6.6.5.5.m2.1.1.3.cmml" type="float" xref="S4.F2.6.6.6.5.5.m2.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.6.6.6.5.5.m2.1c">\text{FID}\approx 2.0</annotation><annotation encoding="application/x-llamapun" id="S4.F2.6.6.6.5.5.m2.1d">FID ≈ 2.0</annotation></semantics></math> within 120 milliseconds. Refer to Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T4" title="Table 4 ‣ Sampling efficiency. ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> for more details. All times are the average inference time using a batch size of 256 on a single H800 GPU for generating <math alttext="256\times 256" class="ltx_Math" display="inline" id="S4.F2.7.7.7.6.6.m3.1"><semantics id="S4.F2.7.7.7.6.6.m3.1a"><mrow id="S4.F2.7.7.7.6.6.m3.1.1" xref="S4.F2.7.7.7.6.6.m3.1.1.cmml"><mn id="S4.F2.7.7.7.6.6.m3.1.1.2" xref="S4.F2.7.7.7.6.6.m3.1.1.2.cmml">256</mn><mo id="S4.F2.7.7.7.6.6.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.F2.7.7.7.6.6.m3.1.1.1.cmml">×</mo><mn id="S4.F2.7.7.7.6.6.m3.1.1.3" xref="S4.F2.7.7.7.6.6.m3.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.7.7.7.6.6.m3.1b"><apply id="S4.F2.7.7.7.6.6.m3.1.1.cmml" xref="S4.F2.7.7.7.6.6.m3.1.1"><times id="S4.F2.7.7.7.6.6.m3.1.1.1.cmml" xref="S4.F2.7.7.7.6.6.m3.1.1.1"></times><cn id="S4.F2.7.7.7.6.6.m3.1.1.2.cmml" type="integer" xref="S4.F2.7.7.7.6.6.m3.1.1.2">256</cn><cn id="S4.F2.7.7.7.6.6.m3.1.1.3.cmml" type="integer" xref="S4.F2.7.7.7.6.6.m3.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.7.7.7.6.6.m3.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.F2.7.7.7.6.6.m3.1d">256 × 256</annotation></semantics></math> images.</figcaption>
</div>
</td>
</tr>
</table>
</figure>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Quantitative analysis.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.2">We present the Fréchet Inception Distance (FID) along with other metrics in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T1" title="Table 1 ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> without classifier-free guidance. Two critical conclusions can be drawn from the results: <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.2.1">State-of-the-Art Performance</span>: D-JEPA achieves state-of-the-art FID and Inception Score (IS) across all model scales. In particular, D-JEPA-L, with only 687M parameters, surpasses all previous works with <math alttext="\text{FID}=2.32,\text{IS}=233.5" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.1.m1.2"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.2a"><mrow id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3.cmml"><mrow id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2a.cmml">FID</mtext><mo id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml">2.32</mn></mrow><mo id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2a.cmml">IS</mtext><mo id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3.cmml">233.5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.2b"><apply id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3a.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1"><eq id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2">FID</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3">2.32</cn></apply><apply id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2"><eq id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2">IS</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3">233.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.2c">\text{FID}=2.32,\text{IS}=233.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.1.m1.2d">FID = 2.32 , IS = 233.5</annotation></semantics></math>. The larger model, D-JEPA-H, further improves the benchmark set by D-JEPA-L to <math alttext="\text{FID}=2.04,\text{IS}=239.3" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.2.m2.2"><semantics id="S4.SS1.SSS0.Px1.p1.2.m2.2a"><mrow id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3.cmml"><mrow id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2a.cmml">FID</mtext><mo id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3.cmml">2.04</mn></mrow><mo id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3a.cmml">,</mo><mrow id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2a.cmml">IS</mtext><mo id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3.cmml">239.3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.2.m2.2b"><apply id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3a.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1"><eq id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2">FID</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3">2.04</cn></apply><apply id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2"><eq id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2">IS</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3">239.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.2.m2.2c">\text{FID}=2.04,\text{IS}=239.3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.2.m2.2d">FID = 2.04 , IS = 239.3</annotation></semantics></math>. <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.2.2">Efficiency in Training</span>: As the model scale increases, the required number of training epochs for D-JEPA decreases significantly. Both D-JEPA-L and D-JEPA-H achieve state-of-the-art performance with substantially fewer training epochs compared to other models. For instance, D-JEPA-L, with 687M parameters and 480 training epochs, outperforms the previous state-of-the-art model, MAR-H, which has 943M parameters and requires 800 training epochs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p2.3">It is well known that selecting an appropriate <span class="ltx_text ltx_markedasmath" id="S4.SS1.SSS0.Px1.p2.3.1">cfg</span> scale can significantly enhance the quality of generated images. For D-JEPA, in addition to adjusting the <span class="ltx_text ltx_markedasmath" id="S4.SS1.SSS0.Px1.p2.3.2">cfg</span> scale, it is also necessary to choose an appropriate temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.3.m3.1"><semantics id="S4.SS1.SSS0.Px1.p2.3.m3.1a"><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.3.m3.1b"><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.3.m3.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p2.3.m3.1d">italic_τ</annotation></semantics></math> to ensure optimal generation quality. We employ a coarse-to-fine grid search to determine the optimal sampling parameters, as detailed in the Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">C.2</span></a>. The optimal sampling configurations are listed on Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T5" title="Table 5 ‣ Sampling efficiency. ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p3.1">We list additional results in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T2" title="Table 2 ‣ Scaling law of D-JEPA. ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a> with classifier-free guidance. To better showcase D-JEPA’s performance, we provide two sets of sampling performance metrics for each model scale, representing the optimal FID and settings more inclined towards IS. The table reveals that D-JEPA achieves superior results in this scenario as well. Specifically, D-JEPA-L and D-JEPA-H reach FID scores of 1.58 and 1.54, respectively, which are very close to the upper limit of the used VAE (FID = 1.199). Although MAR-H achieves a comparable FID (1.55), its IS (303.7) is significantly lower than that of D-JEPA-L (327.2) and D-JEPA-H (341.0), and it requires more training epochs.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Qualitative analysis.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S5.F3" title="Figure 3 ‣ 5 Conclusion ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3</span></a>, we present images generated using the next set-of-tokens prediction. Even when trained on ImageNet1k, D-JEPA is capable of producing highly realistic images with rich and clear local details. Notably, the figure also demonstrates that D-JEPA-H can generate high-quality portraits (the second picture in the second row), a capability not seen in previous generative models. Additionally, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F5" title="Figure 5 ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>, we observe the images generated at different auto-regressive steps. Even with just 8 steps, D-JEPA demonstrates significant generative capabilities, and at 64 steps, it nearly matches the image quality achieved at 256 steps. Fewer auto-regressive steps imply faster image generation, which is crucial for practical applications. In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.F2" title="Figure 2 ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, we use a bubble chart to illustrate D-JEPA’s performance under different computational costs. Remarkably, we can sample high-quality images with <math alttext="\text{FID}\approx 4.0" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mtext id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2a.cmml">FID</mtext><mo id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml">≈</mo><mn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1"><approx id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1"></approx><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2a.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2"><mtext id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2">FID</mtext></ci><cn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.1.m1.1c">\text{FID}\approx 4.0</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px2.p1.1.m1.1d">FID ≈ 4.0</annotation></semantics></math> in just 43 milliseconds, which significantly outperforms previous diffusion models and auto-regressive models.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Scaling law of D-JEPA.</h4>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.5">
<tr class="ltx_tr" id="S4.T2.4.4">
<td class="ltx_td ltx_border_r" id="S4.T2.4.4.5"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.4.4.6">#params</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.1">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.2.2.2">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.m1.1a"><mo id="S4.T2.2.2.2.m1.1.1" stretchy="false" xref="S4.T2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.3">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.m1.1.1" stretchy="false" xref="S4.T2.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.m1.1a"><mo id="S4.T2.4.4.4.m1.1.1" stretchy="false" xref="S4.T2.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><ci id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.6" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" id="S4.T2.5.6.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T2.5.6.1.1" style="background-color:#EFEFEF;">Base scale model (less than 300M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.7.1">MAR-B <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.7.2">208M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.3">2.31</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.4">281.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.5.1">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.6">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.8.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.8.1.1" style="background-color:#ECF4FF;">D-JEPA-B(cfg=3.1)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.8.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.8.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.3.1" style="background-color:#ECF4FF;">1.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.8.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.8.4.1" style="background-color:#ECF4FF;">282.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.5"><span class="ltx_text" id="S4.T2.5.8.5.1" style="background-color:#ECF4FF;">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.9" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.9.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.9.1.1" style="background-color:#ECF4FF;">D-JEPA-B(cfg=4.1)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.9.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.9.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.3"><span class="ltx_text" id="S4.T2.5.9.3.1" style="background-color:#ECF4FF;">2.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.9.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T2.5.9.4.1" style="background-color:#ECF4FF;">320.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.9.5.1" style="background-color:#ECF4FF;">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.6"><span class="ltx_text" id="S4.T2.5.9.6.1" style="background-color:#ECF4FF;">0.59</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="S4.T2.5.5.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T2.5.5.1.1" style="background-color:#EFEFEF;">Large scale model (300<math alttext="\sim" class="ltx_Math" display="inline" id="S4.T2.5.5.1.1.m1.1" style="background-color:#EFEFEF;"><semantics id="S4.T2.5.5.1.1.m1.1a"><mo id="S4.T2.5.5.1.1.m1.1.1" mathbackground="#EFEFEF" xref="S4.T2.5.5.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.5.5.1.1.m1.1.1.cmml" xref="S4.T2.5.5.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.1.1.m1.1d">∼</annotation></semantics></math>700M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.10.1">GIVT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.10.2">304M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.3">3.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.10.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.5">0.84</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.6">0.53</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.11.1">MAGVIT-v2 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.11.2">307M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.3">1.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.11.4">319.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.6">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.12.1">LDM-4 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.12.2">400M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.3">3.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.12.4">247.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.12.5.1">0.87</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.6">0.48</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.13.1">MAR-L <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.13.2">479M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.3">1.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.13.4">296.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.5">0.81</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.6">0.60</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.14.1">U-ViT-H <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib7" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.14.2">501M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.14.3">2.29</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.14.4">263.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.14.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.14.6">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.15.1">ADM <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.15.2">554M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.15.3">4.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.15.4">186.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.15.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.15.6">0.52</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.16.1">Flag-DiT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib129" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.16.2">600M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.16.3">2.40</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.16.4">243.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.16.5">0.81</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.16.6">0.58</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.17.1">Next-DiT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.17.2">600M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.17.3">2.36</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.17.4">250.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.17.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.17.6">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.18">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.18.1">DiT-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.18.2">675M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.18.3">2.27</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.18.4">278.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.18.5">0.83</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.18.6">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.19">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.19.1">SiT-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.19.2">675M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.19.3">2.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.19.4">270.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.19.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.19.6">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.20">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.20.1">MDTv2-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.20.2">676M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.20.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.20.3.1">1.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.20.4">314.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.20.5">0.79</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.20.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.20.6.1">0.65</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.21" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.21.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.21.1.1" style="background-color:#ECF4FF;">D-JEPA-L(cfg=3.0)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.21.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.21.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.21.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.21.3.1" style="background-color:#ECF4FF;">1.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.21.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.21.4.1" style="background-color:#ECF4FF;">303.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.21.5"><span class="ltx_text" id="S4.T2.5.21.5.1" style="background-color:#ECF4FF;">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.21.6"><span class="ltx_text" id="S4.T2.5.21.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.22" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.22.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.22.1.1" style="background-color:#ECF4FF;">D-JEPA-L(cfg=3.9)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.22.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.22.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.22.3"><span class="ltx_text" id="S4.T2.5.22.3.1" style="background-color:#ECF4FF;">1.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.22.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T2.5.22.4.1" style="background-color:#ECF4FF;">327.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.22.5"><span class="ltx_text" id="S4.T2.5.22.5.1" style="background-color:#ECF4FF;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.22.6"><span class="ltx_text" id="S4.T2.5.22.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.23" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="S4.T2.5.23.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T2.5.23.1.1" style="background-color:#EFEFEF;">Huge scale model (900+M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.24">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.24.1">MAR-H <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.24.2">943M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.24.3">1.55</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.24.4">303.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.24.5">0.81</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.24.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.24.6.1">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.25" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.25.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.25.1.1" style="background-color:#ECF4FF;">D-JEPA-H(cfg=3.9)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.25.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.25.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.25.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.25.3.1" style="background-color:#ECF4FF;">1.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.25.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.25.4.1" style="background-color:#ECF4FF;">324.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.25.5"><span class="ltx_text" id="S4.T2.5.25.5.1" style="background-color:#ECF4FF;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.25.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.25.6.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.26" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.26.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.26.1.1" style="background-color:#ECF4FF;">D-JEPA-H(cfg=4.3)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.26.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.26.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.26.3"><span class="ltx_text" id="S4.T2.5.26.3.1" style="background-color:#ECF4FF;">1.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.26.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.26.4.1" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T2.5.26.4.1.1" style="background-color:#ECF4FF;">341.0</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.26.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.26.5.1" style="background-color:#ECF4FF;">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.26.6"><span class="ltx_text" id="S4.T2.5.26.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.27">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.27.1">VDM++ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib57" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.27.2">2.0B</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.27.3">2.12</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.27.4">267.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.27.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.27.6">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>System-level comparison on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="S4.T2.7.m1.1"><semantics id="S4.T2.7.m1.1b"><mrow id="S4.T2.7.m1.1.1" xref="S4.T2.7.m1.1.1.cmml"><mn id="S4.T2.7.m1.1.1.2" xref="S4.T2.7.m1.1.1.2.cmml">256</mn><mo id="S4.T2.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.T2.7.m1.1.1.1.cmml">×</mo><mn id="S4.T2.7.m1.1.1.3" xref="S4.T2.7.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.m1.1c"><apply id="S4.T2.7.m1.1.1.cmml" xref="S4.T2.7.m1.1.1"><times id="S4.T2.7.m1.1.1.1.cmml" xref="S4.T2.7.m1.1.1.1"></times><cn id="S4.T2.7.m1.1.1.2.cmml" type="integer" xref="S4.T2.7.m1.1.1.2">256</cn><cn id="S4.T2.7.m1.1.1.3.cmml" type="integer" xref="S4.T2.7.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.m1.1e">256 × 256</annotation></semantics></math> conditional generation. To better showcase model performance, each model is evaluated with two different cfg scales (obtained by grid searching). One cfg scale provides the best FID score, while the other yields a better IS result at the cost of a negligible degradation in the FID score.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">In summary, as the parameter scale increases, D-JEPA achieves better performance with fewer training epochs, demonstrating excellent scalability. Although similar conclusions have been observed in  <cite class="ltx_cite ltx_citemacro_cite">Peebles &amp; Xie (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite> and  <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, for the former, the required training epochs increase with model size, and for the latter, the required training epochs do not decrease with model size.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p2.1">Moreover, with increasing model size, we are surprised to find that the number of auto-regressive steps required for D-JEPA to achieve optimal sampling results also significantly decreases<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">C.2</span></a> for more details.</span></span></span>. Specifically, for D-JEPA-H, we achieve the best sampling results with just 64 steps. This property ensures performance for constructing larger models and generating ultra-high-definition images and videos such as Sora <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib77" title="">2024</a>)</cite> in the future.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comprehensive Experiments</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In the Appendix, we further demonstrate the excellent inpainting and outpainting capabilities of the D-JEPA model (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS3" title="D.3 Inpainting and Outpainting ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">D.3</span></a>). Beyond diffusion loss, we also designed a flow matching loss to construct D-JEPA (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">F</span></a>). Experiments show that flow matching loss performs better on many tasks. Consequently, we extended our experiments based on flow matching loss to include text-to-image/audio generation and class-conditional video generation. These extended experiments fully demonstrate that D-JEPA is capable of generating various types of continuous data, not limited to images. Furthermore, we attempted to construct a multimodal generation model based on D-JEPA. The results indicate that D-JEPA can generate continuous data and be used to build multimodal understanding and generation models (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7" title="Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">G</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we have introduced D-JEPA as a novel generative model that can handle the generation of continuous data. Through extensive experiments, we have preliminarily validated the feasibility of this approach. However, scaling up the D-JEPA model remains a significant challenge that warrants further investigation. Additionally, the acceleration strategies and application ecosystems for diffusion models and auto-regressive models have already reached a high level of maturity. Adopting these successful strategies for the further development of D-JEPA is crucial. We hope that this work will inspire future researchers to explore the D-JEPA architecture, laying the groundwork for the construction of a unified multimodal model in the future.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1242" id="S5.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>D-JEPA achieves state-of-the-art image quality. We showcase selected high-fidelity examples of class-conditional generation on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="S5.F3.2.m1.1"><semantics id="S5.F3.2.m1.1b"><mrow id="S5.F3.2.m1.1.1" xref="S5.F3.2.m1.1.1.cmml"><mn id="S5.F3.2.m1.1.1.2" xref="S5.F3.2.m1.1.1.2.cmml">256</mn><mo id="S5.F3.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.F3.2.m1.1.1.1.cmml">×</mo><mn id="S5.F3.2.m1.1.1.3" xref="S5.F3.2.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><apply id="S5.F3.2.m1.1.1.cmml" xref="S5.F3.2.m1.1.1"><times id="S5.F3.2.m1.1.1.1.cmml" xref="S5.F3.2.m1.1.1.1"></times><cn id="S5.F3.2.m1.1.1.2.cmml" type="integer" xref="S5.F3.2.m1.1.1.2">256</cn><cn id="S5.F3.2.m1.1.1.3.cmml" type="integer" xref="S5.F3.2.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S5.F3.2.m1.1e">256 × 256</annotation></semantics></math> using D-JEPA-H.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albergo et al. (2023)</span>
<span class="ltx_bibblock">
Michael S Albergo, Nicholas M Boffi, and Eric Vanden-Eijnden.

</span>
<span class="ltx_bibblock">Stochastic interpolants: A unifying framework for flows and diffusions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08797</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assran et al. (2021)</span>
<span class="ltx_bibblock">
Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Armand Joulin, Nicolas Ballas, and Michael Rabbat.

</span>
<span class="ltx_bibblock">Semi-supervised learning of visual features by non-parametrically predicting view assignments with support samples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE/CVF International Conference on Computer Vision</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assran et al. (2022)</span>
<span class="ltx_bibblock">
Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Mike Rabbat, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">Masked siamese networks for label-efficient learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">European Conference on Computer Vision</em>, pp.  456–473. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assran et al. (2023)</span>
<span class="ltx_bibblock">
Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">Self-supervised learning from images with a joint-embedding predictive architecture.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  15619–15629, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ba et al. (2016)</span>
<span class="ltx_bibblock">
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Layer normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:1607.06450</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski et al. (2022)</span>
<span class="ltx_bibblock">
Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, and Michael Auli.

</span>
<span class="ltx_bibblock">Data2vec: A general framework for self-supervised learning in speech, vision and language.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Conference on Machine Learning</em>, pp.  1298–1312. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al. (2022)</span>
<span class="ltx_bibblock">
Fan Bao, Chongxuan Li, Yue Cao, and Jun Zhu.

</span>
<span class="ltx_bibblock">All are worth words: a vit backbone for score-based diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">NeurIPS 2022 Workshop on Score-Based Methods</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al. (2021)</span>
<span class="ltx_bibblock">
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei.

</span>
<span class="ltx_bibblock">Beit: Bert pre-training of image transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes et al. (2021)</span>
<span class="ltx_bibblock">
Adrien Bardes, Jean Ponce, and Yann LeCun.

</span>
<span class="ltx_bibblock">Vicreg: Variance-invariance-covariance regularization for self-supervised learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2105.04906</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes et al. (2023a)</span>
<span class="ltx_bibblock">
Adrien Bardes, Quentin Garrido, Jean Ponce, Xinlei Chen, Michael Rabbat, Yann LeCun, Mido Assran, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">V-jepa: Latent video prediction for visual representation learning.

</span>
<span class="ltx_bibblock">2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes et al. (2023b)</span>
<span class="ltx_bibblock">
Adrien Bardes, Jean Ponce, and Yann LeCun.

</span>
<span class="ltx_bibblock">Mc-jepa: A joint-embedding predictive architecture for self-supervised learning of motion and content features.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2307.12698</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes et al. (2024)</span>
<span class="ltx_bibblock">
Adrien Bardes, Quentin Garrido, Jean Ponce, Xinlei Chen, Michael Rabbat, Yann LeCun, Mahmoud Assran, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">Revisiting feature prediction for learning visual representations from video.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2404.08471</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brock et al. (2019)</span>
<span class="ltx_bibblock">
Andrew Brock, Jeff Donahue, and Karen Simonyan.

</span>
<span class="ltx_bibblock">Large scale GAN training for high fidelity natural image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Int. Conf. on Learning Representations (ICLR)</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Advances in neural information processing systems</em>, 33:1877–1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caron et al. (2021)</span>
<span class="ltx_bibblock">
Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.

</span>
<span class="ltx_bibblock">Emerging properties in self-supervised vision transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the IEEE/CVF international conference on computer vision</em>, pp.  9650–9660, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. (2022)</span>
<span class="ltx_bibblock">
Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William T Freeman.

</span>
<span class="ltx_bibblock">Maskgit: Masked generative image transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  11315–11325, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, and Zhenguo Li.

</span>
<span class="ltx_bibblock">Pixart-<math alttext="\alpha" class="ltx_Math" display="inline" id="bib.bib17.1.m1.1"><semantics id="bib.bib17.1.m1.1a"><mi id="bib.bib17.1.m1.1.1" xref="bib.bib17.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="bib.bib17.1.m1.1b"><ci id="bib.bib17.1.m1.1.1.cmml" xref="bib.bib17.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib17.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="bib.bib17.1.m1.1d">italic_α</annotation></semantics></math>: Fast training of diffusion transformer for photorealistic text-to-image synthesis, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Generative pretraining from pixels.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International conference on machine learning</em>, pp.  1691–1703. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021a)</span>
<span class="ltx_bibblock">
Mingjian Chen, Xu Tan, Bohan Li, Yanqing Liu, Tao Qin, Sheng Zhao, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Adaspeech: Adaptive text to speech for custom voice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2103.00993</em>, 2021a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2018)</span>
<span class="ltx_bibblock">
Xi Chen, Nikhil Mishra, Mostafa Rohaninejad, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Pixelsnail: An improved autoregressive generative model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">International conference on machine learning</em>, pp.  864–872. PMLR, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Xiaokang Chen, Mingyu Ding, Xiaodi Wang, Ying Xin, Shentong Mo, Yunhao Wang, Shumin Han, Ping Luo, Gang Zeng, and Jingdong Wang.

</span>
<span class="ltx_bibblock">Context autoencoder for self-supervised representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">International Journal of Computer Vision</em>, 132(1):208–223, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen &amp; He (2021)</span>
<span class="ltx_bibblock">
Xinlei Chen and Kaiming He.

</span>
<span class="ltx_bibblock">Exploring simple siamese representation learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  15750–15758, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021b)</span>
<span class="ltx_bibblock">
Xinlei Chen, Saining Xie, and Kaiming He.

</span>
<span class="ltx_bibblock">An empirical study of training self-supervised vision transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Int. Conference on Computer Vision (ICCV)</em>, pp.  9640–9649, 2021b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi et al. (2023)</span>
<span class="ltx_bibblock">
Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and Shuran Song.

</span>
<span class="ltx_bibblock">Diffusion policy: Visuomotor policy learning via action diffusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2303.04137</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Croitoru et al. (2023)</span>
<span class="ltx_bibblock">
Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah.

</span>
<span class="ltx_bibblock">Diffusion models in vision: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 45(9):10850–10869, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhariwal &amp; Nichol (2021)</span>
<span class="ltx_bibblock">
Prafulla Dhariwal and Alexander Nichol.

</span>
<span class="ltx_bibblock">Diffusion models beat gans on image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in neural information processing systems</em>, 34:8780–8794, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donahue &amp; Simonyan (2019)</span>
<span class="ltx_bibblock">
Jeff Donahue and Karen Simonyan.

</span>
<span class="ltx_bibblock">Large scale adversarial representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2021)</span>
<span class="ltx_bibblock">
Xiaoyi Dong, Jianmin Bao, Ting Zhang, Dongdong Chen, Weiming Zhang, Lu Yuan, Dong Chen, Fang Wen, and Nenghai Yu.

</span>
<span class="ltx_bibblock">Peco: Perceptual codebook for bert pre-training of vision transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2111.12710</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al. (2020)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2010.11929</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elfwing et al. (2018)</span>
<span class="ltx_bibblock">
Stefan Elfwing, Eiji Uchibe, and Kenji Doya.

</span>
<span class="ltx_bibblock">Sigmoid-weighted linear units for neural network function approximation in reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Neural networks</em>, 107:3–11, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser et al. (2021)</span>
<span class="ltx_bibblock">
Patrick Esser, Robin Rombach, and Bjorn Ommer.

</span>
<span class="ltx_bibblock">Taming transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  12873–12883, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser et al. (2024)</span>
<span class="ltx_bibblock">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al.

</span>
<span class="ltx_bibblock">Scaling rectified flow transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2403.03206</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Shanghua Gao, Pan Zhou, Ming-Ming Cheng, and Shuicheng Yan.

</span>
<span class="ltx_bibblock">Mdtv2: Masked diffusion transformer is a strong image synthesizer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2303.14389</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gidaris et al. (2018)</span>
<span class="ltx_bibblock">
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.

</span>
<span class="ltx_bibblock">Unsupervised representation learning by predicting image rotations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:1803.07728</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. (2020)</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Communications of the ACM</em>, 63(11):139–144, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. (2014)</span>
<span class="ltx_bibblock">
Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial nets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gregor et al. (2014)</span>
<span class="ltx_bibblock">
Karol Gregor, Ivo Danihelka, Andriy Mnih, Charles Blundell, and Daan Wierstra.

</span>
<span class="ltx_bibblock">Deep autoregressive networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">International Conference on Machine Learning</em>, pp.  1242–1250. PMLR, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grill et al. (2020)</span>
<span class="ltx_bibblock">
Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al.

</span>
<span class="ltx_bibblock">Bootstrap your own latent-a new approach to self-supervised learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Advances in neural information processing systems</em>, 33:21271–21284, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guetschel et al. (2024)</span>
<span class="ltx_bibblock">
Pierre Guetschel, Thomas Moreau, and Michael Tangermann.

</span>
<span class="ltx_bibblock">S-jepa: towards seamless cross-dataset transfer through dynamic spatial attention.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2403.11772</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hatamizadeh et al. (2023)</span>
<span class="ltx_bibblock">
Ali Hatamizadeh, Jiaming Song, Guilin Liu, Jan Kautz, and Arash Vahdat.

</span>
<span class="ltx_bibblock">Diffit: Diffusion vision transformers for image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2312.02139</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  770–778, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2019)</span>
<span class="ltx_bibblock">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.

</span>
<span class="ltx_bibblock">Momentum contrast for unsupervised visual representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:1911.05722</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2020)</span>
<span class="ltx_bibblock">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.

</span>
<span class="ltx_bibblock">Momentum contrast for unsupervised visual representation learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  9729–9738, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2022a)</span>
<span class="ltx_bibblock">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick.

</span>
<span class="ltx_bibblock">Masked autoencoders are scalable vision learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  16000–16009, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2022b)</span>
<span class="ltx_bibblock">
Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and Qifeng Chen.

</span>
<span class="ltx_bibblock">Latent video diffusion models for high-fidelity long video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2211.13221</em>, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heusel et al. (2017)</span>
<span class="ltx_bibblock">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Gans trained by a two time-scale update rule converge to a local nash equilibrium.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, volume 33, pp.  6840–6851, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2022)</span>
<span class="ltx_bibblock">
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J Fleet.

</span>
<span class="ltx_bibblock">Video diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Advances in Neural Information Processing Systems</em>, 35:8633–8646, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023a)</span>
<span class="ltx_bibblock">
Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao.

</span>
<span class="ltx_bibblock">Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">International Conference on Machine Learning</em>, pp.  13916–13932. PMLR, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023b)</span>
<span class="ltx_bibblock">
Zhicheng Huang, Xiaojie Jin, Chengze Lu, Qibin Hou, Ming-Ming Cheng, Dongmei Fu, Xiaohui Shen, and Jiashi Feng.

</span>
<span class="ltx_bibblock">Contrastive masked autoencoders are stronger vision learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ito (2017)</span>
<span class="ltx_bibblock">
Keith Ito.

</span>
<span class="ltx_bibblock">The lj speech dataset.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://keithito.com/LJ-Speech-Dataset/" title="">https://keithito.com/LJ-Speech-Dataset/</a>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras et al. (2019)</span>
<span class="ltx_bibblock">
Tero Karras, Samuli Laine, and Timo Aila.

</span>
<span class="ltx_bibblock">A style-based generator architecture for generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  4401–4410, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras et al. (2022)</span>
<span class="ltx_bibblock">
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.

</span>
<span class="ltx_bibblock">Elucidating the design space of diffusion-based generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Advances in Neural Information Processing Systems</em>, 35:26565–26577, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kendall et al. (2018)</span>
<span class="ltx_bibblock">
Alex Kendall, Yarin Gal, and Roberto Cipolla.

</span>
<span class="ltx_bibblock">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  7482–7491, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kenton &amp; Toutanova (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of naacL-HLT</em>, volume 1, pp.  2. Minneapolis, Minnesota, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kilian et al. (2024)</span>
<span class="ltx_bibblock">
Maciej Kilian, Varun Japan, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Computational tradeoffs in image synthesis: Diffusion, masked-token, and next-token prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2405.13218</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Gao (2024)</span>
<span class="ltx_bibblock">
Diederik Kingma and Ruiqi Gao.

</span>
<span class="ltx_bibblock">Understanding diffusion objectives as the elbo with simple data augmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kolesnikov et al. (2022)</span>
<span class="ltx_bibblock">
Alexander Kolesnikov, André Susano Pinto, Lucas Beyer, Xiaohua Zhai, Jeremiah Harmsen, and Neil Houlsby.

</span>
<span class="ltx_bibblock">Uvim: A unified modeling approach for vision with learned guiding codes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in Neural Information Processing Systems</em>, 35:26295–26308, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kong et al. (2020)</span>
<span class="ltx_bibblock">
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.

</span>
<span class="ltx_bibblock">Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Proc. of NeurIPS</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al. (2012)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Advances in neural information processing systems</em>, 25, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kynkäänniemi et al. (2019)</span>
<span class="ltx_bibblock">
Tuomas Kynkäänniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila.

</span>
<span class="ltx_bibblock">Improved precision and recall metric for assessing generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun (2022)</span>
<span class="ltx_bibblock">
Yann LeCun.

</span>
<span class="ltx_bibblock">A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Open Review</em>, 62(1):1–62, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. (2006)</span>
<span class="ltx_bibblock">
Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and Fujie Huang.

</span>
<span class="ltx_bibblock">A tutorial on energy-based learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Predicting structured data</em>, 1(0), 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2022)</span>
<span class="ltx_bibblock">
Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han.

</span>
<span class="ltx_bibblock">Autoregressive image generation using residual quantization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  11523–11532, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Tianhong Li, Huiwen Chang, Shlok Mishra, Han Zhang, Dina Katabi, and Dilip Krishnan.

</span>
<span class="ltx_bibblock">Mage: Masked generative encoder to unify representation learning and image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  2142–2152, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Tianhong Li, Yonglong Tian, He Li, Mingyang Deng, and Kaiming He.

</span>
<span class="ltx_bibblock">Autoregressive image generation without vector quantization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2406.11838</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lipman et al. (2022)</span>
<span class="ltx_bibblock">
Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.

</span>
<span class="ltx_bibblock">Flow matching for generative modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y Hou, and Max Tegmark.

</span>
<span class="ltx_bibblock">Kan: Kolmogorov-arnold networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">arXiv preprint arXiv:2404.19756</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv preprint arXiv:1711.05101</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2024a)</span>
<span class="ltx_bibblock">
Nanye Ma, Mark Goldstein, Michael S Albergo, Nicholas M Boffi, Eric Vanden-Eijnden, and Saining Xie.

</span>
<span class="ltx_bibblock">Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2401.08740</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2024b)</span>
<span class="ltx_bibblock">
Xin Ma, Yaohui Wang, Gengyun Jia, Xinyuan Chen, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, and Yu Qiao.

</span>
<span class="ltx_bibblock">Latte: Latent diffusion transformer for video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">arXiv preprint arXiv:2401.03048</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mentzer et al. (2023)</span>
<span class="ltx_bibblock">
Fabian Mentzer, David Minnen, Eirikur Agustsson, and Michael Tschannen.

</span>
<span class="ltx_bibblock">Finite scalar quantization: Vq-vae made simple.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">The Twelfth International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et al. (2021)</span>
<span class="ltx_bibblock">
Dongchan Min, Dong Bok Lee, Eunho Yang, and Sung Ju Hwang.

</span>
<span class="ltx_bibblock">Meta-stylespeech: Multi-speaker adaptive text-to-speech generation.

</span>
<span class="ltx_bibblock">pp.  7748–7759, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al. (2024)</span>
<span class="ltx_bibblock">
Sicheng Mo, Fangzhou Mu, Kuan Heng Lin, Yanli Liu, Bochen Guan, Yin Li, and Bolei Zhou.

</span>
<span class="ltx_bibblock">Freecontrol: Training-free spatial control of any text-to-image diffusion model with any condition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  7465–7475, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol &amp; Dhariwal (2021)</span>
<span class="ltx_bibblock">
Alexander Quinn Nichol and Prafulla Dhariwal.

</span>
<span class="ltx_bibblock">Improved denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">International Conference on Machine Learning</em>, pp.  8162–8171. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noroozi &amp; Favaro (2016)</span>
<span class="ltx_bibblock">
Mehdi Noroozi and Paolo Favaro.

</span>
<span class="ltx_bibblock">Unsupervised learning of visual representations by solving jigsaw puzzles.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">European Conference on Computer Vision</em>, pp.  69–84. Springer, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">https://openai.com/sora.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">OpenAI blog</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmar et al. (2022)</span>
<span class="ltx_bibblock">
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu.

</span>
<span class="ltx_bibblock">On aliased resizing and surprising subtleties in gan evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  11410–11420, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmar et al. (2018)</span>
<span class="ltx_bibblock">
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran.

</span>
<span class="ltx_bibblock">Image transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">International conference on machine learning</em>, pp.  4055–4064. PMLR, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pathak et al. (2016)</span>
<span class="ltx_bibblock">
Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros.

</span>
<span class="ltx_bibblock">Context encoders: Feature learning by inpainting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.  2536–2544, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peebles &amp; Xie (2023)</span>
<span class="ltx_bibblock">
William Peebles and Saining Xie.

</span>
<span class="ltx_bibblock">Scalable diffusion models with transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.  4195–4205, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2021)</span>
<span class="ltx_bibblock">
Jialun Peng, Dong Liu, Songcen Xu, and Houqiang Li.

</span>
<span class="ltx_bibblock">Generating diverse structure for image inpainting with hierarchical vq-vae.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  10775–10784, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2018)</span>
<span class="ltx_bibblock">
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al.

</span>
<span class="ltx_bibblock">Improving language understanding by generative pre-training.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">International conference on machine learning</em>, pp.  8748–8763. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">Journal of machine learning research</em>, 21(140):1–67, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2021)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Zero-shot text-to-image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">International conference on machine learning</em>, pp.  8821–8831. Pmlr, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Razavi et al. (2019)</span>
<span class="ltx_bibblock">
Ali Razavi, Aaron Van den Oord, and Oriol Vinyals.

</span>
<span class="ltx_bibblock">Generating diverse high-fidelity images with vq-vae-2.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  10684–10695, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Russakovsky et al. (2015)</span>
<span class="ltx_bibblock">
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al.

</span>
<span class="ltx_bibblock">Imagenet large scale visual recognition challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">International journal of computer vision</em>, 115(3):211–252, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salimans et al. (2016)</span>
<span class="ltx_bibblock">
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.

</span>
<span class="ltx_bibblock">Improved techniques for training gans.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">Advances in neural information processing systems</em>, 29, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2019)</span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Fast transformer decoding: One write-head is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">arXiv preprint arXiv:1911.02150</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al. (2023)</span>
<span class="ltx_bibblock">
Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.

</span>
<span class="ltx_bibblock">Mostgan-v: Video generation with temporal motion styles.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  5652–5661, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Skorokhodov et al. (2022)</span>
<span class="ltx_bibblock">
Ivan Skorokhodov, Sergey Tulyakov, and Mohamed Elhoseiny.

</span>
<span class="ltx_bibblock">Stylegan-v: A continuous video generator with the price, image quality and perks of stylegan2.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  3626–3636, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2020)</span>
<span class="ltx_bibblock">
Jiaming Song, Chenlin Meng, and Stefano Ermon.

</span>
<span class="ltx_bibblock">Denoising diffusion implicit models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song &amp; Ermon (2019)</span>
<span class="ltx_bibblock">
Yang Song and Stefano Ermon.

</span>
<span class="ltx_bibblock">Generative modeling by estimating gradients of the data distribution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2021)</span>
<span class="ltx_bibblock">
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.

</span>
<span class="ltx_bibblock">Score-based generative modeling through stochastic differential equations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">Int. Conf. on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soomro (2012)</span>
<span class="ltx_bibblock">
K Soomro.

</span>
<span class="ltx_bibblock">Ucf101: A dataset of 101 human actions classes from videos in the wild.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">arXiv preprint arXiv:1212.0402</em>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2024)</span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2019)</span>
<span class="ltx_bibblock">
Hao Sun, Xu Tan, Jun-Wei Gan, Hongzhi Liu, Sheng Zhao, Tao Qin, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Token-level ensemble distillation for grapheme-to-phoneme conversion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">arXiv preprint arXiv:1904.03446</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2024)</span>
<span class="ltx_bibblock">
Keqiang Sun, Junting Pan, Yuying Ge, Hao Li, Haodong Duan, Xiaoshi Wu, Renrui Zhang, Aojun Zhou, Zipeng Qin, Yi Wang, et al.

</span>
<span class="ltx_bibblock">Journeydb: A benchmark for generative image understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024)</span>
<span class="ltx_bibblock">
Octo Model Team, Dibya Ghosh, Homer Walke, Karl Pertsch, Kevin Black, Oier Mees, Sudeep Dasari, Joey Hejna, Tobias Kreiman, Charles Xu, et al.

</span>
<span class="ltx_bibblock">Octo: An open-source generalist robot policy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:2405.12213</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2020)</span>
<span class="ltx_bibblock">
Yonglong Tian, Dilip Krishnan, and Phillip Isola.

</span>
<span class="ltx_bibblock">Contrastive multiview coding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XI 16</em>, pp.  776–794. Springer, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et al. (2021)</span>
<span class="ltx_bibblock">
Yuandong Tian, Xinlei Chen, and Surya Ganguli.

</span>
<span class="ltx_bibblock">Understanding self-supervised learning dynamics without contrastive pairs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">International Conference on Machine Learning</em>, pp.  10268–10278. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tschannen et al. (2023)</span>
<span class="ltx_bibblock">
Michael Tschannen, Cian Eastwood, and Fabian Mentzer.

</span>
<span class="ltx_bibblock">Givt: Generative infinite-vocabulary transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">arXiv preprint arXiv:2312.02116</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van den Oord et al. (2016)</span>
<span class="ltx_bibblock">
Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al.

</span>
<span class="ltx_bibblock">Conditional image generation with pixelcnn decoders.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">Advances in neural information processing systems</em>, 29, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Den Oord et al. (2016)</span>
<span class="ltx_bibblock">
Aäron Van Den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.

</span>
<span class="ltx_bibblock">Pixel recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">International conference on machine learning</em>, pp.  1747–1756. PMLR, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Den Oord et al. (2017)</span>
<span class="ltx_bibblock">
Aaron Van Den Oord, Oriol Vinyals, et al.

</span>
<span class="ltx_bibblock">Neural discrete representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2017)</span>
<span class="ltx_bibblock">
Kunfeng Wang, Chao Gou, Yanjie Duan, Yilun Lin, Xinhu Zheng, and Fei-Yue Wang.

</span>
<span class="ltx_bibblock">Generative adversarial networks: introduction and outlook.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib109.1.1">IEEE/CAA Journal of Automatica Sinica</em>, 4(4):588–598, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2023)</span>
<span class="ltx_bibblock">
Chen Wei, Karttikeya Mangalam, Po-Yao Huang, Yanghao Li, Haoqi Fan, Hu Xu, Huiyu Wang, Cihang Xie, Alan Yuille, and Christoph Feichtenhofer.

</span>
<span class="ltx_bibblock">Diffusion models as masked autoencoders.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib110.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.  16284–16294, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, and Qi Tian.

</span>
<span class="ltx_bibblock">Mvp: Multimodality-guided visual pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib111.1.1">arXiv preprint arXiv:2203.05175</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2022)</span>
<span class="ltx_bibblock">
Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, and Han Hu.

</span>
<span class="ltx_bibblock">Simmim: A simple framework for masked image modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  9653–9663, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan et al. (2021)</span>
<span class="ltx_bibblock">
Wilson Yan, Yunzhi Zhang, Pieter Abbeel, and Aravind Srinivas.

</span>
<span class="ltx_bibblock">Videogpt: Video generation using vq-vae and transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">arXiv preprint arXiv:2104.10157</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024a)</span>
<span class="ltx_bibblock">
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al.

</span>
<span class="ltx_bibblock">Qwen2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">arXiv preprint arXiv:2407.10671</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024b)</span>
<span class="ltx_bibblock">
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et al.

</span>
<span class="ltx_bibblock">Cogvideox: Text-to-video diffusion models with an expert transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">arXiv preprint arXiv:2408.06072</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021)</span>
<span class="ltx_bibblock">
Jiahui Yu, Xin Li, Jing Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.

</span>
<span class="ltx_bibblock">Vector-quantized image modeling with improved vqgan.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">arXiv preprint arXiv:2110.04627</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023a)</span>
<span class="ltx_bibblock">
Lijun Yu, Yong Cheng, Kihyuk Sohn, José Lezama, Han Zhang, Huiwen Chang, Alexander G Hauptmann, Ming-Hsuan Yang, Yuan Hao, Irfan Essa, et al.

</span>
<span class="ltx_bibblock">Magvit: Masked generative video transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  10459–10469, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023b)</span>
<span class="ltx_bibblock">
Lijun Yu, José Lezama, Nitesh B Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander G Hauptmann, et al.

</span>
<span class="ltx_bibblock">Language model beats diffusion–tokenizer is key to visual generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">arXiv preprint arXiv:2310.05737</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Sihyun Yu, Jihoon Tack, Sangwoo Mo, Hyunsu Kim, Junho Kim, Jung-Woo Ha, and Jinwoo Shin.

</span>
<span class="ltx_bibblock">Generating videos with dynamics-aware implicit generative adversarial networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">arXiv preprint arXiv:2202.10571</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023c)</span>
<span class="ltx_bibblock">
Sihyun Yu, Kihyuk Sohn, Subin Kim, and Jinwoo Shin.

</span>
<span class="ltx_bibblock">Video probabilistic diffusion models in projected latent space.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  18456–18466, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zbontar et al. (2021)</span>
<span class="ltx_bibblock">
Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and Stéphane Deny.

</span>
<span class="ltx_bibblock">Barlow twins: Self-supervised learning via redundancy reduction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">International conference on machine learning</em>, pp.  12310–12320. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et al. (2021)</span>
<span class="ltx_bibblock">
Yanhong Zeng, Huan Yang, Hongyang Chao, Jianbo Wang, and Jianlong Fu.

</span>
<span class="ltx_bibblock">Improving visual quality of image synthesis by a token-based generator with transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">Advances in Neural Information Processing Systems</em>, 34:21125–21137, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2017a)</span>
<span class="ltx_bibblock">
Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N Metaxas.

</span>
<span class="ltx_bibblock">Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">Proceedings of the IEEE international conference on computer vision</em>, pp.  5907–5915, 2017a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena.

</span>
<span class="ltx_bibblock">Self-attention generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">Int. Conference on Machine Learning (icml)</em>, pp.  7354–7363, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2017b)</span>
<span class="ltx_bibblock">
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz.

</span>
<span class="ltx_bibblock">mixup: Beyond empirical risk minimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">arXiv preprint arXiv:1710.09412</em>, 2017b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, and Omer Levy.

</span>
<span class="ltx_bibblock">Transfusion: Predict the next token and diffuse images with one multi-modal model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">arXiv preprint arXiv:2408.11039</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2021)</span>
<span class="ltx_bibblock">
Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.

</span>
<span class="ltx_bibblock">ibot: Image bert pre-training with online tokenizer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">arXiv preprint arXiv:2111.07832</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuo et al. (2024a)</span>
<span class="ltx_bibblock">
Le Zhuo, Ruoyi Du, Xiao Han, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, et al.

</span>
<span class="ltx_bibblock">Lumina-next: Making lumina-t2x stronger and faster with next-dit.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">arXiv preprint arXiv:2406.18583</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuo et al. (2024b)</span>
<span class="ltx_bibblock">
Le Zhuo, Ruoyi Du, Han Xiao, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, Lirui Zhao, Fu-Yun Wang, Zhanyu Ma, et al.

</span>
<span class="ltx_bibblock">Lumina-next: Making lumina-t2x stronger and faster with next-dit.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">arXiv preprint arXiv:2406.18583</em>, 2024b.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Related Work</h2>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Self-supervised learning.</h4>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1">Early efforts in unsupervised learning emphasized pretext tasks designed to predict pseudo labels, such as solving jigsaw puzzles <cite class="ltx_cite ltx_citemacro_citep">(Noroozi &amp; Favaro, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib76" title="">2016</a>)</cite>, restoring missing patches <cite class="ltx_cite ltx_citemacro_citep">(Pathak et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib80" title="">2016</a>)</cite>, and predicting image rotations <cite class="ltx_cite ltx_citemacro_citep">(Gidaris et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib34" title="">2018</a>)</cite>. Despite yielding useful representations, these methods lagged behind those acquired through supervised learning.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p2.1">The advent of contrastive learning marked a significant leap forward, achieving near-supervised performance with techniques like MoCo <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib43" title="">2020</a>)</cite> and contrastive multiview coding <cite class="ltx_cite ltx_citemacro_citep">(Tian et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib103" title="">2020</a>)</cite>. BYOL <cite class="ltx_cite ltx_citemacro_citep">(Grill et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>)</cite> further advanced the field by eliminating the need for negative pairs and employing peer networks for mutual learning. However, these methods primarily focused on image data and could not be directly applied to other continuous data types, such as audio.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p3.1">Inspired by developments in natural language processing, masked image modeling (MIM) emerged as an effective approach to self-supervised learning <cite class="ltx_cite ltx_citemacro_citep">(Kenton &amp; Toutanova, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib55" title="">2019</a>)</cite>, extendable to continuous data types such as audio <cite class="ltx_cite ltx_citemacro_citep">(Baevski et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>)</cite>. Models such as BEiT <cite class="ltx_cite ltx_citemacro_citep">(Bao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib8" title="">2021</a>)</cite>, PeCo <cite class="ltx_cite ltx_citemacro_citep">(Dong et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib28" title="">2021</a>)</cite>, and MAE <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> focus on recovering visual tokens or performing pixel-level reconstruction. DiffMAE <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib110" title="">2023</a>)</cite> leverages denoising diffusion decoders primarily for representation learning rather than image generation. While MIM-based methods prioritize downstream performance, they often result in suboptimal reconstructions <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>; Bao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib8" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p4.1">Recent advances such as MAGE <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite> achieve high-quality representations and image generation. However, these methods are limited to image data, failing to empirically demonstrate mutual reinforcement between tasks. Our work uniquely verifies the mutual benefits of representation learning and generative modeling through empirical evidence, demonstrating how these processes can be synergistically combined for superior performance across different types of continuous data.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Generative modeling.</h4>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1">Generative models have seen significant advances in image synthesis. Generative adversarial networks (GANs) <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib36" title="">2014</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib123" title="">2017a</a>; Karras et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib52" title="">2019</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib124" title="">2019</a>; Brock et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib13" title="">2019</a>)</cite> excel in producing realistic images but often face challenges such as training instability and mode collapse. Two-stage models <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib108" title="">2017</a>; Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib64" title="">2022</a>)</cite> tokenize images and apply maximum likelihood estimation in the latent space, with VQ-VAE-2 <cite class="ltx_cite ltx_citemacro_citep">(Razavi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib88" title="">2019</a>)</cite> generating diverse samples. ViT-VQGAN <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>)</cite> utilizes vision transformers <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>, while MaskGIT <cite class="ltx_cite ltx_citemacro_citep">(Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite> employs bidirectional transformers for faster decoding. Additionally, diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>; Song et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib97" title="">2021</a>; Dhariwal &amp; Nichol, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>; Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite> have achieved remarkable results in image synthesis.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p2.1">Autoregressive models <cite class="ltx_cite ltx_citemacro_citep">(Gregor et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib37" title="">2014</a>; Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib107" title="">2016</a>; Van den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib106" title="">2016</a>; Parmar et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib79" title="">2018</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib20" title="">2018</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib18" title="">2020</a>)</cite> generate images as pixel sequences, utilizing recurrent neural networks <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib107" title="">2016</a>)</cite>, convolutional neural networks  <cite class="ltx_cite ltx_citemacro_citep">(Van den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib106" title="">2016</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib20" title="">2018</a>)</cite>, and transformers  <cite class="ltx_cite ltx_citemacro_citep">(Parmar et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib79" title="">2018</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib18" title="">2020</a>)</cite>. Recent approaches  <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib108" title="">2017</a>; Razavi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib88" title="">2019</a>; Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib31" title="">2021</a>; Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib87" title="">2021</a>)</cite> adopt discrete tokens inspired by language models for image modeling. However, training these discrete tokenizers is challenging for high-quality image generation <cite class="ltx_cite ltx_citemacro_citep">(Kolesnikov et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib58" title="">2022</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib117" title="">2023a</a>; Mentzer et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib72" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p3.1">Recent developments, such as GIVT <cite class="ltx_cite ltx_citemacro_citep">(Tschannen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite> and MAR <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, introduce continuous-valued tokens, yielding promising results. Our method directly processes continuous-valued tokens via the diffusion process, ensuring high-quality image generation.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental Setup</h2>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Network configuration.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p1.2">We constructed three variants of D-JEPA using different visual transformer backbones: D-JEPA-B with ViT-B, D-JEPA-L with ViT-L, and D-JEPA-H with ViT-H. In all configurations, <math alttext="u_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="A2.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="A2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">u</mi><mi id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2">𝑢</ci><ci id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p1.1.m1.1c">u_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p1.1.m1.1d">italic_u start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> is implemented as a simple two-layer MLP. The denoising MLP, denoted as <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="A2.SS0.SSS0.Px1.p1.2.m2.1a"><msub id="A2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">ϵ</mi><mi id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2">italic-ϵ</ci><ci id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p1.2.m2.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p1.2.m2.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, follows the implementation described in <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, comprising 6, 8, and 12 residual blocks with linear layers, respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p2.1">We adhered to the standard practice outlined in <cite class="ltx_cite ltx_citemacro_cite">LeCun (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>)</cite> for parameter counting, considering only the learnable parameters updated through gradients. Since the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="A2.SS0.SSS0.Px1.p2.1.m1.1a"><mover accent="true" id="A2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml">ϕ</mi><mo id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p2.1.m1.1b"><apply id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1"><ci id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1">¯</ci><ci id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p2.1.m1.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p2.1.m1.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math> is updated via exponential moving average and is not utilized during sampling, its parameters are excluded from the count. The number of parameters for each model is detailed in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T1" title="Table 1 ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Training.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p1.8">We trained class-conditional latent D-JEPA models at a <math alttext="256\times 256" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="A2.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">256</mn><mo id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">×</mo><mn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1"><times id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2">256</cn><cn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.1.m1.1d">256 × 256</annotation></semantics></math> image resolution on the ImageNet dataset <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib60" title="">2012</a>)</cite>, a highly competitive benchmark for generative modeling. The VAE trained by <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> encodes images into a latent space of size <math alttext="16\times 32\times 32" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="A2.SS0.SSS0.Px2.p1.2.m2.1a"><mrow id="A2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml">16</mn><mo id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml">×</mo><mn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml">32</mn><mo id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml">×</mo><mn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1"><times id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2">16</cn><cn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3">32</cn><cn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.2.m2.1c">16\times 32\times 32</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.2.m2.1d">16 × 32 × 32</annotation></semantics></math>. Subsequently, we employ a patch size of <math alttext="p=1" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="A2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="A2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml">p</mi><mo id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1"><eq id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1"></eq><ci id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2">𝑝</ci><cn id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.3.m3.1c">p=1</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.3.m3.1d">italic_p = 1</annotation></semantics></math> to segment the latent space into semantic tokens, resulting in <math alttext="N=256" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="A2.SS0.SSS0.Px2.p1.4.m4.1a"><mrow id="A2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml">N</mi><mo id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1"><eq id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1"></eq><ci id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2">𝑁</ci><cn id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.4.m4.1c">N=256</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.4.m4.1d">italic_N = 256</annotation></semantics></math> tokens. After sampling all tokens with D-JEPA according to Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#alg1" title="Algorithm 1 ‣ 3.5 Sampling in Next Set-of-Tokens Prediction ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>, we decode them to pixels using the corresponding VAE decoder. We retain the diffusion hyperparameters from ADM <cite class="ltx_cite ltx_citemacro_citep">(Dhariwal &amp; Nichol, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>; specifically, we use a <math alttext="t_{\text{max}}=1000" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.5.m5.1"><semantics id="A2.SS0.SSS0.Px2.p1.5.m5.1a"><mrow id="A2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><msub id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml"><mi id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2.cmml">t</mi><mtext id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3a.cmml">max</mtext></msub><mo id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml">1000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1"><eq id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1"></eq><apply id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2">𝑡</ci><ci id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3a.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3"><mtext id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3.cmml" mathsize="70%" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3">max</mtext></ci></apply><cn id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.5.m5.1c">t_{\text{max}}=1000</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.5.m5.1d">italic_t start_POSTSUBSCRIPT max end_POSTSUBSCRIPT = 1000</annotation></semantics></math> linear variance schedule ranging from <math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.6.m6.1"><semantics id="A2.SS0.SSS0.Px2.p1.6.m6.1a"><mrow id="A2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml">1</mn><mo id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1.cmml">×</mo><msup id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml"><mn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2.cmml">10</mn><mrow id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.cmml"><mo id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3a" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.cmml">−</mo><mn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.6.m6.1b"><apply id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1"><times id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2">1</cn><apply id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3">superscript</csymbol><cn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2">10</cn><apply id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3"><minus id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3"></minus><cn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.6.m6.1c">1\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.6.m6.1d">1 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> to <math alttext="2\times 10^{-2}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.7.m7.1"><semantics id="A2.SS0.SSS0.Px2.p1.7.m7.1a"><mrow id="A2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml">2</mn><mo id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml">×</mo><msup id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml"><mn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2.cmml">10</mn><mrow id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.cmml"><mo id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3a" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.cmml">−</mo><mn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.7.m7.1b"><apply id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1"><times id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2">2</cn><apply id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3">superscript</csymbol><cn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2">10</cn><apply id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3"><minus id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3"></minus><cn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.7.m7.1c">2\times 10^{-2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.7.m7.1d">2 × 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, ADM’s parameterization of the covariance <math alttext="\Sigma_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.8.m8.1"><semantics id="A2.SS0.SSS0.Px2.p1.8.m8.1a"><msub id="A2.SS0.SSS0.Px2.p1.8.m8.1.1" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2" mathvariant="normal" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2.cmml">Σ</mi><mi id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.8.m8.1b"><apply id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2">Σ</ci><ci id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.8.m8.1c">\Sigma_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.8.m8.1d">roman_Σ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, and their method for embedding input timesteps and labels.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p2.4">The final linear layer is initialized with zeros, while other layers follow standard weight initialization techniques from ViT <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>. We train all models using AdamW <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov &amp; Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib69" title="">2017</a>)</cite> with a learning rate of <math alttext="8\times 10^{-4}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="A2.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="A2.SS0.SSS0.Px2.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">8</mn><mo id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml">×</mo><msup id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.cmml">10</mn><mrow id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml"><mo id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3a" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">−</mo><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1"><times id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2">8</cn><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3">superscript</csymbol><cn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2">10</cn><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3"><minus id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3"></minus><cn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.1.m1.1c">8\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.1.m1.1d">8 × 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>, incorporating a 100-epoch linear warmup and a linear weight decay from 0.02 to 0.2 for all parameters except <math alttext="u_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.2.m2.1"><semantics id="A2.SS0.SSS0.Px2.p2.2.m2.1a"><msub id="A2.SS0.SSS0.Px2.p2.2.m2.1.1" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">u</mi><mi id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2">𝑢</ci><ci id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.2.m2.1c">u_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.2.m2.1d">italic_u start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.3.m3.1"><semantics id="A2.SS0.SSS0.Px2.p2.3.m3.1a"><msub id="A2.SS0.SSS0.Px2.p2.3.m3.1.1" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">ϵ</mi><mi id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2">italic-ϵ</ci><ci id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.3.m3.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.3.m3.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.4.m4.1"><semantics id="A2.SS0.SSS0.Px2.p2.4.m4.1a"><mover accent="true" id="A2.SS0.SSS0.Px2.p2.4.m4.1.1" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml">ϕ</mi><mo id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.4.m4.1b"><apply id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1"><ci id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1">¯</ci><ci id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.4.m4.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.4.m4.1d">over¯ start_ARG italic_ϕ end_ARG</annotation></semantics></math>. The experiments are conducted on four workers, each equipped with 8 H800 GPUs, with a total batch size 2048. The only data augmentation applied is horizontal flipping.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p3.1">Following standard practices in generative modeling, we maintain an exponential moving average of D-JEPA weights throughout training, with a decay rate of 0.9999. All reported results are based on the EMA model. The number of training epochs varies depending on the model’s performance during evaluation; training is halted once the evaluation metrics show no significant improvement.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Evaluation metrics.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p1.1">We measure scaling performance using the Fréchet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_citep">(Heusel et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib46" title="">2017</a>)</cite>, the standard metric for evaluating generative models of images. In line with convention, we compare against prior works and report FID-50K using 100 DDPM sampling steps <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite>. FID is known to be sensitive to small implementation details <cite class="ltx_cite ltx_citemacro_citep">(Parmar et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib78" title="">2022</a>)</cite>; to ensure accurate comparisons, all values reported in this paper are obtained by exporting samples and using ADM’s evaluation suite <cite class="ltx_cite ltx_citemacro_citep">(Dhariwal &amp; Nichol, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>. FID numbers reported in this paper do not use classifier-free guidance except where otherwise stated. Additionally, we report the Inception Score (IS) <cite class="ltx_cite ltx_citemacro_citep">(Salimans et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib91" title="">2016</a>)</cite> and Precision/Recall <cite class="ltx_cite ltx_citemacro_citep">(Kynkäänniemi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib61" title="">2019</a>)</cite> as secondary metrics.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Sampling with generalized next token prediction</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Grid searching for optimal classifier-free guidance scale and temperature</h3>
<figure class="ltx_figure" id="A3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf1.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>D-JEPA Base, Coarse Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf2.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>D-JEPA Base, Fine Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf3.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>D-JEPA Large, Coarse Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf4.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>D-JEPA Large, Fine Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf5.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>D-JEPA Huge, Coarse Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf6.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>D-JEPA Huge, Fine Searching</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Grid searching for CFG scale and temperature <math alttext="\tau" class="ltx_Math" display="inline" id="A3.F4.2.m1.1"><semantics id="A3.F4.2.m1.1b"><mi id="A3.F4.2.m1.1.1" xref="A3.F4.2.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.F4.2.m1.1c"><ci id="A3.F4.2.m1.1.1.cmml" xref="A3.F4.2.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F4.2.m1.1d">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.F4.2.m1.1e">italic_τ</annotation></semantics></math>. FID=1.199 and IS=302.69 represent the benchmarks achievable by VAE, which are the theoretical upper limits for D-JEPA.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.3">As described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS3" title="3.3 Diffusion Learning with a Denoising MLP ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.3</span></a>, the temperature <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.p1.1.m1.1"><semantics id="A3.SS1.p1.1.m1.1a"><mi id="A3.SS1.p1.1.m1.1.1" xref="A3.SS1.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.1.m1.1b"><ci id="A3.SS1.p1.1.m1.1.1.cmml" xref="A3.SS1.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.1.m1.1d">italic_τ</annotation></semantics></math> controls the noise level added at each iteration during the denoising process and significantly influences the final sampling results. Therefore, we conducted a grid search to determine each model’s optimal <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.p1.2.m2.1"><semantics id="A3.SS1.p1.2.m2.1a"><mi id="A3.SS1.p1.2.m2.1.1" xref="A3.SS1.p1.2.m2.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.2.m2.1b"><ci id="A3.SS1.p1.2.m2.1.1.cmml" xref="A3.SS1.p1.2.m2.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.2.m2.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.2.m2.1d">italic_τ</annotation></semantics></math>. Similarly, the classifier-free guidance scale <span class="ltx_text ltx_markedasmath" id="A3.SS1.p1.3.1">cfg</span> is known to affect sampling results notably and was also included in the grid search. We use 100 DDPM sampling steps for the denoising MLP following <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>); Ho et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite> and set the auto-regressive steps to 64, which balances sampling efficiency and image quality.</p>
</div>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Coarse searching.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px1.p1.2">In the coarse searching stage, we began by exploring <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="A3.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="A3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px1.p1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px1.p1.1.m1.1d">italic_τ</annotation></semantics></math> from 0.90 to 1.05 with a step size of 0.01, considering <math alttext="\text{cfg}\in\{1.0,2.0,3.0,4.0\}" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px1.p1.2.m2.4"><semantics id="A3.SS1.SSS0.Px1.p1.2.m2.4a"><mrow id="A3.SS1.SSS0.Px1.p1.2.m2.4.5" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.cmml"><mtext id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1.cmml">∈</mo><mrow id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml"><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.1" stretchy="false" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">{</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="A3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">1.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.2.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.2.2.cmml">2.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.3" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.3.3" xref="A3.SS1.SSS0.Px1.p1.2.m2.3.3.cmml">3.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.4" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.4.4" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.4.cmml">4.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.5" stretchy="false" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px1.p1.2.m2.4b"><apply id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5"><in id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1"></in><ci id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2a.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2"><mtext id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2">cfg</mtext></ci><set id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2"><cn id="A3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.1.1">1.0</cn><cn id="A3.SS1.SSS0.Px1.p1.2.m2.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.2.2">2.0</cn><cn id="A3.SS1.SSS0.Px1.p1.2.m2.3.3.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.3.3">3.0</cn><cn id="A3.SS1.SSS0.Px1.p1.2.m2.4.4.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.4">4.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px1.p1.2.m2.4c">\text{cfg}\in\{1.0,2.0,3.0,4.0\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px1.p1.2.m2.4d">cfg ∈ { 1.0 , 2.0 , 3.0 , 4.0 }</annotation></semantics></math>. The results are plotted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf1" title="In Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(a)</span></a>, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf3" title="In Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(c)</span></a>, and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf5" title="In Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(e)</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Fine searching.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px2.p1.7">Based on <math alttext="\text{cfg}=3.0,4.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.1.m1.2"><semantics id="A3.SS1.SSS0.Px2.p1.1.m1.2a"><mrow id="A3.SS1.SSS0.Px2.p1.1.m1.2.3" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1.cmml">=</mo><mrow id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.1.cmml"><mn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">3.0</mn><mo id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.2.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px2.p1.1.m1.2.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.2.cmml">4.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.1.m1.2b"><apply id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3"><eq id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1"></eq><ci id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2"><mtext id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2">cfg</mtext></ci><list id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.2"><cn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1">3.0</cn><cn id="A3.SS1.SSS0.Px2.p1.1.m1.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.2">4.0</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.1.m1.2c">\text{cfg}=3.0,4.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.1.m1.2d">cfg = 3.0 , 4.0</annotation></semantics></math> and <math alttext="\tau=0.97" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.2.m2.1"><semantics id="A3.SS1.SSS0.Px2.p1.2.m2.1a"><mrow id="A3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml">τ</mi><mo id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">0.97</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1"><eq id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2">𝜏</ci><cn id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3">0.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.2.m2.1c">\tau=0.97</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.2.m2.1d">italic_τ = 0.97</annotation></semantics></math>, we conducted a fine search for the best <math alttext="\text{cfg}_{c}-\tau_{c}" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.3.m3.1"><semantics id="A3.SS1.SSS0.Px2.p1.3.m3.1a"><mrow id="A3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><msub id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2a.cmml">cfg</mtext><mi id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml">−</mo><msub id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">τ</mi><mi id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1"><minus id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1"></minus><apply id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2"><mtext id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2">cfg</mtext></ci><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3">𝑐</ci></apply><apply id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2">𝜏</ci><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.3.m3.1c">\text{cfg}_{c}-\tau_{c}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.3.m3.1d">cfg start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - italic_τ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> combinations. In this stage, a 2D grid search was performed with <span class="ltx_text ltx_markedasmath" id="A3.SS1.SSS0.Px2.p1.7.1">cfg</span> ranging from <math alttext="[\text{cfg}_{c}-0.3,\text{cfg}_{c}+0.3]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.5.m5.2"><semantics id="A3.SS1.SSS0.Px2.p1.5.m5.2a"><mrow id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml"><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml">[</mo><mrow id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.cmml"><msub id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2a.cmml">cfg</mtext><mi id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1.cmml">−</mo><mn id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3.cmml">0.3</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.4" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml">,</mo><mrow id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.cmml"><msub id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2a.cmml">cfg</mtext><mi id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1.cmml">+</mo><mn id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3.cmml">0.3</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.5" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.5.m5.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2"><apply id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1"><minus id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1"></minus><apply id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2">cfg</mtext></ci><ci id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3">𝑐</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3">0.3</cn></apply><apply id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2"><plus id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1"></plus><apply id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2">cfg</mtext></ci><ci id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3">𝑐</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3">0.3</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.5.m5.2c">[\text{cfg}_{c}-0.3,\text{cfg}_{c}+0.3]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.5.m5.2d">[ cfg start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - 0.3 , cfg start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + 0.3 ]</annotation></semantics></math> with a step size of 0.1, and <math alttext="\tau_{c}" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.6.m6.1"><semantics id="A3.SS1.SSS0.Px2.p1.6.m6.1a"><msub id="A3.SS1.SSS0.Px2.p1.6.m6.1.1" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml">τ</mi><mi id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.6.m6.1b"><apply id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2">𝜏</ci><ci id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.6.m6.1c">\tau_{c}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.6.m6.1d">italic_τ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> ranging from <math alttext="[\tau_{c}-0.01,\tau_{c}+0.01]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.7.m7.2"><semantics id="A3.SS1.SSS0.Px2.p1.7.m7.2a"><mrow id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml"><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml">[</mo><mrow id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.cmml"><msub id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.cmml"><mi id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2.cmml">τ</mi><mi id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1.cmml">−</mo><mn id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3.cmml">0.01</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.4" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml">,</mo><mrow id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.cmml"><msub id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.cmml"><mi id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2.cmml">τ</mi><mi id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1.cmml">+</mo><mn id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3.cmml">0.01</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.5" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.7.m7.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2"><apply id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1"><minus id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1"></minus><apply id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2">𝜏</ci><ci id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3">𝑐</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3">0.01</cn></apply><apply id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2"><plus id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1"></plus><apply id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2">𝜏</ci><ci id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3">𝑐</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3">0.01</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.7.m7.2c">[\tau_{c}-0.01,\tau_{c}+0.01]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.7.m7.2d">[ italic_τ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - 0.01 , italic_τ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + 0.01 ]</annotation></semantics></math> with a step size of 0.01, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf2" title="In Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(b)</span></a>, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf3" title="In Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(c)</span></a>, and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf6" title="In Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(f)</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="A3.SS1.SSS0.Px2.p2.10">When <math alttext="\text{cfg}=1.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.1.m1.1"><semantics id="A3.SS1.SSS0.Px2.p2.1.m1.1a"><mrow id="A3.SS1.SSS0.Px2.p2.1.m1.1.1" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1"><eq id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.1.m1.1c">\text{cfg}=1.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.1.m1.1d">cfg = 1.0</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="A3.SS1.SSS0.Px2.p2.10.1">i.e.</span>, no classifier-free guidance, we found that <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.2.m2.1"><semantics id="A3.SS1.SSS0.Px2.p2.2.m2.1a"><mi id="A3.SS1.SSS0.Px2.p2.2.m2.1.1" xref="A3.SS1.SSS0.Px2.p2.2.m2.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.2.m2.1b"><ci id="A3.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.2.m2.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.2.m2.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.2.m2.1d">italic_τ</annotation></semantics></math> in the range <math alttext="[0.94,0.95]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.3.m3.2"><semantics id="A3.SS1.SSS0.Px2.p2.3.m3.2a"><mrow id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml"><mo id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2.1" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml">[</mo><mn id="A3.SS1.SSS0.Px2.p2.3.m3.1.1" xref="A3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml">0.94</mn><mo id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2.2" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px2.p2.3.m3.2.2" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.2.cmml">0.95</mn><mo id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.3.m3.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2"><cn id="A3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.3.m3.1.1">0.94</cn><cn id="A3.SS1.SSS0.Px2.p2.3.m3.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.2">0.95</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.3.m3.2c">[0.94,0.95]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.3.m3.2d">[ 0.94 , 0.95 ]</annotation></semantics></math> works well for all models. For <math alttext="\text{cfg}\geq 1.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.4.m4.1"><semantics id="A3.SS1.SSS0.Px2.p2.4.m4.1a"><mrow id="A3.SS1.SSS0.Px2.p2.4.m4.1.1" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1.cmml">≥</mo><mn id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.4.m4.1b"><apply id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1"><geq id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1"></geq><ci id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.4.m4.1c">\text{cfg}\geq 1.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.4.m4.1d">cfg ≥ 1.0</annotation></semantics></math>, <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.5.m5.1"><semantics id="A3.SS1.SSS0.Px2.p2.5.m5.1a"><mi id="A3.SS1.SSS0.Px2.p2.5.m5.1.1" xref="A3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.5.m5.1b"><ci id="A3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.5.m5.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.5.m5.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.5.m5.1d">italic_τ</annotation></semantics></math> in the range <math alttext="[0.97,0.99]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.6.m6.2"><semantics id="A3.SS1.SSS0.Px2.p2.6.m6.2a"><mrow id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml"><mo id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2.1" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml">[</mo><mn id="A3.SS1.SSS0.Px2.p2.6.m6.1.1" xref="A3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml">0.97</mn><mo id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2.2" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px2.p2.6.m6.2.2" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.2.cmml">0.99</mn><mo id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.6.m6.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2"><cn id="A3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.6.m6.1.1">0.97</cn><cn id="A3.SS1.SSS0.Px2.p2.6.m6.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.2">0.99</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.6.m6.2c">[0.97,0.99]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.6.m6.2d">[ 0.97 , 0.99 ]</annotation></semantics></math> performs better for all models. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4" title="Figure 4 ‣ C.1 Grid searching for optimal classifier-free guidance scale and temperature ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> also indicates that <math alttext="\text{cfg}=3.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.7.m7.1"><semantics id="A3.SS1.SSS0.Px2.p2.7.m7.1a"><mrow id="A3.SS1.SSS0.Px2.p2.7.m7.1.1" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3.cmml">3.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.7.m7.1b"><apply id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1"><eq id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3">3.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.7.m7.1c">\text{cfg}=3.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.7.m7.1d">cfg = 3.0</annotation></semantics></math> can achieve a lower FID, while <math alttext="\text{cfg}=4.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.8.m8.1"><semantics id="A3.SS1.SSS0.Px2.p2.8.m8.1a"><mrow id="A3.SS1.SSS0.Px2.p2.8.m8.1.1" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.8.m8.1b"><apply id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1"><eq id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.8.m8.1c">\text{cfg}=4.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.8.m8.1d">cfg = 4.0</annotation></semantics></math> can achieve a better IS. Therefore, we recommend setting <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.9.m9.1"><semantics id="A3.SS1.SSS0.Px2.p2.9.m9.1a"><mi id="A3.SS1.SSS0.Px2.p2.9.m9.1.1" xref="A3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.9.m9.1b"><ci id="A3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.9.m9.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.9.m9.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.9.m9.1d">italic_τ</annotation></semantics></math> to 0.98 for classifier-free guidance and <span class="ltx_text ltx_markedasmath" id="A3.SS1.SSS0.Px2.p2.10.2">cfg</span> to either 3.0 or 4.0 as the default.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Abalation on auto-regressive steps</h3>
<figure class="ltx_table" id="A3.T3">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.4.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.4.4.4">
<tr class="ltx_tr" id="A3.T3.4.4.4.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.4.4.4.5.1"><span class="ltx_text" id="A3.T3.4.4.4.5.1.1" style="background-color:#EFEFEF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.2"><span class="ltx_text" id="A3.T3.4.4.4.5.2.1" style="background-color:#EFEFEF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.3"><span class="ltx_text" id="A3.T3.4.4.4.5.3.1" style="background-color:#EFEFEF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.4"><span class="ltx_text" id="A3.T3.4.4.4.5.4.1" style="background-color:#EFEFEF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.5"><span class="ltx_text" id="A3.T3.4.4.4.5.5.1" style="background-color:#EFEFEF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.6"><span class="ltx_text" id="A3.T3.4.4.4.5.6.1" style="background-color:#EFEFEF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.7"><span class="ltx_text" id="A3.T3.4.4.4.5.7.1" style="background-color:#EFEFEF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.8"><span class="ltx_text" id="A3.T3.4.4.4.5.8.1" style="background-color:#EFEFEF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.9"><span class="ltx_text" id="A3.T3.4.4.4.5.9.1" style="background-color:#EFEFEF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.1.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.1.1.1.1.1.m1.1"><semantics id="A3.T3.1.1.1.1.1.m1.1a"><mo id="A3.T3.1.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.1.1.1.1.1.m1.1b"><ci id="A3.T3.1.1.1.1.1.m1.1.1.cmml" xref="A3.T3.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.1.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.2">4.027</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.3">3.452</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.4">3.431</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.5.1">3.404</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.6">3.419</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.7">3.467</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.8">3.437</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.9">3.421</td>
</tr>
<tr class="ltx_tr" id="A3.T3.2.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.2.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.2.2.2.2.1.m1.1"><semantics id="A3.T3.2.2.2.2.1.m1.1a"><mo id="A3.T3.2.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.2.2.2.2.1.m1.1b"><ci id="A3.T3.2.2.2.2.1.m1.1.1.cmml" xref="A3.T3.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.2.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.2.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.2">184.42</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.3">194.57</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.4">195.74</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.5">197.07</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.6">196.00</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.7">195.29</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.8">194.79</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.9">196.03</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.3.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.3.3.3.3.1.m1.1"><semantics id="A3.T3.3.3.3.3.1.m1.1a"><mo id="A3.T3.3.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.3.3.3.3.1.m1.1b"><ci id="A3.T3.3.3.3.3.1.m1.1.1.cmml" xref="A3.T3.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.3.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.2">0.756</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.3">0.764</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.4">0.764</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.5">0.766</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.6">0.767</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.7">0.763</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.8">0.765</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.9">0.763</td>
</tr>
<tr class="ltx_tr" id="A3.T3.4.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.4.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.4.4.4.4.1.m1.1"><semantics id="A3.T3.4.4.4.4.1.m1.1a"><mo id="A3.T3.4.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.4.4.4.4.1.m1.1b"><ci id="A3.T3.4.4.4.4.1.m1.1.1.cmml" xref="A3.T3.4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.4.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.4.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.2">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.3">0.613</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.4">0.602</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.5">0.608</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.6">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.7">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.8">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.9">0.607</td>
</tr>
<tr class="ltx_tr" id="A3.T3.4.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.4.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.2">0.043</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.3">0.078</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.4">0.114</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.5">0.150</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.6">0.189</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.7">0.227</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.8">0.261</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.9">0.294</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.8.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.8.4.4">
<tr class="ltx_tr" id="A3.T3.8.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.8.4.4.5.1"><span class="ltx_text" id="A3.T3.8.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.2"><span class="ltx_text" id="A3.T3.8.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.3"><span class="ltx_text" id="A3.T3.8.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.4"><span class="ltx_text" id="A3.T3.8.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.5"><span class="ltx_text" id="A3.T3.8.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.6"><span class="ltx_text" id="A3.T3.8.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.7"><span class="ltx_text" id="A3.T3.8.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.8"><span class="ltx_text" id="A3.T3.8.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.9"><span class="ltx_text" id="A3.T3.8.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.5.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.5.1.1.1.1.m1.1"><semantics id="A3.T3.5.1.1.1.1.m1.1a"><mo id="A3.T3.5.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.5.1.1.1.1.m1.1b"><ci id="A3.T3.5.1.1.1.1.m1.1.1.cmml" xref="A3.T3.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.5.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.5.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.2">2.261</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.3">1.912</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.4">1.896</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.5">1.885</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.6">1.885</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.7">1.904</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.8"><span class="ltx_text ltx_font_bold" id="A3.T3.5.1.1.1.8.1">1.871</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.9">1.881</td>
</tr>
<tr class="ltx_tr" id="A3.T3.6.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.6.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.6.2.2.2.1.m1.1"><semantics id="A3.T3.6.2.2.2.1.m1.1a"><mo id="A3.T3.6.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.6.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.6.2.2.2.1.m1.1b"><ci id="A3.T3.6.2.2.2.1.m1.1.1.cmml" xref="A3.T3.6.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.6.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.6.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.2">271.57</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.3">281.46</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.4">281.28</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.5">280.78</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.6">282.38</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.7">280.15</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.8">282.53</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.9">283.92</td>
</tr>
<tr class="ltx_tr" id="A3.T3.7.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.7.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.7.3.3.3.1.m1.1"><semantics id="A3.T3.7.3.3.3.1.m1.1a"><mo id="A3.T3.7.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.7.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.7.3.3.3.1.m1.1b"><ci id="A3.T3.7.3.3.3.1.m1.1.1.cmml" xref="A3.T3.7.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.7.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.7.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.2">0.785</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.3">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.4">0.797</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.5">0.798</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.6">0.799</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.7">0.802</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.8">0.797</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.9">0.802</td>
</tr>
<tr class="ltx_tr" id="A3.T3.8.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.8.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.8.4.4.4.1.m1.1"><semantics id="A3.T3.8.4.4.4.1.m1.1a"><mo id="A3.T3.8.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.8.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.8.4.4.4.1.m1.1b"><ci id="A3.T3.8.4.4.4.1.m1.1.1.cmml" xref="A3.T3.8.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.8.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.8.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.2">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.3">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.4">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.5">0.611</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.6">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.7">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.8">0.605</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.9">0.613</td>
</tr>
<tr class="ltx_tr" id="A3.T3.8.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.8.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.2">0.069</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.3">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.4">0.182</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.5">0.231</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.6">0.309</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.7">0.381</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.8">0.411</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.9">0.539</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.12.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.12.4.4">
<tr class="ltx_tr" id="A3.T3.12.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.12.4.4.5.1"><span class="ltx_text" id="A3.T3.12.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.2"><span class="ltx_text" id="A3.T3.12.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.3"><span class="ltx_text" id="A3.T3.12.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.4"><span class="ltx_text" id="A3.T3.12.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.5"><span class="ltx_text" id="A3.T3.12.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.6"><span class="ltx_text" id="A3.T3.12.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.7"><span class="ltx_text" id="A3.T3.12.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.8"><span class="ltx_text" id="A3.T3.12.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.9"><span class="ltx_text" id="A3.T3.12.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.9.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.9.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.9.1.1.1.1.m1.1"><semantics id="A3.T3.9.1.1.1.1.m1.1a"><mo id="A3.T3.9.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.9.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.9.1.1.1.1.m1.1b"><ci id="A3.T3.9.1.1.1.1.m1.1.1.cmml" xref="A3.T3.9.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.9.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.9.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.2">2.143</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T3.9.1.1.1.3.1">2.081</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.4">2.118</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.5">2.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.6">2.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.7">2.183</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.8">2.096</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.9">2.149</td>
</tr>
<tr class="ltx_tr" id="A3.T3.10.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.10.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.10.2.2.2.1.m1.1"><semantics id="A3.T3.10.2.2.2.1.m1.1a"><mo id="A3.T3.10.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.10.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.10.2.2.2.1.m1.1b"><ci id="A3.T3.10.2.2.2.1.m1.1.1.cmml" xref="A3.T3.10.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.10.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.10.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.2">313.57</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.3">320.94</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.4">318.96</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.5">318.67</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.6">318.94</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.7">318.28</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.8">317.93</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.9">320.62</td>
</tr>
<tr class="ltx_tr" id="A3.T3.11.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.11.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.11.3.3.3.1.m1.1"><semantics id="A3.T3.11.3.3.3.1.m1.1a"><mo id="A3.T3.11.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.11.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.11.3.3.3.1.m1.1b"><ci id="A3.T3.11.3.3.3.1.m1.1.1.cmml" xref="A3.T3.11.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.11.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.11.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.2">0.810</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.3">0.817</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.4">0.815</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.5">0.819</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.6">0.819</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.7">0.820</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.8">0.818</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.9">0.820</td>
</tr>
<tr class="ltx_tr" id="A3.T3.12.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.12.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.12.4.4.4.1.m1.1"><semantics id="A3.T3.12.4.4.4.1.m1.1a"><mo id="A3.T3.12.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.12.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.12.4.4.4.1.m1.1b"><ci id="A3.T3.12.4.4.4.1.m1.1.1.cmml" xref="A3.T3.12.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.12.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.12.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.2">0.586</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.3">0.590</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.4">0.589</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.5">0.595</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.6">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.7">0.589</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.8">0.592</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.9">0.590</td>
</tr>
<tr class="ltx_tr" id="A3.T3.12.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.12.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.2">0.069</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.3">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.4">0.182</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.5">0.231</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.6">0.309</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.7">0.381</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.8">0.411</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.9">0.539</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.16.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.16.4.4">
<tr class="ltx_tr" id="A3.T3.16.4.4.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.16.4.4.5.1"><span class="ltx_text" id="A3.T3.16.4.4.5.1.1" style="background-color:#EFEFEF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.2"><span class="ltx_text" id="A3.T3.16.4.4.5.2.1" style="background-color:#EFEFEF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.3"><span class="ltx_text" id="A3.T3.16.4.4.5.3.1" style="background-color:#EFEFEF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.4"><span class="ltx_text" id="A3.T3.16.4.4.5.4.1" style="background-color:#EFEFEF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.5"><span class="ltx_text" id="A3.T3.16.4.4.5.5.1" style="background-color:#EFEFEF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.6"><span class="ltx_text" id="A3.T3.16.4.4.5.6.1" style="background-color:#EFEFEF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.7"><span class="ltx_text" id="A3.T3.16.4.4.5.7.1" style="background-color:#EFEFEF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.8"><span class="ltx_text" id="A3.T3.16.4.4.5.8.1" style="background-color:#EFEFEF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.9"><span class="ltx_text" id="A3.T3.16.4.4.5.9.1" style="background-color:#EFEFEF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.13.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.13.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.13.1.1.1.1.m1.1"><semantics id="A3.T3.13.1.1.1.1.m1.1a"><mo id="A3.T3.13.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.13.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.13.1.1.1.1.m1.1b"><ci id="A3.T3.13.1.1.1.1.m1.1.1.cmml" xref="A3.T3.13.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.13.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.13.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.2">2.996</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.3">2.371</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.4">2.344</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.5">2.344</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A3.T3.13.1.1.1.6.1">2.323</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.7">2.347</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.8">2.345</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.9">2.362</td>
</tr>
<tr class="ltx_tr" id="A3.T3.14.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.14.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.14.2.2.2.1.m1.1"><semantics id="A3.T3.14.2.2.2.1.m1.1a"><mo id="A3.T3.14.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.14.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.14.2.2.2.1.m1.1b"><ci id="A3.T3.14.2.2.2.1.m1.1.1.cmml" xref="A3.T3.14.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.14.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.14.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.2">211.85</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.3">228.99</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.4">231.36</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.5">231.83</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.6">233.46</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.7">229.20</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.8">230.54</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.9">231.21</td>
</tr>
<tr class="ltx_tr" id="A3.T3.15.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.15.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.15.3.3.3.1.m1.1"><semantics id="A3.T3.15.3.3.3.1.m1.1a"><mo id="A3.T3.15.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.15.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.15.3.3.3.1.m1.1b"><ci id="A3.T3.15.3.3.3.1.m1.1.1.cmml" xref="A3.T3.15.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.15.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.15.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.2">0.765</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.3">0.780</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.4">0.781</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.5">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.6">0.785</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.7">0.782</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.8">0.786</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.9">0.785</td>
</tr>
<tr class="ltx_tr" id="A3.T3.16.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.16.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.16.4.4.4.1.m1.1"><semantics id="A3.T3.16.4.4.4.1.m1.1a"><mo id="A3.T3.16.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.16.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.16.4.4.4.1.m1.1b"><ci id="A3.T3.16.4.4.4.1.m1.1.1.cmml" xref="A3.T3.16.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.16.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.16.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.2">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.3">0.626</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.4">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.5">0.617</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.6">0.616</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.7">0.618</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.8">0.613</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.9">0.617</td>
</tr>
<tr class="ltx_tr" id="A3.T3.16.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.16.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.2">0.079</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.3">0.146</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.4">0.218</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.5">0.293</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.6">0.363</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.7">0.435</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.8">0.554</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.9">0.585</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.20.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.20.4.4">
<tr class="ltx_tr" id="A3.T3.20.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.20.4.4.5.1"><span class="ltx_text" id="A3.T3.20.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.2"><span class="ltx_text" id="A3.T3.20.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.3"><span class="ltx_text" id="A3.T3.20.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.4"><span class="ltx_text" id="A3.T3.20.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.5"><span class="ltx_text" id="A3.T3.20.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.6"><span class="ltx_text" id="A3.T3.20.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.7"><span class="ltx_text" id="A3.T3.20.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.8"><span class="ltx_text" id="A3.T3.20.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.9"><span class="ltx_text" id="A3.T3.20.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.17.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.17.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.17.1.1.1.1.m1.1"><semantics id="A3.T3.17.1.1.1.1.m1.1a"><mo id="A3.T3.17.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.17.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.17.1.1.1.1.m1.1b"><ci id="A3.T3.17.1.1.1.1.m1.1.1.cmml" xref="A3.T3.17.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.17.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.17.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.2">2.042</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.3">1.633</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.4">1.651</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.5">1.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.6">1.637</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.7">1.600</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.8">1.639</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.9"><span class="ltx_text ltx_font_bold" id="A3.T3.17.1.1.1.9.1">1.593</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.18.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.18.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.18.2.2.2.1.m1.1"><semantics id="A3.T3.18.2.2.2.1.m1.1a"><mo id="A3.T3.18.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.18.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.18.2.2.2.1.m1.1b"><ci id="A3.T3.18.2.2.2.1.m1.1.1.cmml" xref="A3.T3.18.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.18.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.18.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.2">282.91</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.3">297.46</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.4">300.76</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.5">299.95</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.6">300.16</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.7">300.96</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.8">302.28</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.9">303.13</td>
</tr>
<tr class="ltx_tr" id="A3.T3.19.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.19.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.19.3.3.3.1.m1.1"><semantics id="A3.T3.19.3.3.3.1.m1.1a"><mo id="A3.T3.19.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.19.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.19.3.3.3.1.m1.1b"><ci id="A3.T3.19.3.3.3.1.m1.1.1.cmml" xref="A3.T3.19.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.19.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.19.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.2">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.3">0.796</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.4">0.802</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.5">0.799</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.6">0.799</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.7">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.8">0.803</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.9">0.801</td>
</tr>
<tr class="ltx_tr" id="A3.T3.20.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.20.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.20.4.4.4.1.m1.1"><semantics id="A3.T3.20.4.4.4.1.m1.1a"><mo id="A3.T3.20.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.20.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.20.4.4.4.1.m1.1b"><ci id="A3.T3.20.4.4.4.1.m1.1.1.cmml" xref="A3.T3.20.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.20.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.20.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.2">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.3">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.4">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.5">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.6">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.7">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.8">0.621</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.9">0.613</td>
</tr>
<tr class="ltx_tr" id="A3.T3.20.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.20.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.2">0.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.3">0.248</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.4">0.361</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.5">0.481</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.6">0.601</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.7">0.743</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.8">0.859</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.9">1.003</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.24.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.24.4.4">
<tr class="ltx_tr" id="A3.T3.24.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.24.4.4.5.1"><span class="ltx_text" id="A3.T3.24.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.2"><span class="ltx_text" id="A3.T3.24.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.3"><span class="ltx_text" id="A3.T3.24.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.4"><span class="ltx_text" id="A3.T3.24.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.5"><span class="ltx_text" id="A3.T3.24.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.6"><span class="ltx_text" id="A3.T3.24.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.7"><span class="ltx_text" id="A3.T3.24.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.8"><span class="ltx_text" id="A3.T3.24.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.9"><span class="ltx_text" id="A3.T3.24.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.21.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.21.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.21.1.1.1.1.m1.1"><semantics id="A3.T3.21.1.1.1.1.m1.1a"><mo id="A3.T3.21.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.21.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.21.1.1.1.1.m1.1b"><ci id="A3.T3.21.1.1.1.1.m1.1.1.cmml" xref="A3.T3.21.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.21.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.21.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.2">1.859</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.3">1.663</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.4">1.706</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.5">1.700</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.6">1.690</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A3.T3.21.1.1.1.7.1">1.649</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.8">1.714</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.9">1.674</td>
</tr>
<tr class="ltx_tr" id="A3.T3.22.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.22.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.22.2.2.2.1.m1.1"><semantics id="A3.T3.22.2.2.2.1.m1.1a"><mo id="A3.T3.22.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.22.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.22.2.2.2.1.m1.1b"><ci id="A3.T3.22.2.2.2.1.m1.1.1.cmml" xref="A3.T3.22.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.22.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.22.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.2">313.27</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.3">325.78</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.4">325.52</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.5">329.41</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.6">326.76</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.7">327.20</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.8">330.74</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.9">328.52</td>
</tr>
<tr class="ltx_tr" id="A3.T3.23.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.23.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.23.3.3.3.1.m1.1"><semantics id="A3.T3.23.3.3.3.1.m1.1a"><mo id="A3.T3.23.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.23.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.23.3.3.3.1.m1.1b"><ci id="A3.T3.23.3.3.3.1.m1.1.1.cmml" xref="A3.T3.23.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.23.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.23.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.2">0.796</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.3">0.807</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.4">0.813</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.5">0.810</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.6">0.809</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.7">0.810</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.8">0.811</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.9">0.813</td>
</tr>
<tr class="ltx_tr" id="A3.T3.24.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.24.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.24.4.4.4.1.m1.1"><semantics id="A3.T3.24.4.4.4.1.m1.1a"><mo id="A3.T3.24.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.24.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.24.4.4.4.1.m1.1b"><ci id="A3.T3.24.4.4.4.1.m1.1.1.cmml" xref="A3.T3.24.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.24.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.24.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.2">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.3">0.617</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.4">0.612</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.5">0.612</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.6">0.617</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.7">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.8">0.605</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.9">0.609</td>
</tr>
<tr class="ltx_tr" id="A3.T3.24.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.24.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.2">0.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.3">0.248</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.4">0.362</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.5">0.481</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.6">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.7">0.747</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.8">0.862</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.9">1.003</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.28" style="width:433.6pt;">
<figure class="ltx_table ltx_align_center" id="A3.T3.28.4">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.28.4.4">
<tr class="ltx_tr" id="A3.T3.28.4.4.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.28.4.4.5.1"><span class="ltx_text" id="A3.T3.28.4.4.5.1.1" style="background-color:#EFEFEF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.2"><span class="ltx_text" id="A3.T3.28.4.4.5.2.1" style="background-color:#EFEFEF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.3"><span class="ltx_text" id="A3.T3.28.4.4.5.3.1" style="background-color:#EFEFEF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.4"><span class="ltx_text" id="A3.T3.28.4.4.5.4.1" style="background-color:#EFEFEF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.5"><span class="ltx_text" id="A3.T3.28.4.4.5.5.1" style="background-color:#EFEFEF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.6"><span class="ltx_text" id="A3.T3.28.4.4.5.6.1" style="background-color:#EFEFEF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.7"><span class="ltx_text" id="A3.T3.28.4.4.5.7.1" style="background-color:#EFEFEF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.8"><span class="ltx_text" id="A3.T3.28.4.4.5.8.1" style="background-color:#EFEFEF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.9"><span class="ltx_text" id="A3.T3.28.4.4.5.9.1" style="background-color:#EFEFEF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.25.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.25.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.25.1.1.1.1.m1.1"><semantics id="A3.T3.25.1.1.1.1.m1.1a"><mo id="A3.T3.25.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.25.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.25.1.1.1.1.m1.1b"><ci id="A3.T3.25.1.1.1.1.m1.1.1.cmml" xref="A3.T3.25.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.25.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.25.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.2">2.849</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.3">2.174</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.4">2.106</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.5">2.083</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.6">2.157</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A3.T3.25.1.1.1.7.1">2.043</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.8">2.133</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.9">2.112</td>
</tr>
<tr class="ltx_tr" id="A3.T3.26.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.26.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.26.2.2.2.1.m1.1"><semantics id="A3.T3.26.2.2.2.1.m1.1a"><mo id="A3.T3.26.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.26.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.26.2.2.2.1.m1.1b"><ci id="A3.T3.26.2.2.2.1.m1.1.1.cmml" xref="A3.T3.26.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.26.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.26.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.2">213.62</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.3">232.50</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.4">235.90</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.5">239.18</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.6">236.30</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.7">239.27</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.8">236.90</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.9">237.74</td>
</tr>
<tr class="ltx_tr" id="A3.T3.27.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.27.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.27.3.3.3.1.m1.1"><semantics id="A3.T3.27.3.3.3.1.m1.1a"><mo id="A3.T3.27.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.27.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.27.3.3.3.1.m1.1b"><ci id="A3.T3.27.3.3.3.1.m1.1.1.cmml" xref="A3.T3.27.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.27.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.27.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.2">0.766</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.3">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.4">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.5">0.784</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.6">0.787</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.7">0.785</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.8">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.9">0.783</td>
</tr>
<tr class="ltx_tr" id="A3.T3.28.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.28.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.28.4.4.4.1.m1.1"><semantics id="A3.T3.28.4.4.4.1.m1.1a"><mo id="A3.T3.28.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.28.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.28.4.4.4.1.m1.1b"><ci id="A3.T3.28.4.4.4.1.m1.1.1.cmml" xref="A3.T3.28.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.28.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.28.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.2">0.634</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.3">0.621</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.4">0.622</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.5">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.6">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.7">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.8">0.630</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.9">0.625</td>
</tr>
<tr class="ltx_tr" id="A3.T3.28.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.28.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.2">0.128</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.3">0.237</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.4">0.348</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.5">0.463</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.6">0.585</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.7">0.705</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.8">0.836</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.9">0.969</td>
</tr>
</table>
</figure>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.32.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.32.4.4">
<tr class="ltx_tr" id="A3.T3.32.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.32.4.4.5.1"><span class="ltx_text" id="A3.T3.32.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.2"><span class="ltx_text" id="A3.T3.32.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.3"><span class="ltx_text" id="A3.T3.32.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.4"><span class="ltx_text" id="A3.T3.32.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.5"><span class="ltx_text" id="A3.T3.32.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.6"><span class="ltx_text" id="A3.T3.32.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.7"><span class="ltx_text" id="A3.T3.32.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.8"><span class="ltx_text" id="A3.T3.32.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.9"><span class="ltx_text" id="A3.T3.32.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.29.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.29.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.29.1.1.1.1.m1.1"><semantics id="A3.T3.29.1.1.1.1.m1.1a"><mo id="A3.T3.29.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.29.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.29.1.1.1.1.m1.1b"><ci id="A3.T3.29.1.1.1.1.m1.1.1.cmml" xref="A3.T3.29.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.29.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.29.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.2">1.859</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.3">1.551</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.4">1.567</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T3.29.1.1.1.5.1">1.542</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.6">1.558</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.7">1.574</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.8">1.901</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.9">1.573</td>
</tr>
<tr class="ltx_tr" id="A3.T3.30.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.30.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.30.2.2.2.1.m1.1"><semantics id="A3.T3.30.2.2.2.1.m1.1a"><mo id="A3.T3.30.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.30.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.30.2.2.2.1.m1.1b"><ci id="A3.T3.30.2.2.2.1.m1.1.1.cmml" xref="A3.T3.30.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.30.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.30.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.2">307.07</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.3">322.79</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.4">325.04</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.5">324.17</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.6">326.59</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.7">321.93</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.8">320.48</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.9">326.27</td>
</tr>
<tr class="ltx_tr" id="A3.T3.31.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.31.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.31.3.3.3.1.m1.1"><semantics id="A3.T3.31.3.3.3.1.m1.1a"><mo id="A3.T3.31.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.31.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.31.3.3.3.1.m1.1b"><ci id="A3.T3.31.3.3.3.1.m1.1.1.cmml" xref="A3.T3.31.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.31.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.31.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.2">0.787</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.3">0.802</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.4">0.807</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.5">0.806</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.6">0.808</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.7">0.806</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.8">0.804</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.9">0.807</td>
</tr>
<tr class="ltx_tr" id="A3.T3.32.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.32.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.32.4.4.4.1.m1.1"><semantics id="A3.T3.32.4.4.4.1.m1.1a"><mo id="A3.T3.32.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.32.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.32.4.4.4.1.m1.1b"><ci id="A3.T3.32.4.4.4.1.m1.1.1.cmml" xref="A3.T3.32.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.32.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.32.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.2">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.3">0.622</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.4">0.622</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.5">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.6">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.7">0.616</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.8">0.615</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.9">0.620</td>
</tr>
<tr class="ltx_tr" id="A3.T3.32.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.32.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.2">0.235</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.3">0.420</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.4">0.606</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.5">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.6">0.994</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.7">1.197</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.8">1.417</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.9">1.659</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.36.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.36.4.4">
<tr class="ltx_tr" id="A3.T3.36.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.36.4.4.5.1"><span class="ltx_text" id="A3.T3.36.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.2"><span class="ltx_text" id="A3.T3.36.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.3"><span class="ltx_text" id="A3.T3.36.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.4"><span class="ltx_text" id="A3.T3.36.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.5"><span class="ltx_text" id="A3.T3.36.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.6"><span class="ltx_text" id="A3.T3.36.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.7"><span class="ltx_text" id="A3.T3.36.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.8"><span class="ltx_text" id="A3.T3.36.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.9"><span class="ltx_text" id="A3.T3.36.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.33.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.33.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;"> </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.33.1.1.1.1.m1.1"><semantics id="A3.T3.33.1.1.1.1.m1.1a"><mo id="A3.T3.33.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.33.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T3.33.1.1.1.1.m1.1b"><ci id="A3.T3.33.1.1.1.1.m1.1.1.cmml" xref="A3.T3.33.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.33.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.33.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.2">1.718</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T3.33.1.1.1.3.1">1.661</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.4">1.669</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.5">1.669</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.6">1.706</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.7">1.703</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.8">1.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.9">1.726</td>
</tr>
<tr class="ltx_tr" id="A3.T3.34.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.34.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.34.2.2.2.1.m1.1"><semantics id="A3.T3.34.2.2.2.1.m1.1a"><mo id="A3.T3.34.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.34.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.34.2.2.2.1.m1.1b"><ci id="A3.T3.34.2.2.2.1.m1.1.1.cmml" xref="A3.T3.34.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.34.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.34.2.2.2.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.2">325.62</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.3">339.62</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.4">339.00</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.5">339.71</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.6">340.75</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.7">338.80</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.8">341.01</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.9">340.00</td>
</tr>
<tr class="ltx_tr" id="A3.T3.35.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.35.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.35.3.3.3.1.m1.1"><semantics id="A3.T3.35.3.3.3.1.m1.1a"><mo id="A3.T3.35.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.35.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.35.3.3.3.1.m1.1b"><ci id="A3.T3.35.3.3.3.1.m1.1.1.cmml" xref="A3.T3.35.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.35.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.35.3.3.3.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.2">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.3">0.814</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.4">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.5">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.6">0.815</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.7">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.8">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.9">0.817</td>
</tr>
<tr class="ltx_tr" id="A3.T3.36.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.36.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.36.4.4.4.1.m1.1"><semantics id="A3.T3.36.4.4.4.1.m1.1a"><mo id="A3.T3.36.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.36.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T3.36.4.4.4.1.m1.1b"><ci id="A3.T3.36.4.4.4.1.m1.1.1.cmml" xref="A3.T3.36.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.36.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.36.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.2">0.610</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.3">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.4">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.5">0.608</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.6">0.610</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.7">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.8">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.9">0.611</td>
</tr>
<tr class="ltx_tr" id="A3.T3.36.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.36.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.2">0.235</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.3">0.420</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.4">0.606</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.5">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.6">0.994</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.7">1.197</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.8">1.417</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.9">1.659</td>
</tr>
</table>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation in auto-regressive steps. <math alttext="(\text{cfg},\tau)" class="ltx_Math" display="inline" id="A3.T3.47.m1.2"><semantics id="A3.T3.47.m1.2b"><mrow id="A3.T3.47.m1.2.3.2" xref="A3.T3.47.m1.2.3.1.cmml"><mo id="A3.T3.47.m1.2.3.2.1" stretchy="false" xref="A3.T3.47.m1.2.3.1.cmml">(</mo><mtext id="A3.T3.47.m1.1.1" xref="A3.T3.47.m1.1.1a.cmml">cfg</mtext><mo id="A3.T3.47.m1.2.3.2.2" xref="A3.T3.47.m1.2.3.1.cmml">,</mo><mi id="A3.T3.47.m1.2.2" xref="A3.T3.47.m1.2.2.cmml">τ</mi><mo id="A3.T3.47.m1.2.3.2.3" stretchy="false" xref="A3.T3.47.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.47.m1.2c"><interval closure="open" id="A3.T3.47.m1.2.3.1.cmml" xref="A3.T3.47.m1.2.3.2"><ci id="A3.T3.47.m1.1.1a.cmml" xref="A3.T3.47.m1.1.1"><mtext id="A3.T3.47.m1.1.1.cmml" xref="A3.T3.47.m1.1.1">cfg</mtext></ci><ci id="A3.T3.47.m1.2.2.cmml" xref="A3.T3.47.m1.2.2">𝜏</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.47.m1.2d">(\text{cfg},\tau)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.47.m1.2e">( cfg , italic_τ )</annotation></semantics></math> combinations: Base, <math alttext="(1.0,0.93)" class="ltx_Math" display="inline" id="A3.T3.48.m2.2"><semantics id="A3.T3.48.m2.2b"><mrow id="A3.T3.48.m2.2.3.2" xref="A3.T3.48.m2.2.3.1.cmml"><mo id="A3.T3.48.m2.2.3.2.1" stretchy="false" xref="A3.T3.48.m2.2.3.1.cmml">(</mo><mn id="A3.T3.48.m2.1.1" xref="A3.T3.48.m2.1.1.cmml">1.0</mn><mo id="A3.T3.48.m2.2.3.2.2" xref="A3.T3.48.m2.2.3.1.cmml">,</mo><mn id="A3.T3.48.m2.2.2" xref="A3.T3.48.m2.2.2.cmml">0.93</mn><mo id="A3.T3.48.m2.2.3.2.3" stretchy="false" xref="A3.T3.48.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.48.m2.2c"><interval closure="open" id="A3.T3.48.m2.2.3.1.cmml" xref="A3.T3.48.m2.2.3.2"><cn id="A3.T3.48.m2.1.1.cmml" type="float" xref="A3.T3.48.m2.1.1">1.0</cn><cn id="A3.T3.48.m2.2.2.cmml" type="float" xref="A3.T3.48.m2.2.2">0.93</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.48.m2.2d">(1.0,0.93)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.48.m2.2e">( 1.0 , 0.93 )</annotation></semantics></math>, <math alttext="(3.1,0.98)" class="ltx_Math" display="inline" id="A3.T3.49.m3.2"><semantics id="A3.T3.49.m3.2b"><mrow id="A3.T3.49.m3.2.3.2" xref="A3.T3.49.m3.2.3.1.cmml"><mo id="A3.T3.49.m3.2.3.2.1" stretchy="false" xref="A3.T3.49.m3.2.3.1.cmml">(</mo><mn id="A3.T3.49.m3.1.1" xref="A3.T3.49.m3.1.1.cmml">3.1</mn><mo id="A3.T3.49.m3.2.3.2.2" xref="A3.T3.49.m3.2.3.1.cmml">,</mo><mn id="A3.T3.49.m3.2.2" xref="A3.T3.49.m3.2.2.cmml">0.98</mn><mo id="A3.T3.49.m3.2.3.2.3" stretchy="false" xref="A3.T3.49.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.49.m3.2c"><interval closure="open" id="A3.T3.49.m3.2.3.1.cmml" xref="A3.T3.49.m3.2.3.2"><cn id="A3.T3.49.m3.1.1.cmml" type="float" xref="A3.T3.49.m3.1.1">3.1</cn><cn id="A3.T3.49.m3.2.2.cmml" type="float" xref="A3.T3.49.m3.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.49.m3.2d">(3.1,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.49.m3.2e">( 3.1 , 0.98 )</annotation></semantics></math>, <math alttext="(4.1,0.97)" class="ltx_Math" display="inline" id="A3.T3.50.m4.2"><semantics id="A3.T3.50.m4.2b"><mrow id="A3.T3.50.m4.2.3.2" xref="A3.T3.50.m4.2.3.1.cmml"><mo id="A3.T3.50.m4.2.3.2.1" stretchy="false" xref="A3.T3.50.m4.2.3.1.cmml">(</mo><mn id="A3.T3.50.m4.1.1" xref="A3.T3.50.m4.1.1.cmml">4.1</mn><mo id="A3.T3.50.m4.2.3.2.2" xref="A3.T3.50.m4.2.3.1.cmml">,</mo><mn id="A3.T3.50.m4.2.2" xref="A3.T3.50.m4.2.2.cmml">0.97</mn><mo id="A3.T3.50.m4.2.3.2.3" stretchy="false" xref="A3.T3.50.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.50.m4.2c"><interval closure="open" id="A3.T3.50.m4.2.3.1.cmml" xref="A3.T3.50.m4.2.3.2"><cn id="A3.T3.50.m4.1.1.cmml" type="float" xref="A3.T3.50.m4.1.1">4.1</cn><cn id="A3.T3.50.m4.2.2.cmml" type="float" xref="A3.T3.50.m4.2.2">0.97</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.50.m4.2d">(4.1,0.97)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.50.m4.2e">( 4.1 , 0.97 )</annotation></semantics></math>; Large, <math alttext="(1.0,0.94)" class="ltx_Math" display="inline" id="A3.T3.51.m5.2"><semantics id="A3.T3.51.m5.2b"><mrow id="A3.T3.51.m5.2.3.2" xref="A3.T3.51.m5.2.3.1.cmml"><mo id="A3.T3.51.m5.2.3.2.1" stretchy="false" xref="A3.T3.51.m5.2.3.1.cmml">(</mo><mn id="A3.T3.51.m5.1.1" xref="A3.T3.51.m5.1.1.cmml">1.0</mn><mo id="A3.T3.51.m5.2.3.2.2" xref="A3.T3.51.m5.2.3.1.cmml">,</mo><mn id="A3.T3.51.m5.2.2" xref="A3.T3.51.m5.2.2.cmml">0.94</mn><mo id="A3.T3.51.m5.2.3.2.3" stretchy="false" xref="A3.T3.51.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.51.m5.2c"><interval closure="open" id="A3.T3.51.m5.2.3.1.cmml" xref="A3.T3.51.m5.2.3.2"><cn id="A3.T3.51.m5.1.1.cmml" type="float" xref="A3.T3.51.m5.1.1">1.0</cn><cn id="A3.T3.51.m5.2.2.cmml" type="float" xref="A3.T3.51.m5.2.2">0.94</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.51.m5.2d">(1.0,0.94)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.51.m5.2e">( 1.0 , 0.94 )</annotation></semantics></math>, <math alttext="(3.0,0.98)" class="ltx_Math" display="inline" id="A3.T3.52.m6.2"><semantics id="A3.T3.52.m6.2b"><mrow id="A3.T3.52.m6.2.3.2" xref="A3.T3.52.m6.2.3.1.cmml"><mo id="A3.T3.52.m6.2.3.2.1" stretchy="false" xref="A3.T3.52.m6.2.3.1.cmml">(</mo><mn id="A3.T3.52.m6.1.1" xref="A3.T3.52.m6.1.1.cmml">3.0</mn><mo id="A3.T3.52.m6.2.3.2.2" xref="A3.T3.52.m6.2.3.1.cmml">,</mo><mn id="A3.T3.52.m6.2.2" xref="A3.T3.52.m6.2.2.cmml">0.98</mn><mo id="A3.T3.52.m6.2.3.2.3" stretchy="false" xref="A3.T3.52.m6.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.52.m6.2c"><interval closure="open" id="A3.T3.52.m6.2.3.1.cmml" xref="A3.T3.52.m6.2.3.2"><cn id="A3.T3.52.m6.1.1.cmml" type="float" xref="A3.T3.52.m6.1.1">3.0</cn><cn id="A3.T3.52.m6.2.2.cmml" type="float" xref="A3.T3.52.m6.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.52.m6.2d">(3.0,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.52.m6.2e">( 3.0 , 0.98 )</annotation></semantics></math>, <math alttext="(3.9,0.98)" class="ltx_Math" display="inline" id="A3.T3.53.m7.2"><semantics id="A3.T3.53.m7.2b"><mrow id="A3.T3.53.m7.2.3.2" xref="A3.T3.53.m7.2.3.1.cmml"><mo id="A3.T3.53.m7.2.3.2.1" stretchy="false" xref="A3.T3.53.m7.2.3.1.cmml">(</mo><mn id="A3.T3.53.m7.1.1" xref="A3.T3.53.m7.1.1.cmml">3.9</mn><mo id="A3.T3.53.m7.2.3.2.2" xref="A3.T3.53.m7.2.3.1.cmml">,</mo><mn id="A3.T3.53.m7.2.2" xref="A3.T3.53.m7.2.2.cmml">0.98</mn><mo id="A3.T3.53.m7.2.3.2.3" stretchy="false" xref="A3.T3.53.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.53.m7.2c"><interval closure="open" id="A3.T3.53.m7.2.3.1.cmml" xref="A3.T3.53.m7.2.3.2"><cn id="A3.T3.53.m7.1.1.cmml" type="float" xref="A3.T3.53.m7.1.1">3.9</cn><cn id="A3.T3.53.m7.2.2.cmml" type="float" xref="A3.T3.53.m7.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.53.m7.2d">(3.9,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.53.m7.2e">( 3.9 , 0.98 )</annotation></semantics></math>; Huge, <math alttext="(1.0,0.95)" class="ltx_Math" display="inline" id="A3.T3.54.m8.2"><semantics id="A3.T3.54.m8.2b"><mrow id="A3.T3.54.m8.2.3.2" xref="A3.T3.54.m8.2.3.1.cmml"><mo id="A3.T3.54.m8.2.3.2.1" stretchy="false" xref="A3.T3.54.m8.2.3.1.cmml">(</mo><mn id="A3.T3.54.m8.1.1" xref="A3.T3.54.m8.1.1.cmml">1.0</mn><mo id="A3.T3.54.m8.2.3.2.2" xref="A3.T3.54.m8.2.3.1.cmml">,</mo><mn id="A3.T3.54.m8.2.2" xref="A3.T3.54.m8.2.2.cmml">0.95</mn><mo id="A3.T3.54.m8.2.3.2.3" stretchy="false" xref="A3.T3.54.m8.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.54.m8.2c"><interval closure="open" id="A3.T3.54.m8.2.3.1.cmml" xref="A3.T3.54.m8.2.3.2"><cn id="A3.T3.54.m8.1.1.cmml" type="float" xref="A3.T3.54.m8.1.1">1.0</cn><cn id="A3.T3.54.m8.2.2.cmml" type="float" xref="A3.T3.54.m8.2.2">0.95</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.54.m8.2d">(1.0,0.95)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.54.m8.2e">( 1.0 , 0.95 )</annotation></semantics></math>, <math alttext="(3.9,0.99)" class="ltx_Math" display="inline" id="A3.T3.55.m9.2"><semantics id="A3.T3.55.m9.2b"><mrow id="A3.T3.55.m9.2.3.2" xref="A3.T3.55.m9.2.3.1.cmml"><mo id="A3.T3.55.m9.2.3.2.1" stretchy="false" xref="A3.T3.55.m9.2.3.1.cmml">(</mo><mn id="A3.T3.55.m9.1.1" xref="A3.T3.55.m9.1.1.cmml">3.9</mn><mo id="A3.T3.55.m9.2.3.2.2" xref="A3.T3.55.m9.2.3.1.cmml">,</mo><mn id="A3.T3.55.m9.2.2" xref="A3.T3.55.m9.2.2.cmml">0.99</mn><mo id="A3.T3.55.m9.2.3.2.3" stretchy="false" xref="A3.T3.55.m9.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.55.m9.2c"><interval closure="open" id="A3.T3.55.m9.2.3.1.cmml" xref="A3.T3.55.m9.2.3.2"><cn id="A3.T3.55.m9.1.1.cmml" type="float" xref="A3.T3.55.m9.1.1">3.9</cn><cn id="A3.T3.55.m9.2.2.cmml" type="float" xref="A3.T3.55.m9.2.2">0.99</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.55.m9.2d">(3.9,0.99)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.55.m9.2e">( 3.9 , 0.99 )</annotation></semantics></math>, <math alttext="(4.3,0.98)" class="ltx_Math" display="inline" id="A3.T3.56.m10.2"><semantics id="A3.T3.56.m10.2b"><mrow id="A3.T3.56.m10.2.3.2" xref="A3.T3.56.m10.2.3.1.cmml"><mo id="A3.T3.56.m10.2.3.2.1" stretchy="false" xref="A3.T3.56.m10.2.3.1.cmml">(</mo><mn id="A3.T3.56.m10.1.1" xref="A3.T3.56.m10.1.1.cmml">4.3</mn><mo id="A3.T3.56.m10.2.3.2.2" xref="A3.T3.56.m10.2.3.1.cmml">,</mo><mn id="A3.T3.56.m10.2.2" xref="A3.T3.56.m10.2.2.cmml">0.98</mn><mo id="A3.T3.56.m10.2.3.2.3" stretchy="false" xref="A3.T3.56.m10.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.56.m10.2c"><interval closure="open" id="A3.T3.56.m10.2.3.1.cmml" xref="A3.T3.56.m10.2.3.2"><cn id="A3.T3.56.m10.1.1.cmml" type="float" xref="A3.T3.56.m10.1.1">4.3</cn><cn id="A3.T3.56.m10.2.2.cmml" type="float" xref="A3.T3.56.m10.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.56.m10.2d">(4.3,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.56.m10.2e">( 4.3 , 0.98 )</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">Unlike the typical next token prediction that predicts only the next token in raster order, the generalized next token prediction can predict multiple tokens in random order, referred to as the next set-of-token prediction in <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>. As mentioned in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS5" title="3.5 Sampling in Next Set-of-Tokens Prediction ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.5</span></a>, we use an iterative sampling strategy with a cosine step schedule. The auto-regressive steps <math alttext="N" class="ltx_Math" display="inline" id="A3.SS2.p1.1.m1.1"><semantics id="A3.SS2.p1.1.m1.1a"><mi id="A3.SS2.p1.1.m1.1.1" xref="A3.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p1.1.m1.1b"><ci id="A3.SS2.p1.1.m1.1.1.cmml" xref="A3.SS2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p1.1.m1.1d">italic_N</annotation></semantics></math> directly affect image quality and sampling efficiency.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.2">We started with <math alttext="T=32" class="ltx_Math" display="inline" id="A3.SS2.p2.1.m1.1"><semantics id="A3.SS2.p2.1.m1.1a"><mrow id="A3.SS2.p2.1.m1.1.1" xref="A3.SS2.p2.1.m1.1.1.cmml"><mi id="A3.SS2.p2.1.m1.1.1.2" xref="A3.SS2.p2.1.m1.1.1.2.cmml">T</mi><mo id="A3.SS2.p2.1.m1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="A3.SS2.p2.1.m1.1.1.3" xref="A3.SS2.p2.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.1.m1.1b"><apply id="A3.SS2.p2.1.m1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1"><eq id="A3.SS2.p2.1.m1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1"></eq><ci id="A3.SS2.p2.1.m1.1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.1.2">𝑇</ci><cn id="A3.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="A3.SS2.p2.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.1.m1.1c">T=32</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p2.1.m1.1d">italic_T = 32</annotation></semantics></math> and incrementally increased by 32 to 256. Note that at <math alttext="T=256" class="ltx_Math" display="inline" id="A3.SS2.p2.2.m2.1"><semantics id="A3.SS2.p2.2.m2.1a"><mrow id="A3.SS2.p2.2.m2.1.1" xref="A3.SS2.p2.2.m2.1.1.cmml"><mi id="A3.SS2.p2.2.m2.1.1.2" xref="A3.SS2.p2.2.m2.1.1.2.cmml">T</mi><mo id="A3.SS2.p2.2.m2.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="A3.SS2.p2.2.m2.1.1.3" xref="A3.SS2.p2.2.m2.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.2.m2.1b"><apply id="A3.SS2.p2.2.m2.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1"><eq id="A3.SS2.p2.2.m2.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1"></eq><ci id="A3.SS2.p2.2.m2.1.1.2.cmml" xref="A3.SS2.p2.2.m2.1.1.2">𝑇</ci><cn id="A3.SS2.p2.2.m2.1.1.3.cmml" type="integer" xref="A3.SS2.p2.2.m2.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.2.m2.1c">T=256</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p2.2.m2.1d">italic_T = 256</annotation></semantics></math>, the next set-of-tokens prediction decays to the typical next token prediction. We conducted experiments both with and without classifier-free guidance. The former requires additional null condition inference, thus doubling the computational cost.</p>
</div>
<figure class="ltx_figure" id="A3.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf1.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span><span class="ltx_text ltx_font_italic" id="A3.F5.sf1.2.1">One step</span> generateion. (AR Steps=1)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf2.g1" src="x11.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf2.2.1">set-of-tokens</span> prediction. (AR Steps: 8)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf3.g1" src="x12.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf3.2.1">set-of-tokens</span> prediction. (AR Steps: 16)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf4.g1" src="x13.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf4.2.1">set-of-tokens</span> prediction. (AR Steps: 32)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf5.g1" src="x14.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf5.2.1">set-of-tokens</span> prediction. (AR Steps: 64)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf6.g1" src="x15.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf6.2.1">set-of-tokens</span> prediction. (AR Steps: 128)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf7.g1" src="x16.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(g) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf7.2.1">token</span> prediction. (AR Steps: 256)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="A3.F5.6.1">Uncurated</span> <math alttext="256\times 256" class="ltx_Math" display="inline" id="A3.F5.3.m1.1"><semantics id="A3.F5.3.m1.1b"><mrow id="A3.F5.3.m1.1.1" xref="A3.F5.3.m1.1.1.cmml"><mn id="A3.F5.3.m1.1.1.2" xref="A3.F5.3.m1.1.1.2.cmml">256</mn><mo id="A3.F5.3.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A3.F5.3.m1.1.1.1.cmml">×</mo><mn id="A3.F5.3.m1.1.1.3" xref="A3.F5.3.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.F5.3.m1.1c"><apply id="A3.F5.3.m1.1.1.cmml" xref="A3.F5.3.m1.1.1"><times id="A3.F5.3.m1.1.1.1.cmml" xref="A3.F5.3.m1.1.1.1"></times><cn id="A3.F5.3.m1.1.1.2.cmml" type="integer" xref="A3.F5.3.m1.1.1.2">256</cn><cn id="A3.F5.3.m1.1.1.3.cmml" type="integer" xref="A3.F5.3.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.3.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A3.F5.3.m1.1e">256 × 256</annotation></semantics></math> D-JEPA-H samples with different auto-regressive steps. <math alttext="\text{cfg}=3.9,\tau=0.99" class="ltx_Math" display="inline" id="A3.F5.4.m2.2"><semantics id="A3.F5.4.m2.2b"><mrow id="A3.F5.4.m2.2.2.2" xref="A3.F5.4.m2.2.2.3.cmml"><mrow id="A3.F5.4.m2.1.1.1.1" xref="A3.F5.4.m2.1.1.1.1.cmml"><mtext id="A3.F5.4.m2.1.1.1.1.2" xref="A3.F5.4.m2.1.1.1.1.2a.cmml">cfg</mtext><mo id="A3.F5.4.m2.1.1.1.1.1" xref="A3.F5.4.m2.1.1.1.1.1.cmml">=</mo><mn id="A3.F5.4.m2.1.1.1.1.3" xref="A3.F5.4.m2.1.1.1.1.3.cmml">3.9</mn></mrow><mo id="A3.F5.4.m2.2.2.2.3" xref="A3.F5.4.m2.2.2.3a.cmml">,</mo><mrow id="A3.F5.4.m2.2.2.2.2" xref="A3.F5.4.m2.2.2.2.2.cmml"><mi id="A3.F5.4.m2.2.2.2.2.2" xref="A3.F5.4.m2.2.2.2.2.2.cmml">τ</mi><mo id="A3.F5.4.m2.2.2.2.2.1" xref="A3.F5.4.m2.2.2.2.2.1.cmml">=</mo><mn id="A3.F5.4.m2.2.2.2.2.3" xref="A3.F5.4.m2.2.2.2.2.3.cmml">0.99</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.F5.4.m2.2c"><apply id="A3.F5.4.m2.2.2.3.cmml" xref="A3.F5.4.m2.2.2.2"><csymbol cd="ambiguous" id="A3.F5.4.m2.2.2.3a.cmml" xref="A3.F5.4.m2.2.2.2.3">formulae-sequence</csymbol><apply id="A3.F5.4.m2.1.1.1.1.cmml" xref="A3.F5.4.m2.1.1.1.1"><eq id="A3.F5.4.m2.1.1.1.1.1.cmml" xref="A3.F5.4.m2.1.1.1.1.1"></eq><ci id="A3.F5.4.m2.1.1.1.1.2a.cmml" xref="A3.F5.4.m2.1.1.1.1.2"><mtext id="A3.F5.4.m2.1.1.1.1.2.cmml" xref="A3.F5.4.m2.1.1.1.1.2">cfg</mtext></ci><cn id="A3.F5.4.m2.1.1.1.1.3.cmml" type="float" xref="A3.F5.4.m2.1.1.1.1.3">3.9</cn></apply><apply id="A3.F5.4.m2.2.2.2.2.cmml" xref="A3.F5.4.m2.2.2.2.2"><eq id="A3.F5.4.m2.2.2.2.2.1.cmml" xref="A3.F5.4.m2.2.2.2.2.1"></eq><ci id="A3.F5.4.m2.2.2.2.2.2.cmml" xref="A3.F5.4.m2.2.2.2.2.2">𝜏</ci><cn id="A3.F5.4.m2.2.2.2.2.3.cmml" type="float" xref="A3.F5.4.m2.2.2.2.2.3">0.99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.4.m2.2d">\text{cfg}=3.9,\tau=0.99</annotation><annotation encoding="application/x-llamapun" id="A3.F5.4.m2.2e">cfg = 3.9 , italic_τ = 0.99</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.p3">
<p class="ltx_p" id="A3.SS2.p3.1">The results are summarized in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T3" title="Table 3 ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3</span></a>. We found that sampling with more than 64 steps for models across all scales significantly outperforms 32 steps. We also visualize the samples in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F5" title="Figure 5 ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>. Notably, at 64 steps, the sampled images are already very close to the optimal results more efficiently. Contrary to our initial assumptions, we discovered that <span class="ltx_text ltx_font_italic" id="A3.SS2.p3.1.1">achieving the best sampling performance does not necessarily require 256 steps.</span> This highlights the advantage of the next set-of-token prediction over typical next-token prediction in terms of sampling efficiency.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.p4">
<p class="ltx_p" id="A3.SS2.p4.1">Another interesting observation is that the steps required to achieve the best FID consistently decrease as the model size increases. Specifically, we achieve the best performance for the huge model with only 64 steps.</p>
</div>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Sampling efficiency.</h4>
<figure class="ltx_table" id="A3.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T4.5">
<tr class="ltx_tr" id="A3.T4.5.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.5.6">Model</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.5.7">cfg</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.1"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T4.1.1.1.m1.1"><semantics id="A3.T4.1.1.1.m1.1a"><mi id="A3.T4.1.1.1.m1.1.1" xref="A3.T4.1.1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.T4.1.1.1.m1.1b"><ci id="A3.T4.1.1.1.m1.1.1.cmml" xref="A3.T4.1.1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.1.1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T4.1.1.1.m1.1d">italic_τ</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.5.8">AR Steps</td>
<td class="ltx_td ltx_align_center" id="A3.T4.2.2.2">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T4.2.2.2.m1.1"><semantics id="A3.T4.2.2.2.m1.1a"><mo id="A3.T4.2.2.2.m1.1.1" stretchy="false" xref="A3.T4.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A3.T4.2.2.2.m1.1b"><ci id="A3.T4.2.2.2.m1.1.1.cmml" xref="A3.T4.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.2.2.2.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T4.3.3.3">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T4.3.3.3.m1.1"><semantics id="A3.T4.3.3.3.m1.1a"><mo id="A3.T4.3.3.3.m1.1.1" stretchy="false" xref="A3.T4.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T4.3.3.3.m1.1b"><ci id="A3.T4.3.3.3.m1.1.1.cmml" xref="A3.T4.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T4.4.4.4">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T4.4.4.4.m1.1"><semantics id="A3.T4.4.4.4.m1.1a"><mo id="A3.T4.4.4.4.m1.1.1" stretchy="false" xref="A3.T4.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T4.4.4.4.m1.1b"><ci id="A3.T4.4.4.4.m1.1.1.cmml" xref="A3.T4.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.4.4.4.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.5.5">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T4.5.5.5.m1.1"><semantics id="A3.T4.5.5.5.m1.1a"><mo id="A3.T4.5.5.5.m1.1.1" stretchy="false" xref="A3.T4.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A3.T4.5.5.5.m1.1b"><ci id="A3.T4.5.5.5.m1.1.1.cmml" xref="A3.T4.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.5.5.5.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.5.9">Sec/Img</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T4.5.6.1">Base</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.2">1.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.3">0.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.4">32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.5">4.027</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.6">184.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.7">0.756</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T4.5.6.8">0.614</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.9">0.043</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.7.1">Base</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.2">3.1</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.4">32</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.5">2.261</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.6">271.57</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.7">0.785</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.7.8">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.9">0.069</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.8.1">Base</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.2">4.1</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.3">0.97</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.5">2.081</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.6">320.94</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.7">0.817</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.8.8">0.590</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.9">0.120</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.9.1">Base</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.2">3.1</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.5">1.912</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.6">281.46</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.7">0.800</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.9.8">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.9">0.120</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.10.1">Large</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.2">3.0</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.5">1.633</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.6">297.46</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.7">0.796</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.10.8">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.9">0.248</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.11.1">Huge</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.2">4.3</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.5">1.661</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.6">339.62</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.7">0.814</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.11.8">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.9">0.463</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.12.1">Huge</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.2">3.9</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.3">0.99</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.4">128</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.5">1.542</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.6">324.17</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.7">0.806</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.12.8">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.9">0.800</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Details of efficiency configuration. <span class="ltx_text ltx_font_bold" id="A3.T4.7.1">Sec/Img</span> denotes the average time to generate one image (measured with a batch size of 256 on an H800 GPU).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS2.SSS0.Px1.p1.1">We measured sampling efficiency using H800 hardware with a batch size 256, averaging the time to generate one image with a resolution of <math alttext="256\times 256" class="ltx_Math" display="inline" id="A3.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="A3.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="A3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">256</mn><mo id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml">×</mo><mn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1"><times id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1"></times><cn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2">256</cn><cn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.SSS0.Px1.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.SSS0.Px1.p1.1.m1.1d">256 × 256</annotation></semantics></math>. Results under selected configurations are plotted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.F2" title="Figure 2 ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, and more details are listed in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T4" title="Table 4 ‣ Sampling efficiency. ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="A3.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T5.5">
<tr class="ltx_tr" id="A3.T5.5.6">
<td class="ltx_td ltx_border_r" id="A3.T5.5.6.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r" colspan="2" id="A3.T5.5.6.2">w/o cfg</td>
<td class="ltx_td ltx_align_left ltx_border_r" colspan="3" id="A3.T5.5.6.3">w/ cfg (best FID)</td>
<td class="ltx_td ltx_align_left" colspan="3" id="A3.T5.5.6.4">w/ cfg (better IS)</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T5.5.5.6">Model</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.7">AR Steps</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.1"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T5.1.1.1.m1.1"><semantics id="A3.T5.1.1.1.m1.1a"><mi id="A3.T5.1.1.1.m1.1.1" xref="A3.T5.1.1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.T5.1.1.1.m1.1b"><ci id="A3.T5.1.1.1.m1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.1.1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T5.1.1.1.m1.1d">italic_τ</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.2.2.2"><span class="ltx_text ltx_markedasmath" id="A3.T5.2.2.2.1">cfg</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.8">AR Steps</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.3.3.3"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T5.3.3.3.m1.1"><semantics id="A3.T5.3.3.3.m1.1a"><mi id="A3.T5.3.3.3.m1.1.1" xref="A3.T5.3.3.3.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.T5.3.3.3.m1.1b"><ci id="A3.T5.3.3.3.m1.1.1.cmml" xref="A3.T5.3.3.3.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.3.3.3.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T5.3.3.3.m1.1d">italic_τ</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.4.4.4"><span class="ltx_text ltx_markedasmath" id="A3.T5.4.4.4.1">cfg</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.9">AR Steps</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.5"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T5.5.5.5.m1.1"><semantics id="A3.T5.5.5.5.m1.1a"><mi id="A3.T5.5.5.5.m1.1.1" xref="A3.T5.5.5.5.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="A3.T5.5.5.5.m1.1b"><ci id="A3.T5.5.5.5.m1.1.1.cmml" xref="A3.T5.5.5.5.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.5.5.5.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T5.5.5.5.m1.1d">italic_τ</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T5.5.7.1">D-JEPA-B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.2">128</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.5.7.3">0.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.4">3.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.5">224</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.5.7.6">0.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.7">4.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.8">64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.9">0.97</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.5.8.1">D-JEPA-L</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.2">160</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.8.3">0.94</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.4">3.0</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.5">256</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.8.6">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.7">3.9</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.8">192</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.9">0.98</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.5.9.1">D-JEPA-H</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.2">192</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.9.3">0.95</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.4">3.9</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.5">128</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.9.6">0.99</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.7">4.3</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.8">224</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.9">0.98</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>The sampling configuration for results listed in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T2" title="Table 2 ‣ Scaling law of D-JEPA. ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T1" title="Table 1 ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> and Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.T6" title="Table 6 ‣ D.1 Full comparison on ImageNet ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="A3.SS2.SSS0.Px1.p2.1">D-JEPA can generate images with an FID of 4.0 in 47 ms, demonstrating strong competitiveness. Moreover, we can achieve state-of-the-art FID within 1 second. In Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T5" title="Table 5 ‣ Sampling efficiency. ‣ C.2 Abalation on auto-regressive steps ‣ Appendix C Sampling with generalized next token prediction ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>, we list the configuration used in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1" title="4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional results on ImageNet</h2>
<section class="ltx_subsection" id="A4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Full comparison on ImageNet</h3>
<figure class="ltx_table" id="A4.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T6.5">
<tr class="ltx_tr" id="A4.T6.4.4">
<td class="ltx_td ltx_border_r" id="A4.T6.4.4.5"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.4.4.6">#Params</td>
<td class="ltx_td ltx_align_center" id="A4.T6.1.1.1">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.1.1.1.m1.1"><semantics id="A4.T6.1.1.1.m1.1a"><mo id="A4.T6.1.1.1.m1.1.1" stretchy="false" xref="A4.T6.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A4.T6.1.1.1.m1.1b"><ci id="A4.T6.1.1.1.m1.1.1.cmml" xref="A4.T6.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.2.2.2">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.2.2.2.m1.1"><semantics id="A4.T6.2.2.2.m1.1a"><mo id="A4.T6.2.2.2.m1.1.1" stretchy="false" xref="A4.T6.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T6.2.2.2.m1.1b"><ci id="A4.T6.2.2.2.m1.1.1.cmml" xref="A4.T6.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A4.T6.3.3.3">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.3.3.3.m1.1"><semantics id="A4.T6.3.3.3.m1.1a"><mo id="A4.T6.3.3.3.m1.1.1" stretchy="false" xref="A4.T6.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T6.3.3.3.m1.1b"><ci id="A4.T6.3.3.3.m1.1.1.cmml" xref="A4.T6.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A4.T6.4.4.4">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.4.4.4.m1.1"><semantics id="A4.T6.4.4.4.m1.1a"><mo id="A4.T6.4.4.4.m1.1.1" stretchy="false" xref="A4.T6.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A4.T6.4.4.4.m1.1b"><ci id="A4.T6.4.4.4.m1.1.1.cmml" xref="A4.T6.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.4.4.4.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.6" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" id="A4.T6.5.6.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A4.T6.5.6.1.1" style="background-color:#EFEFEF;">Base scale model (less than 300M)</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.7.1">MAR-B <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.7.2">208M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.7.3">3.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.7.4">192.4</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.7.5">0.78</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.7.6">0.58</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.8.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.8.1.1" style="background-color:#ECF4FF;">D-JEPA-B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.8.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.8.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.8.3"><span class="ltx_text ltx_font_bold" id="A4.T6.5.8.3.1" style="background-color:#ECF4FF;">3.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.8.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="A4.T6.5.8.4.1" style="background-color:#ECF4FF;">197.1</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.8.5"><span class="ltx_text" id="A4.T6.5.8.5.1" style="background-color:#ECF4FF;">0.77</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.8.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.8.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.9.1">MaskGIT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.9.2">227M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.9.3">6.18</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.9.4">182.1</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.9.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.9.5.1">0.80</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.9.6">0.51</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.10.1">MAGE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.10.2">230M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.10.3">6.93</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.10.4">195.8</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.10.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.10.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="A4.T6.5.5.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A4.T6.5.5.1.1" style="background-color:#EFEFEF;">Large scale model (300<math alttext="\sim" class="ltx_Math" display="inline" id="A4.T6.5.5.1.1.m1.1" style="background-color:#EFEFEF;"><semantics id="A4.T6.5.5.1.1.m1.1a"><mo id="A4.T6.5.5.1.1.m1.1.1" mathbackground="#EFEFEF" xref="A4.T6.5.5.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A4.T6.5.5.1.1.m1.1b"><csymbol cd="latexml" id="A4.T6.5.5.1.1.m1.1.1.cmml" xref="A4.T6.5.5.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.5.5.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A4.T6.5.5.1.1.m1.1d">∼</annotation></semantics></math>700M)</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.11.1">GIVT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.11.2">304M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.11.3">5.67</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.11.4">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.11.5">0.75</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.11.6">0.59</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.12.1">MAGVIT-v2 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.12.2">307M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.12.3">3.65</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.12.4">200.5</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.12.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.12.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.13.1">LDM-4 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.13.2">400M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.13.3">10.56</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.13.4">103.5</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.13.5">0.71</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.13.6">0.62</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.14.1">MAR-L <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.14.2">479M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.14.3">2.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.14.4">221.4</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.14.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.14.5.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.14.6">0.60</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.15.1">ADM <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.15.2">554M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.15.3">10.94</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.15.4">101.0</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.15.5">0.63</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.15.6">0.63</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.16.1">DiT-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.16.2">675M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.16.3">9.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.16.4">121.5</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.16.5">0.67</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.16.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.16.6.1">0.67</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.17.1">SiT-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.17.2">675M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.17.3">8.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.17.4">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.17.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.17.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.18">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.18.1">MDTv2-XL <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.18.2">676M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.18.3">5.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.18.4">155.6</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.18.5">0.72</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.18.6">0.66</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.19" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.19.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.19.1.1" style="background-color:#ECF4FF;">D-JEPA-L</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.19.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.19.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.19.3"><span class="ltx_text ltx_font_bold" id="A4.T6.5.19.3.1" style="background-color:#ECF4FF;">2.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.19.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="A4.T6.5.19.4.1" style="background-color:#ECF4FF;">233.5</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.19.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.19.5.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.19.6"><span class="ltx_text" id="A4.T6.5.19.6.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.20" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="A4.T6.5.20.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A4.T6.5.20.1.1" style="background-color:#EFEFEF;">Huge scale model (900+M)</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.21.1">MAR-H <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.21.2">943M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.21.3">2.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.21.4">227.8</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.21.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.21.5.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.21.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.21.6.1">0.62</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.22" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.22.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.22.1.1" style="background-color:#ECF4FF;">D-JEPA-H</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.22.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.22.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.22.3"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.3.1" style="background-color:#ECF4FF;">2.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.22.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.4.1" style="background-color:#ECF4FF;">239.3</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.22.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.5.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.22.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.6.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.23">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.23.1">Autoreg.  <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib31" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.23.2">1.4B</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.23.3">15.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.23.4">78.3</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.23.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.23.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.24">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.24.1">VDM++ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib57" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.24.2">2.0B</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.24.3">2.40</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.24.4">225.3</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.24.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.24.6">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>System-level comparison on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="A4.T6.7.m1.1"><semantics id="A4.T6.7.m1.1b"><mrow id="A4.T6.7.m1.1.1" xref="A4.T6.7.m1.1.1.cmml"><mn id="A4.T6.7.m1.1.1.2" xref="A4.T6.7.m1.1.1.2.cmml">256</mn><mo id="A4.T6.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A4.T6.7.m1.1.1.1.cmml">×</mo><mn id="A4.T6.7.m1.1.1.3" xref="A4.T6.7.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T6.7.m1.1c"><apply id="A4.T6.7.m1.1.1.cmml" xref="A4.T6.7.m1.1.1"><times id="A4.T6.7.m1.1.1.1.cmml" xref="A4.T6.7.m1.1.1.1"></times><cn id="A4.T6.7.m1.1.1.2.cmml" type="integer" xref="A4.T6.7.m1.1.1.2">256</cn><cn id="A4.T6.7.m1.1.1.3.cmml" type="integer" xref="A4.T6.7.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.7.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A4.T6.7.m1.1e">256 × 256</annotation></semantics></math> conditional generation <span class="ltx_text ltx_font_italic" id="A4.T6.9.1">without</span> classifier-free guidance.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">We provide a more comprehensive comparison with earlier works in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.T6" title="Table 6 ‣ D.1 Full comparison on ImageNet ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>. D-JEPA-B, with only 212M parameters, performs only slightly worse than MAR-L (with 479M parameters), MAR-H (with 943M parameters), and VDM++ (with 2.0B parameters). It is also worth noting that D-JEPA-B significantly outperforms DiT-XL (with 675M parameters) by a large margin in terms of FID (3.40 vs. 9.62) and IS (197.1 vs. 121.5).</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS1.p2">
<p class="ltx_p" id="A4.SS1.p2.2">D-JEPA-L and D-JEPA-H achieve state-of-the-art performance in both FID and IS metrics. Furthermore, D-JEPA-H sets unprecedented records in both of these metrics. Although D-JEPA performs well in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T2" title="Table 2 ‣ Scaling law of D-JEPA. ‣ 4.1 Image Synthetis ‣ 4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, it is not outstanding. However, we believe that the metrics without classifier-free guidance better reflect the actual performance of each model, as the value of <span class="ltx_text ltx_markedasmath" id="A4.SS1.p2.2.1">cfg</span> can significantly impact the results. Determining the optimal <span class="ltx_text ltx_markedasmath" id="A4.SS1.p2.2.2">cfg</span> value for each model is challenging. Therefore, the metrics presented in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.T6" title="Table 6 ‣ D.1 Full comparison on ImageNet ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a> are considered more convincing.</p>
</div>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Training curve</h3>
<figure class="ltx_figure" id="A4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="A4.F6.g1" src="x17.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Training dynamics of model architectures. The sampling parameters for the images evaluated to obtain the FID and IS in the figure are: <math alttext="\text{cfg}=1.0,\tau=0.95,\text{AR Steps}=256" class="ltx_Math" display="inline" id="A4.F6.2.m1.2"><semantics id="A4.F6.2.m1.2b"><mrow id="A4.F6.2.m1.2.2.2" xref="A4.F6.2.m1.2.2.3.cmml"><mrow id="A4.F6.2.m1.1.1.1.1" xref="A4.F6.2.m1.1.1.1.1.cmml"><mtext id="A4.F6.2.m1.1.1.1.1.2" xref="A4.F6.2.m1.1.1.1.1.2a.cmml">cfg</mtext><mo id="A4.F6.2.m1.1.1.1.1.1" xref="A4.F6.2.m1.1.1.1.1.1.cmml">=</mo><mn id="A4.F6.2.m1.1.1.1.1.3" xref="A4.F6.2.m1.1.1.1.1.3.cmml">1.0</mn></mrow><mo id="A4.F6.2.m1.2.2.2.3" xref="A4.F6.2.m1.2.2.3a.cmml">,</mo><mrow id="A4.F6.2.m1.2.2.2.2.2" xref="A4.F6.2.m1.2.2.2.2.3.cmml"><mrow id="A4.F6.2.m1.2.2.2.2.1.1" xref="A4.F6.2.m1.2.2.2.2.1.1.cmml"><mi id="A4.F6.2.m1.2.2.2.2.1.1.2" xref="A4.F6.2.m1.2.2.2.2.1.1.2.cmml">τ</mi><mo id="A4.F6.2.m1.2.2.2.2.1.1.1" xref="A4.F6.2.m1.2.2.2.2.1.1.1.cmml">=</mo><mn id="A4.F6.2.m1.2.2.2.2.1.1.3" xref="A4.F6.2.m1.2.2.2.2.1.1.3.cmml">0.95</mn></mrow><mo id="A4.F6.2.m1.2.2.2.2.2.3" xref="A4.F6.2.m1.2.2.2.2.3a.cmml">,</mo><mrow id="A4.F6.2.m1.2.2.2.2.2.2" xref="A4.F6.2.m1.2.2.2.2.2.2.cmml"><mtext id="A4.F6.2.m1.2.2.2.2.2.2.2" xref="A4.F6.2.m1.2.2.2.2.2.2.2a.cmml">AR Steps</mtext><mo id="A4.F6.2.m1.2.2.2.2.2.2.1" xref="A4.F6.2.m1.2.2.2.2.2.2.1.cmml">=</mo><mn id="A4.F6.2.m1.2.2.2.2.2.2.3" xref="A4.F6.2.m1.2.2.2.2.2.2.3.cmml">256</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.F6.2.m1.2c"><apply id="A4.F6.2.m1.2.2.3.cmml" xref="A4.F6.2.m1.2.2.2"><csymbol cd="ambiguous" id="A4.F6.2.m1.2.2.3a.cmml" xref="A4.F6.2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A4.F6.2.m1.1.1.1.1.cmml" xref="A4.F6.2.m1.1.1.1.1"><eq id="A4.F6.2.m1.1.1.1.1.1.cmml" xref="A4.F6.2.m1.1.1.1.1.1"></eq><ci id="A4.F6.2.m1.1.1.1.1.2a.cmml" xref="A4.F6.2.m1.1.1.1.1.2"><mtext id="A4.F6.2.m1.1.1.1.1.2.cmml" xref="A4.F6.2.m1.1.1.1.1.2">cfg</mtext></ci><cn id="A4.F6.2.m1.1.1.1.1.3.cmml" type="float" xref="A4.F6.2.m1.1.1.1.1.3">1.0</cn></apply><apply id="A4.F6.2.m1.2.2.2.2.3.cmml" xref="A4.F6.2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A4.F6.2.m1.2.2.2.2.3a.cmml" xref="A4.F6.2.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="A4.F6.2.m1.2.2.2.2.1.1.cmml" xref="A4.F6.2.m1.2.2.2.2.1.1"><eq id="A4.F6.2.m1.2.2.2.2.1.1.1.cmml" xref="A4.F6.2.m1.2.2.2.2.1.1.1"></eq><ci id="A4.F6.2.m1.2.2.2.2.1.1.2.cmml" xref="A4.F6.2.m1.2.2.2.2.1.1.2">𝜏</ci><cn id="A4.F6.2.m1.2.2.2.2.1.1.3.cmml" type="float" xref="A4.F6.2.m1.2.2.2.2.1.1.3">0.95</cn></apply><apply id="A4.F6.2.m1.2.2.2.2.2.2.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2"><eq id="A4.F6.2.m1.2.2.2.2.2.2.1.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2.1"></eq><ci id="A4.F6.2.m1.2.2.2.2.2.2.2a.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2.2"><mtext id="A4.F6.2.m1.2.2.2.2.2.2.2.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2.2">AR Steps</mtext></ci><cn id="A4.F6.2.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="A4.F6.2.m1.2.2.2.2.2.2.3">256</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.F6.2.m1.2d">\text{cfg}=1.0,\tau=0.95,\text{AR Steps}=256</annotation><annotation encoding="application/x-llamapun" id="A4.F6.2.m1.2e">cfg = 1.0 , italic_τ = 0.95 , AR Steps = 256</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.1">In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F6" title="Figure 6 ‣ D.2 Training curve ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>, we present the FID and IS metrics as a function of training epochs. It is evident that irrespective of the model size, 160 training epochs are essential for convergence when employing diffusion loss. Models with a smaller parameter count necessitate a more significant number of training epochs. Although the Base, Large, and Huge models were trained for 1400, 480, and 320 epochs, respectively, the trends in the metrics suggest that further increasing the number of training epochs could potentially enhance D-JEPA’s performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS2.p2">
<p class="ltx_p" id="A4.SS2.p2.1">Moreover, it is crucial to highlight that the model size directly influences the attainable performance ceiling. For smaller models, such as D-JEPA-B, achieving the performance levels of larger models, like D-JEPA-L and D-JEPA-H, is unattainable, even with extensive training. As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F6" title="Figure 6 ‣ D.2 Training curve ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>, it is apparent that when the parameter size exceeds 500M, D-JEPA exhibits markedly superior learning capabilities.</p>
</div>
</section>
<section class="ltx_subsection" id="A4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Inpainting and Outpainting</h3>
<figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1127" id="A4.F7.g1" src="x18.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Inpainting and outpainting capabilities of D-JEPA on training data. The percentages below the images indicate the proportion of the reference input that was dropped.</figcaption>
</figure>
<figure class="ltx_figure" id="A4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1128" id="A4.F8.g1" src="x19.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Inpainting and outpainting capabilities of D-JEPA on previously unseen data. The percentages below the images indicate the proportion of the reference input that was dropped.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS3.p1">
<p class="ltx_p" id="A4.SS3.p1.1">In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F7" title="Figure 7 ‣ D.3 Inpainting and Outpainting ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F8" title="Figure 8 ‣ D.3 Inpainting and Outpainting ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a>, we demonstrate D-JEPA’s capabilities in image restoration and inpainting and outpainting on both ImageNet1k images and unseen images. As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F7" title="Figure 7 ‣ D.3 Inpainting and Outpainting ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a>, D-JEPA can reconstruct highly similar images from only 10% of the original features, showcasing its visual solid retrieval capabilities. In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F8" title="Figure 8 ‣ D.3 Inpainting and Outpainting ‣ Appendix D Additional results on ImageNet ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a>, D-JEPA effectively supplements missing visual features based on contextual content.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS3.p2">
<p class="ltx_p" id="A4.SS3.p2.1">We believe that training on larger-scale datasets will significantly enhance D-JEPA’s painting capabilities. Additionally, from the results in these two figures, it is evident that the quality of the training data plays a decisive role in the final generated image quality. D-JEPA, like all other generative models, essentially strives to fit the training data distribution better and finds it challenging to create data distributions that are perceived as better by human standards.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>D-JEPA for representation learning</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Theoretical motivation</h3>
<div class="ltx_para ltx_noindent" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">A theoretical motivation for the effectiveness of the collapse prevention strategy was proposed in  <cite class="ltx_cite ltx_citemacro_cite">Grill et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>)</cite>. We adapt their analysis for our smoothed l1 loss in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>. For ease of exposition, we will disregard the effect of the conditioning variable and consider one-dimensional representations like  <cite class="ltx_cite ltx_citemacro_cite">Bardes et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib12" title="">2024</a>)</cite>. The optimal predictor under Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a> is thus given by the following functional expression:</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A8.EGx1">
<tbody id="A5.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\gamma^{\star}(\phi(x_{i}))" class="ltx_Math" display="inline" id="A5.Ex3.m1.1"><semantics id="A5.Ex3.m1.1a"><mrow id="A5.Ex3.m1.1.1" xref="A5.Ex3.m1.1.1.cmml"><msup id="A5.Ex3.m1.1.1.3" xref="A5.Ex3.m1.1.1.3.cmml"><mi id="A5.Ex3.m1.1.1.3.2" xref="A5.Ex3.m1.1.1.3.2.cmml">γ</mi><mo id="A5.Ex3.m1.1.1.3.3" xref="A5.Ex3.m1.1.1.3.3.cmml">⋆</mo></msup><mo id="A5.Ex3.m1.1.1.2" xref="A5.Ex3.m1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex3.m1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex3.m1.1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m1.1.1.1.1.1.3" xref="A5.Ex3.m1.1.1.1.1.1.3.cmml">ϕ</mi><mo id="A5.Ex3.m1.1.1.1.1.1.2" xref="A5.Ex3.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex3.m1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex3.m1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex3.m1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex3.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex3.m1.1b"><apply id="A5.Ex3.m1.1.1.cmml" xref="A5.Ex3.m1.1.1"><times id="A5.Ex3.m1.1.1.2.cmml" xref="A5.Ex3.m1.1.1.2"></times><apply id="A5.Ex3.m1.1.1.3.cmml" xref="A5.Ex3.m1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex3.m1.1.1.3.1.cmml" xref="A5.Ex3.m1.1.1.3">superscript</csymbol><ci id="A5.Ex3.m1.1.1.3.2.cmml" xref="A5.Ex3.m1.1.1.3.2">𝛾</ci><ci id="A5.Ex3.m1.1.1.3.3.cmml" xref="A5.Ex3.m1.1.1.3.3">⋆</ci></apply><apply id="A5.Ex3.m1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.1.1.1.1"><times id="A5.Ex3.m1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.1.1.1.1.1.2"></times><ci id="A5.Ex3.m1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.1.1.1.1.1.3">italic-ϕ</ci><apply id="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A5.Ex3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex3.m1.1c">\displaystyle\gamma^{\star}(\phi(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="A5.Ex3.m1.1d">italic_γ start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ( italic_ϕ ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{argmin}_{\gamma}\parallel\gamma(\phi(x_{i}))-g_{i}%
\parallel_{1}" class="ltx_Math" display="inline" id="A5.Ex3.m2.1"><semantics id="A5.Ex3.m2.1a"><mrow id="A5.Ex3.m2.1.1" xref="A5.Ex3.m2.1.1.cmml"><mi id="A5.Ex3.m2.1.1.3" xref="A5.Ex3.m2.1.1.3.cmml"></mi><mo id="A5.Ex3.m2.1.1.2" xref="A5.Ex3.m2.1.1.2.cmml">=</mo><mrow id="A5.Ex3.m2.1.1.1" xref="A5.Ex3.m2.1.1.1.cmml"><msub id="A5.Ex3.m2.1.1.1.3" xref="A5.Ex3.m2.1.1.1.3.cmml"><mtext id="A5.Ex3.m2.1.1.1.3.2" xref="A5.Ex3.m2.1.1.1.3.2a.cmml">argmin</mtext><mi id="A5.Ex3.m2.1.1.1.3.3" xref="A5.Ex3.m2.1.1.1.3.3.cmml">γ</mi></msub><mo id="A5.Ex3.m2.1.1.1.2" xref="A5.Ex3.m2.1.1.1.2.cmml">⁢</mo><msub id="A5.Ex3.m2.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.cmml"><mrow id="A5.Ex3.m2.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.2.cmml"><mo id="A5.Ex3.m2.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.3.cmml">γ</mi><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">ϕ</mi><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.2.cmml">−</mo><msub id="A5.Ex3.m2.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.3.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.3.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="A5.Ex3.m2.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="A5.Ex3.m2.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex3.m2.1b"><apply id="A5.Ex3.m2.1.1.cmml" xref="A5.Ex3.m2.1.1"><eq id="A5.Ex3.m2.1.1.2.cmml" xref="A5.Ex3.m2.1.1.2"></eq><csymbol cd="latexml" id="A5.Ex3.m2.1.1.3.cmml" xref="A5.Ex3.m2.1.1.3">absent</csymbol><apply id="A5.Ex3.m2.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1"><times id="A5.Ex3.m2.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.2"></times><apply id="A5.Ex3.m2.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.3.1.cmml" xref="A5.Ex3.m2.1.1.1.3">subscript</csymbol><ci id="A5.Ex3.m2.1.1.1.3.2a.cmml" xref="A5.Ex3.m2.1.1.1.3.2"><mtext id="A5.Ex3.m2.1.1.1.3.2.cmml" xref="A5.Ex3.m2.1.1.1.3.2">argmin</mtext></ci><ci id="A5.Ex3.m2.1.1.1.3.3.cmml" xref="A5.Ex3.m2.1.1.1.3.3">𝛾</ci></apply><apply id="A5.Ex3.m2.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1">subscript</csymbol><apply id="A5.Ex3.m2.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex3.m2.1.1.1.1.1.2.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.2">norm</csymbol><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1"><minus id="A5.Ex3.m2.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.2"></minus><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1"><times id="A5.Ex3.m2.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.2"></times><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.3">𝛾</ci><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3">italic-ϕ</ci><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.2">𝑔</ci><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><cn id="A5.Ex3.m2.1.1.1.1.3.cmml" type="integer" xref="A5.Ex3.m2.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex3.m2.1c">\displaystyle=\text{argmin}_{\gamma}\parallel\gamma(\phi(x_{i}))-g_{i}%
\parallel_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.Ex3.m2.1d">= argmin start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT ∥ italic_γ ( italic_ϕ ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) - italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A5.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{media}(g_{i}|\phi(x_{i}))," class="ltx_Math" display="inline" id="A5.Ex4.m1.1"><semantics id="A5.Ex4.m1.1a"><mrow id="A5.Ex4.m1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.cmml"><mrow id="A5.Ex4.m1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.3.cmml"></mi><mo id="A5.Ex4.m1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.cmml">=</mo><mrow id="A5.Ex4.m1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.cmml"><mtext id="A5.Ex4.m1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.3a.cmml">media</mtext><mo id="A5.Ex4.m1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml"><msub id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml">ϕ</mi><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex4.m1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex4.m1.1b"><apply id="A5.Ex4.m1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1"><eq id="A5.Ex4.m1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2"></eq><csymbol cd="latexml" id="A5.Ex4.m1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.3">absent</csymbol><apply id="A5.Ex4.m1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1"><times id="A5.Ex4.m1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.2"></times><ci id="A5.Ex4.m1.1.1.1.1.1.3a.cmml" xref="A5.Ex4.m1.1.1.1.1.1.3"><mtext id="A5.Ex4.m1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.3">media</mtext></ci><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2">𝑔</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3">italic-ϕ</ci><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex4.m1.1c">\displaystyle=\text{media}(g_{i}|\phi(x_{i})),</annotation><annotation encoding="application/x-llamapun" id="A5.Ex4.m1.1d">= media ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_ϕ ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p3">
<p class="ltx_p" id="A5.SS1.p3.1">Substituting this expression for the optimal predictor into the loss function and evaluating the expected gradient of the encoder gives</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p4">
<table class="ltx_equation ltx_eqn_table" id="A5.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\nabla_{\theta}\mathbb{E}\parallel\gamma^{\star}(\phi_{\theta}(x_{i}))-g_{i}%
\parallel_{1}=\nabla_{\theta}\text{MAD}(g_{i}|\phi_{\theta}(x_{i}))," class="ltx_Math" display="block" id="A5.Ex5.m1.1"><semantics id="A5.Ex5.m1.1a"><mrow id="A5.Ex5.m1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.2.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.2.2" xref="A5.Ex5.m1.1.1.1.1.1.2.2.cmml">∇</mo><mi id="A5.Ex5.m1.1.1.1.1.1.2.3" xref="A5.Ex5.m1.1.1.1.1.1.2.3.cmml">θ</mi></msub><mrow id="A5.Ex5.m1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.3.cmml">𝔼</mi><mo id="A5.Ex5.m1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="A5.Ex5.m1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msup id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">γ</mi><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">⋆</mo></msup><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">ϕ</mi><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">−</mo><msub id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="A5.Ex5.m1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.3.cmml">=</mo><mrow id="A5.Ex5.m1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.2.3" xref="A5.Ex5.m1.1.1.1.1.2.3.cmml"><msub id="A5.Ex5.m1.1.1.1.1.2.3.1" xref="A5.Ex5.m1.1.1.1.1.2.3.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.2.3.1.2" rspace="0.167em" xref="A5.Ex5.m1.1.1.1.1.2.3.1.2.cmml">∇</mo><mi id="A5.Ex5.m1.1.1.1.1.2.3.1.3" xref="A5.Ex5.m1.1.1.1.1.2.3.1.3.cmml">θ</mi></msub><mtext id="A5.Ex5.m1.1.1.1.1.2.3.2" xref="A5.Ex5.m1.1.1.1.1.2.3.2a.cmml">MAD</mtext></mrow><mo id="A5.Ex5.m1.1.1.1.1.2.2" xref="A5.Ex5.m1.1.1.1.1.2.2.cmml">⁢</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.2.cmml">|</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2.cmml">ϕ</mi><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2.cmml">⁢</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex5.m1.1b"><apply id="A5.Ex5.m1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1"><eq id="A5.Ex5.m1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.3"></eq><apply id="A5.Ex5.m1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1"><apply id="A5.Ex5.m1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.2.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.2.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2.2">∇</ci><ci id="A5.Ex5.m1.1.1.1.1.1.2.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2.3">𝜃</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.2"></times><ci id="A5.Ex5.m1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.3">𝔼</ci><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1"><minus id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2"></minus><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2">𝛾</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3">⋆</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">italic-ϕ</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑔</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><cn id="A5.Ex5.m1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="A5.Ex5.m1.1.1.1.1.1.1.1.3">1</cn></apply></apply></apply><apply id="A5.Ex5.m1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2"><times id="A5.Ex5.m1.1.1.1.1.2.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.2"></times><apply id="A5.Ex5.m1.1.1.1.1.2.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3"><apply id="A5.Ex5.m1.1.1.1.1.2.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.3.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.3.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1.2">∇</ci><ci id="A5.Ex5.m1.1.1.1.1.2.3.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1.3">𝜃</ci></apply><ci id="A5.Ex5.m1.1.1.1.1.2.3.2a.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.2"><mtext id="A5.Ex5.m1.1.1.1.1.2.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.2">MAD</mtext></ci></apply><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1"><csymbol cd="latexml" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.2">conditional</csymbol><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2">𝑔</ci><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3">𝑖</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2"></times><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2">italic-ϕ</ci><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3">𝜃</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2">𝑥</ci><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex5.m1.1c">\nabla_{\theta}\mathbb{E}\parallel\gamma^{\star}(\phi_{\theta}(x_{i}))-g_{i}%
\parallel_{1}=\nabla_{\theta}\text{MAD}(g_{i}|\phi_{\theta}(x_{i})),</annotation><annotation encoding="application/x-llamapun" id="A5.Ex5.m1.1d">∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT blackboard_E ∥ italic_γ start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ( italic_ϕ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) - italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ∇ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT MAD ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_ϕ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p5">
<p class="ltx_p" id="A5.SS1.p5.3">where <math alttext="\text{MAD}(\cdot|\phi_{\theta}(x_{i}))" class="ltx_math_unparsed" display="inline" id="A5.SS1.p5.1.m1.1"><semantics id="A5.SS1.p5.1.m1.1a"><mrow id="A5.SS1.p5.1.m1.1b"><mtext id="A5.SS1.p5.1.m1.1.1">MAD</mtext><mrow id="A5.SS1.p5.1.m1.1.2"><mo id="A5.SS1.p5.1.m1.1.2.1" stretchy="false">(</mo><mo id="A5.SS1.p5.1.m1.1.2.2" lspace="0em" rspace="0em">⋅</mo><mo fence="false" id="A5.SS1.p5.1.m1.1.2.3" rspace="0.167em" stretchy="false">|</mo><msub id="A5.SS1.p5.1.m1.1.2.4"><mi id="A5.SS1.p5.1.m1.1.2.4.2">ϕ</mi><mi id="A5.SS1.p5.1.m1.1.2.4.3">θ</mi></msub><mrow id="A5.SS1.p5.1.m1.1.2.5"><mo id="A5.SS1.p5.1.m1.1.2.5.1" stretchy="false">(</mo><msub id="A5.SS1.p5.1.m1.1.2.5.2"><mi id="A5.SS1.p5.1.m1.1.2.5.2.2">x</mi><mi id="A5.SS1.p5.1.m1.1.2.5.2.3">i</mi></msub><mo id="A5.SS1.p5.1.m1.1.2.5.3" stretchy="false">)</mo></mrow><mo id="A5.SS1.p5.1.m1.1.2.6" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="A5.SS1.p5.1.m1.1c">\text{MAD}(\cdot|\phi_{\theta}(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p5.1.m1.1d">MAD ( ⋅ | italic_ϕ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math> is the median absolute deviation of a random variable conditioned on <math alttext="\phi_{\theta}(x_{i})" class="ltx_Math" display="inline" id="A5.SS1.p5.2.m2.1"><semantics id="A5.SS1.p5.2.m2.1a"><mrow id="A5.SS1.p5.2.m2.1.1" xref="A5.SS1.p5.2.m2.1.1.cmml"><msub id="A5.SS1.p5.2.m2.1.1.3" xref="A5.SS1.p5.2.m2.1.1.3.cmml"><mi id="A5.SS1.p5.2.m2.1.1.3.2" xref="A5.SS1.p5.2.m2.1.1.3.2.cmml">ϕ</mi><mi id="A5.SS1.p5.2.m2.1.1.3.3" xref="A5.SS1.p5.2.m2.1.1.3.3.cmml">θ</mi></msub><mo id="A5.SS1.p5.2.m2.1.1.2" xref="A5.SS1.p5.2.m2.1.1.2.cmml">⁢</mo><mrow id="A5.SS1.p5.2.m2.1.1.1.1" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml"><mo id="A5.SS1.p5.2.m2.1.1.1.1.2" stretchy="false" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml">(</mo><msub id="A5.SS1.p5.2.m2.1.1.1.1.1" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml"><mi id="A5.SS1.p5.2.m2.1.1.1.1.1.2" xref="A5.SS1.p5.2.m2.1.1.1.1.1.2.cmml">x</mi><mi id="A5.SS1.p5.2.m2.1.1.1.1.1.3" xref="A5.SS1.p5.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.SS1.p5.2.m2.1.1.1.1.3" stretchy="false" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.SS1.p5.2.m2.1b"><apply id="A5.SS1.p5.2.m2.1.1.cmml" xref="A5.SS1.p5.2.m2.1.1"><times id="A5.SS1.p5.2.m2.1.1.2.cmml" xref="A5.SS1.p5.2.m2.1.1.2"></times><apply id="A5.SS1.p5.2.m2.1.1.3.cmml" xref="A5.SS1.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="A5.SS1.p5.2.m2.1.1.3.1.cmml" xref="A5.SS1.p5.2.m2.1.1.3">subscript</csymbol><ci id="A5.SS1.p5.2.m2.1.1.3.2.cmml" xref="A5.SS1.p5.2.m2.1.1.3.2">italic-ϕ</ci><ci id="A5.SS1.p5.2.m2.1.1.3.3.cmml" xref="A5.SS1.p5.2.m2.1.1.3.3">𝜃</ci></apply><apply id="A5.SS1.p5.2.m2.1.1.1.1.1.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="A5.SS1.p5.2.m2.1.1.1.1.1.1.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1">subscript</csymbol><ci id="A5.SS1.p5.2.m2.1.1.1.1.1.2.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1.1.2">𝑥</ci><ci id="A5.SS1.p5.2.m2.1.1.1.1.1.3.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p5.2.m2.1c">\phi_{\theta}(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p5.2.m2.1d">italic_ϕ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. Thus, in the case where the predictor is optimal, the encoder must learn to capture as much information about the video as possible to minimize the deviation of the target. The hypothesis is that incorporating an exponential moving average to compute the representation of <math alttext="y_{i}" class="ltx_Math" display="inline" id="A5.SS1.p5.3.m3.1"><semantics id="A5.SS1.p5.3.m3.1a"><msub id="A5.SS1.p5.3.m3.1.1" xref="A5.SS1.p5.3.m3.1.1.cmml"><mi id="A5.SS1.p5.3.m3.1.1.2" xref="A5.SS1.p5.3.m3.1.1.2.cmml">y</mi><mi id="A5.SS1.p5.3.m3.1.1.3" xref="A5.SS1.p5.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A5.SS1.p5.3.m3.1b"><apply id="A5.SS1.p5.3.m3.1.1.cmml" xref="A5.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="A5.SS1.p5.3.m3.1.1.1.cmml" xref="A5.SS1.p5.3.m3.1.1">subscript</csymbol><ci id="A5.SS1.p5.3.m3.1.1.2.cmml" xref="A5.SS1.p5.3.m3.1.1.2">𝑦</ci><ci id="A5.SS1.p5.3.m3.1.1.3.cmml" xref="A5.SS1.p5.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p5.3.m3.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p5.3.m3.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> ensures that the predictor evolves faster than the encoder and remains close to optimal, thereby preventing collapse.</p>
</div>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Image classification</h3>
<div class="ltx_para ltx_noindent" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">D-JEPA, a generative model built on the foundation of JEPA <cite class="ltx_cite ltx_citemacro_cite">LeCun (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>)</cite>, inherits the exceptional representation capabilities of JEPA. This intrinsic quality positions D-JEPA as a potentially superior source of pre-training weights for downstream tasks compared to other generative models. To rigorously affirm this hypothesis, we conducted extensive evaluations on two prevalent ImageNet classification tasks: linear probing and fine-tuning.</p>
</div>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Experiment settings.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px1.p1.1">We use the context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="A5.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="A5.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="A5.SS2.SSS0.Px1.p1.1.m1.1.1" xref="A5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="A5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A5.SS2.SSS0.Px1.p1.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.SSS0.Px1.p1.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.SSS0.Px1.p1.1.m1.1d">italic_ϕ</annotation></semantics></math> as the pre-trained model for all downstream tasks, following the approach reported by  <cite class="ltx_cite ltx_citemacro_cite">Assran et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, demonstrating better performance. For representation learning, we globally average pool the output of the feature by the context encoder and use these pooled features as input for the classification head, in alignment with the methodologies described in  <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> and  <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="A5.SS2.SSS0.Px1.p2.1">We conducted experiments in both the raw pixel space and the continuous token space. The primary distinction between these two experiments is whether a VAE is utilized to encode the images. For the former, we fully retain the experimental setup of I-JEPA <cite class="ltx_cite ltx_citemacro_cite">Assran et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, while for the latter, the training settings are entirely retained from MAGE <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px1.p3">
<p class="ltx_p" id="A5.SS2.SSS0.Px1.p3.1">To ensure a fair comparison, for D-JEPA-B, we use the checkpoint saved at 600 epochs for the related experiments, and for D-JEPA-L, we use the checkpoint saved at 300 epochs, consistent with the practices in  <cite class="ltx_cite ltx_citemacro_cite">Assran et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_table" id="A5.T7">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T7.1.tab1" style="width:260.2pt;">
<table class="ltx_tabular ltx_align_middle" id="A5.T7.1.tab1.1">
<tr class="ltx_tr" id="A5.T7.1.tab1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.1.1">Method</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.1.2">Model</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.1.3">#Params</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.1.4">Acc.</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.2" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="4" id="A5.T7.1.tab1.1.2.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.2.1.1" style="background-color:#EFEFEF;">Gemerative models</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.3.1">BigBiGAN <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib27" title="">2019</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.3.2">RN50</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.3.3">23M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.3.4">56.6</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.4.1">MaskGIT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.4.2">BERT</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.4.3">227M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.4.4">57.4</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.5.1">ViT-VQGAN <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.5.2">VIM-Base</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.5.3">650M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.5.4">65.1</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.6.1">ViT-VQGAN <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.6.2">VIM-Large</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.6.3">1697M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.6.4">73.2</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.7" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.7.1"><span class="ltx_text" id="A5.T7.1.tab1.1.7.1.1" style="background-color:#ECF4FF;">D-JEPA (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.7.1.1.1" style="background-color:#ECF4FF;">token space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.7.2"><span class="ltx_text" id="A5.T7.1.tab1.1.7.2.1" style="background-color:#ECF4FF;">ViT-B</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.7.3"><span class="ltx_text" id="A5.T7.1.tab1.1.7.3.1" style="background-color:#ECF4FF;">86M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.7.4"><span class="ltx_text" id="A5.T7.1.tab1.1.7.4.1" style="background-color:#ECF4FF;">46.8</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.8.1"><span class="ltx_text" id="A5.T7.1.tab1.1.8.1.1" style="background-color:#ECF4FF;">D-JEPA (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.8.1.1.1" style="background-color:#ECF4FF;">token space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.8.2"><span class="ltx_text" id="A5.T7.1.tab1.1.8.2.1" style="background-color:#ECF4FF;">ViT-L</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.8.3"><span class="ltx_text" id="A5.T7.1.tab1.1.8.3.1" style="background-color:#ECF4FF;">304M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.8.4"><span class="ltx_text" id="A5.T7.1.tab1.1.8.4.1" style="background-color:#ECF4FF;">47.6</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.9" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.9.1"><span class="ltx_text" id="A5.T7.1.tab1.1.9.1.1" style="background-color:#ECF4FF;">D-JEPA (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.9.1.1.1" style="background-color:#ECF4FF;">pixel space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.9.2"><span class="ltx_text" id="A5.T7.1.tab1.1.9.2.1" style="background-color:#ECF4FF;">ViT-B</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.9.3"><span class="ltx_text" id="A5.T7.1.tab1.1.9.3.1" style="background-color:#ECF4FF;">86M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.9.4"><span class="ltx_text" id="A5.T7.1.tab1.1.9.4.1" style="background-color:#ECF4FF;">73.1</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.10" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.10.1"><span class="ltx_text" id="A5.T7.1.tab1.1.10.1.1" style="background-color:#ECF4FF;">D-JEPA (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.10.1.1.1" style="background-color:#ECF4FF;">pixel space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.10.2"><span class="ltx_text" id="A5.T7.1.tab1.1.10.2.1" style="background-color:#ECF4FF;">ViT-L</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.10.3"><span class="ltx_text" id="A5.T7.1.tab1.1.10.3.1" style="background-color:#ECF4FF;">304M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.10.4"><span class="ltx_text" id="A5.T7.1.tab1.1.10.4.1" style="background-color:#ECF4FF;">77.9</span></td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T7.2.tab1" style="width:169.1pt;">
<table class="ltx_tabular ltx_align_middle" id="A5.T7.2.tab1.1">
<tr class="ltx_tr" id="A5.T7.2.tab1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.1.1">Method</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.1.2">ViT-B</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.1.3">ViT-L</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.2">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T7.2.tab1.1.2.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T7.2.tab1.1.2.1.1" style="background-color:#EFEFEF;">Representation models</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.3.1">data2vec <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.3.2">-</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.3.3">77.3</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.4.1">I-JEPA <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.4.2">72.9</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.4.3">77.5</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.5.1">MAE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.5.2">68.0</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.5.3">76.0</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.6.1">CAE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib21" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.6.2">70.4</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.6.3">78.1</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.7.1">CMAE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib50" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.7.2">73.9</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.7.3">-</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.8.1">MAGE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.8.2">74.7</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.8.3">78.9</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.9.1">MoCo v3 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib23" title="">2021b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.9.2">76.7</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.9.3">77.6</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.10.1">DINO <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib127" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.10.2">72.8</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.10.3">-</td>
</tr>
</table>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Top-1 accuracy of linear probing on ImageNet-1K. For reference, we also list the performance of other state-of-the-art representation models as well.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Linear probing.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px2.p1.1">Linear probing is a primary evaluation protocol for self-supervised learning. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T7" title="Table 7 ‣ Experiment settings. ‣ E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a>, D-JEPA, trained directly on raw pixels, surpasses all generative models in ImageNet-1K linear probe top-1 accuracy, achieving state-of-the-art results. Furthermore, when compared with representation models, D-JEPA remains remarkably competitive.</p>
</div>
<figure class="ltx_table" id="A5.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Fine-tuning performance on ImageNet-1K. We report the top-1 accuracy improvement over training from scratch for different methods (other numbers are taken from the respective papers). The ViT models trained from scratch on semantic tokens follow the exact same training settings as the ViT models trained from scratch on original image pixels in <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>. It is worth noting that ViT-L’s performance is slightly lower than ViT-B’s when trained from scratch on continuous tokens, likely due to only 50 epochs of training. However, we used this setting to ensure a fair comparison with other methods.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="A5.T8.1">
<tr class="ltx_tr" id="A5.T8.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.1.1">Method</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.2">ViT-B</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3">ViT-L</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.2" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T8.1.2.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T8.1.2.1.1" style="background-color:#EFEFEF;">Patchify on raw pixels</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.3.1">Scratch</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.3.2">82.3</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.3.3">82.6</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.4.1">DINO <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib15" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.4.2">+0.5</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.4.3">-</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.5.1">MoCo v3 <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib23" title="">2021b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.5.2">+0.9</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.5.3">+1.5</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.6.1">BEiT <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib8" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.6.2">+0.9</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.6.3">+2.6</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.7.1">MAE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.7.2">+1.3</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.7.3">+3.3</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.8.1">CAE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib21" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.8.2">+1.6</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.8.3">+3.7</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.9.1">MVP <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib111" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.9.2">+2.1</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.9.3">+3.7</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.10.1">PeCo <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib28" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.10.2"><span class="ltx_text ltx_font_bold" id="A5.T8.1.10.2.1">+2.2</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.10.3"><span class="ltx_text ltx_font_bold" id="A5.T8.1.10.3.1">+3.9</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.11" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.11.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A5.T8.1.11.1.1" style="background-color:#ECF4FF;">D-JEPA</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.11.2"><span class="ltx_text" id="A5.T8.1.11.2.1" style="background-color:#ECF4FF;">+2.0</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.11.3"><span class="ltx_text" id="A5.T8.1.11.3.1" style="background-color:#ECF4FF;">+3.2</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.12" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T8.1.12.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T8.1.12.1.1" style="background-color:#EFEFEF;">Patchify on vector-quantinized tokens</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.13.1">Scratch</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.13.2">80.7</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.13.3">80.9</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.14.1">MAGE <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.14.2">+1.8</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.14.3">+3.0</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.15.1">MAGE-C <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.15.2"><span class="ltx_text ltx_font_bold" id="A5.T8.1.15.2.1">+2.2</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.15.3">+3.4</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.16" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T8.1.16.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T8.1.16.1.1" style="background-color:#EFEFEF;">Patchify on continuous tokens</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.17.1">Scratch</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.17.2">79.1</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.17.3">78.7</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.18" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.18.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A5.T8.1.18.1.1" style="background-color:#ECF4FF;">D-JEPA</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.18.2"><span class="ltx_text" id="A5.T8.1.18.2.1" style="background-color:#ECF4FF;">+1.6</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.18.3"><span class="ltx_text" id="A5.T8.1.18.3.1" style="background-color:#ECF4FF;">+2.9</span></td>
</tr>
</table>
</figure>
</section>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Fine-tuning.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T8" title="Table 8 ‣ Linear probing. ‣ E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a> displays the fine-tuning performance of D-JEPA and other self-supervised learning methods, where all the pre-trained encoder parameters are fine-tuned. It is important to note that directly comparing the final performance of these various methods is inappropriate due to their different data-pacifying approaches. Nonetheless, we can compare their performance improvements relative to training-from-scratch models. The results presented in the tables show that D-JEPA demonstrates strong competitiveness as a representation model. Although its ultimate performance does not surpass that of methods operating in raw space, we observe a substantial performance enhancement compared to training from scratch.</p>
</div>
</section>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Analysis on raw pixel space and semantic token space.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px4.p1.1">Although the D-JEPA model trained in the continuous token space has demonstrated impressive performance on generative tasks, an analysis of the results in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T7" title="Table 7 ‣ Experiment settings. ‣ E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a> and Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T8" title="Table 8 ‣ Linear probing. ‣ E.2 Image classification ‣ Appendix E D-JEPA for representation learning ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a> reveals that directly training D-JEPA in the pixel space significantly outperforms training in the token space, particularly in linear probing tasks. We attribute this suboptimal performance in both from-scratch and fine-tuning scenarios to using VAE, as discussed in <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>. Expressly, the training process of VAEs typically excludes complex image preprocessing techniques such as mixup <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib125" title="">2017b</a>)</cite>, which impairs the VAE’s ability to effectively encode preprocessed images for classification tasks, thereby resulting in a performance deficit. We are optimistic that retraining the VAE with these advanced preprocessing techniques will address this issue and yield improved results.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Flow Matching Loss</h2>
<div class="ltx_para ltx_noindent" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">In this section, we transition from the Gaussian denoising setting as described in <cite class="ltx_cite ltx_citemacro_cite">Ho et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite> to the flow matching formulation <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>; Mo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib74" title="">2024</a>; Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>, thereby providing additional flexibility to D-JEPA. We adhere to the formulation presented in <cite class="ltx_cite ltx_citemacro_cite">Zhuo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite> and reformulate it for modeling token distribution.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p2">
<p class="ltx_p" id="A6.p2.2">The schedule that defines how to corrupt data to noise significantly impacts the training and sampling of standard diffusion models. Consequently, numerous diffusion schedules, such as VE <cite class="ltx_cite ltx_citemacro_citep">(Song et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib97" title="">2021</a>)</cite>, VP <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite>, and EDM <cite class="ltx_cite ltx_citemacro_citep">(Karras et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib53" title="">2022</a>)</cite>, have been carefully designed and utilized. In contrast, flow matching <cite class="ltx_cite ltx_citemacro_citep">(Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>; Albergo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib1" title="">2023</a>)</cite> emerges as a simple alternative that linearly interpolates between noise and data along a straight line. More specifically, given the data <math alttext="x_{i}\sim p(x_{i})" class="ltx_Math" display="inline" id="A6.p2.1.m1.1"><semantics id="A6.p2.1.m1.1a"><mrow id="A6.p2.1.m1.1.1" xref="A6.p2.1.m1.1.1.cmml"><msub id="A6.p2.1.m1.1.1.3" xref="A6.p2.1.m1.1.1.3.cmml"><mi id="A6.p2.1.m1.1.1.3.2" xref="A6.p2.1.m1.1.1.3.2.cmml">x</mi><mi id="A6.p2.1.m1.1.1.3.3" xref="A6.p2.1.m1.1.1.3.3.cmml">i</mi></msub><mo id="A6.p2.1.m1.1.1.2" xref="A6.p2.1.m1.1.1.2.cmml">∼</mo><mrow id="A6.p2.1.m1.1.1.1" xref="A6.p2.1.m1.1.1.1.cmml"><mi id="A6.p2.1.m1.1.1.1.3" xref="A6.p2.1.m1.1.1.1.3.cmml">p</mi><mo id="A6.p2.1.m1.1.1.1.2" xref="A6.p2.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="A6.p2.1.m1.1.1.1.1.1" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml"><mo id="A6.p2.1.m1.1.1.1.1.1.2" stretchy="false" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="A6.p2.1.m1.1.1.1.1.1.1" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="A6.p2.1.m1.1.1.1.1.1.1.2" xref="A6.p2.1.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A6.p2.1.m1.1.1.1.1.1.1.3" xref="A6.p2.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A6.p2.1.m1.1.1.1.1.1.3" stretchy="false" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p2.1.m1.1b"><apply id="A6.p2.1.m1.1.1.cmml" xref="A6.p2.1.m1.1.1"><csymbol cd="latexml" id="A6.p2.1.m1.1.1.2.cmml" xref="A6.p2.1.m1.1.1.2">similar-to</csymbol><apply id="A6.p2.1.m1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="A6.p2.1.m1.1.1.3.1.cmml" xref="A6.p2.1.m1.1.1.3">subscript</csymbol><ci id="A6.p2.1.m1.1.1.3.2.cmml" xref="A6.p2.1.m1.1.1.3.2">𝑥</ci><ci id="A6.p2.1.m1.1.1.3.3.cmml" xref="A6.p2.1.m1.1.1.3.3">𝑖</ci></apply><apply id="A6.p2.1.m1.1.1.1.cmml" xref="A6.p2.1.m1.1.1.1"><times id="A6.p2.1.m1.1.1.1.2.cmml" xref="A6.p2.1.m1.1.1.1.2"></times><ci id="A6.p2.1.m1.1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.1.3">𝑝</ci><apply id="A6.p2.1.m1.1.1.1.1.1.1.cmml" xref="A6.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="A6.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="A6.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="A6.p2.1.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="A6.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.1.m1.1c">x_{i}\sim p(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A6.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∼ italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> and Gaussian noise <math alttext="\epsilon\sim\mathcal{N}(0,I)" class="ltx_Math" display="inline" id="A6.p2.2.m2.2"><semantics id="A6.p2.2.m2.2a"><mrow id="A6.p2.2.m2.2.3" xref="A6.p2.2.m2.2.3.cmml"><mi id="A6.p2.2.m2.2.3.2" xref="A6.p2.2.m2.2.3.2.cmml">ϵ</mi><mo id="A6.p2.2.m2.2.3.1" xref="A6.p2.2.m2.2.3.1.cmml">∼</mo><mrow id="A6.p2.2.m2.2.3.3" xref="A6.p2.2.m2.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A6.p2.2.m2.2.3.3.2" xref="A6.p2.2.m2.2.3.3.2.cmml">𝒩</mi><mo id="A6.p2.2.m2.2.3.3.1" xref="A6.p2.2.m2.2.3.3.1.cmml">⁢</mo><mrow id="A6.p2.2.m2.2.3.3.3.2" xref="A6.p2.2.m2.2.3.3.3.1.cmml"><mo id="A6.p2.2.m2.2.3.3.3.2.1" stretchy="false" xref="A6.p2.2.m2.2.3.3.3.1.cmml">(</mo><mn id="A6.p2.2.m2.1.1" xref="A6.p2.2.m2.1.1.cmml">0</mn><mo id="A6.p2.2.m2.2.3.3.3.2.2" xref="A6.p2.2.m2.2.3.3.3.1.cmml">,</mo><mi id="A6.p2.2.m2.2.2" xref="A6.p2.2.m2.2.2.cmml">I</mi><mo id="A6.p2.2.m2.2.3.3.3.2.3" stretchy="false" xref="A6.p2.2.m2.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p2.2.m2.2b"><apply id="A6.p2.2.m2.2.3.cmml" xref="A6.p2.2.m2.2.3"><csymbol cd="latexml" id="A6.p2.2.m2.2.3.1.cmml" xref="A6.p2.2.m2.2.3.1">similar-to</csymbol><ci id="A6.p2.2.m2.2.3.2.cmml" xref="A6.p2.2.m2.2.3.2">italic-ϵ</ci><apply id="A6.p2.2.m2.2.3.3.cmml" xref="A6.p2.2.m2.2.3.3"><times id="A6.p2.2.m2.2.3.3.1.cmml" xref="A6.p2.2.m2.2.3.3.1"></times><ci id="A6.p2.2.m2.2.3.3.2.cmml" xref="A6.p2.2.m2.2.3.3.2">𝒩</ci><interval closure="open" id="A6.p2.2.m2.2.3.3.3.1.cmml" xref="A6.p2.2.m2.2.3.3.3.2"><cn id="A6.p2.2.m2.1.1.cmml" type="integer" xref="A6.p2.2.m2.1.1">0</cn><ci id="A6.p2.2.m2.2.2.cmml" xref="A6.p2.2.m2.2.2">𝐼</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.2.m2.2c">\epsilon\sim\mathcal{N}(0,I)</annotation><annotation encoding="application/x-llamapun" id="A6.p2.2.m2.2d">italic_ϵ ∼ caligraphic_N ( 0 , italic_I )</annotation></semantics></math>, we define an interpolation-based forward process:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p3">
<table class="ltx_equation ltx_eqn_table" id="A6.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x_{i}^{t}=\alpha_{t}x_{i}+\beta_{t}\epsilon," class="ltx_Math" display="block" id="A6.Ex6.m1.1"><semantics id="A6.Ex6.m1.1a"><mrow id="A6.Ex6.m1.1.1.1" xref="A6.Ex6.m1.1.1.1.1.cmml"><mrow id="A6.Ex6.m1.1.1.1.1" xref="A6.Ex6.m1.1.1.1.1.cmml"><msubsup id="A6.Ex6.m1.1.1.1.1.2" xref="A6.Ex6.m1.1.1.1.1.2.cmml"><mi id="A6.Ex6.m1.1.1.1.1.2.2.2" xref="A6.Ex6.m1.1.1.1.1.2.2.2.cmml">x</mi><mi id="A6.Ex6.m1.1.1.1.1.2.2.3" xref="A6.Ex6.m1.1.1.1.1.2.2.3.cmml">i</mi><mi id="A6.Ex6.m1.1.1.1.1.2.3" xref="A6.Ex6.m1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="A6.Ex6.m1.1.1.1.1.1" xref="A6.Ex6.m1.1.1.1.1.1.cmml">=</mo><mrow id="A6.Ex6.m1.1.1.1.1.3" xref="A6.Ex6.m1.1.1.1.1.3.cmml"><mrow id="A6.Ex6.m1.1.1.1.1.3.2" xref="A6.Ex6.m1.1.1.1.1.3.2.cmml"><msub id="A6.Ex6.m1.1.1.1.1.3.2.2" xref="A6.Ex6.m1.1.1.1.1.3.2.2.cmml"><mi id="A6.Ex6.m1.1.1.1.1.3.2.2.2" xref="A6.Ex6.m1.1.1.1.1.3.2.2.2.cmml">α</mi><mi id="A6.Ex6.m1.1.1.1.1.3.2.2.3" xref="A6.Ex6.m1.1.1.1.1.3.2.2.3.cmml">t</mi></msub><mo id="A6.Ex6.m1.1.1.1.1.3.2.1" xref="A6.Ex6.m1.1.1.1.1.3.2.1.cmml">⁢</mo><msub id="A6.Ex6.m1.1.1.1.1.3.2.3" xref="A6.Ex6.m1.1.1.1.1.3.2.3.cmml"><mi id="A6.Ex6.m1.1.1.1.1.3.2.3.2" xref="A6.Ex6.m1.1.1.1.1.3.2.3.2.cmml">x</mi><mi id="A6.Ex6.m1.1.1.1.1.3.2.3.3" xref="A6.Ex6.m1.1.1.1.1.3.2.3.3.cmml">i</mi></msub></mrow><mo id="A6.Ex6.m1.1.1.1.1.3.1" xref="A6.Ex6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="A6.Ex6.m1.1.1.1.1.3.3" xref="A6.Ex6.m1.1.1.1.1.3.3.cmml"><msub id="A6.Ex6.m1.1.1.1.1.3.3.2" xref="A6.Ex6.m1.1.1.1.1.3.3.2.cmml"><mi id="A6.Ex6.m1.1.1.1.1.3.3.2.2" xref="A6.Ex6.m1.1.1.1.1.3.3.2.2.cmml">β</mi><mi id="A6.Ex6.m1.1.1.1.1.3.3.2.3" xref="A6.Ex6.m1.1.1.1.1.3.3.2.3.cmml">t</mi></msub><mo id="A6.Ex6.m1.1.1.1.1.3.3.1" xref="A6.Ex6.m1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="A6.Ex6.m1.1.1.1.1.3.3.3" xref="A6.Ex6.m1.1.1.1.1.3.3.3.cmml">ϵ</mi></mrow></mrow></mrow><mo id="A6.Ex6.m1.1.1.1.2" xref="A6.Ex6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex6.m1.1b"><apply id="A6.Ex6.m1.1.1.1.1.cmml" xref="A6.Ex6.m1.1.1.1"><eq id="A6.Ex6.m1.1.1.1.1.1.cmml" xref="A6.Ex6.m1.1.1.1.1.1"></eq><apply id="A6.Ex6.m1.1.1.1.1.2.cmml" xref="A6.Ex6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.2">superscript</csymbol><apply id="A6.Ex6.m1.1.1.1.1.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.2.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.2">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.2.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.2.2.2">𝑥</ci><ci id="A6.Ex6.m1.1.1.1.1.2.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.2.2.3">𝑖</ci></apply><ci id="A6.Ex6.m1.1.1.1.1.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.2.3">𝑡</ci></apply><apply id="A6.Ex6.m1.1.1.1.1.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3"><plus id="A6.Ex6.m1.1.1.1.1.3.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.1"></plus><apply id="A6.Ex6.m1.1.1.1.1.3.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2"><times id="A6.Ex6.m1.1.1.1.1.3.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.1"></times><apply id="A6.Ex6.m1.1.1.1.1.3.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.3.2.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.3.2.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2.2">𝛼</ci><ci id="A6.Ex6.m1.1.1.1.1.3.2.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2.3">𝑡</ci></apply><apply id="A6.Ex6.m1.1.1.1.1.3.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.3.2.3.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.3.2.3.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3.2">𝑥</ci><ci id="A6.Ex6.m1.1.1.1.1.3.2.3.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3.3">𝑖</ci></apply></apply><apply id="A6.Ex6.m1.1.1.1.1.3.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3"><times id="A6.Ex6.m1.1.1.1.1.3.3.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.1"></times><apply id="A6.Ex6.m1.1.1.1.1.3.3.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.3.3.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.3.3.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2.2">𝛽</ci><ci id="A6.Ex6.m1.1.1.1.1.3.3.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2.3">𝑡</ci></apply><ci id="A6.Ex6.m1.1.1.1.1.3.3.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.3">italic-ϵ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex6.m1.1c">x_{i}^{t}=\alpha_{t}x_{i}+\beta_{t}\epsilon,</annotation><annotation encoding="application/x-llamapun" id="A6.Ex6.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ϵ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p4">
<p class="ltx_p" id="A6.p4.11">where <math alttext="\alpha_{0}=0" class="ltx_Math" display="inline" id="A6.p4.1.m1.1"><semantics id="A6.p4.1.m1.1a"><mrow id="A6.p4.1.m1.1.1" xref="A6.p4.1.m1.1.1.cmml"><msub id="A6.p4.1.m1.1.1.2" xref="A6.p4.1.m1.1.1.2.cmml"><mi id="A6.p4.1.m1.1.1.2.2" xref="A6.p4.1.m1.1.1.2.2.cmml">α</mi><mn id="A6.p4.1.m1.1.1.2.3" xref="A6.p4.1.m1.1.1.2.3.cmml">0</mn></msub><mo id="A6.p4.1.m1.1.1.1" xref="A6.p4.1.m1.1.1.1.cmml">=</mo><mn id="A6.p4.1.m1.1.1.3" xref="A6.p4.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.1.m1.1b"><apply id="A6.p4.1.m1.1.1.cmml" xref="A6.p4.1.m1.1.1"><eq id="A6.p4.1.m1.1.1.1.cmml" xref="A6.p4.1.m1.1.1.1"></eq><apply id="A6.p4.1.m1.1.1.2.cmml" xref="A6.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="A6.p4.1.m1.1.1.2.1.cmml" xref="A6.p4.1.m1.1.1.2">subscript</csymbol><ci id="A6.p4.1.m1.1.1.2.2.cmml" xref="A6.p4.1.m1.1.1.2.2">𝛼</ci><cn id="A6.p4.1.m1.1.1.2.3.cmml" type="integer" xref="A6.p4.1.m1.1.1.2.3">0</cn></apply><cn id="A6.p4.1.m1.1.1.3.cmml" type="integer" xref="A6.p4.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.1.m1.1c">\alpha_{0}=0</annotation><annotation encoding="application/x-llamapun" id="A6.p4.1.m1.1d">italic_α start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 0</annotation></semantics></math>, <math alttext="\beta_{t}=1" class="ltx_Math" display="inline" id="A6.p4.2.m2.1"><semantics id="A6.p4.2.m2.1a"><mrow id="A6.p4.2.m2.1.1" xref="A6.p4.2.m2.1.1.cmml"><msub id="A6.p4.2.m2.1.1.2" xref="A6.p4.2.m2.1.1.2.cmml"><mi id="A6.p4.2.m2.1.1.2.2" xref="A6.p4.2.m2.1.1.2.2.cmml">β</mi><mi id="A6.p4.2.m2.1.1.2.3" xref="A6.p4.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="A6.p4.2.m2.1.1.1" xref="A6.p4.2.m2.1.1.1.cmml">=</mo><mn id="A6.p4.2.m2.1.1.3" xref="A6.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.2.m2.1b"><apply id="A6.p4.2.m2.1.1.cmml" xref="A6.p4.2.m2.1.1"><eq id="A6.p4.2.m2.1.1.1.cmml" xref="A6.p4.2.m2.1.1.1"></eq><apply id="A6.p4.2.m2.1.1.2.cmml" xref="A6.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="A6.p4.2.m2.1.1.2.1.cmml" xref="A6.p4.2.m2.1.1.2">subscript</csymbol><ci id="A6.p4.2.m2.1.1.2.2.cmml" xref="A6.p4.2.m2.1.1.2.2">𝛽</ci><ci id="A6.p4.2.m2.1.1.2.3.cmml" xref="A6.p4.2.m2.1.1.2.3">𝑡</ci></apply><cn id="A6.p4.2.m2.1.1.3.cmml" type="integer" xref="A6.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.2.m2.1c">\beta_{t}=1</annotation><annotation encoding="application/x-llamapun" id="A6.p4.2.m2.1d">italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1</annotation></semantics></math>, <math alttext="\alpha_{1}=1" class="ltx_Math" display="inline" id="A6.p4.3.m3.1"><semantics id="A6.p4.3.m3.1a"><mrow id="A6.p4.3.m3.1.1" xref="A6.p4.3.m3.1.1.cmml"><msub id="A6.p4.3.m3.1.1.2" xref="A6.p4.3.m3.1.1.2.cmml"><mi id="A6.p4.3.m3.1.1.2.2" xref="A6.p4.3.m3.1.1.2.2.cmml">α</mi><mn id="A6.p4.3.m3.1.1.2.3" xref="A6.p4.3.m3.1.1.2.3.cmml">1</mn></msub><mo id="A6.p4.3.m3.1.1.1" xref="A6.p4.3.m3.1.1.1.cmml">=</mo><mn id="A6.p4.3.m3.1.1.3" xref="A6.p4.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.3.m3.1b"><apply id="A6.p4.3.m3.1.1.cmml" xref="A6.p4.3.m3.1.1"><eq id="A6.p4.3.m3.1.1.1.cmml" xref="A6.p4.3.m3.1.1.1"></eq><apply id="A6.p4.3.m3.1.1.2.cmml" xref="A6.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="A6.p4.3.m3.1.1.2.1.cmml" xref="A6.p4.3.m3.1.1.2">subscript</csymbol><ci id="A6.p4.3.m3.1.1.2.2.cmml" xref="A6.p4.3.m3.1.1.2.2">𝛼</ci><cn id="A6.p4.3.m3.1.1.2.3.cmml" type="integer" xref="A6.p4.3.m3.1.1.2.3">1</cn></apply><cn id="A6.p4.3.m3.1.1.3.cmml" type="integer" xref="A6.p4.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.3.m3.1c">\alpha_{1}=1</annotation><annotation encoding="application/x-llamapun" id="A6.p4.3.m3.1d">italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1</annotation></semantics></math>, and <math alttext="\beta_{1}=0" class="ltx_Math" display="inline" id="A6.p4.4.m4.1"><semantics id="A6.p4.4.m4.1a"><mrow id="A6.p4.4.m4.1.1" xref="A6.p4.4.m4.1.1.cmml"><msub id="A6.p4.4.m4.1.1.2" xref="A6.p4.4.m4.1.1.2.cmml"><mi id="A6.p4.4.m4.1.1.2.2" xref="A6.p4.4.m4.1.1.2.2.cmml">β</mi><mn id="A6.p4.4.m4.1.1.2.3" xref="A6.p4.4.m4.1.1.2.3.cmml">1</mn></msub><mo id="A6.p4.4.m4.1.1.1" xref="A6.p4.4.m4.1.1.1.cmml">=</mo><mn id="A6.p4.4.m4.1.1.3" xref="A6.p4.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.4.m4.1b"><apply id="A6.p4.4.m4.1.1.cmml" xref="A6.p4.4.m4.1.1"><eq id="A6.p4.4.m4.1.1.1.cmml" xref="A6.p4.4.m4.1.1.1"></eq><apply id="A6.p4.4.m4.1.1.2.cmml" xref="A6.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="A6.p4.4.m4.1.1.2.1.cmml" xref="A6.p4.4.m4.1.1.2">subscript</csymbol><ci id="A6.p4.4.m4.1.1.2.2.cmml" xref="A6.p4.4.m4.1.1.2.2">𝛽</ci><cn id="A6.p4.4.m4.1.1.2.3.cmml" type="integer" xref="A6.p4.4.m4.1.1.2.3">1</cn></apply><cn id="A6.p4.4.m4.1.1.3.cmml" type="integer" xref="A6.p4.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.4.m4.1c">\beta_{1}=0</annotation><annotation encoding="application/x-llamapun" id="A6.p4.4.m4.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0</annotation></semantics></math>. This interpolation for <math alttext="t\in[0,1]" class="ltx_Math" display="inline" id="A6.p4.5.m5.2"><semantics id="A6.p4.5.m5.2a"><mrow id="A6.p4.5.m5.2.3" xref="A6.p4.5.m5.2.3.cmml"><mi id="A6.p4.5.m5.2.3.2" xref="A6.p4.5.m5.2.3.2.cmml">t</mi><mo id="A6.p4.5.m5.2.3.1" xref="A6.p4.5.m5.2.3.1.cmml">∈</mo><mrow id="A6.p4.5.m5.2.3.3.2" xref="A6.p4.5.m5.2.3.3.1.cmml"><mo id="A6.p4.5.m5.2.3.3.2.1" stretchy="false" xref="A6.p4.5.m5.2.3.3.1.cmml">[</mo><mn id="A6.p4.5.m5.1.1" xref="A6.p4.5.m5.1.1.cmml">0</mn><mo id="A6.p4.5.m5.2.3.3.2.2" xref="A6.p4.5.m5.2.3.3.1.cmml">,</mo><mn id="A6.p4.5.m5.2.2" xref="A6.p4.5.m5.2.2.cmml">1</mn><mo id="A6.p4.5.m5.2.3.3.2.3" stretchy="false" xref="A6.p4.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.5.m5.2b"><apply id="A6.p4.5.m5.2.3.cmml" xref="A6.p4.5.m5.2.3"><in id="A6.p4.5.m5.2.3.1.cmml" xref="A6.p4.5.m5.2.3.1"></in><ci id="A6.p4.5.m5.2.3.2.cmml" xref="A6.p4.5.m5.2.3.2">𝑡</ci><interval closure="closed" id="A6.p4.5.m5.2.3.3.1.cmml" xref="A6.p4.5.m5.2.3.3.2"><cn id="A6.p4.5.m5.1.1.cmml" type="integer" xref="A6.p4.5.m5.1.1">0</cn><cn id="A6.p4.5.m5.2.2.cmml" type="integer" xref="A6.p4.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.5.m5.2c">t\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="A6.p4.5.m5.2d">italic_t ∈ [ 0 , 1 ]</annotation></semantics></math> bridges <math alttext="x_{i}^{0}=\epsilon" class="ltx_Math" display="inline" id="A6.p4.6.m6.1"><semantics id="A6.p4.6.m6.1a"><mrow id="A6.p4.6.m6.1.1" xref="A6.p4.6.m6.1.1.cmml"><msubsup id="A6.p4.6.m6.1.1.2" xref="A6.p4.6.m6.1.1.2.cmml"><mi id="A6.p4.6.m6.1.1.2.2.2" xref="A6.p4.6.m6.1.1.2.2.2.cmml">x</mi><mi id="A6.p4.6.m6.1.1.2.2.3" xref="A6.p4.6.m6.1.1.2.2.3.cmml">i</mi><mn id="A6.p4.6.m6.1.1.2.3" xref="A6.p4.6.m6.1.1.2.3.cmml">0</mn></msubsup><mo id="A6.p4.6.m6.1.1.1" xref="A6.p4.6.m6.1.1.1.cmml">=</mo><mi id="A6.p4.6.m6.1.1.3" xref="A6.p4.6.m6.1.1.3.cmml">ϵ</mi></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.6.m6.1b"><apply id="A6.p4.6.m6.1.1.cmml" xref="A6.p4.6.m6.1.1"><eq id="A6.p4.6.m6.1.1.1.cmml" xref="A6.p4.6.m6.1.1.1"></eq><apply id="A6.p4.6.m6.1.1.2.cmml" xref="A6.p4.6.m6.1.1.2"><csymbol cd="ambiguous" id="A6.p4.6.m6.1.1.2.1.cmml" xref="A6.p4.6.m6.1.1.2">superscript</csymbol><apply id="A6.p4.6.m6.1.1.2.2.cmml" xref="A6.p4.6.m6.1.1.2"><csymbol cd="ambiguous" id="A6.p4.6.m6.1.1.2.2.1.cmml" xref="A6.p4.6.m6.1.1.2">subscript</csymbol><ci id="A6.p4.6.m6.1.1.2.2.2.cmml" xref="A6.p4.6.m6.1.1.2.2.2">𝑥</ci><ci id="A6.p4.6.m6.1.1.2.2.3.cmml" xref="A6.p4.6.m6.1.1.2.2.3">𝑖</ci></apply><cn id="A6.p4.6.m6.1.1.2.3.cmml" type="integer" xref="A6.p4.6.m6.1.1.2.3">0</cn></apply><ci id="A6.p4.6.m6.1.1.3.cmml" xref="A6.p4.6.m6.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.6.m6.1c">x_{i}^{0}=\epsilon</annotation><annotation encoding="application/x-llamapun" id="A6.p4.6.m6.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = italic_ϵ</annotation></semantics></math> and <math alttext="x_{i}^{1}=x_{i}" class="ltx_Math" display="inline" id="A6.p4.7.m7.1"><semantics id="A6.p4.7.m7.1a"><mrow id="A6.p4.7.m7.1.1" xref="A6.p4.7.m7.1.1.cmml"><msubsup id="A6.p4.7.m7.1.1.2" xref="A6.p4.7.m7.1.1.2.cmml"><mi id="A6.p4.7.m7.1.1.2.2.2" xref="A6.p4.7.m7.1.1.2.2.2.cmml">x</mi><mi id="A6.p4.7.m7.1.1.2.2.3" xref="A6.p4.7.m7.1.1.2.2.3.cmml">i</mi><mn id="A6.p4.7.m7.1.1.2.3" xref="A6.p4.7.m7.1.1.2.3.cmml">1</mn></msubsup><mo id="A6.p4.7.m7.1.1.1" xref="A6.p4.7.m7.1.1.1.cmml">=</mo><msub id="A6.p4.7.m7.1.1.3" xref="A6.p4.7.m7.1.1.3.cmml"><mi id="A6.p4.7.m7.1.1.3.2" xref="A6.p4.7.m7.1.1.3.2.cmml">x</mi><mi id="A6.p4.7.m7.1.1.3.3" xref="A6.p4.7.m7.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.7.m7.1b"><apply id="A6.p4.7.m7.1.1.cmml" xref="A6.p4.7.m7.1.1"><eq id="A6.p4.7.m7.1.1.1.cmml" xref="A6.p4.7.m7.1.1.1"></eq><apply id="A6.p4.7.m7.1.1.2.cmml" xref="A6.p4.7.m7.1.1.2"><csymbol cd="ambiguous" id="A6.p4.7.m7.1.1.2.1.cmml" xref="A6.p4.7.m7.1.1.2">superscript</csymbol><apply id="A6.p4.7.m7.1.1.2.2.cmml" xref="A6.p4.7.m7.1.1.2"><csymbol cd="ambiguous" id="A6.p4.7.m7.1.1.2.2.1.cmml" xref="A6.p4.7.m7.1.1.2">subscript</csymbol><ci id="A6.p4.7.m7.1.1.2.2.2.cmml" xref="A6.p4.7.m7.1.1.2.2.2">𝑥</ci><ci id="A6.p4.7.m7.1.1.2.2.3.cmml" xref="A6.p4.7.m7.1.1.2.2.3">𝑖</ci></apply><cn id="A6.p4.7.m7.1.1.2.3.cmml" type="integer" xref="A6.p4.7.m7.1.1.2.3">1</cn></apply><apply id="A6.p4.7.m7.1.1.3.cmml" xref="A6.p4.7.m7.1.1.3"><csymbol cd="ambiguous" id="A6.p4.7.m7.1.1.3.1.cmml" xref="A6.p4.7.m7.1.1.3">subscript</csymbol><ci id="A6.p4.7.m7.1.1.3.2.cmml" xref="A6.p4.7.m7.1.1.3.2">𝑥</ci><ci id="A6.p4.7.m7.1.1.3.3.cmml" xref="A6.p4.7.m7.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.7.m7.1c">x_{i}^{1}=x_{i}</annotation><annotation encoding="application/x-llamapun" id="A6.p4.7.m7.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Similar to the diffusion schedule, this interpolation schedule offers flexible choices of <math alttext="\alpha_{t}" class="ltx_Math" display="inline" id="A6.p4.8.m8.1"><semantics id="A6.p4.8.m8.1a"><msub id="A6.p4.8.m8.1.1" xref="A6.p4.8.m8.1.1.cmml"><mi id="A6.p4.8.m8.1.1.2" xref="A6.p4.8.m8.1.1.2.cmml">α</mi><mi id="A6.p4.8.m8.1.1.3" xref="A6.p4.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A6.p4.8.m8.1b"><apply id="A6.p4.8.m8.1.1.cmml" xref="A6.p4.8.m8.1.1"><csymbol cd="ambiguous" id="A6.p4.8.m8.1.1.1.cmml" xref="A6.p4.8.m8.1.1">subscript</csymbol><ci id="A6.p4.8.m8.1.1.2.cmml" xref="A6.p4.8.m8.1.1.2">𝛼</ci><ci id="A6.p4.8.m8.1.1.3.cmml" xref="A6.p4.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.8.m8.1c">\alpha_{t}</annotation><annotation encoding="application/x-llamapun" id="A6.p4.8.m8.1d">italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\beta_{t}" class="ltx_Math" display="inline" id="A6.p4.9.m9.1"><semantics id="A6.p4.9.m9.1a"><msub id="A6.p4.9.m9.1.1" xref="A6.p4.9.m9.1.1.cmml"><mi id="A6.p4.9.m9.1.1.2" xref="A6.p4.9.m9.1.1.2.cmml">β</mi><mi id="A6.p4.9.m9.1.1.3" xref="A6.p4.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A6.p4.9.m9.1b"><apply id="A6.p4.9.m9.1.1.cmml" xref="A6.p4.9.m9.1.1"><csymbol cd="ambiguous" id="A6.p4.9.m9.1.1.1.cmml" xref="A6.p4.9.m9.1.1">subscript</csymbol><ci id="A6.p4.9.m9.1.1.2.cmml" xref="A6.p4.9.m9.1.1.2">𝛽</ci><ci id="A6.p4.9.m9.1.1.3.cmml" xref="A6.p4.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.9.m9.1c">\beta_{t}</annotation><annotation encoding="application/x-llamapun" id="A6.p4.9.m9.1d">italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. For example, we can utilize the original diffusion schedules, such as <math alttext="\alpha_{t}=\sin\left(\frac{\pi}{2}t\right)" class="ltx_Math" display="inline" id="A6.p4.10.m10.2"><semantics id="A6.p4.10.m10.2a"><mrow id="A6.p4.10.m10.2.2" xref="A6.p4.10.m10.2.2.cmml"><msub id="A6.p4.10.m10.2.2.3" xref="A6.p4.10.m10.2.2.3.cmml"><mi id="A6.p4.10.m10.2.2.3.2" xref="A6.p4.10.m10.2.2.3.2.cmml">α</mi><mi id="A6.p4.10.m10.2.2.3.3" xref="A6.p4.10.m10.2.2.3.3.cmml">t</mi></msub><mo id="A6.p4.10.m10.2.2.2" xref="A6.p4.10.m10.2.2.2.cmml">=</mo><mrow id="A6.p4.10.m10.2.2.1.1" xref="A6.p4.10.m10.2.2.1.2.cmml"><mi id="A6.p4.10.m10.1.1" xref="A6.p4.10.m10.1.1.cmml">sin</mi><mo id="A6.p4.10.m10.2.2.1.1a" xref="A6.p4.10.m10.2.2.1.2.cmml">⁡</mo><mrow id="A6.p4.10.m10.2.2.1.1.1" xref="A6.p4.10.m10.2.2.1.2.cmml"><mo id="A6.p4.10.m10.2.2.1.1.1.2" xref="A6.p4.10.m10.2.2.1.2.cmml">(</mo><mrow id="A6.p4.10.m10.2.2.1.1.1.1" xref="A6.p4.10.m10.2.2.1.1.1.1.cmml"><mfrac id="A6.p4.10.m10.2.2.1.1.1.1.2" xref="A6.p4.10.m10.2.2.1.1.1.1.2.cmml"><mi id="A6.p4.10.m10.2.2.1.1.1.1.2.2" xref="A6.p4.10.m10.2.2.1.1.1.1.2.2.cmml">π</mi><mn id="A6.p4.10.m10.2.2.1.1.1.1.2.3" xref="A6.p4.10.m10.2.2.1.1.1.1.2.3.cmml">2</mn></mfrac><mo id="A6.p4.10.m10.2.2.1.1.1.1.1" xref="A6.p4.10.m10.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="A6.p4.10.m10.2.2.1.1.1.1.3" xref="A6.p4.10.m10.2.2.1.1.1.1.3.cmml">t</mi></mrow><mo id="A6.p4.10.m10.2.2.1.1.1.3" xref="A6.p4.10.m10.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.10.m10.2b"><apply id="A6.p4.10.m10.2.2.cmml" xref="A6.p4.10.m10.2.2"><eq id="A6.p4.10.m10.2.2.2.cmml" xref="A6.p4.10.m10.2.2.2"></eq><apply id="A6.p4.10.m10.2.2.3.cmml" xref="A6.p4.10.m10.2.2.3"><csymbol cd="ambiguous" id="A6.p4.10.m10.2.2.3.1.cmml" xref="A6.p4.10.m10.2.2.3">subscript</csymbol><ci id="A6.p4.10.m10.2.2.3.2.cmml" xref="A6.p4.10.m10.2.2.3.2">𝛼</ci><ci id="A6.p4.10.m10.2.2.3.3.cmml" xref="A6.p4.10.m10.2.2.3.3">𝑡</ci></apply><apply id="A6.p4.10.m10.2.2.1.2.cmml" xref="A6.p4.10.m10.2.2.1.1"><sin id="A6.p4.10.m10.1.1.cmml" xref="A6.p4.10.m10.1.1"></sin><apply id="A6.p4.10.m10.2.2.1.1.1.1.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1"><times id="A6.p4.10.m10.2.2.1.1.1.1.1.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.1"></times><apply id="A6.p4.10.m10.2.2.1.1.1.1.2.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.2"><divide id="A6.p4.10.m10.2.2.1.1.1.1.2.1.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.2"></divide><ci id="A6.p4.10.m10.2.2.1.1.1.1.2.2.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.2.2">𝜋</ci><cn id="A6.p4.10.m10.2.2.1.1.1.1.2.3.cmml" type="integer" xref="A6.p4.10.m10.2.2.1.1.1.1.2.3">2</cn></apply><ci id="A6.p4.10.m10.2.2.1.1.1.1.3.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.10.m10.2c">\alpha_{t}=\sin\left(\frac{\pi}{2}t\right)</annotation><annotation encoding="application/x-llamapun" id="A6.p4.10.m10.2d">italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_sin ( divide start_ARG italic_π end_ARG start_ARG 2 end_ARG italic_t )</annotation></semantics></math> and <math alttext="\beta_{t}=\cos\left(\frac{\pi}{2}t\right)" class="ltx_Math" display="inline" id="A6.p4.11.m11.2"><semantics id="A6.p4.11.m11.2a"><mrow id="A6.p4.11.m11.2.2" xref="A6.p4.11.m11.2.2.cmml"><msub id="A6.p4.11.m11.2.2.3" xref="A6.p4.11.m11.2.2.3.cmml"><mi id="A6.p4.11.m11.2.2.3.2" xref="A6.p4.11.m11.2.2.3.2.cmml">β</mi><mi id="A6.p4.11.m11.2.2.3.3" xref="A6.p4.11.m11.2.2.3.3.cmml">t</mi></msub><mo id="A6.p4.11.m11.2.2.2" xref="A6.p4.11.m11.2.2.2.cmml">=</mo><mrow id="A6.p4.11.m11.2.2.1.1" xref="A6.p4.11.m11.2.2.1.2.cmml"><mi id="A6.p4.11.m11.1.1" xref="A6.p4.11.m11.1.1.cmml">cos</mi><mo id="A6.p4.11.m11.2.2.1.1a" xref="A6.p4.11.m11.2.2.1.2.cmml">⁡</mo><mrow id="A6.p4.11.m11.2.2.1.1.1" xref="A6.p4.11.m11.2.2.1.2.cmml"><mo id="A6.p4.11.m11.2.2.1.1.1.2" xref="A6.p4.11.m11.2.2.1.2.cmml">(</mo><mrow id="A6.p4.11.m11.2.2.1.1.1.1" xref="A6.p4.11.m11.2.2.1.1.1.1.cmml"><mfrac id="A6.p4.11.m11.2.2.1.1.1.1.2" xref="A6.p4.11.m11.2.2.1.1.1.1.2.cmml"><mi id="A6.p4.11.m11.2.2.1.1.1.1.2.2" xref="A6.p4.11.m11.2.2.1.1.1.1.2.2.cmml">π</mi><mn id="A6.p4.11.m11.2.2.1.1.1.1.2.3" xref="A6.p4.11.m11.2.2.1.1.1.1.2.3.cmml">2</mn></mfrac><mo id="A6.p4.11.m11.2.2.1.1.1.1.1" xref="A6.p4.11.m11.2.2.1.1.1.1.1.cmml">⁢</mo><mi id="A6.p4.11.m11.2.2.1.1.1.1.3" xref="A6.p4.11.m11.2.2.1.1.1.1.3.cmml">t</mi></mrow><mo id="A6.p4.11.m11.2.2.1.1.1.3" xref="A6.p4.11.m11.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.11.m11.2b"><apply id="A6.p4.11.m11.2.2.cmml" xref="A6.p4.11.m11.2.2"><eq id="A6.p4.11.m11.2.2.2.cmml" xref="A6.p4.11.m11.2.2.2"></eq><apply id="A6.p4.11.m11.2.2.3.cmml" xref="A6.p4.11.m11.2.2.3"><csymbol cd="ambiguous" id="A6.p4.11.m11.2.2.3.1.cmml" xref="A6.p4.11.m11.2.2.3">subscript</csymbol><ci id="A6.p4.11.m11.2.2.3.2.cmml" xref="A6.p4.11.m11.2.2.3.2">𝛽</ci><ci id="A6.p4.11.m11.2.2.3.3.cmml" xref="A6.p4.11.m11.2.2.3.3">𝑡</ci></apply><apply id="A6.p4.11.m11.2.2.1.2.cmml" xref="A6.p4.11.m11.2.2.1.1"><cos id="A6.p4.11.m11.1.1.cmml" xref="A6.p4.11.m11.1.1"></cos><apply id="A6.p4.11.m11.2.2.1.1.1.1.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1"><times id="A6.p4.11.m11.2.2.1.1.1.1.1.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.1"></times><apply id="A6.p4.11.m11.2.2.1.1.1.1.2.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.2"><divide id="A6.p4.11.m11.2.2.1.1.1.1.2.1.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.2"></divide><ci id="A6.p4.11.m11.2.2.1.1.1.1.2.2.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.2.2">𝜋</ci><cn id="A6.p4.11.m11.2.2.1.1.1.1.2.3.cmml" type="integer" xref="A6.p4.11.m11.2.2.1.1.1.1.2.3">2</cn></apply><ci id="A6.p4.11.m11.2.2.1.1.1.1.3.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.11.m11.2c">\beta_{t}=\cos\left(\frac{\pi}{2}t\right)</annotation><annotation encoding="application/x-llamapun" id="A6.p4.11.m11.2d">italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_cos ( divide start_ARG italic_π end_ARG start_ARG 2 end_ARG italic_t )</annotation></semantics></math> for the VP cosine schedule. However, in our framework, we adopt a linear interpolation schedule between noise and data for its simplicity:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p5">
<table class="ltx_equation ltx_eqn_table" id="A6.Ex7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x_{i}^{t}=tx_{i}+(1-t)\epsilon." class="ltx_Math" display="block" id="A6.Ex7.m1.1"><semantics id="A6.Ex7.m1.1a"><mrow id="A6.Ex7.m1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.cmml"><mrow id="A6.Ex7.m1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.cmml"><msubsup id="A6.Ex7.m1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.3.cmml"><mi id="A6.Ex7.m1.1.1.1.1.3.2.2" xref="A6.Ex7.m1.1.1.1.1.3.2.2.cmml">x</mi><mi id="A6.Ex7.m1.1.1.1.1.3.2.3" xref="A6.Ex7.m1.1.1.1.1.3.2.3.cmml">i</mi><mi id="A6.Ex7.m1.1.1.1.1.3.3" xref="A6.Ex7.m1.1.1.1.1.3.3.cmml">t</mi></msubsup><mo id="A6.Ex7.m1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.2.cmml">=</mo><mrow id="A6.Ex7.m1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.cmml"><mrow id="A6.Ex7.m1.1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.1.3.cmml"><mi id="A6.Ex7.m1.1.1.1.1.1.3.2" xref="A6.Ex7.m1.1.1.1.1.1.3.2.cmml">t</mi><mo id="A6.Ex7.m1.1.1.1.1.1.3.1" xref="A6.Ex7.m1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="A6.Ex7.m1.1.1.1.1.1.3.3" xref="A6.Ex7.m1.1.1.1.1.1.3.3.cmml"><mi id="A6.Ex7.m1.1.1.1.1.1.3.3.2" xref="A6.Ex7.m1.1.1.1.1.1.3.3.2.cmml">x</mi><mi id="A6.Ex7.m1.1.1.1.1.1.3.3.3" xref="A6.Ex7.m1.1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="A6.Ex7.m1.1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="A6.Ex7.m1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.cmml"><mrow id="A6.Ex7.m1.1.1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A6.Ex7.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></mrow><mo id="A6.Ex7.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A6.Ex7.m1.1.1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="A6.Ex7.m1.1.1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.1.1.3.cmml">ϵ</mi></mrow></mrow></mrow><mo id="A6.Ex7.m1.1.1.1.2" lspace="0em" xref="A6.Ex7.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex7.m1.1b"><apply id="A6.Ex7.m1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1"><eq id="A6.Ex7.m1.1.1.1.1.2.cmml" xref="A6.Ex7.m1.1.1.1.1.2"></eq><apply id="A6.Ex7.m1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.Ex7.m1.1.1.1.1.3.1.cmml" xref="A6.Ex7.m1.1.1.1.1.3">superscript</csymbol><apply id="A6.Ex7.m1.1.1.1.1.3.2.cmml" xref="A6.Ex7.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.Ex7.m1.1.1.1.1.3.2.1.cmml" xref="A6.Ex7.m1.1.1.1.1.3">subscript</csymbol><ci id="A6.Ex7.m1.1.1.1.1.3.2.2.cmml" xref="A6.Ex7.m1.1.1.1.1.3.2.2">𝑥</ci><ci id="A6.Ex7.m1.1.1.1.1.3.2.3.cmml" xref="A6.Ex7.m1.1.1.1.1.3.2.3">𝑖</ci></apply><ci id="A6.Ex7.m1.1.1.1.1.3.3.cmml" xref="A6.Ex7.m1.1.1.1.1.3.3">𝑡</ci></apply><apply id="A6.Ex7.m1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1"><plus id="A6.Ex7.m1.1.1.1.1.1.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.2"></plus><apply id="A6.Ex7.m1.1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3"><times id="A6.Ex7.m1.1.1.1.1.1.3.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.1"></times><ci id="A6.Ex7.m1.1.1.1.1.1.3.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.2">𝑡</ci><apply id="A6.Ex7.m1.1.1.1.1.1.3.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex7.m1.1.1.1.1.1.3.3.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.Ex7.m1.1.1.1.1.1.3.3.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3.2">𝑥</ci><ci id="A6.Ex7.m1.1.1.1.1.1.3.3.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply><apply id="A6.Ex7.m1.1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1"><times id="A6.Ex7.m1.1.1.1.1.1.1.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.2"></times><apply id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1"><minus id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="A6.Ex7.m1.1.1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.3">italic-ϵ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex7.m1.1c">x_{i}^{t}=tx_{i}+(1-t)\epsilon.</annotation><annotation encoding="application/x-llamapun" id="A6.Ex7.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_t italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + ( 1 - italic_t ) italic_ϵ .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p6">
<p class="ltx_p" id="A6.p6.1">This formulation represents a uniform transformation with constant velocity between the data and noise. The corresponding time-dependent velocity field is defined as:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p7">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A8.EGx2">
<tbody id="A6.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle v_{t}(x_{i}^{t})" class="ltx_Math" display="inline" id="A6.E5.m1.1"><semantics id="A6.E5.m1.1a"><mrow id="A6.E5.m1.1.1" xref="A6.E5.m1.1.1.cmml"><msub id="A6.E5.m1.1.1.3" xref="A6.E5.m1.1.1.3.cmml"><mi id="A6.E5.m1.1.1.3.2" xref="A6.E5.m1.1.1.3.2.cmml">v</mi><mi id="A6.E5.m1.1.1.3.3" xref="A6.E5.m1.1.1.3.3.cmml">t</mi></msub><mo id="A6.E5.m1.1.1.2" xref="A6.E5.m1.1.1.2.cmml">⁢</mo><mrow id="A6.E5.m1.1.1.1.1" xref="A6.E5.m1.1.1.1.1.1.cmml"><mo id="A6.E5.m1.1.1.1.1.2" stretchy="false" xref="A6.E5.m1.1.1.1.1.1.cmml">(</mo><msubsup id="A6.E5.m1.1.1.1.1.1" xref="A6.E5.m1.1.1.1.1.1.cmml"><mi id="A6.E5.m1.1.1.1.1.1.2.2" xref="A6.E5.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A6.E5.m1.1.1.1.1.1.2.3" xref="A6.E5.m1.1.1.1.1.1.2.3.cmml">i</mi><mi id="A6.E5.m1.1.1.1.1.1.3" xref="A6.E5.m1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.E5.m1.1.1.1.1.3" stretchy="false" xref="A6.E5.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.E5.m1.1b"><apply id="A6.E5.m1.1.1.cmml" xref="A6.E5.m1.1.1"><times id="A6.E5.m1.1.1.2.cmml" xref="A6.E5.m1.1.1.2"></times><apply id="A6.E5.m1.1.1.3.cmml" xref="A6.E5.m1.1.1.3"><csymbol cd="ambiguous" id="A6.E5.m1.1.1.3.1.cmml" xref="A6.E5.m1.1.1.3">subscript</csymbol><ci id="A6.E5.m1.1.1.3.2.cmml" xref="A6.E5.m1.1.1.3.2">𝑣</ci><ci id="A6.E5.m1.1.1.3.3.cmml" xref="A6.E5.m1.1.1.3.3">𝑡</ci></apply><apply id="A6.E5.m1.1.1.1.1.1.cmml" xref="A6.E5.m1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E5.m1.1.1.1.1.1.1.cmml" xref="A6.E5.m1.1.1.1.1">superscript</csymbol><apply id="A6.E5.m1.1.1.1.1.1.2.cmml" xref="A6.E5.m1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E5.m1.1.1.1.1.1.2.1.cmml" xref="A6.E5.m1.1.1.1.1">subscript</csymbol><ci id="A6.E5.m1.1.1.1.1.1.2.2.cmml" xref="A6.E5.m1.1.1.1.1.1.2.2">𝑥</ci><ci id="A6.E5.m1.1.1.1.1.1.2.3.cmml" xref="A6.E5.m1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="A6.E5.m1.1.1.1.1.1.3.cmml" xref="A6.E5.m1.1.1.1.1.1.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E5.m1.1c">\displaystyle v_{t}(x_{i}^{t})</annotation><annotation encoding="application/x-llamapun" id="A6.E5.m1.1d">italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\dot{\alpha}_{t}x_{i}+\dot{\beta}_{t}\epsilon" class="ltx_Math" display="inline" id="A6.E5.m2.1"><semantics id="A6.E5.m2.1a"><mrow id="A6.E5.m2.1.1" xref="A6.E5.m2.1.1.cmml"><mi id="A6.E5.m2.1.1.2" xref="A6.E5.m2.1.1.2.cmml"></mi><mo id="A6.E5.m2.1.1.1" xref="A6.E5.m2.1.1.1.cmml">=</mo><mrow id="A6.E5.m2.1.1.3" xref="A6.E5.m2.1.1.3.cmml"><mrow id="A6.E5.m2.1.1.3.2" xref="A6.E5.m2.1.1.3.2.cmml"><msub id="A6.E5.m2.1.1.3.2.2" xref="A6.E5.m2.1.1.3.2.2.cmml"><mover accent="true" id="A6.E5.m2.1.1.3.2.2.2" xref="A6.E5.m2.1.1.3.2.2.2.cmml"><mi id="A6.E5.m2.1.1.3.2.2.2.2" xref="A6.E5.m2.1.1.3.2.2.2.2.cmml">α</mi><mo id="A6.E5.m2.1.1.3.2.2.2.1" xref="A6.E5.m2.1.1.3.2.2.2.1.cmml">˙</mo></mover><mi id="A6.E5.m2.1.1.3.2.2.3" xref="A6.E5.m2.1.1.3.2.2.3.cmml">t</mi></msub><mo id="A6.E5.m2.1.1.3.2.1" xref="A6.E5.m2.1.1.3.2.1.cmml">⁢</mo><msub id="A6.E5.m2.1.1.3.2.3" xref="A6.E5.m2.1.1.3.2.3.cmml"><mi id="A6.E5.m2.1.1.3.2.3.2" xref="A6.E5.m2.1.1.3.2.3.2.cmml">x</mi><mi id="A6.E5.m2.1.1.3.2.3.3" xref="A6.E5.m2.1.1.3.2.3.3.cmml">i</mi></msub></mrow><mo id="A6.E5.m2.1.1.3.1" xref="A6.E5.m2.1.1.3.1.cmml">+</mo><mrow id="A6.E5.m2.1.1.3.3" xref="A6.E5.m2.1.1.3.3.cmml"><msub id="A6.E5.m2.1.1.3.3.2" xref="A6.E5.m2.1.1.3.3.2.cmml"><mover accent="true" id="A6.E5.m2.1.1.3.3.2.2" xref="A6.E5.m2.1.1.3.3.2.2.cmml"><mi id="A6.E5.m2.1.1.3.3.2.2.2" xref="A6.E5.m2.1.1.3.3.2.2.2.cmml">β</mi><mo id="A6.E5.m2.1.1.3.3.2.2.1" xref="A6.E5.m2.1.1.3.3.2.2.1.cmml">˙</mo></mover><mi id="A6.E5.m2.1.1.3.3.2.3" xref="A6.E5.m2.1.1.3.3.2.3.cmml">t</mi></msub><mo id="A6.E5.m2.1.1.3.3.1" xref="A6.E5.m2.1.1.3.3.1.cmml">⁢</mo><mi id="A6.E5.m2.1.1.3.3.3" xref="A6.E5.m2.1.1.3.3.3.cmml">ϵ</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.E5.m2.1b"><apply id="A6.E5.m2.1.1.cmml" xref="A6.E5.m2.1.1"><eq id="A6.E5.m2.1.1.1.cmml" xref="A6.E5.m2.1.1.1"></eq><csymbol cd="latexml" id="A6.E5.m2.1.1.2.cmml" xref="A6.E5.m2.1.1.2">absent</csymbol><apply id="A6.E5.m2.1.1.3.cmml" xref="A6.E5.m2.1.1.3"><plus id="A6.E5.m2.1.1.3.1.cmml" xref="A6.E5.m2.1.1.3.1"></plus><apply id="A6.E5.m2.1.1.3.2.cmml" xref="A6.E5.m2.1.1.3.2"><times id="A6.E5.m2.1.1.3.2.1.cmml" xref="A6.E5.m2.1.1.3.2.1"></times><apply id="A6.E5.m2.1.1.3.2.2.cmml" xref="A6.E5.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="A6.E5.m2.1.1.3.2.2.1.cmml" xref="A6.E5.m2.1.1.3.2.2">subscript</csymbol><apply id="A6.E5.m2.1.1.3.2.2.2.cmml" xref="A6.E5.m2.1.1.3.2.2.2"><ci id="A6.E5.m2.1.1.3.2.2.2.1.cmml" xref="A6.E5.m2.1.1.3.2.2.2.1">˙</ci><ci id="A6.E5.m2.1.1.3.2.2.2.2.cmml" xref="A6.E5.m2.1.1.3.2.2.2.2">𝛼</ci></apply><ci id="A6.E5.m2.1.1.3.2.2.3.cmml" xref="A6.E5.m2.1.1.3.2.2.3">𝑡</ci></apply><apply id="A6.E5.m2.1.1.3.2.3.cmml" xref="A6.E5.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="A6.E5.m2.1.1.3.2.3.1.cmml" xref="A6.E5.m2.1.1.3.2.3">subscript</csymbol><ci id="A6.E5.m2.1.1.3.2.3.2.cmml" xref="A6.E5.m2.1.1.3.2.3.2">𝑥</ci><ci id="A6.E5.m2.1.1.3.2.3.3.cmml" xref="A6.E5.m2.1.1.3.2.3.3">𝑖</ci></apply></apply><apply id="A6.E5.m2.1.1.3.3.cmml" xref="A6.E5.m2.1.1.3.3"><times id="A6.E5.m2.1.1.3.3.1.cmml" xref="A6.E5.m2.1.1.3.3.1"></times><apply id="A6.E5.m2.1.1.3.3.2.cmml" xref="A6.E5.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="A6.E5.m2.1.1.3.3.2.1.cmml" xref="A6.E5.m2.1.1.3.3.2">subscript</csymbol><apply id="A6.E5.m2.1.1.3.3.2.2.cmml" xref="A6.E5.m2.1.1.3.3.2.2"><ci id="A6.E5.m2.1.1.3.3.2.2.1.cmml" xref="A6.E5.m2.1.1.3.3.2.2.1">˙</ci><ci id="A6.E5.m2.1.1.3.3.2.2.2.cmml" xref="A6.E5.m2.1.1.3.3.2.2.2">𝛽</ci></apply><ci id="A6.E5.m2.1.1.3.3.2.3.cmml" xref="A6.E5.m2.1.1.3.3.2.3">𝑡</ci></apply><ci id="A6.E5.m2.1.1.3.3.3.cmml" xref="A6.E5.m2.1.1.3.3.3">italic-ϵ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E5.m2.1c">\displaystyle=\dot{\alpha}_{t}x_{i}+\dot{\beta}_{t}\epsilon</annotation><annotation encoding="application/x-llamapun" id="A6.E5.m2.1d">= over˙ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + over˙ start_ARG italic_β end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ϵ</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
<tbody id="A6.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=x_{i}-\epsilon," class="ltx_Math" display="inline" id="A6.E6.m1.1"><semantics id="A6.E6.m1.1a"><mrow id="A6.E6.m1.1.1.1" xref="A6.E6.m1.1.1.1.1.cmml"><mrow id="A6.E6.m1.1.1.1.1" xref="A6.E6.m1.1.1.1.1.cmml"><mi id="A6.E6.m1.1.1.1.1.2" xref="A6.E6.m1.1.1.1.1.2.cmml"></mi><mo id="A6.E6.m1.1.1.1.1.1" xref="A6.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="A6.E6.m1.1.1.1.1.3" xref="A6.E6.m1.1.1.1.1.3.cmml"><msub id="A6.E6.m1.1.1.1.1.3.2" xref="A6.E6.m1.1.1.1.1.3.2.cmml"><mi id="A6.E6.m1.1.1.1.1.3.2.2" xref="A6.E6.m1.1.1.1.1.3.2.2.cmml">x</mi><mi id="A6.E6.m1.1.1.1.1.3.2.3" xref="A6.E6.m1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="A6.E6.m1.1.1.1.1.3.1" xref="A6.E6.m1.1.1.1.1.3.1.cmml">−</mo><mi id="A6.E6.m1.1.1.1.1.3.3" xref="A6.E6.m1.1.1.1.1.3.3.cmml">ϵ</mi></mrow></mrow><mo id="A6.E6.m1.1.1.1.2" xref="A6.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.E6.m1.1b"><apply id="A6.E6.m1.1.1.1.1.cmml" xref="A6.E6.m1.1.1.1"><eq id="A6.E6.m1.1.1.1.1.1.cmml" xref="A6.E6.m1.1.1.1.1.1"></eq><csymbol cd="latexml" id="A6.E6.m1.1.1.1.1.2.cmml" xref="A6.E6.m1.1.1.1.1.2">absent</csymbol><apply id="A6.E6.m1.1.1.1.1.3.cmml" xref="A6.E6.m1.1.1.1.1.3"><minus id="A6.E6.m1.1.1.1.1.3.1.cmml" xref="A6.E6.m1.1.1.1.1.3.1"></minus><apply id="A6.E6.m1.1.1.1.1.3.2.cmml" xref="A6.E6.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A6.E6.m1.1.1.1.1.3.2.1.cmml" xref="A6.E6.m1.1.1.1.1.3.2">subscript</csymbol><ci id="A6.E6.m1.1.1.1.1.3.2.2.cmml" xref="A6.E6.m1.1.1.1.1.3.2.2">𝑥</ci><ci id="A6.E6.m1.1.1.1.1.3.2.3.cmml" xref="A6.E6.m1.1.1.1.1.3.2.3">𝑖</ci></apply><ci id="A6.E6.m1.1.1.1.1.3.3.cmml" xref="A6.E6.m1.1.1.1.1.3.3">italic-ϵ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E6.m1.1c">\displaystyle=x_{i}-\epsilon,</annotation><annotation encoding="application/x-llamapun" id="A6.E6.m1.1d">= italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_ϵ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p8">
<p class="ltx_p" id="A6.p8.5">where <math alttext="\dot{\alpha}" class="ltx_Math" display="inline" id="A6.p8.1.m1.1"><semantics id="A6.p8.1.m1.1a"><mover accent="true" id="A6.p8.1.m1.1.1" xref="A6.p8.1.m1.1.1.cmml"><mi id="A6.p8.1.m1.1.1.2" xref="A6.p8.1.m1.1.1.2.cmml">α</mi><mo id="A6.p8.1.m1.1.1.1" xref="A6.p8.1.m1.1.1.1.cmml">˙</mo></mover><annotation-xml encoding="MathML-Content" id="A6.p8.1.m1.1b"><apply id="A6.p8.1.m1.1.1.cmml" xref="A6.p8.1.m1.1.1"><ci id="A6.p8.1.m1.1.1.1.cmml" xref="A6.p8.1.m1.1.1.1">˙</ci><ci id="A6.p8.1.m1.1.1.2.cmml" xref="A6.p8.1.m1.1.1.2">𝛼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.1.m1.1c">\dot{\alpha}</annotation><annotation encoding="application/x-llamapun" id="A6.p8.1.m1.1d">over˙ start_ARG italic_α end_ARG</annotation></semantics></math> and <math alttext="\dot{\beta}" class="ltx_Math" display="inline" id="A6.p8.2.m2.1"><semantics id="A6.p8.2.m2.1a"><mover accent="true" id="A6.p8.2.m2.1.1" xref="A6.p8.2.m2.1.1.cmml"><mi id="A6.p8.2.m2.1.1.2" xref="A6.p8.2.m2.1.1.2.cmml">β</mi><mo id="A6.p8.2.m2.1.1.1" xref="A6.p8.2.m2.1.1.1.cmml">˙</mo></mover><annotation-xml encoding="MathML-Content" id="A6.p8.2.m2.1b"><apply id="A6.p8.2.m2.1.1.cmml" xref="A6.p8.2.m2.1.1"><ci id="A6.p8.2.m2.1.1.1.cmml" xref="A6.p8.2.m2.1.1.1">˙</ci><ci id="A6.p8.2.m2.1.1.2.cmml" xref="A6.p8.2.m2.1.1.2">𝛽</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.2.m2.1c">\dot{\beta}</annotation><annotation encoding="application/x-llamapun" id="A6.p8.2.m2.1d">over˙ start_ARG italic_β end_ARG</annotation></semantics></math> denote the time derivatives of <math alttext="\alpha" class="ltx_Math" display="inline" id="A6.p8.3.m3.1"><semantics id="A6.p8.3.m3.1a"><mi id="A6.p8.3.m3.1.1" xref="A6.p8.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A6.p8.3.m3.1b"><ci id="A6.p8.3.m3.1.1.cmml" xref="A6.p8.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A6.p8.3.m3.1d">italic_α</annotation></semantics></math> and <math alttext="\beta" class="ltx_Math" display="inline" id="A6.p8.4.m4.1"><semantics id="A6.p8.4.m4.1a"><mi id="A6.p8.4.m4.1.1" xref="A6.p8.4.m4.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="A6.p8.4.m4.1b"><ci id="A6.p8.4.m4.1.1.cmml" xref="A6.p8.4.m4.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.4.m4.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="A6.p8.4.m4.1d">italic_β</annotation></semantics></math>. This time-dependent velocity field <math alttext="v:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}^{d}" class="ltx_Math" display="inline" id="A6.p8.5.m5.2"><semantics id="A6.p8.5.m5.2a"><mrow id="A6.p8.5.m5.2.3" xref="A6.p8.5.m5.2.3.cmml"><mi id="A6.p8.5.m5.2.3.2" xref="A6.p8.5.m5.2.3.2.cmml">v</mi><mo id="A6.p8.5.m5.2.3.1" lspace="0.278em" rspace="0.278em" xref="A6.p8.5.m5.2.3.1.cmml">:</mo><mrow id="A6.p8.5.m5.2.3.3" xref="A6.p8.5.m5.2.3.3.cmml"><mrow id="A6.p8.5.m5.2.3.3.2" xref="A6.p8.5.m5.2.3.3.2.cmml"><mrow id="A6.p8.5.m5.2.3.3.2.2.2" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml"><mo id="A6.p8.5.m5.2.3.3.2.2.2.1" stretchy="false" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml">[</mo><mn id="A6.p8.5.m5.1.1" xref="A6.p8.5.m5.1.1.cmml">0</mn><mo id="A6.p8.5.m5.2.3.3.2.2.2.2" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml">,</mo><mn id="A6.p8.5.m5.2.2" xref="A6.p8.5.m5.2.2.cmml">1</mn><mo id="A6.p8.5.m5.2.3.3.2.2.2.3" rspace="0.055em" stretchy="false" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml">]</mo></mrow><mo id="A6.p8.5.m5.2.3.3.2.1" rspace="0.222em" xref="A6.p8.5.m5.2.3.3.2.1.cmml">×</mo><msup id="A6.p8.5.m5.2.3.3.2.3" xref="A6.p8.5.m5.2.3.3.2.3.cmml"><mi id="A6.p8.5.m5.2.3.3.2.3.2" xref="A6.p8.5.m5.2.3.3.2.3.2.cmml">ℝ</mi><mi id="A6.p8.5.m5.2.3.3.2.3.3" xref="A6.p8.5.m5.2.3.3.2.3.3.cmml">d</mi></msup></mrow><mo id="A6.p8.5.m5.2.3.3.1" stretchy="false" xref="A6.p8.5.m5.2.3.3.1.cmml">→</mo><msup id="A6.p8.5.m5.2.3.3.3" xref="A6.p8.5.m5.2.3.3.3.cmml"><mi id="A6.p8.5.m5.2.3.3.3.2" xref="A6.p8.5.m5.2.3.3.3.2.cmml">ℝ</mi><mi id="A6.p8.5.m5.2.3.3.3.3" xref="A6.p8.5.m5.2.3.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p8.5.m5.2b"><apply id="A6.p8.5.m5.2.3.cmml" xref="A6.p8.5.m5.2.3"><ci id="A6.p8.5.m5.2.3.1.cmml" xref="A6.p8.5.m5.2.3.1">:</ci><ci id="A6.p8.5.m5.2.3.2.cmml" xref="A6.p8.5.m5.2.3.2">𝑣</ci><apply id="A6.p8.5.m5.2.3.3.cmml" xref="A6.p8.5.m5.2.3.3"><ci id="A6.p8.5.m5.2.3.3.1.cmml" xref="A6.p8.5.m5.2.3.3.1">→</ci><apply id="A6.p8.5.m5.2.3.3.2.cmml" xref="A6.p8.5.m5.2.3.3.2"><times id="A6.p8.5.m5.2.3.3.2.1.cmml" xref="A6.p8.5.m5.2.3.3.2.1"></times><interval closure="closed" id="A6.p8.5.m5.2.3.3.2.2.1.cmml" xref="A6.p8.5.m5.2.3.3.2.2.2"><cn id="A6.p8.5.m5.1.1.cmml" type="integer" xref="A6.p8.5.m5.1.1">0</cn><cn id="A6.p8.5.m5.2.2.cmml" type="integer" xref="A6.p8.5.m5.2.2">1</cn></interval><apply id="A6.p8.5.m5.2.3.3.2.3.cmml" xref="A6.p8.5.m5.2.3.3.2.3"><csymbol cd="ambiguous" id="A6.p8.5.m5.2.3.3.2.3.1.cmml" xref="A6.p8.5.m5.2.3.3.2.3">superscript</csymbol><ci id="A6.p8.5.m5.2.3.3.2.3.2.cmml" xref="A6.p8.5.m5.2.3.3.2.3.2">ℝ</ci><ci id="A6.p8.5.m5.2.3.3.2.3.3.cmml" xref="A6.p8.5.m5.2.3.3.2.3.3">𝑑</ci></apply></apply><apply id="A6.p8.5.m5.2.3.3.3.cmml" xref="A6.p8.5.m5.2.3.3.3"><csymbol cd="ambiguous" id="A6.p8.5.m5.2.3.3.3.1.cmml" xref="A6.p8.5.m5.2.3.3.3">superscript</csymbol><ci id="A6.p8.5.m5.2.3.3.3.2.cmml" xref="A6.p8.5.m5.2.3.3.3.2">ℝ</ci><ci id="A6.p8.5.m5.2.3.3.3.3.cmml" xref="A6.p8.5.m5.2.3.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.5.m5.2c">v:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="A6.p8.5.m5.2d">italic_v : [ 0 , 1 ] × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> defines an ordinary differential equation known as the Flow ODE:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p9">
<table class="ltx_equation ltx_eqn_table" id="A6.Ex8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="dx_{i}=v_{t}(x_{i}^{t})dt." class="ltx_Math" display="block" id="A6.Ex8.m1.1"><semantics id="A6.Ex8.m1.1a"><mrow id="A6.Ex8.m1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.cmml"><mrow id="A6.Ex8.m1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.cmml"><mrow id="A6.Ex8.m1.1.1.1.1.3" xref="A6.Ex8.m1.1.1.1.1.3.cmml"><mi id="A6.Ex8.m1.1.1.1.1.3.2" xref="A6.Ex8.m1.1.1.1.1.3.2.cmml">d</mi><mo id="A6.Ex8.m1.1.1.1.1.3.1" xref="A6.Ex8.m1.1.1.1.1.3.1.cmml">⁢</mo><msub id="A6.Ex8.m1.1.1.1.1.3.3" xref="A6.Ex8.m1.1.1.1.1.3.3.cmml"><mi id="A6.Ex8.m1.1.1.1.1.3.3.2" xref="A6.Ex8.m1.1.1.1.1.3.3.2.cmml">x</mi><mi id="A6.Ex8.m1.1.1.1.1.3.3.3" xref="A6.Ex8.m1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="A6.Ex8.m1.1.1.1.1.2" xref="A6.Ex8.m1.1.1.1.1.2.cmml">=</mo><mrow id="A6.Ex8.m1.1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.1.cmml"><msub id="A6.Ex8.m1.1.1.1.1.1.3" xref="A6.Ex8.m1.1.1.1.1.1.3.cmml"><mi id="A6.Ex8.m1.1.1.1.1.1.3.2" xref="A6.Ex8.m1.1.1.1.1.1.3.2.cmml">v</mi><mi id="A6.Ex8.m1.1.1.1.1.1.3.3" xref="A6.Ex8.m1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="A6.Ex8.m1.1.1.1.1.1.2" xref="A6.Ex8.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A6.Ex8.m1.1.1.1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml"><mo id="A6.Ex8.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="A6.Ex8.m1.1.1.1.1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml"><mi id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="A6.Ex8.m1.1.1.1.1.1.1.1.1.3" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.Ex8.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A6.Ex8.m1.1.1.1.1.1.2a" xref="A6.Ex8.m1.1.1.1.1.1.2.cmml">⁢</mo><mi id="A6.Ex8.m1.1.1.1.1.1.4" xref="A6.Ex8.m1.1.1.1.1.1.4.cmml">d</mi><mo id="A6.Ex8.m1.1.1.1.1.1.2b" xref="A6.Ex8.m1.1.1.1.1.1.2.cmml">⁢</mo><mi id="A6.Ex8.m1.1.1.1.1.1.5" xref="A6.Ex8.m1.1.1.1.1.1.5.cmml">t</mi></mrow></mrow><mo id="A6.Ex8.m1.1.1.1.2" lspace="0em" xref="A6.Ex8.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex8.m1.1b"><apply id="A6.Ex8.m1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1"><eq id="A6.Ex8.m1.1.1.1.1.2.cmml" xref="A6.Ex8.m1.1.1.1.1.2"></eq><apply id="A6.Ex8.m1.1.1.1.1.3.cmml" xref="A6.Ex8.m1.1.1.1.1.3"><times id="A6.Ex8.m1.1.1.1.1.3.1.cmml" xref="A6.Ex8.m1.1.1.1.1.3.1"></times><ci id="A6.Ex8.m1.1.1.1.1.3.2.cmml" xref="A6.Ex8.m1.1.1.1.1.3.2">𝑑</ci><apply id="A6.Ex8.m1.1.1.1.1.3.3.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.3.3.1.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.Ex8.m1.1.1.1.1.3.3.2.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3.2">𝑥</ci><ci id="A6.Ex8.m1.1.1.1.1.3.3.3.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3.3">𝑖</ci></apply></apply><apply id="A6.Ex8.m1.1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1"><times id="A6.Ex8.m1.1.1.1.1.1.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.2"></times><apply id="A6.Ex8.m1.1.1.1.1.1.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.1.3.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3">subscript</csymbol><ci id="A6.Ex8.m1.1.1.1.1.1.3.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3.2">𝑣</ci><ci id="A6.Ex8.m1.1.1.1.1.1.3.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="A6.Ex8.m1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="A6.Ex8.m1.1.1.1.1.1.4.cmml" xref="A6.Ex8.m1.1.1.1.1.1.4">𝑑</ci><ci id="A6.Ex8.m1.1.1.1.1.1.5.cmml" xref="A6.Ex8.m1.1.1.1.1.1.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex8.m1.1c">dx_{i}=v_{t}(x_{i}^{t})dt.</annotation><annotation encoding="application/x-llamapun" id="A6.Ex8.m1.1d">italic_d italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) italic_d italic_t .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p10">
<p class="ltx_p" id="A6.p10.5">We use <math alttext="\phi_{t}(x_{i})" class="ltx_Math" display="inline" id="A6.p10.1.m1.1"><semantics id="A6.p10.1.m1.1a"><mrow id="A6.p10.1.m1.1.1" xref="A6.p10.1.m1.1.1.cmml"><msub id="A6.p10.1.m1.1.1.3" xref="A6.p10.1.m1.1.1.3.cmml"><mi id="A6.p10.1.m1.1.1.3.2" xref="A6.p10.1.m1.1.1.3.2.cmml">ϕ</mi><mi id="A6.p10.1.m1.1.1.3.3" xref="A6.p10.1.m1.1.1.3.3.cmml">t</mi></msub><mo id="A6.p10.1.m1.1.1.2" xref="A6.p10.1.m1.1.1.2.cmml">⁢</mo><mrow id="A6.p10.1.m1.1.1.1.1" xref="A6.p10.1.m1.1.1.1.1.1.cmml"><mo id="A6.p10.1.m1.1.1.1.1.2" stretchy="false" xref="A6.p10.1.m1.1.1.1.1.1.cmml">(</mo><msub id="A6.p10.1.m1.1.1.1.1.1" xref="A6.p10.1.m1.1.1.1.1.1.cmml"><mi id="A6.p10.1.m1.1.1.1.1.1.2" xref="A6.p10.1.m1.1.1.1.1.1.2.cmml">x</mi><mi id="A6.p10.1.m1.1.1.1.1.1.3" xref="A6.p10.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A6.p10.1.m1.1.1.1.1.3" stretchy="false" xref="A6.p10.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.1.m1.1b"><apply id="A6.p10.1.m1.1.1.cmml" xref="A6.p10.1.m1.1.1"><times id="A6.p10.1.m1.1.1.2.cmml" xref="A6.p10.1.m1.1.1.2"></times><apply id="A6.p10.1.m1.1.1.3.cmml" xref="A6.p10.1.m1.1.1.3"><csymbol cd="ambiguous" id="A6.p10.1.m1.1.1.3.1.cmml" xref="A6.p10.1.m1.1.1.3">subscript</csymbol><ci id="A6.p10.1.m1.1.1.3.2.cmml" xref="A6.p10.1.m1.1.1.3.2">italic-ϕ</ci><ci id="A6.p10.1.m1.1.1.3.3.cmml" xref="A6.p10.1.m1.1.1.3.3">𝑡</ci></apply><apply id="A6.p10.1.m1.1.1.1.1.1.cmml" xref="A6.p10.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A6.p10.1.m1.1.1.1.1.1.1.cmml" xref="A6.p10.1.m1.1.1.1.1">subscript</csymbol><ci id="A6.p10.1.m1.1.1.1.1.1.2.cmml" xref="A6.p10.1.m1.1.1.1.1.1.2">𝑥</ci><ci id="A6.p10.1.m1.1.1.1.1.1.3.cmml" xref="A6.p10.1.m1.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.1.m1.1c">\phi_{t}(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A6.p10.1.m1.1d">italic_ϕ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> to represent the solution of the Flow ODE with the initial condition <math alttext="\phi_{0}(x_{i})=x_{i}" class="ltx_Math" display="inline" id="A6.p10.2.m2.1"><semantics id="A6.p10.2.m2.1a"><mrow id="A6.p10.2.m2.1.1" xref="A6.p10.2.m2.1.1.cmml"><mrow id="A6.p10.2.m2.1.1.1" xref="A6.p10.2.m2.1.1.1.cmml"><msub id="A6.p10.2.m2.1.1.1.3" xref="A6.p10.2.m2.1.1.1.3.cmml"><mi id="A6.p10.2.m2.1.1.1.3.2" xref="A6.p10.2.m2.1.1.1.3.2.cmml">ϕ</mi><mn id="A6.p10.2.m2.1.1.1.3.3" xref="A6.p10.2.m2.1.1.1.3.3.cmml">0</mn></msub><mo id="A6.p10.2.m2.1.1.1.2" xref="A6.p10.2.m2.1.1.1.2.cmml">⁢</mo><mrow id="A6.p10.2.m2.1.1.1.1.1" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml"><mo id="A6.p10.2.m2.1.1.1.1.1.2" stretchy="false" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="A6.p10.2.m2.1.1.1.1.1.1" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml"><mi id="A6.p10.2.m2.1.1.1.1.1.1.2" xref="A6.p10.2.m2.1.1.1.1.1.1.2.cmml">x</mi><mi id="A6.p10.2.m2.1.1.1.1.1.1.3" xref="A6.p10.2.m2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A6.p10.2.m2.1.1.1.1.1.3" stretchy="false" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A6.p10.2.m2.1.1.2" xref="A6.p10.2.m2.1.1.2.cmml">=</mo><msub id="A6.p10.2.m2.1.1.3" xref="A6.p10.2.m2.1.1.3.cmml"><mi id="A6.p10.2.m2.1.1.3.2" xref="A6.p10.2.m2.1.1.3.2.cmml">x</mi><mi id="A6.p10.2.m2.1.1.3.3" xref="A6.p10.2.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.2.m2.1b"><apply id="A6.p10.2.m2.1.1.cmml" xref="A6.p10.2.m2.1.1"><eq id="A6.p10.2.m2.1.1.2.cmml" xref="A6.p10.2.m2.1.1.2"></eq><apply id="A6.p10.2.m2.1.1.1.cmml" xref="A6.p10.2.m2.1.1.1"><times id="A6.p10.2.m2.1.1.1.2.cmml" xref="A6.p10.2.m2.1.1.1.2"></times><apply id="A6.p10.2.m2.1.1.1.3.cmml" xref="A6.p10.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="A6.p10.2.m2.1.1.1.3.1.cmml" xref="A6.p10.2.m2.1.1.1.3">subscript</csymbol><ci id="A6.p10.2.m2.1.1.1.3.2.cmml" xref="A6.p10.2.m2.1.1.1.3.2">italic-ϕ</ci><cn id="A6.p10.2.m2.1.1.1.3.3.cmml" type="integer" xref="A6.p10.2.m2.1.1.1.3.3">0</cn></apply><apply id="A6.p10.2.m2.1.1.1.1.1.1.cmml" xref="A6.p10.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.p10.2.m2.1.1.1.1.1.1.1.cmml" xref="A6.p10.2.m2.1.1.1.1.1">subscript</csymbol><ci id="A6.p10.2.m2.1.1.1.1.1.1.2.cmml" xref="A6.p10.2.m2.1.1.1.1.1.1.2">𝑥</ci><ci id="A6.p10.2.m2.1.1.1.1.1.1.3.cmml" xref="A6.p10.2.m2.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="A6.p10.2.m2.1.1.3.cmml" xref="A6.p10.2.m2.1.1.3"><csymbol cd="ambiguous" id="A6.p10.2.m2.1.1.3.1.cmml" xref="A6.p10.2.m2.1.1.3">subscript</csymbol><ci id="A6.p10.2.m2.1.1.3.2.cmml" xref="A6.p10.2.m2.1.1.3.2">𝑥</ci><ci id="A6.p10.2.m2.1.1.3.3.cmml" xref="A6.p10.2.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.2.m2.1c">\phi_{0}(x_{i})=x_{i}</annotation><annotation encoding="application/x-llamapun" id="A6.p10.2.m2.1d">italic_ϕ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
By solving this Flow ODE from <math alttext="t=0" class="ltx_Math" display="inline" id="A6.p10.3.m3.1"><semantics id="A6.p10.3.m3.1a"><mrow id="A6.p10.3.m3.1.1" xref="A6.p10.3.m3.1.1.cmml"><mi id="A6.p10.3.m3.1.1.2" xref="A6.p10.3.m3.1.1.2.cmml">t</mi><mo id="A6.p10.3.m3.1.1.1" xref="A6.p10.3.m3.1.1.1.cmml">=</mo><mn id="A6.p10.3.m3.1.1.3" xref="A6.p10.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.3.m3.1b"><apply id="A6.p10.3.m3.1.1.cmml" xref="A6.p10.3.m3.1.1"><eq id="A6.p10.3.m3.1.1.1.cmml" xref="A6.p10.3.m3.1.1.1"></eq><ci id="A6.p10.3.m3.1.1.2.cmml" xref="A6.p10.3.m3.1.1.2">𝑡</ci><cn id="A6.p10.3.m3.1.1.3.cmml" type="integer" xref="A6.p10.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.3.m3.1c">t=0</annotation><annotation encoding="application/x-llamapun" id="A6.p10.3.m3.1d">italic_t = 0</annotation></semantics></math> to <math alttext="t=1" class="ltx_Math" display="inline" id="A6.p10.4.m4.1"><semantics id="A6.p10.4.m4.1a"><mrow id="A6.p10.4.m4.1.1" xref="A6.p10.4.m4.1.1.cmml"><mi id="A6.p10.4.m4.1.1.2" xref="A6.p10.4.m4.1.1.2.cmml">t</mi><mo id="A6.p10.4.m4.1.1.1" xref="A6.p10.4.m4.1.1.1.cmml">=</mo><mn id="A6.p10.4.m4.1.1.3" xref="A6.p10.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.4.m4.1b"><apply id="A6.p10.4.m4.1.1.cmml" xref="A6.p10.4.m4.1.1"><eq id="A6.p10.4.m4.1.1.1.cmml" xref="A6.p10.4.m4.1.1.1"></eq><ci id="A6.p10.4.m4.1.1.2.cmml" xref="A6.p10.4.m4.1.1.2">𝑡</ci><cn id="A6.p10.4.m4.1.1.3.cmml" type="integer" xref="A6.p10.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.4.m4.1c">t=1</annotation><annotation encoding="application/x-llamapun" id="A6.p10.4.m4.1d">italic_t = 1</annotation></semantics></math>, we transform noise into data samples using the approximated velocity fields <math alttext="v_{\theta}(x_{i}^{t},t)" class="ltx_Math" display="inline" id="A6.p10.5.m5.2"><semantics id="A6.p10.5.m5.2a"><mrow id="A6.p10.5.m5.2.2" xref="A6.p10.5.m5.2.2.cmml"><msub id="A6.p10.5.m5.2.2.3" xref="A6.p10.5.m5.2.2.3.cmml"><mi id="A6.p10.5.m5.2.2.3.2" xref="A6.p10.5.m5.2.2.3.2.cmml">v</mi><mi id="A6.p10.5.m5.2.2.3.3" xref="A6.p10.5.m5.2.2.3.3.cmml">θ</mi></msub><mo id="A6.p10.5.m5.2.2.2" xref="A6.p10.5.m5.2.2.2.cmml">⁢</mo><mrow id="A6.p10.5.m5.2.2.1.1" xref="A6.p10.5.m5.2.2.1.2.cmml"><mo id="A6.p10.5.m5.2.2.1.1.2" stretchy="false" xref="A6.p10.5.m5.2.2.1.2.cmml">(</mo><msubsup id="A6.p10.5.m5.2.2.1.1.1" xref="A6.p10.5.m5.2.2.1.1.1.cmml"><mi id="A6.p10.5.m5.2.2.1.1.1.2.2" xref="A6.p10.5.m5.2.2.1.1.1.2.2.cmml">x</mi><mi id="A6.p10.5.m5.2.2.1.1.1.2.3" xref="A6.p10.5.m5.2.2.1.1.1.2.3.cmml">i</mi><mi id="A6.p10.5.m5.2.2.1.1.1.3" xref="A6.p10.5.m5.2.2.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.p10.5.m5.2.2.1.1.3" xref="A6.p10.5.m5.2.2.1.2.cmml">,</mo><mi id="A6.p10.5.m5.1.1" xref="A6.p10.5.m5.1.1.cmml">t</mi><mo id="A6.p10.5.m5.2.2.1.1.4" stretchy="false" xref="A6.p10.5.m5.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.5.m5.2b"><apply id="A6.p10.5.m5.2.2.cmml" xref="A6.p10.5.m5.2.2"><times id="A6.p10.5.m5.2.2.2.cmml" xref="A6.p10.5.m5.2.2.2"></times><apply id="A6.p10.5.m5.2.2.3.cmml" xref="A6.p10.5.m5.2.2.3"><csymbol cd="ambiguous" id="A6.p10.5.m5.2.2.3.1.cmml" xref="A6.p10.5.m5.2.2.3">subscript</csymbol><ci id="A6.p10.5.m5.2.2.3.2.cmml" xref="A6.p10.5.m5.2.2.3.2">𝑣</ci><ci id="A6.p10.5.m5.2.2.3.3.cmml" xref="A6.p10.5.m5.2.2.3.3">𝜃</ci></apply><interval closure="open" id="A6.p10.5.m5.2.2.1.2.cmml" xref="A6.p10.5.m5.2.2.1.1"><apply id="A6.p10.5.m5.2.2.1.1.1.cmml" xref="A6.p10.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="A6.p10.5.m5.2.2.1.1.1.1.cmml" xref="A6.p10.5.m5.2.2.1.1.1">superscript</csymbol><apply id="A6.p10.5.m5.2.2.1.1.1.2.cmml" xref="A6.p10.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="A6.p10.5.m5.2.2.1.1.1.2.1.cmml" xref="A6.p10.5.m5.2.2.1.1.1">subscript</csymbol><ci id="A6.p10.5.m5.2.2.1.1.1.2.2.cmml" xref="A6.p10.5.m5.2.2.1.1.1.2.2">𝑥</ci><ci id="A6.p10.5.m5.2.2.1.1.1.2.3.cmml" xref="A6.p10.5.m5.2.2.1.1.1.2.3">𝑖</ci></apply><ci id="A6.p10.5.m5.2.2.1.1.1.3.cmml" xref="A6.p10.5.m5.2.2.1.1.1.3">𝑡</ci></apply><ci id="A6.p10.5.m5.1.1.cmml" xref="A6.p10.5.m5.1.1">𝑡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.5.m5.2c">v_{\theta}(x_{i}^{t},t)</annotation><annotation encoding="application/x-llamapun" id="A6.p10.5.m5.2d">italic_v start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , italic_t )</annotation></semantics></math>. During training, the flow-matching objective directly regresses to the target velocity:</p>
<table class="ltx_equation ltx_eqn_table" id="A6.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{v}=\int_{0}^{1}\mathbb{E}\left[\parallel v_{\theta}(x_{i}^{t},t)-%
\dot{\alpha}_{t}x_{i}-\dot{\beta}_{t}\epsilon\parallel^{2}\right]dt," class="ltx_Math" display="block" id="A6.E7.m1.2"><semantics id="A6.E7.m1.2a"><mrow id="A6.E7.m1.2.2.1" xref="A6.E7.m1.2.2.1.1.cmml"><mrow id="A6.E7.m1.2.2.1.1" xref="A6.E7.m1.2.2.1.1.cmml"><msub id="A6.E7.m1.2.2.1.1.3" xref="A6.E7.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A6.E7.m1.2.2.1.1.3.2" xref="A6.E7.m1.2.2.1.1.3.2.cmml">ℒ</mi><mi id="A6.E7.m1.2.2.1.1.3.3" xref="A6.E7.m1.2.2.1.1.3.3.cmml">v</mi></msub><mo id="A6.E7.m1.2.2.1.1.2" rspace="0.111em" xref="A6.E7.m1.2.2.1.1.2.cmml">=</mo><mrow id="A6.E7.m1.2.2.1.1.1" xref="A6.E7.m1.2.2.1.1.1.cmml"><msubsup id="A6.E7.m1.2.2.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.2.2.2" xref="A6.E7.m1.2.2.1.1.1.2.2.2.cmml">∫</mo><mn id="A6.E7.m1.2.2.1.1.1.2.2.3" xref="A6.E7.m1.2.2.1.1.1.2.2.3.cmml">0</mn><mn id="A6.E7.m1.2.2.1.1.1.2.3" xref="A6.E7.m1.2.2.1.1.1.2.3.cmml">1</mn></msubsup><mrow id="A6.E7.m1.2.2.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.3.cmml">𝔼</mi><mo id="A6.E7.m1.2.2.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.2.cmml">⁢</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.1.2.1.cmml">[</mo><msup id="A6.E7.m1.2.2.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">v</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msubsup id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="A6.E7.m1.1.1" xref="A6.E7.m1.1.1.cmml">t</mi><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.4" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mover accent="true" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml">α</mi><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml">˙</mo></mover><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">t</mi></msub><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">x</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2a" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.cmml"><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.cmml"><mover accent="true" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2.cmml">β</mi><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1.cmml">˙</mo></mover><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3.cmml">t</mi></msub><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1.cmml">⁢</mo><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3.cmml">ϵ</mi></mrow></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="A6.E7.m1.2.2.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.2.1.cmml">]</mo></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.2a" lspace="0em" xref="A6.E7.m1.2.2.1.1.1.1.2.cmml">⁢</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.4" xref="A6.E7.m1.2.2.1.1.1.1.4.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.4.1" rspace="0em" xref="A6.E7.m1.2.2.1.1.1.1.4.1.cmml">𝑑</mo><mi id="A6.E7.m1.2.2.1.1.1.1.4.2" xref="A6.E7.m1.2.2.1.1.1.1.4.2.cmml">t</mi></mrow></mrow></mrow></mrow><mo id="A6.E7.m1.2.2.1.2" xref="A6.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.E7.m1.2b"><apply id="A6.E7.m1.2.2.1.1.cmml" xref="A6.E7.m1.2.2.1"><eq id="A6.E7.m1.2.2.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.2"></eq><apply id="A6.E7.m1.2.2.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.3.1.cmml" xref="A6.E7.m1.2.2.1.1.3">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.3.2.cmml" xref="A6.E7.m1.2.2.1.1.3.2">ℒ</ci><ci id="A6.E7.m1.2.2.1.1.3.3.cmml" xref="A6.E7.m1.2.2.1.1.3.3">𝑣</ci></apply><apply id="A6.E7.m1.2.2.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1"><apply id="A6.E7.m1.2.2.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.2">superscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.2.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.2">subscript</csymbol><int id="A6.E7.m1.2.2.1.1.1.2.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.2.2.2"></int><cn id="A6.E7.m1.2.2.1.1.1.2.2.3.cmml" type="integer" xref="A6.E7.m1.2.2.1.1.1.2.2.3">0</cn></apply><cn id="A6.E7.m1.2.2.1.1.1.2.3.cmml" type="integer" xref="A6.E7.m1.2.2.1.1.1.2.3">1</cn></apply><apply id="A6.E7.m1.2.2.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1"><times id="A6.E7.m1.2.2.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.2"></times><ci id="A6.E7.m1.2.2.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.3">𝔼</ci><apply id="A6.E7.m1.2.2.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="A6.E7.m1.2.2.1.1.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1"><minus id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"></minus><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><times id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2">𝑣</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><interval closure="open" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="A6.E7.m1.1.1.cmml" xref="A6.E7.m1.1.1">𝑡</ci></interval></apply><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><times id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1"></times><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2"><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1">˙</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2">𝛼</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑡</ci></apply><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2">𝑥</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4"><times id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1"></times><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2">subscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2"><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1">˙</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2">𝛽</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3">𝑡</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3">italic-ϵ</ci></apply></apply></apply><cn id="A6.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.3">2</cn></apply></apply><apply id="A6.E7.m1.2.2.1.1.1.1.4.cmml" xref="A6.E7.m1.2.2.1.1.1.1.4"><csymbol cd="latexml" id="A6.E7.m1.2.2.1.1.1.1.4.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.4.1">differential-d</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.4.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.4.2">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E7.m1.2c">\mathcal{L}_{v}=\int_{0}^{1}\mathbb{E}\left[\parallel v_{\theta}(x_{i}^{t},t)-%
\dot{\alpha}_{t}x_{i}-\dot{\beta}_{t}\epsilon\parallel^{2}\right]dt,</annotation><annotation encoding="application/x-llamapun" id="A6.E7.m1.2d">caligraphic_L start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT = ∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT blackboard_E [ ∥ italic_v start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , italic_t ) - over˙ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - over˙ start_ARG italic_β end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_ϵ ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] italic_d italic_t ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A6.p10.6">which is termed the Conditional Flow Matching loss <cite class="ltx_cite ltx_citemacro_citep">(Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>, sharing similarities with the noise prediction or score prediction losses in diffusion models.</p>
</div>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis of flow matching loss</h4>
<figure class="ltx_figure" id="A6.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="460" id="A6.F9.g1" src="x20.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Comparison between flow matching loss in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.E7" title="In Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a> and diffusion loss in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E4" title="In 3.3 Diffusion Learning with a Denoising MLP ‣ 3 Methodology ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> on FID.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p1.1">We experimented to evaluate the performance of flow matching loss using the D-JEPA-B model on the ImageNet1k dataset for image generation, training the model for 300 epochs. The experimental settings were consistent with those described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4" title="4 Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a>. The FID convergence curve is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.F9" title="Figure 9 ‣ Analysis of flow matching loss ‣ Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">9</span></a>. As anticipated, the flow matching loss demonstrated a faster convergence rate than the diffusion loss, achieving convergence within approximately 160 epochs.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p2.1">However, it was observed that the flow matching loss encounters difficulties in reducing the FID score during the later stages of training. We hypothesize that this limitation may be attributed to the denoising MLP being too lightweight to manage the continuous-space denoising operations required by flow matching efficiently. This issue can potentially be alleviated by increasing the network capacity of the denoising MLP. Despite this, the images generated using flow matching loss exhibit superior texture quality.</p>
</div>
<figure class="ltx_figure" id="A6.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="124" id="A6.F10.sf1.g1" src="x21.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Diffusion loss</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="124" id="A6.F10.sf2.g1" src="x22.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Flow matching loss</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Failure cases of diffusion loss in video clip generation. The samples are generated using the D-JEPA-L model trained for 1600 epochs on UCF101 dataset, with 225 auto-regressive steps for sampling 3000 tokens.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p3.1">As illustrated in App. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7" title="Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">G</span></a>, the flow matching loss significantly outperforms the diffusion loss for more challenging tasks. In specific scenarios, the diffusion loss may even lead to training failures, as depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.F10" title="Figure 10 ‣ Analysis of flow matching loss ‣ Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">10</span></a>. Consequently, we adopt the flow-matching loss for the remainder of this paper.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Comprehensive Experiments</h2>
<div class="ltx_para ltx_noindent" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">This section presents detailed experimental procedures and results for D-JEPA across various tasks. It is important to emphasize that <span class="ltx_text ltx_font_italic" id="A7.p1.1.1">our objective is not to achieve state-of-the-art performance on these tasks, as this is beyond the scope of the current study and will be explored in future research.</span> Instead, we aim to demonstrate that D-JEPA is a robust and versatile generative model capable of handling various continuous data types. Consequently, we did not perform extensive hyperparameter tuning; unless otherwise specified, all training settings are consistent with those used for image generation on ImageNet. As noted in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">F</span></a>, we employ flow matching loss instead of diffusion loss for all experiments in this section.</p>
</div>
<section class="ltx_subsection" id="A7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Text-to-Audio Generation</h3>
<figure class="ltx_figure" id="A7.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1067" id="A7.F11.g1" src="x23.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Visualizations of the generated waveform over training epochs. From top to bottom, each waveform represents the result sampled every 400 epochs. The corresponding text of the generated speech samples is “<span class="ltx_text ltx_font_italic" id="A7.F11.2.1">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition</span>.”</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS1.p1">
<p class="ltx_p" id="A7.SS1.p1.1">In this experiment, we adapted D-JEPA-B for speech synthesis, incorporating a phoneme and pitch encoder. To integrate text conditions, we replaced the attention module in the vision transformer with multimodal attention, as first proposed by  <cite class="ltx_cite ltx_citemacro_cite">Esser et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib32" title="">2024</a>)</cite>. The phoneme vocabulary size is set to 73. For the pitch encoder, the lookup table size is set to 300, and the encoded pitch embedding size is 256, with a hidden channel size of 256.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS1.p2">
<p class="ltx_p" id="A7.SS1.p2.1">We utilized the LJSpeech benchmark dataset <cite class="ltx_cite ltx_citemacro_citep">(Ito, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib51" title="">2017</a>)</cite>, which consists of 13,100 audio clips sampled at 22,050 Hz from a female speaker, totaling approximately 24 hours. Text sequences were converted into phoneme sequences using an open-source grapheme-to-phoneme conversion tool <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib100" title="">2019</a>)</cite>. Following common practices <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib19" title="">2021a</a>; Min et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib73" title="">2021</a>; Zhuo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite>, we preprocessed the speech and text data by (1) extracting the spectrogram with an FFT size of 1024, hop size of 256, and window size of 1024 samples; (2) converting it to a mel-spectrogram with 80 frequency bins; and (3) extracting the F0 (fundamental frequency) from the raw waveform using Parselmouth. Our implementation is based on the open-source project by  <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib49" title="">2023a</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS1.p3">
<p class="ltx_p" id="A7.SS1.p3.1">Notably, the diffusion loss did not perform optimally on this small-scale dataset. To better accommodate the varying lengths of sentences, we employed 1D Rotary Position Embedding (RoPE) <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib99" title="">2024</a>)</cite> as the positional embedding. D-JEPA-B was trained for 134,000 steps, approximately 2,600 epochs, using 4 NVIDIA A100 GPUs with a total batch size of 256 sentences. HiFi-GAN <cite class="ltx_cite ltx_citemacro_citep">(Kong et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib59" title="">2020</a>)</cite> (V1) was utilized as the vocoder to synthesize the waveform from the generated mel-spectrogram.</p>
</div>
<section class="ltx_paragraph" id="A7.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<figure class="ltx_figure" id="A7.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A7.F12.g1" src="x24.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Visualizations of the reference and generated waveform. The corresponding texts of generated speech samples is “<span class="ltx_text ltx_font_italic" id="A7.F12.2.1">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition</span>”.</figcaption>
</figure>
<figure class="ltx_figure" id="A7.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="711" id="A7.F13.g1" src="x25.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Visualizations of the reference and generated mel-spectrograms. The corresponding texts of generated speech samples is “<span class="ltx_text ltx_font_italic" id="A7.F13.2.1">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition</span>”.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS1.SSS0.Px1.p1.1">In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F11" title="Figure 11 ‣ G.1 Text-to-Audio Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">11</span></a>, we demonstrate the sampling results of the trained model at intervals of 400 epochs. We observed that after 1,600 epochs, D-JEPA-B can generate relatively clear audio. As training proceeded, the speech quality steadily improved, with pronunciations becoming clearer and the intonation and pauses closely matching those of natural speech. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F13" title="Figure 13 ‣ Analysis ‣ G.1 Text-to-Audio Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">13</span></a> and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F12" title="Figure 12 ‣ Analysis ‣ G.1 Text-to-Audio Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">12</span></a> show sampled mel-spectrogram and waveform, respectively. It is evident that after 2,600 epochs of training, the sampled audio closely resembles the reference audio.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>Text-to-Image Generation</h3>
<div class="ltx_para ltx_noindent" id="A7.SS2.p1">
<p class="ltx_p" id="A7.SS2.p1.2">In this experiment, we adapted D-JEPA-L for the task of text-to-image generation. Similar to previous experiments, we incorporated text conditions using multimodal attention. Additionally, we utilized a more powerful VAE model from  <cite class="ltx_cite ltx_citemacro_cite">Esser et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib32" title="">2024</a>)</cite>. A <math alttext="256\times 256" class="ltx_Math" display="inline" id="A7.SS2.p1.1.m1.1"><semantics id="A7.SS2.p1.1.m1.1a"><mrow id="A7.SS2.p1.1.m1.1.1" xref="A7.SS2.p1.1.m1.1.1.cmml"><mn id="A7.SS2.p1.1.m1.1.1.2" xref="A7.SS2.p1.1.m1.1.1.2.cmml">256</mn><mo id="A7.SS2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="A7.SS2.p1.1.m1.1.1.3" xref="A7.SS2.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.p1.1.m1.1b"><apply id="A7.SS2.p1.1.m1.1.1.cmml" xref="A7.SS2.p1.1.m1.1.1"><times id="A7.SS2.p1.1.m1.1.1.1.cmml" xref="A7.SS2.p1.1.m1.1.1.1"></times><cn id="A7.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS2.p1.1.m1.1.1.2">256</cn><cn id="A7.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="A7.SS2.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.p1.1.m1.1d">256 × 256</annotation></semantics></math> resolution image is encoded into a latent representation of size <math alttext="16\times 32\times 32" class="ltx_Math" display="inline" id="A7.SS2.p1.2.m2.1"><semantics id="A7.SS2.p1.2.m2.1a"><mrow id="A7.SS2.p1.2.m2.1.1" xref="A7.SS2.p1.2.m2.1.1.cmml"><mn id="A7.SS2.p1.2.m2.1.1.2" xref="A7.SS2.p1.2.m2.1.1.2.cmml">16</mn><mo id="A7.SS2.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="A7.SS2.p1.2.m2.1.1.3" xref="A7.SS2.p1.2.m2.1.1.3.cmml">32</mn><mo id="A7.SS2.p1.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p1.2.m2.1.1.1.cmml">×</mo><mn id="A7.SS2.p1.2.m2.1.1.4" xref="A7.SS2.p1.2.m2.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.p1.2.m2.1b"><apply id="A7.SS2.p1.2.m2.1.1.cmml" xref="A7.SS2.p1.2.m2.1.1"><times id="A7.SS2.p1.2.m2.1.1.1.cmml" xref="A7.SS2.p1.2.m2.1.1.1"></times><cn id="A7.SS2.p1.2.m2.1.1.2.cmml" type="integer" xref="A7.SS2.p1.2.m2.1.1.2">16</cn><cn id="A7.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="A7.SS2.p1.2.m2.1.1.3">32</cn><cn id="A7.SS2.p1.2.m2.1.1.4.cmml" type="integer" xref="A7.SS2.p1.2.m2.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p1.2.m2.1c">16\times 32\times 32</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.p1.2.m2.1d">16 × 32 × 32</annotation></semantics></math>, which is then patched with a patch size of 2. We replaced the positional encoding with a 2D RoPE suitable for images for this task. We employed the QWen2-1.5B language model <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib114" title="">2024a</a>)</cite> as the text encoder, which offers superior text understanding capabilities compared to models like CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib85" title="">2021</a>)</cite> or T5 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib86" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS2.p2">
<p class="ltx_p" id="A7.SS2.p2.1">We conducted experiments on an internal dataset composed of both public and private data. The public dataset comprises millions of images from  <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib101" title="">2024</a>)</cite>. We performed meticulous data cleaning, referencing the methods used by PixelArt <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib17" title="">2023</a>)</cite> and SD3.0 <cite class="ltx_cite ltx_citemacro_citep">(Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib32" title="">2024</a>)</cite>. Since we did not intend to explore multi-scale resolution generation at this stage (reserved for future work), we resized all images to a <math alttext="256\times 256" class="ltx_Math" display="inline" id="A7.SS2.p2.1.m1.1"><semantics id="A7.SS2.p2.1.m1.1a"><mrow id="A7.SS2.p2.1.m1.1.1" xref="A7.SS2.p2.1.m1.1.1.cmml"><mn id="A7.SS2.p2.1.m1.1.1.2" xref="A7.SS2.p2.1.m1.1.1.2.cmml">256</mn><mo id="A7.SS2.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p2.1.m1.1.1.1.cmml">×</mo><mn id="A7.SS2.p2.1.m1.1.1.3" xref="A7.SS2.p2.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.p2.1.m1.1b"><apply id="A7.SS2.p2.1.m1.1.1.cmml" xref="A7.SS2.p2.1.m1.1.1"><times id="A7.SS2.p2.1.m1.1.1.1.cmml" xref="A7.SS2.p2.1.m1.1.1.1"></times><cn id="A7.SS2.p2.1.m1.1.1.2.cmml" type="integer" xref="A7.SS2.p2.1.m1.1.1.2">256</cn><cn id="A7.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="A7.SS2.p2.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p2.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.p2.1.m1.1d">256 × 256</annotation></semantics></math> resolution for training.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS2.p3">
<p class="ltx_p" id="A7.SS2.p3.1">We trained D-JEPA-L from scratch for approximately 500 epochs (measured by the ImageNet data volume) without additional pre-training. Unlike many diffusion models such as  <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib17" title="">2023</a>)</cite>, we found that training from scratch yielded satisfactory results for D-JEPA-L; using pre-trained weights from ImageNet resulted in decreased performance, consistent with the findings in  <cite class="ltx_cite ltx_citemacro_cite">Zhuo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite>. We conducted this experiment on four workers, each with 8 H800 GPUs. We maintained a total batch size of 2048 with the help of gradient checkpointing techniques.</p>
</div>
<section class="ltx_paragraph" id="A7.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<figure class="ltx_figure" id="A7.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="167" id="A7.F14.g1" src="x26.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Text to image samples during training. From left to right, the results are sampled at intervals of 40 epochs, from the 40th to the 200th epoch. The corresponding prompt: <span class="ltx_text ltx_font_italic" id="A7.F14.2.1">a photo of a backpack below a cake.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS2.SSS0.Px1.p1.1">In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F14" title="Figure 14 ‣ Analysis ‣ G.2 Text-to-Image Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">14</span></a>, we show the images sampled every 40 epochs during the early training stages (up to 200 epochs). Early in training, D-JEPA tended to generate single objects and struggled to understand multiple objects or spatial relationships. After 120 epochs of training, the model could generally generate single objects well, but various objects were still missing. As training progressed, D-JEPA began generating multiple objects and gradually grasped the correct spatial relationships. We observed that after about 160 epochs, the model could generate high-quality images, as shown in the penultimate image in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F14" title="Figure 14 ‣ Analysis ‣ G.2 Text-to-Image Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">14</span></a>. However, it still struggled to create accurate spatial relationships between objects. For instance, when given the prompt ”a backpack <span class="ltx_text ltx_font_bold" id="A7.SS2.SSS0.Px1.p1.1.1">below</span> a cake,” the generated content showed ”a backpack <span class="ltx_text ltx_font_bold" id="A7.SS2.SSS0.Px1.p1.1.2">behind</span> a cake,” which is more consistent with common sense. In other words, the model could understand conventional spatial relationships at this stage but still struggled with abstract spatial relationships, especially those not present in the training data. As training continued, the model’s ability to understand abstract concepts improved, as demonstrated in the last image in the figure, which correctly generated the spatial relationship.</p>
</div>
<figure class="ltx_figure" id="A7.F15">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf1.g1" src="x27.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>A beautiful girl.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf2.g1" src="x28.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Beautiful scene with mountains and rivers in a small village.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf3.g1" src="x29.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>A snowy mountain.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf4.g1" src="x30.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>A crab made of cheese on a plate.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Samples of text to image generation. Resolution: <math alttext="256\times 256" class="ltx_Math" display="inline" id="A7.F15.2.m1.1"><semantics id="A7.F15.2.m1.1b"><mrow id="A7.F15.2.m1.1.1" xref="A7.F15.2.m1.1.1.cmml"><mn id="A7.F15.2.m1.1.1.2" xref="A7.F15.2.m1.1.1.2.cmml">256</mn><mo id="A7.F15.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.F15.2.m1.1.1.1.cmml">×</mo><mn id="A7.F15.2.m1.1.1.3" xref="A7.F15.2.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.F15.2.m1.1c"><apply id="A7.F15.2.m1.1.1.cmml" xref="A7.F15.2.m1.1.1"><times id="A7.F15.2.m1.1.1.1.cmml" xref="A7.F15.2.m1.1.1.1"></times><cn id="A7.F15.2.m1.1.1.2.cmml" type="integer" xref="A7.F15.2.m1.1.1.2">256</cn><cn id="A7.F15.2.m1.1.1.3.cmml" type="integer" xref="A7.F15.2.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.F15.2.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A7.F15.2.m1.1e">256 × 256</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="A7.SS2.SSS0.Px1.p2.1">In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F15" title="Figure 15 ‣ Analysis ‣ G.2 Text-to-Image Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">15</span></a>, we demonstrate the model’s capabilities to generate high-quality images after <span class="ltx_text ltx_font_italic" id="A7.SS2.SSS0.Px1.p2.1.1">300</span> training epochs. D-JEPA can already produce detailed portraits and rich scenes, although some local artifacts still exist. We believe that by using larger models, conducting more extensive training, and utilizing higher-resolution data, D-JEPA’s text-to-image generation capabilities will be significantly enhanced.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.3 </span>Class Conditioned Video Generation</h3>
<div class="ltx_para ltx_noindent" id="A7.SS3.p1">
<p class="ltx_p" id="A7.SS3.p1.1">In this experiment, we adapted D-JEPA-L for class-conditioned video generation. We utilized the open-source VideoVAE from  <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib115" title="">2024b</a>)</cite>, which compresses the video’s temporal and spatial resolutions by factors of 4 and 8, significantly reducing the computational burden during video generation. We divided each video frame into tokens with a patch size of 2 along the spatial and four along the temporal dimensions. Empirically, we found that using a larger patch size in the temporal dimension helps the model learn more consistent motion.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS3.p2">
<p class="ltx_p" id="A7.SS3.p2.4">We conducted the experiments on the UCF101 dataset <cite class="ltx_cite ltx_citemacro_citep">(Soomro, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib98" title="">2012</a>)</cite>, a widely recognized benchmark in human action recognition, consisting of 13,320 video clips spanning 101 action categories, including a diverse range of activities such as sports, musical instruments, and human-object interactions. This richly annotated dataset covers a broad spectrum of real-world scenarios captured under varying conditions, making it an essential resource for advancing and evaluating video generation methods. It has been widely used in recent works <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib71" title="">2024b</a>; Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib48" title="">2022</a>)</cite>. We trained our model on the original <math alttext="240\times 320" class="ltx_Math" display="inline" id="A7.SS3.p2.1.m1.1"><semantics id="A7.SS3.p2.1.m1.1a"><mrow id="A7.SS3.p2.1.m1.1.1" xref="A7.SS3.p2.1.m1.1.1.cmml"><mn id="A7.SS3.p2.1.m1.1.1.2" xref="A7.SS3.p2.1.m1.1.1.2.cmml">240</mn><mo id="A7.SS3.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.1.m1.1.1.1.cmml">×</mo><mn id="A7.SS3.p2.1.m1.1.1.3" xref="A7.SS3.p2.1.m1.1.1.3.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.1.m1.1b"><apply id="A7.SS3.p2.1.m1.1.1.cmml" xref="A7.SS3.p2.1.m1.1.1"><times id="A7.SS3.p2.1.m1.1.1.1.cmml" xref="A7.SS3.p2.1.m1.1.1.1"></times><cn id="A7.SS3.p2.1.m1.1.1.2.cmml" type="integer" xref="A7.SS3.p2.1.m1.1.1.2">240</cn><cn id="A7.SS3.p2.1.m1.1.1.3.cmml" type="integer" xref="A7.SS3.p2.1.m1.1.1.3">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.1.m1.1c">240\times 320</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.1.m1.1d">240 × 320</annotation></semantics></math> resolution. We sampled eight frames per second to generate 20-second videos, totaling 160 frames. We used zero padding for videos shorter than 20 seconds to align the number of frames. During training, each input video clip was sized at <math alttext="160\times 240\times 320" class="ltx_Math" display="inline" id="A7.SS3.p2.2.m2.1"><semantics id="A7.SS3.p2.2.m2.1a"><mrow id="A7.SS3.p2.2.m2.1.1" xref="A7.SS3.p2.2.m2.1.1.cmml"><mn id="A7.SS3.p2.2.m2.1.1.2" xref="A7.SS3.p2.2.m2.1.1.2.cmml">160</mn><mo id="A7.SS3.p2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.2.m2.1.1.1.cmml">×</mo><mn id="A7.SS3.p2.2.m2.1.1.3" xref="A7.SS3.p2.2.m2.1.1.3.cmml">240</mn><mo id="A7.SS3.p2.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.2.m2.1.1.1.cmml">×</mo><mn id="A7.SS3.p2.2.m2.1.1.4" xref="A7.SS3.p2.2.m2.1.1.4.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.2.m2.1b"><apply id="A7.SS3.p2.2.m2.1.1.cmml" xref="A7.SS3.p2.2.m2.1.1"><times id="A7.SS3.p2.2.m2.1.1.1.cmml" xref="A7.SS3.p2.2.m2.1.1.1"></times><cn id="A7.SS3.p2.2.m2.1.1.2.cmml" type="integer" xref="A7.SS3.p2.2.m2.1.1.2">160</cn><cn id="A7.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="A7.SS3.p2.2.m2.1.1.3">240</cn><cn id="A7.SS3.p2.2.m2.1.1.4.cmml" type="integer" xref="A7.SS3.p2.2.m2.1.1.4">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.2.m2.1c">160\times 240\times 320</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.2.m2.1d">160 × 240 × 320</annotation></semantics></math>, yielding a latent embedding with <math alttext="40\times 30\times 40" class="ltx_Math" display="inline" id="A7.SS3.p2.3.m3.1"><semantics id="A7.SS3.p2.3.m3.1a"><mrow id="A7.SS3.p2.3.m3.1.1" xref="A7.SS3.p2.3.m3.1.1.cmml"><mn id="A7.SS3.p2.3.m3.1.1.2" xref="A7.SS3.p2.3.m3.1.1.2.cmml">40</mn><mo id="A7.SS3.p2.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.3.m3.1.1.1.cmml">×</mo><mn id="A7.SS3.p2.3.m3.1.1.3" xref="A7.SS3.p2.3.m3.1.1.3.cmml">30</mn><mo id="A7.SS3.p2.3.m3.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.3.m3.1.1.1.cmml">×</mo><mn id="A7.SS3.p2.3.m3.1.1.4" xref="A7.SS3.p2.3.m3.1.1.4.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.3.m3.1b"><apply id="A7.SS3.p2.3.m3.1.1.cmml" xref="A7.SS3.p2.3.m3.1.1"><times id="A7.SS3.p2.3.m3.1.1.1.cmml" xref="A7.SS3.p2.3.m3.1.1.1"></times><cn id="A7.SS3.p2.3.m3.1.1.2.cmml" type="integer" xref="A7.SS3.p2.3.m3.1.1.2">40</cn><cn id="A7.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="A7.SS3.p2.3.m3.1.1.3">30</cn><cn id="A7.SS3.p2.3.m3.1.1.4.cmml" type="integer" xref="A7.SS3.p2.3.m3.1.1.4">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.3.m3.1c">40\times 30\times 40</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.3.m3.1d">40 × 30 × 40</annotation></semantics></math>, and subsequently patched into <math alttext="10\times 15\times 20=3000" class="ltx_Math" display="inline" id="A7.SS3.p2.4.m4.1"><semantics id="A7.SS3.p2.4.m4.1a"><mrow id="A7.SS3.p2.4.m4.1.1" xref="A7.SS3.p2.4.m4.1.1.cmml"><mrow id="A7.SS3.p2.4.m4.1.1.2" xref="A7.SS3.p2.4.m4.1.1.2.cmml"><mn id="A7.SS3.p2.4.m4.1.1.2.2" xref="A7.SS3.p2.4.m4.1.1.2.2.cmml">10</mn><mo id="A7.SS3.p2.4.m4.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.4.m4.1.1.2.1.cmml">×</mo><mn id="A7.SS3.p2.4.m4.1.1.2.3" xref="A7.SS3.p2.4.m4.1.1.2.3.cmml">15</mn><mo id="A7.SS3.p2.4.m4.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.4.m4.1.1.2.1.cmml">×</mo><mn id="A7.SS3.p2.4.m4.1.1.2.4" xref="A7.SS3.p2.4.m4.1.1.2.4.cmml">20</mn></mrow><mo id="A7.SS3.p2.4.m4.1.1.1" xref="A7.SS3.p2.4.m4.1.1.1.cmml">=</mo><mn id="A7.SS3.p2.4.m4.1.1.3" xref="A7.SS3.p2.4.m4.1.1.3.cmml">3000</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.4.m4.1b"><apply id="A7.SS3.p2.4.m4.1.1.cmml" xref="A7.SS3.p2.4.m4.1.1"><eq id="A7.SS3.p2.4.m4.1.1.1.cmml" xref="A7.SS3.p2.4.m4.1.1.1"></eq><apply id="A7.SS3.p2.4.m4.1.1.2.cmml" xref="A7.SS3.p2.4.m4.1.1.2"><times id="A7.SS3.p2.4.m4.1.1.2.1.cmml" xref="A7.SS3.p2.4.m4.1.1.2.1"></times><cn id="A7.SS3.p2.4.m4.1.1.2.2.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.2.2">10</cn><cn id="A7.SS3.p2.4.m4.1.1.2.3.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.2.3">15</cn><cn id="A7.SS3.p2.4.m4.1.1.2.4.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.2.4">20</cn></apply><cn id="A7.SS3.p2.4.m4.1.1.3.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.3">3000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.4.m4.1c">10\times 15\times 20=3000</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.4.m4.1d">10 × 15 × 20 = 3000</annotation></semantics></math> tokens. During sampling, we completed video generation in 64 steps. We trained D-JEPA-L from scratch on four workers, each equipped with 8 H800 GPUs, maintaining a global batch size of 512. We also utilized gradient checkpointing to reduce the demand for GPU memory.</p>
</div>
<figure class="ltx_table" id="A7.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T9.1" style="width:433.6pt;height:12.2pt;vertical-align:-0.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-436.5pt,12.0pt) scale(0.331840363944817,0.331840363944817) ;">
<table class="ltx_tabular ltx_align_middle" id="A7.T9.1.1">
<tr class="ltx_tr" id="A7.T9.1.1.1">
<td class="ltx_td ltx_border_r" id="A7.T9.1.1.1.2"></td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.3">DIGAN <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib119" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.4">StyleGAN-V <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib94" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.1">Latte<sup class="ltx_sup" id="A7.T9.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="A7.T9.1.1.1.1.1.1">⋆</span></sup> <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib71" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.5">LVDM <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib45" title="">2022b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.6">MoStGAN-V <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib93" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.7">PVDM <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib120" title="">2023c</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.8" style="background-color:#ECF4FF;"><span class="ltx_text" id="A7.T9.1.1.1.8.1" style="background-color:#ECF4FF;">D-JEPA</span></td>
</tr>
<tr class="ltx_tr" id="A7.T9.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A7.T9.1.1.2.1">FVD-16</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.2">1630.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.3">1431.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.4">333.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.5">372.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.6">1380.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.7">1141.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.8" style="background-color:#ECF4FF;"><span class="ltx_text" id="A7.T9.1.1.2.8.1" style="background-color:#ECF4FF;">365.2</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Quantitative comparisons of short video generation on UCF101. <sup class="ltx_sup" id="A7.T9.5.1"><span class="ltx_text ltx_font_italic" id="A7.T9.5.1.1">⋆</span></sup> indicates training on additional image data.</figcaption>
</figure>
<figure class="ltx_figure" id="A7.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="251" id="A7.F16.g1" src="x31.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>The training curve of flow matching loss on UCF101.</figcaption>
</figure>
<section class="ltx_paragraph" id="A7.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<div class="ltx_para ltx_noindent" id="A7.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS3.SSS0.Px1.p1.1">Current video generation models based on diffusion typically require pre-training or joint training on images and videos. We found this approach unnecessary for video generation; instead, it introduces an artificial separation between spatial and temporal aspects, hindering motion generation. The D-JEPA-based video generation model is trained directly on videos, treating all tokens as standard tokens without incorporating 3D attention or other structural designs. These straightforward yet effective mechanisms enable D-JEPA to generate videos more holistically. Since D-JEPA randomly generates the next token from the entire token sequence, it captures the overall video quality more effectively. It decides when to terminate video generation, thereby avoiding the production of redundant video segments, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.F10" title="Figure 10 ‣ Analysis of flow matching loss ‣ Appendix F Flow Matching Loss ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">10</span></a>. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F16" title="Figure 16 ‣ G.3 Class Conditioned Video Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">16</span></a> also indicates that D-JEPA maintains stability throughout the training process. We also present the FVD metrics in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.T9" title="Table 9 ‣ G.3 Class Conditioned Video Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">9</span></a>, where D-JEPA achieves results second only to Latte <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib71" title="">2024b</a>)</cite>, which is trained on additional image data.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.4 </span>Multi-Modal Generation</h3>
<div class="ltx_para ltx_noindent" id="A7.SS4.p1">
<p class="ltx_p" id="A7.SS4.p1.1">In this experiment, we aim to demonstrate the potential of D-JEPA as a unified multimodal model. This is an ambitious attempt, as D-JEPA can generate text using <span class="ltx_text ltx_font_italic" id="A7.SS4.p1.1.1">next token prediction</span> and create images, videos, etc., using <span class="ltx_text ltx_font_italic" id="A7.SS4.p1.1.2">next set of tokens prediction</span>. Essentially, we adopted the design philosophy of Transfusion <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite> but replaced the diffusion model with the D-JEPA model.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS4.p2">
<p class="ltx_p" id="A7.SS4.p2.1">To simplify the task, we constructed a model that simultaneously generates text and images. Unlike the text-to-image generation described in App. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS2" title="G.2 Text-to-Image Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">G.2</span></a>, image generation in the multimodal mode does not rely on any text embedding model. Text and images are directly used as inputs to the model, which then simultaneously predicts both text and image.</p>
</div>
<figure class="ltx_figure" id="A7.F17">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="314" id="A7.F17.1.g1" src="x32.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="314" id="A7.F17.2.g1" src="x33.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="314" id="A7.F17.3.g1" src="x34.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="315" id="A7.F17.4.g1" src="x35.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="338" id="A7.F17.5.g1" src="x36.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="346" id="A7.F17.6.g1" src="x37.png" width="761"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Samples of text to image generation by multi-modal models build on the top of D-JEPA.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS4.p3">
<p class="ltx_p" id="A7.SS4.p3.1">During the sampling process, we input the image caption that needs to be generated and let the network continuously predict the next tokens until it samples a “<math alttext="&lt;|\textit{visual\_start}|&gt;" class="ltx_Math" display="inline" id="A7.SS4.p3.1.m1.1"><semantics id="A7.SS4.p3.1.m1.1a"><mrow id="A7.SS4.p3.1.m1.1.2" xref="A7.SS4.p3.1.m1.1.2.cmml"><mi id="A7.SS4.p3.1.m1.1.2.2" xref="A7.SS4.p3.1.m1.1.2.2.cmml"></mi><mo id="A7.SS4.p3.1.m1.1.2.3" xref="A7.SS4.p3.1.m1.1.2.3.cmml">&lt;</mo><mrow id="A7.SS4.p3.1.m1.1.2.4.2" xref="A7.SS4.p3.1.m1.1.2.4.1.cmml"><mo id="A7.SS4.p3.1.m1.1.2.4.2.1" stretchy="false" xref="A7.SS4.p3.1.m1.1.2.4.1.1.cmml">|</mo><mtext class="ltx_mathvariant_italic" id="A7.SS4.p3.1.m1.1.1" xref="A7.SS4.p3.1.m1.1.1a.cmml">visual_start</mtext><mo id="A7.SS4.p3.1.m1.1.2.4.2.2" stretchy="false" xref="A7.SS4.p3.1.m1.1.2.4.1.1.cmml">|</mo></mrow><mo id="A7.SS4.p3.1.m1.1.2.5" xref="A7.SS4.p3.1.m1.1.2.5.cmml">&gt;</mo><mi id="A7.SS4.p3.1.m1.1.2.6" xref="A7.SS4.p3.1.m1.1.2.6.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.1.m1.1b"><apply id="A7.SS4.p3.1.m1.1.2.cmml" xref="A7.SS4.p3.1.m1.1.2"><and id="A7.SS4.p3.1.m1.1.2a.cmml" xref="A7.SS4.p3.1.m1.1.2"></and><apply id="A7.SS4.p3.1.m1.1.2b.cmml" xref="A7.SS4.p3.1.m1.1.2"><lt id="A7.SS4.p3.1.m1.1.2.3.cmml" xref="A7.SS4.p3.1.m1.1.2.3"></lt><csymbol cd="latexml" id="A7.SS4.p3.1.m1.1.2.2.cmml" xref="A7.SS4.p3.1.m1.1.2.2">absent</csymbol><apply id="A7.SS4.p3.1.m1.1.2.4.1.cmml" xref="A7.SS4.p3.1.m1.1.2.4.2"><abs id="A7.SS4.p3.1.m1.1.2.4.1.1.cmml" xref="A7.SS4.p3.1.m1.1.2.4.2.1"></abs><ci id="A7.SS4.p3.1.m1.1.1a.cmml" xref="A7.SS4.p3.1.m1.1.1"><mtext class="ltx_mathvariant_italic" id="A7.SS4.p3.1.m1.1.1.cmml" xref="A7.SS4.p3.1.m1.1.1">visual_start</mtext></ci></apply></apply><apply id="A7.SS4.p3.1.m1.1.2c.cmml" xref="A7.SS4.p3.1.m1.1.2"><gt id="A7.SS4.p3.1.m1.1.2.5.cmml" xref="A7.SS4.p3.1.m1.1.2.5"></gt><share href="https://arxiv.org/html/2410.03755v1#A7.SS4.p3.1.m1.1.2.4.cmml" id="A7.SS4.p3.1.m1.1.2d.cmml" xref="A7.SS4.p3.1.m1.1.2"></share><csymbol cd="latexml" id="A7.SS4.p3.1.m1.1.2.6.cmml" xref="A7.SS4.p3.1.m1.1.2.6">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.1.m1.1c">&lt;|\textit{visual\_start}|&gt;</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.1.m1.1d">&lt; | visual_start | &gt;</annotation></semantics></math>” control token. Then, it switches to the next set of tokens prediction mode to complete the sampling of the entire image. The specific sampling process and training details follow the methodology described by  <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite>. We showcase the image generation effects of this novel architecture in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F17" title="Figure 17 ‣ G.4 Multi-Modal Generation ‣ Appendix G Comprehensive Experiments ‣ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">17</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS4.p4">
<p class="ltx_p" id="A7.SS4.p4.1">Empirically, we found that the multimodal model built with D-JEPA can more effectively couple discrete text and other continuous data types in terms of architecture and engineering implementation. Further exploration of this field will be presented in future work.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Limitations</h2>
<section class="ltx_paragraph" id="A8.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Potential performance bottleneck from denoising MLP.</h4>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A8.SS0.SSS0.Px1.p1.1">In the D-JEPA framework, the context encoder, target encoder, and feature predictor all utilize standard visual transformer structures. This work and numerous other studies extensively validated the scalability and capacity for scaling up these structures, suggesting significant potential for D-JEPA. However, diffusion or flow matching loss is implemented using a simple Multi-Layer Perceptron (MLP) structure. Although it is theoretically proven that a 3-layer MLP can fit any function, we have observed in practice that the MLP may become a bottleneck for the final performance of the D-JEPA model. More critically, our experiments indicate that increasing the number of MLP layers or widening the MLP dimensions does not significantly improve performance. Recent works, such as KAN <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib68" title="">2024</a>)</cite>, have demonstrated significant advantages over MLPs in various tasks. We also attempted to construct a network of comparable scale using KAN, but so far, it has not resulted in a significant performance improvement. While the current MLP structure has achieved satisfactory results in our experiments, exploring alternative network structures to replace the MLP remains a crucial area for further investigation.</p>
</div>
</section>
<section class="ltx_paragraph" id="A8.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Efficiency issues due to bi-directional attention.</h4>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p1.1">Although D-JEPA employs a generalized next-token prediction strategy, its primary structure is entirely realized through visual transformers, which use bi-directional attention during training and inference. This prevents highly effective key-value caching strategy based on causal attention to reduce computation. Notably, in the feature predictor network, we train with all masked and context tokens together using bi-directional attention. This means that each token must continuously attend to information from context and masked tokens. This behavior during training forces us to feed all tokens into the network simultaneously during sampling, especially at the beginning, leading to substantial unnecessary computational overhead. Simple estimates suggest that this process can result in up to <math alttext="50\%" class="ltx_Math" display="inline" id="A8.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="A8.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A8.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">50</mn><mo id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A8.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1">percent</csymbol><cn id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS0.SSS0.Px2.p1.1.m1.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="A8.SS0.SSS0.Px2.p1.1.m1.1d">50 %</annotation></semantics></math> useless computation for the feature predictor in extreme cases.</p>
</div>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p2.1">Intuitively, when predicting the features of masked tokens, we should only need information from context tokens without attending to other masked tokens. This would allow us to avoid feeding all masked tokens into the network during inference, significantly reducing extra computational costs. Based on this, we attempted to develop a new attention mechanism during training. In this approach, the attention for masked tokens in the feature predictor is restricted to all context tokens and itself, while context tokens always attend to all context tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p3.1">Surprisingly, training with this new attention mechanism did not effectively reduce the FID on ImageNet (FID remained above 50 after 160 epochs). This aligns with findings in <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite>, emphasizing that diffusion models must use bi-directional attention during training to ensure effectiveness. Similar observations were made in the MAR <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> context. Therefore, improving the efficiency of the attention module during training and inference for D-JEPA remains a critical issue.</p>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 05:55:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
