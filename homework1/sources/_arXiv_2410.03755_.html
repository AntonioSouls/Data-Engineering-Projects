<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Denoising with a Joint-Embedding Predictive Architecture</title>
<!--Generated on Wed Oct  2 05:55:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03755v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S1" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.SS0.SSS0.Px1" title="In 2 Background â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Joint-embedding predictive architectures (JEPAs).</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.SS0.SSS0.Px2" title="In 2 Background â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Diffusion models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.SS0.SSS0.Px3" title="In 2 Background â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Generalized next-token prediction.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS1" title="In 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Tokenization and Masking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS2" title="In 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Representation Learning with JEPAs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS3" title="In 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Diffusion Learning with a Denoising MLP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS4" title="In 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Training with D-JEPA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS5" title="In 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Sampling in Next Set-of-Tokens Prediction</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1" title="In 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Image Synthetis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1.SSS0.Px1" title="In 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Quantitative analysis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1.SSS0.Px2" title="In 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Qualitative analysis.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1.SSS0.Px3" title="In 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Scaling law of D-JEPA.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS2" title="In 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Comprehensive Experiments</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S5" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A1" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A1.SS0.SSS0.Px1" title="In Appendix A Related Work â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Self-supervised learning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A1.SS0.SSS0.Px2" title="In Appendix A Related Work â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Generative modeling.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2.SS0.SSS0.Px1" title="In Appendix B Experimental Setup â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Network configuration.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2.SS0.SSS0.Px2" title="In Appendix B Experimental Setup â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Training.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2.SS0.SSS0.Px3" title="In Appendix B Experimental Setup â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Evaluation metrics.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Sampling with generalized next token prediction</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS1" title="In Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Grid searching for optimal classifier-free guidance scale and temperature</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS1.SSS0.Px1" title="In C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Coarse searching.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS1.SSS0.Px2" title="In C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Fine searching.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="In Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Abalation on auto-regressive steps</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2.SSS0.Px1" title="In C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Sampling efficiency.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Additional results on ImageNet</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS1" title="In Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>Full comparison on ImageNet</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS2" title="In Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>Training curve</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS3" title="In Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.3 </span>Inpainting and Outpainting</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>D-JEPA for representation learning</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS1" title="In Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Theoretical motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2" title="In Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Image classification</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px1" title="In E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Experiment settings.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px2" title="In E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Linear probing.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px3" title="In E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Fine-tuning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2.SSS0.Px4" title="In E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis on raw pixel space and semantic token space.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Flow Matching Loss</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.SS0.SSS0.Px1" title="In Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis of flow matching loss</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Comprehensive Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS1" title="In Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.1 </span>Text-to-Audio Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS1.SSS0.Px1" title="In G.1 Text-to-Audio Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS2" title="In Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.2 </span>Text-to-Image Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS2.SSS0.Px1" title="In G.2 Text-to-Image Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS3" title="In Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.3 </span>Class Conditioned Video Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS3.SSS0.Px1" title="In G.3 Class Conditioned Video Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS4" title="In Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.4 </span>Multi-Modal Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A8" title="In Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Limitations</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A8.SS0.SSS0.Px1" title="In Appendix H Limitations â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Potential performance bottleneck from denoising MLP.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A8.SS0.SSS0.Px2" title="In Appendix H Limitations â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_title">Efficiency issues due to bi-directional attention.</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Denoising with a Joint-Embedding Predictive Architecture</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dengsheng Chen 
<br class="ltx_break"/>Meituan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">chendengsheng@meituan.com</span>
<br class="ltx_break"/>&amp;Jie Hu 
<br class="ltx_break"/>Meituan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">hujie39@meituan.com</span>
<br class="ltx_break"/>&amp;Xiaoming Wei 
<br class="ltx_break"/>Meituan
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">weixiaoming@meituan.com</span>
<br class="ltx_break"/>&amp;Enhua Wu
<br class="ltx_break"/>SKLCS, Institute of Software, Chinese Academy of Sciences
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id4">weh@ios.ac.cn</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Joint-embedding predictive architectures (JEPAs) have shown substantial promise in self-supervised representation learning, yet their application in generative modeling remains underexplored. Conversely, diffusion models have demonstrated significant efficacy in modeling arbitrary probability distributions. In this paper, we introduce Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), pioneering the integration of JEPA within generative modeling. By recognizing JEPA as a form of masked image modeling, we reinterpret it as a generalized next-token prediction strategy, facilitating data generation in an auto-regressive manner. Furthermore, we incorporate diffusion loss to model the per-token probability distribution, enabling data generation in a continuous space. We also adapt flow matching loss as an alternative to diffusion loss, thereby enhancing the flexibility of D-JEPA. Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability. Our base, large, and huge models outperform all previous generative models across all scales on class-conditional ImageNet benchmarks. Beyond image generation, D-JEPA is well-suited for other continuous data modeling, including video and audio.</p>
<p class="ltx_p" id="id6.id2">Project page: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://d-jepa.github.io/" title="">https://d-jepa.github.io/</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The extraordinary success of generative language modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib83" title="">2018</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib84" title="">2019</a>; Brown etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib14" title="">2020</a>)</cite>, which excel in next-token prediction, has spurred efforts to adapt autoregressive models for other domains, notably image generationÂ <cite class="ltx_cite ltx_citemacro_citep">(Kilian etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib56" title="">2024</a>; Zeng etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib122" title="">2021</a>; Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>; Esser etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib31" title="">2021</a>; Yu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>. Typically, this involves discretizing visual data into token sequencesÂ <cite class="ltx_cite ltx_citemacro_citep">(Van DenÂ Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib108" title="">2017</a>)</cite>, a process that can sometimes degrade image quality. Despite this, the technique has gained substantial interest due to its powerful capabilities Â <cite class="ltx_cite ltx_citemacro_citep">(Razavi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib88" title="">2019</a>; Peng etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib82" title="">2021</a>; Yan etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib113" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recently, diffusion modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>; Song etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib95" title="">2020</a>; Nichol &amp; Dhariwal, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib75" title="">2021</a>)</cite> have emerged as a dominant force in generative modeling, surpassing generative adversarial networks (GANs)Â <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib36" title="">2014</a>; Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib109" title="">2017</a>; Goodfellow etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib35" title="">2020</a>)</cite> with their superior performance in producing high-fidelity images. Concurrently, significant advancements have been made in self-supervised representation learning, particularly through masked image modelingÂ <cite class="ltx_cite ltx_citemacro_citep">(Xie etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib112" title="">2022</a>; Baevski etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>; Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>; He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> and invariance-based techniquesÂ <cite class="ltx_cite ltx_citemacro_citep">(Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib3" title="">2022</a>; Caron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib15" title="">2021</a>; Chen &amp; He, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib22" title="">2021</a>; Grill etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>; Zbontar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib121" title="">2021</a>)</cite>. However, generative modeling and representation learning development has largely progressed in isolation, with limited cross-fertilizationÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recent efforts have sought to integrate diffusion models within an autoregressive framework, such as MARÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> and TransfusionÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite>. These models, however, primarily focus on enhancing generative model performance from the perspective of generation alone, often overlooking advancements in representation learning. Conversely, within the realm of representation learning, researchers tend to emphasize model performance on downstream tasks Â <cite class="ltx_cite ltx_citemacro_citep">(Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, neglecting the potential for these models to excel in generative modeling.
To bridge this gap, we propose a novel framework, termed â€œDenoising with a Joint-Embedding Predictive Architectureâ€ (D-JEPA), that effectively leverages next-token prediction from a representation learning perspective. Specifically, we adopt the joint-embedding predictive architecture as the core of our design, enabling us to reframe masked image modeling methods into a generalized next-token prediction strategy, thus facilitating autoregressive data generation. Additionally, we incorporate a diffusion lossÂ (or flow matching loss) to model the per-token probability distribution, allowing for data generation in a continuous space.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.12">Specifically, D-JEPA consists of three identical visual transformer backbonesÂ <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>: a context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><mi id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.1d">italic_Ï•</annotation></semantics></math>, a target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S1.p4.2.m2.1"><semantics id="S1.p4.2.m2.1a"><mover accent="true" id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml">Ï•</mi><mo id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><ci id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1">Â¯</ci><ci id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.2.m2.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math>, and a feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S1.p4.3.m3.1"><semantics id="S1.p4.3.m3.1a"><mi id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><ci id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S1.p4.3.m3.1d">italic_Î³</annotation></semantics></math>. It employs two loss functions: diffusion loss (<math alttext="\mathcal{L}_{d}" class="ltx_Math" display="inline" id="S1.p4.4.m4.1"><semantics id="S1.p4.4.m4.1a"><msub id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.p4.4.m4.1.1.2" xref="S1.p4.4.m4.1.1.2.cmml">â„’</mi><mi id="S1.p4.4.m4.1.1.3" xref="S1.p4.4.m4.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.1b"><apply id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S1.p4.4.m4.1.1.1.cmml" xref="S1.p4.4.m4.1.1">subscript</csymbol><ci id="S1.p4.4.m4.1.1.2.cmml" xref="S1.p4.4.m4.1.1.2">â„’</ci><ci id="S1.p4.4.m4.1.1.3.cmml" xref="S1.p4.4.m4.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">\mathcal{L}_{d}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math>) and prediction loss (<math alttext="\mathcal{L}_{p}" class="ltx_Math" display="inline" id="S1.p4.5.m5.1"><semantics id="S1.p4.5.m5.1a"><msub id="S1.p4.5.m5.1.1" xref="S1.p4.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.p4.5.m5.1.1.2" xref="S1.p4.5.m5.1.1.2.cmml">â„’</mi><mi id="S1.p4.5.m5.1.1.3" xref="S1.p4.5.m5.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.5.m5.1b"><apply id="S1.p4.5.m5.1.1.cmml" xref="S1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S1.p4.5.m5.1.1.1.cmml" xref="S1.p4.5.m5.1.1">subscript</csymbol><ci id="S1.p4.5.m5.1.1.2.cmml" xref="S1.p4.5.m5.1.1.2">â„’</ci><ci id="S1.p4.5.m5.1.1.3.cmml" xref="S1.p4.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.5.m5.1c">\mathcal{L}_{p}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.5.m5.1d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>), both involving a multi-layer perceptronÂ (MLP) network. The denoising MLP, used in diffusion loss, is applied to each masked token <math alttext="x_{i}" class="ltx_Math" display="inline" id="S1.p4.6.m6.1"><semantics id="S1.p4.6.m6.1a"><msub id="S1.p4.6.m6.1.1" xref="S1.p4.6.m6.1.1.cmml"><mi id="S1.p4.6.m6.1.1.2" xref="S1.p4.6.m6.1.1.2.cmml">x</mi><mi id="S1.p4.6.m6.1.1.3" xref="S1.p4.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.6.m6.1b"><apply id="S1.p4.6.m6.1.1.cmml" xref="S1.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S1.p4.6.m6.1.1.1.cmml" xref="S1.p4.6.m6.1.1">subscript</csymbol><ci id="S1.p4.6.m6.1.1.2.cmml" xref="S1.p4.6.m6.1.1.2">ğ‘¥</ci><ci id="S1.p4.6.m6.1.1.3.cmml" xref="S1.p4.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.6.m6.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.6.m6.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, modeling the conditional probability distribution <math alttext="p(x_{i}\mid z_{i})" class="ltx_Math" display="inline" id="S1.p4.7.m7.1"><semantics id="S1.p4.7.m7.1a"><mrow id="S1.p4.7.m7.1.1" xref="S1.p4.7.m7.1.1.cmml"><mi id="S1.p4.7.m7.1.1.3" xref="S1.p4.7.m7.1.1.3.cmml">p</mi><mo id="S1.p4.7.m7.1.1.2" xref="S1.p4.7.m7.1.1.2.cmml">â¢</mo><mrow id="S1.p4.7.m7.1.1.1.1" xref="S1.p4.7.m7.1.1.1.1.1.cmml"><mo id="S1.p4.7.m7.1.1.1.1.2" stretchy="false" xref="S1.p4.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S1.p4.7.m7.1.1.1.1.1" xref="S1.p4.7.m7.1.1.1.1.1.cmml"><msub id="S1.p4.7.m7.1.1.1.1.1.2" xref="S1.p4.7.m7.1.1.1.1.1.2.cmml"><mi id="S1.p4.7.m7.1.1.1.1.1.2.2" xref="S1.p4.7.m7.1.1.1.1.1.2.2.cmml">x</mi><mi id="S1.p4.7.m7.1.1.1.1.1.2.3" xref="S1.p4.7.m7.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S1.p4.7.m7.1.1.1.1.1.1" xref="S1.p4.7.m7.1.1.1.1.1.1.cmml">âˆ£</mo><msub id="S1.p4.7.m7.1.1.1.1.1.3" xref="S1.p4.7.m7.1.1.1.1.1.3.cmml"><mi id="S1.p4.7.m7.1.1.1.1.1.3.2" xref="S1.p4.7.m7.1.1.1.1.1.3.2.cmml">z</mi><mi id="S1.p4.7.m7.1.1.1.1.1.3.3" xref="S1.p4.7.m7.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S1.p4.7.m7.1.1.1.1.3" stretchy="false" xref="S1.p4.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.7.m7.1b"><apply id="S1.p4.7.m7.1.1.cmml" xref="S1.p4.7.m7.1.1"><times id="S1.p4.7.m7.1.1.2.cmml" xref="S1.p4.7.m7.1.1.2"></times><ci id="S1.p4.7.m7.1.1.3.cmml" xref="S1.p4.7.m7.1.1.3">ğ‘</ci><apply id="S1.p4.7.m7.1.1.1.1.1.cmml" xref="S1.p4.7.m7.1.1.1.1"><csymbol cd="latexml" id="S1.p4.7.m7.1.1.1.1.1.1.cmml" xref="S1.p4.7.m7.1.1.1.1.1.1">conditional</csymbol><apply id="S1.p4.7.m7.1.1.1.1.1.2.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S1.p4.7.m7.1.1.1.1.1.2.1.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2">subscript</csymbol><ci id="S1.p4.7.m7.1.1.1.1.1.2.2.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S1.p4.7.m7.1.1.1.1.1.2.3.cmml" xref="S1.p4.7.m7.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S1.p4.7.m7.1.1.1.1.1.3.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S1.p4.7.m7.1.1.1.1.1.3.1.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3">subscript</csymbol><ci id="S1.p4.7.m7.1.1.1.1.1.3.2.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S1.p4.7.m7.1.1.1.1.1.3.3.cmml" xref="S1.p4.7.m7.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.7.m7.1c">p(x_{i}\mid z_{i})</annotation><annotation encoding="application/x-llamapun" id="S1.p4.7.m7.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ£ italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> and evaluating the predicted latent variable <math alttext="z_{i}" class="ltx_Math" display="inline" id="S1.p4.8.m8.1"><semantics id="S1.p4.8.m8.1a"><msub id="S1.p4.8.m8.1.1" xref="S1.p4.8.m8.1.1.cmml"><mi id="S1.p4.8.m8.1.1.2" xref="S1.p4.8.m8.1.1.2.cmml">z</mi><mi id="S1.p4.8.m8.1.1.3" xref="S1.p4.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.8.m8.1b"><apply id="S1.p4.8.m8.1.1.cmml" xref="S1.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S1.p4.8.m8.1.1.1.cmml" xref="S1.p4.8.m8.1.1">subscript</csymbol><ci id="S1.p4.8.m8.1.1.2.cmml" xref="S1.p4.8.m8.1.1.2">ğ‘§</ci><ci id="S1.p4.8.m8.1.1.3.cmml" xref="S1.p4.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.8.m8.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.8.m8.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> generated by the feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S1.p4.9.m9.1"><semantics id="S1.p4.9.m9.1a"><mi id="S1.p4.9.m9.1.1" xref="S1.p4.9.m9.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S1.p4.9.m9.1b"><ci id="S1.p4.9.m9.1.1.cmml" xref="S1.p4.9.m9.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.9.m9.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S1.p4.9.m9.1d">italic_Î³</annotation></semantics></math>. The prediction loss (<math alttext="\mathcal{L}_{p}" class="ltx_Math" display="inline" id="S1.p4.10.m10.1"><semantics id="S1.p4.10.m10.1a"><msub id="S1.p4.10.m10.1.1" xref="S1.p4.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S1.p4.10.m10.1.1.2" xref="S1.p4.10.m10.1.1.2.cmml">â„’</mi><mi id="S1.p4.10.m10.1.1.3" xref="S1.p4.10.m10.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.10.m10.1b"><apply id="S1.p4.10.m10.1.1.cmml" xref="S1.p4.10.m10.1.1"><csymbol cd="ambiguous" id="S1.p4.10.m10.1.1.1.cmml" xref="S1.p4.10.m10.1.1">subscript</csymbol><ci id="S1.p4.10.m10.1.1.2.cmml" xref="S1.p4.10.m10.1.1.2">â„’</ci><ci id="S1.p4.10.m10.1.1.3.cmml" xref="S1.p4.10.m10.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.10.m10.1c">\mathcal{L}_{p}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.10.m10.1d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math>), using a smooth loss function <math alttext="l_{1}" class="ltx_Math" display="inline" id="S1.p4.11.m11.1"><semantics id="S1.p4.11.m11.1a"><msub id="S1.p4.11.m11.1.1" xref="S1.p4.11.m11.1.1.cmml"><mi id="S1.p4.11.m11.1.1.2" xref="S1.p4.11.m11.1.1.2.cmml">l</mi><mn id="S1.p4.11.m11.1.1.3" xref="S1.p4.11.m11.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S1.p4.11.m11.1b"><apply id="S1.p4.11.m11.1.1.cmml" xref="S1.p4.11.m11.1.1"><csymbol cd="ambiguous" id="S1.p4.11.m11.1.1.1.cmml" xref="S1.p4.11.m11.1.1">subscript</csymbol><ci id="S1.p4.11.m11.1.1.2.cmml" xref="S1.p4.11.m11.1.1.2">ğ‘™</ci><cn id="S1.p4.11.m11.1.1.3.cmml" type="integer" xref="S1.p4.11.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.11.m11.1c">l_{1}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.11.m11.1d">italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, facilitates the latent variables <math alttext="z_{i}" class="ltx_Math" display="inline" id="S1.p4.12.m12.1"><semantics id="S1.p4.12.m12.1a"><msub id="S1.p4.12.m12.1.1" xref="S1.p4.12.m12.1.1.cmml"><mi id="S1.p4.12.m12.1.1.2" xref="S1.p4.12.m12.1.1.2.cmml">z</mi><mi id="S1.p4.12.m12.1.1.3" xref="S1.p4.12.m12.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S1.p4.12.m12.1b"><apply id="S1.p4.12.m12.1.1.cmml" xref="S1.p4.12.m12.1.1"><csymbol cd="ambiguous" id="S1.p4.12.m12.1.1.1.cmml" xref="S1.p4.12.m12.1.1">subscript</csymbol><ci id="S1.p4.12.m12.1.1.2.cmml" xref="S1.p4.12.m12.1.1.2">ğ‘§</ci><ci id="S1.p4.12.m12.1.1.3.cmml" xref="S1.p4.12.m12.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.12.m12.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S1.p4.12.m12.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to capture high-level semantic information.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Empirically, D-JEPA exhibits a consistent decrease in FID scores as GFLOPs increase, achieving these results with fewer training epochs, indicating its good scalability. Our base, large, and huge variants outperform all previously generative models across different scales on class-conditional ImageNet benchmarks. In our comprehensive experiments, we further advanced the field of generative models by substituting the diffusion loss with flow matching lossÂ <cite class="ltx_cite ltx_citemacro_citep">(Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>. This substitution enables D-JEPA to excel in image generation and modeling other types of continuous data, including video and audio. Moreover, D-JEPA exhibits remarkable flexibility, extending seamlessly to text-conditioned and multi-modal generations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Our contributions are threefold. <span class="ltx_text ltx_font_italic" id="S1.p6.1.1">Firstly</span>, we successfully integrate advancements in representation learning into generative modeling, achieving state-of-the-art performance on the ImageNet benchmark. <span class="ltx_text ltx_font_italic" id="S1.p6.1.2">Secondly</span>, we validate the effectiveness of the generalized next-token prediction approach in generative modeling, demonstrating superior scalability, which establishes a robust foundation for developing more powerful text-conditioned models. <span class="ltx_text ltx_font_italic" id="S1.p6.1.3">Lastly</span>, D-JEPA exhibits impressive extensibility, directly applicable to generate images, videos, audio, and more, providing theoretical support for constructing unified multi-modal models.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="239" id="S2.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data flow during D-JEPA training. Initially, the training data is divided into non-overlapping semantic tokens, which can be either in the raw space or in the latent space obtained after VAE encoding. A random subset of these input tokens is then masked. The feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S2.F1.4.m1.1"><semantics id="S2.F1.4.m1.1b"><mi id="S2.F1.4.m1.1.1" xref="S2.F1.4.m1.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S2.F1.4.m1.1c"><ci id="S2.F1.4.m1.1.1.cmml" xref="S2.F1.4.m1.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.4.m1.1d">\gamma</annotation><annotation encoding="application/x-llamapun" id="S2.F1.4.m1.1e">italic_Î³</annotation></semantics></math> is employed to predict features for these masked tokens, utilizing the unmasked tokens as contextual information. Each masked token is concurrently subjected to a diffusion loss (or flow matching loss) to learn the distribution of each token <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S2.F1.5.m2.1"><semantics id="S2.F1.5.m2.1b"><mrow id="S2.F1.5.m2.1.1" xref="S2.F1.5.m2.1.1.cmml"><mi id="S2.F1.5.m2.1.1.3" xref="S2.F1.5.m2.1.1.3.cmml">p</mi><mo id="S2.F1.5.m2.1.1.2" xref="S2.F1.5.m2.1.1.2.cmml">â¢</mo><mrow id="S2.F1.5.m2.1.1.1.1" xref="S2.F1.5.m2.1.1.1.1.1.cmml"><mo id="S2.F1.5.m2.1.1.1.1.2" stretchy="false" xref="S2.F1.5.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.F1.5.m2.1.1.1.1.1" xref="S2.F1.5.m2.1.1.1.1.1.cmml"><msub id="S2.F1.5.m2.1.1.1.1.1.2" xref="S2.F1.5.m2.1.1.1.1.1.2.cmml"><mi id="S2.F1.5.m2.1.1.1.1.1.2.2" xref="S2.F1.5.m2.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.F1.5.m2.1.1.1.1.1.2.3" xref="S2.F1.5.m2.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.F1.5.m2.1.1.1.1.1.1" xref="S2.F1.5.m2.1.1.1.1.1.1.cmml">|</mo><msub id="S2.F1.5.m2.1.1.1.1.1.3" xref="S2.F1.5.m2.1.1.1.1.1.3.cmml"><mi id="S2.F1.5.m2.1.1.1.1.1.3.2" xref="S2.F1.5.m2.1.1.1.1.1.3.2.cmml">z</mi><mi id="S2.F1.5.m2.1.1.1.1.1.3.3" xref="S2.F1.5.m2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.F1.5.m2.1.1.1.1.3" stretchy="false" xref="S2.F1.5.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.5.m2.1c"><apply id="S2.F1.5.m2.1.1.cmml" xref="S2.F1.5.m2.1.1"><times id="S2.F1.5.m2.1.1.2.cmml" xref="S2.F1.5.m2.1.1.2"></times><ci id="S2.F1.5.m2.1.1.3.cmml" xref="S2.F1.5.m2.1.1.3">ğ‘</ci><apply id="S2.F1.5.m2.1.1.1.1.1.cmml" xref="S2.F1.5.m2.1.1.1.1"><csymbol cd="latexml" id="S2.F1.5.m2.1.1.1.1.1.1.cmml" xref="S2.F1.5.m2.1.1.1.1.1.1">conditional</csymbol><apply id="S2.F1.5.m2.1.1.1.1.1.2.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.F1.5.m2.1.1.1.1.1.2.1.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.F1.5.m2.1.1.1.1.1.2.2.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S2.F1.5.m2.1.1.1.1.1.2.3.cmml" xref="S2.F1.5.m2.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.F1.5.m2.1.1.1.1.1.3.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.F1.5.m2.1.1.1.1.1.3.1.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3">subscript</csymbol><ci id="S2.F1.5.m2.1.1.1.1.1.3.2.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S2.F1.5.m2.1.1.1.1.1.3.3.cmml" xref="S2.F1.5.m2.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.5.m2.1d">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.F1.5.m2.1e">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, independently. Additionally, a prediction loss is applied, compelling each masked token to regress towards the target tokens <math alttext="g_{i}" class="ltx_Math" display="inline" id="S2.F1.6.m3.1"><semantics id="S2.F1.6.m3.1b"><msub id="S2.F1.6.m3.1.1" xref="S2.F1.6.m3.1.1.cmml"><mi id="S2.F1.6.m3.1.1.2" xref="S2.F1.6.m3.1.1.2.cmml">g</mi><mi id="S2.F1.6.m3.1.1.3" xref="S2.F1.6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F1.6.m3.1c"><apply id="S2.F1.6.m3.1.1.cmml" xref="S2.F1.6.m3.1.1"><csymbol cd="ambiguous" id="S2.F1.6.m3.1.1.1.cmml" xref="S2.F1.6.m3.1.1">subscript</csymbol><ci id="S2.F1.6.m3.1.1.2.cmml" xref="S2.F1.6.m3.1.1.2">ğ‘”</ci><ci id="S2.F1.6.m3.1.1.3.cmml" xref="S2.F1.6.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.6.m3.1d">g_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.F1.6.m3.1e">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">D-JEPA is grounded in the principles of joint-embedding predictive architectures (JEPAs) and diffusion models. We provide an overview of these methodologies alongside a generalized next-token prediction strategy to facilitate an understanding of our approach.</p>
</div>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Joint-embedding predictive architectures (JEPAs).</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Self-supervised learning has transformed representation learning by enabling systems to uncover autonomously and model relationships within their inputs <cite class="ltx_cite ltx_citemacro_citep">(LeCun etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib63" title="">2006</a>)</cite>. Among these methods, joint-embedding predictive architectures (JEPAs)<cite class="ltx_cite ltx_citemacro_citep">(LeCun, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>; Bardes etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib11" title="">b</a>; Guetschel etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib39" title="">2024</a>)</cite> have gained prominence. JEPAs are designed to predict the embeddings of a target signal using a context signal processed through a predictor network, which is conditioned on an additional (potentially latent) variable, such as class labels.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.2">A significant challenge in deploying JEPAs is representation collapse, which occurs when the energy landscape flattens, causing the encoder to produce uniform outputs regardless of the inputs. This uniformity negates the advantages of learned representations <cite class="ltx_cite ltx_citemacro_citep">(Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>. Various strategies have been proposed to address this issue. Contrastive losses <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib42" title="">2019</a>; Chen &amp; He, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib22" title="">2021</a>)</cite> work by explicitly separating the embeddings of negative samples. Non-contrastive losses <cite class="ltx_cite ltx_citemacro_citep">(Zbontar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib121" title="">2021</a>; Bardes etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib9" title="">2021</a>)</cite> aims to reduce redundancies between embeddings, thereby improving robustness. Clustering-based methods <cite class="ltx_cite ltx_citemacro_citep">(Caron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib15" title="">2021</a>; Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib2" title="">2021</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib3" title="">2022</a>)</cite> increase the entropy of the aggregate embedding to maintain diversity. Additionally, heuristic approaches <cite class="ltx_cite ltx_citemacro_citep">(Chen &amp; He, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib22" title="">2021</a>; Grill etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>; Baevski etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>; Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite> often utilize asymmetric architectural designs between the context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="S2.SS0.SSS0.Px1.p2.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.1.m1.1d">italic_Ï•</annotation></semantics></math> and the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px1.p2.2.m2.1"><semantics id="S2.SS0.SSS0.Px1.p2.2.m2.1a"><mover accent="true" id="S2.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2.cmml">Ï•</mi><mo id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.2.m2.1b"><apply id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1"><ci id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.1">Â¯</ci><ci id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.2.m2.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p2.2.m2.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math> to prevent collapse.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p3.1">However, the issue of representation collapse is effectively mitigated in D-JEPA due to the introduction of an additional diffusion loss for the predicted embeddings. The diffusion loss does not reside in the same energy landscape as JEPAs, thus effectively avoiding model collapse. Consequently, similar to the approach in <cite class="ltx_cite ltx_citemacro_cite">LeCun (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>)</cite>, we can employ two identical networks as the context and target encoders. The parameters of the target encoder are efficiently updated through an exponential moving average method, significantly enhancing training efficiency and reducing the number of parameters that need to be learned. Refer to Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS2" title="3.2 Representation Learning with JEPAs â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.2</span></a> for more details.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Diffusion models.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.9">Denoising diffusion models provide a robust framework for modeling arbitrary distributions <cite class="ltx_cite ltx_citemacro_citep">(Croitoru etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib25" title="">2023</a>)</cite>. Given a ground truth sample <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.1.m1.1d">italic_x</annotation></semantics></math> conditioned on a variable <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S2.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.2.m2.1d">italic_z</annotation></semantics></math>, the objective is to model the conditional probability distribution <math alttext="p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1"><times id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3">ğ‘</ci><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3">ğ‘§</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.1c">p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.3.m3.1d">italic_p ( italic_x | italic_z )</annotation></semantics></math>. The sample <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="S2.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.4.m4.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.4.m4.1d">italic_x</annotation></semantics></math> could represent various domains, such as images in pixel space, features in latent space, or control signals in robotic systems <cite class="ltx_cite ltx_citemacro_citep">(Chi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib24" title="">2023</a>; Team etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib102" title="">2024</a>)</cite>. In our case, <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.5.m5.1"><semantics id="S2.SS0.SSS0.Px2.p1.5.m5.1a"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.5.m5.1b"><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.5.m5.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.5.m5.1d">italic_x</annotation></semantics></math> represents a token, while <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.6.m6.1"><semantics id="S2.SS0.SSS0.Px2.p1.6.m6.1a"><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.6.m6.1b"><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.6.m6.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.6.m6.1d">italic_z</annotation></semantics></math> contains information to aid in reconstructing <math alttext="x" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.7.m7.1"><semantics id="S2.SS0.SSS0.Px2.p1.7.m7.1a"><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.7.m7.1b"><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.7.m7.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.7.m7.1d">italic_x</annotation></semantics></math>; here, <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.8.m8.1"><semantics id="S2.SS0.SSS0.Px2.p1.8.m8.1a"><mi id="S2.SS0.SSS0.Px2.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.8.m8.1b"><ci id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.8.m8.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.8.m8.1d">italic_z</annotation></semantics></math> corresponds to the predicted embeddings by feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.9.m9.1"><semantics id="S2.SS0.SSS0.Px2.p1.9.m9.1a"><mi id="S2.SS0.SSS0.Px2.p1.9.m9.1.1" xref="S2.SS0.SSS0.Px2.p1.9.m9.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.9.m9.1b"><ci id="S2.SS0.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.9.m9.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.9.m9.1d">italic_Î³</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">Following the formulation presented in <cite class="ltx_cite ltx_citemacro_cite">Dhariwal &amp; Nichol (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>, we define the loss function for modeling the underlying probability distribution <math alttext="p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1"><times id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.3">ğ‘</ci><apply id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p2.1.m1.1.1.1.1.1.3">ğ‘§</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p2.1.m1.1c">p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p2.1.m1.1d">italic_p ( italic_x | italic_z )</annotation></semantics></math> using a denoising criterion:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}(z,x)=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-%
\varepsilon_{\theta}(x^{t}|t,z)\right\|^{2}\right]," class="ltx_math_unparsed" display="block" id="S2.E1.m1.6"><semantics id="S2.E1.m1.6a"><mrow id="S2.E1.m1.6b"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.6.7">â„’</mi><mrow id="S2.E1.m1.6.8"><mo id="S2.E1.m1.6.8.1" stretchy="false">(</mo><mi id="S2.E1.m1.3.3">z</mi><mo id="S2.E1.m1.6.8.2">,</mo><mi id="S2.E1.m1.4.4">x</mi><mo id="S2.E1.m1.6.8.3" stretchy="false">)</mo></mrow><mo id="S2.E1.m1.6.9">=</mo><msub id="S2.E1.m1.6.10"><mi id="S2.E1.m1.6.10.2">ğ”¼</mi><mrow id="S2.E1.m1.2.2.2.4"><mi id="S2.E1.m1.1.1.1.1">Îµ</mi><mo id="S2.E1.m1.2.2.2.4.1">,</mo><mi id="S2.E1.m1.2.2.2.2">t</mi></mrow></msub><mrow id="S2.E1.m1.6.11"><mo id="S2.E1.m1.6.11.1">[</mo><mo id="S2.E1.m1.6.11.2" lspace="0em" rspace="0.167em" stretchy="true">âˆ¥</mo><mi id="S2.E1.m1.6.11.3">Îµ</mi><mo id="S2.E1.m1.6.11.4">âˆ’</mo><msub id="S2.E1.m1.6.11.5"><mi id="S2.E1.m1.6.11.5.2">Îµ</mi><mi id="S2.E1.m1.6.11.5.3">Î¸</mi></msub><mrow id="S2.E1.m1.6.11.6"><mo id="S2.E1.m1.6.11.6.1" stretchy="false">(</mo><msup id="S2.E1.m1.6.11.6.2"><mi id="S2.E1.m1.6.11.6.2.2">x</mi><mi id="S2.E1.m1.6.11.6.2.3">t</mi></msup><mo fence="false" id="S2.E1.m1.6.11.6.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.E1.m1.5.5">t</mi><mo id="S2.E1.m1.6.11.6.4">,</mo><mi id="S2.E1.m1.6.6">z</mi><mo id="S2.E1.m1.6.11.6.5" stretchy="false">)</mo></mrow><msup id="S2.E1.m1.6.11.7"><mo id="S2.E1.m1.6.11.7.2" lspace="0em" rspace="0.167em" stretchy="true">âˆ¥</mo><mn id="S2.E1.m1.6.11.7.3">2</mn></msup><mo id="S2.E1.m1.6.11.8">]</mo></mrow><mo id="S2.E1.m1.6.12">,</mo></mrow><annotation encoding="application/x-tex" id="S2.E1.m1.6c">\mathcal{L}(z,x)=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-%
\varepsilon_{\theta}(x^{t}|t,z)\right\|^{2}\right],</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.6d">caligraphic_L ( italic_z , italic_x ) = blackboard_E start_POSTSUBSCRIPT italic_Îµ , italic_t end_POSTSUBSCRIPT [ âˆ¥ italic_Îµ - italic_Îµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT | italic_t , italic_z ) âˆ¥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p3.12">where <math alttext="\varepsilon" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p3.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p3.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p3.1.m1.1.1.cmml">Îµ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.1.m1.1.1">ğœ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.1.m1.1c">\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.1.m1.1d">italic_Îµ</annotation></semantics></math> represents a noise sample from the normal distribution <math alttext="\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.2.m2.2"><semantics id="S2.SS0.SSS0.Px2.p3.2.m2.2a"><mrow id="S2.SS0.SSS0.Px2.p3.2.m2.2.3" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2.cmml">ğ’©</mi><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2.1" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml">(</mo><mn id="S2.SS0.SSS0.Px2.p3.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p3.2.m2.1.1.cmml">ğŸ</mn><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px2.p3.2.m2.2.2" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.2.cmml">ğˆ</mi><mo id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.2.m2.2b"><apply id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3"><times id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.1"></times><ci id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.2">ğ’©</ci><interval closure="open" id="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.3.3.2"><cn id="S2.SS0.SSS0.Px2.p3.2.m2.1.1.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p3.2.m2.1.1">0</cn><ci id="S2.SS0.SSS0.Px2.p3.2.m2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.2.m2.2.2">ğˆ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.2.m2.2c">\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.2.m2.2d">caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math>. The noise-corrupted sample <math alttext="x^{t}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.3.m3.1"><semantics id="S2.SS0.SSS0.Px2.p3.3.m3.1a"><msup id="S2.SS0.SSS0.Px2.p3.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.3.m3.1b"><apply id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.3.m3.1c">x^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.3.m3.1d">italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> is expressed as <math alttext="x^{t}=\sqrt{\bar{\alpha}_{t}}x+\sqrt{1-\bar{\alpha}_{t}}\varepsilon" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.4.m4.1"><semantics id="S2.SS0.SSS0.Px2.p3.4.m4.1a"><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.cmml"><msup id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3.cmml">t</mi></msup><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1.cmml">=</mo><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.cmml"><msqrt id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.cmml"><msub id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.cmml"><mover accent="true" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2.cmml">Î±</mi><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1.cmml">Â¯</mo></mover><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3.cmml">t</mi></msub></msqrt><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1.cmml">â¢</mo><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3.cmml">x</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1.cmml">+</mo><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.cmml"><msqrt id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.cmml"><mn id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2.cmml">1</mn><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1.cmml">âˆ’</mo><msub id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2.cmml">Î±</mi><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1.cmml">Â¯</mo></mover><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1.cmml">â¢</mo><mi id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3.cmml">Îµ</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.4.m4.1b"><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1"><eq id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.1"></eq><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.2.3">ğ‘¡</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3"><plus id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.1"></plus><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2"><times id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.1"></times><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2"><root id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2a.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2"></root><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2"><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.1">Â¯</ci><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.2.2">ğ›¼</ci></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.2.2.3">ğ‘¡</ci></apply></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.2.3">ğ‘¥</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3"><times id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.1"></times><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2"><root id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2a.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2"></root><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2"><minus id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.1"></minus><cn id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.2">1</cn><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2"><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.1">Â¯</ci><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.2.2">ğ›¼</ci></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.2.2.3.3">ğ‘¡</ci></apply></apply></apply><ci id="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.4.m4.1.1.3.3.3">ğœ€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.4.m4.1c">x^{t}=\sqrt{\bar{\alpha}_{t}}x+\sqrt{1-\bar{\alpha}_{t}}\varepsilon</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.4.m4.1d">italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = square-root start_ARG overÂ¯ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_x + square-root start_ARG 1 - overÂ¯ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_Îµ</annotation></semantics></math>, with <math alttext="\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.5.m5.1"><semantics id="S2.SS0.SSS0.Px2.p3.5.m5.1a"><msub id="S2.SS0.SSS0.Px2.p3.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.cmml"><mover accent="true" id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2.cmml">Î±</mi><mo id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1.cmml">Â¯</mo></mover><mi id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.5.m5.1b"><apply id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1">subscript</csymbol><apply id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2"><ci id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.1">Â¯</ci><ci id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.2.2">ğ›¼</ci></apply><ci id="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.5.m5.1c">\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.5.m5.1d">overÂ¯ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> defining a noise schedule <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>; Nichol &amp; Dhariwal, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib75" title="">2021</a>)</cite> and <math alttext="t" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.6.m6.1"><semantics id="S2.SS0.SSS0.Px2.p3.6.m6.1a"><mi id="S2.SS0.SSS0.Px2.p3.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.6.m6.1b"><ci id="S2.SS0.SSS0.Px2.p3.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.6.m6.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.6.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.6.m6.1d">italic_t</annotation></semantics></math> indicating a specific time step within this schedule. The function <math alttext="\varepsilon_{\theta}(x^{t}|t,z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.7.m7.3"><semantics id="S2.SS0.SSS0.Px2.p3.7.m7.3a"><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.cmml"><msub id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.cmml"><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2.cmml">Îµ</mi><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3.cmml">Î¸</mi></msub><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml"><msup id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3.cmml">t</mi></msup><mo fence="false" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.1.1.cmml">t</mi><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.2.1" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px2.p3.7.m7.2.2" xref="S2.SS0.SSS0.Px2.p3.7.m7.2.2.cmml">z</mi></mrow></mrow><mo id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.7.m7.3b"><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3"><times id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.2"></times><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.2">ğœ€</ci><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.3.3">ğœƒ</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.1">conditional</csymbol><apply id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.2.3">ğ‘¡</ci></apply><list id="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.3.3.1.1.1.3.2"><ci id="S2.SS0.SSS0.Px2.p3.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.1.1">ğ‘¡</ci><ci id="S2.SS0.SSS0.Px2.p3.7.m7.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.7.m7.2.2">ğ‘§</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.7.m7.3c">\varepsilon_{\theta}(x^{t}|t,z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.7.m7.3d">italic_Îµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT | italic_t , italic_z )</annotation></semantics></math> denotes the network processing <math alttext="x^{t}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.8.m8.1"><semantics id="S2.SS0.SSS0.Px2.p3.8.m8.1a"><msup id="S2.SS0.SSS0.Px2.p3.8.m8.1.1" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.8.m8.1b"><apply id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.8.m8.1c">x^{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.8.m8.1d">italic_x start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>, conditioned on both <math alttext="t" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.9.m9.1"><semantics id="S2.SS0.SSS0.Px2.p3.9.m9.1a"><mi id="S2.SS0.SSS0.Px2.p3.9.m9.1.1" xref="S2.SS0.SSS0.Px2.p3.9.m9.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.9.m9.1b"><ci id="S2.SS0.SSS0.Px2.p3.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.9.m9.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.9.m9.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.9.m9.1d">italic_t</annotation></semantics></math> and <math alttext="z" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.10.m10.1"><semantics id="S2.SS0.SSS0.Px2.p3.10.m10.1a"><mi id="S2.SS0.SSS0.Px2.p3.10.m10.1.1" xref="S2.SS0.SSS0.Px2.p3.10.m10.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.10.m10.1b"><ci id="S2.SS0.SSS0.Px2.p3.10.m10.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.10.m10.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.10.m10.1c">z</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.10.m10.1d">italic_z</annotation></semantics></math>. As discussed in <cite class="ltx_cite ltx_citemacro_cite">Song &amp; Ermon (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib96" title="">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Song etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib97" title="">2021</a>)</cite>, Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.E1" title="In Diffusion models. â€£ 2 Background â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> acts as a form of score matching, associated with a loss function regarding the score function of <math alttext="p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.11.m11.1"><semantics id="S2.SS0.SSS0.Px2.p3.11.m11.1a"><mrow id="S2.SS0.SSS0.Px2.p3.11.m11.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.11.m11.1b"><apply id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1"><times id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.3">ğ‘</ci><apply id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.11.m11.1.1.1.1.1.3">ğ‘§</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.11.m11.1c">p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.11.m11.1d">italic_p ( italic_x | italic_z )</annotation></semantics></math>, represented as <math alttext="\nabla\log_{x}p(x|z)" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.12.m12.1"><semantics id="S2.SS0.SSS0.Px2.p3.12.m12.1a"><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.cmml"><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1" rspace="0.167em" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1.cmml">âˆ‡</mo><msub id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2.cmml">log</mi><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3.cmml">x</mi></msub></mrow><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3a" lspace="0.167em" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.cmml">â¡</mo><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2.cmml">p</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3.cmml">z</mi></mrow><mo id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.12.m12.1b"><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1"><times id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.2"></times><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3"><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1"><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.1">âˆ‡</ci><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2">subscript</csymbol><log id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.2"></log><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.1.2.3">ğ‘¥</ci></apply></apply><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.3.2">ğ‘</ci></apply><apply id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p3.12.m12.1.1.1.1.1.3">ğ‘§</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.12.m12.1c">\nabla\log_{x}p(x|z)</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.12.m12.1d">âˆ‡ roman_log start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_p ( italic_x | italic_z )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p4.3">Unlike typical applications of diffusion models that represent the joint distribution of all pixels or tokens, our approach leverages the diffusion model to represent the distribution of individual tokens following <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p4.3.1">i.e.</span>, <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p4.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p4.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3.cmml">p</mi><mo id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2.cmml">â¢</mo><mrow id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml"><msub id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1"><times id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.3">ğ‘</ci><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.1.m1.1c">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.1.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. This allows us to simultaneously apply both diffusion loss and prediction loss to the tokens. Consequently, the noise estimator <math alttext="\varepsilon_{\theta}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.2.m2.1"><semantics id="S2.SS0.SSS0.Px2.p4.2.m2.1a"><msub id="S2.SS0.SSS0.Px2.p4.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2.cmml">Îµ</mi><mi id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.2.m2.1b"><apply id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.2">ğœ€</ci><ci id="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p4.2.m2.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.2.m2.1c">\varepsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.2.m2.1d">italic_Îµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, parameterized by <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.3.m3.1"><semantics id="S2.SS0.SSS0.Px2.p4.3.m3.1a"><mi id="S2.SS0.SSS0.Px2.p4.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p4.3.m3.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.3.m3.1b"><ci id="S2.SS0.SSS0.Px2.p4.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.3.m3.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.3.m3.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.3.m3.1d">italic_Î¸</annotation></semantics></math>, can be efficiently modeled using a small MLP network in our case. This significantly enhances the efficiency of the denoising process in the continuous space. Further details are provided in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS3" title="3.3 Diffusion Learning with a Denoising MLP â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Generalized next-token prediction.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Next-token prediction, or autoregressive modeling, typically predicts the next token based on preceding tokens, establishing a sequential dependency <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib83" title="">2018</a>)</cite>. Generalized next-token prediction techniques, such as MaskGIT <cite class="ltx_cite ltx_citemacro_citep">(Chang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite> and MAGE <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>, integrate an MAE-style <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> encoder and decoder with positional embeddings to streamline the prediction process. This approach facilitates interaction among known tokens and accelerates inference by generating multiple tokens per step, as demonstrated in the next set-of-token prediction strategies like MAR <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, even without key-value caching <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib92" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">Our D-JEPA model extends these innovations by integrating the masked image modeling approach as a generalized next-token prediction strategy to facilitate an autoregressive generation manner. We can flexibly adjust the number of tokens predicted in each step by controlling the auto-regressive steps. Contrary to the intuition formed by existing methodsÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>, the best performance under the D-JEPA architecture is not achieved when the auto-regressive steps are maximized, <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px3.p2.1.1">i.e.</span>, when the generalized next-token prediction predicts only one token at a time. Moreover, as the scale of the model parameters increases, the number of auto-regressive steps required to achieve the best sampling results decreases accordingly. This fully demonstrates that converting the masked image modeling method into a next-token prediction strategy is not only feasible but also highly effective. Refer to the Experiment part in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4" title="4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> for more analysis.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we will first introduce how to convert masked image modeling into the next-token prediction. Following this, we will explain how representation learning and diffusion learning coexist within D-JEPA. Finally, we will describe how to generate samples using the generalized next-token prediction approach. The overall architecture of D-JEPA is illustrated in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.F1" title="Figure 1 â€£ 2 Background â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.4">For clarity, we denote a sequence of tokens using blackboard bold letters, such as <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">ğ•</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ğ•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">blackboard_X</annotation></semantics></math>, with individual tokens represented by lowercase letters with subscripts (<span class="ltx_text ltx_font_italic" id="S3.p2.4.1">e.g.</span>, <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><msub id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml">x</mi><mi id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> as a token in <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="S3.p2.3.m3.1"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">ğ•</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">ğ•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.1d">blackboard_X</annotation></semantics></math>). The notation <math alttext="|\mathbb{X}|" class="ltx_Math" display="inline" id="S3.p2.4.m4.1"><semantics id="S3.p2.4.m4.1a"><mrow id="S3.p2.4.m4.1.2.2" xref="S3.p2.4.m4.1.2.1.cmml"><mo id="S3.p2.4.m4.1.2.2.1" stretchy="false" xref="S3.p2.4.m4.1.2.1.1.cmml">|</mo><mi id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">ğ•</mi><mo id="S3.p2.4.m4.1.2.2.2" stretchy="false" xref="S3.p2.4.m4.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.2.1.cmml" xref="S3.p2.4.m4.1.2.2"><abs id="S3.p2.4.m4.1.2.1.1.cmml" xref="S3.p2.4.m4.1.2.2.1"></abs><ci id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">ğ•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">|\mathbb{X}|</annotation><annotation encoding="application/x-llamapun" id="S3.p2.4.m4.1d">| blackboard_X |</annotation></semantics></math> indicates the number of tokens in the sequence.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Tokenization and Masking</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.3">In masked image modeling, certain image regions are randomly masked during training, prompting the feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_Î³</annotation></semantics></math> to predict the content of these masked areas based on the context (unmasked) regions. In representation learning, masking is typically applied directly to raw pixels <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>; Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, and it has been observed that masking contiguous regions significantly enhances the representation learning capability. This is crucial, as it implies that when we patchify an image into tokens, we can randomly mask tokens without degrading performance since each token inherently represents a continuous region. Based on this, we can patchify images into non-overlapping semantic tokens <math alttext="\mathbb{U}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">ğ•Œ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ•Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbb{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">blackboard_U</annotation></semantics></math> based on a specific patch size <math alttext="p" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_p</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Although images are directly segmented into patches on raw pixels, which is also the standard practice in visual transformers <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>, recent generative models <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; Rombach etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite> tend to first encode images into the latent space using a VAE before performing patchification, arguing that this significantly reduces the training cost of generative models and accelerates the sampling speed. However, we found that this approach noticeably degrades D-JEPAâ€™s performance in representation tasks.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>More analysis about D-JEPAâ€™s performance in representation tasks have been listed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS2" title="E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">E.2</span></a>.</span></span></span> Since the primary goal of this work is to ensure that D-JEPA functions as an outstanding generative model, we adopted the latent space modeling strategy initially proposed by <cite class="ltx_cite ltx_citemacro_cite">Rombach etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite>. (It is important to note that <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">training in latent space is not a necessity for D-JEPA</span>; it can be trained in raw space and still achieve excellent results.)</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.3">Subsequently, we perform random masking on these tokens. Masking ratios <math alttext="r_{mask}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">r</mi><mrow id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS1.p3.1.m1.1.1.3.2" xref="S3.SS1.p3.1.m1.1.1.3.2.cmml">m</mi><mo id="S3.SS1.p3.1.m1.1.1.3.1" xref="S3.SS1.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS1.p3.1.m1.1.1.3.3" xref="S3.SS1.p3.1.m1.1.1.3.3.cmml">a</mi><mo id="S3.SS1.p3.1.m1.1.1.3.1a" xref="S3.SS1.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS1.p3.1.m1.1.1.3.4" xref="S3.SS1.p3.1.m1.1.1.3.4.cmml">s</mi><mo id="S3.SS1.p3.1.m1.1.1.3.1b" xref="S3.SS1.p3.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S3.SS1.p3.1.m1.1.1.3.5" xref="S3.SS1.p3.1.m1.1.1.3.5.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3"><times id="S3.SS1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS1.p3.1.m1.1.1.3.1"></times><ci id="S3.SS1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS1.p3.1.m1.1.1.3.2">ğ‘š</ci><ci id="S3.SS1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3.3">ğ‘</ci><ci id="S3.SS1.p3.1.m1.1.1.3.4.cmml" xref="S3.SS1.p3.1.m1.1.1.3.4">ğ‘ </ci><ci id="S3.SS1.p3.1.m1.1.1.3.5.cmml" xref="S3.SS1.p3.1.m1.1.1.3.5">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">r_{mask}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_r start_POSTSUBSCRIPT italic_m italic_a italic_s italic_k end_POSTSUBSCRIPT</annotation></semantics></math> are sampled from a truncated normal distribution with a mean of 1.0, a standard deviation of 0.25, and a lower bound of 0.7. Consequently, more than 70% of the tokens are randomly masked. This results in a sequence of randomly masked tokens of length <math alttext="\lceil r_{mask}\cdot|\mathbb{U}|\rceil" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.2"><semantics id="S3.SS1.p3.2.m2.2a"><mrow id="S3.SS1.p3.2.m2.2.2.1" xref="S3.SS1.p3.2.m2.2.2.2.cmml"><mo id="S3.SS1.p3.2.m2.2.2.1.2" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.2.1.cmml">âŒˆ</mo><mrow id="S3.SS1.p3.2.m2.2.2.1.1" xref="S3.SS1.p3.2.m2.2.2.1.1.cmml"><msub id="S3.SS1.p3.2.m2.2.2.1.1.2" xref="S3.SS1.p3.2.m2.2.2.1.1.2.cmml"><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.2" xref="S3.SS1.p3.2.m2.2.2.1.1.2.2.cmml">r</mi><mrow id="S3.SS1.p3.2.m2.2.2.1.1.2.3" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.cmml"><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.2" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.2.cmml">m</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.3" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.3.cmml">a</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1a" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.4" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.4.cmml">s</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1b" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS1.p3.2.m2.2.2.1.1.2.3.5" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.5.cmml">k</mi></mrow></msub><mo id="S3.SS1.p3.2.m2.2.2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p3.2.m2.2.2.1.1.1.cmml">â‹…</mo><mrow id="S3.SS1.p3.2.m2.2.2.1.1.3.2" xref="S3.SS1.p3.2.m2.2.2.1.1.3.1.cmml"><mo id="S3.SS1.p3.2.m2.2.2.1.1.3.2.1" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.1.1.3.1.1.cmml">|</mo><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">ğ•Œ</mi><mo id="S3.SS1.p3.2.m2.2.2.1.1.3.2.2" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.1.1.3.1.1.cmml">|</mo></mrow></mrow><mo id="S3.SS1.p3.2.m2.2.2.1.3" stretchy="false" xref="S3.SS1.p3.2.m2.2.2.2.1.cmml">âŒ‰</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.2b"><apply id="S3.SS1.p3.2.m2.2.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1"><ceiling id="S3.SS1.p3.2.m2.2.2.2.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.2"></ceiling><apply id="S3.SS1.p3.2.m2.2.2.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1"><ci id="S3.SS1.p3.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.1">â‹…</ci><apply id="S3.SS1.p3.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.2.2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2">subscript</csymbol><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.2">ğ‘Ÿ</ci><apply id="S3.SS1.p3.2.m2.2.2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3"><times id="S3.SS1.p3.2.m2.2.2.1.1.2.3.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.1"></times><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.2.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.2">ğ‘š</ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.3.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.3">ğ‘</ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.4.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.4">ğ‘ </ci><ci id="S3.SS1.p3.2.m2.2.2.1.1.2.3.5.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.2.3.5">ğ‘˜</ci></apply></apply><apply id="S3.SS1.p3.2.m2.2.2.1.1.3.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.3.2"><abs id="S3.SS1.p3.2.m2.2.2.1.1.3.1.1.cmml" xref="S3.SS1.p3.2.m2.2.2.1.1.3.2.1"></abs><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ğ•Œ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.2c">\lceil r_{mask}\cdot|\mathbb{U}|\rceil</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.2d">âŒˆ italic_r start_POSTSUBSCRIPT italic_m italic_a italic_s italic_k end_POSTSUBSCRIPT â‹… | blackboard_U | âŒ‰</annotation></semantics></math>, and a sequence of remaining unmasked tokens, <math alttext="\mathbb{Y}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><mi id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">ğ•</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><ci id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">ğ•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathbb{Y}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">blackboard_Y</annotation></semantics></math>. Masking a substantial portion of tokens reduces both pre-training time and memory usage while improving performance, consistent with findings in previous works<cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>; Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; Assran etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Representation Learning with JEPAs</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Earlier masked image modeling methods, such as MAE <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>, directly use a decoder network to predict the missing raw pixels. This approach gives these models some outpainting capabilities (i.e., completing missing parts of an image), but they still cannot directly generate high-quality images. Subsequent works, such as DiffMAE <cite class="ltx_cite ltx_citemacro_citep">(Wei etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib110" title="">2023</a>)</cite>, attempted to leverage diffusion models within MAE to enhance the image generation capabilities of these models, but the results were limited. Moreover, this direct raw pixel prediction approach severely restricts the modelâ€™s representation ability, especially compared to models like CLIPÂ <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib85" title="">2021</a>)</cite>, which use contrastive learning on massive datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.6">Meanwhile, a new architecture called JEPA has gained widespread attention and was successfully applied to representation learning on ImageNet by <cite class="ltx_cite ltx_citemacro_cite">Assran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, achieving excellent results. JEPA does not directly predict the missing raw pixels; instead, it uses a separate feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_Î³</annotation></semantics></math> to predict the target embedding <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> corresponding to the missing parts. The target embedding <math alttext="g_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğ‘”</ci><ci id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">g_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, generated by the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><mover accent="true" id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">Ï•</mi><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><ci id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1">Â¯</ci><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math> by feeding all tokensÂ (<math alttext="\mathbb{U}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">ğ•Œ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">ğ•Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\mathbb{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">blackboard_U</annotation></semantics></math>), is used as the ground truth for <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><msub id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">z</mi><mi id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">ğ‘§</ci><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.8">The prediction loss objective for unsupervised representation learning on each masked token is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{p}=\mathbb{E}_{z_{i}=\psi(c_{i}),g_{i}}\left[\mathcal{D}(u_{%
\theta}(z_{i}),g_{i})\right]," class="ltx_Math" display="block" id="S3.E2.m1.3"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.3.2" xref="S3.E2.m1.3.3.1.1.3.2.cmml">â„’</mi><mi id="S3.E2.m1.3.3.1.1.3.3" xref="S3.E2.m1.3.3.1.1.3.3.cmml">p</mi></msub><mo id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.3.2.cmml">ğ”¼</mi><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><msub id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.4.cmml"><mi id="S3.E2.m1.2.2.2.4.2" xref="S3.E2.m1.2.2.2.4.2.cmml">z</mi><mi id="S3.E2.m1.2.2.2.4.3" xref="S3.E2.m1.2.2.2.4.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.2.3.cmml">=</mo><mrow id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">Ïˆ</mi><mo id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.2.cmml">g</mi><mi id="S3.E2.m1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.2.3.cmml">i</mi></msub></mrow></mrow></msub><mo id="S3.E2.m1.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.1.1.1.1.1.1.4" xref="S3.E2.m1.3.3.1.1.1.1.1.1.4.cmml">ğ’Ÿ</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml">â¢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml">u</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.4" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml">g</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.5" stretchy="false" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"></eq><apply id="S3.E2.m1.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2">â„’</ci><ci id="S3.E2.m1.3.3.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.3.3">ğ‘</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"></times><apply id="S3.E2.m1.3.3.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.3.2">ğ”¼</ci><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><eq id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.3"></eq><apply id="S3.E2.m1.2.2.2.4.cmml" xref="S3.E2.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.4.1.cmml" xref="S3.E2.m1.2.2.2.4">subscript</csymbol><ci id="S3.E2.m1.2.2.2.4.2.cmml" xref="S3.E2.m1.2.2.2.4.2">ğ‘§</ci><ci id="S3.E2.m1.2.2.2.4.3.cmml" xref="S3.E2.m1.2.2.2.4.3">ğ‘–</ci></apply><list id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">ğœ“</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.2">ğ‘”</ci><ci id="S3.E2.m1.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3">ğ‘–</ci></apply></list></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.3"></times><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.4">ğ’Ÿ</ci><interval closure="open" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2"><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.2">ğ‘¢</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.2">ğ‘”</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\mathcal{L}_{p}=\mathbb{E}_{z_{i}=\psi(c_{i}),g_{i}}\left[\mathcal{D}(u_{%
\theta}(z_{i}),g_{i})\right],</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.3d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_Ïˆ ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ caligraphic_D ( italic_u start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.7">where <math alttext="\mathcal{D}(u_{\theta}(z_{i}),g_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.2"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.1.m1.2.2.4" xref="S3.SS2.p3.1.m1.2.2.4.cmml">ğ’Ÿ</mi><mo id="S3.SS2.p3.1.m1.2.2.3" xref="S3.SS2.p3.1.m1.2.2.3.cmml">â¢</mo><mrow id="S3.SS2.p3.1.m1.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml"><mo id="S3.SS2.p3.1.m1.2.2.2.2.3" stretchy="false" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">(</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.2.cmml">u</mi><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.1.m1.2.2.2.2.4" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">,</mo><msub id="S3.SS2.p3.1.m1.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2.cmml">g</mi><mi id="S3.SS2.p3.1.m1.2.2.2.2.2.3" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p3.1.m1.2.2.2.2.5" stretchy="false" xref="S3.SS2.p3.1.m1.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><apply id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2"><times id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.3"></times><ci id="S3.SS2.p3.1.m1.2.2.4.cmml" xref="S3.SS2.p3.1.m1.2.2.4">ğ’Ÿ</ci><interval closure="open" id="S3.SS2.p3.1.m1.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2"><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2"></times><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.2">ğ‘¢</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.SS2.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.2">ğ‘”</ci><ci id="S3.SS2.p3.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.2.2.2.3">ğ‘–</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">\mathcal{D}(u_{\theta}(z_{i}),g_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.2d">caligraphic_D ( italic_u start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is a distance measure function, and <math alttext="u_{\theta}(z_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mrow id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><msub id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS2.p3.2.m2.1.1.3.2" xref="S3.SS2.p3.2.m2.1.1.3.2.cmml">u</mi><mi id="S3.SS2.p3.2.m2.1.1.3.3" xref="S3.SS2.p3.2.m2.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><times id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2"></times><apply id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.p3.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.p3.2.m2.1.1.3.2">ğ‘¢</ci><ci id="S3.SS2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3.3">ğœƒ</ci></apply><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">u_{\theta}(z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_u start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is the projection feature of <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msub id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">z</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">ğ‘§</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> using a two-layer MLP <math alttext="u_{\theta}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">u</mi><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">ğ‘¢</ci><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">u_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_u start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>. This loss is optimized exclusively for masked tokens, as optimizing for all tokens has been shown to diminish both generative and representational performance, as noted in <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>); Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>. In fact, the choice of distance measure function <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">caligraphic_D</annotation></semantics></math> in Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a> is relatively flexible. In <cite class="ltx_cite ltx_citemacro_cite">Assran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, the MSE function was chosen, while <cite class="ltx_cite ltx_citemacro_cite">Bardes etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>)</cite> used the <math alttext="l_{1}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">l</mi><mn id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">ğ‘™</ci><cn id="S3.SS2.p3.6.m6.1.1.3.cmml" type="integer" xref="S3.SS2.p3.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">l_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> function. Here, we use the smoothed <math alttext="l_{1}" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><msub id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">l</mi><mn id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">ğ‘™</ci><cn id="S3.SS2.p3.7.m7.1.1.3.cmml" type="integer" xref="S3.SS2.p3.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">l_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> function, following <cite class="ltx_cite ltx_citemacro_cite">Baevski etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>)</cite>, which we found to be more stable.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">Since JEPA predicts feature embeddings, they cannot be directly used for generation tasks or even outpainting. Experiments show that token embeddings trained with JEPA can only reconstruct image content somewhat related to the surrounding context and are almost incapable of generating high-quality imagesÂ <cite class="ltx_cite ltx_citemacro_citep">(Bardes etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>)</cite>. This further diminishes the consideration of JEPA architecture as a generative model. Here, we surprisingly find that as long as the JEPA training process also includes generative task training, excellent generative results can be achieved, which will be elaborated on in the next section.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.5">We use three identical visual transformers as the context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_Ï•</annotation></semantics></math>, target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mover accent="true" id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml"><mi id="S3.SS2.p5.2.m2.1.1.2" xref="S3.SS2.p5.2.m2.1.1.2.cmml">Ï•</mi><mo id="S3.SS2.p5.2.m2.1.1.1" xref="S3.SS2.p5.2.m2.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><apply id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1"><ci id="S3.SS2.p5.2.m2.1.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1.1">Â¯</ci><ci id="S3.SS2.p5.2.m2.1.1.2.cmml" xref="S3.SS2.p5.2.m2.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math>, and feature predictor <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.p5.3.m3.1"><semantics id="S3.SS2.p5.3.m3.1a"><mi id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><ci id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.3.m3.1d">italic_Î³</annotation></semantics></math>. The parameters of <math alttext="\phi" class="ltx_Math" display="inline" id="S3.SS2.p5.4.m4.1"><semantics id="S3.SS2.p5.4.m4.1a"><mi id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><ci id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.4.m4.1d">italic_Ï•</annotation></semantics></math> and <math alttext="\gamma" class="ltx_Math" display="inline" id="S3.SS2.p5.5.m5.1"><semantics id="S3.SS2.p5.5.m5.1a"><mi id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><ci id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.5.m5.1d">italic_Î³</annotation></semantics></math> are randomly initialized and then updated with a gradient descent method. The parameters of the target encoder are initialized identically to the context encoder and then updated via an exponentially moving average of the context encoder parameters:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\bar{\phi}\leftarrow\alpha\bar{\phi}+(1-\alpha)\phi," class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">Ï•</mi><mo id="S3.E3.m1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.3.1.cmml">Â¯</mo></mover><mo id="S3.E3.m1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.2.cmml">â†</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.3.2.cmml">Î±</mi><mo id="S3.E3.m1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.3.1.cmml">â¢</mo><mover accent="true" id="S3.E3.m1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.3.3.2.cmml">Ï•</mi><mo id="S3.E3.m1.1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.1.3.3.1.cmml">Â¯</mo></mover></mrow><mo id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml">Î±</mi></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">â¢</mo><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">Ï•</mi></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><ci id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2">â†</ci><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><ci id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.1">Â¯</ci><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">italic-Ï•</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2"></plus><apply id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2">ğ›¼</ci><apply id="S3.E3.m1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3"><ci id="S3.E3.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.1">Â¯</ci><ci id="S3.E3.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.2">italic-Ï•</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3">ğ›¼</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">italic-Ï•</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\bar{\phi}\leftarrow\alpha\bar{\phi}+(1-\alpha)\phi,</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">overÂ¯ start_ARG italic_Ï• end_ARG â† italic_Î± overÂ¯ start_ARG italic_Ï• end_ARG + ( 1 - italic_Î± ) italic_Ï• ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p5.8">where <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.p5.6.m1.1"><semantics id="S3.SS2.p5.6.m1.1a"><mi id="S3.SS2.p5.6.m1.1.1" xref="S3.SS2.p5.6.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.6.m1.1b"><ci id="S3.SS2.p5.6.m1.1.1.cmml" xref="S3.SS2.p5.6.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.6.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.6.m1.1d">italic_Î±</annotation></semantics></math> controls the update frequency. In <cite class="ltx_cite ltx_citemacro_cite">Bardes etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib10" title="">2023a</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Assran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, a linear warmup is applied to gradually increase <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS2.p5.7.m2.1"><semantics id="S3.SS2.p5.7.m2.1a"><mi id="S3.SS2.p5.7.m2.1.1" xref="S3.SS2.p5.7.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.7.m2.1b"><ci id="S3.SS2.p5.7.m2.1.1.cmml" xref="S3.SS2.p5.7.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.7.m2.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.7.m2.1d">italic_Î±</annotation></semantics></math> from a smaller value to a larger one to effectively control the update speed of the target encoder, thereby preventing the model collapse. Thanks to the constraint of diffusion loss, for D-JEPA, we simply use a constant <math alttext="\alpha=0.9999" class="ltx_Math" display="inline" id="S3.SS2.p5.8.m3.1"><semantics id="S3.SS2.p5.8.m3.1a"><mrow id="S3.SS2.p5.8.m3.1.1" xref="S3.SS2.p5.8.m3.1.1.cmml"><mi id="S3.SS2.p5.8.m3.1.1.2" xref="S3.SS2.p5.8.m3.1.1.2.cmml">Î±</mi><mo id="S3.SS2.p5.8.m3.1.1.1" xref="S3.SS2.p5.8.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p5.8.m3.1.1.3" xref="S3.SS2.p5.8.m3.1.1.3.cmml">0.9999</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.8.m3.1b"><apply id="S3.SS2.p5.8.m3.1.1.cmml" xref="S3.SS2.p5.8.m3.1.1"><eq id="S3.SS2.p5.8.m3.1.1.1.cmml" xref="S3.SS2.p5.8.m3.1.1.1"></eq><ci id="S3.SS2.p5.8.m3.1.1.2.cmml" xref="S3.SS2.p5.8.m3.1.1.2">ğ›¼</ci><cn id="S3.SS2.p5.8.m3.1.1.3.cmml" type="float" xref="S3.SS2.p5.8.m3.1.1.3">0.9999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.8.m3.1c">\alpha=0.9999</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.8.m3.1d">italic_Î± = 0.9999</annotation></semantics></math>, which is sufficient.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.3">In Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, <math alttext="g_{i}=\text{sg}(\bar{\phi}(\mathbb{U}))" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.2"><semantics id="S3.SS2.p6.1.m1.2a"><mrow id="S3.SS2.p6.1.m1.2.2" xref="S3.SS2.p6.1.m1.2.2.cmml"><msub id="S3.SS2.p6.1.m1.2.2.3" xref="S3.SS2.p6.1.m1.2.2.3.cmml"><mi id="S3.SS2.p6.1.m1.2.2.3.2" xref="S3.SS2.p6.1.m1.2.2.3.2.cmml">g</mi><mi id="S3.SS2.p6.1.m1.2.2.3.3" xref="S3.SS2.p6.1.m1.2.2.3.3.cmml">i</mi></msub><mo id="S3.SS2.p6.1.m1.2.2.2" xref="S3.SS2.p6.1.m1.2.2.2.cmml">=</mo><mrow id="S3.SS2.p6.1.m1.2.2.1" xref="S3.SS2.p6.1.m1.2.2.1.cmml"><mtext id="S3.SS2.p6.1.m1.2.2.1.3" xref="S3.SS2.p6.1.m1.2.2.1.3a.cmml">sg</mtext><mo id="S3.SS2.p6.1.m1.2.2.1.2" xref="S3.SS2.p6.1.m1.2.2.1.2.cmml">â¢</mo><mrow id="S3.SS2.p6.1.m1.2.2.1.1.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml"><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.2" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p6.1.m1.2.2.1.1.1.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml"><mover accent="true" id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.cmml"><mi id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2.cmml">Ï•</mi><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1.cmml">Â¯</mo></mover><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.1" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.SS2.p6.1.m1.2.2.1.1.1.1.3.2" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml"><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.3.2.1" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">(</mo><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">ğ•Œ</mi><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.1.3.2.2" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p6.1.m1.2.2.1.1.1.3" stretchy="false" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.2b"><apply id="S3.SS2.p6.1.m1.2.2.cmml" xref="S3.SS2.p6.1.m1.2.2"><eq id="S3.SS2.p6.1.m1.2.2.2.cmml" xref="S3.SS2.p6.1.m1.2.2.2"></eq><apply id="S3.SS2.p6.1.m1.2.2.3.cmml" xref="S3.SS2.p6.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p6.1.m1.2.2.3.1.cmml" xref="S3.SS2.p6.1.m1.2.2.3">subscript</csymbol><ci id="S3.SS2.p6.1.m1.2.2.3.2.cmml" xref="S3.SS2.p6.1.m1.2.2.3.2">ğ‘”</ci><ci id="S3.SS2.p6.1.m1.2.2.3.3.cmml" xref="S3.SS2.p6.1.m1.2.2.3.3">ğ‘–</ci></apply><apply id="S3.SS2.p6.1.m1.2.2.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1"><times id="S3.SS2.p6.1.m1.2.2.1.2.cmml" xref="S3.SS2.p6.1.m1.2.2.1.2"></times><ci id="S3.SS2.p6.1.m1.2.2.1.3a.cmml" xref="S3.SS2.p6.1.m1.2.2.1.3"><mtext id="S3.SS2.p6.1.m1.2.2.1.3.cmml" xref="S3.SS2.p6.1.m1.2.2.1.3">sg</mtext></ci><apply id="S3.SS2.p6.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1"><times id="S3.SS2.p6.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.1"></times><apply id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2"><ci id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.1">Â¯</ci><ci id="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.SS2.p6.1.m1.2.2.1.1.1.1.2.2">italic-Ï•</ci></apply><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">ğ•Œ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.2c">g_{i}=\text{sg}(\bar{\phi}(\mathbb{U}))</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.2d">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = sg ( overÂ¯ start_ARG italic_Ï• end_ARG ( blackboard_U ) )</annotation></semantics></math>, where <math alttext="\text{sg}(\cdot)" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mrow id="S3.SS2.p6.2.m2.1.2" xref="S3.SS2.p6.2.m2.1.2.cmml"><mtext id="S3.SS2.p6.2.m2.1.2.2" xref="S3.SS2.p6.2.m2.1.2.2a.cmml">sg</mtext><mo id="S3.SS2.p6.2.m2.1.2.1" xref="S3.SS2.p6.2.m2.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.p6.2.m2.1.2.3.2" xref="S3.SS2.p6.2.m2.1.2.cmml"><mo id="S3.SS2.p6.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS2.p6.2.m2.1.2.cmml">(</mo><mo id="S3.SS2.p6.2.m2.1.1" lspace="0em" rspace="0em" xref="S3.SS2.p6.2.m2.1.1.cmml">â‹…</mo><mo id="S3.SS2.p6.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS2.p6.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><apply id="S3.SS2.p6.2.m2.1.2.cmml" xref="S3.SS2.p6.2.m2.1.2"><times id="S3.SS2.p6.2.m2.1.2.1.cmml" xref="S3.SS2.p6.2.m2.1.2.1"></times><ci id="S3.SS2.p6.2.m2.1.2.2a.cmml" xref="S3.SS2.p6.2.m2.1.2.2"><mtext id="S3.SS2.p6.2.m2.1.2.2.cmml" xref="S3.SS2.p6.2.m2.1.2.2">sg</mtext></ci><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">\text{sg}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">sg ( â‹… )</annotation></semantics></math> denotes a stop-gradient operation, which does not backpropagate through its argument. This ensures that the parameters of the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><mover accent="true" id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml"><mi id="S3.SS2.p6.3.m3.1.1.2" xref="S3.SS2.p6.3.m3.1.1.2.cmml">Ï•</mi><mo id="S3.SS2.p6.3.m3.1.1.1" xref="S3.SS2.p6.3.m3.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><apply id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1"><ci id="S3.SS2.p6.3.m3.1.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1.1">Â¯</ci><ci id="S3.SS2.p6.3.m3.1.1.2.cmml" xref="S3.SS2.p6.3.m3.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math> are updated only through exponentially moving average , <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.3.1">i.e.</span>, Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E3" title="In 3.2 Representation Learning with JEPAs â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3</span></a>, a strategy that has been used to prevent collapse in image pre-training <cite class="ltx_cite ltx_citemacro_citep">(Grill etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>)</cite>, and studied empirically <cite class="ltx_cite ltx_citemacro_citep">(Xie etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib112" title="">2022</a>)</cite> and theoretically <cite class="ltx_cite ltx_citemacro_citep">(Tian etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib104" title="">2021</a>)</cite>Â <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>A theoretical motivation for the effectiveness of this collapse prevention strategy is proposed in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.SS1" title="E.1 Theoretical motivation â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">E.1</span></a>.</span></span></span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Diffusion Learning with a Denoising MLP</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">Our method diverges from traditional approaches by focusing on learning the conditional distribution <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">p</mi><mo id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS3.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.2.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p1.1.m1.1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><times id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"></times><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ğ‘</ci><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> for each token, given <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, rather than capturing the distribution of entire images. This approach eliminates the need to denoise the entire JEPA model, as some prior works require <cite class="ltx_cite ltx_citemacro_cite">Hatamizadeh etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib40" title="">2023</a>); Peebles &amp; Xie (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>); Wei etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib110" title="">2023</a>)</cite>, allowing us to utilize a significantly smaller network to model each token individually.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.6">Hence, the denoising loss objective can be formulated by slightly modifying Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S2.E1" title="In Diffusion models. â€£ 2 Background â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> to model the token distribution as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{d}=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-\varepsilon%
_{\theta}(x_{i}^{t}|t,z_{i})\right\|^{2}\right]." class="ltx_math_unparsed" display="block" id="S3.E4.m1.3"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3b"><msub id="S3.E4.m1.3.4"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.3.4.2">â„’</mi><mi id="S3.E4.m1.3.4.3">d</mi></msub><mo id="S3.E4.m1.3.5">=</mo><msub id="S3.E4.m1.3.6"><mi id="S3.E4.m1.3.6.2">ğ”¼</mi><mrow id="S3.E4.m1.2.2.2.4"><mi id="S3.E4.m1.1.1.1.1">Îµ</mi><mo id="S3.E4.m1.2.2.2.4.1">,</mo><mi id="S3.E4.m1.2.2.2.2">t</mi></mrow></msub><mrow id="S3.E4.m1.3.7"><mo id="S3.E4.m1.3.7.1">[</mo><mo id="S3.E4.m1.3.7.2" lspace="0em" rspace="0.167em" stretchy="true">âˆ¥</mo><mi id="S3.E4.m1.3.7.3">Îµ</mi><mo id="S3.E4.m1.3.7.4">âˆ’</mo><msub id="S3.E4.m1.3.7.5"><mi id="S3.E4.m1.3.7.5.2">Îµ</mi><mi id="S3.E4.m1.3.7.5.3">Î¸</mi></msub><mrow id="S3.E4.m1.3.7.6"><mo id="S3.E4.m1.3.7.6.1" stretchy="false">(</mo><msubsup id="S3.E4.m1.3.7.6.2"><mi id="S3.E4.m1.3.7.6.2.2.2">x</mi><mi id="S3.E4.m1.3.7.6.2.2.3">i</mi><mi id="S3.E4.m1.3.7.6.2.3">t</mi></msubsup><mo fence="false" id="S3.E4.m1.3.7.6.3" rspace="0.167em" stretchy="false">|</mo><mi id="S3.E4.m1.3.3">t</mi><mo id="S3.E4.m1.3.7.6.4">,</mo><msub id="S3.E4.m1.3.7.6.5"><mi id="S3.E4.m1.3.7.6.5.2">z</mi><mi id="S3.E4.m1.3.7.6.5.3">i</mi></msub><mo id="S3.E4.m1.3.7.6.6" stretchy="false">)</mo></mrow><msup id="S3.E4.m1.3.7.7"><mo id="S3.E4.m1.3.7.7.2" lspace="0em" rspace="0.167em" stretchy="true">âˆ¥</mo><mn id="S3.E4.m1.3.7.7.3">2</mn></msup><mo id="S3.E4.m1.3.7.8">]</mo></mrow><mo id="S3.E4.m1.3.8" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\mathcal{L}_{d}=\mathbb{E}_{\varepsilon,t}\left[\left\|\varepsilon-\varepsilon%
_{\theta}(x_{i}^{t}|t,z_{i})\right\|^{2}\right].</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.3d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_Îµ , italic_t end_POSTSUBSCRIPT [ âˆ¥ italic_Îµ - italic_Îµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT | italic_t , italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) âˆ¥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p2.5">For denoising, we employ a compact multi-layer perceptron (MLP) comprising a few residual blocks <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib41" title="">2016</a>)</cite> as <math alttext="\varepsilon_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">Îµ</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ğœ€</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\varepsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_Îµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>. Each block sequentially applies LayerNorm (LN) <cite class="ltx_cite ltx_citemacro_citep">(Ba etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib5" title="">2016</a>)</cite>, a linear layer, the SiLU activation function <cite class="ltx_cite ltx_citemacro_citep">(Elfwing etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib30" title="">2018</a>)</cite>, and another linear layer, integrated with a residual connection, following <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>.
<math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is added to the time embedding of the noise schedule time-step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">italic_t</annotation></semantics></math>, then conditions the MLP in the LN layers via AdaLN <cite class="ltx_cite ltx_citemacro_citep">(Peebles &amp; Xie, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>. During training, we independently sample <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">italic_t</annotation></semantics></math> four times for each token to maximize the utilization of the diffusion loss without recomputing <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS3.p2.5.m5.1"><semantics id="S3.SS3.p2.5.m5.1a"><msub id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml"><mi id="S3.SS3.p2.5.m5.1.1.2" xref="S3.SS3.p2.5.m5.1.1.2.cmml">z</mi><mi id="S3.SS3.p2.5.m5.1.1.3" xref="S3.SS3.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><apply id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.5.m5.1.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p2.5.m5.1.1.2.cmml" xref="S3.SS3.p2.5.m5.1.1.2">ğ‘§</ci><ci id="S3.SS3.p2.5.m5.1.1.3.cmml" xref="S3.SS3.p2.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.5.m5.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">At inference time, it is required to draw samples from the distribution <math alttext="p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mrow id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">p</mi><mo id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p3.1.m1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS3.p3.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p3.1.m1.1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml"><msub id="S3.SS3.p3.1.m1.1.1.1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.2.2" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.2.3" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p3.1.m1.1.1.1.1.1.1" xref="S3.SS3.p3.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p3.1.m1.1.1.1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.3.2" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p3.1.m1.1.1.1.1.1.3.3" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p3.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p3.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><times id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2"></times><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">ğ‘</ci><apply id="S3.SS3.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.SS3.p3.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.1.m1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. Sampling is done via a reverse diffusion procedure <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x^{i}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(x^{i}_{t}-\frac{1-\alpha_{t}}{%
\sqrt{1-\bar{\alpha}_{t}}}\varepsilon_{\theta}(x^{i}_{t}|t,z_{i})\right)+%
\sigma_{t}\delta," class="ltx_Math" display="block" id="S3.Ex1.m1.2"><semantics id="S3.Ex1.m1.2a"><mrow id="S3.Ex1.m1.2.2.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1" xref="S3.Ex1.m1.2.2.1.1.cmml"><msubsup id="S3.Ex1.m1.2.2.1.1.3" xref="S3.Ex1.m1.2.2.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.3.2.2.cmml">x</mi><mrow id="S3.Ex1.m1.2.2.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.3.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.3.3.2" xref="S3.Ex1.m1.2.2.1.1.3.3.2.cmml">t</mi><mo id="S3.Ex1.m1.2.2.1.1.3.3.1" xref="S3.Ex1.m1.2.2.1.1.3.3.1.cmml">âˆ’</mo><mn id="S3.Ex1.m1.2.2.1.1.3.3.3" xref="S3.Ex1.m1.2.2.1.1.3.3.3.cmml">1</mn></mrow><mi id="S3.Ex1.m1.2.2.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.Ex1.m1.2.2.1.1.2" xref="S3.Ex1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.Ex1.m1.2.2.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.cmml"><mfrac id="S3.Ex1.m1.2.2.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.3.cmml"><mn id="S3.Ex1.m1.2.2.1.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.3.2.cmml">1</mn><msqrt id="S3.Ex1.m1.2.2.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.cmml"><msub id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2.cmml">Î±</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3.cmml">t</mi></msub></msqrt></mfrac><mo id="S3.Ex1.m1.2.2.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml"><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">t</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mfrac id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml"><mn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml">1</mn><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml">âˆ’</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2.cmml">Î±</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3.cmml">t</mi></msub></mrow><msqrt id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml"><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml"><mn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2.cmml">1</mn><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1.cmml">âˆ’</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.cmml"><mover accent="true" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2.cmml">Î±</mi><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1.cmml">Â¯</mo></mover><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3.cmml">t</mi></msub></mrow></msqrt></mfrac><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml">Îµ</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml">Î¸</mi></msub><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2a" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msubsup><mo fence="false" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">t</mi><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.1.1.2" xref="S3.Ex1.m1.2.2.1.1.1.2.cmml">+</mo><mrow id="S3.Ex1.m1.2.2.1.1.1.3" xref="S3.Ex1.m1.2.2.1.1.1.3.cmml"><msub id="S3.Ex1.m1.2.2.1.1.1.3.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.cmml"><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.2" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2.cmml">Ïƒ</mi><mi id="S3.Ex1.m1.2.2.1.1.1.3.2.3" xref="S3.Ex1.m1.2.2.1.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.Ex1.m1.2.2.1.1.1.3.1" xref="S3.Ex1.m1.2.2.1.1.1.3.1.cmml">â¢</mo><mi id="S3.Ex1.m1.2.2.1.1.1.3.3" xref="S3.Ex1.m1.2.2.1.1.1.3.3.cmml">Î´</mi></mrow></mrow></mrow><mo id="S3.Ex1.m1.2.2.1.2" xref="S3.Ex1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.2b"><apply id="S3.Ex1.m1.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.1"><eq id="S3.Ex1.m1.2.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.2"></eq><apply id="S3.Ex1.m1.2.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3.2.2">ğ‘¥</ci><ci id="S3.Ex1.m1.2.2.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3"><minus id="S3.Ex1.m1.2.2.1.1.3.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3.1"></minus><ci id="S3.Ex1.m1.2.2.1.1.3.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.3.3.2">ğ‘¡</ci><cn id="S3.Ex1.m1.2.2.1.1.3.3.3.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.3.3.3">1</cn></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1"><plus id="S3.Ex1.m1.2.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.2"></plus><apply id="S3.Ex1.m1.2.2.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.2"></times><apply id="S3.Ex1.m1.2.2.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3"><divide id="S3.Ex1.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3"></divide><cn id="S3.Ex1.m1.2.2.1.1.1.1.3.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.1.1.3.2">1</cn><apply id="S3.Ex1.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3"><root id="S3.Ex1.m1.2.2.1.1.1.1.3.3a.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3"></root><apply id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.2">ğ›¼</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.3.3.2.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.2"></minus><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.2.3">ğ‘–</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1"><times id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.2"></times><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3"><divide id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3"></divide><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.1"></minus><cn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.2">1</cn><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2">ğ›¼</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3">ğ‘¡</ci></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3"><root id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3a.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3"></root><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2"><minus id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1"></minus><cn id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2.cmml" type="integer" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2">1</cn><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2"><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1">Â¯</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2">ğ›¼</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3">ğ‘¡</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.2">ğœ€</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.4.3">ğœƒ</ci></apply><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.3">ğ‘–</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><list id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">ğ‘¡</ci><apply id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></list></apply></apply></apply></apply><apply id="S3.Ex1.m1.2.2.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3"><times id="S3.Ex1.m1.2.2.1.1.1.3.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.1"></times><apply id="S3.Ex1.m1.2.2.1.1.1.3.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.2">ğœ</ci><ci id="S3.Ex1.m1.2.2.1.1.1.3.2.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.2.3">ğ‘¡</ci></apply><ci id="S3.Ex1.m1.2.2.1.1.1.3.3.cmml" xref="S3.Ex1.m1.2.2.1.1.1.3.3">ğ›¿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.2c">x^{i}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(x^{i}_{t}-\frac{1-\alpha_{t}}{%
\sqrt{1-\bar{\alpha}_{t}}}\varepsilon_{\theta}(x^{i}_{t}|t,z_{i})\right)+%
\sigma_{t}\delta,</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.2d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG ( italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 - italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 1 - overÂ¯ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_Îµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_t , italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) + italic_Ïƒ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_Î´ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p3.8">where <math alttext="\delta" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m1.1"><semantics id="S3.SS3.p3.2.m1.1a"><mi id="S3.SS3.p3.2.m1.1.1" xref="S3.SS3.p3.2.m1.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m1.1b"><ci id="S3.SS3.p3.2.m1.1.1.cmml" xref="S3.SS3.p3.2.m1.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m1.1c">\delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m1.1d">italic_Î´</annotation></semantics></math> is sampled from the Gaussian distribution <math alttext="\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m2.2"><semantics id="S3.SS3.p3.3.m2.2a"><mrow id="S3.SS3.p3.3.m2.2.3" xref="S3.SS3.p3.3.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m2.2.3.2" xref="S3.SS3.p3.3.m2.2.3.2.cmml">ğ’©</mi><mo id="S3.SS3.p3.3.m2.2.3.1" xref="S3.SS3.p3.3.m2.2.3.1.cmml">â¢</mo><mrow id="S3.SS3.p3.3.m2.2.3.3.2" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml"><mo id="S3.SS3.p3.3.m2.2.3.3.2.1" stretchy="false" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml">(</mo><mn id="S3.SS3.p3.3.m2.1.1" xref="S3.SS3.p3.3.m2.1.1.cmml">ğŸ</mn><mo id="S3.SS3.p3.3.m2.2.3.3.2.2" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml">,</mo><mi id="S3.SS3.p3.3.m2.2.2" xref="S3.SS3.p3.3.m2.2.2.cmml">ğˆ</mi><mo id="S3.SS3.p3.3.m2.2.3.3.2.3" stretchy="false" xref="S3.SS3.p3.3.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m2.2b"><apply id="S3.SS3.p3.3.m2.2.3.cmml" xref="S3.SS3.p3.3.m2.2.3"><times id="S3.SS3.p3.3.m2.2.3.1.cmml" xref="S3.SS3.p3.3.m2.2.3.1"></times><ci id="S3.SS3.p3.3.m2.2.3.2.cmml" xref="S3.SS3.p3.3.m2.2.3.2">ğ’©</ci><interval closure="open" id="S3.SS3.p3.3.m2.2.3.3.1.cmml" xref="S3.SS3.p3.3.m2.2.3.3.2"><cn id="S3.SS3.p3.3.m2.1.1.cmml" type="integer" xref="S3.SS3.p3.3.m2.1.1">0</cn><ci id="S3.SS3.p3.3.m2.2.2.cmml" xref="S3.SS3.p3.3.m2.2.2">ğˆ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m2.2c">\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m2.2d">caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math> and <math alttext="\sigma_{t}" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m3.1"><semantics id="S3.SS3.p3.4.m3.1a"><msub id="S3.SS3.p3.4.m3.1.1" xref="S3.SS3.p3.4.m3.1.1.cmml"><mi id="S3.SS3.p3.4.m3.1.1.2" xref="S3.SS3.p3.4.m3.1.1.2.cmml">Ïƒ</mi><mi id="S3.SS3.p3.4.m3.1.1.3" xref="S3.SS3.p3.4.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m3.1b"><apply id="S3.SS3.p3.4.m3.1.1.cmml" xref="S3.SS3.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m3.1.1.1.cmml" xref="S3.SS3.p3.4.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m3.1.1.2.cmml" xref="S3.SS3.p3.4.m3.1.1.2">ğœ</ci><ci id="S3.SS3.p3.4.m3.1.1.3.cmml" xref="S3.SS3.p3.4.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m3.1c">\sigma_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m3.1d">italic_Ïƒ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the noise level at time step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m4.1"><semantics id="S3.SS3.p3.5.m4.1a"><mi id="S3.SS3.p3.5.m4.1.1" xref="S3.SS3.p3.5.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m4.1b"><ci id="S3.SS3.p3.5.m4.1.1.cmml" xref="S3.SS3.p3.5.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m4.1d">italic_t</annotation></semantics></math>. Starting with <math alttext="x^{i}_{T}\sim\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m5.2"><semantics id="S3.SS3.p3.6.m5.2a"><mrow id="S3.SS3.p3.6.m5.2.3" xref="S3.SS3.p3.6.m5.2.3.cmml"><msubsup id="S3.SS3.p3.6.m5.2.3.2" xref="S3.SS3.p3.6.m5.2.3.2.cmml"><mi id="S3.SS3.p3.6.m5.2.3.2.2.2" xref="S3.SS3.p3.6.m5.2.3.2.2.2.cmml">x</mi><mi id="S3.SS3.p3.6.m5.2.3.2.3" xref="S3.SS3.p3.6.m5.2.3.2.3.cmml">T</mi><mi id="S3.SS3.p3.6.m5.2.3.2.2.3" xref="S3.SS3.p3.6.m5.2.3.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS3.p3.6.m5.2.3.1" xref="S3.SS3.p3.6.m5.2.3.1.cmml">âˆ¼</mo><mrow id="S3.SS3.p3.6.m5.2.3.3" xref="S3.SS3.p3.6.m5.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.6.m5.2.3.3.2" xref="S3.SS3.p3.6.m5.2.3.3.2.cmml">ğ’©</mi><mo id="S3.SS3.p3.6.m5.2.3.3.1" xref="S3.SS3.p3.6.m5.2.3.3.1.cmml">â¢</mo><mrow id="S3.SS3.p3.6.m5.2.3.3.3.2" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml"><mo id="S3.SS3.p3.6.m5.2.3.3.3.2.1" stretchy="false" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml">(</mo><mn id="S3.SS3.p3.6.m5.1.1" xref="S3.SS3.p3.6.m5.1.1.cmml">ğŸ</mn><mo id="S3.SS3.p3.6.m5.2.3.3.3.2.2" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml">,</mo><mi id="S3.SS3.p3.6.m5.2.2" xref="S3.SS3.p3.6.m5.2.2.cmml">ğˆ</mi><mo id="S3.SS3.p3.6.m5.2.3.3.3.2.3" stretchy="false" xref="S3.SS3.p3.6.m5.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m5.2b"><apply id="S3.SS3.p3.6.m5.2.3.cmml" xref="S3.SS3.p3.6.m5.2.3"><csymbol cd="latexml" id="S3.SS3.p3.6.m5.2.3.1.cmml" xref="S3.SS3.p3.6.m5.2.3.1">similar-to</csymbol><apply id="S3.SS3.p3.6.m5.2.3.2.cmml" xref="S3.SS3.p3.6.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m5.2.3.2.1.cmml" xref="S3.SS3.p3.6.m5.2.3.2">subscript</csymbol><apply id="S3.SS3.p3.6.m5.2.3.2.2.cmml" xref="S3.SS3.p3.6.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m5.2.3.2.2.1.cmml" xref="S3.SS3.p3.6.m5.2.3.2">superscript</csymbol><ci id="S3.SS3.p3.6.m5.2.3.2.2.2.cmml" xref="S3.SS3.p3.6.m5.2.3.2.2.2">ğ‘¥</ci><ci id="S3.SS3.p3.6.m5.2.3.2.2.3.cmml" xref="S3.SS3.p3.6.m5.2.3.2.2.3">ğ‘–</ci></apply><ci id="S3.SS3.p3.6.m5.2.3.2.3.cmml" xref="S3.SS3.p3.6.m5.2.3.2.3">ğ‘‡</ci></apply><apply id="S3.SS3.p3.6.m5.2.3.3.cmml" xref="S3.SS3.p3.6.m5.2.3.3"><times id="S3.SS3.p3.6.m5.2.3.3.1.cmml" xref="S3.SS3.p3.6.m5.2.3.3.1"></times><ci id="S3.SS3.p3.6.m5.2.3.3.2.cmml" xref="S3.SS3.p3.6.m5.2.3.3.2">ğ’©</ci><interval closure="open" id="S3.SS3.p3.6.m5.2.3.3.3.1.cmml" xref="S3.SS3.p3.6.m5.2.3.3.3.2"><cn id="S3.SS3.p3.6.m5.1.1.cmml" type="integer" xref="S3.SS3.p3.6.m5.1.1">0</cn><ci id="S3.SS3.p3.6.m5.2.2.cmml" xref="S3.SS3.p3.6.m5.2.2">ğˆ</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m5.2c">x^{i}_{T}\sim\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.6.m5.2d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT âˆ¼ caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math>, this procedure produces a sample <math alttext="x^{i}_{0}" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m6.1"><semantics id="S3.SS3.p3.7.m6.1a"><msubsup id="S3.SS3.p3.7.m6.1.1" xref="S3.SS3.p3.7.m6.1.1.cmml"><mi id="S3.SS3.p3.7.m6.1.1.2.2" xref="S3.SS3.p3.7.m6.1.1.2.2.cmml">x</mi><mn id="S3.SS3.p3.7.m6.1.1.3" xref="S3.SS3.p3.7.m6.1.1.3.cmml">0</mn><mi id="S3.SS3.p3.7.m6.1.1.2.3" xref="S3.SS3.p3.7.m6.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m6.1b"><apply id="S3.SS3.p3.7.m6.1.1.cmml" xref="S3.SS3.p3.7.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m6.1.1.1.cmml" xref="S3.SS3.p3.7.m6.1.1">subscript</csymbol><apply id="S3.SS3.p3.7.m6.1.1.2.cmml" xref="S3.SS3.p3.7.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m6.1.1.2.1.cmml" xref="S3.SS3.p3.7.m6.1.1">superscript</csymbol><ci id="S3.SS3.p3.7.m6.1.1.2.2.cmml" xref="S3.SS3.p3.7.m6.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p3.7.m6.1.1.2.3.cmml" xref="S3.SS3.p3.7.m6.1.1.2.3">ğ‘–</ci></apply><cn id="S3.SS3.p3.7.m6.1.1.3.cmml" type="integer" xref="S3.SS3.p3.7.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m6.1c">x^{i}_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.7.m6.1d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> such that <math alttext="x^{i}_{0}\sim p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p3.8.m7.1"><semantics id="S3.SS3.p3.8.m7.1a"><mrow id="S3.SS3.p3.8.m7.1.1" xref="S3.SS3.p3.8.m7.1.1.cmml"><msubsup id="S3.SS3.p3.8.m7.1.1.3" xref="S3.SS3.p3.8.m7.1.1.3.cmml"><mi id="S3.SS3.p3.8.m7.1.1.3.2.2" xref="S3.SS3.p3.8.m7.1.1.3.2.2.cmml">x</mi><mn id="S3.SS3.p3.8.m7.1.1.3.3" xref="S3.SS3.p3.8.m7.1.1.3.3.cmml">0</mn><mi id="S3.SS3.p3.8.m7.1.1.3.2.3" xref="S3.SS3.p3.8.m7.1.1.3.2.3.cmml">i</mi></msubsup><mo id="S3.SS3.p3.8.m7.1.1.2" xref="S3.SS3.p3.8.m7.1.1.2.cmml">âˆ¼</mo><mrow id="S3.SS3.p3.8.m7.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.cmml"><mi id="S3.SS3.p3.8.m7.1.1.1.3" xref="S3.SS3.p3.8.m7.1.1.1.3.cmml">p</mi><mo id="S3.SS3.p3.8.m7.1.1.1.2" xref="S3.SS3.p3.8.m7.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p3.8.m7.1.1.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml"><mo id="S3.SS3.p3.8.m7.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p3.8.m7.1.1.1.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.1" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p3.8.m7.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m7.1b"><apply id="S3.SS3.p3.8.m7.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1"><csymbol cd="latexml" id="S3.SS3.p3.8.m7.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.2">similar-to</csymbol><apply id="S3.SS3.p3.8.m7.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.3.1.cmml" xref="S3.SS3.p3.8.m7.1.1.3">subscript</csymbol><apply id="S3.SS3.p3.8.m7.1.1.3.2.cmml" xref="S3.SS3.p3.8.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.3.2.1.cmml" xref="S3.SS3.p3.8.m7.1.1.3">superscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.3.2.2.cmml" xref="S3.SS3.p3.8.m7.1.1.3.2.2">ğ‘¥</ci><ci id="S3.SS3.p3.8.m7.1.1.3.2.3.cmml" xref="S3.SS3.p3.8.m7.1.1.3.2.3">ğ‘–</ci></apply><cn id="S3.SS3.p3.8.m7.1.1.3.3.cmml" type="integer" xref="S3.SS3.p3.8.m7.1.1.3.3">0</cn></apply><apply id="S3.SS3.p3.8.m7.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1"><times id="S3.SS3.p3.8.m7.1.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.2"></times><ci id="S3.SS3.p3.8.m7.1.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.3">ğ‘</ci><apply id="S3.SS3.p3.8.m7.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.8.m7.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m7.1c">x^{i}_{0}\sim p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.8.m7.1d">italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT âˆ¼ italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.7">We adopt the temperature sampling method presented in <cite class="ltx_cite ltx_citemacro_cite">Dhariwal &amp; Nichol (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>); Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>. Conceptually, with a temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><mi id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><ci id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_Ï„</annotation></semantics></math>, one would sample from the (renormalized) probability <math alttext="p(x_{i}|z_{i})^{\frac{1}{\tau}}" class="ltx_Math" display="inline" id="S3.SS3.p4.2.m2.1"><semantics id="S3.SS3.p4.2.m2.1a"><mrow id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">p</mi><mo id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">â¢</mo><msup id="S3.SS3.p4.2.m2.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.cmml"><mrow id="S3.SS3.p4.2.m2.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml"><mo id="S3.SS3.p4.2.m2.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.2.m2.1.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p4.2.m2.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mfrac id="S3.SS3.p4.2.m2.1.1.1.3" xref="S3.SS3.p4.2.m2.1.1.1.3.cmml"><mn id="S3.SS3.p4.2.m2.1.1.1.3.2" xref="S3.SS3.p4.2.m2.1.1.1.3.2.cmml">1</mn><mi id="S3.SS3.p4.2.m2.1.1.1.3.3" xref="S3.SS3.p4.2.m2.1.1.1.3.3.cmml">Ï„</mi></mfrac></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><times id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2"></times><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">ğ‘</ci><apply id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1">superscript</csymbol><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply><apply id="S3.SS3.p4.2.m2.1.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.3"><divide id="S3.SS3.p4.2.m2.1.1.1.3.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1.3"></divide><cn id="S3.SS3.p4.2.m2.1.1.1.3.2.cmml" type="integer" xref="S3.SS3.p4.2.m2.1.1.1.3.2">1</cn><ci id="S3.SS3.p4.2.m2.1.1.1.3.3.cmml" xref="S3.SS3.p4.2.m2.1.1.1.3.3">ğœ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">p(x_{i}|z_{i})^{\frac{1}{\tau}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.2.m2.1d">italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG italic_Ï„ end_ARG end_POSTSUPERSCRIPT</annotation></semantics></math>, whose score function is <math alttext="\frac{1}{\tau}\nabla\log p(x_{i}|z_{i})" class="ltx_Math" display="inline" id="S3.SS3.p4.3.m3.1"><semantics id="S3.SS3.p4.3.m3.1a"><mrow id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml"><mfrac id="S3.SS3.p4.3.m3.1.1.3" xref="S3.SS3.p4.3.m3.1.1.3.cmml"><mn id="S3.SS3.p4.3.m3.1.1.3.2" xref="S3.SS3.p4.3.m3.1.1.3.2.cmml">1</mn><mi id="S3.SS3.p4.3.m3.1.1.3.3" xref="S3.SS3.p4.3.m3.1.1.3.3.cmml">Ï„</mi></mfrac><mo id="S3.SS3.p4.3.m3.1.1.2" lspace="0.167em" xref="S3.SS3.p4.3.m3.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p4.3.m3.1.1.4" xref="S3.SS3.p4.3.m3.1.1.4.cmml"><mrow id="S3.SS3.p4.3.m3.1.1.4.1" xref="S3.SS3.p4.3.m3.1.1.4.1.cmml"><mo id="S3.SS3.p4.3.m3.1.1.4.1.1" rspace="0.167em" xref="S3.SS3.p4.3.m3.1.1.4.1.1.cmml">âˆ‡</mo><mi id="S3.SS3.p4.3.m3.1.1.4.1.2" xref="S3.SS3.p4.3.m3.1.1.4.1.2.cmml">log</mi></mrow><mo id="S3.SS3.p4.3.m3.1.1.4a" lspace="0.167em" xref="S3.SS3.p4.3.m3.1.1.4.cmml">â¡</mo><mi id="S3.SS3.p4.3.m3.1.1.4.2" xref="S3.SS3.p4.3.m3.1.1.4.2.cmml">p</mi></mrow><mo id="S3.SS3.p4.3.m3.1.1.2a" xref="S3.SS3.p4.3.m3.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p4.3.m3.1.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS3.p4.3.m3.1.1.1.1.2" stretchy="false" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p4.3.m3.1.1.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml"><msub id="S3.SS3.p4.3.m3.1.1.1.1.1.2" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.2.2" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.2.3" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S3.SS3.p4.3.m3.1.1.1.1.1.1" xref="S3.SS3.p4.3.m3.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS3.p4.3.m3.1.1.1.1.1.3" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.3.2" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p4.3.m3.1.1.1.1.1.3.3" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S3.SS3.p4.3.m3.1.1.1.1.3" stretchy="false" xref="S3.SS3.p4.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><apply id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1"><times id="S3.SS3.p4.3.m3.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.2"></times><apply id="S3.SS3.p4.3.m3.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3"><divide id="S3.SS3.p4.3.m3.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.3"></divide><cn id="S3.SS3.p4.3.m3.1.1.3.2.cmml" type="integer" xref="S3.SS3.p4.3.m3.1.1.3.2">1</cn><ci id="S3.SS3.p4.3.m3.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.3.3">ğœ</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.4.cmml" xref="S3.SS3.p4.3.m3.1.1.4"><apply id="S3.SS3.p4.3.m3.1.1.4.1.cmml" xref="S3.SS3.p4.3.m3.1.1.4.1"><ci id="S3.SS3.p4.3.m3.1.1.4.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.4.1.1">âˆ‡</ci><log id="S3.SS3.p4.3.m3.1.1.4.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.4.1.2"></log></apply><ci id="S3.SS3.p4.3.m3.1.1.4.2.cmml" xref="S3.SS3.p4.3.m3.1.1.4.2">ğ‘</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS3.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p4.3.m3.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.SS3.p4.3.m3.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p4.3.m3.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">\frac{1}{\tau}\nabla\log p(x_{i}|z_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.3.m3.1d">divide start_ARG 1 end_ARG start_ARG italic_Ï„ end_ARG âˆ‡ roman_log italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. Intuitively, we adjust the noise variance <math alttext="\sigma_{t}\delta" class="ltx_Math" display="inline" id="S3.SS3.p4.4.m4.1"><semantics id="S3.SS3.p4.4.m4.1a"><mrow id="S3.SS3.p4.4.m4.1.1" xref="S3.SS3.p4.4.m4.1.1.cmml"><msub id="S3.SS3.p4.4.m4.1.1.2" xref="S3.SS3.p4.4.m4.1.1.2.cmml"><mi id="S3.SS3.p4.4.m4.1.1.2.2" xref="S3.SS3.p4.4.m4.1.1.2.2.cmml">Ïƒ</mi><mi id="S3.SS3.p4.4.m4.1.1.2.3" xref="S3.SS3.p4.4.m4.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS3.p4.4.m4.1.1.1" xref="S3.SS3.p4.4.m4.1.1.1.cmml">â¢</mo><mi id="S3.SS3.p4.4.m4.1.1.3" xref="S3.SS3.p4.4.m4.1.1.3.cmml">Î´</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.4.m4.1b"><apply id="S3.SS3.p4.4.m4.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1"><times id="S3.SS3.p4.4.m4.1.1.1.cmml" xref="S3.SS3.p4.4.m4.1.1.1"></times><apply id="S3.SS3.p4.4.m4.1.1.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p4.4.m4.1.1.2.1.cmml" xref="S3.SS3.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.p4.4.m4.1.1.2.2.cmml" xref="S3.SS3.p4.4.m4.1.1.2.2">ğœ</ci><ci id="S3.SS3.p4.4.m4.1.1.2.3.cmml" xref="S3.SS3.p4.4.m4.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS3.p4.4.m4.1.1.3.cmml" xref="S3.SS3.p4.4.m4.1.1.3">ğ›¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.4.m4.1c">\sigma_{t}\delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.4.m4.1d">italic_Ïƒ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_Î´</annotation></semantics></math> in the sampler by <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS3.p4.5.m5.1"><semantics id="S3.SS3.p4.5.m5.1a"><mi id="S3.SS3.p4.5.m5.1.1" xref="S3.SS3.p4.5.m5.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.5.m5.1b"><ci id="S3.SS3.p4.5.m5.1.1.cmml" xref="S3.SS3.p4.5.m5.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.5.m5.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.5.m5.1d">italic_Ï„</annotation></semantics></math> to control the sample diversity. Experimentally, <math alttext="\tau=0.98" class="ltx_Math" display="inline" id="S3.SS3.p4.6.m6.1"><semantics id="S3.SS3.p4.6.m6.1a"><mrow id="S3.SS3.p4.6.m6.1.1" xref="S3.SS3.p4.6.m6.1.1.cmml"><mi id="S3.SS3.p4.6.m6.1.1.2" xref="S3.SS3.p4.6.m6.1.1.2.cmml">Ï„</mi><mo id="S3.SS3.p4.6.m6.1.1.1" xref="S3.SS3.p4.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS3.p4.6.m6.1.1.3" xref="S3.SS3.p4.6.m6.1.1.3.cmml">0.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.6.m6.1b"><apply id="S3.SS3.p4.6.m6.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1"><eq id="S3.SS3.p4.6.m6.1.1.1.cmml" xref="S3.SS3.p4.6.m6.1.1.1"></eq><ci id="S3.SS3.p4.6.m6.1.1.2.cmml" xref="S3.SS3.p4.6.m6.1.1.2">ğœ</ci><cn id="S3.SS3.p4.6.m6.1.1.3.cmml" type="float" xref="S3.SS3.p4.6.m6.1.1.3">0.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.6.m6.1c">\tau=0.98</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.6.m6.1d">italic_Ï„ = 0.98</annotation></semantics></math> and <math alttext="\tau=0.94" class="ltx_Math" display="inline" id="S3.SS3.p4.7.m7.1"><semantics id="S3.SS3.p4.7.m7.1a"><mrow id="S3.SS3.p4.7.m7.1.1" xref="S3.SS3.p4.7.m7.1.1.cmml"><mi id="S3.SS3.p4.7.m7.1.1.2" xref="S3.SS3.p4.7.m7.1.1.2.cmml">Ï„</mi><mo id="S3.SS3.p4.7.m7.1.1.1" xref="S3.SS3.p4.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS3.p4.7.m7.1.1.3" xref="S3.SS3.p4.7.m7.1.1.3.cmml">0.94</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.7.m7.1b"><apply id="S3.SS3.p4.7.m7.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1"><eq id="S3.SS3.p4.7.m7.1.1.1.cmml" xref="S3.SS3.p4.7.m7.1.1.1"></eq><ci id="S3.SS3.p4.7.m7.1.1.2.cmml" xref="S3.SS3.p4.7.m7.1.1.2">ğœ</ci><cn id="S3.SS3.p4.7.m7.1.1.3.cmml" type="float" xref="S3.SS3.p4.7.m7.1.1.3">0.94</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.7.m7.1c">\tau=0.94</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.7.m7.1d">italic_Ï„ = 0.94</annotation></semantics></math> are suitable for image generation with and without classifier-free guidance, respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1">Furthermore, we also introduce the recently popular <span class="ltx_text ltx_font_italic" id="S3.SS3.p5.1.1">flow matching loss</span> <cite class="ltx_cite ltx_citemacro_citep">(Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S3.SS3.p5.1.2">i.e.</span>, Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.E7" title="In Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a>, as an alternative to the denoising loss (Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E4" title="In 3.3 Diffusion Learning with a Denoising MLP â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a>). Overall, flow matching achieves faster convergence and generates higher-quality visual content, and it can be more easily adapted to different scenarios. However, for scenarios where the diffusion loss can converge, fully trained diffusion loss can achieve better performance than flow-matching loss. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Here, we discuss flow matching loss and diffusion loss, which are not equivalent to flow matching models and diffusion models. For a detailed analysis, please refer to AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">F</span></a>.</span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Training with D-JEPA</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.2">By choosing different training objectives, D-JEPA can seamlessly transition between representation learning and diffusion learning without any changes to the network architecture. Typically, when faced with multiple training objectives, one needs to carefully balance each component in the final loss objective to ensure the modelâ€™s effectivenesÂ <cite class="ltx_cite ltx_citemacro_citep">(Kendall etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib54" title="">2018</a>)</cite>. However, the prediction loss <math alttext="\mathcal{L}_{p}" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">â„’</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">â„’</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mathcal{L}_{p}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT</annotation></semantics></math> and the diffusion loss <math alttext="\mathcal{L}_{d}" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">â„’</mi><mi id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">â„’</ci><ci id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\mathcal{L}_{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> in D-JEPA do not have conflicting or mutually exclusive relationships.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p2">
<p class="ltx_p" id="S3.SS4.p2.1">The diffusion loss effectively prevents the potential representation collapse issue faced by the prediction loss, while the prediction loss can provide the diffusion model with higher-level semantic feature information <math alttext="z_{i}" class="ltx_Math" display="inline" id="S3.SS4.p2.1.m1.1"><semantics id="S3.SS4.p2.1.m1.1a"><msub id="S3.SS4.p2.1.m1.1.1" xref="S3.SS4.p2.1.m1.1.1.cmml"><mi id="S3.SS4.p2.1.m1.1.1.2" xref="S3.SS4.p2.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS4.p2.1.m1.1.1.3" xref="S3.SS4.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p2.1.m1.1b"><apply id="S3.SS4.p2.1.m1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p2.1.m1.1.1.1.cmml" xref="S3.SS4.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p2.1.m1.1.1.2.cmml" xref="S3.SS4.p2.1.m1.1.1.2">ğ‘§</ci><ci id="S3.SS4.p2.1.m1.1.1.3.cmml" xref="S3.SS4.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p2.1.m1.1c">z_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p2.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Therefore, the overall loss function can be simply defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}=\mathcal{L}_{d}+\mathcal{L}_{p}." class="ltx_Math" display="block" id="S3.Ex2.m1.1"><semantics id="S3.Ex2.m1.1a"><mrow id="S3.Ex2.m1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.cmml"><mrow id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.1.2.cmml">â„’</mi><mo id="S3.Ex2.m1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.Ex2.m1.1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.1.3.cmml"><msub id="S3.Ex2.m1.1.1.1.1.3.2" xref="S3.Ex2.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.1.1.1.1.3.2.2" xref="S3.Ex2.m1.1.1.1.1.3.2.2.cmml">â„’</mi><mi id="S3.Ex2.m1.1.1.1.1.3.2.3" xref="S3.Ex2.m1.1.1.1.1.3.2.3.cmml">d</mi></msub><mo id="S3.Ex2.m1.1.1.1.1.3.1" xref="S3.Ex2.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.1.1.1.1.3.3" xref="S3.Ex2.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex2.m1.1.1.1.1.3.3.2" xref="S3.Ex2.m1.1.1.1.1.3.3.2.cmml">â„’</mi><mi id="S3.Ex2.m1.1.1.1.1.3.3.3" xref="S3.Ex2.m1.1.1.1.1.3.3.3.cmml">p</mi></msub></mrow></mrow><mo id="S3.Ex2.m1.1.1.1.2" lspace="0em" xref="S3.Ex2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.1b"><apply id="S3.Ex2.m1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1"><eq id="S3.Ex2.m1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1"></eq><ci id="S3.Ex2.m1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1.2">â„’</ci><apply id="S3.Ex2.m1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3"><plus id="S3.Ex2.m1.1.1.1.1.3.1.cmml" xref="S3.Ex2.m1.1.1.1.1.3.1"></plus><apply id="S3.Ex2.m1.1.1.1.1.3.2.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.1.1.3.2.1.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.Ex2.m1.1.1.1.1.3.2.2.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2.2">â„’</ci><ci id="S3.Ex2.m1.1.1.1.1.3.2.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3.2.3">ğ‘‘</ci></apply><apply id="S3.Ex2.m1.1.1.1.1.3.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.1.1.1.1.3.3.1.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.Ex2.m1.1.1.1.1.3.3.2.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3.2">â„’</ci><ci id="S3.Ex2.m1.1.1.1.1.3.3.3.cmml" xref="S3.Ex2.m1.1.1.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.1c">\mathcal{L}=\mathcal{L}_{d}+\mathcal{L}_{p}.</annotation><annotation encoding="application/x-llamapun" id="S3.Ex2.m1.1d">caligraphic_L = caligraphic_L start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS4.p3">
<p class="ltx_p" id="S3.SS4.p3.1">Experiments show that this approach plays a crucial role in enabling D-JEPA to converge faster and achieve better results when scaling up the model.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Sampling in Next Set-of-Tokens Prediction</h3>
<div class="ltx_para ltx_noindent" id="S3.SS5.p1">
<p class="ltx_p" id="S3.SS5.p1.4">For the evaluation of generative models in generalized next-token prediction, we adopt an <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.4.1">iterative sampling</span> strategy analogous to those used in <cite class="ltx_cite ltx_citemacro_cite">Chang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>); Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, as shown in Algo.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#alg1" title="Algorithm 1 â€£ 3.5 Sampling in Next Set-of-Tokens Prediction â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>. This strategy gradually reduces the masking ratio from <math alttext="1.0" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><mn id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><cn id="S3.SS5.p1.1.m1.1.1.cmml" type="float" xref="S3.SS5.p1.1.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">1.0</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.1.m1.1d">1.0</annotation></semantics></math> to <math alttext="0.0" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1"><semantics id="S3.SS5.p1.2.m2.1a"><mn id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><cn id="S3.SS5.p1.2.m2.1.1.cmml" type="float" xref="S3.SS5.p1.2.m2.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">0.0</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.2.m2.1d">0.0</annotation></semantics></math> in accordance with a cosine schedule, typically utilizing <math alttext="64" class="ltx_Math" display="inline" id="S3.SS5.p1.3.m3.1"><semantics id="S3.SS5.p1.3.m3.1a"><mn id="S3.SS5.p1.3.m3.1.1" xref="S3.SS5.p1.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.3.m3.1b"><cn id="S3.SS5.p1.3.m3.1.1.cmml" type="integer" xref="S3.SS5.p1.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.3.m3.1c">64</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.3.m3.1d">64</annotation></semantics></math> auto-regressive steps. D-JEPA employs fully randomized orderings following <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> to decide the next set of tokens to predict. This design, along with the temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S3.SS5.p1.4.m4.1"><semantics id="S3.SS5.p1.4.m4.1a"><mi id="S3.SS5.p1.4.m4.1.1" xref="S3.SS5.p1.4.m4.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.4.m4.1b"><ci id="S3.SS5.p1.4.m4.1.1.cmml" xref="S3.SS5.p1.4.m4.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.4.m4.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p1.4.m4.1d">italic_Ï„</annotation></semantics></math>, effectively enhances the diversity of the generated samples.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS5.p2">
<p class="ltx_p" id="S3.SS5.p2.3">When the number of auto-regressive steps <math alttext="T" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.1"><semantics id="S3.SS5.p2.1.m1.1a"><mi id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><ci id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.1.m1.1d">italic_T</annotation></semantics></math> equals the total tokens <math alttext="N" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.1"><semantics id="S3.SS5.p2.2.m2.1a"><mi id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><ci id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.2.m2.1d">italic_N</annotation></semantics></math>, it means that we sample one token at each step. In this case, the <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.1">generalized next-token prediction</span> is equivalent to a <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.2">typical next-token prediction</span>. In another extreme case, <math alttext="T=1" class="ltx_Math" display="inline" id="S3.SS5.p2.3.m3.1"><semantics id="S3.SS5.p2.3.m3.1a"><mrow id="S3.SS5.p2.3.m3.1.1" xref="S3.SS5.p2.3.m3.1.1.cmml"><mi id="S3.SS5.p2.3.m3.1.1.2" xref="S3.SS5.p2.3.m3.1.1.2.cmml">T</mi><mo id="S3.SS5.p2.3.m3.1.1.1" xref="S3.SS5.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS5.p2.3.m3.1.1.3" xref="S3.SS5.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.3.m3.1b"><apply id="S3.SS5.p2.3.m3.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1"><eq id="S3.SS5.p2.3.m3.1.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1.1"></eq><ci id="S3.SS5.p2.3.m3.1.1.2.cmml" xref="S3.SS5.p2.3.m3.1.1.2">ğ‘‡</ci><cn id="S3.SS5.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS5.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.3.m3.1c">T=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.p2.3.m3.1d">italic_T = 1</annotation></semantics></math>, all tokens are sampled in one step, <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.3">i.e.</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.p2.3.4">one-step generation</span> like <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS5.p3">
<p class="ltx_p" id="S3.SS5.p3.1">As analyzed in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">C.2</span></a>, for D-JEPA, adopting a more efficient next set-of-tokens prediction strategy often yields better results. Particularly, as the model scale increases, fewer auto-regressive steps are required. Additionally, as shown in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F5" title="Figure 5 â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>, one-step generation fails to produce high-quality images, which is a major reason for the subpar performance of MAE <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>. Even with just eight steps of iterative sampling, we can generate clearly recognizable content. This fully demonstrates that D-JEPAâ€™s use of the next set of tokens prediction strategy is key to ensuring its strong generative capabilities.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<div class="ltx_listing ltx_listing" id="alg1.2">
<div class="ltx_listingline" id="alg0.l1">
<span class="ltx_tag ltx_tag_listingline">1:</span><math alttext="T" class="ltx_Math" display="inline" id="alg0.l1.m1.1"><semantics id="alg0.l1.m1.1a"><mi id="alg0.l1.m1.1.1" xref="alg0.l1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg0.l1.m1.1b"><ci id="alg0.l1.m1.1.1.cmml" xref="alg0.l1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="alg0.l1.m1.1d">italic_T</annotation></semantics></math>: Number of auto-regressive steps, <math alttext="N" class="ltx_Math" display="inline" id="alg0.l1.m2.1"><semantics id="alg0.l1.m2.1a"><mi id="alg0.l1.m2.1.1" xref="alg0.l1.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg0.l1.m2.1b"><ci id="alg0.l1.m2.1.1.cmml" xref="alg0.l1.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l1.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="alg0.l1.m2.1d">italic_N</annotation></semantics></math>: Total tokens to sample, <math alttext="\tau" class="ltx_Math" display="inline" id="alg0.l1.m3.1"><semantics id="alg0.l1.m3.1a"><mi id="alg0.l1.m3.1.1" xref="alg0.l1.m3.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="alg0.l1.m3.1b"><ci id="alg0.l1.m3.1.1.cmml" xref="alg0.l1.m3.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l1.m3.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="alg0.l1.m3.1d">italic_Ï„</annotation></semantics></math>: Temperature to control noise.

</div>
<div class="ltx_listingline" id="alg0.l2">
<span class="ltx_tag ltx_tag_listingline">2:</span><span class="ltx_text ltx_font_bold" id="alg0.l2.1">Initialize:</span> <math alttext="\mathbb{X}\leftarrow\emptyset" class="ltx_Math" display="inline" id="alg0.l2.m1.1"><semantics id="alg0.l2.m1.1a"><mrow id="alg0.l2.m1.1.1" xref="alg0.l2.m1.1.1.cmml"><mi id="alg0.l2.m1.1.1.2" xref="alg0.l2.m1.1.1.2.cmml">ğ•</mi><mo id="alg0.l2.m1.1.1.1" stretchy="false" xref="alg0.l2.m1.1.1.1.cmml">â†</mo><mi id="alg0.l2.m1.1.1.3" mathvariant="normal" xref="alg0.l2.m1.1.1.3.cmml">âˆ…</mi></mrow><annotation-xml encoding="MathML-Content" id="alg0.l2.m1.1b"><apply id="alg0.l2.m1.1.1.cmml" xref="alg0.l2.m1.1.1"><ci id="alg0.l2.m1.1.1.1.cmml" xref="alg0.l2.m1.1.1.1">â†</ci><ci id="alg0.l2.m1.1.1.2.cmml" xref="alg0.l2.m1.1.1.2">ğ•</ci><emptyset id="alg0.l2.m1.1.1.3.cmml" xref="alg0.l2.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l2.m1.1c">\mathbb{X}\leftarrow\emptyset</annotation><annotation encoding="application/x-llamapun" id="alg0.l2.m1.1d">blackboard_X â† âˆ…</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg0.l3">
<span class="ltx_tag ltx_tag_listingline">3:</span><span class="ltx_text ltx_font_bold" id="alg0.l3.1">for</span>Â <math alttext="n" class="ltx_Math" display="inline" id="alg0.l3.m1.1"><semantics id="alg0.l3.m1.1a"><mi id="alg0.l3.m1.1.1" xref="alg0.l3.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg0.l3.m1.1b"><ci id="alg0.l3.m1.1.1.cmml" xref="alg0.l3.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l3.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="alg0.l3.m1.1d">italic_n</annotation></semantics></math> in <math alttext="\text{cosine-step-function}(T,N)" class="ltx_Math" display="inline" id="alg0.l3.m2.2"><semantics id="alg0.l3.m2.2a"><mrow id="alg0.l3.m2.2.3" xref="alg0.l3.m2.2.3.cmml"><mtext id="alg0.l3.m2.2.3.2" xref="alg0.l3.m2.2.3.2a.cmml">cosine-step-function</mtext><mo id="alg0.l3.m2.2.3.1" xref="alg0.l3.m2.2.3.1.cmml">â¢</mo><mrow id="alg0.l3.m2.2.3.3.2" xref="alg0.l3.m2.2.3.3.1.cmml"><mo id="alg0.l3.m2.2.3.3.2.1" stretchy="false" xref="alg0.l3.m2.2.3.3.1.cmml">(</mo><mi id="alg0.l3.m2.1.1" xref="alg0.l3.m2.1.1.cmml">T</mi><mo id="alg0.l3.m2.2.3.3.2.2" xref="alg0.l3.m2.2.3.3.1.cmml">,</mo><mi id="alg0.l3.m2.2.2" xref="alg0.l3.m2.2.2.cmml">N</mi><mo id="alg0.l3.m2.2.3.3.2.3" stretchy="false" xref="alg0.l3.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l3.m2.2b"><apply id="alg0.l3.m2.2.3.cmml" xref="alg0.l3.m2.2.3"><times id="alg0.l3.m2.2.3.1.cmml" xref="alg0.l3.m2.2.3.1"></times><ci id="alg0.l3.m2.2.3.2a.cmml" xref="alg0.l3.m2.2.3.2"><mtext id="alg0.l3.m2.2.3.2.cmml" xref="alg0.l3.m2.2.3.2">cosine-step-function</mtext></ci><interval closure="open" id="alg0.l3.m2.2.3.3.1.cmml" xref="alg0.l3.m2.2.3.3.2"><ci id="alg0.l3.m2.1.1.cmml" xref="alg0.l3.m2.1.1">ğ‘‡</ci><ci id="alg0.l3.m2.2.2.cmml" xref="alg0.l3.m2.2.2">ğ‘</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l3.m2.2c">\text{cosine-step-function}(T,N)</annotation><annotation encoding="application/x-llamapun" id="alg0.l3.m2.2d">cosine-step-function ( italic_T , italic_N )</annotation></semantics></math>Â <span class="ltx_text ltx_font_bold" id="alg0.l3.2">do</span>
</div>
<div class="ltx_listingline" id="alg0.l4">
<span class="ltx_tag ltx_tag_listingline">4:</span>Â Â Â Â Â <math alttext="\mathbb{C}\leftarrow\phi(\mathbb{X})" class="ltx_Math" display="inline" id="alg0.l4.m1.1"><semantics id="alg0.l4.m1.1a"><mrow id="alg0.l4.m1.1.2" xref="alg0.l4.m1.1.2.cmml"><mi id="alg0.l4.m1.1.2.2" xref="alg0.l4.m1.1.2.2.cmml">â„‚</mi><mo id="alg0.l4.m1.1.2.1" stretchy="false" xref="alg0.l4.m1.1.2.1.cmml">â†</mo><mrow id="alg0.l4.m1.1.2.3" xref="alg0.l4.m1.1.2.3.cmml"><mi id="alg0.l4.m1.1.2.3.2" xref="alg0.l4.m1.1.2.3.2.cmml">Ï•</mi><mo id="alg0.l4.m1.1.2.3.1" xref="alg0.l4.m1.1.2.3.1.cmml">â¢</mo><mrow id="alg0.l4.m1.1.2.3.3.2" xref="alg0.l4.m1.1.2.3.cmml"><mo id="alg0.l4.m1.1.2.3.3.2.1" stretchy="false" xref="alg0.l4.m1.1.2.3.cmml">(</mo><mi id="alg0.l4.m1.1.1" xref="alg0.l4.m1.1.1.cmml">ğ•</mi><mo id="alg0.l4.m1.1.2.3.3.2.2" stretchy="false" xref="alg0.l4.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l4.m1.1b"><apply id="alg0.l4.m1.1.2.cmml" xref="alg0.l4.m1.1.2"><ci id="alg0.l4.m1.1.2.1.cmml" xref="alg0.l4.m1.1.2.1">â†</ci><ci id="alg0.l4.m1.1.2.2.cmml" xref="alg0.l4.m1.1.2.2">â„‚</ci><apply id="alg0.l4.m1.1.2.3.cmml" xref="alg0.l4.m1.1.2.3"><times id="alg0.l4.m1.1.2.3.1.cmml" xref="alg0.l4.m1.1.2.3.1"></times><ci id="alg0.l4.m1.1.2.3.2.cmml" xref="alg0.l4.m1.1.2.3.2">italic-Ï•</ci><ci id="alg0.l4.m1.1.1.cmml" xref="alg0.l4.m1.1.1">ğ•</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l4.m1.1c">\mathbb{C}\leftarrow\phi(\mathbb{X})</annotation><annotation encoding="application/x-llamapun" id="alg0.l4.m1.1d">blackboard_C â† italic_Ï• ( blackboard_X )</annotation></semantics></math> <span class="ltx_text" id="alg0.l4.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l4.1.m1.1"><semantics id="alg0.l4.1.m1.1a"><mo id="alg0.l4.1.m1.1.1" xref="alg0.l4.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg0.l4.1.m1.1b"><ci id="alg0.l4.1.m1.1.1.cmml" xref="alg0.l4.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l4.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l4.1.m1.1d">â–·</annotation></semantics></math> Encode the sampled tokens to obtain context features
</span>
</div>
<div class="ltx_listingline" id="alg0.l5">
<span class="ltx_tag ltx_tag_listingline">5:</span>Â Â Â Â Â <math alttext="\mathbb{Z}\leftarrow\gamma(\mathbb{C})" class="ltx_Math" display="inline" id="alg0.l5.m1.1"><semantics id="alg0.l5.m1.1a"><mrow id="alg0.l5.m1.1.2" xref="alg0.l5.m1.1.2.cmml"><mi id="alg0.l5.m1.1.2.2" xref="alg0.l5.m1.1.2.2.cmml">â„¤</mi><mo id="alg0.l5.m1.1.2.1" stretchy="false" xref="alg0.l5.m1.1.2.1.cmml">â†</mo><mrow id="alg0.l5.m1.1.2.3" xref="alg0.l5.m1.1.2.3.cmml"><mi id="alg0.l5.m1.1.2.3.2" xref="alg0.l5.m1.1.2.3.2.cmml">Î³</mi><mo id="alg0.l5.m1.1.2.3.1" xref="alg0.l5.m1.1.2.3.1.cmml">â¢</mo><mrow id="alg0.l5.m1.1.2.3.3.2" xref="alg0.l5.m1.1.2.3.cmml"><mo id="alg0.l5.m1.1.2.3.3.2.1" stretchy="false" xref="alg0.l5.m1.1.2.3.cmml">(</mo><mi id="alg0.l5.m1.1.1" xref="alg0.l5.m1.1.1.cmml">â„‚</mi><mo id="alg0.l5.m1.1.2.3.3.2.2" stretchy="false" xref="alg0.l5.m1.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l5.m1.1b"><apply id="alg0.l5.m1.1.2.cmml" xref="alg0.l5.m1.1.2"><ci id="alg0.l5.m1.1.2.1.cmml" xref="alg0.l5.m1.1.2.1">â†</ci><ci id="alg0.l5.m1.1.2.2.cmml" xref="alg0.l5.m1.1.2.2">â„¤</ci><apply id="alg0.l5.m1.1.2.3.cmml" xref="alg0.l5.m1.1.2.3"><times id="alg0.l5.m1.1.2.3.1.cmml" xref="alg0.l5.m1.1.2.3.1"></times><ci id="alg0.l5.m1.1.2.3.2.cmml" xref="alg0.l5.m1.1.2.3.2">ğ›¾</ci><ci id="alg0.l5.m1.1.1.cmml" xref="alg0.l5.m1.1.1">â„‚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l5.m1.1c">\mathbb{Z}\leftarrow\gamma(\mathbb{C})</annotation><annotation encoding="application/x-llamapun" id="alg0.l5.m1.1d">blackboard_Z â† italic_Î³ ( blackboard_C )</annotation></semantics></math> <span class="ltx_text" id="alg0.l5.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l5.1.m1.1"><semantics id="alg0.l5.1.m1.1a"><mo id="alg0.l5.1.m1.1.1" xref="alg0.l5.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg0.l5.1.m1.1b"><ci id="alg0.l5.1.m1.1.1.cmml" xref="alg0.l5.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l5.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l5.1.m1.1d">â–·</annotation></semantics></math> Predict features of unsampled tokens using the feature predictor
</span>
</div>
<div class="ltx_listingline" id="alg0.l6">
<span class="ltx_tag ltx_tag_listingline">6:</span>Â Â Â Â Â <math alttext="\{z_{0},\ldots,z_{n}\}\sim\mathbb{Z}" class="ltx_Math" display="inline" id="alg0.l6.m1.3"><semantics id="alg0.l6.m1.3a"><mrow id="alg0.l6.m1.3.3" xref="alg0.l6.m1.3.3.cmml"><mrow id="alg0.l6.m1.3.3.2.2" xref="alg0.l6.m1.3.3.2.3.cmml"><mo id="alg0.l6.m1.3.3.2.2.3" stretchy="false" xref="alg0.l6.m1.3.3.2.3.cmml">{</mo><msub id="alg0.l6.m1.2.2.1.1.1" xref="alg0.l6.m1.2.2.1.1.1.cmml"><mi id="alg0.l6.m1.2.2.1.1.1.2" xref="alg0.l6.m1.2.2.1.1.1.2.cmml">z</mi><mn id="alg0.l6.m1.2.2.1.1.1.3" xref="alg0.l6.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="alg0.l6.m1.3.3.2.2.4" xref="alg0.l6.m1.3.3.2.3.cmml">,</mo><mi id="alg0.l6.m1.1.1" mathvariant="normal" xref="alg0.l6.m1.1.1.cmml">â€¦</mi><mo id="alg0.l6.m1.3.3.2.2.5" xref="alg0.l6.m1.3.3.2.3.cmml">,</mo><msub id="alg0.l6.m1.3.3.2.2.2" xref="alg0.l6.m1.3.3.2.2.2.cmml"><mi id="alg0.l6.m1.3.3.2.2.2.2" xref="alg0.l6.m1.3.3.2.2.2.2.cmml">z</mi><mi id="alg0.l6.m1.3.3.2.2.2.3" xref="alg0.l6.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l6.m1.3.3.2.2.6" stretchy="false" xref="alg0.l6.m1.3.3.2.3.cmml">}</mo></mrow><mo id="alg0.l6.m1.3.3.3" xref="alg0.l6.m1.3.3.3.cmml">âˆ¼</mo><mi id="alg0.l6.m1.3.3.4" xref="alg0.l6.m1.3.3.4.cmml">â„¤</mi></mrow><annotation-xml encoding="MathML-Content" id="alg0.l6.m1.3b"><apply id="alg0.l6.m1.3.3.cmml" xref="alg0.l6.m1.3.3"><csymbol cd="latexml" id="alg0.l6.m1.3.3.3.cmml" xref="alg0.l6.m1.3.3.3">similar-to</csymbol><set id="alg0.l6.m1.3.3.2.3.cmml" xref="alg0.l6.m1.3.3.2.2"><apply id="alg0.l6.m1.2.2.1.1.1.cmml" xref="alg0.l6.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg0.l6.m1.2.2.1.1.1.1.cmml" xref="alg0.l6.m1.2.2.1.1.1">subscript</csymbol><ci id="alg0.l6.m1.2.2.1.1.1.2.cmml" xref="alg0.l6.m1.2.2.1.1.1.2">ğ‘§</ci><cn id="alg0.l6.m1.2.2.1.1.1.3.cmml" type="integer" xref="alg0.l6.m1.2.2.1.1.1.3">0</cn></apply><ci id="alg0.l6.m1.1.1.cmml" xref="alg0.l6.m1.1.1">â€¦</ci><apply id="alg0.l6.m1.3.3.2.2.2.cmml" xref="alg0.l6.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg0.l6.m1.3.3.2.2.2.1.cmml" xref="alg0.l6.m1.3.3.2.2.2">subscript</csymbol><ci id="alg0.l6.m1.3.3.2.2.2.2.cmml" xref="alg0.l6.m1.3.3.2.2.2.2">ğ‘§</ci><ci id="alg0.l6.m1.3.3.2.2.2.3.cmml" xref="alg0.l6.m1.3.3.2.2.2.3">ğ‘›</ci></apply></set><ci id="alg0.l6.m1.3.3.4.cmml" xref="alg0.l6.m1.3.3.4">â„¤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.m1.3c">\{z_{0},\ldots,z_{n}\}\sim\mathbb{Z}</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.m1.3d">{ italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , â€¦ , italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } âˆ¼ blackboard_Z</annotation></semantics></math> <span class="ltx_text" id="alg0.l6.3" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l6.1.m1.1"><semantics id="alg0.l6.1.m1.1a"><mo id="alg0.l6.1.m1.1.1" xref="alg0.l6.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg0.l6.1.m1.1b"><ci id="alg0.l6.1.m1.1.1.cmml" xref="alg0.l6.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.1.m1.1d">â–·</annotation></semantics></math> Randomly select <math alttext="n" class="ltx_Math" display="inline" id="alg0.l6.2.m2.1"><semantics id="alg0.l6.2.m2.1a"><mi id="alg0.l6.2.m2.1.1" xref="alg0.l6.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg0.l6.2.m2.1b"><ci id="alg0.l6.2.m2.1.1.cmml" xref="alg0.l6.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.2.m2.1d">italic_n</annotation></semantics></math> tokens from <math alttext="\mathbb{Z}" class="ltx_Math" display="inline" id="alg0.l6.3.m3.1"><semantics id="alg0.l6.3.m3.1a"><mi id="alg0.l6.3.m3.1.1" xref="alg0.l6.3.m3.1.1.cmml">â„¤</mi><annotation-xml encoding="MathML-Content" id="alg0.l6.3.m3.1b"><ci id="alg0.l6.3.m3.1.1.cmml" xref="alg0.l6.3.m3.1.1">â„¤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l6.3.m3.1c">\mathbb{Z}</annotation><annotation encoding="application/x-llamapun" id="alg0.l6.3.m3.1d">blackboard_Z</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="alg0.l7">
<span class="ltx_tag ltx_tag_listingline">7:</span>Â Â Â Â Â <math alttext="\{x_{0},\ldots,x_{n}\}\leftarrow\text{denoise}(\epsilon_{\theta},\{z_{0},%
\ldots,z_{n}\},\tau)" class="ltx_Math" display="inline" id="alg0.l7.m1.7"><semantics id="alg0.l7.m1.7a"><mrow id="alg0.l7.m1.7.7" xref="alg0.l7.m1.7.7.cmml"><mrow id="alg0.l7.m1.5.5.2.2" xref="alg0.l7.m1.5.5.2.3.cmml"><mo id="alg0.l7.m1.5.5.2.2.3" stretchy="false" xref="alg0.l7.m1.5.5.2.3.cmml">{</mo><msub id="alg0.l7.m1.4.4.1.1.1" xref="alg0.l7.m1.4.4.1.1.1.cmml"><mi id="alg0.l7.m1.4.4.1.1.1.2" xref="alg0.l7.m1.4.4.1.1.1.2.cmml">x</mi><mn id="alg0.l7.m1.4.4.1.1.1.3" xref="alg0.l7.m1.4.4.1.1.1.3.cmml">0</mn></msub><mo id="alg0.l7.m1.5.5.2.2.4" xref="alg0.l7.m1.5.5.2.3.cmml">,</mo><mi id="alg0.l7.m1.1.1" mathvariant="normal" xref="alg0.l7.m1.1.1.cmml">â€¦</mi><mo id="alg0.l7.m1.5.5.2.2.5" xref="alg0.l7.m1.5.5.2.3.cmml">,</mo><msub id="alg0.l7.m1.5.5.2.2.2" xref="alg0.l7.m1.5.5.2.2.2.cmml"><mi id="alg0.l7.m1.5.5.2.2.2.2" xref="alg0.l7.m1.5.5.2.2.2.2.cmml">x</mi><mi id="alg0.l7.m1.5.5.2.2.2.3" xref="alg0.l7.m1.5.5.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l7.m1.5.5.2.2.6" stretchy="false" xref="alg0.l7.m1.5.5.2.3.cmml">}</mo></mrow><mo id="alg0.l7.m1.7.7.5" stretchy="false" xref="alg0.l7.m1.7.7.5.cmml">â†</mo><mrow id="alg0.l7.m1.7.7.4" xref="alg0.l7.m1.7.7.4.cmml"><mtext id="alg0.l7.m1.7.7.4.4" xref="alg0.l7.m1.7.7.4.4a.cmml">denoise</mtext><mo id="alg0.l7.m1.7.7.4.3" xref="alg0.l7.m1.7.7.4.3.cmml">â¢</mo><mrow id="alg0.l7.m1.7.7.4.2.2" xref="alg0.l7.m1.7.7.4.2.3.cmml"><mo id="alg0.l7.m1.7.7.4.2.2.3" stretchy="false" xref="alg0.l7.m1.7.7.4.2.3.cmml">(</mo><msub id="alg0.l7.m1.6.6.3.1.1.1" xref="alg0.l7.m1.6.6.3.1.1.1.cmml"><mi id="alg0.l7.m1.6.6.3.1.1.1.2" xref="alg0.l7.m1.6.6.3.1.1.1.2.cmml">Ïµ</mi><mi id="alg0.l7.m1.6.6.3.1.1.1.3" xref="alg0.l7.m1.6.6.3.1.1.1.3.cmml">Î¸</mi></msub><mo id="alg0.l7.m1.7.7.4.2.2.4" xref="alg0.l7.m1.7.7.4.2.3.cmml">,</mo><mrow id="alg0.l7.m1.7.7.4.2.2.2.2" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml"><mo id="alg0.l7.m1.7.7.4.2.2.2.2.3" stretchy="false" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">{</mo><msub id="alg0.l7.m1.7.7.4.2.2.2.1.1" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.cmml"><mi id="alg0.l7.m1.7.7.4.2.2.2.1.1.2" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.2.cmml">z</mi><mn id="alg0.l7.m1.7.7.4.2.2.2.1.1.3" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.3.cmml">0</mn></msub><mo id="alg0.l7.m1.7.7.4.2.2.2.2.4" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">,</mo><mi id="alg0.l7.m1.2.2" mathvariant="normal" xref="alg0.l7.m1.2.2.cmml">â€¦</mi><mo id="alg0.l7.m1.7.7.4.2.2.2.2.5" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">,</mo><msub id="alg0.l7.m1.7.7.4.2.2.2.2.2" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.cmml"><mi id="alg0.l7.m1.7.7.4.2.2.2.2.2.2" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.2.cmml">z</mi><mi id="alg0.l7.m1.7.7.4.2.2.2.2.2.3" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l7.m1.7.7.4.2.2.2.2.6" stretchy="false" xref="alg0.l7.m1.7.7.4.2.2.2.3.cmml">}</mo></mrow><mo id="alg0.l7.m1.7.7.4.2.2.5" xref="alg0.l7.m1.7.7.4.2.3.cmml">,</mo><mi id="alg0.l7.m1.3.3" xref="alg0.l7.m1.3.3.cmml">Ï„</mi><mo id="alg0.l7.m1.7.7.4.2.2.6" stretchy="false" xref="alg0.l7.m1.7.7.4.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l7.m1.7b"><apply id="alg0.l7.m1.7.7.cmml" xref="alg0.l7.m1.7.7"><ci id="alg0.l7.m1.7.7.5.cmml" xref="alg0.l7.m1.7.7.5">â†</ci><set id="alg0.l7.m1.5.5.2.3.cmml" xref="alg0.l7.m1.5.5.2.2"><apply id="alg0.l7.m1.4.4.1.1.1.cmml" xref="alg0.l7.m1.4.4.1.1.1"><csymbol cd="ambiguous" id="alg0.l7.m1.4.4.1.1.1.1.cmml" xref="alg0.l7.m1.4.4.1.1.1">subscript</csymbol><ci id="alg0.l7.m1.4.4.1.1.1.2.cmml" xref="alg0.l7.m1.4.4.1.1.1.2">ğ‘¥</ci><cn id="alg0.l7.m1.4.4.1.1.1.3.cmml" type="integer" xref="alg0.l7.m1.4.4.1.1.1.3">0</cn></apply><ci id="alg0.l7.m1.1.1.cmml" xref="alg0.l7.m1.1.1">â€¦</ci><apply id="alg0.l7.m1.5.5.2.2.2.cmml" xref="alg0.l7.m1.5.5.2.2.2"><csymbol cd="ambiguous" id="alg0.l7.m1.5.5.2.2.2.1.cmml" xref="alg0.l7.m1.5.5.2.2.2">subscript</csymbol><ci id="alg0.l7.m1.5.5.2.2.2.2.cmml" xref="alg0.l7.m1.5.5.2.2.2.2">ğ‘¥</ci><ci id="alg0.l7.m1.5.5.2.2.2.3.cmml" xref="alg0.l7.m1.5.5.2.2.2.3">ğ‘›</ci></apply></set><apply id="alg0.l7.m1.7.7.4.cmml" xref="alg0.l7.m1.7.7.4"><times id="alg0.l7.m1.7.7.4.3.cmml" xref="alg0.l7.m1.7.7.4.3"></times><ci id="alg0.l7.m1.7.7.4.4a.cmml" xref="alg0.l7.m1.7.7.4.4"><mtext id="alg0.l7.m1.7.7.4.4.cmml" xref="alg0.l7.m1.7.7.4.4">denoise</mtext></ci><vector id="alg0.l7.m1.7.7.4.2.3.cmml" xref="alg0.l7.m1.7.7.4.2.2"><apply id="alg0.l7.m1.6.6.3.1.1.1.cmml" xref="alg0.l7.m1.6.6.3.1.1.1"><csymbol cd="ambiguous" id="alg0.l7.m1.6.6.3.1.1.1.1.cmml" xref="alg0.l7.m1.6.6.3.1.1.1">subscript</csymbol><ci id="alg0.l7.m1.6.6.3.1.1.1.2.cmml" xref="alg0.l7.m1.6.6.3.1.1.1.2">italic-Ïµ</ci><ci id="alg0.l7.m1.6.6.3.1.1.1.3.cmml" xref="alg0.l7.m1.6.6.3.1.1.1.3">ğœƒ</ci></apply><set id="alg0.l7.m1.7.7.4.2.2.2.3.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2"><apply id="alg0.l7.m1.7.7.4.2.2.2.1.1.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.1.1"><csymbol cd="ambiguous" id="alg0.l7.m1.7.7.4.2.2.2.1.1.1.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.1.1">subscript</csymbol><ci id="alg0.l7.m1.7.7.4.2.2.2.1.1.2.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.2">ğ‘§</ci><cn id="alg0.l7.m1.7.7.4.2.2.2.1.1.3.cmml" type="integer" xref="alg0.l7.m1.7.7.4.2.2.2.1.1.3">0</cn></apply><ci id="alg0.l7.m1.2.2.cmml" xref="alg0.l7.m1.2.2">â€¦</ci><apply id="alg0.l7.m1.7.7.4.2.2.2.2.2.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2"><csymbol cd="ambiguous" id="alg0.l7.m1.7.7.4.2.2.2.2.2.1.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2">subscript</csymbol><ci id="alg0.l7.m1.7.7.4.2.2.2.2.2.2.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.2">ğ‘§</ci><ci id="alg0.l7.m1.7.7.4.2.2.2.2.2.3.cmml" xref="alg0.l7.m1.7.7.4.2.2.2.2.2.3">ğ‘›</ci></apply></set><ci id="alg0.l7.m1.3.3.cmml" xref="alg0.l7.m1.3.3">ğœ</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l7.m1.7c">\{x_{0},\ldots,x_{n}\}\leftarrow\text{denoise}(\epsilon_{\theta},\{z_{0},%
\ldots,z_{n}\},\tau)</annotation><annotation encoding="application/x-llamapun" id="alg0.l7.m1.7d">{ italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } â† denoise ( italic_Ïµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT , { italic_z start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , â€¦ , italic_z start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , italic_Ï„ )</annotation></semantics></math> <span class="ltx_text" id="alg0.l7.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l7.1.m1.1"><semantics id="alg0.l7.1.m1.1a"><mo id="alg0.l7.1.m1.1.1" xref="alg0.l7.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg0.l7.1.m1.1b"><ci id="alg0.l7.1.m1.1.1.cmml" xref="alg0.l7.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l7.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l7.1.m1.1d">â–·</annotation></semantics></math> Perform denoising on the selected tokens
</span>
</div>
<div class="ltx_listingline" id="alg0.l8">
<span class="ltx_tag ltx_tag_listingline">8:</span>Â Â Â Â Â <math alttext="\mathbb{X}\leftarrow\mathbb{X}\cup\{x_{0},\ldots,x_{n}\}" class="ltx_Math" display="inline" id="alg0.l8.m1.3"><semantics id="alg0.l8.m1.3a"><mrow id="alg0.l8.m1.3.3" xref="alg0.l8.m1.3.3.cmml"><mi id="alg0.l8.m1.3.3.4" xref="alg0.l8.m1.3.3.4.cmml">ğ•</mi><mo id="alg0.l8.m1.3.3.3" stretchy="false" xref="alg0.l8.m1.3.3.3.cmml">â†</mo><mrow id="alg0.l8.m1.3.3.2" xref="alg0.l8.m1.3.3.2.cmml"><mi id="alg0.l8.m1.3.3.2.4" xref="alg0.l8.m1.3.3.2.4.cmml">ğ•</mi><mo id="alg0.l8.m1.3.3.2.3" xref="alg0.l8.m1.3.3.2.3.cmml">âˆª</mo><mrow id="alg0.l8.m1.3.3.2.2.2" xref="alg0.l8.m1.3.3.2.2.3.cmml"><mo id="alg0.l8.m1.3.3.2.2.2.3" stretchy="false" xref="alg0.l8.m1.3.3.2.2.3.cmml">{</mo><msub id="alg0.l8.m1.2.2.1.1.1.1" xref="alg0.l8.m1.2.2.1.1.1.1.cmml"><mi id="alg0.l8.m1.2.2.1.1.1.1.2" xref="alg0.l8.m1.2.2.1.1.1.1.2.cmml">x</mi><mn id="alg0.l8.m1.2.2.1.1.1.1.3" xref="alg0.l8.m1.2.2.1.1.1.1.3.cmml">0</mn></msub><mo id="alg0.l8.m1.3.3.2.2.2.4" xref="alg0.l8.m1.3.3.2.2.3.cmml">,</mo><mi id="alg0.l8.m1.1.1" mathvariant="normal" xref="alg0.l8.m1.1.1.cmml">â€¦</mi><mo id="alg0.l8.m1.3.3.2.2.2.5" xref="alg0.l8.m1.3.3.2.2.3.cmml">,</mo><msub id="alg0.l8.m1.3.3.2.2.2.2" xref="alg0.l8.m1.3.3.2.2.2.2.cmml"><mi id="alg0.l8.m1.3.3.2.2.2.2.2" xref="alg0.l8.m1.3.3.2.2.2.2.2.cmml">x</mi><mi id="alg0.l8.m1.3.3.2.2.2.2.3" xref="alg0.l8.m1.3.3.2.2.2.2.3.cmml">n</mi></msub><mo id="alg0.l8.m1.3.3.2.2.2.6" stretchy="false" xref="alg0.l8.m1.3.3.2.2.3.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg0.l8.m1.3b"><apply id="alg0.l8.m1.3.3.cmml" xref="alg0.l8.m1.3.3"><ci id="alg0.l8.m1.3.3.3.cmml" xref="alg0.l8.m1.3.3.3">â†</ci><ci id="alg0.l8.m1.3.3.4.cmml" xref="alg0.l8.m1.3.3.4">ğ•</ci><apply id="alg0.l8.m1.3.3.2.cmml" xref="alg0.l8.m1.3.3.2"><union id="alg0.l8.m1.3.3.2.3.cmml" xref="alg0.l8.m1.3.3.2.3"></union><ci id="alg0.l8.m1.3.3.2.4.cmml" xref="alg0.l8.m1.3.3.2.4">ğ•</ci><set id="alg0.l8.m1.3.3.2.2.3.cmml" xref="alg0.l8.m1.3.3.2.2.2"><apply id="alg0.l8.m1.2.2.1.1.1.1.cmml" xref="alg0.l8.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg0.l8.m1.2.2.1.1.1.1.1.cmml" xref="alg0.l8.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg0.l8.m1.2.2.1.1.1.1.2.cmml" xref="alg0.l8.m1.2.2.1.1.1.1.2">ğ‘¥</ci><cn id="alg0.l8.m1.2.2.1.1.1.1.3.cmml" type="integer" xref="alg0.l8.m1.2.2.1.1.1.1.3">0</cn></apply><ci id="alg0.l8.m1.1.1.cmml" xref="alg0.l8.m1.1.1">â€¦</ci><apply id="alg0.l8.m1.3.3.2.2.2.2.cmml" xref="alg0.l8.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg0.l8.m1.3.3.2.2.2.2.1.cmml" xref="alg0.l8.m1.3.3.2.2.2.2">subscript</csymbol><ci id="alg0.l8.m1.3.3.2.2.2.2.2.cmml" xref="alg0.l8.m1.3.3.2.2.2.2.2">ğ‘¥</ci><ci id="alg0.l8.m1.3.3.2.2.2.2.3.cmml" xref="alg0.l8.m1.3.3.2.2.2.2.3">ğ‘›</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg0.l8.m1.3c">\mathbb{X}\leftarrow\mathbb{X}\cup\{x_{0},\ldots,x_{n}\}</annotation><annotation encoding="application/x-llamapun" id="alg0.l8.m1.3d">blackboard_X â† blackboard_X âˆª { italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> <span class="ltx_text" id="alg0.l8.2" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg0.l8.1.m1.1"><semantics id="alg0.l8.1.m1.1a"><mo id="alg0.l8.1.m1.1.1" xref="alg0.l8.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg0.l8.1.m1.1b"><ci id="alg0.l8.1.m1.1.1.cmml" xref="alg0.l8.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l8.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg0.l8.1.m1.1d">â–·</annotation></semantics></math> Add the denoised tokens to <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="alg0.l8.2.m2.1"><semantics id="alg0.l8.2.m2.1a"><mi id="alg0.l8.2.m2.1.1" xref="alg0.l8.2.m2.1.1.cmml">ğ•</mi><annotation-xml encoding="MathML-Content" id="alg0.l8.2.m2.1b"><ci id="alg0.l8.2.m2.1.1.cmml" xref="alg0.l8.2.m2.1.1">ğ•</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l8.2.m2.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="alg0.l8.2.m2.1d">blackboard_X</annotation></semantics></math>
</span>
</div>
<div class="ltx_listingline" id="alg0.l9">
<span class="ltx_tag ltx_tag_listingline">9:</span><span class="ltx_text ltx_font_bold" id="alg0.l9.1">end</span>Â <span class="ltx_text ltx_font_bold" id="alg0.l9.2">for</span>
</div>
<div class="ltx_listingline" id="alg0.l10">
<span class="ltx_tag ltx_tag_listingline">10:</span><span class="ltx_text ltx_font_bold" id="alg0.l10.1">Return:</span> <math alttext="\mathbb{X}" class="ltx_Math" display="inline" id="alg0.l10.m1.1"><semantics id="alg0.l10.m1.1a"><mi id="alg0.l10.m1.1.1" xref="alg0.l10.m1.1.1.cmml">ğ•</mi><annotation-xml encoding="MathML-Content" id="alg0.l10.m1.1b"><ci id="alg0.l10.m1.1.1.cmml" xref="alg0.l10.m1.1.1">ğ•</ci></annotation-xml><annotation encoding="application/x-tex" id="alg0.l10.m1.1c">\mathbb{X}</annotation><annotation encoding="application/x-llamapun" id="alg0.l10.m1.1d">blackboard_X</annotation></semantics></math>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.3.1.1">Algorithm 1</span> </span> Generalized next token prediction with D-JEPA</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">To evaluate D-JEPAâ€™s generative performance, we conduct experiments on the ImageNet-1K dataset <cite class="ltx_cite ltx_citemacro_cite">Russakovsky etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib90" title="">2015</a>)</cite> for the task of class-conditional image generation. Please refer to AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A2" title="Appendix B Experimental Setup â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">B</span></a> for detailed experimental settings.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Image Synthetis</h3>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T1.5">
<tr class="ltx_tr" id="S4.T1.4.4">
<td class="ltx_td ltx_border_r" id="S4.T1.4.4.5"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.4.6">#Params</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.4.4.7">#Epochs</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.1">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.2.2.2">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.m1.1a"><mo id="S4.T1.2.2.2.m1.1.1" stretchy="false" xref="S4.T1.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.3.3">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.m1.1.1" stretchy="false" xref="S4.T1.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.4">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.4.4.4.m1.1"><semantics id="S4.T1.4.4.4.m1.1a"><mo id="S4.T1.4.4.4.m1.1.1" stretchy="false" xref="S4.T1.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.4.m1.1d">â†‘</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.6" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="7" id="S4.T1.5.6.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T1.5.6.1.1" style="background-color:#EFEFEF;">Base scale model (less than 300M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.7.1">MAR-BÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.7.2">208M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.7.3">800</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.7.4">3.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.7.5">192.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.7.6">0.78</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.7.7">0.58</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.8.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.8.1.1" style="background-color:#ECF4FF;">D-JEPA-B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.8.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.8.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.8.3"><span class="ltx_text" id="S4.T1.5.8.3.1" style="background-color:#ECF4FF;">1400</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.8.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.8.4.1" style="background-color:#ECF4FF;">3.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.8.5" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.8.5.1" style="background-color:#ECF4FF;">197.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.8.6"><span class="ltx_text" id="S4.T1.5.8.6.1" style="background-color:#ECF4FF;">0.77</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.8.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.8.7.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.9.1">MaskGITÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.9.2">227M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.3">300</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.4">6.18</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.9.5">182.1</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.9.6.1">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.9.7">0.51</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.10.1">MAGEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.10.2">230M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.3">1600</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.4">6.93</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.10.5">195.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.10.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="7" id="S4.T1.5.5.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T1.5.5.1.1" style="background-color:#EFEFEF;">Large scale model (300<math alttext="\sim" class="ltx_Math" display="inline" id="S4.T1.5.5.1.1.m1.1" style="background-color:#EFEFEF;"><semantics id="S4.T1.5.5.1.1.m1.1a"><mo id="S4.T1.5.5.1.1.m1.1.1" mathbackground="#EFEFEF" xref="S4.T1.5.5.1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.1.1.m1.1b"><csymbol cd="latexml" id="S4.T1.5.5.1.1.m1.1.1.cmml" xref="S4.T1.5.5.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T1.5.5.1.1.m1.1d">âˆ¼</annotation></semantics></math>700M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.11.1">GIVTÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.11.2">304M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.3">500</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.4">5.67</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.11.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.6">0.75</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.11.7">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.12.1">MAGVIT-v2Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.12.2">307M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.3">1080</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.4">3.65</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.12.5">200.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.12.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.13.1">MAR-LÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.13.2">479M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.13.3">800</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.13.4">2.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.13.5">221.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.13.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.13.6.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.13.7">0.60</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.14.1">DiT-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.14.2">675M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.14.3">1400</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.14.4">9.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.14.5">121.5</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.14.6">0.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.14.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.14.7.1">0.67</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.15.1">SiT-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.15.2">675M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.15.3">1400</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.15.4">8.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.15.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.15.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.15.7">-</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.16.1">MDTv2-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.16.2">676M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.16.3">400</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.16.4">5.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.16.5">155.6</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.16.6">0.72</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.16.7">0.66</td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.17" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.17.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.17.1.1" style="background-color:#ECF4FF;">D-JEPA-L</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.17.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.17.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.17.3"><span class="ltx_text" id="S4.T1.5.17.3.1" style="background-color:#ECF4FF;">480</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.17.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.17.4.1" style="background-color:#ECF4FF;">2.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.17.5" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.17.5.1" style="background-color:#ECF4FF;">233.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.17.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.17.6.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.17.7"><span class="ltx_text" id="S4.T1.5.17.7.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.18" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="7" id="S4.T1.5.18.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T1.5.18.1.1" style="background-color:#EFEFEF;">Huge scale model (900+M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.19">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.19.1">MAR-HÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.19.2">943M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.19.3">800</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.19.4">2.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.19.5">227.8</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.19.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.19.6.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.19.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.19.7.1">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.20" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.20.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.20.1.1" style="background-color:#ECF4FF;">D-JEPA-H</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.20.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T1.5.20.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.20.3"><span class="ltx_text" id="S4.T1.5.20.3.1" style="background-color:#ECF4FF;">320</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.20.4"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.4.1" style="background-color:#ECF4FF;">2.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.20.5" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.5.1" style="background-color:#ECF4FF;">239.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.20.6"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.6.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.20.7"><span class="ltx_text ltx_font_bold" id="S4.T1.5.20.7.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.5.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.21.1">VDM++Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib57" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T1.5.21.2">2.0B</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.21.3">1120</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.21.4">2.40</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T1.5.21.5">225.3</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.21.6">-</td>
<td class="ltx_td ltx_align_center" id="S4.T1.5.21.7">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>System-level comparison on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="S4.T1.7.m1.1"><semantics id="S4.T1.7.m1.1b"><mrow id="S4.T1.7.m1.1.1" xref="S4.T1.7.m1.1.1.cmml"><mn id="S4.T1.7.m1.1.1.2" xref="S4.T1.7.m1.1.1.2.cmml">256</mn><mo id="S4.T1.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.T1.7.m1.1.1.1.cmml">Ã—</mo><mn id="S4.T1.7.m1.1.1.3" xref="S4.T1.7.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.7.m1.1c"><apply id="S4.T1.7.m1.1.1.cmml" xref="S4.T1.7.m1.1.1"><times id="S4.T1.7.m1.1.1.1.cmml" xref="S4.T1.7.m1.1.1.1"></times><cn id="S4.T1.7.m1.1.1.2.cmml" type="integer" xref="S4.T1.7.m1.1.1.2">256</cn><cn id="S4.T1.7.m1.1.1.3.cmml" type="integer" xref="S4.T1.7.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.T1.7.m1.1e">256 Ã— 256</annotation></semantics></math> conditional generation <span class="ltx_text ltx_font_italic" id="S4.T1.9.1">without</span> classifier-free guidance. For ease of comparison, we have omitted earlier works with FID greater than 10. A more detailed table can be found in the appendix.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.F2.7">
<tr class="ltx_tr" id="S4.F2.7.7">
<td class="ltx_td ltx_align_center" id="S4.F2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="269" id="S4.F2.1.1.1.g1" src="x2.png" width="448"/></td>
<td class="ltx_td ltx_align_center" id="S4.F2.7.7.7">
<div class="ltx_block ltx_parbox ltx_align_bottom" id="S4.F2.7.7.7.6" style="width:173.4pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_block">Figure 2: </span>FID <span class="ltx_text ltx_font_italic" id="S4.F2.7.7.7.6.8.1">vs</span>. IS under different sampling efficiencies. We can achieve <math alttext="\text{FID}\approx 4.0" class="ltx_Math" display="inline" id="S4.F2.5.5.5.4.4.m1.1"><semantics id="S4.F2.5.5.5.4.4.m1.1a"><mrow id="S4.F2.5.5.5.4.4.m1.1.1" xref="S4.F2.5.5.5.4.4.m1.1.1.cmml"><mtext id="S4.F2.5.5.5.4.4.m1.1.1.2" xref="S4.F2.5.5.5.4.4.m1.1.1.2a.cmml">FID</mtext><mo id="S4.F2.5.5.5.4.4.m1.1.1.1" xref="S4.F2.5.5.5.4.4.m1.1.1.1.cmml">â‰ˆ</mo><mn id="S4.F2.5.5.5.4.4.m1.1.1.3" xref="S4.F2.5.5.5.4.4.m1.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.5.5.5.4.4.m1.1b"><apply id="S4.F2.5.5.5.4.4.m1.1.1.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1"><approx id="S4.F2.5.5.5.4.4.m1.1.1.1.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1.1"></approx><ci id="S4.F2.5.5.5.4.4.m1.1.1.2a.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1.2"><mtext id="S4.F2.5.5.5.4.4.m1.1.1.2.cmml" xref="S4.F2.5.5.5.4.4.m1.1.1.2">FID</mtext></ci><cn id="S4.F2.5.5.5.4.4.m1.1.1.3.cmml" type="float" xref="S4.F2.5.5.5.4.4.m1.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.5.5.4.4.m1.1c">\text{FID}\approx 4.0</annotation><annotation encoding="application/x-llamapun" id="S4.F2.5.5.5.4.4.m1.1d">FID â‰ˆ 4.0</annotation></semantics></math> within 43 milliseconds (not plotted in the figure for compactness). Additionally, the figure shows that D-JEPA can achieve <math alttext="\text{FID}\approx 2.0" class="ltx_Math" display="inline" id="S4.F2.6.6.6.5.5.m2.1"><semantics id="S4.F2.6.6.6.5.5.m2.1a"><mrow id="S4.F2.6.6.6.5.5.m2.1.1" xref="S4.F2.6.6.6.5.5.m2.1.1.cmml"><mtext id="S4.F2.6.6.6.5.5.m2.1.1.2" xref="S4.F2.6.6.6.5.5.m2.1.1.2a.cmml">FID</mtext><mo id="S4.F2.6.6.6.5.5.m2.1.1.1" xref="S4.F2.6.6.6.5.5.m2.1.1.1.cmml">â‰ˆ</mo><mn id="S4.F2.6.6.6.5.5.m2.1.1.3" xref="S4.F2.6.6.6.5.5.m2.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.6.6.6.5.5.m2.1b"><apply id="S4.F2.6.6.6.5.5.m2.1.1.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1"><approx id="S4.F2.6.6.6.5.5.m2.1.1.1.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1.1"></approx><ci id="S4.F2.6.6.6.5.5.m2.1.1.2a.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1.2"><mtext id="S4.F2.6.6.6.5.5.m2.1.1.2.cmml" xref="S4.F2.6.6.6.5.5.m2.1.1.2">FID</mtext></ci><cn id="S4.F2.6.6.6.5.5.m2.1.1.3.cmml" type="float" xref="S4.F2.6.6.6.5.5.m2.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.6.6.6.5.5.m2.1c">\text{FID}\approx 2.0</annotation><annotation encoding="application/x-llamapun" id="S4.F2.6.6.6.5.5.m2.1d">FID â‰ˆ 2.0</annotation></semantics></math> within 120 milliseconds. Refer to TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T4" title="Table 4 â€£ Sampling efficiency. â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> for more details. All times are the average inference time using a batch size of 256 on a single H800 GPU for generating <math alttext="256\times 256" class="ltx_Math" display="inline" id="S4.F2.7.7.7.6.6.m3.1"><semantics id="S4.F2.7.7.7.6.6.m3.1a"><mrow id="S4.F2.7.7.7.6.6.m3.1.1" xref="S4.F2.7.7.7.6.6.m3.1.1.cmml"><mn id="S4.F2.7.7.7.6.6.m3.1.1.2" xref="S4.F2.7.7.7.6.6.m3.1.1.2.cmml">256</mn><mo id="S4.F2.7.7.7.6.6.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.F2.7.7.7.6.6.m3.1.1.1.cmml">Ã—</mo><mn id="S4.F2.7.7.7.6.6.m3.1.1.3" xref="S4.F2.7.7.7.6.6.m3.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.7.7.7.6.6.m3.1b"><apply id="S4.F2.7.7.7.6.6.m3.1.1.cmml" xref="S4.F2.7.7.7.6.6.m3.1.1"><times id="S4.F2.7.7.7.6.6.m3.1.1.1.cmml" xref="S4.F2.7.7.7.6.6.m3.1.1.1"></times><cn id="S4.F2.7.7.7.6.6.m3.1.1.2.cmml" type="integer" xref="S4.F2.7.7.7.6.6.m3.1.1.2">256</cn><cn id="S4.F2.7.7.7.6.6.m3.1.1.3.cmml" type="integer" xref="S4.F2.7.7.7.6.6.m3.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.7.7.7.6.6.m3.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.F2.7.7.7.6.6.m3.1d">256 Ã— 256</annotation></semantics></math> images.</figcaption>
</div>
</td>
</tr>
</table>
</figure>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Quantitative analysis.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.2">We present the FrÃ©chet Inception Distance (FID) along with other metrics in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T1" title="Table 1 â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> without classifier-free guidance. Two critical conclusions can be drawn from the results: <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.2.1">State-of-the-Art Performance</span>: D-JEPA achieves state-of-the-art FID and Inception Score (IS) across all model scales. In particular, D-JEPA-L, with only 687M parameters, surpasses all previous works with <math alttext="\text{FID}=2.32,\text{IS}=233.5" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.1.m1.2"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.2a"><mrow id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3.cmml"><mrow id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2a.cmml">FID</mtext><mo id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml">2.32</mn></mrow><mo id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2a.cmml">IS</mtext><mo id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3.cmml">233.5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.2b"><apply id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.3a.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1"><eq id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.2">FID</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.1.3">2.32</cn></apply><apply id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2"><eq id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2"><mtext id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.2">IS</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.1.m1.2.2.2.2.3">233.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.2c">\text{FID}=2.32,\text{IS}=233.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.1.m1.2d">FID = 2.32 , IS = 233.5</annotation></semantics></math>. The larger model, D-JEPA-H, further improves the benchmark set by D-JEPA-L to <math alttext="\text{FID}=2.04,\text{IS}=239.3" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.2.m2.2"><semantics id="S4.SS1.SSS0.Px1.p1.2.m2.2a"><mrow id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3.cmml"><mrow id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2a.cmml">FID</mtext><mo id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3.cmml">2.04</mn></mrow><mo id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3a.cmml">,</mo><mrow id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.cmml"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2a.cmml">IS</mtext><mo id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3.cmml">239.3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.2.m2.2b"><apply id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.3a.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1"><eq id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.2">FID</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.1.3">2.04</cn></apply><apply id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2"><eq id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.1"></eq><ci id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2a.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2"><mtext id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.2">IS</mtext></ci><cn id="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3.cmml" type="float" xref="S4.SS1.SSS0.Px1.p1.2.m2.2.2.2.2.3">239.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.2.m2.2c">\text{FID}=2.04,\text{IS}=239.3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.2.m2.2d">FID = 2.04 , IS = 239.3</annotation></semantics></math>. <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px1.p1.2.2">Efficiency in Training</span>: As the model scale increases, the required number of training epochs for D-JEPA decreases significantly. Both D-JEPA-L and D-JEPA-H achieve state-of-the-art performance with substantially fewer training epochs compared to other models. For instance, D-JEPA-L, with 687M parameters and 480 training epochs, outperforms the previous state-of-the-art model, MAR-H, which has 943M parameters and requires 800 training epochs.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p2.3">It is well known that selecting an appropriate <span class="ltx_text ltx_markedasmath" id="S4.SS1.SSS0.Px1.p2.3.1">cfg</span> scale can significantly enhance the quality of generated images. For D-JEPA, in addition to adjusting the <span class="ltx_text ltx_markedasmath" id="S4.SS1.SSS0.Px1.p2.3.2">cfg</span> scale, it is also necessary to choose an appropriate temperature <math alttext="\tau" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p2.3.m3.1"><semantics id="S4.SS1.SSS0.Px1.p2.3.m3.1a"><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.3.m3.1b"><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.3.m3.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p2.3.m3.1d">italic_Ï„</annotation></semantics></math> to ensure optimal generation quality. We employ a coarse-to-fine grid search to determine the optimal sampling parameters, as detailed in the Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">C.2</span></a>. The optimal sampling configurations are listed on Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T5" title="Table 5 â€£ Sampling efficiency. â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p3.1">We list additional results in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T2" title="Table 2 â€£ Scaling law of D-JEPA. â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a> with classifier-free guidance. To better showcase D-JEPAâ€™s performance, we provide two sets of sampling performance metrics for each model scale, representing the optimal FID and settings more inclined towards IS. The table reveals that D-JEPA achieves superior results in this scenario as well. Specifically, D-JEPA-L and D-JEPA-H reach FID scores of 1.58 and 1.54, respectively, which are very close to the upper limit of the used VAE (FID = 1.199). Although MAR-H achieves a comparable FID (1.55), its IS (303.7) is significantly lower than that of D-JEPA-L (327.2) and D-JEPA-H (341.0), and it requires more training epochs.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Qualitative analysis.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S5.F3" title="Figure 3 â€£ 5 Conclusion â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3</span></a>, we present images generated using the next set-of-tokens prediction. Even when trained on ImageNet1k, D-JEPA is capable of producing highly realistic images with rich and clear local details. Notably, the figure also demonstrates that D-JEPA-H can generate high-quality portraits (the second picture in the second row), a capability not seen in previous generative models. Additionally, as shown in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F5" title="Figure 5 â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>, we observe the images generated at different auto-regressive steps. Even with just 8 steps, D-JEPA demonstrates significant generative capabilities, and at 64 steps, it nearly matches the image quality achieved at 256 steps. Fewer auto-regressive steps imply faster image generation, which is crucial for practical applications. In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.F2" title="Figure 2 â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, we use a bubble chart to illustrate D-JEPAâ€™s performance under different computational costs. Remarkably, we can sample high-quality images with <math alttext="\text{FID}\approx 4.0" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mtext id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2a.cmml">FID</mtext><mo id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml">â‰ˆ</mo><mn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1"><approx id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.1"></approx><ci id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2a.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2"><mtext id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.2">FID</mtext></ci><cn id="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px2.p1.1.m1.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.p1.1.m1.1c">\text{FID}\approx 4.0</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px2.p1.1.m1.1d">FID â‰ˆ 4.0</annotation></semantics></math> in just 43 milliseconds, which significantly outperforms previous diffusion models and auto-regressive models.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Scaling law of D-JEPA.</h4>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.5">
<tr class="ltx_tr" id="S4.T2.4.4">
<td class="ltx_td ltx_border_r" id="S4.T2.4.4.5"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.4.4.6">#params</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.1">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.m1.1.1" stretchy="false" xref="S4.T2.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.2.2.2">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.m1.1a"><mo id="S4.T2.2.2.2.m1.1.1" stretchy="false" xref="S4.T2.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><ci id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.3.3.3">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.m1.1a"><mo id="S4.T2.3.3.3.m1.1.1" stretchy="false" xref="S4.T2.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><ci id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.4.4">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.m1.1a"><mo id="S4.T2.4.4.4.m1.1.1" stretchy="false" xref="S4.T2.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.m1.1b"><ci id="S4.T2.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.m1.1d">â†‘</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.6" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" id="S4.T2.5.6.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T2.5.6.1.1" style="background-color:#EFEFEF;">Base scale model (less than 300M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.7.1">MAR-BÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.7.2">208M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.3">2.31</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.7.4">281.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.7.5.1">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.7.6">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.8.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.8.1.1" style="background-color:#ECF4FF;">D-JEPA-B(cfg=3.1)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.8.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.8.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.3.1" style="background-color:#ECF4FF;">1.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.8.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.8.4.1" style="background-color:#ECF4FF;">282.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.5"><span class="ltx_text" id="S4.T2.5.8.5.1" style="background-color:#ECF4FF;">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.8.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.8.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.9" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.9.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.9.1.1" style="background-color:#ECF4FF;">D-JEPA-B(cfg=4.1)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.9.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.9.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.3"><span class="ltx_text" id="S4.T2.5.9.3.1" style="background-color:#ECF4FF;">2.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.9.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T2.5.9.4.1" style="background-color:#ECF4FF;">320.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.9.5.1" style="background-color:#ECF4FF;">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.9.6"><span class="ltx_text" id="S4.T2.5.9.6.1" style="background-color:#ECF4FF;">0.59</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="S4.T2.5.5.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T2.5.5.1.1" style="background-color:#EFEFEF;">Large scale model (300<math alttext="\sim" class="ltx_Math" display="inline" id="S4.T2.5.5.1.1.m1.1" style="background-color:#EFEFEF;"><semantics id="S4.T2.5.5.1.1.m1.1a"><mo id="S4.T2.5.5.1.1.m1.1.1" mathbackground="#EFEFEF" xref="S4.T2.5.5.1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.1.m1.1b"><csymbol cd="latexml" id="S4.T2.5.5.1.1.m1.1.1.cmml" xref="S4.T2.5.5.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.1.1.m1.1d">âˆ¼</annotation></semantics></math>700M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.10.1">GIVTÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.10.2">304M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.3">3.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.10.4">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.5">0.84</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.10.6">0.53</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.11.1">MAGVIT-v2Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.11.2">307M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.3">1.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.11.4">319.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.11.6">-</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.12.1">LDM-4Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.12.2">400M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.3">3.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.12.4">247.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.12.5.1">0.87</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.12.6">0.48</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.13.1">MAR-LÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.13.2">479M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.3">1.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.13.4">296.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.5">0.81</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.13.6">0.60</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.14.1">U-ViT-HÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib7" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.14.2">501M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.14.3">2.29</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.14.4">263.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.14.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.14.6">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.15.1">ADMÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.15.2">554M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.15.3">4.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.15.4">186.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.15.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.15.6">0.52</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.16.1">Flag-DiTÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib129" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.16.2">600M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.16.3">2.40</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.16.4">243.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.16.5">0.81</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.16.6">0.58</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.17.1">Next-DiTÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.17.2">600M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.17.3">2.36</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.17.4">250.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.17.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.17.6">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.18">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.18.1">DiT-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.18.2">675M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.18.3">2.27</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.18.4">278.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.18.5">0.83</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.18.6">0.57</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.19">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.19.1">SiT-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.19.2">675M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.19.3">2.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.19.4">270.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.19.5">0.82</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.19.6">0.59</td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.20">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.20.1">MDTv2-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.20.2">676M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.20.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.20.3.1">1.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.20.4">314.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.20.5">0.79</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.20.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.20.6.1">0.65</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.21" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.21.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.21.1.1" style="background-color:#ECF4FF;">D-JEPA-L(cfg=3.0)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.21.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.21.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.21.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.21.3.1" style="background-color:#ECF4FF;">1.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.21.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.21.4.1" style="background-color:#ECF4FF;">303.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.21.5"><span class="ltx_text" id="S4.T2.5.21.5.1" style="background-color:#ECF4FF;">0.80</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.21.6"><span class="ltx_text" id="S4.T2.5.21.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.22" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.22.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.22.1.1" style="background-color:#ECF4FF;">D-JEPA-L(cfg=3.9)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.22.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.22.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.22.3"><span class="ltx_text" id="S4.T2.5.22.3.1" style="background-color:#ECF4FF;">1.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.22.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T2.5.22.4.1" style="background-color:#ECF4FF;">327.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.22.5"><span class="ltx_text" id="S4.T2.5.22.5.1" style="background-color:#ECF4FF;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.22.6"><span class="ltx_text" id="S4.T2.5.22.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.23" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="S4.T2.5.23.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="S4.T2.5.23.1.1" style="background-color:#EFEFEF;">Huge scale model (900+M)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.24">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.24.1">MAR-HÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.24.2">943M</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.24.3">1.55</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.24.4">303.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.24.5">0.81</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.24.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.24.6.1">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.25" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.25.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.25.1.1" style="background-color:#ECF4FF;">D-JEPA-H(cfg=3.9)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.25.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.25.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.25.3"><span class="ltx_text ltx_font_bold" id="S4.T2.5.25.3.1" style="background-color:#ECF4FF;">1.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.25.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.25.4.1" style="background-color:#ECF4FF;">324.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.25.5"><span class="ltx_text" id="S4.T2.5.25.5.1" style="background-color:#ECF4FF;">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.25.6"><span class="ltx_text ltx_font_bold" id="S4.T2.5.25.6.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.26" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.26.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.26.1.1" style="background-color:#ECF4FF;">D-JEPA-H(cfg=4.3)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.26.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.26.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.26.3"><span class="ltx_text" id="S4.T2.5.26.3.1" style="background-color:#ECF4FF;">1.68</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.26.4" style="background-color:#ECF4FF;"><span class="ltx_text" id="S4.T2.5.26.4.1" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="S4.T2.5.26.4.1.1" style="background-color:#ECF4FF;">341.0</span></span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.26.5"><span class="ltx_text ltx_font_bold" id="S4.T2.5.26.5.1" style="background-color:#ECF4FF;">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.26.6"><span class="ltx_text" id="S4.T2.5.26.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.5.27">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.27.1">VDM++Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib57" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.5.27.2">2.0B</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.27.3">2.12</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.5.27.4">267.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.27.5">-</td>
<td class="ltx_td ltx_align_center" id="S4.T2.5.27.6">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>System-level comparison on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="S4.T2.7.m1.1"><semantics id="S4.T2.7.m1.1b"><mrow id="S4.T2.7.m1.1.1" xref="S4.T2.7.m1.1.1.cmml"><mn id="S4.T2.7.m1.1.1.2" xref="S4.T2.7.m1.1.1.2.cmml">256</mn><mo id="S4.T2.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.T2.7.m1.1.1.1.cmml">Ã—</mo><mn id="S4.T2.7.m1.1.1.3" xref="S4.T2.7.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.m1.1c"><apply id="S4.T2.7.m1.1.1.cmml" xref="S4.T2.7.m1.1.1"><times id="S4.T2.7.m1.1.1.1.cmml" xref="S4.T2.7.m1.1.1.1"></times><cn id="S4.T2.7.m1.1.1.2.cmml" type="integer" xref="S4.T2.7.m1.1.1.2">256</cn><cn id="S4.T2.7.m1.1.1.3.cmml" type="integer" xref="S4.T2.7.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.m1.1e">256 Ã— 256</annotation></semantics></math> conditional generation. To better showcase model performance, each model is evaluated with two different cfg scales (obtained by grid searching). One cfg scale provides the best FID score, while the other yields a better IS result at the cost of a negligible degradation in the FID score.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">In summary, as the parameter scale increases, D-JEPA achieves better performance with fewer training epochs, demonstrating excellent scalability. Although similar conclusions have been observed in Â <cite class="ltx_cite ltx_citemacro_cite">Peebles &amp; Xie (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite> and Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, for the former, the required training epochs increase with model size, and for the latter, the required training epochs do not decrease with model size.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p2.1">Moreover, with increasing model size, we are surprised to find that the number of auto-regressive steps required for D-JEPA to achieve optimal sampling results also significantly decreases<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Refer to AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.SS2" title="C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">C.2</span></a> for more details.</span></span></span>. Specifically, for D-JEPA-H, we achieve the best sampling results with just 64 steps. This property ensures performance for constructing larger models and generating ultra-high-definition images and videos such as SoraÂ <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib77" title="">2024</a>)</cite> in the future.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Comprehensive Experiments</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In the Appendix, we further demonstrate the excellent inpainting and outpainting capabilities of the D-JEPA model (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.SS3" title="D.3 Inpainting and Outpainting â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">D.3</span></a>). Beyond diffusion loss, we also designed a flow matching loss to construct D-JEPA (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">F</span></a>). Experiments show that flow matching loss performs better on many tasks. Consequently, we extended our experiments based on flow matching loss to include text-to-image/audio generation and class-conditional video generation. These extended experiments fully demonstrate that D-JEPA is capable of generating various types of continuous data, not limited to images. Furthermore, we attempted to construct a multimodal generation model based on D-JEPA. The results indicate that D-JEPA can generate continuous data and be used to build multimodal understanding and generation models (Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7" title="Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">G</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this study, we have introduced D-JEPA as a novel generative model that can handle the generation of continuous data. Through extensive experiments, we have preliminarily validated the feasibility of this approach. However, scaling up the D-JEPA model remains a significant challenge that warrants further investigation. Additionally, the acceleration strategies and application ecosystems for diffusion models and auto-regressive models have already reached a high level of maturity. Adopting these successful strategies for the further development of D-JEPA is crucial. We hope that this work will inspire future researchers to explore the D-JEPA architecture, laying the groundwork for the construction of a unified multimodal model in the future.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1242" id="S5.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>D-JEPA achieves state-of-the-art image quality. We showcase selected high-fidelity examples of class-conditional generation on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="S5.F3.2.m1.1"><semantics id="S5.F3.2.m1.1b"><mrow id="S5.F3.2.m1.1.1" xref="S5.F3.2.m1.1.1.cmml"><mn id="S5.F3.2.m1.1.1.2" xref="S5.F3.2.m1.1.1.2.cmml">256</mn><mo id="S5.F3.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.F3.2.m1.1.1.1.cmml">Ã—</mo><mn id="S5.F3.2.m1.1.1.3" xref="S5.F3.2.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><apply id="S5.F3.2.m1.1.1.cmml" xref="S5.F3.2.m1.1.1"><times id="S5.F3.2.m1.1.1.1.cmml" xref="S5.F3.2.m1.1.1.1"></times><cn id="S5.F3.2.m1.1.1.2.cmml" type="integer" xref="S5.F3.2.m1.1.1.2">256</cn><cn id="S5.F3.2.m1.1.1.3.cmml" type="integer" xref="S5.F3.2.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="S5.F3.2.m1.1e">256 Ã— 256</annotation></semantics></math> using D-JEPA-H.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Albergo etÂ al. (2023)</span>
<span class="ltx_bibblock">
MichaelÂ S Albergo, NicholasÂ M Boffi, and Eric Vanden-Eijnden.

</span>
<span class="ltx_bibblock">Stochastic interpolants: A unifying framework for flows and diffusions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08797</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assran etÂ al. (2021)</span>
<span class="ltx_bibblock">
Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Armand Joulin, Nicolas Ballas, and Michael Rabbat.

</span>
<span class="ltx_bibblock">Semi-supervised learning of visual features by non-parametrically predicting view assignments with support samples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE/CVF International Conference on Computer Vision</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assran etÂ al. (2022)</span>
<span class="ltx_bibblock">
Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Mike Rabbat, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">Masked siamese networks for label-efficient learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">European Conference on Computer Vision</em>, pp.Â  456â€“473. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Assran etÂ al. (2023)</span>
<span class="ltx_bibblock">
Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">Self-supervised learning from images with a joint-embedding predictive architecture.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  15619â€“15629, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ba etÂ al. (2016)</span>
<span class="ltx_bibblock">
JimmyÂ Lei Ba, JamieÂ Ryan Kiros, and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Layer normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:1607.06450</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baevski etÂ al. (2022)</span>
<span class="ltx_bibblock">
Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, and Michael Auli.

</span>
<span class="ltx_bibblock">Data2vec: A general framework for self-supervised learning in speech, vision and language.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Conference on Machine Learning</em>, pp.Â  1298â€“1312. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao etÂ al. (2022)</span>
<span class="ltx_bibblock">
Fan Bao, Chongxuan Li, Yue Cao, and Jun Zhu.

</span>
<span class="ltx_bibblock">All are worth words: a vit backbone for score-based diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">NeurIPS 2022 Workshop on Score-Based Methods</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao etÂ al. (2021)</span>
<span class="ltx_bibblock">
Hangbo Bao, LiÂ Dong, Songhao Piao, and Furu Wei.

</span>
<span class="ltx_bibblock">Beit: Bert pre-training of image transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes etÂ al. (2021)</span>
<span class="ltx_bibblock">
Adrien Bardes, Jean Ponce, and Yann LeCun.

</span>
<span class="ltx_bibblock">Vicreg: Variance-invariance-covariance regularization for self-supervised learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2105.04906</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Adrien Bardes, Quentin Garrido, Jean Ponce, Xinlei Chen, Michael Rabbat, Yann LeCun, Mido Assran, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">V-jepa: Latent video prediction for visual representation learning.

</span>
<span class="ltx_bibblock">2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Adrien Bardes, Jean Ponce, and Yann LeCun.

</span>
<span class="ltx_bibblock">Mc-jepa: A joint-embedding predictive architecture for self-supervised learning of motion and content features.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2307.12698</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bardes etÂ al. (2024)</span>
<span class="ltx_bibblock">
Adrien Bardes, Quentin Garrido, Jean Ponce, Xinlei Chen, Michael Rabbat, Yann LeCun, Mahmoud Assran, and Nicolas Ballas.

</span>
<span class="ltx_bibblock">Revisiting feature prediction for learning visual representations from video.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2404.08471</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brock etÂ al. (2019)</span>
<span class="ltx_bibblock">
Andrew Brock, Jeff Donahue, and Karen Simonyan.

</span>
<span class="ltx_bibblock">Large scale GAN training for high fidelity natural image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Int. Conf. on Learning Representations (ICLR)</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown etÂ al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, JaredÂ D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, etÂ al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Advances in neural information processing systems</em>, 33:1877â€“1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caron etÂ al. (2021)</span>
<span class="ltx_bibblock">
Mathilde Caron, Hugo Touvron, Ishan Misra, HervÃ© JÃ©gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.

</span>
<span class="ltx_bibblock">Emerging properties in self-supervised vision transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the IEEE/CVF international conference on computer vision</em>, pp.Â  9650â€“9660, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Huiwen Chang, Han Zhang, LuÂ Jiang, CeÂ Liu, and WilliamÂ T Freeman.

</span>
<span class="ltx_bibblock">Maskgit: Masked generative image transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  11315â€“11325, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, and Zhenguo Li.

</span>
<span class="ltx_bibblock">Pixart-<math alttext="\alpha" class="ltx_Math" display="inline" id="bib.bib17.1.m1.1"><semantics id="bib.bib17.1.m1.1a"><mi id="bib.bib17.1.m1.1.1" xref="bib.bib17.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="bib.bib17.1.m1.1b"><ci id="bib.bib17.1.m1.1.1.cmml" xref="bib.bib17.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib17.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="bib.bib17.1.m1.1d">italic_Î±</annotation></semantics></math>: Fast training of diffusion transformer for photorealistic text-to-image synthesis, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2020)</span>
<span class="ltx_bibblock">
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Generative pretraining from pixels.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International conference on machine learning</em>, pp.Â  1691â€“1703. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2021a)</span>
<span class="ltx_bibblock">
Mingjian Chen, XuÂ Tan, Bohan Li, Yanqing Liu, Tao Qin, Sheng Zhao, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Adaspeech: Adaptive text to speech for custom voice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2103.00993</em>, 2021a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2018)</span>
<span class="ltx_bibblock">
XiÂ Chen, Nikhil Mishra, Mostafa Rohaninejad, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Pixelsnail: An improved autoregressive generative model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">International conference on machine learning</em>, pp.Â  864â€“872. PMLR, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2024)</span>
<span class="ltx_bibblock">
Xiaokang Chen, Mingyu Ding, Xiaodi Wang, Ying Xin, Shentong Mo, Yunhao Wang, Shumin Han, Ping Luo, Gang Zeng, and Jingdong Wang.

</span>
<span class="ltx_bibblock">Context autoencoder for self-supervised representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">International Journal of Computer Vision</em>, 132(1):208â€“223, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen &amp; He (2021)</span>
<span class="ltx_bibblock">
Xinlei Chen and Kaiming He.

</span>
<span class="ltx_bibblock">Exploring simple siamese representation learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  15750â€“15758, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2021b)</span>
<span class="ltx_bibblock">
Xinlei Chen, Saining Xie, and Kaiming He.

</span>
<span class="ltx_bibblock">An empirical study of training self-supervised vision transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Int. Conference on Computer Vision (ICCV)</em>, pp.Â  9640â€“9649, 2021b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi etÂ al. (2023)</span>
<span class="ltx_bibblock">
Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and Shuran Song.

</span>
<span class="ltx_bibblock">Diffusion policy: Visuomotor policy learning via action diffusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2303.04137</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Croitoru etÂ al. (2023)</span>
<span class="ltx_bibblock">
Florinel-Alin Croitoru, Vlad Hondru, RaduÂ Tudor Ionescu, and Mubarak Shah.

</span>
<span class="ltx_bibblock">Diffusion models in vision: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 45(9):10850â€“10869, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhariwal &amp; Nichol (2021)</span>
<span class="ltx_bibblock">
Prafulla Dhariwal and Alexander Nichol.

</span>
<span class="ltx_bibblock">Diffusion models beat gans on image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in neural information processing systems</em>, 34:8780â€“8794, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Donahue &amp; Simonyan (2019)</span>
<span class="ltx_bibblock">
Jeff Donahue and Karen Simonyan.

</span>
<span class="ltx_bibblock">Large scale adversarial representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong etÂ al. (2021)</span>
<span class="ltx_bibblock">
Xiaoyi Dong, Jianmin Bao, Ting Zhang, Dongdong Chen, Weiming Zhang, LuÂ Yuan, Dong Chen, Fang Wen, and Nenghai Yu.

</span>
<span class="ltx_bibblock">Peco: Perceptual codebook for bert pre-training of vision transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2111.12710</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy etÂ al. (2020)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, etÂ al.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2010.11929</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elfwing etÂ al. (2018)</span>
<span class="ltx_bibblock">
Stefan Elfwing, Eiji Uchibe, and Kenji Doya.

</span>
<span class="ltx_bibblock">Sigmoid-weighted linear units for neural network function approximation in reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Neural networks</em>, 107:3â€“11, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser etÂ al. (2021)</span>
<span class="ltx_bibblock">
Patrick Esser, Robin Rombach, and Bjorn Ommer.

</span>
<span class="ltx_bibblock">Taming transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  12873â€“12883, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser etÂ al. (2024)</span>
<span class="ltx_bibblock">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas MÃ¼ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, etÂ al.

</span>
<span class="ltx_bibblock">Scaling rectified flow transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2403.03206</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shanghua Gao, Pan Zhou, Ming-Ming Cheng, and Shuicheng Yan.

</span>
<span class="ltx_bibblock">Mdtv2: Masked diffusion transformer is a strong image synthesizer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2303.14389</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gidaris etÂ al. (2018)</span>
<span class="ltx_bibblock">
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.

</span>
<span class="ltx_bibblock">Unsupervised representation learning by predicting image rotations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:1803.07728</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow etÂ al. (2020)</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Communications of the ACM</em>, 63(11):139â€“144, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow etÂ al. (2014)</span>
<span class="ltx_bibblock">
IanÂ J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative adversarial nets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gregor etÂ al. (2014)</span>
<span class="ltx_bibblock">
Karol Gregor, Ivo Danihelka, Andriy Mnih, Charles Blundell, and Daan Wierstra.

</span>
<span class="ltx_bibblock">Deep autoregressive networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">International Conference on Machine Learning</em>, pp.Â  1242â€“1250. PMLR, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grill etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jean-Bastien Grill, Florian Strub, Florent AltchÃ©, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo AvilaÂ Pires, Zhaohan Guo, Mohammad GheshlaghiÂ Azar, etÂ al.

</span>
<span class="ltx_bibblock">Bootstrap your own latent-a new approach to self-supervised learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Advances in neural information processing systems</em>, 33:21271â€“21284, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guetschel etÂ al. (2024)</span>
<span class="ltx_bibblock">
Pierre Guetschel, Thomas Moreau, and Michael Tangermann.

</span>
<span class="ltx_bibblock">S-jepa: towards seamless cross-dataset transfer through dynamic spatial attention.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2403.11772</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hatamizadeh etÂ al. (2023)</span>
<span class="ltx_bibblock">
Ali Hatamizadeh, Jiaming Song, Guilin Liu, Jan Kautz, and Arash Vahdat.

</span>
<span class="ltx_bibblock">Diffit: Diffusion vision transformers for image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2312.02139</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.Â  770â€“778, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2019)</span>
<span class="ltx_bibblock">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.

</span>
<span class="ltx_bibblock">Momentum contrast for unsupervised visual representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:1911.05722</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.

</span>
<span class="ltx_bibblock">Momentum contrast for unsupervised visual representation learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  9729â€“9738, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, and Ross Girshick.

</span>
<span class="ltx_bibblock">Masked autoencoders are scalable vision learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  16000â€“16009, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and Qifeng Chen.

</span>
<span class="ltx_bibblock">Latent video diffusion models for high-fidelity long video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2211.13221</em>, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heusel etÂ al. (2017)</span>
<span class="ltx_bibblock">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Gans trained by a two time-scale update rule converge to a local nash equilibrium.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, volumeÂ 33, pp.Â  6840â€“6851, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and DavidÂ J Fleet.

</span>
<span class="ltx_bibblock">Video diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Advances in Neural Information Processing Systems</em>, 35:8633â€“8646, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Rongjie Huang, Jiawei Huang, Dongchao Yang, YiÂ Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao.

</span>
<span class="ltx_bibblock">Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">International Conference on Machine Learning</em>, pp.Â  13916â€“13932. PMLR, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Zhicheng Huang, Xiaojie Jin, Chengze Lu, Qibin Hou, Ming-Ming Cheng, Dongmei Fu, Xiaohui Shen, and Jiashi Feng.

</span>
<span class="ltx_bibblock">Contrastive masked autoencoders are stronger vision learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ito (2017)</span>
<span class="ltx_bibblock">
Keith Ito.

</span>
<span class="ltx_bibblock">The lj speech dataset.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://keithito.com/LJ-Speech-Dataset/" title="">https://keithito.com/LJ-Speech-Dataset/</a>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras etÂ al. (2019)</span>
<span class="ltx_bibblock">
Tero Karras, Samuli Laine, and Timo Aila.

</span>
<span class="ltx_bibblock">A style-based generator architecture for generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  4401â€“4410, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karras etÂ al. (2022)</span>
<span class="ltx_bibblock">
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.

</span>
<span class="ltx_bibblock">Elucidating the design space of diffusion-based generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Advances in Neural Information Processing Systems</em>, 35:26565â€“26577, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kendall etÂ al. (2018)</span>
<span class="ltx_bibblock">
Alex Kendall, Yarin Gal, and Roberto Cipolla.

</span>
<span class="ltx_bibblock">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.Â  7482â€“7491, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kenton &amp; Toutanova (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin Ming-WeiÂ Chang Kenton and LeeÂ Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Proceedings of naacL-HLT</em>, volumeÂ 1, pp.Â Â 2. Minneapolis, Minnesota, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kilian etÂ al. (2024)</span>
<span class="ltx_bibblock">
Maciej Kilian, Varun Japan, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Computational tradeoffs in image synthesis: Diffusion, masked-token, and next-token prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2405.13218</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Gao (2024)</span>
<span class="ltx_bibblock">
Diederik Kingma and Ruiqi Gao.

</span>
<span class="ltx_bibblock">Understanding diffusion objectives as the elbo with simple data augmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kolesnikov etÂ al. (2022)</span>
<span class="ltx_bibblock">
Alexander Kolesnikov, AndrÃ© SusanoÂ Pinto, Lucas Beyer, Xiaohua Zhai, Jeremiah Harmsen, and Neil Houlsby.

</span>
<span class="ltx_bibblock">Uvim: A unified modeling approach for vision with learned guiding codes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in Neural Information Processing Systems</em>, 35:26295â€“26308, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kong etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae.

</span>
<span class="ltx_bibblock">Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Proc. of NeurIPS</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky etÂ al. (2012)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Advances in neural information processing systems</em>, 25, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">KynkÃ¤Ã¤nniemi etÂ al. (2019)</span>
<span class="ltx_bibblock">
Tuomas KynkÃ¤Ã¤nniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila.

</span>
<span class="ltx_bibblock">Improved precision and recall metric for assessing generative models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun (2022)</span>
<span class="ltx_bibblock">
Yann LeCun.

</span>
<span class="ltx_bibblock">A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Open Review</em>, 62(1):1â€“62, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun etÂ al. (2006)</span>
<span class="ltx_bibblock">
Yann LeCun, Sumit Chopra, Raia Hadsell, MÂ Ranzato, and Fujie Huang.

</span>
<span class="ltx_bibblock">A tutorial on energy-based learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">Predicting structured data</em>, 1(0), 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2022)</span>
<span class="ltx_bibblock">
Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han.

</span>
<span class="ltx_bibblock">Autoregressive image generation using residual quantization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  11523â€“11532, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Tianhong Li, Huiwen Chang, Shlok Mishra, Han Zhang, Dina Katabi, and Dilip Krishnan.

</span>
<span class="ltx_bibblock">Mage: Masked generative encoder to unify representation learning and image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  2142â€“2152, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024)</span>
<span class="ltx_bibblock">
Tianhong Li, Yonglong Tian, HeÂ Li, Mingyang Deng, and Kaiming He.

</span>
<span class="ltx_bibblock">Autoregressive image generation without vector quantization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2406.11838</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lipman etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yaron Lipman, RickyÂ TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.

</span>
<span class="ltx_bibblock">Flow matching for generative modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">The Eleventh International Conference on Learning Representations</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin SoljaÄiÄ‡, ThomasÂ Y Hou, and Max Tegmark.

</span>
<span class="ltx_bibblock">Kan: Kolmogorov-arnold networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">arXiv preprint arXiv:2404.19756</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2017)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv preprint arXiv:1711.05101</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Nanye Ma, Mark Goldstein, MichaelÂ S Albergo, NicholasÂ M Boffi, Eric Vanden-Eijnden, and Saining Xie.

</span>
<span class="ltx_bibblock">Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2401.08740</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Xin Ma, Yaohui Wang, Gengyun Jia, Xinyuan Chen, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, and YuÂ Qiao.

</span>
<span class="ltx_bibblock">Latte: Latent diffusion transformer for video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">arXiv preprint arXiv:2401.03048</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mentzer etÂ al. (2023)</span>
<span class="ltx_bibblock">
Fabian Mentzer, David Minnen, Eirikur Agustsson, and Michael Tschannen.

</span>
<span class="ltx_bibblock">Finite scalar quantization: Vq-vae made simple.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">The Twelfth International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min etÂ al. (2021)</span>
<span class="ltx_bibblock">
Dongchan Min, DongÂ Bok Lee, Eunho Yang, and SungÂ Ju Hwang.

</span>
<span class="ltx_bibblock">Meta-stylespeech: Multi-speaker adaptive text-to-speech generation.

</span>
<span class="ltx_bibblock">pp.Â  7748â€“7759, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo etÂ al. (2024)</span>
<span class="ltx_bibblock">
Sicheng Mo, Fangzhou Mu, KuanÂ Heng Lin, Yanli Liu, Bochen Guan, Yin Li, and Bolei Zhou.

</span>
<span class="ltx_bibblock">Freecontrol: Training-free spatial control of any text-to-image diffusion model with any condition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  7465â€“7475, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol &amp; Dhariwal (2021)</span>
<span class="ltx_bibblock">
AlexanderÂ Quinn Nichol and Prafulla Dhariwal.

</span>
<span class="ltx_bibblock">Improved denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">International Conference on Machine Learning</em>, pp.Â  8162â€“8171. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noroozi &amp; Favaro (2016)</span>
<span class="ltx_bibblock">
Mehdi Noroozi and Paolo Favaro.

</span>
<span class="ltx_bibblock">Unsupervised learning of visual representations by solving jigsaw puzzles.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">European Conference on Computer Vision</em>, pp.Â  69â€“84. Springer, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">https://openai.com/sora.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">OpenAI blog</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmar etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu.

</span>
<span class="ltx_bibblock">On aliased resizing and surprising subtleties in gan evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  11410â€“11420, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmar etÂ al. (2018)</span>
<span class="ltx_bibblock">
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran.

</span>
<span class="ltx_bibblock">Image transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">International conference on machine learning</em>, pp.Â  4055â€“4064. PMLR, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pathak etÂ al. (2016)</span>
<span class="ltx_bibblock">
Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and AlexeiÂ A Efros.

</span>
<span class="ltx_bibblock">Context encoders: Feature learning by inpainting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.Â  2536â€“2544, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peebles &amp; Xie (2023)</span>
<span class="ltx_bibblock">
William Peebles and Saining Xie.

</span>
<span class="ltx_bibblock">Scalable diffusion models with transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  4195â€“4205, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jialun Peng, Dong Liu, Songcen Xu, and Houqiang Li.

</span>
<span class="ltx_bibblock">Generating diverse structure for image inpainting with hierarchical vq-vae.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  10775â€“10784, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2018)</span>
<span class="ltx_bibblock">
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, etÂ al.

</span>
<span class="ltx_bibblock">Improving language understanding by generative pre-training.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, etÂ al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, etÂ al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">International conference on machine learning</em>, pp.Â  8748â€“8763. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel etÂ al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and PeterÂ J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">Journal of machine learning research</em>, 21(140):1â€“67, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh etÂ al. (2021)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Zero-shot text-to-image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">International conference on machine learning</em>, pp.Â  8821â€“8831. Pmlr, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Razavi etÂ al. (2019)</span>
<span class="ltx_bibblock">
Ali Razavi, Aaron VanÂ den Oord, and Oriol Vinyals.

</span>
<span class="ltx_bibblock">Generating diverse high-fidelity images with vq-vae-2.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach etÂ al. (2022)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ¶rn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  10684â€“10695, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Russakovsky etÂ al. (2015)</span>
<span class="ltx_bibblock">
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, etÂ al.

</span>
<span class="ltx_bibblock">Imagenet large scale visual recognition challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">International journal of computer vision</em>, 115(3):211â€“252, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib91">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salimans etÂ al. (2016)</span>
<span class="ltx_bibblock">
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and XiÂ Chen.

</span>
<span class="ltx_bibblock">Improved techniques for training gans.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">Advances in neural information processing systems</em>, 29, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib92">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2019)</span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Fast transformer decoding: One write-head is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">arXiv preprint arXiv:1911.02150</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib93">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.

</span>
<span class="ltx_bibblock">Mostgan-v: Video generation with temporal motion styles.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  5652â€“5661, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib94">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Skorokhodov etÂ al. (2022)</span>
<span class="ltx_bibblock">
Ivan Skorokhodov, Sergey Tulyakov, and Mohamed Elhoseiny.

</span>
<span class="ltx_bibblock">Stylegan-v: A continuous video generator with the price, image quality and perks of stylegan2.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  3626â€“3636, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib95">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jiaming Song, Chenlin Meng, and Stefano Ermon.

</span>
<span class="ltx_bibblock">Denoising diffusion implicit models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib95.1.1">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib96">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song &amp; Ermon (2019)</span>
<span class="ltx_bibblock">
Yang Song and Stefano Ermon.

</span>
<span class="ltx_bibblock">Generative modeling by estimating gradients of the data distribution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib96.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib97">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song etÂ al. (2021)</span>
<span class="ltx_bibblock">
Yang Song, Jascha Sohl-Dickstein, DiederikÂ P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.

</span>
<span class="ltx_bibblock">Score-based generative modeling through stochastic differential equations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib97.1.1">Int. Conf. on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib98">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soomro (2012)</span>
<span class="ltx_bibblock">
KÂ Soomro.

</span>
<span class="ltx_bibblock">Ucf101: A dataset of 101 human actions classes from videos in the wild.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib98.1.1">arXiv preprint arXiv:1212.0402</em>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib99">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha Ahmed, YuÂ Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib99.1.1">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib100">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2019)</span>
<span class="ltx_bibblock">
Hao Sun, XuÂ Tan, Jun-Wei Gan, Hongzhi Liu, Sheng Zhao, Tao Qin, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Token-level ensemble distillation for grapheme-to-phoneme conversion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib100.1.1">arXiv preprint arXiv:1904.03446</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib101">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2024)</span>
<span class="ltx_bibblock">
Keqiang Sun, Junting Pan, Yuying Ge, Hao Li, Haodong Duan, Xiaoshi Wu, Renrui Zhang, Aojun Zhou, Zipeng Qin, YiÂ Wang, etÂ al.

</span>
<span class="ltx_bibblock">Journeydb: A benchmark for generative image understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib101.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib102">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team etÂ al. (2024)</span>
<span class="ltx_bibblock">
OctoÂ Model Team, Dibya Ghosh, Homer Walke, Karl Pertsch, Kevin Black, Oier Mees, Sudeep Dasari, Joey Hejna, Tobias Kreiman, Charles Xu, etÂ al.

</span>
<span class="ltx_bibblock">Octo: An open-source generalist robot policy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib102.1.1">arXiv preprint arXiv:2405.12213</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib103">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian etÂ al. (2020)</span>
<span class="ltx_bibblock">
Yonglong Tian, Dilip Krishnan, and Phillip Isola.

</span>
<span class="ltx_bibblock">Contrastive multiview coding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib103.1.1">Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XI 16</em>, pp.Â  776â€“794. Springer, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib104">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian etÂ al. (2021)</span>
<span class="ltx_bibblock">
Yuandong Tian, Xinlei Chen, and Surya Ganguli.

</span>
<span class="ltx_bibblock">Understanding self-supervised learning dynamics without contrastive pairs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib104.1.1">International Conference on Machine Learning</em>, pp.Â  10268â€“10278. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib105">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tschannen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Michael Tschannen, Cian Eastwood, and Fabian Mentzer.

</span>
<span class="ltx_bibblock">Givt: Generative infinite-vocabulary transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib105.1.1">arXiv preprint arXiv:2312.02116</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib106">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">VanÂ den Oord etÂ al. (2016)</span>
<span class="ltx_bibblock">
Aaron VanÂ den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, etÂ al.

</span>
<span class="ltx_bibblock">Conditional image generation with pixelcnn decoders.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib106.1.1">Advances in neural information processing systems</em>, 29, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib107">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van DenÂ Oord etÂ al. (2016)</span>
<span class="ltx_bibblock">
AÃ¤ron Van DenÂ Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.

</span>
<span class="ltx_bibblock">Pixel recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib107.1.1">International conference on machine learning</em>, pp.Â  1747â€“1756. PMLR, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib108">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van DenÂ Oord etÂ al. (2017)</span>
<span class="ltx_bibblock">
Aaron Van DenÂ Oord, Oriol Vinyals, etÂ al.

</span>
<span class="ltx_bibblock">Neural discrete representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib108.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib109">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2017)</span>
<span class="ltx_bibblock">
Kunfeng Wang, Chao Gou, Yanjie Duan, Yilun Lin, Xinhu Zheng, and Fei-Yue Wang.

</span>
<span class="ltx_bibblock">Generative adversarial networks: introduction and outlook.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib109.1.1">IEEE/CAA Journal of Automatica Sinica</em>, 4(4):588â€“598, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib110">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2023)</span>
<span class="ltx_bibblock">
Chen Wei, Karttikeya Mangalam, Po-Yao Huang, Yanghao Li, Haoqi Fan, HuÂ Xu, Huiyu Wang, Cihang Xie, Alan Yuille, and Christoph Feichtenhofer.

</span>
<span class="ltx_bibblock">Diffusion models as masked autoencoders.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib110.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.Â  16284â€“16294, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib111">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2022)</span>
<span class="ltx_bibblock">
Longhui Wei, Lingxi Xie, Wengang Zhou, Houqiang Li, and QiÂ Tian.

</span>
<span class="ltx_bibblock">Mvp: Multimodality-guided visual pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib111.1.1">arXiv preprint arXiv:2203.05175</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib112">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie etÂ al. (2022)</span>
<span class="ltx_bibblock">
Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, QiÂ Dai, and Han Hu.

</span>
<span class="ltx_bibblock">Simmim: A simple framework for masked image modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib112.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  9653â€“9663, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib113">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan etÂ al. (2021)</span>
<span class="ltx_bibblock">
Wilson Yan, Yunzhi Zhang, Pieter Abbeel, and Aravind Srinivas.

</span>
<span class="ltx_bibblock">Videogpt: Video generation using vq-vae and transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib113.1.1">arXiv preprint arXiv:2104.10157</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib114">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2024a)</span>
<span class="ltx_bibblock">
AnÂ Yang, Baosong Yang, Binyuan Hui, BoÂ Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, etÂ al.

</span>
<span class="ltx_bibblock">Qwen2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib114.1.1">arXiv preprint arXiv:2407.10671</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib115">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, etÂ al.

</span>
<span class="ltx_bibblock">Cogvideox: Text-to-video diffusion models with an expert transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib115.1.1">arXiv preprint arXiv:2408.06072</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib116">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jiahui Yu, Xin Li, JingÂ Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.

</span>
<span class="ltx_bibblock">Vector-quantized image modeling with improved vqgan.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib116.1.1">arXiv preprint arXiv:2110.04627</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib117">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Lijun Yu, Yong Cheng, Kihyuk Sohn, JosÃ© Lezama, Han Zhang, Huiwen Chang, AlexanderÂ G Hauptmann, Ming-Hsuan Yang, Yuan Hao, Irfan Essa, etÂ al.

</span>
<span class="ltx_bibblock">Magvit: Masked generative video transformer.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib117.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.Â  10459â€“10469, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib118">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Lijun Yu, JosÃ© Lezama, NiteshÂ B Gundavarapu, Luca Versari, Kihyuk Sohn, David Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, AlexanderÂ G Hauptmann, etÂ al.

</span>
<span class="ltx_bibblock">Language model beats diffusionâ€“tokenizer is key to visual generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib118.1.1">arXiv preprint arXiv:2310.05737</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib119">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Sihyun Yu, Jihoon Tack, Sangwoo Mo, Hyunsu Kim, Junho Kim, Jung-Woo Ha, and Jinwoo Shin.

</span>
<span class="ltx_bibblock">Generating videos with dynamics-aware implicit generative adversarial networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib119.1.1">arXiv preprint arXiv:2202.10571</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib120">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2023c)</span>
<span class="ltx_bibblock">
Sihyun Yu, Kihyuk Sohn, Subin Kim, and Jinwoo Shin.

</span>
<span class="ltx_bibblock">Video probabilistic diffusion models in projected latent space.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib120.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  18456â€“18466, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib121">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zbontar etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jure Zbontar, LiÂ Jing, Ishan Misra, Yann LeCun, and StÃ©phane Deny.

</span>
<span class="ltx_bibblock">Barlow twins: Self-supervised learning via redundancy reduction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib121.1.1">International conference on machine learning</em>, pp.Â  12310â€“12320. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib122">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng etÂ al. (2021)</span>
<span class="ltx_bibblock">
Yanhong Zeng, Huan Yang, Hongyang Chao, Jianbo Wang, and Jianlong Fu.

</span>
<span class="ltx_bibblock">Improving visual quality of image synthesis by a token-based generator with transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib122.1.1">Advances in Neural Information Processing Systems</em>, 34:21125â€“21137, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib123">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2017a)</span>
<span class="ltx_bibblock">
Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and DimitrisÂ N Metaxas.

</span>
<span class="ltx_bibblock">Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib123.1.1">Proceedings of the IEEE international conference on computer vision</em>, pp.Â  5907â€“5915, 2017a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib124">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus Odena.

</span>
<span class="ltx_bibblock">Self-attention generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib124.1.1">Int. Conference on Machine Learning (icml)</em>, pp.Â  7354â€“7363, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib125">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2017b)</span>
<span class="ltx_bibblock">
Hongyi Zhang, Moustapha Cisse, YannÂ N Dauphin, and David Lopez-Paz.

</span>
<span class="ltx_bibblock">mixup: Beyond empirical risk minimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib125.1.1">arXiv preprint arXiv:1710.09412</em>, 2017b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib126">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2024)</span>
<span class="ltx_bibblock">
Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, and Omer Levy.

</span>
<span class="ltx_bibblock">Transfusion: Predict the next token and diffuse images with one multi-modal model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib126.1.1">arXiv preprint arXiv:2408.11039</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib127">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao Kong.

</span>
<span class="ltx_bibblock">ibot: Image bert pre-training with online tokenizer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib127.1.1">arXiv preprint arXiv:2111.07832</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib128">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuo etÂ al. (2024a)</span>
<span class="ltx_bibblock">
LeÂ Zhuo, Ruoyi Du, Xiao Han, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, etÂ al.

</span>
<span class="ltx_bibblock">Lumina-next: Making lumina-t2x stronger and faster with next-dit.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib128.1.1">arXiv preprint arXiv:2406.18583</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib129">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuo etÂ al. (2024b)</span>
<span class="ltx_bibblock">
LeÂ Zhuo, Ruoyi Du, Han Xiao, Yangguang Li, Dongyang Liu, Rongjie Huang, Wenze Liu, Lirui Zhao, Fu-Yun Wang, Zhanyu Ma, etÂ al.

</span>
<span class="ltx_bibblock">Lumina-next: Making lumina-t2x stronger and faster with next-dit.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib129.1.1">arXiv preprint arXiv:2406.18583</em>, 2024b.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Related Work</h2>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Self-supervised learning.</h4>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1">Early efforts in unsupervised learning emphasized pretext tasks designed to predict pseudo labels, such as solving jigsaw puzzlesÂ <cite class="ltx_cite ltx_citemacro_citep">(Noroozi &amp; Favaro, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib76" title="">2016</a>)</cite>, restoring missing patchesÂ <cite class="ltx_cite ltx_citemacro_citep">(Pathak etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib80" title="">2016</a>)</cite>, and predicting image rotationsÂ <cite class="ltx_cite ltx_citemacro_citep">(Gidaris etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib34" title="">2018</a>)</cite>. Despite yielding useful representations, these methods lagged behind those acquired through supervised learning.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p2.1">The advent of contrastive learning marked a significant leap forward, achieving near-supervised performance with techniques like MoCoÂ <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib43" title="">2020</a>)</cite> and contrastive multiview codingÂ <cite class="ltx_cite ltx_citemacro_citep">(Tian etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib103" title="">2020</a>)</cite>. BYOLÂ <cite class="ltx_cite ltx_citemacro_citep">(Grill etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>)</cite> further advanced the field by eliminating the need for negative pairs and employing peer networks for mutual learning. However, these methods primarily focused on image data and could not be directly applied to other continuous data types, such as audio.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p3.1">Inspired by developments in natural language processing, masked image modeling (MIM) emerged as an effective approach to self-supervised learningÂ <cite class="ltx_cite ltx_citemacro_citep">(Kenton &amp; Toutanova, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib55" title="">2019</a>)</cite>, extendable to continuous data types such as audioÂ <cite class="ltx_cite ltx_citemacro_citep">(Baevski etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>)</cite>. Models such as BEiTÂ <cite class="ltx_cite ltx_citemacro_citep">(Bao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib8" title="">2021</a>)</cite>, PeCoÂ <cite class="ltx_cite ltx_citemacro_citep">(Dong etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib28" title="">2021</a>)</cite>, and MAEÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> focus on recovering visual tokens or performing pixel-level reconstruction. DiffMAEÂ <cite class="ltx_cite ltx_citemacro_citep">(Wei etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib110" title="">2023</a>)</cite> leverages denoising diffusion decoders primarily for representation learning rather than image generation. While MIM-based methods prioritize downstream performance, they often result in suboptimal reconstructionsÂ <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>; Bao etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib8" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p4.1">Recent advances such as MAGEÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite> achieve high-quality representations and image generation. However, these methods are limited to image data, failing to empirically demonstrate mutual reinforcement between tasks. Our work uniquely verifies the mutual benefits of representation learning and generative modeling through empirical evidence, demonstrating how these processes can be synergistically combined for superior performance across different types of continuous data.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Generative modeling.</h4>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1">Generative models have seen significant advances in image synthesis. Generative adversarial networks (GANs)Â <cite class="ltx_cite ltx_citemacro_citep">(Goodfellow etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib36" title="">2014</a>; Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib123" title="">2017a</a>; Karras etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib52" title="">2019</a>; Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib124" title="">2019</a>; Brock etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib13" title="">2019</a>)</cite> excel in producing realistic images but often face challenges such as training instability and mode collapse. Two-stage modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Van DenÂ Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib108" title="">2017</a>; Chang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>; Yu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>; Lee etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib64" title="">2022</a>)</cite> tokenize images and apply maximum likelihood estimation in the latent space, with VQ-VAE-2Â <cite class="ltx_cite ltx_citemacro_citep">(Razavi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib88" title="">2019</a>)</cite> generating diverse samples. ViT-VQGANÂ <cite class="ltx_cite ltx_citemacro_citep">(Yu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>)</cite> utilizes vision transformersÂ <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>, while MaskGITÂ <cite class="ltx_cite ltx_citemacro_citep">(Chang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite> employs bidirectional transformers for faster decoding. Additionally, diffusion modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>; Song etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib97" title="">2021</a>; Dhariwal &amp; Nichol, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>; Rombach etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite> have achieved remarkable results in image synthesis.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p2.1">Autoregressive modelsÂ <cite class="ltx_cite ltx_citemacro_citep">(Gregor etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib37" title="">2014</a>; Van DenÂ Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib107" title="">2016</a>; VanÂ den Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib106" title="">2016</a>; Parmar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib79" title="">2018</a>; Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib20" title="">2018</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib18" title="">2020</a>)</cite> generate images as pixel sequences, utilizing recurrent neural networksÂ <cite class="ltx_cite ltx_citemacro_citep">(Van DenÂ Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib107" title="">2016</a>)</cite>, convolutional neural networks Â <cite class="ltx_cite ltx_citemacro_citep">(VanÂ den Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib106" title="">2016</a>; Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib20" title="">2018</a>)</cite>, and transformers Â <cite class="ltx_cite ltx_citemacro_citep">(Parmar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib79" title="">2018</a>; Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib18" title="">2020</a>)</cite>. Recent approaches Â <cite class="ltx_cite ltx_citemacro_citep">(Van DenÂ Oord etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib108" title="">2017</a>; Razavi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib88" title="">2019</a>; Esser etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib31" title="">2021</a>; Ramesh etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib87" title="">2021</a>)</cite> adopt discrete tokens inspired by language models for image modeling. However, training these discrete tokenizers is challenging for high-quality image generationÂ <cite class="ltx_cite ltx_citemacro_citep">(Kolesnikov etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib58" title="">2022</a>; Yu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib117" title="">2023a</a>; Mentzer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib72" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p3.1">Recent developments, such as GIVTÂ <cite class="ltx_cite ltx_citemacro_citep">(Tschannen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite> and MARÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, introduce continuous-valued tokens, yielding promising results. Our method directly processes continuous-valued tokens via the diffusion process, ensuring high-quality image generation.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental Setup</h2>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Network configuration.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p1.2">We constructed three variants of D-JEPA using different visual transformer backbones: D-JEPA-B with ViT-B, D-JEPA-L with ViT-L, and D-JEPA-H with ViT-H. In all configurations, <math alttext="u_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="A2.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="A2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">u</mi><mi id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2">ğ‘¢</ci><ci id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p1.1.m1.1c">u_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p1.1.m1.1d">italic_u start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> is implemented as a simple two-layer MLP. The denoising MLP, denoted as <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="A2.SS0.SSS0.Px1.p1.2.m2.1a"><msub id="A2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">Ïµ</mi><mi id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2">italic-Ïµ</ci><ci id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p1.2.m2.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p1.2.m2.1d">italic_Ïµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, follows the implementation described in <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>, comprising 6, 8, and 12 residual blocks with linear layers, respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p2.1">We adhered to the standard practice outlined in <cite class="ltx_cite ltx_citemacro_cite">LeCun (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>)</cite> for parameter counting, considering only the learnable parameters updated through gradients. Since the target encoder <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p2.1.m1.1"><semantics id="A2.SS0.SSS0.Px1.p2.1.m1.1a"><mover accent="true" id="A2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml">Ï•</mi><mo id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p2.1.m1.1b"><apply id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1"><ci id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.1">Â¯</ci><ci id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p2.1.m1.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p2.1.m1.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math> is updated via exponential moving average and is not utilized during sampling, its parameters are excluded from the count. The number of parameters for each model is detailed in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T1" title="Table 1 â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Training.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p1.8">We trained class-conditional latent D-JEPA models at a <math alttext="256\times 256" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="A2.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">256</mn><mo id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1"><times id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.2">256</cn><cn id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.1.m1.1d">256 Ã— 256</annotation></semantics></math> image resolution on the ImageNet dataset <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib60" title="">2012</a>)</cite>, a highly competitive benchmark for generative modeling. The VAE trained by <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> encodes images into a latent space of size <math alttext="16\times 32\times 32" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="A2.SS0.SSS0.Px2.p1.2.m2.1a"><mrow id="A2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml">16</mn><mo id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml">32</mn><mo id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1"><times id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.2">16</cn><cn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.3">32</cn><cn id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.2.m2.1c">16\times 32\times 32</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.2.m2.1d">16 Ã— 32 Ã— 32</annotation></semantics></math>. Subsequently, we employ a patch size of <math alttext="p=1" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="A2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="A2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml">p</mi><mo id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1"><eq id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1"></eq><ci id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2">ğ‘</ci><cn id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.3.m3.1c">p=1</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.3.m3.1d">italic_p = 1</annotation></semantics></math> to segment the latent space into semantic tokens, resulting in <math alttext="N=256" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.4.m4.1"><semantics id="A2.SS0.SSS0.Px2.p1.4.m4.1a"><mrow id="A2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml">N</mi><mo id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1"><eq id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.1"></eq><ci id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.2">ğ‘</ci><cn id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.4.m4.1c">N=256</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.4.m4.1d">italic_N = 256</annotation></semantics></math> tokens. After sampling all tokens with D-JEPA according to AlgorithmÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#alg1" title="Algorithm 1 â€£ 3.5 Sampling in Next Set-of-Tokens Prediction â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a>, we decode them to pixels using the corresponding VAE decoder. We retain the diffusion hyperparameters from ADM <cite class="ltx_cite ltx_citemacro_citep">(Dhariwal &amp; Nichol, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>; specifically, we use a <math alttext="t_{\text{max}}=1000" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.5.m5.1"><semantics id="A2.SS0.SSS0.Px2.p1.5.m5.1a"><mrow id="A2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><msub id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml"><mi id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2.cmml">t</mi><mtext id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3a.cmml">max</mtext></msub><mo id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml">1000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1"><eq id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1"></eq><apply id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.2">ğ‘¡</ci><ci id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3a.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3"><mtext id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3.cmml" mathsize="70%" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.3">max</mtext></ci></apply><cn id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.5.m5.1c">t_{\text{max}}=1000</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.5.m5.1d">italic_t start_POSTSUBSCRIPT max end_POSTSUBSCRIPT = 1000</annotation></semantics></math> linear variance schedule ranging from <math alttext="1\times 10^{-4}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.6.m6.1"><semantics id="A2.SS0.SSS0.Px2.p1.6.m6.1a"><mrow id="A2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml">1</mn><mo id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1.cmml">Ã—</mo><msup id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml"><mn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2.cmml">10</mn><mrow id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.cmml"><mo id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3a" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.cmml">âˆ’</mo><mn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.6.m6.1b"><apply id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1"><times id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.2">1</cn><apply id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3">superscript</csymbol><cn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.2">10</cn><apply id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3"><minus id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3"></minus><cn id="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.6.m6.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.6.m6.1c">1\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.6.m6.1d">1 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> to <math alttext="2\times 10^{-2}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.7.m7.1"><semantics id="A2.SS0.SSS0.Px2.p1.7.m7.1a"><mrow id="A2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml">2</mn><mo id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml">Ã—</mo><msup id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml"><mn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2.cmml">10</mn><mrow id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.cmml"><mo id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3a" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.cmml">âˆ’</mo><mn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2.cmml">2</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.7.m7.1b"><apply id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1"><times id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.2">2</cn><apply id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3">superscript</csymbol><cn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.2">10</cn><apply id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3"><minus id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.1.cmml" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3"></minus><cn id="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p1.7.m7.1.1.3.3.2">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.7.m7.1c">2\times 10^{-2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.7.m7.1d">2 Ã— 10 start_POSTSUPERSCRIPT - 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, ADMâ€™s parameterization of the covariance <math alttext="\Sigma_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p1.8.m8.1"><semantics id="A2.SS0.SSS0.Px2.p1.8.m8.1a"><msub id="A2.SS0.SSS0.Px2.p1.8.m8.1.1" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2" mathvariant="normal" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2.cmml">Î£</mi><mi id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.8.m8.1b"><apply id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.2">Î£</ci><ci id="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.8.m8.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.8.m8.1c">\Sigma_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.8.m8.1d">roman_Î£ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, and their method for embedding input timesteps and labels.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p2.4">The final linear layer is initialized with zeros, while other layers follow standard weight initialization techniques from ViT <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib29" title="">2020</a>)</cite>. We train all models using AdamW <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov &amp; Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib69" title="">2017</a>)</cite> with a learning rate of <math alttext="8\times 10^{-4}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="A2.SS0.SSS0.Px2.p2.1.m1.1a"><mrow id="A2.SS0.SSS0.Px2.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">8</mn><mo id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml">Ã—</mo><msup id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.cmml">10</mn><mrow id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml"><mo id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3a" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1"><times id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1"></times><cn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2">8</cn><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3">superscript</csymbol><cn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.2">10</cn><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3"><minus id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3"></minus><cn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2.cmml" type="integer" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.1.m1.1c">8\times 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.1.m1.1d">8 Ã— 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>, incorporating a 100-epoch linear warmup and a linear weight decay from 0.02 to 0.2 for all parameters except <math alttext="u_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.2.m2.1"><semantics id="A2.SS0.SSS0.Px2.p2.2.m2.1a"><msub id="A2.SS0.SSS0.Px2.p2.2.m2.1.1" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">u</mi><mi id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2">ğ‘¢</ci><ci id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.2.m2.1c">u_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.2.m2.1d">italic_u start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.3.m3.1"><semantics id="A2.SS0.SSS0.Px2.p2.3.m3.1a"><msub id="A2.SS0.SSS0.Px2.p2.3.m3.1.1" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">Ïµ</mi><mi id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2">italic-Ïµ</ci><ci id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.3.m3.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.3.m3.1d">italic_Ïµ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="\bar{\phi}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px2.p2.4.m4.1"><semantics id="A2.SS0.SSS0.Px2.p2.4.m4.1a"><mover accent="true" id="A2.SS0.SSS0.Px2.p2.4.m4.1.1" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml">Ï•</mi><mo id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.4.m4.1b"><apply id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1"><ci id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1">Â¯</ci><ci id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2">italic-Ï•</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.4.m4.1c">\bar{\phi}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.4.m4.1d">overÂ¯ start_ARG italic_Ï• end_ARG</annotation></semantics></math>. The experiments are conducted on four workers, each equipped with 8 H800 GPUs, with a total batch size 2048. The only data augmentation applied is horizontal flipping.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p3.1">Following standard practices in generative modeling, we maintain an exponential moving average of D-JEPA weights throughout training, with a decay rate of 0.9999. All reported results are based on the EMA model. The number of training epochs varies depending on the modelâ€™s performance during evaluation; training is halted once the evaluation metrics show no significant improvement.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Evaluation metrics.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p1.1">We measure scaling performance using the FrÃ©chet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_citep">(Heusel etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib46" title="">2017</a>)</cite>, the standard metric for evaluating generative models of images. In line with convention, we compare against prior works and report FID-50K using 100 DDPM sampling steps <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite>. FID is known to be sensitive to small implementation details <cite class="ltx_cite ltx_citemacro_citep">(Parmar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib78" title="">2022</a>)</cite>; to ensure accurate comparisons, all values reported in this paper are obtained by exporting samples and using ADMâ€™s evaluation suite <cite class="ltx_cite ltx_citemacro_citep">(Dhariwal &amp; Nichol, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>. FID numbers reported in this paper do not use classifier-free guidance except where otherwise stated. Additionally, we report the Inception Score (IS) <cite class="ltx_cite ltx_citemacro_citep">(Salimans etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib91" title="">2016</a>)</cite> and Precision/Recall <cite class="ltx_cite ltx_citemacro_citep">(KynkÃ¤Ã¤nniemi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib61" title="">2019</a>)</cite> as secondary metrics.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Sampling with generalized next token prediction</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Grid searching for optimal classifier-free guidance scale and temperature</h3>
<figure class="ltx_figure" id="A3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf1.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>D-JEPA Base, Coarse Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf2.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>D-JEPA Base, Fine Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf3.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>D-JEPA Large, Coarse Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf4.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>D-JEPA Large, Fine Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf5.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>D-JEPA Huge, Coarse Searching</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F4.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F4.sf6.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>D-JEPA Huge, Fine Searching</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Grid searching for CFG scale and temperature <math alttext="\tau" class="ltx_Math" display="inline" id="A3.F4.2.m1.1"><semantics id="A3.F4.2.m1.1b"><mi id="A3.F4.2.m1.1.1" xref="A3.F4.2.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.F4.2.m1.1c"><ci id="A3.F4.2.m1.1.1.cmml" xref="A3.F4.2.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.F4.2.m1.1d">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.F4.2.m1.1e">italic_Ï„</annotation></semantics></math>. FID=1.199 and IS=302.69 represent the benchmarks achievable by VAE, which are the theoretical upper limits for D-JEPA.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.3">As described in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS3" title="3.3 Diffusion Learning with a Denoising MLP â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.3</span></a>, the temperature <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.p1.1.m1.1"><semantics id="A3.SS1.p1.1.m1.1a"><mi id="A3.SS1.p1.1.m1.1.1" xref="A3.SS1.p1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.1.m1.1b"><ci id="A3.SS1.p1.1.m1.1.1.cmml" xref="A3.SS1.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.1.m1.1d">italic_Ï„</annotation></semantics></math> controls the noise level added at each iteration during the denoising process and significantly influences the final sampling results. Therefore, we conducted a grid search to determine each modelâ€™s optimal <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.p1.2.m2.1"><semantics id="A3.SS1.p1.2.m2.1a"><mi id="A3.SS1.p1.2.m2.1.1" xref="A3.SS1.p1.2.m2.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.2.m2.1b"><ci id="A3.SS1.p1.2.m2.1.1.cmml" xref="A3.SS1.p1.2.m2.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.2.m2.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.2.m2.1d">italic_Ï„</annotation></semantics></math>. Similarly, the classifier-free guidance scale <span class="ltx_text ltx_markedasmath" id="A3.SS1.p1.3.1">cfg</span> is known to affect sampling results notably and was also included in the grid search. We use 100 DDPM sampling steps for the denoising MLP following <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>); Ho etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite> and set the auto-regressive steps to 64, which balances sampling efficiency and image quality.</p>
</div>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Coarse searching.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px1.p1.2">In the coarse searching stage, we began by exploring <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="A3.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="A3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px1.p1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px1.p1.1.m1.1d">italic_Ï„</annotation></semantics></math> from 0.90 to 1.05 with a step size of 0.01, considering <math alttext="\text{cfg}\in\{1.0,2.0,3.0,4.0\}" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px1.p1.2.m2.4"><semantics id="A3.SS1.SSS0.Px1.p1.2.m2.4a"><mrow id="A3.SS1.SSS0.Px1.p1.2.m2.4.5" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.cmml"><mtext id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1.cmml">âˆˆ</mo><mrow id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml"><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.1" stretchy="false" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">{</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="A3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">1.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.2.2" xref="A3.SS1.SSS0.Px1.p1.2.m2.2.2.cmml">2.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.3" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.3.3" xref="A3.SS1.SSS0.Px1.p1.2.m2.3.3.cmml">3.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.4" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px1.p1.2.m2.4.4" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.4.cmml">4.0</mn><mo id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2.5" stretchy="false" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px1.p1.2.m2.4b"><apply id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5"><in id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.1"></in><ci id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2a.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2"><mtext id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.2">cfg</mtext></ci><set id="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.1.cmml" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.5.3.2"><cn id="A3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.1.1">1.0</cn><cn id="A3.SS1.SSS0.Px1.p1.2.m2.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.2.2">2.0</cn><cn id="A3.SS1.SSS0.Px1.p1.2.m2.3.3.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.3.3">3.0</cn><cn id="A3.SS1.SSS0.Px1.p1.2.m2.4.4.cmml" type="float" xref="A3.SS1.SSS0.Px1.p1.2.m2.4.4">4.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px1.p1.2.m2.4c">\text{cfg}\in\{1.0,2.0,3.0,4.0\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px1.p1.2.m2.4d">cfg âˆˆ { 1.0 , 2.0 , 3.0 , 4.0 }</annotation></semantics></math>. The results are plotted in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf1" title="In Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(a)</span></a>, Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf3" title="In Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(c)</span></a>, and Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf5" title="In Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(e)</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Fine searching.</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px2.p1.7">Based on <math alttext="\text{cfg}=3.0,4.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.1.m1.2"><semantics id="A3.SS1.SSS0.Px2.p1.1.m1.2a"><mrow id="A3.SS1.SSS0.Px2.p1.1.m1.2.3" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1.cmml">=</mo><mrow id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.1.cmml"><mn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">3.0</mn><mo id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.2.1" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px2.p1.1.m1.2.2" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.2.cmml">4.0</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.1.m1.2b"><apply id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3"><eq id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.1"></eq><ci id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2"><mtext id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.2">cfg</mtext></ci><list id="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.3.3.2"><cn id="A3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.1.m1.1.1">3.0</cn><cn id="A3.SS1.SSS0.Px2.p1.1.m1.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.1.m1.2.2">4.0</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.1.m1.2c">\text{cfg}=3.0,4.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.1.m1.2d">cfg = 3.0 , 4.0</annotation></semantics></math> and <math alttext="\tau=0.97" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.2.m2.1"><semantics id="A3.SS1.SSS0.Px2.p1.2.m2.1a"><mrow id="A3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml">Ï„</mi><mo id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml">0.97</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1"><eq id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.2">ğœ</ci><cn id="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.2.m2.1.1.3">0.97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.2.m2.1c">\tau=0.97</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.2.m2.1d">italic_Ï„ = 0.97</annotation></semantics></math>, we conducted a fine search for the best <math alttext="\text{cfg}_{c}-\tau_{c}" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.3.m3.1"><semantics id="A3.SS1.SSS0.Px2.p1.3.m3.1a"><mrow id="A3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><msub id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2a.cmml">cfg</mtext><mi id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml">âˆ’</mo><msub id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">Ï„</mi><mi id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3.cmml">c</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1"><minus id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.1"></minus><apply id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2"><mtext id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.2">cfg</mtext></ci><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.2.3">ğ‘</ci></apply><apply id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.2">ğœ</ci><ci id="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="A3.SS1.SSS0.Px2.p1.3.m3.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.3.m3.1c">\text{cfg}_{c}-\tau_{c}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.3.m3.1d">cfg start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - italic_Ï„ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> combinations. In this stage, a 2D grid search was performed with <span class="ltx_text ltx_markedasmath" id="A3.SS1.SSS0.Px2.p1.7.1">cfg</span> ranging from <math alttext="[\text{cfg}_{c}-0.3,\text{cfg}_{c}+0.3]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.5.m5.2"><semantics id="A3.SS1.SSS0.Px2.p1.5.m5.2a"><mrow id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml"><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml">[</mo><mrow id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.cmml"><msub id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2a.cmml">cfg</mtext><mi id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1.cmml">âˆ’</mo><mn id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3.cmml">0.3</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.4" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml">,</mo><mrow id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.cmml"><msub id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.cmml"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2a.cmml">cfg</mtext><mi id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1.cmml">+</mo><mn id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3.cmml">0.3</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.5" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.5.m5.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2"><apply id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1"><minus id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.1"></minus><apply id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.2">cfg</mtext></ci><ci id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.2.3">ğ‘</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.5.m5.1.1.1.1.3">0.3</cn></apply><apply id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2"><plus id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.1"></plus><apply id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2a.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2"><mtext id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.2">cfg</mtext></ci><ci id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.2.3">ğ‘</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.5.m5.2.2.2.2.3">0.3</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.5.m5.2c">[\text{cfg}_{c}-0.3,\text{cfg}_{c}+0.3]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.5.m5.2d">[ cfg start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - 0.3 , cfg start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + 0.3 ]</annotation></semantics></math> with a step size of 0.1, and <math alttext="\tau_{c}" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.6.m6.1"><semantics id="A3.SS1.SSS0.Px2.p1.6.m6.1a"><msub id="A3.SS1.SSS0.Px2.p1.6.m6.1.1" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml">Ï„</mi><mi id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.6.m6.1b"><apply id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.2">ğœ</ci><ci id="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="A3.SS1.SSS0.Px2.p1.6.m6.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.6.m6.1c">\tau_{c}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.6.m6.1d">italic_Ï„ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> ranging from <math alttext="[\tau_{c}-0.01,\tau_{c}+0.01]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p1.7.m7.2"><semantics id="A3.SS1.SSS0.Px2.p1.7.m7.2a"><mrow id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml"><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml">[</mo><mrow id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.cmml"><msub id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.cmml"><mi id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2.cmml">Ï„</mi><mi id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1.cmml">âˆ’</mo><mn id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3.cmml">0.01</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.4" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml">,</mo><mrow id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.cmml"><msub id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.cmml"><mi id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2.cmml">Ï„</mi><mi id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3.cmml">c</mi></msub><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1.cmml">+</mo><mn id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3.cmml">0.01</mn></mrow><mo id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.5" stretchy="false" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p1.7.m7.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2"><apply id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1"><minus id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.1"></minus><apply id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.2">ğœ</ci><ci id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.2.3">ğ‘</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.7.m7.1.1.1.1.3">0.01</cn></apply><apply id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2"><plus id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.1"></plus><apply id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2"><csymbol cd="ambiguous" id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.1.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2">subscript</csymbol><ci id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.2">ğœ</ci><ci id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3.cmml" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.2.3">ğ‘</ci></apply><cn id="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p1.7.m7.2.2.2.2.3">0.01</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p1.7.m7.2c">[\tau_{c}-0.01,\tau_{c}+0.01]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p1.7.m7.2d">[ italic_Ï„ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - 0.01 , italic_Ï„ start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + 0.01 ]</annotation></semantics></math> with a step size of 0.01, as illustrated in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf2" title="In Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(b)</span></a>, Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf3" title="In Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(c)</span></a>, and Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4.sf6" title="In Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4(f)</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="A3.SS1.SSS0.Px2.p2.10">When <math alttext="\text{cfg}=1.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.1.m1.1"><semantics id="A3.SS1.SSS0.Px2.p2.1.m1.1a"><mrow id="A3.SS1.SSS0.Px2.p2.1.m1.1.1" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1"><eq id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.1.m1.1c">\text{cfg}=1.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.1.m1.1d">cfg = 1.0</annotation></semantics></math>, <span class="ltx_text ltx_font_italic" id="A3.SS1.SSS0.Px2.p2.10.1">i.e.</span>, no classifier-free guidance, we found that <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.2.m2.1"><semantics id="A3.SS1.SSS0.Px2.p2.2.m2.1a"><mi id="A3.SS1.SSS0.Px2.p2.2.m2.1.1" xref="A3.SS1.SSS0.Px2.p2.2.m2.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.2.m2.1b"><ci id="A3.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.2.m2.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.2.m2.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.2.m2.1d">italic_Ï„</annotation></semantics></math> in the range <math alttext="[0.94,0.95]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.3.m3.2"><semantics id="A3.SS1.SSS0.Px2.p2.3.m3.2a"><mrow id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml"><mo id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2.1" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml">[</mo><mn id="A3.SS1.SSS0.Px2.p2.3.m3.1.1" xref="A3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml">0.94</mn><mo id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2.2" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px2.p2.3.m3.2.2" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.2.cmml">0.95</mn><mo id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.3.m3.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p2.3.m3.2.3.1.cmml" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.3.2"><cn id="A3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.3.m3.1.1">0.94</cn><cn id="A3.SS1.SSS0.Px2.p2.3.m3.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.3.m3.2.2">0.95</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.3.m3.2c">[0.94,0.95]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.3.m3.2d">[ 0.94 , 0.95 ]</annotation></semantics></math> works well for all models. For <math alttext="\text{cfg}\geq 1.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.4.m4.1"><semantics id="A3.SS1.SSS0.Px2.p2.4.m4.1a"><mrow id="A3.SS1.SSS0.Px2.p2.4.m4.1.1" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1.cmml">â‰¥</mo><mn id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.4.m4.1b"><apply id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1"><geq id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.1"></geq><ci id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.4.m4.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.4.m4.1c">\text{cfg}\geq 1.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.4.m4.1d">cfg â‰¥ 1.0</annotation></semantics></math>, <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.5.m5.1"><semantics id="A3.SS1.SSS0.Px2.p2.5.m5.1a"><mi id="A3.SS1.SSS0.Px2.p2.5.m5.1.1" xref="A3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.5.m5.1b"><ci id="A3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.5.m5.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.5.m5.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.5.m5.1d">italic_Ï„</annotation></semantics></math> in the range <math alttext="[0.97,0.99]" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.6.m6.2"><semantics id="A3.SS1.SSS0.Px2.p2.6.m6.2a"><mrow id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml"><mo id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2.1" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml">[</mo><mn id="A3.SS1.SSS0.Px2.p2.6.m6.1.1" xref="A3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml">0.97</mn><mo id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2.2" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml">,</mo><mn id="A3.SS1.SSS0.Px2.p2.6.m6.2.2" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.2.cmml">0.99</mn><mo id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2.3" stretchy="false" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.6.m6.2b"><interval closure="closed" id="A3.SS1.SSS0.Px2.p2.6.m6.2.3.1.cmml" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.3.2"><cn id="A3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.6.m6.1.1">0.97</cn><cn id="A3.SS1.SSS0.Px2.p2.6.m6.2.2.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.6.m6.2.2">0.99</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.6.m6.2c">[0.97,0.99]</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.6.m6.2d">[ 0.97 , 0.99 ]</annotation></semantics></math> performs better for all models. Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F4" title="Figure 4 â€£ C.1 Grid searching for optimal classifier-free guidance scale and temperature â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> also indicates that <math alttext="\text{cfg}=3.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.7.m7.1"><semantics id="A3.SS1.SSS0.Px2.p2.7.m7.1a"><mrow id="A3.SS1.SSS0.Px2.p2.7.m7.1.1" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3.cmml">3.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.7.m7.1b"><apply id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1"><eq id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.7.m7.1.1.3">3.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.7.m7.1c">\text{cfg}=3.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.7.m7.1d">cfg = 3.0</annotation></semantics></math> can achieve a lower FID, while <math alttext="\text{cfg}=4.0" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.8.m8.1"><semantics id="A3.SS1.SSS0.Px2.p2.8.m8.1a"><mrow id="A3.SS1.SSS0.Px2.p2.8.m8.1.1" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml"><mtext id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2a.cmml">cfg</mtext><mo id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1.cmml">=</mo><mn id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3.cmml">4.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.8.m8.1b"><apply id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1"><eq id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.1"></eq><ci id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2a.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2"><mtext id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2.cmml" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.2">cfg</mtext></ci><cn id="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3.cmml" type="float" xref="A3.SS1.SSS0.Px2.p2.8.m8.1.1.3">4.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.8.m8.1c">\text{cfg}=4.0</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.8.m8.1d">cfg = 4.0</annotation></semantics></math> can achieve a better IS. Therefore, we recommend setting <math alttext="\tau" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px2.p2.9.m9.1"><semantics id="A3.SS1.SSS0.Px2.p2.9.m9.1a"><mi id="A3.SS1.SSS0.Px2.p2.9.m9.1.1" xref="A3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px2.p2.9.m9.1b"><ci id="A3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml" xref="A3.SS1.SSS0.Px2.p2.9.m9.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px2.p2.9.m9.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px2.p2.9.m9.1d">italic_Ï„</annotation></semantics></math> to 0.98 for classifier-free guidance and <span class="ltx_text ltx_markedasmath" id="A3.SS1.SSS0.Px2.p2.10.2">cfg</span> to either 3.0 or 4.0 as the default.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Abalation on auto-regressive steps</h3>
<figure class="ltx_table" id="A3.T3">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.4.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.4.4.4">
<tr class="ltx_tr" id="A3.T3.4.4.4.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.4.4.4.5.1"><span class="ltx_text" id="A3.T3.4.4.4.5.1.1" style="background-color:#EFEFEF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.2"><span class="ltx_text" id="A3.T3.4.4.4.5.2.1" style="background-color:#EFEFEF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.3"><span class="ltx_text" id="A3.T3.4.4.4.5.3.1" style="background-color:#EFEFEF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.4"><span class="ltx_text" id="A3.T3.4.4.4.5.4.1" style="background-color:#EFEFEF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.5"><span class="ltx_text" id="A3.T3.4.4.4.5.5.1" style="background-color:#EFEFEF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.6"><span class="ltx_text" id="A3.T3.4.4.4.5.6.1" style="background-color:#EFEFEF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.7"><span class="ltx_text" id="A3.T3.4.4.4.5.7.1" style="background-color:#EFEFEF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.8"><span class="ltx_text" id="A3.T3.4.4.4.5.8.1" style="background-color:#EFEFEF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.5.9"><span class="ltx_text" id="A3.T3.4.4.4.5.9.1" style="background-color:#EFEFEF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.1.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.1.1.1.1.1.m1.1"><semantics id="A3.T3.1.1.1.1.1.m1.1a"><mo id="A3.T3.1.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.1.1.1.1.1.m1.1b"><ci id="A3.T3.1.1.1.1.1.m1.1.1.cmml" xref="A3.T3.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.1.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.2">4.027</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.3">3.452</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.4">3.431</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.5.1">3.404</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.6">3.419</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.7">3.467</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.8">3.437</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.1.1.9">3.421</td>
</tr>
<tr class="ltx_tr" id="A3.T3.2.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.2.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.2.2.2.2.1.m1.1"><semantics id="A3.T3.2.2.2.2.1.m1.1a"><mo id="A3.T3.2.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.2.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.2.2.2.2.1.m1.1b"><ci id="A3.T3.2.2.2.2.1.m1.1.1.cmml" xref="A3.T3.2.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.2.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.2.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.2">184.42</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.3">194.57</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.4">195.74</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.5">197.07</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.6">196.00</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.7">195.29</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.8">194.79</td>
<td class="ltx_td ltx_align_center" id="A3.T3.2.2.2.2.9">196.03</td>
</tr>
<tr class="ltx_tr" id="A3.T3.3.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.3.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.3.3.3.3.1.m1.1"><semantics id="A3.T3.3.3.3.3.1.m1.1a"><mo id="A3.T3.3.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.3.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.3.3.3.3.1.m1.1b"><ci id="A3.T3.3.3.3.3.1.m1.1.1.cmml" xref="A3.T3.3.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.3.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.2">0.756</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.3">0.764</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.4">0.764</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.5">0.766</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.6">0.767</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.7">0.763</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.8">0.765</td>
<td class="ltx_td ltx_align_center" id="A3.T3.3.3.3.3.9">0.763</td>
</tr>
<tr class="ltx_tr" id="A3.T3.4.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.4.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.4.4.4.4.1.m1.1"><semantics id="A3.T3.4.4.4.4.1.m1.1a"><mo id="A3.T3.4.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.4.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.4.4.4.4.1.m1.1b"><ci id="A3.T3.4.4.4.4.1.m1.1.1.cmml" xref="A3.T3.4.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.4.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.4.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.2">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.3">0.613</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.4">0.602</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.5">0.608</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.6">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.7">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.8">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.4.9">0.607</td>
</tr>
<tr class="ltx_tr" id="A3.T3.4.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.4.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.2">0.043</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.3">0.078</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.4">0.114</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.5">0.150</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.6">0.189</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.7">0.227</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.8">0.261</td>
<td class="ltx_td ltx_align_center" id="A3.T3.4.4.4.6.9">0.294</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.8.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.8.4.4">
<tr class="ltx_tr" id="A3.T3.8.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.8.4.4.5.1"><span class="ltx_text" id="A3.T3.8.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.2"><span class="ltx_text" id="A3.T3.8.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.3"><span class="ltx_text" id="A3.T3.8.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.4"><span class="ltx_text" id="A3.T3.8.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.5"><span class="ltx_text" id="A3.T3.8.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.6"><span class="ltx_text" id="A3.T3.8.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.7"><span class="ltx_text" id="A3.T3.8.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.8"><span class="ltx_text" id="A3.T3.8.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.5.9"><span class="ltx_text" id="A3.T3.8.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.5.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.5.1.1.1.1.m1.1"><semantics id="A3.T3.5.1.1.1.1.m1.1a"><mo id="A3.T3.5.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.5.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.5.1.1.1.1.m1.1b"><ci id="A3.T3.5.1.1.1.1.m1.1.1.cmml" xref="A3.T3.5.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.5.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.5.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.2">2.261</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.3">1.912</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.4">1.896</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.5">1.885</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.6">1.885</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.7">1.904</td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.8"><span class="ltx_text ltx_font_bold" id="A3.T3.5.1.1.1.8.1">1.871</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.5.1.1.1.9">1.881</td>
</tr>
<tr class="ltx_tr" id="A3.T3.6.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.6.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.6.2.2.2.1.m1.1"><semantics id="A3.T3.6.2.2.2.1.m1.1a"><mo id="A3.T3.6.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.6.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.6.2.2.2.1.m1.1b"><ci id="A3.T3.6.2.2.2.1.m1.1.1.cmml" xref="A3.T3.6.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.6.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.6.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.2">271.57</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.3">281.46</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.4">281.28</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.5">280.78</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.6">282.38</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.7">280.15</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.8">282.53</td>
<td class="ltx_td ltx_align_center" id="A3.T3.6.2.2.2.9">283.92</td>
</tr>
<tr class="ltx_tr" id="A3.T3.7.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.7.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.7.3.3.3.1.m1.1"><semantics id="A3.T3.7.3.3.3.1.m1.1a"><mo id="A3.T3.7.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.7.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.7.3.3.3.1.m1.1b"><ci id="A3.T3.7.3.3.3.1.m1.1.1.cmml" xref="A3.T3.7.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.7.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.7.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.2">0.785</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.3">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.4">0.797</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.5">0.798</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.6">0.799</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.7">0.802</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.8">0.797</td>
<td class="ltx_td ltx_align_center" id="A3.T3.7.3.3.3.9">0.802</td>
</tr>
<tr class="ltx_tr" id="A3.T3.8.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.8.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.8.4.4.4.1.m1.1"><semantics id="A3.T3.8.4.4.4.1.m1.1a"><mo id="A3.T3.8.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.8.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.8.4.4.4.1.m1.1b"><ci id="A3.T3.8.4.4.4.1.m1.1.1.cmml" xref="A3.T3.8.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.8.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.8.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.2">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.3">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.4">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.5">0.611</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.6">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.7">0.609</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.8">0.605</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.4.9">0.613</td>
</tr>
<tr class="ltx_tr" id="A3.T3.8.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.8.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.2">0.069</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.3">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.4">0.182</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.5">0.231</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.6">0.309</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.7">0.381</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.8">0.411</td>
<td class="ltx_td ltx_align_center" id="A3.T3.8.4.4.6.9">0.539</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.12.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.12.4.4">
<tr class="ltx_tr" id="A3.T3.12.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.12.4.4.5.1"><span class="ltx_text" id="A3.T3.12.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.2"><span class="ltx_text" id="A3.T3.12.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.3"><span class="ltx_text" id="A3.T3.12.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.4"><span class="ltx_text" id="A3.T3.12.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.5"><span class="ltx_text" id="A3.T3.12.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.6"><span class="ltx_text" id="A3.T3.12.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.7"><span class="ltx_text" id="A3.T3.12.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.8"><span class="ltx_text" id="A3.T3.12.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.5.9"><span class="ltx_text" id="A3.T3.12.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.9.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.9.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.9.1.1.1.1.m1.1"><semantics id="A3.T3.9.1.1.1.1.m1.1a"><mo id="A3.T3.9.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.9.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.9.1.1.1.1.m1.1b"><ci id="A3.T3.9.1.1.1.1.m1.1.1.cmml" xref="A3.T3.9.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.9.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.9.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.2">2.143</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T3.9.1.1.1.3.1">2.081</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.4">2.118</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.5">2.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.6">2.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.7">2.183</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.8">2.096</td>
<td class="ltx_td ltx_align_center" id="A3.T3.9.1.1.1.9">2.149</td>
</tr>
<tr class="ltx_tr" id="A3.T3.10.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.10.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.10.2.2.2.1.m1.1"><semantics id="A3.T3.10.2.2.2.1.m1.1a"><mo id="A3.T3.10.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.10.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.10.2.2.2.1.m1.1b"><ci id="A3.T3.10.2.2.2.1.m1.1.1.cmml" xref="A3.T3.10.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.10.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.10.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.2">313.57</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.3">320.94</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.4">318.96</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.5">318.67</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.6">318.94</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.7">318.28</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.8">317.93</td>
<td class="ltx_td ltx_align_center" id="A3.T3.10.2.2.2.9">320.62</td>
</tr>
<tr class="ltx_tr" id="A3.T3.11.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.11.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.11.3.3.3.1.m1.1"><semantics id="A3.T3.11.3.3.3.1.m1.1a"><mo id="A3.T3.11.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.11.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.11.3.3.3.1.m1.1b"><ci id="A3.T3.11.3.3.3.1.m1.1.1.cmml" xref="A3.T3.11.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.11.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.11.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.2">0.810</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.3">0.817</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.4">0.815</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.5">0.819</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.6">0.819</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.7">0.820</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.8">0.818</td>
<td class="ltx_td ltx_align_center" id="A3.T3.11.3.3.3.9">0.820</td>
</tr>
<tr class="ltx_tr" id="A3.T3.12.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.12.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.12.4.4.4.1.m1.1"><semantics id="A3.T3.12.4.4.4.1.m1.1a"><mo id="A3.T3.12.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.12.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.12.4.4.4.1.m1.1b"><ci id="A3.T3.12.4.4.4.1.m1.1.1.cmml" xref="A3.T3.12.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.12.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.12.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.2">0.586</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.3">0.590</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.4">0.589</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.5">0.595</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.6">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.7">0.589</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.8">0.592</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.4.9">0.590</td>
</tr>
<tr class="ltx_tr" id="A3.T3.12.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.12.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.2">0.069</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.3">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.4">0.182</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.5">0.231</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.6">0.309</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.7">0.381</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.8">0.411</td>
<td class="ltx_td ltx_align_center" id="A3.T3.12.4.4.6.9">0.539</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.16.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.16.4.4">
<tr class="ltx_tr" id="A3.T3.16.4.4.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.16.4.4.5.1"><span class="ltx_text" id="A3.T3.16.4.4.5.1.1" style="background-color:#EFEFEF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.2"><span class="ltx_text" id="A3.T3.16.4.4.5.2.1" style="background-color:#EFEFEF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.3"><span class="ltx_text" id="A3.T3.16.4.4.5.3.1" style="background-color:#EFEFEF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.4"><span class="ltx_text" id="A3.T3.16.4.4.5.4.1" style="background-color:#EFEFEF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.5"><span class="ltx_text" id="A3.T3.16.4.4.5.5.1" style="background-color:#EFEFEF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.6"><span class="ltx_text" id="A3.T3.16.4.4.5.6.1" style="background-color:#EFEFEF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.7"><span class="ltx_text" id="A3.T3.16.4.4.5.7.1" style="background-color:#EFEFEF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.8"><span class="ltx_text" id="A3.T3.16.4.4.5.8.1" style="background-color:#EFEFEF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.5.9"><span class="ltx_text" id="A3.T3.16.4.4.5.9.1" style="background-color:#EFEFEF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.13.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.13.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.13.1.1.1.1.m1.1"><semantics id="A3.T3.13.1.1.1.1.m1.1a"><mo id="A3.T3.13.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.13.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.13.1.1.1.1.m1.1b"><ci id="A3.T3.13.1.1.1.1.m1.1.1.cmml" xref="A3.T3.13.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.13.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.13.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.2">2.996</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.3">2.371</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.4">2.344</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.5">2.344</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A3.T3.13.1.1.1.6.1">2.323</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.7">2.347</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.8">2.345</td>
<td class="ltx_td ltx_align_center" id="A3.T3.13.1.1.1.9">2.362</td>
</tr>
<tr class="ltx_tr" id="A3.T3.14.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.14.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.14.2.2.2.1.m1.1"><semantics id="A3.T3.14.2.2.2.1.m1.1a"><mo id="A3.T3.14.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.14.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.14.2.2.2.1.m1.1b"><ci id="A3.T3.14.2.2.2.1.m1.1.1.cmml" xref="A3.T3.14.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.14.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.14.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.2">211.85</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.3">228.99</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.4">231.36</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.5">231.83</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.6">233.46</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.7">229.20</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.8">230.54</td>
<td class="ltx_td ltx_align_center" id="A3.T3.14.2.2.2.9">231.21</td>
</tr>
<tr class="ltx_tr" id="A3.T3.15.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.15.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.15.3.3.3.1.m1.1"><semantics id="A3.T3.15.3.3.3.1.m1.1a"><mo id="A3.T3.15.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.15.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.15.3.3.3.1.m1.1b"><ci id="A3.T3.15.3.3.3.1.m1.1.1.cmml" xref="A3.T3.15.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.15.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.15.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.2">0.765</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.3">0.780</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.4">0.781</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.5">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.6">0.785</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.7">0.782</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.8">0.786</td>
<td class="ltx_td ltx_align_center" id="A3.T3.15.3.3.3.9">0.785</td>
</tr>
<tr class="ltx_tr" id="A3.T3.16.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.16.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.16.4.4.4.1.m1.1"><semantics id="A3.T3.16.4.4.4.1.m1.1a"><mo id="A3.T3.16.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.16.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.16.4.4.4.1.m1.1b"><ci id="A3.T3.16.4.4.4.1.m1.1.1.cmml" xref="A3.T3.16.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.16.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.16.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.2">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.3">0.626</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.4">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.5">0.617</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.6">0.616</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.7">0.618</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.8">0.613</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.4.9">0.617</td>
</tr>
<tr class="ltx_tr" id="A3.T3.16.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.16.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.2">0.079</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.3">0.146</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.4">0.218</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.5">0.293</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.6">0.363</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.7">0.435</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.8">0.554</td>
<td class="ltx_td ltx_align_center" id="A3.T3.16.4.4.6.9">0.585</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.20.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.20.4.4">
<tr class="ltx_tr" id="A3.T3.20.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.20.4.4.5.1"><span class="ltx_text" id="A3.T3.20.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.2"><span class="ltx_text" id="A3.T3.20.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.3"><span class="ltx_text" id="A3.T3.20.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.4"><span class="ltx_text" id="A3.T3.20.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.5"><span class="ltx_text" id="A3.T3.20.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.6"><span class="ltx_text" id="A3.T3.20.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.7"><span class="ltx_text" id="A3.T3.20.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.8"><span class="ltx_text" id="A3.T3.20.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.5.9"><span class="ltx_text" id="A3.T3.20.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.17.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.17.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.17.1.1.1.1.m1.1"><semantics id="A3.T3.17.1.1.1.1.m1.1a"><mo id="A3.T3.17.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.17.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.17.1.1.1.1.m1.1b"><ci id="A3.T3.17.1.1.1.1.m1.1.1.cmml" xref="A3.T3.17.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.17.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.17.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.2">2.042</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.3">1.633</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.4">1.651</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.5">1.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.6">1.637</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.7">1.600</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.8">1.639</td>
<td class="ltx_td ltx_align_center" id="A3.T3.17.1.1.1.9"><span class="ltx_text ltx_font_bold" id="A3.T3.17.1.1.1.9.1">1.593</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.18.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.18.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.18.2.2.2.1.m1.1"><semantics id="A3.T3.18.2.2.2.1.m1.1a"><mo id="A3.T3.18.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.18.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.18.2.2.2.1.m1.1b"><ci id="A3.T3.18.2.2.2.1.m1.1.1.cmml" xref="A3.T3.18.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.18.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.18.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.2">282.91</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.3">297.46</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.4">300.76</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.5">299.95</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.6">300.16</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.7">300.96</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.8">302.28</td>
<td class="ltx_td ltx_align_center" id="A3.T3.18.2.2.2.9">303.13</td>
</tr>
<tr class="ltx_tr" id="A3.T3.19.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.19.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.19.3.3.3.1.m1.1"><semantics id="A3.T3.19.3.3.3.1.m1.1a"><mo id="A3.T3.19.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.19.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.19.3.3.3.1.m1.1b"><ci id="A3.T3.19.3.3.3.1.m1.1.1.cmml" xref="A3.T3.19.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.19.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.19.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.2">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.3">0.796</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.4">0.802</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.5">0.799</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.6">0.799</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.7">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.8">0.803</td>
<td class="ltx_td ltx_align_center" id="A3.T3.19.3.3.3.9">0.801</td>
</tr>
<tr class="ltx_tr" id="A3.T3.20.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.20.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.20.4.4.4.1.m1.1"><semantics id="A3.T3.20.4.4.4.1.m1.1a"><mo id="A3.T3.20.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.20.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.20.4.4.4.1.m1.1b"><ci id="A3.T3.20.4.4.4.1.m1.1.1.cmml" xref="A3.T3.20.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.20.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.20.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.2">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.3">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.4">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.5">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.6">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.7">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.8">0.621</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.4.9">0.613</td>
</tr>
<tr class="ltx_tr" id="A3.T3.20.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.20.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.2">0.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.3">0.248</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.4">0.361</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.5">0.481</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.6">0.601</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.7">0.743</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.8">0.859</td>
<td class="ltx_td ltx_align_center" id="A3.T3.20.4.4.6.9">1.003</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.24.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.24.4.4">
<tr class="ltx_tr" id="A3.T3.24.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.24.4.4.5.1"><span class="ltx_text" id="A3.T3.24.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.2"><span class="ltx_text" id="A3.T3.24.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.3"><span class="ltx_text" id="A3.T3.24.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.4"><span class="ltx_text" id="A3.T3.24.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.5"><span class="ltx_text" id="A3.T3.24.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.6"><span class="ltx_text" id="A3.T3.24.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.7"><span class="ltx_text" id="A3.T3.24.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.8"><span class="ltx_text" id="A3.T3.24.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.5.9"><span class="ltx_text" id="A3.T3.24.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.21.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.21.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.21.1.1.1.1.m1.1"><semantics id="A3.T3.21.1.1.1.1.m1.1a"><mo id="A3.T3.21.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.21.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.21.1.1.1.1.m1.1b"><ci id="A3.T3.21.1.1.1.1.m1.1.1.cmml" xref="A3.T3.21.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.21.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.21.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.2">1.859</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.3">1.663</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.4">1.706</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.5">1.700</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.6">1.690</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A3.T3.21.1.1.1.7.1">1.649</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.8">1.714</td>
<td class="ltx_td ltx_align_center" id="A3.T3.21.1.1.1.9">1.674</td>
</tr>
<tr class="ltx_tr" id="A3.T3.22.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.22.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.22.2.2.2.1.m1.1"><semantics id="A3.T3.22.2.2.2.1.m1.1a"><mo id="A3.T3.22.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.22.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.22.2.2.2.1.m1.1b"><ci id="A3.T3.22.2.2.2.1.m1.1.1.cmml" xref="A3.T3.22.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.22.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.22.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.2">313.27</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.3">325.78</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.4">325.52</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.5">329.41</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.6">326.76</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.7">327.20</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.8">330.74</td>
<td class="ltx_td ltx_align_center" id="A3.T3.22.2.2.2.9">328.52</td>
</tr>
<tr class="ltx_tr" id="A3.T3.23.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.23.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.23.3.3.3.1.m1.1"><semantics id="A3.T3.23.3.3.3.1.m1.1a"><mo id="A3.T3.23.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.23.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.23.3.3.3.1.m1.1b"><ci id="A3.T3.23.3.3.3.1.m1.1.1.cmml" xref="A3.T3.23.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.23.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.23.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.2">0.796</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.3">0.807</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.4">0.813</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.5">0.810</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.6">0.809</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.7">0.810</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.8">0.811</td>
<td class="ltx_td ltx_align_center" id="A3.T3.23.3.3.3.9">0.813</td>
</tr>
<tr class="ltx_tr" id="A3.T3.24.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.24.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.24.4.4.4.1.m1.1"><semantics id="A3.T3.24.4.4.4.1.m1.1a"><mo id="A3.T3.24.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.24.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.24.4.4.4.1.m1.1b"><ci id="A3.T3.24.4.4.4.1.m1.1.1.cmml" xref="A3.T3.24.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.24.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.24.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.2">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.3">0.617</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.4">0.612</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.5">0.612</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.6">0.617</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.7">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.8">0.605</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.4.9">0.609</td>
</tr>
<tr class="ltx_tr" id="A3.T3.24.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.24.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.2">0.139</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.3">0.248</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.4">0.362</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.5">0.481</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.6">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.7">0.747</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.8">0.862</td>
<td class="ltx_td ltx_align_center" id="A3.T3.24.4.4.6.9">1.003</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.28" style="width:433.6pt;">
<figure class="ltx_table ltx_align_center" id="A3.T3.28.4">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.28.4.4">
<tr class="ltx_tr" id="A3.T3.28.4.4.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.28.4.4.5.1"><span class="ltx_text" id="A3.T3.28.4.4.5.1.1" style="background-color:#EFEFEF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.2"><span class="ltx_text" id="A3.T3.28.4.4.5.2.1" style="background-color:#EFEFEF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.3"><span class="ltx_text" id="A3.T3.28.4.4.5.3.1" style="background-color:#EFEFEF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.4"><span class="ltx_text" id="A3.T3.28.4.4.5.4.1" style="background-color:#EFEFEF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.5"><span class="ltx_text" id="A3.T3.28.4.4.5.5.1" style="background-color:#EFEFEF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.6"><span class="ltx_text" id="A3.T3.28.4.4.5.6.1" style="background-color:#EFEFEF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.7"><span class="ltx_text" id="A3.T3.28.4.4.5.7.1" style="background-color:#EFEFEF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.8"><span class="ltx_text" id="A3.T3.28.4.4.5.8.1" style="background-color:#EFEFEF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.5.9"><span class="ltx_text" id="A3.T3.28.4.4.5.9.1" style="background-color:#EFEFEF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.25.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.25.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.25.1.1.1.1.m1.1"><semantics id="A3.T3.25.1.1.1.1.m1.1a"><mo id="A3.T3.25.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.25.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.25.1.1.1.1.m1.1b"><ci id="A3.T3.25.1.1.1.1.m1.1.1.cmml" xref="A3.T3.25.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.25.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.25.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.2">2.849</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.3">2.174</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.4">2.106</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.5">2.083</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.6">2.157</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A3.T3.25.1.1.1.7.1">2.043</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.8">2.133</td>
<td class="ltx_td ltx_align_center" id="A3.T3.25.1.1.1.9">2.112</td>
</tr>
<tr class="ltx_tr" id="A3.T3.26.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.26.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.26.2.2.2.1.m1.1"><semantics id="A3.T3.26.2.2.2.1.m1.1a"><mo id="A3.T3.26.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.26.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.26.2.2.2.1.m1.1b"><ci id="A3.T3.26.2.2.2.1.m1.1.1.cmml" xref="A3.T3.26.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.26.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.26.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.2">213.62</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.3">232.50</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.4">235.90</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.5">239.18</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.6">236.30</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.7">239.27</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.8">236.90</td>
<td class="ltx_td ltx_align_center" id="A3.T3.26.2.2.2.9">237.74</td>
</tr>
<tr class="ltx_tr" id="A3.T3.27.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.27.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.27.3.3.3.1.m1.1"><semantics id="A3.T3.27.3.3.3.1.m1.1a"><mo id="A3.T3.27.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.27.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.27.3.3.3.1.m1.1b"><ci id="A3.T3.27.3.3.3.1.m1.1.1.cmml" xref="A3.T3.27.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.27.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.27.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.2">0.766</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.3">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.4">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.5">0.784</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.6">0.787</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.7">0.785</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.8">0.783</td>
<td class="ltx_td ltx_align_center" id="A3.T3.27.3.3.3.9">0.783</td>
</tr>
<tr class="ltx_tr" id="A3.T3.28.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.28.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.28.4.4.4.1.m1.1"><semantics id="A3.T3.28.4.4.4.1.m1.1a"><mo id="A3.T3.28.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.28.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.28.4.4.4.1.m1.1b"><ci id="A3.T3.28.4.4.4.1.m1.1.1.cmml" xref="A3.T3.28.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.28.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.28.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.2">0.634</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.3">0.621</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.4">0.622</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.5">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.6">0.623</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.7">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.8">0.630</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.4.9">0.625</td>
</tr>
<tr class="ltx_tr" id="A3.T3.28.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.28.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.2">0.128</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.3">0.237</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.4">0.348</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.5">0.463</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.6">0.585</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.7">0.705</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.8">0.836</td>
<td class="ltx_td ltx_align_center" id="A3.T3.28.4.4.6.9">0.969</td>
</tr>
</table>
</figure>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.32.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.32.4.4">
<tr class="ltx_tr" id="A3.T3.32.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.32.4.4.5.1"><span class="ltx_text" id="A3.T3.32.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.2"><span class="ltx_text" id="A3.T3.32.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.3"><span class="ltx_text" id="A3.T3.32.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.4"><span class="ltx_text" id="A3.T3.32.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.5"><span class="ltx_text" id="A3.T3.32.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.6"><span class="ltx_text" id="A3.T3.32.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.7"><span class="ltx_text" id="A3.T3.32.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.8"><span class="ltx_text" id="A3.T3.32.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.5.9"><span class="ltx_text" id="A3.T3.32.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.29.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.29.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.29.1.1.1.1.m1.1"><semantics id="A3.T3.29.1.1.1.1.m1.1a"><mo id="A3.T3.29.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.29.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.29.1.1.1.1.m1.1b"><ci id="A3.T3.29.1.1.1.1.m1.1.1.cmml" xref="A3.T3.29.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.29.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.29.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.2">1.859</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.3">1.551</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.4">1.567</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T3.29.1.1.1.5.1">1.542</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.6">1.558</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.7">1.574</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.8">1.901</td>
<td class="ltx_td ltx_align_center" id="A3.T3.29.1.1.1.9">1.573</td>
</tr>
<tr class="ltx_tr" id="A3.T3.30.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.30.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.30.2.2.2.1.m1.1"><semantics id="A3.T3.30.2.2.2.1.m1.1a"><mo id="A3.T3.30.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.30.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.30.2.2.2.1.m1.1b"><ci id="A3.T3.30.2.2.2.1.m1.1.1.cmml" xref="A3.T3.30.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.30.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.30.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.2">307.07</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.3">322.79</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.4">325.04</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.5">324.17</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.6">326.59</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.7">321.93</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.8">320.48</td>
<td class="ltx_td ltx_align_center" id="A3.T3.30.2.2.2.9">326.27</td>
</tr>
<tr class="ltx_tr" id="A3.T3.31.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.31.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.31.3.3.3.1.m1.1"><semantics id="A3.T3.31.3.3.3.1.m1.1a"><mo id="A3.T3.31.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.31.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.31.3.3.3.1.m1.1b"><ci id="A3.T3.31.3.3.3.1.m1.1.1.cmml" xref="A3.T3.31.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.31.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.31.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.2">0.787</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.3">0.802</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.4">0.807</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.5">0.806</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.6">0.808</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.7">0.806</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.8">0.804</td>
<td class="ltx_td ltx_align_center" id="A3.T3.31.3.3.3.9">0.807</td>
</tr>
<tr class="ltx_tr" id="A3.T3.32.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.32.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.32.4.4.4.1.m1.1"><semantics id="A3.T3.32.4.4.4.1.m1.1a"><mo id="A3.T3.32.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.32.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.32.4.4.4.1.m1.1b"><ci id="A3.T3.32.4.4.4.1.m1.1.1.cmml" xref="A3.T3.32.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.32.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.32.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.2">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.3">0.622</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.4">0.622</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.5">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.6">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.7">0.616</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.8">0.615</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.4.9">0.620</td>
</tr>
<tr class="ltx_tr" id="A3.T3.32.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.32.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.2">0.235</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.3">0.420</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.4">0.606</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.5">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.6">0.994</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.7">1.197</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.8">1.417</td>
<td class="ltx_td ltx_align_center" id="A3.T3.32.4.4.6.9">1.659</td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A3.T3.36.4" style="width:433.6pt;">
<table class="ltx_tabular ltx_align_middle" id="A3.T3.36.4.4">
<tr class="ltx_tr" id="A3.T3.36.4.4.5" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.36.4.4.5.1"><span class="ltx_text" id="A3.T3.36.4.4.5.1.1" style="background-color:#ECF4FF;">AR Steps</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.2"><span class="ltx_text" id="A3.T3.36.4.4.5.2.1" style="background-color:#ECF4FF;">32</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.3"><span class="ltx_text" id="A3.T3.36.4.4.5.3.1" style="background-color:#ECF4FF;">64</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.4"><span class="ltx_text" id="A3.T3.36.4.4.5.4.1" style="background-color:#ECF4FF;">96</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.5"><span class="ltx_text" id="A3.T3.36.4.4.5.5.1" style="background-color:#ECF4FF;">128</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.6"><span class="ltx_text" id="A3.T3.36.4.4.5.6.1" style="background-color:#ECF4FF;">160</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.7"><span class="ltx_text" id="A3.T3.36.4.4.5.7.1" style="background-color:#ECF4FF;">192</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.8"><span class="ltx_text" id="A3.T3.36.4.4.5.8.1" style="background-color:#ECF4FF;">224</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.5.9"><span class="ltx_text" id="A3.T3.36.4.4.5.9.1" style="background-color:#ECF4FF;">256</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.33.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.33.1.1.1.1">
<span class="ltx_rule" style="width:100%;height:0.8pt;background:black;display:inline-block;">Â </span>
FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T3.33.1.1.1.1.m1.1"><semantics id="A3.T3.33.1.1.1.1.m1.1a"><mo id="A3.T3.33.1.1.1.1.m1.1.1" stretchy="false" xref="A3.T3.33.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T3.33.1.1.1.1.m1.1b"><ci id="A3.T3.33.1.1.1.1.m1.1.1.cmml" xref="A3.T3.33.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.33.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.33.1.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.2">1.718</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T3.33.1.1.1.3.1">1.661</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.4">1.669</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.5">1.669</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.6">1.706</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.7">1.703</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.8">1.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.33.1.1.1.9">1.726</td>
</tr>
<tr class="ltx_tr" id="A3.T3.34.2.2.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.34.2.2.2.1">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.34.2.2.2.1.m1.1"><semantics id="A3.T3.34.2.2.2.1.m1.1a"><mo id="A3.T3.34.2.2.2.1.m1.1.1" stretchy="false" xref="A3.T3.34.2.2.2.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.34.2.2.2.1.m1.1b"><ci id="A3.T3.34.2.2.2.1.m1.1.1.cmml" xref="A3.T3.34.2.2.2.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.34.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.34.2.2.2.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.2">325.62</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.3">339.62</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.4">339.00</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.5">339.71</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.6">340.75</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.7">338.80</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.8">341.01</td>
<td class="ltx_td ltx_align_center" id="A3.T3.34.2.2.2.9">340.00</td>
</tr>
<tr class="ltx_tr" id="A3.T3.35.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.35.3.3.3.1">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.35.3.3.3.1.m1.1"><semantics id="A3.T3.35.3.3.3.1.m1.1a"><mo id="A3.T3.35.3.3.3.1.m1.1.1" stretchy="false" xref="A3.T3.35.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.35.3.3.3.1.m1.1b"><ci id="A3.T3.35.3.3.3.1.m1.1.1.cmml" xref="A3.T3.35.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.35.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.35.3.3.3.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.2">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.3">0.814</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.4">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.5">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.6">0.815</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.7">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.8">0.816</td>
<td class="ltx_td ltx_align_center" id="A3.T3.35.3.3.3.9">0.817</td>
</tr>
<tr class="ltx_tr" id="A3.T3.36.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.36.4.4.4.1">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T3.36.4.4.4.1.m1.1"><semantics id="A3.T3.36.4.4.4.1.m1.1a"><mo id="A3.T3.36.4.4.4.1.m1.1.1" stretchy="false" xref="A3.T3.36.4.4.4.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T3.36.4.4.4.1.m1.1b"><ci id="A3.T3.36.4.4.4.1.m1.1.1.cmml" xref="A3.T3.36.4.4.4.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.36.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T3.36.4.4.4.1.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.2">0.610</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.3">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.4">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.5">0.608</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.6">0.610</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.7">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.8">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.4.9">0.611</td>
</tr>
<tr class="ltx_tr" id="A3.T3.36.4.4.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T3.36.4.4.6.1">Sec/Img</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.2">0.235</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.3">0.420</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.4">0.606</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.5">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.6">0.994</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.7">1.197</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.8">1.417</td>
<td class="ltx_td ltx_align_center" id="A3.T3.36.4.4.6.9">1.659</td>
</tr>
</table>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation in auto-regressive steps. <math alttext="(\text{cfg},\tau)" class="ltx_Math" display="inline" id="A3.T3.47.m1.2"><semantics id="A3.T3.47.m1.2b"><mrow id="A3.T3.47.m1.2.3.2" xref="A3.T3.47.m1.2.3.1.cmml"><mo id="A3.T3.47.m1.2.3.2.1" stretchy="false" xref="A3.T3.47.m1.2.3.1.cmml">(</mo><mtext id="A3.T3.47.m1.1.1" xref="A3.T3.47.m1.1.1a.cmml">cfg</mtext><mo id="A3.T3.47.m1.2.3.2.2" xref="A3.T3.47.m1.2.3.1.cmml">,</mo><mi id="A3.T3.47.m1.2.2" xref="A3.T3.47.m1.2.2.cmml">Ï„</mi><mo id="A3.T3.47.m1.2.3.2.3" stretchy="false" xref="A3.T3.47.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.47.m1.2c"><interval closure="open" id="A3.T3.47.m1.2.3.1.cmml" xref="A3.T3.47.m1.2.3.2"><ci id="A3.T3.47.m1.1.1a.cmml" xref="A3.T3.47.m1.1.1"><mtext id="A3.T3.47.m1.1.1.cmml" xref="A3.T3.47.m1.1.1">cfg</mtext></ci><ci id="A3.T3.47.m1.2.2.cmml" xref="A3.T3.47.m1.2.2">ğœ</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.47.m1.2d">(\text{cfg},\tau)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.47.m1.2e">( cfg , italic_Ï„ )</annotation></semantics></math> combinations: Base, <math alttext="(1.0,0.93)" class="ltx_Math" display="inline" id="A3.T3.48.m2.2"><semantics id="A3.T3.48.m2.2b"><mrow id="A3.T3.48.m2.2.3.2" xref="A3.T3.48.m2.2.3.1.cmml"><mo id="A3.T3.48.m2.2.3.2.1" stretchy="false" xref="A3.T3.48.m2.2.3.1.cmml">(</mo><mn id="A3.T3.48.m2.1.1" xref="A3.T3.48.m2.1.1.cmml">1.0</mn><mo id="A3.T3.48.m2.2.3.2.2" xref="A3.T3.48.m2.2.3.1.cmml">,</mo><mn id="A3.T3.48.m2.2.2" xref="A3.T3.48.m2.2.2.cmml">0.93</mn><mo id="A3.T3.48.m2.2.3.2.3" stretchy="false" xref="A3.T3.48.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.48.m2.2c"><interval closure="open" id="A3.T3.48.m2.2.3.1.cmml" xref="A3.T3.48.m2.2.3.2"><cn id="A3.T3.48.m2.1.1.cmml" type="float" xref="A3.T3.48.m2.1.1">1.0</cn><cn id="A3.T3.48.m2.2.2.cmml" type="float" xref="A3.T3.48.m2.2.2">0.93</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.48.m2.2d">(1.0,0.93)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.48.m2.2e">( 1.0 , 0.93 )</annotation></semantics></math>, <math alttext="(3.1,0.98)" class="ltx_Math" display="inline" id="A3.T3.49.m3.2"><semantics id="A3.T3.49.m3.2b"><mrow id="A3.T3.49.m3.2.3.2" xref="A3.T3.49.m3.2.3.1.cmml"><mo id="A3.T3.49.m3.2.3.2.1" stretchy="false" xref="A3.T3.49.m3.2.3.1.cmml">(</mo><mn id="A3.T3.49.m3.1.1" xref="A3.T3.49.m3.1.1.cmml">3.1</mn><mo id="A3.T3.49.m3.2.3.2.2" xref="A3.T3.49.m3.2.3.1.cmml">,</mo><mn id="A3.T3.49.m3.2.2" xref="A3.T3.49.m3.2.2.cmml">0.98</mn><mo id="A3.T3.49.m3.2.3.2.3" stretchy="false" xref="A3.T3.49.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.49.m3.2c"><interval closure="open" id="A3.T3.49.m3.2.3.1.cmml" xref="A3.T3.49.m3.2.3.2"><cn id="A3.T3.49.m3.1.1.cmml" type="float" xref="A3.T3.49.m3.1.1">3.1</cn><cn id="A3.T3.49.m3.2.2.cmml" type="float" xref="A3.T3.49.m3.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.49.m3.2d">(3.1,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.49.m3.2e">( 3.1 , 0.98 )</annotation></semantics></math>, <math alttext="(4.1,0.97)" class="ltx_Math" display="inline" id="A3.T3.50.m4.2"><semantics id="A3.T3.50.m4.2b"><mrow id="A3.T3.50.m4.2.3.2" xref="A3.T3.50.m4.2.3.1.cmml"><mo id="A3.T3.50.m4.2.3.2.1" stretchy="false" xref="A3.T3.50.m4.2.3.1.cmml">(</mo><mn id="A3.T3.50.m4.1.1" xref="A3.T3.50.m4.1.1.cmml">4.1</mn><mo id="A3.T3.50.m4.2.3.2.2" xref="A3.T3.50.m4.2.3.1.cmml">,</mo><mn id="A3.T3.50.m4.2.2" xref="A3.T3.50.m4.2.2.cmml">0.97</mn><mo id="A3.T3.50.m4.2.3.2.3" stretchy="false" xref="A3.T3.50.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.50.m4.2c"><interval closure="open" id="A3.T3.50.m4.2.3.1.cmml" xref="A3.T3.50.m4.2.3.2"><cn id="A3.T3.50.m4.1.1.cmml" type="float" xref="A3.T3.50.m4.1.1">4.1</cn><cn id="A3.T3.50.m4.2.2.cmml" type="float" xref="A3.T3.50.m4.2.2">0.97</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.50.m4.2d">(4.1,0.97)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.50.m4.2e">( 4.1 , 0.97 )</annotation></semantics></math>; Large, <math alttext="(1.0,0.94)" class="ltx_Math" display="inline" id="A3.T3.51.m5.2"><semantics id="A3.T3.51.m5.2b"><mrow id="A3.T3.51.m5.2.3.2" xref="A3.T3.51.m5.2.3.1.cmml"><mo id="A3.T3.51.m5.2.3.2.1" stretchy="false" xref="A3.T3.51.m5.2.3.1.cmml">(</mo><mn id="A3.T3.51.m5.1.1" xref="A3.T3.51.m5.1.1.cmml">1.0</mn><mo id="A3.T3.51.m5.2.3.2.2" xref="A3.T3.51.m5.2.3.1.cmml">,</mo><mn id="A3.T3.51.m5.2.2" xref="A3.T3.51.m5.2.2.cmml">0.94</mn><mo id="A3.T3.51.m5.2.3.2.3" stretchy="false" xref="A3.T3.51.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.51.m5.2c"><interval closure="open" id="A3.T3.51.m5.2.3.1.cmml" xref="A3.T3.51.m5.2.3.2"><cn id="A3.T3.51.m5.1.1.cmml" type="float" xref="A3.T3.51.m5.1.1">1.0</cn><cn id="A3.T3.51.m5.2.2.cmml" type="float" xref="A3.T3.51.m5.2.2">0.94</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.51.m5.2d">(1.0,0.94)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.51.m5.2e">( 1.0 , 0.94 )</annotation></semantics></math>, <math alttext="(3.0,0.98)" class="ltx_Math" display="inline" id="A3.T3.52.m6.2"><semantics id="A3.T3.52.m6.2b"><mrow id="A3.T3.52.m6.2.3.2" xref="A3.T3.52.m6.2.3.1.cmml"><mo id="A3.T3.52.m6.2.3.2.1" stretchy="false" xref="A3.T3.52.m6.2.3.1.cmml">(</mo><mn id="A3.T3.52.m6.1.1" xref="A3.T3.52.m6.1.1.cmml">3.0</mn><mo id="A3.T3.52.m6.2.3.2.2" xref="A3.T3.52.m6.2.3.1.cmml">,</mo><mn id="A3.T3.52.m6.2.2" xref="A3.T3.52.m6.2.2.cmml">0.98</mn><mo id="A3.T3.52.m6.2.3.2.3" stretchy="false" xref="A3.T3.52.m6.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.52.m6.2c"><interval closure="open" id="A3.T3.52.m6.2.3.1.cmml" xref="A3.T3.52.m6.2.3.2"><cn id="A3.T3.52.m6.1.1.cmml" type="float" xref="A3.T3.52.m6.1.1">3.0</cn><cn id="A3.T3.52.m6.2.2.cmml" type="float" xref="A3.T3.52.m6.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.52.m6.2d">(3.0,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.52.m6.2e">( 3.0 , 0.98 )</annotation></semantics></math>, <math alttext="(3.9,0.98)" class="ltx_Math" display="inline" id="A3.T3.53.m7.2"><semantics id="A3.T3.53.m7.2b"><mrow id="A3.T3.53.m7.2.3.2" xref="A3.T3.53.m7.2.3.1.cmml"><mo id="A3.T3.53.m7.2.3.2.1" stretchy="false" xref="A3.T3.53.m7.2.3.1.cmml">(</mo><mn id="A3.T3.53.m7.1.1" xref="A3.T3.53.m7.1.1.cmml">3.9</mn><mo id="A3.T3.53.m7.2.3.2.2" xref="A3.T3.53.m7.2.3.1.cmml">,</mo><mn id="A3.T3.53.m7.2.2" xref="A3.T3.53.m7.2.2.cmml">0.98</mn><mo id="A3.T3.53.m7.2.3.2.3" stretchy="false" xref="A3.T3.53.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.53.m7.2c"><interval closure="open" id="A3.T3.53.m7.2.3.1.cmml" xref="A3.T3.53.m7.2.3.2"><cn id="A3.T3.53.m7.1.1.cmml" type="float" xref="A3.T3.53.m7.1.1">3.9</cn><cn id="A3.T3.53.m7.2.2.cmml" type="float" xref="A3.T3.53.m7.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.53.m7.2d">(3.9,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.53.m7.2e">( 3.9 , 0.98 )</annotation></semantics></math>; Huge, <math alttext="(1.0,0.95)" class="ltx_Math" display="inline" id="A3.T3.54.m8.2"><semantics id="A3.T3.54.m8.2b"><mrow id="A3.T3.54.m8.2.3.2" xref="A3.T3.54.m8.2.3.1.cmml"><mo id="A3.T3.54.m8.2.3.2.1" stretchy="false" xref="A3.T3.54.m8.2.3.1.cmml">(</mo><mn id="A3.T3.54.m8.1.1" xref="A3.T3.54.m8.1.1.cmml">1.0</mn><mo id="A3.T3.54.m8.2.3.2.2" xref="A3.T3.54.m8.2.3.1.cmml">,</mo><mn id="A3.T3.54.m8.2.2" xref="A3.T3.54.m8.2.2.cmml">0.95</mn><mo id="A3.T3.54.m8.2.3.2.3" stretchy="false" xref="A3.T3.54.m8.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.54.m8.2c"><interval closure="open" id="A3.T3.54.m8.2.3.1.cmml" xref="A3.T3.54.m8.2.3.2"><cn id="A3.T3.54.m8.1.1.cmml" type="float" xref="A3.T3.54.m8.1.1">1.0</cn><cn id="A3.T3.54.m8.2.2.cmml" type="float" xref="A3.T3.54.m8.2.2">0.95</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.54.m8.2d">(1.0,0.95)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.54.m8.2e">( 1.0 , 0.95 )</annotation></semantics></math>, <math alttext="(3.9,0.99)" class="ltx_Math" display="inline" id="A3.T3.55.m9.2"><semantics id="A3.T3.55.m9.2b"><mrow id="A3.T3.55.m9.2.3.2" xref="A3.T3.55.m9.2.3.1.cmml"><mo id="A3.T3.55.m9.2.3.2.1" stretchy="false" xref="A3.T3.55.m9.2.3.1.cmml">(</mo><mn id="A3.T3.55.m9.1.1" xref="A3.T3.55.m9.1.1.cmml">3.9</mn><mo id="A3.T3.55.m9.2.3.2.2" xref="A3.T3.55.m9.2.3.1.cmml">,</mo><mn id="A3.T3.55.m9.2.2" xref="A3.T3.55.m9.2.2.cmml">0.99</mn><mo id="A3.T3.55.m9.2.3.2.3" stretchy="false" xref="A3.T3.55.m9.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.55.m9.2c"><interval closure="open" id="A3.T3.55.m9.2.3.1.cmml" xref="A3.T3.55.m9.2.3.2"><cn id="A3.T3.55.m9.1.1.cmml" type="float" xref="A3.T3.55.m9.1.1">3.9</cn><cn id="A3.T3.55.m9.2.2.cmml" type="float" xref="A3.T3.55.m9.2.2">0.99</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.55.m9.2d">(3.9,0.99)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.55.m9.2e">( 3.9 , 0.99 )</annotation></semantics></math>, <math alttext="(4.3,0.98)" class="ltx_Math" display="inline" id="A3.T3.56.m10.2"><semantics id="A3.T3.56.m10.2b"><mrow id="A3.T3.56.m10.2.3.2" xref="A3.T3.56.m10.2.3.1.cmml"><mo id="A3.T3.56.m10.2.3.2.1" stretchy="false" xref="A3.T3.56.m10.2.3.1.cmml">(</mo><mn id="A3.T3.56.m10.1.1" xref="A3.T3.56.m10.1.1.cmml">4.3</mn><mo id="A3.T3.56.m10.2.3.2.2" xref="A3.T3.56.m10.2.3.1.cmml">,</mo><mn id="A3.T3.56.m10.2.2" xref="A3.T3.56.m10.2.2.cmml">0.98</mn><mo id="A3.T3.56.m10.2.3.2.3" stretchy="false" xref="A3.T3.56.m10.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.T3.56.m10.2c"><interval closure="open" id="A3.T3.56.m10.2.3.1.cmml" xref="A3.T3.56.m10.2.3.2"><cn id="A3.T3.56.m10.1.1.cmml" type="float" xref="A3.T3.56.m10.1.1">4.3</cn><cn id="A3.T3.56.m10.2.2.cmml" type="float" xref="A3.T3.56.m10.2.2">0.98</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.56.m10.2d">(4.3,0.98)</annotation><annotation encoding="application/x-llamapun" id="A3.T3.56.m10.2e">( 4.3 , 0.98 )</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">Unlike the typical next token prediction that predicts only the next token in raster order, the generalized next token prediction can predict multiple tokens in random order, referred to as the next set-of-token prediction inÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>. As mentioned in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.SS5" title="3.5 Sampling in Next Set-of-Tokens Prediction â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3.5</span></a>, we use an iterative sampling strategy with a cosine step schedule. The auto-regressive steps <math alttext="N" class="ltx_Math" display="inline" id="A3.SS2.p1.1.m1.1"><semantics id="A3.SS2.p1.1.m1.1a"><mi id="A3.SS2.p1.1.m1.1.1" xref="A3.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p1.1.m1.1b"><ci id="A3.SS2.p1.1.m1.1.1.cmml" xref="A3.SS2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p1.1.m1.1d">italic_N</annotation></semantics></math> directly affect image quality and sampling efficiency.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.2">We started with <math alttext="T=32" class="ltx_Math" display="inline" id="A3.SS2.p2.1.m1.1"><semantics id="A3.SS2.p2.1.m1.1a"><mrow id="A3.SS2.p2.1.m1.1.1" xref="A3.SS2.p2.1.m1.1.1.cmml"><mi id="A3.SS2.p2.1.m1.1.1.2" xref="A3.SS2.p2.1.m1.1.1.2.cmml">T</mi><mo id="A3.SS2.p2.1.m1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="A3.SS2.p2.1.m1.1.1.3" xref="A3.SS2.p2.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.1.m1.1b"><apply id="A3.SS2.p2.1.m1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1"><eq id="A3.SS2.p2.1.m1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1"></eq><ci id="A3.SS2.p2.1.m1.1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.1.2">ğ‘‡</ci><cn id="A3.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="A3.SS2.p2.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.1.m1.1c">T=32</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p2.1.m1.1d">italic_T = 32</annotation></semantics></math> and incrementally increased by 32 to 256. Note that at <math alttext="T=256" class="ltx_Math" display="inline" id="A3.SS2.p2.2.m2.1"><semantics id="A3.SS2.p2.2.m2.1a"><mrow id="A3.SS2.p2.2.m2.1.1" xref="A3.SS2.p2.2.m2.1.1.cmml"><mi id="A3.SS2.p2.2.m2.1.1.2" xref="A3.SS2.p2.2.m2.1.1.2.cmml">T</mi><mo id="A3.SS2.p2.2.m2.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="A3.SS2.p2.2.m2.1.1.3" xref="A3.SS2.p2.2.m2.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.2.m2.1b"><apply id="A3.SS2.p2.2.m2.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1"><eq id="A3.SS2.p2.2.m2.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1"></eq><ci id="A3.SS2.p2.2.m2.1.1.2.cmml" xref="A3.SS2.p2.2.m2.1.1.2">ğ‘‡</ci><cn id="A3.SS2.p2.2.m2.1.1.3.cmml" type="integer" xref="A3.SS2.p2.2.m2.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.2.m2.1c">T=256</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p2.2.m2.1d">italic_T = 256</annotation></semantics></math>, the next set-of-tokens prediction decays to the typical next token prediction. We conducted experiments both with and without classifier-free guidance. The former requires additional null condition inference, thus doubling the computational cost.</p>
</div>
<figure class="ltx_figure" id="A3.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf1.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span><span class="ltx_text ltx_font_italic" id="A3.F5.sf1.2.1">One step</span> generateion. (AR Steps=1)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf2.g1" src="x11.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf2.2.1">set-of-tokens</span> prediction. (AR Steps: 8)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf3.g1" src="x12.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf3.2.1">set-of-tokens</span> prediction. (AR Steps: 16)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf4.g1" src="x13.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf4.2.1">set-of-tokens</span> prediction. (AR Steps: 32)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf5.g1" src="x14.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf5.2.1">set-of-tokens</span> prediction. (AR Steps: 64)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf6.g1" src="x15.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf6.2.1">set-of-tokens</span> prediction. (AR Steps: 128)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F5.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="104" id="A3.F5.sf7.g1" src="x16.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(g) </span>Next <span class="ltx_text ltx_font_italic" id="A3.F5.sf7.2.1">token</span> prediction. (AR Steps: 256)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="A3.F5.6.1">Uncurated</span> <math alttext="256\times 256" class="ltx_Math" display="inline" id="A3.F5.3.m1.1"><semantics id="A3.F5.3.m1.1b"><mrow id="A3.F5.3.m1.1.1" xref="A3.F5.3.m1.1.1.cmml"><mn id="A3.F5.3.m1.1.1.2" xref="A3.F5.3.m1.1.1.2.cmml">256</mn><mo id="A3.F5.3.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A3.F5.3.m1.1.1.1.cmml">Ã—</mo><mn id="A3.F5.3.m1.1.1.3" xref="A3.F5.3.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.F5.3.m1.1c"><apply id="A3.F5.3.m1.1.1.cmml" xref="A3.F5.3.m1.1.1"><times id="A3.F5.3.m1.1.1.1.cmml" xref="A3.F5.3.m1.1.1.1"></times><cn id="A3.F5.3.m1.1.1.2.cmml" type="integer" xref="A3.F5.3.m1.1.1.2">256</cn><cn id="A3.F5.3.m1.1.1.3.cmml" type="integer" xref="A3.F5.3.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.3.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A3.F5.3.m1.1e">256 Ã— 256</annotation></semantics></math> D-JEPA-H samples with different auto-regressive steps. <math alttext="\text{cfg}=3.9,\tau=0.99" class="ltx_Math" display="inline" id="A3.F5.4.m2.2"><semantics id="A3.F5.4.m2.2b"><mrow id="A3.F5.4.m2.2.2.2" xref="A3.F5.4.m2.2.2.3.cmml"><mrow id="A3.F5.4.m2.1.1.1.1" xref="A3.F5.4.m2.1.1.1.1.cmml"><mtext id="A3.F5.4.m2.1.1.1.1.2" xref="A3.F5.4.m2.1.1.1.1.2a.cmml">cfg</mtext><mo id="A3.F5.4.m2.1.1.1.1.1" xref="A3.F5.4.m2.1.1.1.1.1.cmml">=</mo><mn id="A3.F5.4.m2.1.1.1.1.3" xref="A3.F5.4.m2.1.1.1.1.3.cmml">3.9</mn></mrow><mo id="A3.F5.4.m2.2.2.2.3" xref="A3.F5.4.m2.2.2.3a.cmml">,</mo><mrow id="A3.F5.4.m2.2.2.2.2" xref="A3.F5.4.m2.2.2.2.2.cmml"><mi id="A3.F5.4.m2.2.2.2.2.2" xref="A3.F5.4.m2.2.2.2.2.2.cmml">Ï„</mi><mo id="A3.F5.4.m2.2.2.2.2.1" xref="A3.F5.4.m2.2.2.2.2.1.cmml">=</mo><mn id="A3.F5.4.m2.2.2.2.2.3" xref="A3.F5.4.m2.2.2.2.2.3.cmml">0.99</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.F5.4.m2.2c"><apply id="A3.F5.4.m2.2.2.3.cmml" xref="A3.F5.4.m2.2.2.2"><csymbol cd="ambiguous" id="A3.F5.4.m2.2.2.3a.cmml" xref="A3.F5.4.m2.2.2.2.3">formulae-sequence</csymbol><apply id="A3.F5.4.m2.1.1.1.1.cmml" xref="A3.F5.4.m2.1.1.1.1"><eq id="A3.F5.4.m2.1.1.1.1.1.cmml" xref="A3.F5.4.m2.1.1.1.1.1"></eq><ci id="A3.F5.4.m2.1.1.1.1.2a.cmml" xref="A3.F5.4.m2.1.1.1.1.2"><mtext id="A3.F5.4.m2.1.1.1.1.2.cmml" xref="A3.F5.4.m2.1.1.1.1.2">cfg</mtext></ci><cn id="A3.F5.4.m2.1.1.1.1.3.cmml" type="float" xref="A3.F5.4.m2.1.1.1.1.3">3.9</cn></apply><apply id="A3.F5.4.m2.2.2.2.2.cmml" xref="A3.F5.4.m2.2.2.2.2"><eq id="A3.F5.4.m2.2.2.2.2.1.cmml" xref="A3.F5.4.m2.2.2.2.2.1"></eq><ci id="A3.F5.4.m2.2.2.2.2.2.cmml" xref="A3.F5.4.m2.2.2.2.2.2">ğœ</ci><cn id="A3.F5.4.m2.2.2.2.2.3.cmml" type="float" xref="A3.F5.4.m2.2.2.2.2.3">0.99</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.4.m2.2d">\text{cfg}=3.9,\tau=0.99</annotation><annotation encoding="application/x-llamapun" id="A3.F5.4.m2.2e">cfg = 3.9 , italic_Ï„ = 0.99</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.p3">
<p class="ltx_p" id="A3.SS2.p3.1">The results are summarized in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T3" title="Table 3 â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">3</span></a>. We found that sampling with more than 64 steps for models across all scales significantly outperforms 32 steps. We also visualize the samples in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.F5" title="Figure 5 â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>. Notably, at 64 steps, the sampled images are already very close to the optimal results more efficiently. Contrary to our initial assumptions, we discovered that <span class="ltx_text ltx_font_italic" id="A3.SS2.p3.1.1">achieving the best sampling performance does not necessarily require 256 steps.</span> This highlights the advantage of the next set-of-token prediction over typical next-token prediction in terms of sampling efficiency.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.p4">
<p class="ltx_p" id="A3.SS2.p4.1">Another interesting observation is that the steps required to achieve the best FID consistently decrease as the model size increases. Specifically, we achieve the best performance for the huge model with only 64 steps.</p>
</div>
<section class="ltx_paragraph" id="A3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Sampling efficiency.</h4>
<figure class="ltx_table" id="A3.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T4.5">
<tr class="ltx_tr" id="A3.T4.5.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.5.6">Model</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.5.7">cfg</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.1"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T4.1.1.1.m1.1"><semantics id="A3.T4.1.1.1.m1.1a"><mi id="A3.T4.1.1.1.m1.1.1" xref="A3.T4.1.1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.T4.1.1.1.m1.1b"><ci id="A3.T4.1.1.1.m1.1.1.cmml" xref="A3.T4.1.1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.1.1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T4.1.1.1.m1.1d">italic_Ï„</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.5.8">AR Steps</td>
<td class="ltx_td ltx_align_center" id="A3.T4.2.2.2">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A3.T4.2.2.2.m1.1"><semantics id="A3.T4.2.2.2.m1.1a"><mo id="A3.T4.2.2.2.m1.1.1" stretchy="false" xref="A3.T4.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A3.T4.2.2.2.m1.1b"><ci id="A3.T4.2.2.2.m1.1.1.cmml" xref="A3.T4.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.2.2.2.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T4.3.3.3">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T4.3.3.3.m1.1"><semantics id="A3.T4.3.3.3.m1.1a"><mo id="A3.T4.3.3.3.m1.1.1" stretchy="false" xref="A3.T4.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T4.3.3.3.m1.1b"><ci id="A3.T4.3.3.3.m1.1.1.cmml" xref="A3.T4.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.3.3.3.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T4.4.4.4">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T4.4.4.4.m1.1"><semantics id="A3.T4.4.4.4.m1.1a"><mo id="A3.T4.4.4.4.m1.1.1" stretchy="false" xref="A3.T4.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T4.4.4.4.m1.1b"><ci id="A3.T4.4.4.4.m1.1.1.cmml" xref="A3.T4.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.4.4.4.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.5.5">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A3.T4.5.5.5.m1.1"><semantics id="A3.T4.5.5.5.m1.1a"><mo id="A3.T4.5.5.5.m1.1.1" stretchy="false" xref="A3.T4.5.5.5.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A3.T4.5.5.5.m1.1b"><ci id="A3.T4.5.5.5.m1.1.1.cmml" xref="A3.T4.5.5.5.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T4.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A3.T4.5.5.5.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.5.9">Sec/Img</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T4.5.6.1">Base</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.2">1.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.3">0.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.4">32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.5">4.027</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.6">184.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.7">0.756</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T4.5.6.8">0.614</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.5.6.9">0.043</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.7.1">Base</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.2">3.1</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.4">32</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.5">2.261</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.6">271.57</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.7">0.785</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.7.8">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.7.9">0.069</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.8.1">Base</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.2">4.1</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.3">0.97</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.5">2.081</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.6">320.94</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.7">0.817</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.8.8">0.590</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.8.9">0.120</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.9.1">Base</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.2">3.1</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.5">1.912</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.6">281.46</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.7">0.800</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.9.8">0.603</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.9.9">0.120</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.10.1">Large</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.2">3.0</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.5">1.633</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.6">297.46</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.7">0.796</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.10.8">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.10.9">0.248</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.11.1">Huge</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.2">4.3</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.3">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.4">64</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.5">1.661</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.6">339.62</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.7">0.814</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.11.8">0.614</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.11.9">0.463</td>
</tr>
<tr class="ltx_tr" id="A3.T4.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T4.5.12.1">Huge</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.2">3.9</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.3">0.99</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.4">128</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.5">1.542</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.6">324.17</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.7">0.806</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T4.5.12.8">0.619</td>
<td class="ltx_td ltx_align_center" id="A3.T4.5.12.9">0.800</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Details of efficiency configuration. <span class="ltx_text ltx_font_bold" id="A3.T4.7.1">Sec/Img</span> denotes the average time to generate one image (measured with a batch size of 256 on an H800 GPU).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS2.SSS0.Px1.p1.1">We measured sampling efficiency using H800 hardware with a batch size 256, averaging the time to generate one image with a resolution of <math alttext="256\times 256" class="ltx_Math" display="inline" id="A3.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="A3.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="A3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">256</mn><mo id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1"><times id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.1"></times><cn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" type="integer" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.2">256</cn><cn id="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="A3.SS2.SSS0.Px1.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.SSS0.Px1.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.SSS0.Px1.p1.1.m1.1d">256 Ã— 256</annotation></semantics></math>. Results under selected configurations are plotted in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.F2" title="Figure 2 â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, and more details are listed in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T4" title="Table 4 â€£ Sampling efficiency. â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="A3.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T5.5">
<tr class="ltx_tr" id="A3.T5.5.6">
<td class="ltx_td ltx_border_r" id="A3.T5.5.6.1"></td>
<td class="ltx_td ltx_align_left ltx_border_r" colspan="2" id="A3.T5.5.6.2">w/o cfg</td>
<td class="ltx_td ltx_align_left ltx_border_r" colspan="3" id="A3.T5.5.6.3">w/ cfg (best FID)</td>
<td class="ltx_td ltx_align_left" colspan="3" id="A3.T5.5.6.4">w/ cfg (better IS)</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T5.5.5.6">Model</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.7">AR Steps</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.1"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T5.1.1.1.m1.1"><semantics id="A3.T5.1.1.1.m1.1a"><mi id="A3.T5.1.1.1.m1.1.1" xref="A3.T5.1.1.1.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.T5.1.1.1.m1.1b"><ci id="A3.T5.1.1.1.m1.1.1.cmml" xref="A3.T5.1.1.1.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.1.1.1.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T5.1.1.1.m1.1d">italic_Ï„</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.2.2.2"><span class="ltx_text ltx_markedasmath" id="A3.T5.2.2.2.1">cfg</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.8">AR Steps</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.3.3.3"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T5.3.3.3.m1.1"><semantics id="A3.T5.3.3.3.m1.1a"><mi id="A3.T5.3.3.3.m1.1.1" xref="A3.T5.3.3.3.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.T5.3.3.3.m1.1b"><ci id="A3.T5.3.3.3.m1.1.1.cmml" xref="A3.T5.3.3.3.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.3.3.3.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T5.3.3.3.m1.1d">italic_Ï„</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.4.4.4"><span class="ltx_text ltx_markedasmath" id="A3.T5.4.4.4.1">cfg</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.9">AR Steps</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.5.5"><math alttext="\tau" class="ltx_Math" display="inline" id="A3.T5.5.5.5.m1.1"><semantics id="A3.T5.5.5.5.m1.1a"><mi id="A3.T5.5.5.5.m1.1.1" xref="A3.T5.5.5.5.m1.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="A3.T5.5.5.5.m1.1b"><ci id="A3.T5.5.5.5.m1.1.1.cmml" xref="A3.T5.5.5.5.m1.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T5.5.5.5.m1.1c">\tau</annotation><annotation encoding="application/x-llamapun" id="A3.T5.5.5.5.m1.1d">italic_Ï„</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A3.T5.5.7.1">D-JEPA-B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.2">128</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.5.7.3">0.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.4">3.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.5">224</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.5.7.6">0.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.7">4.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.8">64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.5.7.9">0.97</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.5.8.1">D-JEPA-L</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.2">160</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.8.3">0.94</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.4">3.0</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.5">256</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.8.6">0.98</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.7">3.9</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.8">192</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.8.9">0.98</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A3.T5.5.9.1">D-JEPA-H</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.2">192</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.9.3">0.95</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.4">3.9</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.5">128</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A3.T5.5.9.6">0.99</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.7">4.3</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.8">224</td>
<td class="ltx_td ltx_align_center" id="A3.T5.5.9.9">0.98</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>The sampling configuration for results listed in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T2" title="Table 2 â€£ Scaling law of D-JEPA. â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T1" title="Table 1 â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">1</span></a> and Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.T6" title="Table 6 â€£ D.1 Full comparison on ImageNet â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="A3.SS2.SSS0.Px1.p2.1">D-JEPA can generate images with an FID of 4.0 in 47 ms, demonstrating strong competitiveness. Moreover, we can achieve state-of-the-art FID within 1 second. In Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A3.T5" title="Table 5 â€£ Sampling efficiency. â€£ C.2 Abalation on auto-regressive steps â€£ Appendix C Sampling with generalized next token prediction â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">5</span></a>, we list the configuration used in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.SS1" title="4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional results on ImageNet</h2>
<section class="ltx_subsection" id="A4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Full comparison on ImageNet</h3>
<figure class="ltx_table" id="A4.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T6.5">
<tr class="ltx_tr" id="A4.T6.4.4">
<td class="ltx_td ltx_border_r" id="A4.T6.4.4.5"></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.4.4.6">#Params</td>
<td class="ltx_td ltx_align_center" id="A4.T6.1.1.1">FID<math alttext="\downarrow" class="ltx_Math" display="inline" id="A4.T6.1.1.1.m1.1"><semantics id="A4.T6.1.1.1.m1.1a"><mo id="A4.T6.1.1.1.m1.1.1" stretchy="false" xref="A4.T6.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="A4.T6.1.1.1.m1.1b"><ci id="A4.T6.1.1.1.m1.1.1.cmml" xref="A4.T6.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.1.1.1.m1.1d">â†“</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.2.2.2">IS<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.2.2.2.m1.1"><semantics id="A4.T6.2.2.2.m1.1a"><mo id="A4.T6.2.2.2.m1.1.1" stretchy="false" xref="A4.T6.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A4.T6.2.2.2.m1.1b"><ci id="A4.T6.2.2.2.m1.1.1.cmml" xref="A4.T6.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.2.2.2.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A4.T6.3.3.3">Pre.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.3.3.3.m1.1"><semantics id="A4.T6.3.3.3.m1.1a"><mo id="A4.T6.3.3.3.m1.1.1" stretchy="false" xref="A4.T6.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A4.T6.3.3.3.m1.1b"><ci id="A4.T6.3.3.3.m1.1.1.cmml" xref="A4.T6.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.3.3.3.m1.1d">â†‘</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A4.T6.4.4.4">Rec.<math alttext="\uparrow" class="ltx_Math" display="inline" id="A4.T6.4.4.4.m1.1"><semantics id="A4.T6.4.4.4.m1.1a"><mo id="A4.T6.4.4.4.m1.1.1" stretchy="false" xref="A4.T6.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="A4.T6.4.4.4.m1.1b"><ci id="A4.T6.4.4.4.m1.1.1.cmml" xref="A4.T6.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A4.T6.4.4.4.m1.1d">â†‘</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.6" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="6" id="A4.T6.5.6.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A4.T6.5.6.1.1" style="background-color:#EFEFEF;">Base scale model (less than 300M)</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.7.1">MAR-BÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.7.2">208M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.7.3">3.48</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.7.4">192.4</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.7.5">0.78</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.7.6">0.58</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.8.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.8.1.1" style="background-color:#ECF4FF;">D-JEPA-B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.8.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.8.2.1" style="background-color:#ECF4FF;">212M</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.8.3"><span class="ltx_text ltx_font_bold" id="A4.T6.5.8.3.1" style="background-color:#ECF4FF;">3.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.8.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="A4.T6.5.8.4.1" style="background-color:#ECF4FF;">197.1</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.8.5"><span class="ltx_text" id="A4.T6.5.8.5.1" style="background-color:#ECF4FF;">0.77</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.8.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.8.6.1" style="background-color:#ECF4FF;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.9.1">MaskGITÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.9.2">227M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.9.3">6.18</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.9.4">182.1</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.9.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.9.5.1">0.80</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.9.6">0.51</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.10.1">MAGEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.10.2">230M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.10.3">6.93</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.10.4">195.8</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.10.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.10.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.5" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="A4.T6.5.5.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A4.T6.5.5.1.1" style="background-color:#EFEFEF;">Large scale model (300<math alttext="\sim" class="ltx_Math" display="inline" id="A4.T6.5.5.1.1.m1.1" style="background-color:#EFEFEF;"><semantics id="A4.T6.5.5.1.1.m1.1a"><mo id="A4.T6.5.5.1.1.m1.1.1" mathbackground="#EFEFEF" xref="A4.T6.5.5.1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="A4.T6.5.5.1.1.m1.1b"><csymbol cd="latexml" id="A4.T6.5.5.1.1.m1.1.1.cmml" xref="A4.T6.5.5.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.5.5.1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="A4.T6.5.5.1.1.m1.1d">âˆ¼</annotation></semantics></math>700M)</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.11.1">GIVTÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib105" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.11.2">304M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.11.3">5.67</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.11.4">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.11.5">0.75</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.11.6">0.59</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.12.1">MAGVIT-v2Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib118" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.12.2">307M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.12.3">3.65</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.12.4">200.5</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.12.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.12.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.13.1">LDM-4Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib89" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.13.2">400M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.13.3">10.56</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.13.4">103.5</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.13.5">0.71</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.13.6">0.62</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.14.1">MAR-LÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.14.2">479M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.14.3">2.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.14.4">221.4</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.14.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.14.5.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.14.6">0.60</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.15.1">ADMÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib26" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.15.2">554M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.15.3">10.94</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.15.4">101.0</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.15.5">0.63</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.15.6">0.63</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.16.1">DiT-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib81" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.16.2">675M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.16.3">9.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.16.4">121.5</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.16.5">0.67</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.16.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.16.6.1">0.67</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.17.1">SiT-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.17.2">675M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.17.3">8.60</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.17.4">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.17.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.17.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.18">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.18.1">MDTv2-XLÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib33" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.18.2">676M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.18.3">5.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.18.4">155.6</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.18.5">0.72</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.18.6">0.66</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.19" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.19.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.19.1.1" style="background-color:#ECF4FF;">D-JEPA-L</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.19.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.19.2.1" style="background-color:#ECF4FF;">687M</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.19.3"><span class="ltx_text ltx_font_bold" id="A4.T6.5.19.3.1" style="background-color:#ECF4FF;">2.32</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.19.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="A4.T6.5.19.4.1" style="background-color:#ECF4FF;">233.5</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.19.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.19.5.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.19.6"><span class="ltx_text" id="A4.T6.5.19.6.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.20" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="6" id="A4.T6.5.20.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A4.T6.5.20.1.1" style="background-color:#EFEFEF;">Huge scale model (900+M)</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.21">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.21.1">MAR-HÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.21.2">943M</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.21.3">2.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.21.4">227.8</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.21.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.21.5.1">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.21.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.21.6.1">0.62</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.22" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.22.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.22.1.1" style="background-color:#ECF4FF;">D-JEPA-H</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.22.2" style="background-color:#ECF4FF;"><span class="ltx_text" id="A4.T6.5.22.2.1" style="background-color:#ECF4FF;">1.4B</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.22.3"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.3.1" style="background-color:#ECF4FF;">2.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.22.4" style="background-color:#ECF4FF;"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.4.1" style="background-color:#ECF4FF;">239.3</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.22.5"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.5.1" style="background-color:#ECF4FF;">0.79</span></td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.22.6"><span class="ltx_text ltx_font_bold" id="A4.T6.5.22.6.1" style="background-color:#ECF4FF;">0.62</span></td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.23">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.23.1">Autoreg. Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib31" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.23.2">1.4B</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.23.3">15.78</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.23.4">78.3</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.23.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.23.6">-</td>
</tr>
<tr class="ltx_tr" id="A4.T6.5.24">
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.24.1">VDM++Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib57" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="A4.T6.5.24.2">2.0B</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.24.3">2.40</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A4.T6.5.24.4">225.3</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.24.5">-</td>
<td class="ltx_td ltx_align_center" id="A4.T6.5.24.6">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>System-level comparison on ImageNet <math alttext="256\times 256" class="ltx_Math" display="inline" id="A4.T6.7.m1.1"><semantics id="A4.T6.7.m1.1b"><mrow id="A4.T6.7.m1.1.1" xref="A4.T6.7.m1.1.1.cmml"><mn id="A4.T6.7.m1.1.1.2" xref="A4.T6.7.m1.1.1.2.cmml">256</mn><mo id="A4.T6.7.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A4.T6.7.m1.1.1.1.cmml">Ã—</mo><mn id="A4.T6.7.m1.1.1.3" xref="A4.T6.7.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T6.7.m1.1c"><apply id="A4.T6.7.m1.1.1.cmml" xref="A4.T6.7.m1.1.1"><times id="A4.T6.7.m1.1.1.1.cmml" xref="A4.T6.7.m1.1.1.1"></times><cn id="A4.T6.7.m1.1.1.2.cmml" type="integer" xref="A4.T6.7.m1.1.1.2">256</cn><cn id="A4.T6.7.m1.1.1.3.cmml" type="integer" xref="A4.T6.7.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.7.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A4.T6.7.m1.1e">256 Ã— 256</annotation></semantics></math> conditional generation <span class="ltx_text ltx_font_italic" id="A4.T6.9.1">without</span> classifier-free guidance.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">We provide a more comprehensive comparison with earlier works in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.T6" title="Table 6 â€£ D.1 Full comparison on ImageNet â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>. D-JEPA-B, with only 212M parameters, performs only slightly worse than MAR-L (with 479M parameters), MAR-H (with 943M parameters), and VDM++ (with 2.0B parameters). It is also worth noting that D-JEPA-B significantly outperforms DiT-XL (with 675M parameters) by a large margin in terms of FID (3.40 vs. 9.62) and IS (197.1 vs. 121.5).</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS1.p2">
<p class="ltx_p" id="A4.SS1.p2.2">D-JEPA-L and D-JEPA-H achieve state-of-the-art performance in both FID and IS metrics. Furthermore, D-JEPA-H sets unprecedented records in both of these metrics. Although D-JEPA performs well in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4.T2" title="Table 2 â€£ Scaling law of D-JEPA. â€£ 4.1 Image Synthetis â€£ 4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>, it is not outstanding. However, we believe that the metrics without classifier-free guidance better reflect the actual performance of each model, as the value of <span class="ltx_text ltx_markedasmath" id="A4.SS1.p2.2.1">cfg</span> can significantly impact the results. Determining the optimal <span class="ltx_text ltx_markedasmath" id="A4.SS1.p2.2.2">cfg</span> value for each model is challenging. Therefore, the metrics presented in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.T6" title="Table 6 â€£ D.1 Full comparison on ImageNet â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a> are considered more convincing.</p>
</div>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Training curve</h3>
<figure class="ltx_figure" id="A4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="A4.F6.g1" src="x17.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Training dynamics of model architectures. The sampling parameters for the images evaluated to obtain the FID and IS in the figure are: <math alttext="\text{cfg}=1.0,\tau=0.95,\text{AR Steps}=256" class="ltx_Math" display="inline" id="A4.F6.2.m1.2"><semantics id="A4.F6.2.m1.2b"><mrow id="A4.F6.2.m1.2.2.2" xref="A4.F6.2.m1.2.2.3.cmml"><mrow id="A4.F6.2.m1.1.1.1.1" xref="A4.F6.2.m1.1.1.1.1.cmml"><mtext id="A4.F6.2.m1.1.1.1.1.2" xref="A4.F6.2.m1.1.1.1.1.2a.cmml">cfg</mtext><mo id="A4.F6.2.m1.1.1.1.1.1" xref="A4.F6.2.m1.1.1.1.1.1.cmml">=</mo><mn id="A4.F6.2.m1.1.1.1.1.3" xref="A4.F6.2.m1.1.1.1.1.3.cmml">1.0</mn></mrow><mo id="A4.F6.2.m1.2.2.2.3" xref="A4.F6.2.m1.2.2.3a.cmml">,</mo><mrow id="A4.F6.2.m1.2.2.2.2.2" xref="A4.F6.2.m1.2.2.2.2.3.cmml"><mrow id="A4.F6.2.m1.2.2.2.2.1.1" xref="A4.F6.2.m1.2.2.2.2.1.1.cmml"><mi id="A4.F6.2.m1.2.2.2.2.1.1.2" xref="A4.F6.2.m1.2.2.2.2.1.1.2.cmml">Ï„</mi><mo id="A4.F6.2.m1.2.2.2.2.1.1.1" xref="A4.F6.2.m1.2.2.2.2.1.1.1.cmml">=</mo><mn id="A4.F6.2.m1.2.2.2.2.1.1.3" xref="A4.F6.2.m1.2.2.2.2.1.1.3.cmml">0.95</mn></mrow><mo id="A4.F6.2.m1.2.2.2.2.2.3" xref="A4.F6.2.m1.2.2.2.2.3a.cmml">,</mo><mrow id="A4.F6.2.m1.2.2.2.2.2.2" xref="A4.F6.2.m1.2.2.2.2.2.2.cmml"><mtext id="A4.F6.2.m1.2.2.2.2.2.2.2" xref="A4.F6.2.m1.2.2.2.2.2.2.2a.cmml">AR Steps</mtext><mo id="A4.F6.2.m1.2.2.2.2.2.2.1" xref="A4.F6.2.m1.2.2.2.2.2.2.1.cmml">=</mo><mn id="A4.F6.2.m1.2.2.2.2.2.2.3" xref="A4.F6.2.m1.2.2.2.2.2.2.3.cmml">256</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.F6.2.m1.2c"><apply id="A4.F6.2.m1.2.2.3.cmml" xref="A4.F6.2.m1.2.2.2"><csymbol cd="ambiguous" id="A4.F6.2.m1.2.2.3a.cmml" xref="A4.F6.2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="A4.F6.2.m1.1.1.1.1.cmml" xref="A4.F6.2.m1.1.1.1.1"><eq id="A4.F6.2.m1.1.1.1.1.1.cmml" xref="A4.F6.2.m1.1.1.1.1.1"></eq><ci id="A4.F6.2.m1.1.1.1.1.2a.cmml" xref="A4.F6.2.m1.1.1.1.1.2"><mtext id="A4.F6.2.m1.1.1.1.1.2.cmml" xref="A4.F6.2.m1.1.1.1.1.2">cfg</mtext></ci><cn id="A4.F6.2.m1.1.1.1.1.3.cmml" type="float" xref="A4.F6.2.m1.1.1.1.1.3">1.0</cn></apply><apply id="A4.F6.2.m1.2.2.2.2.3.cmml" xref="A4.F6.2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="A4.F6.2.m1.2.2.2.2.3a.cmml" xref="A4.F6.2.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="A4.F6.2.m1.2.2.2.2.1.1.cmml" xref="A4.F6.2.m1.2.2.2.2.1.1"><eq id="A4.F6.2.m1.2.2.2.2.1.1.1.cmml" xref="A4.F6.2.m1.2.2.2.2.1.1.1"></eq><ci id="A4.F6.2.m1.2.2.2.2.1.1.2.cmml" xref="A4.F6.2.m1.2.2.2.2.1.1.2">ğœ</ci><cn id="A4.F6.2.m1.2.2.2.2.1.1.3.cmml" type="float" xref="A4.F6.2.m1.2.2.2.2.1.1.3">0.95</cn></apply><apply id="A4.F6.2.m1.2.2.2.2.2.2.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2"><eq id="A4.F6.2.m1.2.2.2.2.2.2.1.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2.1"></eq><ci id="A4.F6.2.m1.2.2.2.2.2.2.2a.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2.2"><mtext id="A4.F6.2.m1.2.2.2.2.2.2.2.cmml" xref="A4.F6.2.m1.2.2.2.2.2.2.2">AR Steps</mtext></ci><cn id="A4.F6.2.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="A4.F6.2.m1.2.2.2.2.2.2.3">256</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.F6.2.m1.2d">\text{cfg}=1.0,\tau=0.95,\text{AR Steps}=256</annotation><annotation encoding="application/x-llamapun" id="A4.F6.2.m1.2e">cfg = 1.0 , italic_Ï„ = 0.95 , AR Steps = 256</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.1">In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F6" title="Figure 6 â€£ D.2 Training curve â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>, we present the FID and IS metrics as a function of training epochs. It is evident that irrespective of the model size, 160 training epochs are essential for convergence when employing diffusion loss. Models with a smaller parameter count necessitate a more significant number of training epochs. Although the Base, Large, and Huge models were trained for 1400, 480, and 320 epochs, respectively, the trends in the metrics suggest that further increasing the number of training epochs could potentially enhance D-JEPAâ€™s performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS2.p2">
<p class="ltx_p" id="A4.SS2.p2.1">Moreover, it is crucial to highlight that the model size directly influences the attainable performance ceiling. For smaller models, such as D-JEPA-B, achieving the performance levels of larger models, like D-JEPA-L and D-JEPA-H, is unattainable, even with extensive training. As illustrated in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F6" title="Figure 6 â€£ D.2 Training curve â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">6</span></a>, it is apparent that when the parameter size exceeds 500M, D-JEPA exhibits markedly superior learning capabilities.</p>
</div>
</section>
<section class="ltx_subsection" id="A4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.3 </span>Inpainting and Outpainting</h3>
<figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1127" id="A4.F7.g1" src="x18.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Inpainting and outpainting capabilities of D-JEPA on training data. The percentages below the images indicate the proportion of the reference input that was dropped.</figcaption>
</figure>
<figure class="ltx_figure" id="A4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1128" id="A4.F8.g1" src="x19.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Inpainting and outpainting capabilities of D-JEPA on previously unseen data. The percentages below the images indicate the proportion of the reference input that was dropped.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS3.p1">
<p class="ltx_p" id="A4.SS3.p1.1">In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F7" title="Figure 7 â€£ D.3 Inpainting and Outpainting â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a> and Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F8" title="Figure 8 â€£ D.3 Inpainting and Outpainting â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a>, we demonstrate D-JEPAâ€™s capabilities in image restoration and inpainting and outpainting on both ImageNet1k images and unseen images. As shown in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F7" title="Figure 7 â€£ D.3 Inpainting and Outpainting â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a>, D-JEPA can reconstruct highly similar images from only 10% of the original features, showcasing its visual solid retrieval capabilities. In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A4.F8" title="Figure 8 â€£ D.3 Inpainting and Outpainting â€£ Appendix D Additional results on ImageNet â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a>, D-JEPA effectively supplements missing visual features based on contextual content.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS3.p2">
<p class="ltx_p" id="A4.SS3.p2.1">We believe that training on larger-scale datasets will significantly enhance D-JEPAâ€™s painting capabilities. Additionally, from the results in these two figures, it is evident that the quality of the training data plays a decisive role in the final generated image quality. D-JEPA, like all other generative models, essentially strives to fit the training data distribution better and finds it challenging to create data distributions that are perceived as better by human standards.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>D-JEPA for representation learning</h2>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Theoretical motivation</h3>
<div class="ltx_para ltx_noindent" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">A theoretical motivation for the effectiveness of the collapse prevention strategy was proposed in Â <cite class="ltx_cite ltx_citemacro_cite">Grill etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib38" title="">2020</a>)</cite>. We adapt their analysis for our smoothed l1 loss in Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a>. For ease of exposition, we will disregard the effect of the conditioning variable and consider one-dimensional representations like Â <cite class="ltx_cite ltx_citemacro_cite">Bardes etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib12" title="">2024</a>)</cite>. The optimal predictor under Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E2" title="In 3.2 Representation Learning with JEPAs â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">2</span></a> is thus given by the following functional expression:</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p2">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A8.EGx1">
<tbody id="A5.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\gamma^{\star}(\phi(x_{i}))" class="ltx_Math" display="inline" id="A5.Ex3.m1.1"><semantics id="A5.Ex3.m1.1a"><mrow id="A5.Ex3.m1.1.1" xref="A5.Ex3.m1.1.1.cmml"><msup id="A5.Ex3.m1.1.1.3" xref="A5.Ex3.m1.1.1.3.cmml"><mi id="A5.Ex3.m1.1.1.3.2" xref="A5.Ex3.m1.1.1.3.2.cmml">Î³</mi><mo id="A5.Ex3.m1.1.1.3.3" xref="A5.Ex3.m1.1.1.3.3.cmml">â‹†</mo></msup><mo id="A5.Ex3.m1.1.1.2" xref="A5.Ex3.m1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex3.m1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex3.m1.1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m1.1.1.1.1.1.3" xref="A5.Ex3.m1.1.1.1.1.1.3.cmml">Ï•</mi><mo id="A5.Ex3.m1.1.1.1.1.1.2" xref="A5.Ex3.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex3.m1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex3.m1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex3.m1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex3.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex3.m1.1b"><apply id="A5.Ex3.m1.1.1.cmml" xref="A5.Ex3.m1.1.1"><times id="A5.Ex3.m1.1.1.2.cmml" xref="A5.Ex3.m1.1.1.2"></times><apply id="A5.Ex3.m1.1.1.3.cmml" xref="A5.Ex3.m1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex3.m1.1.1.3.1.cmml" xref="A5.Ex3.m1.1.1.3">superscript</csymbol><ci id="A5.Ex3.m1.1.1.3.2.cmml" xref="A5.Ex3.m1.1.1.3.2">ğ›¾</ci><ci id="A5.Ex3.m1.1.1.3.3.cmml" xref="A5.Ex3.m1.1.1.3.3">â‹†</ci></apply><apply id="A5.Ex3.m1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.1.1.1.1"><times id="A5.Ex3.m1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.1.1.1.1.1.2"></times><ci id="A5.Ex3.m1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.1.1.1.1.1.3">italic-Ï•</ci><apply id="A5.Ex3.m1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A5.Ex3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex3.m1.1c">\displaystyle\gamma^{\star}(\phi(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="A5.Ex3.m1.1d">italic_Î³ start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ( italic_Ï• ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{argmin}_{\gamma}\parallel\gamma(\phi(x_{i}))-g_{i}%
\parallel_{1}" class="ltx_Math" display="inline" id="A5.Ex3.m2.1"><semantics id="A5.Ex3.m2.1a"><mrow id="A5.Ex3.m2.1.1" xref="A5.Ex3.m2.1.1.cmml"><mi id="A5.Ex3.m2.1.1.3" xref="A5.Ex3.m2.1.1.3.cmml"></mi><mo id="A5.Ex3.m2.1.1.2" xref="A5.Ex3.m2.1.1.2.cmml">=</mo><mrow id="A5.Ex3.m2.1.1.1" xref="A5.Ex3.m2.1.1.1.cmml"><msub id="A5.Ex3.m2.1.1.1.3" xref="A5.Ex3.m2.1.1.1.3.cmml"><mtext id="A5.Ex3.m2.1.1.1.3.2" xref="A5.Ex3.m2.1.1.1.3.2a.cmml">argmin</mtext><mi id="A5.Ex3.m2.1.1.1.3.3" xref="A5.Ex3.m2.1.1.1.3.3.cmml">Î³</mi></msub><mo id="A5.Ex3.m2.1.1.1.2" xref="A5.Ex3.m2.1.1.1.2.cmml">â¢</mo><msub id="A5.Ex3.m2.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.cmml"><mrow id="A5.Ex3.m2.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.2.cmml"><mo id="A5.Ex3.m2.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.3.cmml">Î³</mi><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">Ï•</mi><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex3.m2.1.1.1.1.1.1.1.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><msub id="A5.Ex3.m2.1.1.1.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.3.2" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex3.m2.1.1.1.1.1.1.1.3.3" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="A5.Ex3.m2.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex3.m2.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="A5.Ex3.m2.1.1.1.1.3" xref="A5.Ex3.m2.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex3.m2.1b"><apply id="A5.Ex3.m2.1.1.cmml" xref="A5.Ex3.m2.1.1"><eq id="A5.Ex3.m2.1.1.2.cmml" xref="A5.Ex3.m2.1.1.2"></eq><csymbol cd="latexml" id="A5.Ex3.m2.1.1.3.cmml" xref="A5.Ex3.m2.1.1.3">absent</csymbol><apply id="A5.Ex3.m2.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1"><times id="A5.Ex3.m2.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.2"></times><apply id="A5.Ex3.m2.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.3.1.cmml" xref="A5.Ex3.m2.1.1.1.3">subscript</csymbol><ci id="A5.Ex3.m2.1.1.1.3.2a.cmml" xref="A5.Ex3.m2.1.1.1.3.2"><mtext id="A5.Ex3.m2.1.1.1.3.2.cmml" xref="A5.Ex3.m2.1.1.1.3.2">argmin</mtext></ci><ci id="A5.Ex3.m2.1.1.1.3.3.cmml" xref="A5.Ex3.m2.1.1.1.3.3">ğ›¾</ci></apply><apply id="A5.Ex3.m2.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1">subscript</csymbol><apply id="A5.Ex3.m2.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex3.m2.1.1.1.1.1.2.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.2">norm</csymbol><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1"><minus id="A5.Ex3.m2.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.2"></minus><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1"><times id="A5.Ex3.m2.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.2"></times><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.3">ğ›¾</ci><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.3">italic-Ï•</ci><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><apply id="A5.Ex3.m2.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex3.m2.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.2">ğ‘”</ci><ci id="A5.Ex3.m2.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex3.m2.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn id="A5.Ex3.m2.1.1.1.1.3.cmml" type="integer" xref="A5.Ex3.m2.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex3.m2.1c">\displaystyle=\text{argmin}_{\gamma}\parallel\gamma(\phi(x_{i}))-g_{i}%
\parallel_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.Ex3.m2.1d">= argmin start_POSTSUBSCRIPT italic_Î³ end_POSTSUBSCRIPT âˆ¥ italic_Î³ ( italic_Ï• ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) - italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ¥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A5.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\text{media}(g_{i}|\phi(x_{i}))," class="ltx_Math" display="inline" id="A5.Ex4.m1.1"><semantics id="A5.Ex4.m1.1a"><mrow id="A5.Ex4.m1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.cmml"><mrow id="A5.Ex4.m1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.3.cmml"></mi><mo id="A5.Ex4.m1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.2.cmml">=</mo><mrow id="A5.Ex4.m1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.cmml"><mtext id="A5.Ex4.m1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.3a.cmml">media</mtext><mo id="A5.Ex4.m1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml"><msub id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml">Ï•</mi><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex4.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex4.m1.1.1.1.2" xref="A5.Ex4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex4.m1.1b"><apply id="A5.Ex4.m1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1"><eq id="A5.Ex4.m1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.2"></eq><csymbol cd="latexml" id="A5.Ex4.m1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.3">absent</csymbol><apply id="A5.Ex4.m1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1"><times id="A5.Ex4.m1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.2"></times><ci id="A5.Ex4.m1.1.1.1.1.1.3a.cmml" xref="A5.Ex4.m1.1.1.1.1.1.3"><mtext id="A5.Ex4.m1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.3">media</mtext></ci><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.2">ğ‘”</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.2"></times><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.3">italic-Ï•</ci><apply id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex4.m1.1c">\displaystyle=\text{media}(g_{i}|\phi(x_{i})),</annotation><annotation encoding="application/x-llamapun" id="A5.Ex4.m1.1d">= media ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_Ï• ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p3">
<p class="ltx_p" id="A5.SS1.p3.1">Substituting this expression for the optimal predictor into the loss function and evaluating the expected gradient of the encoder gives</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p4">
<table class="ltx_equation ltx_eqn_table" id="A5.Ex5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\nabla_{\theta}\mathbb{E}\parallel\gamma^{\star}(\phi_{\theta}(x_{i}))-g_{i}%
\parallel_{1}=\nabla_{\theta}\text{MAD}(g_{i}|\phi_{\theta}(x_{i}))," class="ltx_Math" display="block" id="A5.Ex5.m1.1"><semantics id="A5.Ex5.m1.1a"><mrow id="A5.Ex5.m1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.2.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.2.2" xref="A5.Ex5.m1.1.1.1.1.1.2.2.cmml">âˆ‡</mo><mi id="A5.Ex5.m1.1.1.1.1.1.2.3" xref="A5.Ex5.m1.1.1.1.1.1.2.3.cmml">Î¸</mi></msub><mrow id="A5.Ex5.m1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.3.cmml">ğ”¼</mi><mo id="A5.Ex5.m1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.2.cmml">â¢</mo><msub id="A5.Ex5.m1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msup id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">Î³</mi><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">â‹†</mo></msup><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">Ï•</mi><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><msub id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="A5.Ex5.m1.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.1.1.1.3.cmml">1</mn></msub></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.3.cmml">=</mo><mrow id="A5.Ex5.m1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.cmml"><mrow id="A5.Ex5.m1.1.1.1.1.2.3" xref="A5.Ex5.m1.1.1.1.1.2.3.cmml"><msub id="A5.Ex5.m1.1.1.1.1.2.3.1" xref="A5.Ex5.m1.1.1.1.1.2.3.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.2.3.1.2" rspace="0.167em" xref="A5.Ex5.m1.1.1.1.1.2.3.1.2.cmml">âˆ‡</mo><mi id="A5.Ex5.m1.1.1.1.1.2.3.1.3" xref="A5.Ex5.m1.1.1.1.1.2.3.1.3.cmml">Î¸</mi></msub><mtext id="A5.Ex5.m1.1.1.1.1.2.3.2" xref="A5.Ex5.m1.1.1.1.1.2.3.2a.cmml">MAD</mtext></mrow><mo id="A5.Ex5.m1.1.1.1.1.2.2" xref="A5.Ex5.m1.1.1.1.1.2.2.cmml">â¢</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml">(</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2.cmml">g</mi><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3.cmml">i</mi></msub><mo fence="false" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.2.cmml">|</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.cmml"><msub id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.cmml"><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2.cmml">Ï•</mi><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2.cmml">â¢</mo><mrow id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml"><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.2" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml">(</mo><msub id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.1.2.1.1.3" stretchy="false" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="A5.Ex5.m1.1.1.1.2" xref="A5.Ex5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.Ex5.m1.1b"><apply id="A5.Ex5.m1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1"><eq id="A5.Ex5.m1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.3"></eq><apply id="A5.Ex5.m1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1"><apply id="A5.Ex5.m1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.2.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.2.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2.2">âˆ‡</ci><ci id="A5.Ex5.m1.1.1.1.1.1.2.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.2.3">ğœƒ</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.2"></times><ci id="A5.Ex5.m1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.3">ğ”¼</ci><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1"><minus id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.2"></minus><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ›¾</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.3.3">â‹†</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">italic-Ï•</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply><apply id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘”</ci><ci id="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><cn id="A5.Ex5.m1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="A5.Ex5.m1.1.1.1.1.1.1.1.3">1</cn></apply></apply></apply><apply id="A5.Ex5.m1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2"><times id="A5.Ex5.m1.1.1.1.1.2.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.2"></times><apply id="A5.Ex5.m1.1.1.1.1.2.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3"><apply id="A5.Ex5.m1.1.1.1.1.2.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.3.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.3.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1.2">âˆ‡</ci><ci id="A5.Ex5.m1.1.1.1.1.2.3.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.1.3">ğœƒ</ci></apply><ci id="A5.Ex5.m1.1.1.1.1.2.3.2a.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.2"><mtext id="A5.Ex5.m1.1.1.1.1.2.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.3.2">MAD</mtext></ci></apply><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1"><csymbol cd="latexml" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.2">conditional</csymbol><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.2">ğ‘”</ci><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.3.3">ğ‘–</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1"><times id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.2"></times><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.2">italic-Ï•</ci><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1">subscript</csymbol><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml" xref="A5.Ex5.m1.1.1.1.1.2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.Ex5.m1.1c">\nabla_{\theta}\mathbb{E}\parallel\gamma^{\star}(\phi_{\theta}(x_{i}))-g_{i}%
\parallel_{1}=\nabla_{\theta}\text{MAD}(g_{i}|\phi_{\theta}(x_{i})),</annotation><annotation encoding="application/x-llamapun" id="A5.Ex5.m1.1d">âˆ‡ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT blackboard_E âˆ¥ italic_Î³ start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ( italic_Ï• start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) - italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ¥ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = âˆ‡ start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT MAD ( italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_Ï• start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS1.p5">
<p class="ltx_p" id="A5.SS1.p5.3">where <math alttext="\text{MAD}(\cdot|\phi_{\theta}(x_{i}))" class="ltx_math_unparsed" display="inline" id="A5.SS1.p5.1.m1.1"><semantics id="A5.SS1.p5.1.m1.1a"><mrow id="A5.SS1.p5.1.m1.1b"><mtext id="A5.SS1.p5.1.m1.1.1">MAD</mtext><mrow id="A5.SS1.p5.1.m1.1.2"><mo id="A5.SS1.p5.1.m1.1.2.1" stretchy="false">(</mo><mo id="A5.SS1.p5.1.m1.1.2.2" lspace="0em" rspace="0em">â‹…</mo><mo fence="false" id="A5.SS1.p5.1.m1.1.2.3" rspace="0.167em" stretchy="false">|</mo><msub id="A5.SS1.p5.1.m1.1.2.4"><mi id="A5.SS1.p5.1.m1.1.2.4.2">Ï•</mi><mi id="A5.SS1.p5.1.m1.1.2.4.3">Î¸</mi></msub><mrow id="A5.SS1.p5.1.m1.1.2.5"><mo id="A5.SS1.p5.1.m1.1.2.5.1" stretchy="false">(</mo><msub id="A5.SS1.p5.1.m1.1.2.5.2"><mi id="A5.SS1.p5.1.m1.1.2.5.2.2">x</mi><mi id="A5.SS1.p5.1.m1.1.2.5.2.3">i</mi></msub><mo id="A5.SS1.p5.1.m1.1.2.5.3" stretchy="false">)</mo></mrow><mo id="A5.SS1.p5.1.m1.1.2.6" stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="A5.SS1.p5.1.m1.1c">\text{MAD}(\cdot|\phi_{\theta}(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p5.1.m1.1d">MAD ( â‹… | italic_Ï• start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math> is the median absolute deviation of a random variable conditioned on <math alttext="\phi_{\theta}(x_{i})" class="ltx_Math" display="inline" id="A5.SS1.p5.2.m2.1"><semantics id="A5.SS1.p5.2.m2.1a"><mrow id="A5.SS1.p5.2.m2.1.1" xref="A5.SS1.p5.2.m2.1.1.cmml"><msub id="A5.SS1.p5.2.m2.1.1.3" xref="A5.SS1.p5.2.m2.1.1.3.cmml"><mi id="A5.SS1.p5.2.m2.1.1.3.2" xref="A5.SS1.p5.2.m2.1.1.3.2.cmml">Ï•</mi><mi id="A5.SS1.p5.2.m2.1.1.3.3" xref="A5.SS1.p5.2.m2.1.1.3.3.cmml">Î¸</mi></msub><mo id="A5.SS1.p5.2.m2.1.1.2" xref="A5.SS1.p5.2.m2.1.1.2.cmml">â¢</mo><mrow id="A5.SS1.p5.2.m2.1.1.1.1" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml"><mo id="A5.SS1.p5.2.m2.1.1.1.1.2" stretchy="false" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml">(</mo><msub id="A5.SS1.p5.2.m2.1.1.1.1.1" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml"><mi id="A5.SS1.p5.2.m2.1.1.1.1.1.2" xref="A5.SS1.p5.2.m2.1.1.1.1.1.2.cmml">x</mi><mi id="A5.SS1.p5.2.m2.1.1.1.1.1.3" xref="A5.SS1.p5.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A5.SS1.p5.2.m2.1.1.1.1.3" stretchy="false" xref="A5.SS1.p5.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A5.SS1.p5.2.m2.1b"><apply id="A5.SS1.p5.2.m2.1.1.cmml" xref="A5.SS1.p5.2.m2.1.1"><times id="A5.SS1.p5.2.m2.1.1.2.cmml" xref="A5.SS1.p5.2.m2.1.1.2"></times><apply id="A5.SS1.p5.2.m2.1.1.3.cmml" xref="A5.SS1.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="A5.SS1.p5.2.m2.1.1.3.1.cmml" xref="A5.SS1.p5.2.m2.1.1.3">subscript</csymbol><ci id="A5.SS1.p5.2.m2.1.1.3.2.cmml" xref="A5.SS1.p5.2.m2.1.1.3.2">italic-Ï•</ci><ci id="A5.SS1.p5.2.m2.1.1.3.3.cmml" xref="A5.SS1.p5.2.m2.1.1.3.3">ğœƒ</ci></apply><apply id="A5.SS1.p5.2.m2.1.1.1.1.1.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="A5.SS1.p5.2.m2.1.1.1.1.1.1.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1">subscript</csymbol><ci id="A5.SS1.p5.2.m2.1.1.1.1.1.2.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1.1.2">ğ‘¥</ci><ci id="A5.SS1.p5.2.m2.1.1.1.1.1.3.cmml" xref="A5.SS1.p5.2.m2.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p5.2.m2.1c">\phi_{\theta}(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p5.2.m2.1d">italic_Ï• start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>. Thus, in the case where the predictor is optimal, the encoder must learn to capture as much information about the video as possible to minimize the deviation of the target. The hypothesis is that incorporating an exponential moving average to compute the representation of <math alttext="y_{i}" class="ltx_Math" display="inline" id="A5.SS1.p5.3.m3.1"><semantics id="A5.SS1.p5.3.m3.1a"><msub id="A5.SS1.p5.3.m3.1.1" xref="A5.SS1.p5.3.m3.1.1.cmml"><mi id="A5.SS1.p5.3.m3.1.1.2" xref="A5.SS1.p5.3.m3.1.1.2.cmml">y</mi><mi id="A5.SS1.p5.3.m3.1.1.3" xref="A5.SS1.p5.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A5.SS1.p5.3.m3.1b"><apply id="A5.SS1.p5.3.m3.1.1.cmml" xref="A5.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="A5.SS1.p5.3.m3.1.1.1.cmml" xref="A5.SS1.p5.3.m3.1.1">subscript</csymbol><ci id="A5.SS1.p5.3.m3.1.1.2.cmml" xref="A5.SS1.p5.3.m3.1.1.2">ğ‘¦</ci><ci id="A5.SS1.p5.3.m3.1.1.3.cmml" xref="A5.SS1.p5.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p5.3.m3.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p5.3.m3.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> ensures that the predictor evolves faster than the encoder and remains close to optimal, thereby preventing collapse.</p>
</div>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Image classification</h3>
<div class="ltx_para ltx_noindent" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">D-JEPA, a generative model built on the foundation of JEPAÂ <cite class="ltx_cite ltx_citemacro_cite">LeCun (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib62" title="">2022</a>)</cite>, inherits the exceptional representation capabilities of JEPA. This intrinsic quality positions D-JEPA as a potentially superior source of pre-training weights for downstream tasks compared to other generative models. To rigorously affirm this hypothesis, we conducted extensive evaluations on two prevalent ImageNet classification tasks: linear probing and fine-tuning.</p>
</div>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Experiment settings.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px1.p1.1">We use the context encoder <math alttext="\phi" class="ltx_Math" display="inline" id="A5.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="A5.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="A5.SS2.SSS0.Px1.p1.1.m1.1.1" xref="A5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="A5.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="A5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A5.SS2.SSS0.Px1.p1.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.SSS0.Px1.p1.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.SSS0.Px1.p1.1.m1.1d">italic_Ï•</annotation></semantics></math> as the pre-trained model for all downstream tasks, following the approach reported by Â <cite class="ltx_cite ltx_citemacro_cite">Assran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, demonstrating better performance. For representation learning, we globally average pool the output of the feature by the context encoder and use these pooled features as input for the classification head, in alignment with the methodologies described in Â <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite> and Â <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="A5.SS2.SSS0.Px1.p2.1">We conducted experiments in both the raw pixel space and the continuous token space. The primary distinction between these two experiments is whether a VAE is utilized to encode the images. For the former, we fully retain the experimental setup of I-JEPAÂ <cite class="ltx_cite ltx_citemacro_cite">Assran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>, while for the latter, the training settings are entirely retained from MAGEÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px1.p3">
<p class="ltx_p" id="A5.SS2.SSS0.Px1.p3.1">To ensure a fair comparison, for D-JEPA-B, we use the checkpoint saved at 600 epochs for the related experiments, and for D-JEPA-L, we use the checkpoint saved at 300 epochs, consistent with the practices in Â <cite class="ltx_cite ltx_citemacro_cite">Assran etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>.</p>
</div>
<figure class="ltx_table" id="A5.T7">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T7.1.tab1" style="width:260.2pt;">
<table class="ltx_tabular ltx_align_middle" id="A5.T7.1.tab1.1">
<tr class="ltx_tr" id="A5.T7.1.tab1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.1.1">Method</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.1.2">Model</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.1.3">#Params</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.1.4">Acc.</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.2" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="4" id="A5.T7.1.tab1.1.2.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.2.1.1" style="background-color:#EFEFEF;">Gemerative models</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.3.1">BigBiGANÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib27" title="">2019</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.3.2">RN50</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.3.3">23M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.3.4">56.6</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.4.1">MaskGITÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib16" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.4.2">BERT</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.4.3">227M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.4.4">57.4</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.5.1">ViT-VQGANÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.5.2">VIM-Base</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.5.3">650M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.5.4">65.1</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.6.1">ViT-VQGANÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib116" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.6.2">VIM-Large</td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.6.3">1697M</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.6.4">73.2</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.7" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.7.1"><span class="ltx_text" id="A5.T7.1.tab1.1.7.1.1" style="background-color:#ECF4FF;">D-JEPAÂ (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.7.1.1.1" style="background-color:#ECF4FF;">token space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.7.2"><span class="ltx_text" id="A5.T7.1.tab1.1.7.2.1" style="background-color:#ECF4FF;">ViT-B</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.7.3"><span class="ltx_text" id="A5.T7.1.tab1.1.7.3.1" style="background-color:#ECF4FF;">86M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.7.4"><span class="ltx_text" id="A5.T7.1.tab1.1.7.4.1" style="background-color:#ECF4FF;">46.8</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.8" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.8.1"><span class="ltx_text" id="A5.T7.1.tab1.1.8.1.1" style="background-color:#ECF4FF;">D-JEPAÂ (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.8.1.1.1" style="background-color:#ECF4FF;">token space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.8.2"><span class="ltx_text" id="A5.T7.1.tab1.1.8.2.1" style="background-color:#ECF4FF;">ViT-L</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.8.3"><span class="ltx_text" id="A5.T7.1.tab1.1.8.3.1" style="background-color:#ECF4FF;">304M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.8.4"><span class="ltx_text" id="A5.T7.1.tab1.1.8.4.1" style="background-color:#ECF4FF;">47.6</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.9" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.9.1"><span class="ltx_text" id="A5.T7.1.tab1.1.9.1.1" style="background-color:#ECF4FF;">D-JEPAÂ (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.9.1.1.1" style="background-color:#ECF4FF;">pixel space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.9.2"><span class="ltx_text" id="A5.T7.1.tab1.1.9.2.1" style="background-color:#ECF4FF;">ViT-B</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.9.3"><span class="ltx_text" id="A5.T7.1.tab1.1.9.3.1" style="background-color:#ECF4FF;">86M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.9.4"><span class="ltx_text" id="A5.T7.1.tab1.1.9.4.1" style="background-color:#ECF4FF;">73.1</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.tab1.1.10" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.1.tab1.1.10.1"><span class="ltx_text" id="A5.T7.1.tab1.1.10.1.1" style="background-color:#ECF4FF;">D-JEPAÂ (<span class="ltx_text ltx_font_italic" id="A5.T7.1.tab1.1.10.1.1.1" style="background-color:#ECF4FF;">pixel space</span>)</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.10.2"><span class="ltx_text" id="A5.T7.1.tab1.1.10.2.1" style="background-color:#ECF4FF;">ViT-L</span></td>
<td class="ltx_td ltx_align_left" id="A5.T7.1.tab1.1.10.3"><span class="ltx_text" id="A5.T7.1.tab1.1.10.3.1" style="background-color:#ECF4FF;">304M</span></td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.tab1.1.10.4"><span class="ltx_text" id="A5.T7.1.tab1.1.10.4.1" style="background-color:#ECF4FF;">77.9</span></td>
</tr>
</table>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="A5.T7.2.tab1" style="width:169.1pt;">
<table class="ltx_tabular ltx_align_middle" id="A5.T7.2.tab1.1">
<tr class="ltx_tr" id="A5.T7.2.tab1.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.1.1">Method</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.1.2">ViT-B</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.1.3">ViT-L</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.2">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T7.2.tab1.1.2.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T7.2.tab1.1.2.1.1" style="background-color:#EFEFEF;">Representation models</span></td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.3.1">data2vecÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib6" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.3.2">-</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.3.3">77.3</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.4.1">I-JEPAÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib4" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.4.2">72.9</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.4.3">77.5</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.5.1">MAEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.5.2">68.0</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.5.3">76.0</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.6.1">CAEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib21" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.6.2">70.4</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.6.3">78.1</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.7.1">CMAEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib50" title="">2023b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.7.2">73.9</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.7.3">-</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.8.1">MAGEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.8.2">74.7</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.8.3">78.9</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.9.1">MoCo v3Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib23" title="">2021b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.9.2">76.7</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.9.3">77.6</td>
</tr>
<tr class="ltx_tr" id="A5.T7.2.tab1.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T7.2.tab1.1.10.1">DINOÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib127" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.10.2">72.8</td>
<td class="ltx_td ltx_align_center" id="A5.T7.2.tab1.1.10.3">-</td>
</tr>
</table>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Top-1 accuracy of linear probing on ImageNet-1K. For reference, we also list the performance of other state-of-the-art representation models as well.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Linear probing.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px2.p1.1">Linear probing is a primary evaluation protocol for self-supervised learning. As shown in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T7" title="Table 7 â€£ Experiment settings. â€£ E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a>, D-JEPA, trained directly on raw pixels, surpasses all generative models in ImageNet-1K linear probe top-1 accuracy, achieving state-of-the-art results. Furthermore, when compared with representation models, D-JEPA remains remarkably competitive.</p>
</div>
<figure class="ltx_table" id="A5.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Fine-tuning performance on ImageNet-1K. We report the top-1 accuracy improvement over training from scratch for different methods (other numbers are taken from the respective papers). The ViT models trained from scratch on semantic tokens follow the exact same training settings as the ViT models trained from scratch on original image pixels in <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>. It is worth noting that ViT-Lâ€™s performance is slightly lower than ViT-Bâ€™s when trained from scratch on continuous tokens, likely due to only 50 epochs of training. However, we used this setting to ensure a fair comparison with other methods.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="A5.T8.1">
<tr class="ltx_tr" id="A5.T8.1.1">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.1.1">Method</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.2">ViT-B</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3">ViT-L</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.2" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T8.1.2.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T8.1.2.1.1" style="background-color:#EFEFEF;">Patchify on raw pixels</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.3.1">Scratch</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.3.2">82.3</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.3.3">82.6</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.4.1">DINOÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib15" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.4.2">+0.5</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.4.3">-</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.5.1">MoCo v3Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib23" title="">2021b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.5.2">+0.9</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.5.3">+1.5</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.6.1">BEiTÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib8" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.6.2">+0.9</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.6.3">+2.6</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.7.1">MAEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib44" title="">2022a</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.7.2">+1.3</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.7.3">+3.3</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.8.1">CAEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib21" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.8.2">+1.6</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.8.3">+3.7</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.9">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.9.1">MVPÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib111" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.9.2">+2.1</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.9.3">+3.7</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.10.1">PeCoÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib28" title="">2021</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.10.2"><span class="ltx_text ltx_font_bold" id="A5.T8.1.10.2.1">+2.2</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.10.3"><span class="ltx_text ltx_font_bold" id="A5.T8.1.10.3.1">+3.9</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.11" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.11.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A5.T8.1.11.1.1" style="background-color:#ECF4FF;">D-JEPA</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.11.2"><span class="ltx_text" id="A5.T8.1.11.2.1" style="background-color:#ECF4FF;">+2.0</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.11.3"><span class="ltx_text" id="A5.T8.1.11.3.1" style="background-color:#ECF4FF;">+3.2</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.12" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T8.1.12.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T8.1.12.1.1" style="background-color:#EFEFEF;">Patchify on vector-quantinized tokens</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.13">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.13.1">Scratch</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.13.2">80.7</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.13.3">80.9</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.14.1">MAGEÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.14.2">+1.8</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.14.3">+3.0</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.15">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.15.1">MAGE-CÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.15.2"><span class="ltx_text ltx_font_bold" id="A5.T8.1.15.2.1">+2.2</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.15.3">+3.4</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.16" style="background-color:#EFEFEF;">
<td class="ltx_td ltx_align_left" colspan="3" id="A5.T8.1.16.1" style="background-color:#EFEFEF;"><span class="ltx_text ltx_font_italic" id="A5.T8.1.16.1.1" style="background-color:#EFEFEF;">Patchify on continuous tokens</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.17">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.17.1">Scratch</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.17.2">79.1</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.17.3">78.7</td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.18" style="background-color:#ECF4FF;">
<td class="ltx_td ltx_align_left ltx_border_r" id="A5.T8.1.18.1" style="background-color:#ECF4FF;"><span class="ltx_text" id="A5.T8.1.18.1.1" style="background-color:#ECF4FF;">D-JEPA</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.18.2"><span class="ltx_text" id="A5.T8.1.18.2.1" style="background-color:#ECF4FF;">+1.6</span></td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.18.3"><span class="ltx_text" id="A5.T8.1.18.3.1" style="background-color:#ECF4FF;">+2.9</span></td>
</tr>
</table>
</figure>
</section>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Fine-tuning.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px3.p1.1">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T8" title="Table 8 â€£ Linear probing. â€£ E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a> displays the fine-tuning performance of D-JEPA and other self-supervised learning methods, where all the pre-trained encoder parameters are fine-tuned. It is important to note that directly comparing the final performance of these various methods is inappropriate due to their different data-pacifying approaches. Nonetheless, we can compare their performance improvements relative to training-from-scratch models. The results presented in the tables show that D-JEPA demonstrates strong competitiveness as a representation model. Although its ultimate performance does not surpass that of methods operating in raw space, we observe a substantial performance enhancement compared to training from scratch.</p>
</div>
</section>
<section class="ltx_paragraph" id="A5.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Analysis on raw pixel space and semantic token space.</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="A5.SS2.SSS0.Px4.p1.1">Although the D-JEPA model trained in the continuous token space has demonstrated impressive performance on generative tasks, an analysis of the results in Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T7" title="Table 7 â€£ Experiment settings. â€£ E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a> and Tab.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A5.T8" title="Table 8 â€£ Linear probing. â€£ E.2 Image classification â€£ Appendix E D-JEPA for representation learning â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">8</span></a> reveals that directly training D-JEPA in the pixel space significantly outperforms training in the token space, particularly in linear probing tasks. We attribute this suboptimal performance in both from-scratch and fine-tuning scenarios to using VAE, as discussed in <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib65" title="">2023</a>)</cite>. Expressly, the training process of VAEs typically excludes complex image preprocessing techniques such as mixupÂ <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib125" title="">2017b</a>)</cite>, which impairs the VAEâ€™s ability to effectively encode preprocessed images for classification tasks, thereby resulting in a performance deficit. We are optimistic that retraining the VAE with these advanced preprocessing techniques will address this issue and yield improved results.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Flow Matching Loss</h2>
<div class="ltx_para ltx_noindent" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">In this section, we transition from the Gaussian denoising setting as described in <cite class="ltx_cite ltx_citemacro_cite">Ho etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite> to the flow matching formulation <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib70" title="">2024a</a>; Mo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib74" title="">2024</a>; Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>, thereby providing additional flexibility to D-JEPA. We adhere to the formulation presented in <cite class="ltx_cite ltx_citemacro_cite">Zhuo etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite> and reformulate it for modeling token distribution.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p2">
<p class="ltx_p" id="A6.p2.2">The schedule that defines how to corrupt data to noise significantly impacts the training and sampling of standard diffusion models. Consequently, numerous diffusion schedules, such as VEÂ <cite class="ltx_cite ltx_citemacro_citep">(Song etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib97" title="">2021</a>)</cite>, VPÂ <cite class="ltx_cite ltx_citemacro_citep">(Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib47" title="">2020</a>)</cite>, and EDMÂ <cite class="ltx_cite ltx_citemacro_citep">(Karras etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib53" title="">2022</a>)</cite>, have been carefully designed and utilized. In contrast, flow matchingÂ <cite class="ltx_cite ltx_citemacro_citep">(Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>; Albergo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib1" title="">2023</a>)</cite> emerges as a simple alternative that linearly interpolates between noise and data along a straight line. More specifically, given the data <math alttext="x_{i}\sim p(x_{i})" class="ltx_Math" display="inline" id="A6.p2.1.m1.1"><semantics id="A6.p2.1.m1.1a"><mrow id="A6.p2.1.m1.1.1" xref="A6.p2.1.m1.1.1.cmml"><msub id="A6.p2.1.m1.1.1.3" xref="A6.p2.1.m1.1.1.3.cmml"><mi id="A6.p2.1.m1.1.1.3.2" xref="A6.p2.1.m1.1.1.3.2.cmml">x</mi><mi id="A6.p2.1.m1.1.1.3.3" xref="A6.p2.1.m1.1.1.3.3.cmml">i</mi></msub><mo id="A6.p2.1.m1.1.1.2" xref="A6.p2.1.m1.1.1.2.cmml">âˆ¼</mo><mrow id="A6.p2.1.m1.1.1.1" xref="A6.p2.1.m1.1.1.1.cmml"><mi id="A6.p2.1.m1.1.1.1.3" xref="A6.p2.1.m1.1.1.1.3.cmml">p</mi><mo id="A6.p2.1.m1.1.1.1.2" xref="A6.p2.1.m1.1.1.1.2.cmml">â¢</mo><mrow id="A6.p2.1.m1.1.1.1.1.1" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml"><mo id="A6.p2.1.m1.1.1.1.1.1.2" stretchy="false" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="A6.p2.1.m1.1.1.1.1.1.1" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="A6.p2.1.m1.1.1.1.1.1.1.2" xref="A6.p2.1.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="A6.p2.1.m1.1.1.1.1.1.1.3" xref="A6.p2.1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A6.p2.1.m1.1.1.1.1.1.3" stretchy="false" xref="A6.p2.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p2.1.m1.1b"><apply id="A6.p2.1.m1.1.1.cmml" xref="A6.p2.1.m1.1.1"><csymbol cd="latexml" id="A6.p2.1.m1.1.1.2.cmml" xref="A6.p2.1.m1.1.1.2">similar-to</csymbol><apply id="A6.p2.1.m1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="A6.p2.1.m1.1.1.3.1.cmml" xref="A6.p2.1.m1.1.1.3">subscript</csymbol><ci id="A6.p2.1.m1.1.1.3.2.cmml" xref="A6.p2.1.m1.1.1.3.2">ğ‘¥</ci><ci id="A6.p2.1.m1.1.1.3.3.cmml" xref="A6.p2.1.m1.1.1.3.3">ğ‘–</ci></apply><apply id="A6.p2.1.m1.1.1.1.cmml" xref="A6.p2.1.m1.1.1.1"><times id="A6.p2.1.m1.1.1.1.2.cmml" xref="A6.p2.1.m1.1.1.1.2"></times><ci id="A6.p2.1.m1.1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.1.3">ğ‘</ci><apply id="A6.p2.1.m1.1.1.1.1.1.1.cmml" xref="A6.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="A6.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="A6.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="A6.p2.1.m1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A6.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="A6.p2.1.m1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.1.m1.1c">x_{i}\sim p(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A6.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ¼ italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> and Gaussian noise <math alttext="\epsilon\sim\mathcal{N}(0,I)" class="ltx_Math" display="inline" id="A6.p2.2.m2.2"><semantics id="A6.p2.2.m2.2a"><mrow id="A6.p2.2.m2.2.3" xref="A6.p2.2.m2.2.3.cmml"><mi id="A6.p2.2.m2.2.3.2" xref="A6.p2.2.m2.2.3.2.cmml">Ïµ</mi><mo id="A6.p2.2.m2.2.3.1" xref="A6.p2.2.m2.2.3.1.cmml">âˆ¼</mo><mrow id="A6.p2.2.m2.2.3.3" xref="A6.p2.2.m2.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A6.p2.2.m2.2.3.3.2" xref="A6.p2.2.m2.2.3.3.2.cmml">ğ’©</mi><mo id="A6.p2.2.m2.2.3.3.1" xref="A6.p2.2.m2.2.3.3.1.cmml">â¢</mo><mrow id="A6.p2.2.m2.2.3.3.3.2" xref="A6.p2.2.m2.2.3.3.3.1.cmml"><mo id="A6.p2.2.m2.2.3.3.3.2.1" stretchy="false" xref="A6.p2.2.m2.2.3.3.3.1.cmml">(</mo><mn id="A6.p2.2.m2.1.1" xref="A6.p2.2.m2.1.1.cmml">0</mn><mo id="A6.p2.2.m2.2.3.3.3.2.2" xref="A6.p2.2.m2.2.3.3.3.1.cmml">,</mo><mi id="A6.p2.2.m2.2.2" xref="A6.p2.2.m2.2.2.cmml">I</mi><mo id="A6.p2.2.m2.2.3.3.3.2.3" stretchy="false" xref="A6.p2.2.m2.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p2.2.m2.2b"><apply id="A6.p2.2.m2.2.3.cmml" xref="A6.p2.2.m2.2.3"><csymbol cd="latexml" id="A6.p2.2.m2.2.3.1.cmml" xref="A6.p2.2.m2.2.3.1">similar-to</csymbol><ci id="A6.p2.2.m2.2.3.2.cmml" xref="A6.p2.2.m2.2.3.2">italic-Ïµ</ci><apply id="A6.p2.2.m2.2.3.3.cmml" xref="A6.p2.2.m2.2.3.3"><times id="A6.p2.2.m2.2.3.3.1.cmml" xref="A6.p2.2.m2.2.3.3.1"></times><ci id="A6.p2.2.m2.2.3.3.2.cmml" xref="A6.p2.2.m2.2.3.3.2">ğ’©</ci><interval closure="open" id="A6.p2.2.m2.2.3.3.3.1.cmml" xref="A6.p2.2.m2.2.3.3.3.2"><cn id="A6.p2.2.m2.1.1.cmml" type="integer" xref="A6.p2.2.m2.1.1">0</cn><ci id="A6.p2.2.m2.2.2.cmml" xref="A6.p2.2.m2.2.2">ğ¼</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.2.m2.2c">\epsilon\sim\mathcal{N}(0,I)</annotation><annotation encoding="application/x-llamapun" id="A6.p2.2.m2.2d">italic_Ïµ âˆ¼ caligraphic_N ( 0 , italic_I )</annotation></semantics></math>, we define an interpolation-based forward process:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p3">
<table class="ltx_equation ltx_eqn_table" id="A6.Ex6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x_{i}^{t}=\alpha_{t}x_{i}+\beta_{t}\epsilon," class="ltx_Math" display="block" id="A6.Ex6.m1.1"><semantics id="A6.Ex6.m1.1a"><mrow id="A6.Ex6.m1.1.1.1" xref="A6.Ex6.m1.1.1.1.1.cmml"><mrow id="A6.Ex6.m1.1.1.1.1" xref="A6.Ex6.m1.1.1.1.1.cmml"><msubsup id="A6.Ex6.m1.1.1.1.1.2" xref="A6.Ex6.m1.1.1.1.1.2.cmml"><mi id="A6.Ex6.m1.1.1.1.1.2.2.2" xref="A6.Ex6.m1.1.1.1.1.2.2.2.cmml">x</mi><mi id="A6.Ex6.m1.1.1.1.1.2.2.3" xref="A6.Ex6.m1.1.1.1.1.2.2.3.cmml">i</mi><mi id="A6.Ex6.m1.1.1.1.1.2.3" xref="A6.Ex6.m1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="A6.Ex6.m1.1.1.1.1.1" xref="A6.Ex6.m1.1.1.1.1.1.cmml">=</mo><mrow id="A6.Ex6.m1.1.1.1.1.3" xref="A6.Ex6.m1.1.1.1.1.3.cmml"><mrow id="A6.Ex6.m1.1.1.1.1.3.2" xref="A6.Ex6.m1.1.1.1.1.3.2.cmml"><msub id="A6.Ex6.m1.1.1.1.1.3.2.2" xref="A6.Ex6.m1.1.1.1.1.3.2.2.cmml"><mi id="A6.Ex6.m1.1.1.1.1.3.2.2.2" xref="A6.Ex6.m1.1.1.1.1.3.2.2.2.cmml">Î±</mi><mi id="A6.Ex6.m1.1.1.1.1.3.2.2.3" xref="A6.Ex6.m1.1.1.1.1.3.2.2.3.cmml">t</mi></msub><mo id="A6.Ex6.m1.1.1.1.1.3.2.1" xref="A6.Ex6.m1.1.1.1.1.3.2.1.cmml">â¢</mo><msub id="A6.Ex6.m1.1.1.1.1.3.2.3" xref="A6.Ex6.m1.1.1.1.1.3.2.3.cmml"><mi id="A6.Ex6.m1.1.1.1.1.3.2.3.2" xref="A6.Ex6.m1.1.1.1.1.3.2.3.2.cmml">x</mi><mi id="A6.Ex6.m1.1.1.1.1.3.2.3.3" xref="A6.Ex6.m1.1.1.1.1.3.2.3.3.cmml">i</mi></msub></mrow><mo id="A6.Ex6.m1.1.1.1.1.3.1" xref="A6.Ex6.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="A6.Ex6.m1.1.1.1.1.3.3" xref="A6.Ex6.m1.1.1.1.1.3.3.cmml"><msub id="A6.Ex6.m1.1.1.1.1.3.3.2" xref="A6.Ex6.m1.1.1.1.1.3.3.2.cmml"><mi id="A6.Ex6.m1.1.1.1.1.3.3.2.2" xref="A6.Ex6.m1.1.1.1.1.3.3.2.2.cmml">Î²</mi><mi id="A6.Ex6.m1.1.1.1.1.3.3.2.3" xref="A6.Ex6.m1.1.1.1.1.3.3.2.3.cmml">t</mi></msub><mo id="A6.Ex6.m1.1.1.1.1.3.3.1" xref="A6.Ex6.m1.1.1.1.1.3.3.1.cmml">â¢</mo><mi id="A6.Ex6.m1.1.1.1.1.3.3.3" xref="A6.Ex6.m1.1.1.1.1.3.3.3.cmml">Ïµ</mi></mrow></mrow></mrow><mo id="A6.Ex6.m1.1.1.1.2" xref="A6.Ex6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex6.m1.1b"><apply id="A6.Ex6.m1.1.1.1.1.cmml" xref="A6.Ex6.m1.1.1.1"><eq id="A6.Ex6.m1.1.1.1.1.1.cmml" xref="A6.Ex6.m1.1.1.1.1.1"></eq><apply id="A6.Ex6.m1.1.1.1.1.2.cmml" xref="A6.Ex6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.2">superscript</csymbol><apply id="A6.Ex6.m1.1.1.1.1.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.2.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.2">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.2.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.2.2.2">ğ‘¥</ci><ci id="A6.Ex6.m1.1.1.1.1.2.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.2.2.3">ğ‘–</ci></apply><ci id="A6.Ex6.m1.1.1.1.1.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="A6.Ex6.m1.1.1.1.1.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3"><plus id="A6.Ex6.m1.1.1.1.1.3.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.1"></plus><apply id="A6.Ex6.m1.1.1.1.1.3.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2"><times id="A6.Ex6.m1.1.1.1.1.3.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.1"></times><apply id="A6.Ex6.m1.1.1.1.1.3.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.3.2.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.3.2.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2.2">ğ›¼</ci><ci id="A6.Ex6.m1.1.1.1.1.3.2.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.2.3">ğ‘¡</ci></apply><apply id="A6.Ex6.m1.1.1.1.1.3.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.3.2.3.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.3.2.3.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3.2">ğ‘¥</ci><ci id="A6.Ex6.m1.1.1.1.1.3.2.3.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.2.3.3">ğ‘–</ci></apply></apply><apply id="A6.Ex6.m1.1.1.1.1.3.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3"><times id="A6.Ex6.m1.1.1.1.1.3.3.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.1"></times><apply id="A6.Ex6.m1.1.1.1.1.3.3.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="A6.Ex6.m1.1.1.1.1.3.3.2.1.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="A6.Ex6.m1.1.1.1.1.3.3.2.2.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2.2">ğ›½</ci><ci id="A6.Ex6.m1.1.1.1.1.3.3.2.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.2.3">ğ‘¡</ci></apply><ci id="A6.Ex6.m1.1.1.1.1.3.3.3.cmml" xref="A6.Ex6.m1.1.1.1.1.3.3.3">italic-Ïµ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex6.m1.1c">x_{i}^{t}=\alpha_{t}x_{i}+\beta_{t}\epsilon,</annotation><annotation encoding="application/x-llamapun" id="A6.Ex6.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_Ïµ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p4">
<p class="ltx_p" id="A6.p4.11">where <math alttext="\alpha_{0}=0" class="ltx_Math" display="inline" id="A6.p4.1.m1.1"><semantics id="A6.p4.1.m1.1a"><mrow id="A6.p4.1.m1.1.1" xref="A6.p4.1.m1.1.1.cmml"><msub id="A6.p4.1.m1.1.1.2" xref="A6.p4.1.m1.1.1.2.cmml"><mi id="A6.p4.1.m1.1.1.2.2" xref="A6.p4.1.m1.1.1.2.2.cmml">Î±</mi><mn id="A6.p4.1.m1.1.1.2.3" xref="A6.p4.1.m1.1.1.2.3.cmml">0</mn></msub><mo id="A6.p4.1.m1.1.1.1" xref="A6.p4.1.m1.1.1.1.cmml">=</mo><mn id="A6.p4.1.m1.1.1.3" xref="A6.p4.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.1.m1.1b"><apply id="A6.p4.1.m1.1.1.cmml" xref="A6.p4.1.m1.1.1"><eq id="A6.p4.1.m1.1.1.1.cmml" xref="A6.p4.1.m1.1.1.1"></eq><apply id="A6.p4.1.m1.1.1.2.cmml" xref="A6.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="A6.p4.1.m1.1.1.2.1.cmml" xref="A6.p4.1.m1.1.1.2">subscript</csymbol><ci id="A6.p4.1.m1.1.1.2.2.cmml" xref="A6.p4.1.m1.1.1.2.2">ğ›¼</ci><cn id="A6.p4.1.m1.1.1.2.3.cmml" type="integer" xref="A6.p4.1.m1.1.1.2.3">0</cn></apply><cn id="A6.p4.1.m1.1.1.3.cmml" type="integer" xref="A6.p4.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.1.m1.1c">\alpha_{0}=0</annotation><annotation encoding="application/x-llamapun" id="A6.p4.1.m1.1d">italic_Î± start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 0</annotation></semantics></math>, <math alttext="\beta_{t}=1" class="ltx_Math" display="inline" id="A6.p4.2.m2.1"><semantics id="A6.p4.2.m2.1a"><mrow id="A6.p4.2.m2.1.1" xref="A6.p4.2.m2.1.1.cmml"><msub id="A6.p4.2.m2.1.1.2" xref="A6.p4.2.m2.1.1.2.cmml"><mi id="A6.p4.2.m2.1.1.2.2" xref="A6.p4.2.m2.1.1.2.2.cmml">Î²</mi><mi id="A6.p4.2.m2.1.1.2.3" xref="A6.p4.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="A6.p4.2.m2.1.1.1" xref="A6.p4.2.m2.1.1.1.cmml">=</mo><mn id="A6.p4.2.m2.1.1.3" xref="A6.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.2.m2.1b"><apply id="A6.p4.2.m2.1.1.cmml" xref="A6.p4.2.m2.1.1"><eq id="A6.p4.2.m2.1.1.1.cmml" xref="A6.p4.2.m2.1.1.1"></eq><apply id="A6.p4.2.m2.1.1.2.cmml" xref="A6.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="A6.p4.2.m2.1.1.2.1.cmml" xref="A6.p4.2.m2.1.1.2">subscript</csymbol><ci id="A6.p4.2.m2.1.1.2.2.cmml" xref="A6.p4.2.m2.1.1.2.2">ğ›½</ci><ci id="A6.p4.2.m2.1.1.2.3.cmml" xref="A6.p4.2.m2.1.1.2.3">ğ‘¡</ci></apply><cn id="A6.p4.2.m2.1.1.3.cmml" type="integer" xref="A6.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.2.m2.1c">\beta_{t}=1</annotation><annotation encoding="application/x-llamapun" id="A6.p4.2.m2.1d">italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1</annotation></semantics></math>, <math alttext="\alpha_{1}=1" class="ltx_Math" display="inline" id="A6.p4.3.m3.1"><semantics id="A6.p4.3.m3.1a"><mrow id="A6.p4.3.m3.1.1" xref="A6.p4.3.m3.1.1.cmml"><msub id="A6.p4.3.m3.1.1.2" xref="A6.p4.3.m3.1.1.2.cmml"><mi id="A6.p4.3.m3.1.1.2.2" xref="A6.p4.3.m3.1.1.2.2.cmml">Î±</mi><mn id="A6.p4.3.m3.1.1.2.3" xref="A6.p4.3.m3.1.1.2.3.cmml">1</mn></msub><mo id="A6.p4.3.m3.1.1.1" xref="A6.p4.3.m3.1.1.1.cmml">=</mo><mn id="A6.p4.3.m3.1.1.3" xref="A6.p4.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.3.m3.1b"><apply id="A6.p4.3.m3.1.1.cmml" xref="A6.p4.3.m3.1.1"><eq id="A6.p4.3.m3.1.1.1.cmml" xref="A6.p4.3.m3.1.1.1"></eq><apply id="A6.p4.3.m3.1.1.2.cmml" xref="A6.p4.3.m3.1.1.2"><csymbol cd="ambiguous" id="A6.p4.3.m3.1.1.2.1.cmml" xref="A6.p4.3.m3.1.1.2">subscript</csymbol><ci id="A6.p4.3.m3.1.1.2.2.cmml" xref="A6.p4.3.m3.1.1.2.2">ğ›¼</ci><cn id="A6.p4.3.m3.1.1.2.3.cmml" type="integer" xref="A6.p4.3.m3.1.1.2.3">1</cn></apply><cn id="A6.p4.3.m3.1.1.3.cmml" type="integer" xref="A6.p4.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.3.m3.1c">\alpha_{1}=1</annotation><annotation encoding="application/x-llamapun" id="A6.p4.3.m3.1d">italic_Î± start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1</annotation></semantics></math>, and <math alttext="\beta_{1}=0" class="ltx_Math" display="inline" id="A6.p4.4.m4.1"><semantics id="A6.p4.4.m4.1a"><mrow id="A6.p4.4.m4.1.1" xref="A6.p4.4.m4.1.1.cmml"><msub id="A6.p4.4.m4.1.1.2" xref="A6.p4.4.m4.1.1.2.cmml"><mi id="A6.p4.4.m4.1.1.2.2" xref="A6.p4.4.m4.1.1.2.2.cmml">Î²</mi><mn id="A6.p4.4.m4.1.1.2.3" xref="A6.p4.4.m4.1.1.2.3.cmml">1</mn></msub><mo id="A6.p4.4.m4.1.1.1" xref="A6.p4.4.m4.1.1.1.cmml">=</mo><mn id="A6.p4.4.m4.1.1.3" xref="A6.p4.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.4.m4.1b"><apply id="A6.p4.4.m4.1.1.cmml" xref="A6.p4.4.m4.1.1"><eq id="A6.p4.4.m4.1.1.1.cmml" xref="A6.p4.4.m4.1.1.1"></eq><apply id="A6.p4.4.m4.1.1.2.cmml" xref="A6.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="A6.p4.4.m4.1.1.2.1.cmml" xref="A6.p4.4.m4.1.1.2">subscript</csymbol><ci id="A6.p4.4.m4.1.1.2.2.cmml" xref="A6.p4.4.m4.1.1.2.2">ğ›½</ci><cn id="A6.p4.4.m4.1.1.2.3.cmml" type="integer" xref="A6.p4.4.m4.1.1.2.3">1</cn></apply><cn id="A6.p4.4.m4.1.1.3.cmml" type="integer" xref="A6.p4.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.4.m4.1c">\beta_{1}=0</annotation><annotation encoding="application/x-llamapun" id="A6.p4.4.m4.1d">italic_Î² start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0</annotation></semantics></math>. This interpolation for <math alttext="t\in[0,1]" class="ltx_Math" display="inline" id="A6.p4.5.m5.2"><semantics id="A6.p4.5.m5.2a"><mrow id="A6.p4.5.m5.2.3" xref="A6.p4.5.m5.2.3.cmml"><mi id="A6.p4.5.m5.2.3.2" xref="A6.p4.5.m5.2.3.2.cmml">t</mi><mo id="A6.p4.5.m5.2.3.1" xref="A6.p4.5.m5.2.3.1.cmml">âˆˆ</mo><mrow id="A6.p4.5.m5.2.3.3.2" xref="A6.p4.5.m5.2.3.3.1.cmml"><mo id="A6.p4.5.m5.2.3.3.2.1" stretchy="false" xref="A6.p4.5.m5.2.3.3.1.cmml">[</mo><mn id="A6.p4.5.m5.1.1" xref="A6.p4.5.m5.1.1.cmml">0</mn><mo id="A6.p4.5.m5.2.3.3.2.2" xref="A6.p4.5.m5.2.3.3.1.cmml">,</mo><mn id="A6.p4.5.m5.2.2" xref="A6.p4.5.m5.2.2.cmml">1</mn><mo id="A6.p4.5.m5.2.3.3.2.3" stretchy="false" xref="A6.p4.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.5.m5.2b"><apply id="A6.p4.5.m5.2.3.cmml" xref="A6.p4.5.m5.2.3"><in id="A6.p4.5.m5.2.3.1.cmml" xref="A6.p4.5.m5.2.3.1"></in><ci id="A6.p4.5.m5.2.3.2.cmml" xref="A6.p4.5.m5.2.3.2">ğ‘¡</ci><interval closure="closed" id="A6.p4.5.m5.2.3.3.1.cmml" xref="A6.p4.5.m5.2.3.3.2"><cn id="A6.p4.5.m5.1.1.cmml" type="integer" xref="A6.p4.5.m5.1.1">0</cn><cn id="A6.p4.5.m5.2.2.cmml" type="integer" xref="A6.p4.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.5.m5.2c">t\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="A6.p4.5.m5.2d">italic_t âˆˆ [ 0 , 1 ]</annotation></semantics></math> bridges <math alttext="x_{i}^{0}=\epsilon" class="ltx_Math" display="inline" id="A6.p4.6.m6.1"><semantics id="A6.p4.6.m6.1a"><mrow id="A6.p4.6.m6.1.1" xref="A6.p4.6.m6.1.1.cmml"><msubsup id="A6.p4.6.m6.1.1.2" xref="A6.p4.6.m6.1.1.2.cmml"><mi id="A6.p4.6.m6.1.1.2.2.2" xref="A6.p4.6.m6.1.1.2.2.2.cmml">x</mi><mi id="A6.p4.6.m6.1.1.2.2.3" xref="A6.p4.6.m6.1.1.2.2.3.cmml">i</mi><mn id="A6.p4.6.m6.1.1.2.3" xref="A6.p4.6.m6.1.1.2.3.cmml">0</mn></msubsup><mo id="A6.p4.6.m6.1.1.1" xref="A6.p4.6.m6.1.1.1.cmml">=</mo><mi id="A6.p4.6.m6.1.1.3" xref="A6.p4.6.m6.1.1.3.cmml">Ïµ</mi></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.6.m6.1b"><apply id="A6.p4.6.m6.1.1.cmml" xref="A6.p4.6.m6.1.1"><eq id="A6.p4.6.m6.1.1.1.cmml" xref="A6.p4.6.m6.1.1.1"></eq><apply id="A6.p4.6.m6.1.1.2.cmml" xref="A6.p4.6.m6.1.1.2"><csymbol cd="ambiguous" id="A6.p4.6.m6.1.1.2.1.cmml" xref="A6.p4.6.m6.1.1.2">superscript</csymbol><apply id="A6.p4.6.m6.1.1.2.2.cmml" xref="A6.p4.6.m6.1.1.2"><csymbol cd="ambiguous" id="A6.p4.6.m6.1.1.2.2.1.cmml" xref="A6.p4.6.m6.1.1.2">subscript</csymbol><ci id="A6.p4.6.m6.1.1.2.2.2.cmml" xref="A6.p4.6.m6.1.1.2.2.2">ğ‘¥</ci><ci id="A6.p4.6.m6.1.1.2.2.3.cmml" xref="A6.p4.6.m6.1.1.2.2.3">ğ‘–</ci></apply><cn id="A6.p4.6.m6.1.1.2.3.cmml" type="integer" xref="A6.p4.6.m6.1.1.2.3">0</cn></apply><ci id="A6.p4.6.m6.1.1.3.cmml" xref="A6.p4.6.m6.1.1.3">italic-Ïµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.6.m6.1c">x_{i}^{0}=\epsilon</annotation><annotation encoding="application/x-llamapun" id="A6.p4.6.m6.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = italic_Ïµ</annotation></semantics></math> and <math alttext="x_{i}^{1}=x_{i}" class="ltx_Math" display="inline" id="A6.p4.7.m7.1"><semantics id="A6.p4.7.m7.1a"><mrow id="A6.p4.7.m7.1.1" xref="A6.p4.7.m7.1.1.cmml"><msubsup id="A6.p4.7.m7.1.1.2" xref="A6.p4.7.m7.1.1.2.cmml"><mi id="A6.p4.7.m7.1.1.2.2.2" xref="A6.p4.7.m7.1.1.2.2.2.cmml">x</mi><mi id="A6.p4.7.m7.1.1.2.2.3" xref="A6.p4.7.m7.1.1.2.2.3.cmml">i</mi><mn id="A6.p4.7.m7.1.1.2.3" xref="A6.p4.7.m7.1.1.2.3.cmml">1</mn></msubsup><mo id="A6.p4.7.m7.1.1.1" xref="A6.p4.7.m7.1.1.1.cmml">=</mo><msub id="A6.p4.7.m7.1.1.3" xref="A6.p4.7.m7.1.1.3.cmml"><mi id="A6.p4.7.m7.1.1.3.2" xref="A6.p4.7.m7.1.1.3.2.cmml">x</mi><mi id="A6.p4.7.m7.1.1.3.3" xref="A6.p4.7.m7.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.7.m7.1b"><apply id="A6.p4.7.m7.1.1.cmml" xref="A6.p4.7.m7.1.1"><eq id="A6.p4.7.m7.1.1.1.cmml" xref="A6.p4.7.m7.1.1.1"></eq><apply id="A6.p4.7.m7.1.1.2.cmml" xref="A6.p4.7.m7.1.1.2"><csymbol cd="ambiguous" id="A6.p4.7.m7.1.1.2.1.cmml" xref="A6.p4.7.m7.1.1.2">superscript</csymbol><apply id="A6.p4.7.m7.1.1.2.2.cmml" xref="A6.p4.7.m7.1.1.2"><csymbol cd="ambiguous" id="A6.p4.7.m7.1.1.2.2.1.cmml" xref="A6.p4.7.m7.1.1.2">subscript</csymbol><ci id="A6.p4.7.m7.1.1.2.2.2.cmml" xref="A6.p4.7.m7.1.1.2.2.2">ğ‘¥</ci><ci id="A6.p4.7.m7.1.1.2.2.3.cmml" xref="A6.p4.7.m7.1.1.2.2.3">ğ‘–</ci></apply><cn id="A6.p4.7.m7.1.1.2.3.cmml" type="integer" xref="A6.p4.7.m7.1.1.2.3">1</cn></apply><apply id="A6.p4.7.m7.1.1.3.cmml" xref="A6.p4.7.m7.1.1.3"><csymbol cd="ambiguous" id="A6.p4.7.m7.1.1.3.1.cmml" xref="A6.p4.7.m7.1.1.3">subscript</csymbol><ci id="A6.p4.7.m7.1.1.3.2.cmml" xref="A6.p4.7.m7.1.1.3.2">ğ‘¥</ci><ci id="A6.p4.7.m7.1.1.3.3.cmml" xref="A6.p4.7.m7.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.7.m7.1c">x_{i}^{1}=x_{i}</annotation><annotation encoding="application/x-llamapun" id="A6.p4.7.m7.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Similar to the diffusion schedule, this interpolation schedule offers flexible choices of <math alttext="\alpha_{t}" class="ltx_Math" display="inline" id="A6.p4.8.m8.1"><semantics id="A6.p4.8.m8.1a"><msub id="A6.p4.8.m8.1.1" xref="A6.p4.8.m8.1.1.cmml"><mi id="A6.p4.8.m8.1.1.2" xref="A6.p4.8.m8.1.1.2.cmml">Î±</mi><mi id="A6.p4.8.m8.1.1.3" xref="A6.p4.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A6.p4.8.m8.1b"><apply id="A6.p4.8.m8.1.1.cmml" xref="A6.p4.8.m8.1.1"><csymbol cd="ambiguous" id="A6.p4.8.m8.1.1.1.cmml" xref="A6.p4.8.m8.1.1">subscript</csymbol><ci id="A6.p4.8.m8.1.1.2.cmml" xref="A6.p4.8.m8.1.1.2">ğ›¼</ci><ci id="A6.p4.8.m8.1.1.3.cmml" xref="A6.p4.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.8.m8.1c">\alpha_{t}</annotation><annotation encoding="application/x-llamapun" id="A6.p4.8.m8.1d">italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\beta_{t}" class="ltx_Math" display="inline" id="A6.p4.9.m9.1"><semantics id="A6.p4.9.m9.1a"><msub id="A6.p4.9.m9.1.1" xref="A6.p4.9.m9.1.1.cmml"><mi id="A6.p4.9.m9.1.1.2" xref="A6.p4.9.m9.1.1.2.cmml">Î²</mi><mi id="A6.p4.9.m9.1.1.3" xref="A6.p4.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A6.p4.9.m9.1b"><apply id="A6.p4.9.m9.1.1.cmml" xref="A6.p4.9.m9.1.1"><csymbol cd="ambiguous" id="A6.p4.9.m9.1.1.1.cmml" xref="A6.p4.9.m9.1.1">subscript</csymbol><ci id="A6.p4.9.m9.1.1.2.cmml" xref="A6.p4.9.m9.1.1.2">ğ›½</ci><ci id="A6.p4.9.m9.1.1.3.cmml" xref="A6.p4.9.m9.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.9.m9.1c">\beta_{t}</annotation><annotation encoding="application/x-llamapun" id="A6.p4.9.m9.1d">italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. For example, we can utilize the original diffusion schedules, such as <math alttext="\alpha_{t}=\sin\left(\frac{\pi}{2}t\right)" class="ltx_Math" display="inline" id="A6.p4.10.m10.2"><semantics id="A6.p4.10.m10.2a"><mrow id="A6.p4.10.m10.2.2" xref="A6.p4.10.m10.2.2.cmml"><msub id="A6.p4.10.m10.2.2.3" xref="A6.p4.10.m10.2.2.3.cmml"><mi id="A6.p4.10.m10.2.2.3.2" xref="A6.p4.10.m10.2.2.3.2.cmml">Î±</mi><mi id="A6.p4.10.m10.2.2.3.3" xref="A6.p4.10.m10.2.2.3.3.cmml">t</mi></msub><mo id="A6.p4.10.m10.2.2.2" xref="A6.p4.10.m10.2.2.2.cmml">=</mo><mrow id="A6.p4.10.m10.2.2.1.1" xref="A6.p4.10.m10.2.2.1.2.cmml"><mi id="A6.p4.10.m10.1.1" xref="A6.p4.10.m10.1.1.cmml">sin</mi><mo id="A6.p4.10.m10.2.2.1.1a" xref="A6.p4.10.m10.2.2.1.2.cmml">â¡</mo><mrow id="A6.p4.10.m10.2.2.1.1.1" xref="A6.p4.10.m10.2.2.1.2.cmml"><mo id="A6.p4.10.m10.2.2.1.1.1.2" xref="A6.p4.10.m10.2.2.1.2.cmml">(</mo><mrow id="A6.p4.10.m10.2.2.1.1.1.1" xref="A6.p4.10.m10.2.2.1.1.1.1.cmml"><mfrac id="A6.p4.10.m10.2.2.1.1.1.1.2" xref="A6.p4.10.m10.2.2.1.1.1.1.2.cmml"><mi id="A6.p4.10.m10.2.2.1.1.1.1.2.2" xref="A6.p4.10.m10.2.2.1.1.1.1.2.2.cmml">Ï€</mi><mn id="A6.p4.10.m10.2.2.1.1.1.1.2.3" xref="A6.p4.10.m10.2.2.1.1.1.1.2.3.cmml">2</mn></mfrac><mo id="A6.p4.10.m10.2.2.1.1.1.1.1" xref="A6.p4.10.m10.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="A6.p4.10.m10.2.2.1.1.1.1.3" xref="A6.p4.10.m10.2.2.1.1.1.1.3.cmml">t</mi></mrow><mo id="A6.p4.10.m10.2.2.1.1.1.3" xref="A6.p4.10.m10.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.10.m10.2b"><apply id="A6.p4.10.m10.2.2.cmml" xref="A6.p4.10.m10.2.2"><eq id="A6.p4.10.m10.2.2.2.cmml" xref="A6.p4.10.m10.2.2.2"></eq><apply id="A6.p4.10.m10.2.2.3.cmml" xref="A6.p4.10.m10.2.2.3"><csymbol cd="ambiguous" id="A6.p4.10.m10.2.2.3.1.cmml" xref="A6.p4.10.m10.2.2.3">subscript</csymbol><ci id="A6.p4.10.m10.2.2.3.2.cmml" xref="A6.p4.10.m10.2.2.3.2">ğ›¼</ci><ci id="A6.p4.10.m10.2.2.3.3.cmml" xref="A6.p4.10.m10.2.2.3.3">ğ‘¡</ci></apply><apply id="A6.p4.10.m10.2.2.1.2.cmml" xref="A6.p4.10.m10.2.2.1.1"><sin id="A6.p4.10.m10.1.1.cmml" xref="A6.p4.10.m10.1.1"></sin><apply id="A6.p4.10.m10.2.2.1.1.1.1.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1"><times id="A6.p4.10.m10.2.2.1.1.1.1.1.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.1"></times><apply id="A6.p4.10.m10.2.2.1.1.1.1.2.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.2"><divide id="A6.p4.10.m10.2.2.1.1.1.1.2.1.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.2"></divide><ci id="A6.p4.10.m10.2.2.1.1.1.1.2.2.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.2.2">ğœ‹</ci><cn id="A6.p4.10.m10.2.2.1.1.1.1.2.3.cmml" type="integer" xref="A6.p4.10.m10.2.2.1.1.1.1.2.3">2</cn></apply><ci id="A6.p4.10.m10.2.2.1.1.1.1.3.cmml" xref="A6.p4.10.m10.2.2.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.10.m10.2c">\alpha_{t}=\sin\left(\frac{\pi}{2}t\right)</annotation><annotation encoding="application/x-llamapun" id="A6.p4.10.m10.2d">italic_Î± start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_sin ( divide start_ARG italic_Ï€ end_ARG start_ARG 2 end_ARG italic_t )</annotation></semantics></math> and <math alttext="\beta_{t}=\cos\left(\frac{\pi}{2}t\right)" class="ltx_Math" display="inline" id="A6.p4.11.m11.2"><semantics id="A6.p4.11.m11.2a"><mrow id="A6.p4.11.m11.2.2" xref="A6.p4.11.m11.2.2.cmml"><msub id="A6.p4.11.m11.2.2.3" xref="A6.p4.11.m11.2.2.3.cmml"><mi id="A6.p4.11.m11.2.2.3.2" xref="A6.p4.11.m11.2.2.3.2.cmml">Î²</mi><mi id="A6.p4.11.m11.2.2.3.3" xref="A6.p4.11.m11.2.2.3.3.cmml">t</mi></msub><mo id="A6.p4.11.m11.2.2.2" xref="A6.p4.11.m11.2.2.2.cmml">=</mo><mrow id="A6.p4.11.m11.2.2.1.1" xref="A6.p4.11.m11.2.2.1.2.cmml"><mi id="A6.p4.11.m11.1.1" xref="A6.p4.11.m11.1.1.cmml">cos</mi><mo id="A6.p4.11.m11.2.2.1.1a" xref="A6.p4.11.m11.2.2.1.2.cmml">â¡</mo><mrow id="A6.p4.11.m11.2.2.1.1.1" xref="A6.p4.11.m11.2.2.1.2.cmml"><mo id="A6.p4.11.m11.2.2.1.1.1.2" xref="A6.p4.11.m11.2.2.1.2.cmml">(</mo><mrow id="A6.p4.11.m11.2.2.1.1.1.1" xref="A6.p4.11.m11.2.2.1.1.1.1.cmml"><mfrac id="A6.p4.11.m11.2.2.1.1.1.1.2" xref="A6.p4.11.m11.2.2.1.1.1.1.2.cmml"><mi id="A6.p4.11.m11.2.2.1.1.1.1.2.2" xref="A6.p4.11.m11.2.2.1.1.1.1.2.2.cmml">Ï€</mi><mn id="A6.p4.11.m11.2.2.1.1.1.1.2.3" xref="A6.p4.11.m11.2.2.1.1.1.1.2.3.cmml">2</mn></mfrac><mo id="A6.p4.11.m11.2.2.1.1.1.1.1" xref="A6.p4.11.m11.2.2.1.1.1.1.1.cmml">â¢</mo><mi id="A6.p4.11.m11.2.2.1.1.1.1.3" xref="A6.p4.11.m11.2.2.1.1.1.1.3.cmml">t</mi></mrow><mo id="A6.p4.11.m11.2.2.1.1.1.3" xref="A6.p4.11.m11.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p4.11.m11.2b"><apply id="A6.p4.11.m11.2.2.cmml" xref="A6.p4.11.m11.2.2"><eq id="A6.p4.11.m11.2.2.2.cmml" xref="A6.p4.11.m11.2.2.2"></eq><apply id="A6.p4.11.m11.2.2.3.cmml" xref="A6.p4.11.m11.2.2.3"><csymbol cd="ambiguous" id="A6.p4.11.m11.2.2.3.1.cmml" xref="A6.p4.11.m11.2.2.3">subscript</csymbol><ci id="A6.p4.11.m11.2.2.3.2.cmml" xref="A6.p4.11.m11.2.2.3.2">ğ›½</ci><ci id="A6.p4.11.m11.2.2.3.3.cmml" xref="A6.p4.11.m11.2.2.3.3">ğ‘¡</ci></apply><apply id="A6.p4.11.m11.2.2.1.2.cmml" xref="A6.p4.11.m11.2.2.1.1"><cos id="A6.p4.11.m11.1.1.cmml" xref="A6.p4.11.m11.1.1"></cos><apply id="A6.p4.11.m11.2.2.1.1.1.1.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1"><times id="A6.p4.11.m11.2.2.1.1.1.1.1.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.1"></times><apply id="A6.p4.11.m11.2.2.1.1.1.1.2.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.2"><divide id="A6.p4.11.m11.2.2.1.1.1.1.2.1.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.2"></divide><ci id="A6.p4.11.m11.2.2.1.1.1.1.2.2.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.2.2">ğœ‹</ci><cn id="A6.p4.11.m11.2.2.1.1.1.1.2.3.cmml" type="integer" xref="A6.p4.11.m11.2.2.1.1.1.1.2.3">2</cn></apply><ci id="A6.p4.11.m11.2.2.1.1.1.1.3.cmml" xref="A6.p4.11.m11.2.2.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p4.11.m11.2c">\beta_{t}=\cos\left(\frac{\pi}{2}t\right)</annotation><annotation encoding="application/x-llamapun" id="A6.p4.11.m11.2d">italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_cos ( divide start_ARG italic_Ï€ end_ARG start_ARG 2 end_ARG italic_t )</annotation></semantics></math> for the VP cosine schedule. However, in our framework, we adopt a linear interpolation schedule between noise and data for its simplicity:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p5">
<table class="ltx_equation ltx_eqn_table" id="A6.Ex7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x_{i}^{t}=tx_{i}+(1-t)\epsilon." class="ltx_Math" display="block" id="A6.Ex7.m1.1"><semantics id="A6.Ex7.m1.1a"><mrow id="A6.Ex7.m1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.cmml"><mrow id="A6.Ex7.m1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.cmml"><msubsup id="A6.Ex7.m1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.3.cmml"><mi id="A6.Ex7.m1.1.1.1.1.3.2.2" xref="A6.Ex7.m1.1.1.1.1.3.2.2.cmml">x</mi><mi id="A6.Ex7.m1.1.1.1.1.3.2.3" xref="A6.Ex7.m1.1.1.1.1.3.2.3.cmml">i</mi><mi id="A6.Ex7.m1.1.1.1.1.3.3" xref="A6.Ex7.m1.1.1.1.1.3.3.cmml">t</mi></msubsup><mo id="A6.Ex7.m1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.2.cmml">=</mo><mrow id="A6.Ex7.m1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.cmml"><mrow id="A6.Ex7.m1.1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.1.3.cmml"><mi id="A6.Ex7.m1.1.1.1.1.1.3.2" xref="A6.Ex7.m1.1.1.1.1.1.3.2.cmml">t</mi><mo id="A6.Ex7.m1.1.1.1.1.1.3.1" xref="A6.Ex7.m1.1.1.1.1.1.3.1.cmml">â¢</mo><msub id="A6.Ex7.m1.1.1.1.1.1.3.3" xref="A6.Ex7.m1.1.1.1.1.1.3.3.cmml"><mi id="A6.Ex7.m1.1.1.1.1.1.3.3.2" xref="A6.Ex7.m1.1.1.1.1.1.3.3.2.cmml">x</mi><mi id="A6.Ex7.m1.1.1.1.1.1.3.3.3" xref="A6.Ex7.m1.1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="A6.Ex7.m1.1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="A6.Ex7.m1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.cmml"><mrow id="A6.Ex7.m1.1.1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="A6.Ex7.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></mrow><mo id="A6.Ex7.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A6.Ex7.m1.1.1.1.1.1.1.2" xref="A6.Ex7.m1.1.1.1.1.1.1.2.cmml">â¢</mo><mi id="A6.Ex7.m1.1.1.1.1.1.1.3" xref="A6.Ex7.m1.1.1.1.1.1.1.3.cmml">Ïµ</mi></mrow></mrow></mrow><mo id="A6.Ex7.m1.1.1.1.2" lspace="0em" xref="A6.Ex7.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex7.m1.1b"><apply id="A6.Ex7.m1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1"><eq id="A6.Ex7.m1.1.1.1.1.2.cmml" xref="A6.Ex7.m1.1.1.1.1.2"></eq><apply id="A6.Ex7.m1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.Ex7.m1.1.1.1.1.3.1.cmml" xref="A6.Ex7.m1.1.1.1.1.3">superscript</csymbol><apply id="A6.Ex7.m1.1.1.1.1.3.2.cmml" xref="A6.Ex7.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.Ex7.m1.1.1.1.1.3.2.1.cmml" xref="A6.Ex7.m1.1.1.1.1.3">subscript</csymbol><ci id="A6.Ex7.m1.1.1.1.1.3.2.2.cmml" xref="A6.Ex7.m1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="A6.Ex7.m1.1.1.1.1.3.2.3.cmml" xref="A6.Ex7.m1.1.1.1.1.3.2.3">ğ‘–</ci></apply><ci id="A6.Ex7.m1.1.1.1.1.3.3.cmml" xref="A6.Ex7.m1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="A6.Ex7.m1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1"><plus id="A6.Ex7.m1.1.1.1.1.1.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.2"></plus><apply id="A6.Ex7.m1.1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3"><times id="A6.Ex7.m1.1.1.1.1.1.3.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.1"></times><ci id="A6.Ex7.m1.1.1.1.1.1.3.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.2">ğ‘¡</ci><apply id="A6.Ex7.m1.1.1.1.1.1.3.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex7.m1.1.1.1.1.1.3.3.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.Ex7.m1.1.1.1.1.1.3.3.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3.2">ğ‘¥</ci><ci id="A6.Ex7.m1.1.1.1.1.1.3.3.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.3.3.3">ğ‘–</ci></apply></apply><apply id="A6.Ex7.m1.1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1"><times id="A6.Ex7.m1.1.1.1.1.1.1.2.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.2"></times><apply id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1"><minus id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="A6.Ex7.m1.1.1.1.1.1.1.3.cmml" xref="A6.Ex7.m1.1.1.1.1.1.1.3">italic-Ïµ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex7.m1.1c">x_{i}^{t}=tx_{i}+(1-t)\epsilon.</annotation><annotation encoding="application/x-llamapun" id="A6.Ex7.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = italic_t italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + ( 1 - italic_t ) italic_Ïµ .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p6">
<p class="ltx_p" id="A6.p6.1">This formulation represents a uniform transformation with constant velocity between the data and noise. The corresponding time-dependent velocity field is defined as:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p7">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A8.EGx2">
<tbody id="A6.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle v_{t}(x_{i}^{t})" class="ltx_Math" display="inline" id="A6.E5.m1.1"><semantics id="A6.E5.m1.1a"><mrow id="A6.E5.m1.1.1" xref="A6.E5.m1.1.1.cmml"><msub id="A6.E5.m1.1.1.3" xref="A6.E5.m1.1.1.3.cmml"><mi id="A6.E5.m1.1.1.3.2" xref="A6.E5.m1.1.1.3.2.cmml">v</mi><mi id="A6.E5.m1.1.1.3.3" xref="A6.E5.m1.1.1.3.3.cmml">t</mi></msub><mo id="A6.E5.m1.1.1.2" xref="A6.E5.m1.1.1.2.cmml">â¢</mo><mrow id="A6.E5.m1.1.1.1.1" xref="A6.E5.m1.1.1.1.1.1.cmml"><mo id="A6.E5.m1.1.1.1.1.2" stretchy="false" xref="A6.E5.m1.1.1.1.1.1.cmml">(</mo><msubsup id="A6.E5.m1.1.1.1.1.1" xref="A6.E5.m1.1.1.1.1.1.cmml"><mi id="A6.E5.m1.1.1.1.1.1.2.2" xref="A6.E5.m1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A6.E5.m1.1.1.1.1.1.2.3" xref="A6.E5.m1.1.1.1.1.1.2.3.cmml">i</mi><mi id="A6.E5.m1.1.1.1.1.1.3" xref="A6.E5.m1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.E5.m1.1.1.1.1.3" stretchy="false" xref="A6.E5.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.E5.m1.1b"><apply id="A6.E5.m1.1.1.cmml" xref="A6.E5.m1.1.1"><times id="A6.E5.m1.1.1.2.cmml" xref="A6.E5.m1.1.1.2"></times><apply id="A6.E5.m1.1.1.3.cmml" xref="A6.E5.m1.1.1.3"><csymbol cd="ambiguous" id="A6.E5.m1.1.1.3.1.cmml" xref="A6.E5.m1.1.1.3">subscript</csymbol><ci id="A6.E5.m1.1.1.3.2.cmml" xref="A6.E5.m1.1.1.3.2">ğ‘£</ci><ci id="A6.E5.m1.1.1.3.3.cmml" xref="A6.E5.m1.1.1.3.3">ğ‘¡</ci></apply><apply id="A6.E5.m1.1.1.1.1.1.cmml" xref="A6.E5.m1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E5.m1.1.1.1.1.1.1.cmml" xref="A6.E5.m1.1.1.1.1">superscript</csymbol><apply id="A6.E5.m1.1.1.1.1.1.2.cmml" xref="A6.E5.m1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E5.m1.1.1.1.1.1.2.1.cmml" xref="A6.E5.m1.1.1.1.1">subscript</csymbol><ci id="A6.E5.m1.1.1.1.1.1.2.2.cmml" xref="A6.E5.m1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="A6.E5.m1.1.1.1.1.1.2.3.cmml" xref="A6.E5.m1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="A6.E5.m1.1.1.1.1.1.3.cmml" xref="A6.E5.m1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E5.m1.1c">\displaystyle v_{t}(x_{i}^{t})</annotation><annotation encoding="application/x-llamapun" id="A6.E5.m1.1d">italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\dot{\alpha}_{t}x_{i}+\dot{\beta}_{t}\epsilon" class="ltx_Math" display="inline" id="A6.E5.m2.1"><semantics id="A6.E5.m2.1a"><mrow id="A6.E5.m2.1.1" xref="A6.E5.m2.1.1.cmml"><mi id="A6.E5.m2.1.1.2" xref="A6.E5.m2.1.1.2.cmml"></mi><mo id="A6.E5.m2.1.1.1" xref="A6.E5.m2.1.1.1.cmml">=</mo><mrow id="A6.E5.m2.1.1.3" xref="A6.E5.m2.1.1.3.cmml"><mrow id="A6.E5.m2.1.1.3.2" xref="A6.E5.m2.1.1.3.2.cmml"><msub id="A6.E5.m2.1.1.3.2.2" xref="A6.E5.m2.1.1.3.2.2.cmml"><mover accent="true" id="A6.E5.m2.1.1.3.2.2.2" xref="A6.E5.m2.1.1.3.2.2.2.cmml"><mi id="A6.E5.m2.1.1.3.2.2.2.2" xref="A6.E5.m2.1.1.3.2.2.2.2.cmml">Î±</mi><mo id="A6.E5.m2.1.1.3.2.2.2.1" xref="A6.E5.m2.1.1.3.2.2.2.1.cmml">Ë™</mo></mover><mi id="A6.E5.m2.1.1.3.2.2.3" xref="A6.E5.m2.1.1.3.2.2.3.cmml">t</mi></msub><mo id="A6.E5.m2.1.1.3.2.1" xref="A6.E5.m2.1.1.3.2.1.cmml">â¢</mo><msub id="A6.E5.m2.1.1.3.2.3" xref="A6.E5.m2.1.1.3.2.3.cmml"><mi id="A6.E5.m2.1.1.3.2.3.2" xref="A6.E5.m2.1.1.3.2.3.2.cmml">x</mi><mi id="A6.E5.m2.1.1.3.2.3.3" xref="A6.E5.m2.1.1.3.2.3.3.cmml">i</mi></msub></mrow><mo id="A6.E5.m2.1.1.3.1" xref="A6.E5.m2.1.1.3.1.cmml">+</mo><mrow id="A6.E5.m2.1.1.3.3" xref="A6.E5.m2.1.1.3.3.cmml"><msub id="A6.E5.m2.1.1.3.3.2" xref="A6.E5.m2.1.1.3.3.2.cmml"><mover accent="true" id="A6.E5.m2.1.1.3.3.2.2" xref="A6.E5.m2.1.1.3.3.2.2.cmml"><mi id="A6.E5.m2.1.1.3.3.2.2.2" xref="A6.E5.m2.1.1.3.3.2.2.2.cmml">Î²</mi><mo id="A6.E5.m2.1.1.3.3.2.2.1" xref="A6.E5.m2.1.1.3.3.2.2.1.cmml">Ë™</mo></mover><mi id="A6.E5.m2.1.1.3.3.2.3" xref="A6.E5.m2.1.1.3.3.2.3.cmml">t</mi></msub><mo id="A6.E5.m2.1.1.3.3.1" xref="A6.E5.m2.1.1.3.3.1.cmml">â¢</mo><mi id="A6.E5.m2.1.1.3.3.3" xref="A6.E5.m2.1.1.3.3.3.cmml">Ïµ</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.E5.m2.1b"><apply id="A6.E5.m2.1.1.cmml" xref="A6.E5.m2.1.1"><eq id="A6.E5.m2.1.1.1.cmml" xref="A6.E5.m2.1.1.1"></eq><csymbol cd="latexml" id="A6.E5.m2.1.1.2.cmml" xref="A6.E5.m2.1.1.2">absent</csymbol><apply id="A6.E5.m2.1.1.3.cmml" xref="A6.E5.m2.1.1.3"><plus id="A6.E5.m2.1.1.3.1.cmml" xref="A6.E5.m2.1.1.3.1"></plus><apply id="A6.E5.m2.1.1.3.2.cmml" xref="A6.E5.m2.1.1.3.2"><times id="A6.E5.m2.1.1.3.2.1.cmml" xref="A6.E5.m2.1.1.3.2.1"></times><apply id="A6.E5.m2.1.1.3.2.2.cmml" xref="A6.E5.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="A6.E5.m2.1.1.3.2.2.1.cmml" xref="A6.E5.m2.1.1.3.2.2">subscript</csymbol><apply id="A6.E5.m2.1.1.3.2.2.2.cmml" xref="A6.E5.m2.1.1.3.2.2.2"><ci id="A6.E5.m2.1.1.3.2.2.2.1.cmml" xref="A6.E5.m2.1.1.3.2.2.2.1">Ë™</ci><ci id="A6.E5.m2.1.1.3.2.2.2.2.cmml" xref="A6.E5.m2.1.1.3.2.2.2.2">ğ›¼</ci></apply><ci id="A6.E5.m2.1.1.3.2.2.3.cmml" xref="A6.E5.m2.1.1.3.2.2.3">ğ‘¡</ci></apply><apply id="A6.E5.m2.1.1.3.2.3.cmml" xref="A6.E5.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="A6.E5.m2.1.1.3.2.3.1.cmml" xref="A6.E5.m2.1.1.3.2.3">subscript</csymbol><ci id="A6.E5.m2.1.1.3.2.3.2.cmml" xref="A6.E5.m2.1.1.3.2.3.2">ğ‘¥</ci><ci id="A6.E5.m2.1.1.3.2.3.3.cmml" xref="A6.E5.m2.1.1.3.2.3.3">ğ‘–</ci></apply></apply><apply id="A6.E5.m2.1.1.3.3.cmml" xref="A6.E5.m2.1.1.3.3"><times id="A6.E5.m2.1.1.3.3.1.cmml" xref="A6.E5.m2.1.1.3.3.1"></times><apply id="A6.E5.m2.1.1.3.3.2.cmml" xref="A6.E5.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="A6.E5.m2.1.1.3.3.2.1.cmml" xref="A6.E5.m2.1.1.3.3.2">subscript</csymbol><apply id="A6.E5.m2.1.1.3.3.2.2.cmml" xref="A6.E5.m2.1.1.3.3.2.2"><ci id="A6.E5.m2.1.1.3.3.2.2.1.cmml" xref="A6.E5.m2.1.1.3.3.2.2.1">Ë™</ci><ci id="A6.E5.m2.1.1.3.3.2.2.2.cmml" xref="A6.E5.m2.1.1.3.3.2.2.2">ğ›½</ci></apply><ci id="A6.E5.m2.1.1.3.3.2.3.cmml" xref="A6.E5.m2.1.1.3.3.2.3">ğ‘¡</ci></apply><ci id="A6.E5.m2.1.1.3.3.3.cmml" xref="A6.E5.m2.1.1.3.3.3">italic-Ïµ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E5.m2.1c">\displaystyle=\dot{\alpha}_{t}x_{i}+\dot{\beta}_{t}\epsilon</annotation><annotation encoding="application/x-llamapun" id="A6.E5.m2.1d">= overË™ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + overË™ start_ARG italic_Î² end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_Ïµ</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
<tbody id="A6.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=x_{i}-\epsilon," class="ltx_Math" display="inline" id="A6.E6.m1.1"><semantics id="A6.E6.m1.1a"><mrow id="A6.E6.m1.1.1.1" xref="A6.E6.m1.1.1.1.1.cmml"><mrow id="A6.E6.m1.1.1.1.1" xref="A6.E6.m1.1.1.1.1.cmml"><mi id="A6.E6.m1.1.1.1.1.2" xref="A6.E6.m1.1.1.1.1.2.cmml"></mi><mo id="A6.E6.m1.1.1.1.1.1" xref="A6.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="A6.E6.m1.1.1.1.1.3" xref="A6.E6.m1.1.1.1.1.3.cmml"><msub id="A6.E6.m1.1.1.1.1.3.2" xref="A6.E6.m1.1.1.1.1.3.2.cmml"><mi id="A6.E6.m1.1.1.1.1.3.2.2" xref="A6.E6.m1.1.1.1.1.3.2.2.cmml">x</mi><mi id="A6.E6.m1.1.1.1.1.3.2.3" xref="A6.E6.m1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="A6.E6.m1.1.1.1.1.3.1" xref="A6.E6.m1.1.1.1.1.3.1.cmml">âˆ’</mo><mi id="A6.E6.m1.1.1.1.1.3.3" xref="A6.E6.m1.1.1.1.1.3.3.cmml">Ïµ</mi></mrow></mrow><mo id="A6.E6.m1.1.1.1.2" xref="A6.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.E6.m1.1b"><apply id="A6.E6.m1.1.1.1.1.cmml" xref="A6.E6.m1.1.1.1"><eq id="A6.E6.m1.1.1.1.1.1.cmml" xref="A6.E6.m1.1.1.1.1.1"></eq><csymbol cd="latexml" id="A6.E6.m1.1.1.1.1.2.cmml" xref="A6.E6.m1.1.1.1.1.2">absent</csymbol><apply id="A6.E6.m1.1.1.1.1.3.cmml" xref="A6.E6.m1.1.1.1.1.3"><minus id="A6.E6.m1.1.1.1.1.3.1.cmml" xref="A6.E6.m1.1.1.1.1.3.1"></minus><apply id="A6.E6.m1.1.1.1.1.3.2.cmml" xref="A6.E6.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A6.E6.m1.1.1.1.1.3.2.1.cmml" xref="A6.E6.m1.1.1.1.1.3.2">subscript</csymbol><ci id="A6.E6.m1.1.1.1.1.3.2.2.cmml" xref="A6.E6.m1.1.1.1.1.3.2.2">ğ‘¥</ci><ci id="A6.E6.m1.1.1.1.1.3.2.3.cmml" xref="A6.E6.m1.1.1.1.1.3.2.3">ğ‘–</ci></apply><ci id="A6.E6.m1.1.1.1.1.3.3.cmml" xref="A6.E6.m1.1.1.1.1.3.3">italic-Ïµ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E6.m1.1c">\displaystyle=x_{i}-\epsilon,</annotation><annotation encoding="application/x-llamapun" id="A6.E6.m1.1d">= italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_Ïµ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p8">
<p class="ltx_p" id="A6.p8.5">where <math alttext="\dot{\alpha}" class="ltx_Math" display="inline" id="A6.p8.1.m1.1"><semantics id="A6.p8.1.m1.1a"><mover accent="true" id="A6.p8.1.m1.1.1" xref="A6.p8.1.m1.1.1.cmml"><mi id="A6.p8.1.m1.1.1.2" xref="A6.p8.1.m1.1.1.2.cmml">Î±</mi><mo id="A6.p8.1.m1.1.1.1" xref="A6.p8.1.m1.1.1.1.cmml">Ë™</mo></mover><annotation-xml encoding="MathML-Content" id="A6.p8.1.m1.1b"><apply id="A6.p8.1.m1.1.1.cmml" xref="A6.p8.1.m1.1.1"><ci id="A6.p8.1.m1.1.1.1.cmml" xref="A6.p8.1.m1.1.1.1">Ë™</ci><ci id="A6.p8.1.m1.1.1.2.cmml" xref="A6.p8.1.m1.1.1.2">ğ›¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.1.m1.1c">\dot{\alpha}</annotation><annotation encoding="application/x-llamapun" id="A6.p8.1.m1.1d">overË™ start_ARG italic_Î± end_ARG</annotation></semantics></math> and <math alttext="\dot{\beta}" class="ltx_Math" display="inline" id="A6.p8.2.m2.1"><semantics id="A6.p8.2.m2.1a"><mover accent="true" id="A6.p8.2.m2.1.1" xref="A6.p8.2.m2.1.1.cmml"><mi id="A6.p8.2.m2.1.1.2" xref="A6.p8.2.m2.1.1.2.cmml">Î²</mi><mo id="A6.p8.2.m2.1.1.1" xref="A6.p8.2.m2.1.1.1.cmml">Ë™</mo></mover><annotation-xml encoding="MathML-Content" id="A6.p8.2.m2.1b"><apply id="A6.p8.2.m2.1.1.cmml" xref="A6.p8.2.m2.1.1"><ci id="A6.p8.2.m2.1.1.1.cmml" xref="A6.p8.2.m2.1.1.1">Ë™</ci><ci id="A6.p8.2.m2.1.1.2.cmml" xref="A6.p8.2.m2.1.1.2">ğ›½</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.2.m2.1c">\dot{\beta}</annotation><annotation encoding="application/x-llamapun" id="A6.p8.2.m2.1d">overË™ start_ARG italic_Î² end_ARG</annotation></semantics></math> denote the time derivatives of <math alttext="\alpha" class="ltx_Math" display="inline" id="A6.p8.3.m3.1"><semantics id="A6.p8.3.m3.1a"><mi id="A6.p8.3.m3.1.1" xref="A6.p8.3.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A6.p8.3.m3.1b"><ci id="A6.p8.3.m3.1.1.cmml" xref="A6.p8.3.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A6.p8.3.m3.1d">italic_Î±</annotation></semantics></math> and <math alttext="\beta" class="ltx_Math" display="inline" id="A6.p8.4.m4.1"><semantics id="A6.p8.4.m4.1a"><mi id="A6.p8.4.m4.1.1" xref="A6.p8.4.m4.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A6.p8.4.m4.1b"><ci id="A6.p8.4.m4.1.1.cmml" xref="A6.p8.4.m4.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.4.m4.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="A6.p8.4.m4.1d">italic_Î²</annotation></semantics></math>. This time-dependent velocity field <math alttext="v:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}^{d}" class="ltx_Math" display="inline" id="A6.p8.5.m5.2"><semantics id="A6.p8.5.m5.2a"><mrow id="A6.p8.5.m5.2.3" xref="A6.p8.5.m5.2.3.cmml"><mi id="A6.p8.5.m5.2.3.2" xref="A6.p8.5.m5.2.3.2.cmml">v</mi><mo id="A6.p8.5.m5.2.3.1" lspace="0.278em" rspace="0.278em" xref="A6.p8.5.m5.2.3.1.cmml">:</mo><mrow id="A6.p8.5.m5.2.3.3" xref="A6.p8.5.m5.2.3.3.cmml"><mrow id="A6.p8.5.m5.2.3.3.2" xref="A6.p8.5.m5.2.3.3.2.cmml"><mrow id="A6.p8.5.m5.2.3.3.2.2.2" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml"><mo id="A6.p8.5.m5.2.3.3.2.2.2.1" stretchy="false" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml">[</mo><mn id="A6.p8.5.m5.1.1" xref="A6.p8.5.m5.1.1.cmml">0</mn><mo id="A6.p8.5.m5.2.3.3.2.2.2.2" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml">,</mo><mn id="A6.p8.5.m5.2.2" xref="A6.p8.5.m5.2.2.cmml">1</mn><mo id="A6.p8.5.m5.2.3.3.2.2.2.3" rspace="0.055em" stretchy="false" xref="A6.p8.5.m5.2.3.3.2.2.1.cmml">]</mo></mrow><mo id="A6.p8.5.m5.2.3.3.2.1" rspace="0.222em" xref="A6.p8.5.m5.2.3.3.2.1.cmml">Ã—</mo><msup id="A6.p8.5.m5.2.3.3.2.3" xref="A6.p8.5.m5.2.3.3.2.3.cmml"><mi id="A6.p8.5.m5.2.3.3.2.3.2" xref="A6.p8.5.m5.2.3.3.2.3.2.cmml">â„</mi><mi id="A6.p8.5.m5.2.3.3.2.3.3" xref="A6.p8.5.m5.2.3.3.2.3.3.cmml">d</mi></msup></mrow><mo id="A6.p8.5.m5.2.3.3.1" stretchy="false" xref="A6.p8.5.m5.2.3.3.1.cmml">â†’</mo><msup id="A6.p8.5.m5.2.3.3.3" xref="A6.p8.5.m5.2.3.3.3.cmml"><mi id="A6.p8.5.m5.2.3.3.3.2" xref="A6.p8.5.m5.2.3.3.3.2.cmml">â„</mi><mi id="A6.p8.5.m5.2.3.3.3.3" xref="A6.p8.5.m5.2.3.3.3.3.cmml">d</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p8.5.m5.2b"><apply id="A6.p8.5.m5.2.3.cmml" xref="A6.p8.5.m5.2.3"><ci id="A6.p8.5.m5.2.3.1.cmml" xref="A6.p8.5.m5.2.3.1">:</ci><ci id="A6.p8.5.m5.2.3.2.cmml" xref="A6.p8.5.m5.2.3.2">ğ‘£</ci><apply id="A6.p8.5.m5.2.3.3.cmml" xref="A6.p8.5.m5.2.3.3"><ci id="A6.p8.5.m5.2.3.3.1.cmml" xref="A6.p8.5.m5.2.3.3.1">â†’</ci><apply id="A6.p8.5.m5.2.3.3.2.cmml" xref="A6.p8.5.m5.2.3.3.2"><times id="A6.p8.5.m5.2.3.3.2.1.cmml" xref="A6.p8.5.m5.2.3.3.2.1"></times><interval closure="closed" id="A6.p8.5.m5.2.3.3.2.2.1.cmml" xref="A6.p8.5.m5.2.3.3.2.2.2"><cn id="A6.p8.5.m5.1.1.cmml" type="integer" xref="A6.p8.5.m5.1.1">0</cn><cn id="A6.p8.5.m5.2.2.cmml" type="integer" xref="A6.p8.5.m5.2.2">1</cn></interval><apply id="A6.p8.5.m5.2.3.3.2.3.cmml" xref="A6.p8.5.m5.2.3.3.2.3"><csymbol cd="ambiguous" id="A6.p8.5.m5.2.3.3.2.3.1.cmml" xref="A6.p8.5.m5.2.3.3.2.3">superscript</csymbol><ci id="A6.p8.5.m5.2.3.3.2.3.2.cmml" xref="A6.p8.5.m5.2.3.3.2.3.2">â„</ci><ci id="A6.p8.5.m5.2.3.3.2.3.3.cmml" xref="A6.p8.5.m5.2.3.3.2.3.3">ğ‘‘</ci></apply></apply><apply id="A6.p8.5.m5.2.3.3.3.cmml" xref="A6.p8.5.m5.2.3.3.3"><csymbol cd="ambiguous" id="A6.p8.5.m5.2.3.3.3.1.cmml" xref="A6.p8.5.m5.2.3.3.3">superscript</csymbol><ci id="A6.p8.5.m5.2.3.3.3.2.cmml" xref="A6.p8.5.m5.2.3.3.3.2">â„</ci><ci id="A6.p8.5.m5.2.3.3.3.3.cmml" xref="A6.p8.5.m5.2.3.3.3.3">ğ‘‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p8.5.m5.2c">v:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="A6.p8.5.m5.2d">italic_v : [ 0 , 1 ] Ã— blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> defines an ordinary differential equation known as the Flow ODE:</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p9">
<table class="ltx_equation ltx_eqn_table" id="A6.Ex8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="dx_{i}=v_{t}(x_{i}^{t})dt." class="ltx_Math" display="block" id="A6.Ex8.m1.1"><semantics id="A6.Ex8.m1.1a"><mrow id="A6.Ex8.m1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.cmml"><mrow id="A6.Ex8.m1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.cmml"><mrow id="A6.Ex8.m1.1.1.1.1.3" xref="A6.Ex8.m1.1.1.1.1.3.cmml"><mi id="A6.Ex8.m1.1.1.1.1.3.2" xref="A6.Ex8.m1.1.1.1.1.3.2.cmml">d</mi><mo id="A6.Ex8.m1.1.1.1.1.3.1" xref="A6.Ex8.m1.1.1.1.1.3.1.cmml">â¢</mo><msub id="A6.Ex8.m1.1.1.1.1.3.3" xref="A6.Ex8.m1.1.1.1.1.3.3.cmml"><mi id="A6.Ex8.m1.1.1.1.1.3.3.2" xref="A6.Ex8.m1.1.1.1.1.3.3.2.cmml">x</mi><mi id="A6.Ex8.m1.1.1.1.1.3.3.3" xref="A6.Ex8.m1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="A6.Ex8.m1.1.1.1.1.2" xref="A6.Ex8.m1.1.1.1.1.2.cmml">=</mo><mrow id="A6.Ex8.m1.1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.1.cmml"><msub id="A6.Ex8.m1.1.1.1.1.1.3" xref="A6.Ex8.m1.1.1.1.1.1.3.cmml"><mi id="A6.Ex8.m1.1.1.1.1.1.3.2" xref="A6.Ex8.m1.1.1.1.1.1.3.2.cmml">v</mi><mi id="A6.Ex8.m1.1.1.1.1.1.3.3" xref="A6.Ex8.m1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="A6.Ex8.m1.1.1.1.1.1.2" xref="A6.Ex8.m1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A6.Ex8.m1.1.1.1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml"><mo id="A6.Ex8.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="A6.Ex8.m1.1.1.1.1.1.1.1.1" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml"><mi id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="A6.Ex8.m1.1.1.1.1.1.1.1.1.3" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.Ex8.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="A6.Ex8.m1.1.1.1.1.1.2a" xref="A6.Ex8.m1.1.1.1.1.1.2.cmml">â¢</mo><mi id="A6.Ex8.m1.1.1.1.1.1.4" xref="A6.Ex8.m1.1.1.1.1.1.4.cmml">d</mi><mo id="A6.Ex8.m1.1.1.1.1.1.2b" xref="A6.Ex8.m1.1.1.1.1.1.2.cmml">â¢</mo><mi id="A6.Ex8.m1.1.1.1.1.1.5" xref="A6.Ex8.m1.1.1.1.1.1.5.cmml">t</mi></mrow></mrow><mo id="A6.Ex8.m1.1.1.1.2" lspace="0em" xref="A6.Ex8.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex8.m1.1b"><apply id="A6.Ex8.m1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1"><eq id="A6.Ex8.m1.1.1.1.1.2.cmml" xref="A6.Ex8.m1.1.1.1.1.2"></eq><apply id="A6.Ex8.m1.1.1.1.1.3.cmml" xref="A6.Ex8.m1.1.1.1.1.3"><times id="A6.Ex8.m1.1.1.1.1.3.1.cmml" xref="A6.Ex8.m1.1.1.1.1.3.1"></times><ci id="A6.Ex8.m1.1.1.1.1.3.2.cmml" xref="A6.Ex8.m1.1.1.1.1.3.2">ğ‘‘</ci><apply id="A6.Ex8.m1.1.1.1.1.3.3.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.3.3.1.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.Ex8.m1.1.1.1.1.3.3.2.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3.2">ğ‘¥</ci><ci id="A6.Ex8.m1.1.1.1.1.3.3.3.cmml" xref="A6.Ex8.m1.1.1.1.1.3.3.3">ğ‘–</ci></apply></apply><apply id="A6.Ex8.m1.1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1"><times id="A6.Ex8.m1.1.1.1.1.1.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.2"></times><apply id="A6.Ex8.m1.1.1.1.1.1.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.1.3.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3">subscript</csymbol><ci id="A6.Ex8.m1.1.1.1.1.1.3.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3.2">ğ‘£</ci><ci id="A6.Ex8.m1.1.1.1.1.1.3.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="A6.Ex8.m1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="A6.Ex8.m1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.Ex8.m1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="A6.Ex8.m1.1.1.1.1.1.4.cmml" xref="A6.Ex8.m1.1.1.1.1.1.4">ğ‘‘</ci><ci id="A6.Ex8.m1.1.1.1.1.1.5.cmml" xref="A6.Ex8.m1.1.1.1.1.1.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex8.m1.1c">dx_{i}=v_{t}(x_{i}^{t})dt.</annotation><annotation encoding="application/x-llamapun" id="A6.Ex8.m1.1d">italic_d italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ) italic_d italic_t .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A6.p10">
<p class="ltx_p" id="A6.p10.5">We use <math alttext="\phi_{t}(x_{i})" class="ltx_Math" display="inline" id="A6.p10.1.m1.1"><semantics id="A6.p10.1.m1.1a"><mrow id="A6.p10.1.m1.1.1" xref="A6.p10.1.m1.1.1.cmml"><msub id="A6.p10.1.m1.1.1.3" xref="A6.p10.1.m1.1.1.3.cmml"><mi id="A6.p10.1.m1.1.1.3.2" xref="A6.p10.1.m1.1.1.3.2.cmml">Ï•</mi><mi id="A6.p10.1.m1.1.1.3.3" xref="A6.p10.1.m1.1.1.3.3.cmml">t</mi></msub><mo id="A6.p10.1.m1.1.1.2" xref="A6.p10.1.m1.1.1.2.cmml">â¢</mo><mrow id="A6.p10.1.m1.1.1.1.1" xref="A6.p10.1.m1.1.1.1.1.1.cmml"><mo id="A6.p10.1.m1.1.1.1.1.2" stretchy="false" xref="A6.p10.1.m1.1.1.1.1.1.cmml">(</mo><msub id="A6.p10.1.m1.1.1.1.1.1" xref="A6.p10.1.m1.1.1.1.1.1.cmml"><mi id="A6.p10.1.m1.1.1.1.1.1.2" xref="A6.p10.1.m1.1.1.1.1.1.2.cmml">x</mi><mi id="A6.p10.1.m1.1.1.1.1.1.3" xref="A6.p10.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A6.p10.1.m1.1.1.1.1.3" stretchy="false" xref="A6.p10.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.1.m1.1b"><apply id="A6.p10.1.m1.1.1.cmml" xref="A6.p10.1.m1.1.1"><times id="A6.p10.1.m1.1.1.2.cmml" xref="A6.p10.1.m1.1.1.2"></times><apply id="A6.p10.1.m1.1.1.3.cmml" xref="A6.p10.1.m1.1.1.3"><csymbol cd="ambiguous" id="A6.p10.1.m1.1.1.3.1.cmml" xref="A6.p10.1.m1.1.1.3">subscript</csymbol><ci id="A6.p10.1.m1.1.1.3.2.cmml" xref="A6.p10.1.m1.1.1.3.2">italic-Ï•</ci><ci id="A6.p10.1.m1.1.1.3.3.cmml" xref="A6.p10.1.m1.1.1.3.3">ğ‘¡</ci></apply><apply id="A6.p10.1.m1.1.1.1.1.1.cmml" xref="A6.p10.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A6.p10.1.m1.1.1.1.1.1.1.cmml" xref="A6.p10.1.m1.1.1.1.1">subscript</csymbol><ci id="A6.p10.1.m1.1.1.1.1.1.2.cmml" xref="A6.p10.1.m1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A6.p10.1.m1.1.1.1.1.1.3.cmml" xref="A6.p10.1.m1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.1.m1.1c">\phi_{t}(x_{i})</annotation><annotation encoding="application/x-llamapun" id="A6.p10.1.m1.1d">italic_Ï• start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> to represent the solution of the Flow ODE with the initial condition <math alttext="\phi_{0}(x_{i})=x_{i}" class="ltx_Math" display="inline" id="A6.p10.2.m2.1"><semantics id="A6.p10.2.m2.1a"><mrow id="A6.p10.2.m2.1.1" xref="A6.p10.2.m2.1.1.cmml"><mrow id="A6.p10.2.m2.1.1.1" xref="A6.p10.2.m2.1.1.1.cmml"><msub id="A6.p10.2.m2.1.1.1.3" xref="A6.p10.2.m2.1.1.1.3.cmml"><mi id="A6.p10.2.m2.1.1.1.3.2" xref="A6.p10.2.m2.1.1.1.3.2.cmml">Ï•</mi><mn id="A6.p10.2.m2.1.1.1.3.3" xref="A6.p10.2.m2.1.1.1.3.3.cmml">0</mn></msub><mo id="A6.p10.2.m2.1.1.1.2" xref="A6.p10.2.m2.1.1.1.2.cmml">â¢</mo><mrow id="A6.p10.2.m2.1.1.1.1.1" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml"><mo id="A6.p10.2.m2.1.1.1.1.1.2" stretchy="false" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="A6.p10.2.m2.1.1.1.1.1.1" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml"><mi id="A6.p10.2.m2.1.1.1.1.1.1.2" xref="A6.p10.2.m2.1.1.1.1.1.1.2.cmml">x</mi><mi id="A6.p10.2.m2.1.1.1.1.1.1.3" xref="A6.p10.2.m2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A6.p10.2.m2.1.1.1.1.1.3" stretchy="false" xref="A6.p10.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A6.p10.2.m2.1.1.2" xref="A6.p10.2.m2.1.1.2.cmml">=</mo><msub id="A6.p10.2.m2.1.1.3" xref="A6.p10.2.m2.1.1.3.cmml"><mi id="A6.p10.2.m2.1.1.3.2" xref="A6.p10.2.m2.1.1.3.2.cmml">x</mi><mi id="A6.p10.2.m2.1.1.3.3" xref="A6.p10.2.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.2.m2.1b"><apply id="A6.p10.2.m2.1.1.cmml" xref="A6.p10.2.m2.1.1"><eq id="A6.p10.2.m2.1.1.2.cmml" xref="A6.p10.2.m2.1.1.2"></eq><apply id="A6.p10.2.m2.1.1.1.cmml" xref="A6.p10.2.m2.1.1.1"><times id="A6.p10.2.m2.1.1.1.2.cmml" xref="A6.p10.2.m2.1.1.1.2"></times><apply id="A6.p10.2.m2.1.1.1.3.cmml" xref="A6.p10.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="A6.p10.2.m2.1.1.1.3.1.cmml" xref="A6.p10.2.m2.1.1.1.3">subscript</csymbol><ci id="A6.p10.2.m2.1.1.1.3.2.cmml" xref="A6.p10.2.m2.1.1.1.3.2">italic-Ï•</ci><cn id="A6.p10.2.m2.1.1.1.3.3.cmml" type="integer" xref="A6.p10.2.m2.1.1.1.3.3">0</cn></apply><apply id="A6.p10.2.m2.1.1.1.1.1.1.cmml" xref="A6.p10.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.p10.2.m2.1.1.1.1.1.1.1.cmml" xref="A6.p10.2.m2.1.1.1.1.1">subscript</csymbol><ci id="A6.p10.2.m2.1.1.1.1.1.1.2.cmml" xref="A6.p10.2.m2.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="A6.p10.2.m2.1.1.1.1.1.1.3.cmml" xref="A6.p10.2.m2.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="A6.p10.2.m2.1.1.3.cmml" xref="A6.p10.2.m2.1.1.3"><csymbol cd="ambiguous" id="A6.p10.2.m2.1.1.3.1.cmml" xref="A6.p10.2.m2.1.1.3">subscript</csymbol><ci id="A6.p10.2.m2.1.1.3.2.cmml" xref="A6.p10.2.m2.1.1.3.2">ğ‘¥</ci><ci id="A6.p10.2.m2.1.1.3.3.cmml" xref="A6.p10.2.m2.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.2.m2.1c">\phi_{0}(x_{i})=x_{i}</annotation><annotation encoding="application/x-llamapun" id="A6.p10.2.m2.1d">italic_Ï• start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
By solving this Flow ODE from <math alttext="t=0" class="ltx_Math" display="inline" id="A6.p10.3.m3.1"><semantics id="A6.p10.3.m3.1a"><mrow id="A6.p10.3.m3.1.1" xref="A6.p10.3.m3.1.1.cmml"><mi id="A6.p10.3.m3.1.1.2" xref="A6.p10.3.m3.1.1.2.cmml">t</mi><mo id="A6.p10.3.m3.1.1.1" xref="A6.p10.3.m3.1.1.1.cmml">=</mo><mn id="A6.p10.3.m3.1.1.3" xref="A6.p10.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.3.m3.1b"><apply id="A6.p10.3.m3.1.1.cmml" xref="A6.p10.3.m3.1.1"><eq id="A6.p10.3.m3.1.1.1.cmml" xref="A6.p10.3.m3.1.1.1"></eq><ci id="A6.p10.3.m3.1.1.2.cmml" xref="A6.p10.3.m3.1.1.2">ğ‘¡</ci><cn id="A6.p10.3.m3.1.1.3.cmml" type="integer" xref="A6.p10.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.3.m3.1c">t=0</annotation><annotation encoding="application/x-llamapun" id="A6.p10.3.m3.1d">italic_t = 0</annotation></semantics></math> to <math alttext="t=1" class="ltx_Math" display="inline" id="A6.p10.4.m4.1"><semantics id="A6.p10.4.m4.1a"><mrow id="A6.p10.4.m4.1.1" xref="A6.p10.4.m4.1.1.cmml"><mi id="A6.p10.4.m4.1.1.2" xref="A6.p10.4.m4.1.1.2.cmml">t</mi><mo id="A6.p10.4.m4.1.1.1" xref="A6.p10.4.m4.1.1.1.cmml">=</mo><mn id="A6.p10.4.m4.1.1.3" xref="A6.p10.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.4.m4.1b"><apply id="A6.p10.4.m4.1.1.cmml" xref="A6.p10.4.m4.1.1"><eq id="A6.p10.4.m4.1.1.1.cmml" xref="A6.p10.4.m4.1.1.1"></eq><ci id="A6.p10.4.m4.1.1.2.cmml" xref="A6.p10.4.m4.1.1.2">ğ‘¡</ci><cn id="A6.p10.4.m4.1.1.3.cmml" type="integer" xref="A6.p10.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.4.m4.1c">t=1</annotation><annotation encoding="application/x-llamapun" id="A6.p10.4.m4.1d">italic_t = 1</annotation></semantics></math>, we transform noise into data samples using the approximated velocity fields <math alttext="v_{\theta}(x_{i}^{t},t)" class="ltx_Math" display="inline" id="A6.p10.5.m5.2"><semantics id="A6.p10.5.m5.2a"><mrow id="A6.p10.5.m5.2.2" xref="A6.p10.5.m5.2.2.cmml"><msub id="A6.p10.5.m5.2.2.3" xref="A6.p10.5.m5.2.2.3.cmml"><mi id="A6.p10.5.m5.2.2.3.2" xref="A6.p10.5.m5.2.2.3.2.cmml">v</mi><mi id="A6.p10.5.m5.2.2.3.3" xref="A6.p10.5.m5.2.2.3.3.cmml">Î¸</mi></msub><mo id="A6.p10.5.m5.2.2.2" xref="A6.p10.5.m5.2.2.2.cmml">â¢</mo><mrow id="A6.p10.5.m5.2.2.1.1" xref="A6.p10.5.m5.2.2.1.2.cmml"><mo id="A6.p10.5.m5.2.2.1.1.2" stretchy="false" xref="A6.p10.5.m5.2.2.1.2.cmml">(</mo><msubsup id="A6.p10.5.m5.2.2.1.1.1" xref="A6.p10.5.m5.2.2.1.1.1.cmml"><mi id="A6.p10.5.m5.2.2.1.1.1.2.2" xref="A6.p10.5.m5.2.2.1.1.1.2.2.cmml">x</mi><mi id="A6.p10.5.m5.2.2.1.1.1.2.3" xref="A6.p10.5.m5.2.2.1.1.1.2.3.cmml">i</mi><mi id="A6.p10.5.m5.2.2.1.1.1.3" xref="A6.p10.5.m5.2.2.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.p10.5.m5.2.2.1.1.3" xref="A6.p10.5.m5.2.2.1.2.cmml">,</mo><mi id="A6.p10.5.m5.1.1" xref="A6.p10.5.m5.1.1.cmml">t</mi><mo id="A6.p10.5.m5.2.2.1.1.4" stretchy="false" xref="A6.p10.5.m5.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.p10.5.m5.2b"><apply id="A6.p10.5.m5.2.2.cmml" xref="A6.p10.5.m5.2.2"><times id="A6.p10.5.m5.2.2.2.cmml" xref="A6.p10.5.m5.2.2.2"></times><apply id="A6.p10.5.m5.2.2.3.cmml" xref="A6.p10.5.m5.2.2.3"><csymbol cd="ambiguous" id="A6.p10.5.m5.2.2.3.1.cmml" xref="A6.p10.5.m5.2.2.3">subscript</csymbol><ci id="A6.p10.5.m5.2.2.3.2.cmml" xref="A6.p10.5.m5.2.2.3.2">ğ‘£</ci><ci id="A6.p10.5.m5.2.2.3.3.cmml" xref="A6.p10.5.m5.2.2.3.3">ğœƒ</ci></apply><interval closure="open" id="A6.p10.5.m5.2.2.1.2.cmml" xref="A6.p10.5.m5.2.2.1.1"><apply id="A6.p10.5.m5.2.2.1.1.1.cmml" xref="A6.p10.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="A6.p10.5.m5.2.2.1.1.1.1.cmml" xref="A6.p10.5.m5.2.2.1.1.1">superscript</csymbol><apply id="A6.p10.5.m5.2.2.1.1.1.2.cmml" xref="A6.p10.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="A6.p10.5.m5.2.2.1.1.1.2.1.cmml" xref="A6.p10.5.m5.2.2.1.1.1">subscript</csymbol><ci id="A6.p10.5.m5.2.2.1.1.1.2.2.cmml" xref="A6.p10.5.m5.2.2.1.1.1.2.2">ğ‘¥</ci><ci id="A6.p10.5.m5.2.2.1.1.1.2.3.cmml" xref="A6.p10.5.m5.2.2.1.1.1.2.3">ğ‘–</ci></apply><ci id="A6.p10.5.m5.2.2.1.1.1.3.cmml" xref="A6.p10.5.m5.2.2.1.1.1.3">ğ‘¡</ci></apply><ci id="A6.p10.5.m5.1.1.cmml" xref="A6.p10.5.m5.1.1">ğ‘¡</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p10.5.m5.2c">v_{\theta}(x_{i}^{t},t)</annotation><annotation encoding="application/x-llamapun" id="A6.p10.5.m5.2d">italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , italic_t )</annotation></semantics></math>. During training, the flow-matching objective directly regresses to the target velocity:</p>
<table class="ltx_equation ltx_eqn_table" id="A6.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{v}=\int_{0}^{1}\mathbb{E}\left[\parallel v_{\theta}(x_{i}^{t},t)-%
\dot{\alpha}_{t}x_{i}-\dot{\beta}_{t}\epsilon\parallel^{2}\right]dt," class="ltx_Math" display="block" id="A6.E7.m1.2"><semantics id="A6.E7.m1.2a"><mrow id="A6.E7.m1.2.2.1" xref="A6.E7.m1.2.2.1.1.cmml"><mrow id="A6.E7.m1.2.2.1.1" xref="A6.E7.m1.2.2.1.1.cmml"><msub id="A6.E7.m1.2.2.1.1.3" xref="A6.E7.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A6.E7.m1.2.2.1.1.3.2" xref="A6.E7.m1.2.2.1.1.3.2.cmml">â„’</mi><mi id="A6.E7.m1.2.2.1.1.3.3" xref="A6.E7.m1.2.2.1.1.3.3.cmml">v</mi></msub><mo id="A6.E7.m1.2.2.1.1.2" rspace="0.111em" xref="A6.E7.m1.2.2.1.1.2.cmml">=</mo><mrow id="A6.E7.m1.2.2.1.1.1" xref="A6.E7.m1.2.2.1.1.1.cmml"><msubsup id="A6.E7.m1.2.2.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.2.2.2" xref="A6.E7.m1.2.2.1.1.1.2.2.2.cmml">âˆ«</mo><mn id="A6.E7.m1.2.2.1.1.1.2.2.3" xref="A6.E7.m1.2.2.1.1.1.2.2.3.cmml">0</mn><mn id="A6.E7.m1.2.2.1.1.1.2.3" xref="A6.E7.m1.2.2.1.1.1.2.3.cmml">1</mn></msubsup><mrow id="A6.E7.m1.2.2.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.3.cmml">ğ”¼</mi><mo id="A6.E7.m1.2.2.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.2.cmml">â¢</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.1.2.1.cmml">[</mo><msup id="A6.E7.m1.2.2.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">v</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msubsup id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="A6.E7.m1.1.1" xref="A6.E7.m1.1.1.cmml">t</mi><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.4" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mover accent="true" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml">Î±</mi><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml">Ë™</mo></mover><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">t</mi></msub><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â¢</mo><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">x</mi><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2a" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.cmml"><msub id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.cmml"><mover accent="true" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.cmml"><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2.cmml">Î²</mi><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1.cmml">Ë™</mo></mover><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3.cmml">t</mi></msub><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1.cmml">â¢</mo><mi id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3.cmml">Ïµ</mi></mrow></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="A6.E7.m1.2.2.1.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="A6.E7.m1.2.2.1.1.1.1.1.1.3" xref="A6.E7.m1.2.2.1.1.1.1.1.2.1.cmml">]</mo></mrow><mo id="A6.E7.m1.2.2.1.1.1.1.2a" lspace="0em" xref="A6.E7.m1.2.2.1.1.1.1.2.cmml">â¢</mo><mrow id="A6.E7.m1.2.2.1.1.1.1.4" xref="A6.E7.m1.2.2.1.1.1.1.4.cmml"><mo id="A6.E7.m1.2.2.1.1.1.1.4.1" rspace="0em" xref="A6.E7.m1.2.2.1.1.1.1.4.1.cmml">ğ‘‘</mo><mi id="A6.E7.m1.2.2.1.1.1.1.4.2" xref="A6.E7.m1.2.2.1.1.1.1.4.2.cmml">t</mi></mrow></mrow></mrow></mrow><mo id="A6.E7.m1.2.2.1.2" xref="A6.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.E7.m1.2b"><apply id="A6.E7.m1.2.2.1.1.cmml" xref="A6.E7.m1.2.2.1"><eq id="A6.E7.m1.2.2.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.2"></eq><apply id="A6.E7.m1.2.2.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.3.1.cmml" xref="A6.E7.m1.2.2.1.1.3">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.3.2.cmml" xref="A6.E7.m1.2.2.1.1.3.2">â„’</ci><ci id="A6.E7.m1.2.2.1.1.3.3.cmml" xref="A6.E7.m1.2.2.1.1.3.3">ğ‘£</ci></apply><apply id="A6.E7.m1.2.2.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1"><apply id="A6.E7.m1.2.2.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.2">superscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.2.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.2">subscript</csymbol><int id="A6.E7.m1.2.2.1.1.1.2.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.2.2.2"></int><cn id="A6.E7.m1.2.2.1.1.1.2.2.3.cmml" type="integer" xref="A6.E7.m1.2.2.1.1.1.2.2.3">0</cn></apply><cn id="A6.E7.m1.2.2.1.1.1.2.3.cmml" type="integer" xref="A6.E7.m1.2.2.1.1.1.2.3">1</cn></apply><apply id="A6.E7.m1.2.2.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1"><times id="A6.E7.m1.2.2.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.2"></times><ci id="A6.E7.m1.2.2.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.3">ğ”¼</ci><apply id="A6.E7.m1.2.2.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="A6.E7.m1.2.2.1.1.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1"><minus id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"></minus><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><times id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘£</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><interval closure="open" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1"><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><ci id="A6.E7.m1.1.1.cmml" xref="A6.E7.m1.1.1">ğ‘¡</ci></interval></apply><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><times id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1"></times><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2"><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1">Ë™</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2">ğ›¼</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.2">ğ‘¥</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.3">ğ‘–</ci></apply></apply><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4"><times id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.1"></times><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2">subscript</csymbol><apply id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2"><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.1">Ë™</ci><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.2.2">ğ›½</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.2.3">ğ‘¡</ci></apply><ci id="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4.3">italic-Ïµ</ci></apply></apply></apply><cn id="A6.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="A6.E7.m1.2.2.1.1.1.1.1.1.1.3">2</cn></apply></apply><apply id="A6.E7.m1.2.2.1.1.1.1.4.cmml" xref="A6.E7.m1.2.2.1.1.1.1.4"><csymbol cd="latexml" id="A6.E7.m1.2.2.1.1.1.1.4.1.cmml" xref="A6.E7.m1.2.2.1.1.1.1.4.1">differential-d</csymbol><ci id="A6.E7.m1.2.2.1.1.1.1.4.2.cmml" xref="A6.E7.m1.2.2.1.1.1.1.4.2">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.E7.m1.2c">\mathcal{L}_{v}=\int_{0}^{1}\mathbb{E}\left[\parallel v_{\theta}(x_{i}^{t},t)-%
\dot{\alpha}_{t}x_{i}-\dot{\beta}_{t}\epsilon\parallel^{2}\right]dt,</annotation><annotation encoding="application/x-llamapun" id="A6.E7.m1.2d">caligraphic_L start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT = âˆ« start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT blackboard_E [ âˆ¥ italic_v start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT , italic_t ) - overË™ start_ARG italic_Î± end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - overË™ start_ARG italic_Î² end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_Ïµ âˆ¥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] italic_d italic_t ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A6.p10.6">which is termed the Conditional Flow Matching lossÂ <cite class="ltx_cite ltx_citemacro_citep">(Lipman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib67" title="">2022</a>)</cite>, sharing similarities with the noise prediction or score prediction losses in diffusion models.</p>
</div>
<section class="ltx_paragraph" id="A6.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis of flow matching loss</h4>
<figure class="ltx_figure" id="A6.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="460" id="A6.F9.g1" src="x20.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Comparison between flow matching loss in Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.E7" title="In Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">7</span></a> and diffusion loss in Eq.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S3.E4" title="In 3.3 Diffusion Learning with a Denoising MLP â€£ 3 Methodology â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a> on FID.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p1.1">We experimented to evaluate the performance of flow matching loss using the D-JEPA-B model on the ImageNet1k dataset for image generation, training the model for 300 epochs. The experimental settings were consistent with those described in Sec.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#S4" title="4 Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">4</span></a>. The FID convergence curve is illustrated in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.F9" title="Figure 9 â€£ Analysis of flow matching loss â€£ Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">9</span></a>. As anticipated, the flow matching loss demonstrated a faster convergence rate than the diffusion loss, achieving convergence within approximately 160 epochs.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p2.1">However, it was observed that the flow matching loss encounters difficulties in reducing the FID score during the later stages of training. We hypothesize that this limitation may be attributed to the denoising MLP being too lightweight to manage the continuous-space denoising operations required by flow matching efficiently. This issue can potentially be alleviated by increasing the network capacity of the denoising MLP. Despite this, the images generated using flow matching loss exhibit superior texture quality.</p>
</div>
<figure class="ltx_figure" id="A6.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="124" id="A6.F10.sf1.g1" src="x21.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Diffusion loss</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A6.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="124" id="A6.F10.sf2.g1" src="x22.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Flow matching loss</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Failure cases of diffusion loss in video clip generation. The samples are generated using the D-JEPA-L model trained for 1600 epochs on UCF101 dataset, with 225 auto-regressive steps for sampling 3000 tokens.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p3.1">As illustrated in App.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7" title="Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">G</span></a>, the flow matching loss significantly outperforms the diffusion loss for more challenging tasks. In specific scenarios, the diffusion loss may even lead to training failures, as depicted in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.F10" title="Figure 10 â€£ Analysis of flow matching loss â€£ Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">10</span></a>. Consequently, we adopt the flow-matching loss for the remainder of this paper.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Comprehensive Experiments</h2>
<div class="ltx_para ltx_noindent" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">This section presents detailed experimental procedures and results for D-JEPA across various tasks. It is important to emphasize that <span class="ltx_text ltx_font_italic" id="A7.p1.1.1">our objective is not to achieve state-of-the-art performance on these tasks, as this is beyond the scope of the current study and will be explored in future research.</span> Instead, we aim to demonstrate that D-JEPA is a robust and versatile generative model capable of handling various continuous data types. Consequently, we did not perform extensive hyperparameter tuning; unless otherwise specified, all training settings are consistent with those used for image generation on ImageNet. As noted in AppendixÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6" title="Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">F</span></a>, we employ flow matching loss instead of diffusion loss for all experiments in this section.</p>
</div>
<section class="ltx_subsection" id="A7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Text-to-Audio Generation</h3>
<figure class="ltx_figure" id="A7.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1067" id="A7.F11.g1" src="x23.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Visualizations of the generated waveform over training epochs. From top to bottom, each waveform represents the result sampled every 400 epochs. The corresponding text of the generated speech samples is â€œ<span class="ltx_text ltx_font_italic" id="A7.F11.2.1">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition</span>.â€</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS1.p1">
<p class="ltx_p" id="A7.SS1.p1.1">In this experiment, we adapted D-JEPA-B for speech synthesis, incorporating a phoneme and pitch encoder. To integrate text conditions, we replaced the attention module in the vision transformer with multimodal attention, as first proposed by Â <cite class="ltx_cite ltx_citemacro_cite">Esser etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib32" title="">2024</a>)</cite>. The phoneme vocabulary size is set to 73. For the pitch encoder, the lookup table size is set to 300, and the encoded pitch embedding size is 256, with a hidden channel size of 256.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS1.p2">
<p class="ltx_p" id="A7.SS1.p2.1">We utilized the LJSpeech benchmark datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Ito, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib51" title="">2017</a>)</cite>, which consists of 13,100 audio clips sampled at 22,050 Hz from a female speaker, totaling approximately 24 hours. Text sequences were converted into phoneme sequences using an open-source grapheme-to-phoneme conversion toolÂ <cite class="ltx_cite ltx_citemacro_citep">(Sun etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib100" title="">2019</a>)</cite>. Following common practicesÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib19" title="">2021a</a>; Min etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib73" title="">2021</a>; Zhuo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite>, we preprocessed the speech and text data by (1) extracting the spectrogram with an FFT size of 1024, hop size of 256, and window size of 1024 samples; (2) converting it to a mel-spectrogram with 80 frequency bins; and (3) extracting the F0 (fundamental frequency) from the raw waveform using Parselmouth. Our implementation is based on the open-source project by Â <cite class="ltx_cite ltx_citemacro_cite">Huang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib49" title="">2023a</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS1.p3">
<p class="ltx_p" id="A7.SS1.p3.1">Notably, the diffusion loss did not perform optimally on this small-scale dataset. To better accommodate the varying lengths of sentences, we employed 1D Rotary Position Embedding (RoPE)Â <cite class="ltx_cite ltx_citemacro_citep">(Su etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib99" title="">2024</a>)</cite> as the positional embedding. D-JEPA-B was trained for 134,000 steps, approximately 2,600 epochs, using 4 NVIDIA A100 GPUs with a total batch size of 256 sentences. HiFi-GANÂ <cite class="ltx_cite ltx_citemacro_citep">(Kong etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib59" title="">2020</a>)</cite> (V1) was utilized as the vocoder to synthesize the waveform from the generated mel-spectrogram.</p>
</div>
<section class="ltx_paragraph" id="A7.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<figure class="ltx_figure" id="A7.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A7.F12.g1" src="x24.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Visualizations of the reference and generated waveform. The corresponding texts of generated speech samples is â€œ<span class="ltx_text ltx_font_italic" id="A7.F12.2.1">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition</span>â€.</figcaption>
</figure>
<figure class="ltx_figure" id="A7.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="711" id="A7.F13.g1" src="x25.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Visualizations of the reference and generated mel-spectrograms. The corresponding texts of generated speech samples is â€œ<span class="ltx_text ltx_font_italic" id="A7.F13.2.1">Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition</span>â€.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS1.SSS0.Px1.p1.1">In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F11" title="Figure 11 â€£ G.1 Text-to-Audio Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">11</span></a>, we demonstrate the sampling results of the trained model at intervals of 400 epochs. We observed that after 1,600 epochs, D-JEPA-B can generate relatively clear audio. As training proceeded, the speech quality steadily improved, with pronunciations becoming clearer and the intonation and pauses closely matching those of natural speech. Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F13" title="Figure 13 â€£ Analysis â€£ G.1 Text-to-Audio Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">13</span></a> and Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F12" title="Figure 12 â€£ Analysis â€£ G.1 Text-to-Audio Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">12</span></a> show sampled mel-spectrogram and waveform, respectively. It is evident that after 2,600 epochs of training, the sampled audio closely resembles the reference audio.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>Text-to-Image Generation</h3>
<div class="ltx_para ltx_noindent" id="A7.SS2.p1">
<p class="ltx_p" id="A7.SS2.p1.2">In this experiment, we adapted D-JEPA-L for the task of text-to-image generation. Similar to previous experiments, we incorporated text conditions using multimodal attention. Additionally, we utilized a more powerful VAE model from Â <cite class="ltx_cite ltx_citemacro_cite">Esser etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib32" title="">2024</a>)</cite>. A <math alttext="256\times 256" class="ltx_Math" display="inline" id="A7.SS2.p1.1.m1.1"><semantics id="A7.SS2.p1.1.m1.1a"><mrow id="A7.SS2.p1.1.m1.1.1" xref="A7.SS2.p1.1.m1.1.1.cmml"><mn id="A7.SS2.p1.1.m1.1.1.2" xref="A7.SS2.p1.1.m1.1.1.2.cmml">256</mn><mo id="A7.SS2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="A7.SS2.p1.1.m1.1.1.3" xref="A7.SS2.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.p1.1.m1.1b"><apply id="A7.SS2.p1.1.m1.1.1.cmml" xref="A7.SS2.p1.1.m1.1.1"><times id="A7.SS2.p1.1.m1.1.1.1.cmml" xref="A7.SS2.p1.1.m1.1.1.1"></times><cn id="A7.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS2.p1.1.m1.1.1.2">256</cn><cn id="A7.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="A7.SS2.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p1.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.p1.1.m1.1d">256 Ã— 256</annotation></semantics></math> resolution image is encoded into a latent representation of size <math alttext="16\times 32\times 32" class="ltx_Math" display="inline" id="A7.SS2.p1.2.m2.1"><semantics id="A7.SS2.p1.2.m2.1a"><mrow id="A7.SS2.p1.2.m2.1.1" xref="A7.SS2.p1.2.m2.1.1.cmml"><mn id="A7.SS2.p1.2.m2.1.1.2" xref="A7.SS2.p1.2.m2.1.1.2.cmml">16</mn><mo id="A7.SS2.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="A7.SS2.p1.2.m2.1.1.3" xref="A7.SS2.p1.2.m2.1.1.3.cmml">32</mn><mo id="A7.SS2.p1.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="A7.SS2.p1.2.m2.1.1.4" xref="A7.SS2.p1.2.m2.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.p1.2.m2.1b"><apply id="A7.SS2.p1.2.m2.1.1.cmml" xref="A7.SS2.p1.2.m2.1.1"><times id="A7.SS2.p1.2.m2.1.1.1.cmml" xref="A7.SS2.p1.2.m2.1.1.1"></times><cn id="A7.SS2.p1.2.m2.1.1.2.cmml" type="integer" xref="A7.SS2.p1.2.m2.1.1.2">16</cn><cn id="A7.SS2.p1.2.m2.1.1.3.cmml" type="integer" xref="A7.SS2.p1.2.m2.1.1.3">32</cn><cn id="A7.SS2.p1.2.m2.1.1.4.cmml" type="integer" xref="A7.SS2.p1.2.m2.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p1.2.m2.1c">16\times 32\times 32</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.p1.2.m2.1d">16 Ã— 32 Ã— 32</annotation></semantics></math>, which is then patched with a patch size of 2. We replaced the positional encoding with a 2D RoPE suitable for images for this task. We employed the QWen2-1.5B language modelÂ <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib114" title="">2024a</a>)</cite> as the text encoder, which offers superior text understanding capabilities compared to models like CLIPÂ <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib85" title="">2021</a>)</cite> or T5Â <cite class="ltx_cite ltx_citemacro_citep">(Raffel etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib86" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS2.p2">
<p class="ltx_p" id="A7.SS2.p2.1">We conducted experiments on an internal dataset composed of both public and private data. The public dataset comprises millions of images from Â <cite class="ltx_cite ltx_citemacro_cite">Sun etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib101" title="">2024</a>)</cite>. We performed meticulous data cleaning, referencing the methods used by PixelArtÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib17" title="">2023</a>)</cite> and SD3.0Â <cite class="ltx_cite ltx_citemacro_citep">(Esser etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib32" title="">2024</a>)</cite>. Since we did not intend to explore multi-scale resolution generation at this stage (reserved for future work), we resized all images to a <math alttext="256\times 256" class="ltx_Math" display="inline" id="A7.SS2.p2.1.m1.1"><semantics id="A7.SS2.p2.1.m1.1a"><mrow id="A7.SS2.p2.1.m1.1.1" xref="A7.SS2.p2.1.m1.1.1.cmml"><mn id="A7.SS2.p2.1.m1.1.1.2" xref="A7.SS2.p2.1.m1.1.1.2.cmml">256</mn><mo id="A7.SS2.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="A7.SS2.p2.1.m1.1.1.3" xref="A7.SS2.p2.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.p2.1.m1.1b"><apply id="A7.SS2.p2.1.m1.1.1.cmml" xref="A7.SS2.p2.1.m1.1.1"><times id="A7.SS2.p2.1.m1.1.1.1.cmml" xref="A7.SS2.p2.1.m1.1.1.1"></times><cn id="A7.SS2.p2.1.m1.1.1.2.cmml" type="integer" xref="A7.SS2.p2.1.m1.1.1.2">256</cn><cn id="A7.SS2.p2.1.m1.1.1.3.cmml" type="integer" xref="A7.SS2.p2.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.p2.1.m1.1c">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.p2.1.m1.1d">256 Ã— 256</annotation></semantics></math> resolution for training.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS2.p3">
<p class="ltx_p" id="A7.SS2.p3.1">We trained D-JEPA-L from scratch for approximately 500 epochs (measured by the ImageNet data volume) without additional pre-training. Unlike many diffusion models such as Â <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib17" title="">2023</a>)</cite>, we found that training from scratch yielded satisfactory results for D-JEPA-L; using pre-trained weights from ImageNet resulted in decreased performance, consistent with the findings in Â <cite class="ltx_cite ltx_citemacro_cite">Zhuo etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib128" title="">2024a</a>)</cite>. We conducted this experiment on four workers, each with 8 H800 GPUs. We maintained a total batch size of 2048 with the help of gradient checkpointing techniques.</p>
</div>
<section class="ltx_paragraph" id="A7.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<figure class="ltx_figure" id="A7.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="167" id="A7.F14.g1" src="x26.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Text to image samples during training. From left to right, the results are sampled at intervals of 40 epochs, from the 40th to the 200th epoch. The corresponding prompt: <span class="ltx_text ltx_font_italic" id="A7.F14.2.1">a photo of a backpack below a cake.</span></figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS2.SSS0.Px1.p1.1">In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F14" title="Figure 14 â€£ Analysis â€£ G.2 Text-to-Image Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">14</span></a>, we show the images sampled every 40 epochs during the early training stages (up to 200 epochs). Early in training, D-JEPA tended to generate single objects and struggled to understand multiple objects or spatial relationships. After 120 epochs of training, the model could generally generate single objects well, but various objects were still missing. As training progressed, D-JEPA began generating multiple objects and gradually grasped the correct spatial relationships. We observed that after about 160 epochs, the model could generate high-quality images, as shown in the penultimate image in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F14" title="Figure 14 â€£ Analysis â€£ G.2 Text-to-Image Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">14</span></a>. However, it still struggled to create accurate spatial relationships between objects. For instance, when given the prompt â€a backpack <span class="ltx_text ltx_font_bold" id="A7.SS2.SSS0.Px1.p1.1.1">below</span> a cake,â€ the generated content showed â€a backpack <span class="ltx_text ltx_font_bold" id="A7.SS2.SSS0.Px1.p1.1.2">behind</span> a cake,â€ which is more consistent with common sense. In other words, the model could understand conventional spatial relationships at this stage but still struggled with abstract spatial relationships, especially those not present in the training data. As training continued, the modelâ€™s ability to understand abstract concepts improved, as demonstrated in the last image in the figure, which correctly generated the spatial relationship.</p>
</div>
<figure class="ltx_figure" id="A7.F15">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf1.g1" src="x27.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>A beautiful girl.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf2.g1" src="x28.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Beautiful scene with mountains and rivers in a small village.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf3.g1" src="x29.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>A snowy mountain.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F15.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="191" id="A7.F15.sf4.g1" src="x30.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>A crab made of cheese on a plate.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Samples of text to image generation. Resolution: <math alttext="256\times 256" class="ltx_Math" display="inline" id="A7.F15.2.m1.1"><semantics id="A7.F15.2.m1.1b"><mrow id="A7.F15.2.m1.1.1" xref="A7.F15.2.m1.1.1.cmml"><mn id="A7.F15.2.m1.1.1.2" xref="A7.F15.2.m1.1.1.2.cmml">256</mn><mo id="A7.F15.2.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.F15.2.m1.1.1.1.cmml">Ã—</mo><mn id="A7.F15.2.m1.1.1.3" xref="A7.F15.2.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.F15.2.m1.1c"><apply id="A7.F15.2.m1.1.1.cmml" xref="A7.F15.2.m1.1.1"><times id="A7.F15.2.m1.1.1.1.cmml" xref="A7.F15.2.m1.1.1.1"></times><cn id="A7.F15.2.m1.1.1.2.cmml" type="integer" xref="A7.F15.2.m1.1.1.2">256</cn><cn id="A7.F15.2.m1.1.1.3.cmml" type="integer" xref="A7.F15.2.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.F15.2.m1.1d">256\times 256</annotation><annotation encoding="application/x-llamapun" id="A7.F15.2.m1.1e">256 Ã— 256</annotation></semantics></math>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="A7.SS2.SSS0.Px1.p2.1">In Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F15" title="Figure 15 â€£ Analysis â€£ G.2 Text-to-Image Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">15</span></a>, we demonstrate the modelâ€™s capabilities to generate high-quality images after <span class="ltx_text ltx_font_italic" id="A7.SS2.SSS0.Px1.p2.1.1">300</span> training epochs. D-JEPA can already produce detailed portraits and rich scenes, although some local artifacts still exist. We believe that by using larger models, conducting more extensive training, and utilizing higher-resolution data, D-JEPAâ€™s text-to-image generation capabilities will be significantly enhanced.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.3 </span>Class Conditioned Video Generation</h3>
<div class="ltx_para ltx_noindent" id="A7.SS3.p1">
<p class="ltx_p" id="A7.SS3.p1.1">In this experiment, we adapted D-JEPA-L for class-conditioned video generation. We utilized the open-source VideoVAE from Â <cite class="ltx_cite ltx_citemacro_cite">Yang etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib115" title="">2024b</a>)</cite>, which compresses the videoâ€™s temporal and spatial resolutions by factors of 4 and 8, significantly reducing the computational burden during video generation. We divided each video frame into tokens with a patch size of 2 along the spatial and four along the temporal dimensions. Empirically, we found that using a larger patch size in the temporal dimension helps the model learn more consistent motion.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS3.p2">
<p class="ltx_p" id="A7.SS3.p2.4">We conducted the experiments on the UCF101 datasetÂ <cite class="ltx_cite ltx_citemacro_citep">(Soomro, <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib98" title="">2012</a>)</cite>, a widely recognized benchmark in human action recognition, consisting of 13,320 video clips spanning 101 action categories, including a diverse range of activities such as sports, musical instruments, and human-object interactions. This richly annotated dataset covers a broad spectrum of real-world scenarios captured under varying conditions, making it an essential resource for advancing and evaluating video generation methods. It has been widely used in recent worksÂ <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib71" title="">2024b</a>; Ho etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib48" title="">2022</a>)</cite>. We trained our model on the original <math alttext="240\times 320" class="ltx_Math" display="inline" id="A7.SS3.p2.1.m1.1"><semantics id="A7.SS3.p2.1.m1.1a"><mrow id="A7.SS3.p2.1.m1.1.1" xref="A7.SS3.p2.1.m1.1.1.cmml"><mn id="A7.SS3.p2.1.m1.1.1.2" xref="A7.SS3.p2.1.m1.1.1.2.cmml">240</mn><mo id="A7.SS3.p2.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="A7.SS3.p2.1.m1.1.1.3" xref="A7.SS3.p2.1.m1.1.1.3.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.1.m1.1b"><apply id="A7.SS3.p2.1.m1.1.1.cmml" xref="A7.SS3.p2.1.m1.1.1"><times id="A7.SS3.p2.1.m1.1.1.1.cmml" xref="A7.SS3.p2.1.m1.1.1.1"></times><cn id="A7.SS3.p2.1.m1.1.1.2.cmml" type="integer" xref="A7.SS3.p2.1.m1.1.1.2">240</cn><cn id="A7.SS3.p2.1.m1.1.1.3.cmml" type="integer" xref="A7.SS3.p2.1.m1.1.1.3">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.1.m1.1c">240\times 320</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.1.m1.1d">240 Ã— 320</annotation></semantics></math> resolution. We sampled eight frames per second to generate 20-second videos, totaling 160 frames. We used zero padding for videos shorter than 20 seconds to align the number of frames. During training, each input video clip was sized at <math alttext="160\times 240\times 320" class="ltx_Math" display="inline" id="A7.SS3.p2.2.m2.1"><semantics id="A7.SS3.p2.2.m2.1a"><mrow id="A7.SS3.p2.2.m2.1.1" xref="A7.SS3.p2.2.m2.1.1.cmml"><mn id="A7.SS3.p2.2.m2.1.1.2" xref="A7.SS3.p2.2.m2.1.1.2.cmml">160</mn><mo id="A7.SS3.p2.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="A7.SS3.p2.2.m2.1.1.3" xref="A7.SS3.p2.2.m2.1.1.3.cmml">240</mn><mo id="A7.SS3.p2.2.m2.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="A7.SS3.p2.2.m2.1.1.4" xref="A7.SS3.p2.2.m2.1.1.4.cmml">320</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.2.m2.1b"><apply id="A7.SS3.p2.2.m2.1.1.cmml" xref="A7.SS3.p2.2.m2.1.1"><times id="A7.SS3.p2.2.m2.1.1.1.cmml" xref="A7.SS3.p2.2.m2.1.1.1"></times><cn id="A7.SS3.p2.2.m2.1.1.2.cmml" type="integer" xref="A7.SS3.p2.2.m2.1.1.2">160</cn><cn id="A7.SS3.p2.2.m2.1.1.3.cmml" type="integer" xref="A7.SS3.p2.2.m2.1.1.3">240</cn><cn id="A7.SS3.p2.2.m2.1.1.4.cmml" type="integer" xref="A7.SS3.p2.2.m2.1.1.4">320</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.2.m2.1c">160\times 240\times 320</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.2.m2.1d">160 Ã— 240 Ã— 320</annotation></semantics></math>, yielding a latent embedding with <math alttext="40\times 30\times 40" class="ltx_Math" display="inline" id="A7.SS3.p2.3.m3.1"><semantics id="A7.SS3.p2.3.m3.1a"><mrow id="A7.SS3.p2.3.m3.1.1" xref="A7.SS3.p2.3.m3.1.1.cmml"><mn id="A7.SS3.p2.3.m3.1.1.2" xref="A7.SS3.p2.3.m3.1.1.2.cmml">40</mn><mo id="A7.SS3.p2.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.3.m3.1.1.1.cmml">Ã—</mo><mn id="A7.SS3.p2.3.m3.1.1.3" xref="A7.SS3.p2.3.m3.1.1.3.cmml">30</mn><mo id="A7.SS3.p2.3.m3.1.1.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.3.m3.1.1.1.cmml">Ã—</mo><mn id="A7.SS3.p2.3.m3.1.1.4" xref="A7.SS3.p2.3.m3.1.1.4.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.3.m3.1b"><apply id="A7.SS3.p2.3.m3.1.1.cmml" xref="A7.SS3.p2.3.m3.1.1"><times id="A7.SS3.p2.3.m3.1.1.1.cmml" xref="A7.SS3.p2.3.m3.1.1.1"></times><cn id="A7.SS3.p2.3.m3.1.1.2.cmml" type="integer" xref="A7.SS3.p2.3.m3.1.1.2">40</cn><cn id="A7.SS3.p2.3.m3.1.1.3.cmml" type="integer" xref="A7.SS3.p2.3.m3.1.1.3">30</cn><cn id="A7.SS3.p2.3.m3.1.1.4.cmml" type="integer" xref="A7.SS3.p2.3.m3.1.1.4">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.3.m3.1c">40\times 30\times 40</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.3.m3.1d">40 Ã— 30 Ã— 40</annotation></semantics></math>, and subsequently patched into <math alttext="10\times 15\times 20=3000" class="ltx_Math" display="inline" id="A7.SS3.p2.4.m4.1"><semantics id="A7.SS3.p2.4.m4.1a"><mrow id="A7.SS3.p2.4.m4.1.1" xref="A7.SS3.p2.4.m4.1.1.cmml"><mrow id="A7.SS3.p2.4.m4.1.1.2" xref="A7.SS3.p2.4.m4.1.1.2.cmml"><mn id="A7.SS3.p2.4.m4.1.1.2.2" xref="A7.SS3.p2.4.m4.1.1.2.2.cmml">10</mn><mo id="A7.SS3.p2.4.m4.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.4.m4.1.1.2.1.cmml">Ã—</mo><mn id="A7.SS3.p2.4.m4.1.1.2.3" xref="A7.SS3.p2.4.m4.1.1.2.3.cmml">15</mn><mo id="A7.SS3.p2.4.m4.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="A7.SS3.p2.4.m4.1.1.2.1.cmml">Ã—</mo><mn id="A7.SS3.p2.4.m4.1.1.2.4" xref="A7.SS3.p2.4.m4.1.1.2.4.cmml">20</mn></mrow><mo id="A7.SS3.p2.4.m4.1.1.1" xref="A7.SS3.p2.4.m4.1.1.1.cmml">=</mo><mn id="A7.SS3.p2.4.m4.1.1.3" xref="A7.SS3.p2.4.m4.1.1.3.cmml">3000</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.p2.4.m4.1b"><apply id="A7.SS3.p2.4.m4.1.1.cmml" xref="A7.SS3.p2.4.m4.1.1"><eq id="A7.SS3.p2.4.m4.1.1.1.cmml" xref="A7.SS3.p2.4.m4.1.1.1"></eq><apply id="A7.SS3.p2.4.m4.1.1.2.cmml" xref="A7.SS3.p2.4.m4.1.1.2"><times id="A7.SS3.p2.4.m4.1.1.2.1.cmml" xref="A7.SS3.p2.4.m4.1.1.2.1"></times><cn id="A7.SS3.p2.4.m4.1.1.2.2.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.2.2">10</cn><cn id="A7.SS3.p2.4.m4.1.1.2.3.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.2.3">15</cn><cn id="A7.SS3.p2.4.m4.1.1.2.4.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.2.4">20</cn></apply><cn id="A7.SS3.p2.4.m4.1.1.3.cmml" type="integer" xref="A7.SS3.p2.4.m4.1.1.3">3000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.p2.4.m4.1c">10\times 15\times 20=3000</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.p2.4.m4.1d">10 Ã— 15 Ã— 20 = 3000</annotation></semantics></math> tokens. During sampling, we completed video generation in 64 steps. We trained D-JEPA-L from scratch on four workers, each equipped with 8 H800 GPUs, maintaining a global batch size of 512. We also utilized gradient checkpointing to reduce the demand for GPU memory.</p>
</div>
<figure class="ltx_table" id="A7.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T9.1" style="width:433.6pt;height:12.2pt;vertical-align:-0.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-436.5pt,12.0pt) scale(0.331840363944817,0.331840363944817) ;">
<table class="ltx_tabular ltx_align_middle" id="A7.T9.1.1">
<tr class="ltx_tr" id="A7.T9.1.1.1">
<td class="ltx_td ltx_border_r" id="A7.T9.1.1.1.2"></td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.3">DIGANÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib119" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.4">StyleGAN-VÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib94" title="">2022</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.1">Latte<sup class="ltx_sup" id="A7.T9.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="A7.T9.1.1.1.1.1.1">â‹†</span></sup>Â <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib71" title="">2024b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.5">LVDMÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib45" title="">2022b</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.6">MoStGAN-VÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib93" title="">2023</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.7">PVDMÂ <cite class="ltx_cite ltx_citemacro_citeyearpar">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib120" title="">2023c</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="A7.T9.1.1.1.8" style="background-color:#ECF4FF;"><span class="ltx_text" id="A7.T9.1.1.1.8.1" style="background-color:#ECF4FF;">D-JEPA</span></td>
</tr>
<tr class="ltx_tr" id="A7.T9.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A7.T9.1.1.2.1">FVD-16</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.2">1630.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.3">1431.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.4">333.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.5">372.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.6">1380.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.7">1141.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T9.1.1.2.8" style="background-color:#ECF4FF;"><span class="ltx_text" id="A7.T9.1.1.2.8.1" style="background-color:#ECF4FF;">365.2</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Quantitative comparisons of short video generation on UCF101. <sup class="ltx_sup" id="A7.T9.5.1"><span class="ltx_text ltx_font_italic" id="A7.T9.5.1.1">â‹†</span></sup> indicates training on additional image data.</figcaption>
</figure>
<figure class="ltx_figure" id="A7.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="251" id="A7.F16.g1" src="x31.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>The training curve of flow matching loss on UCF101.</figcaption>
</figure>
<section class="ltx_paragraph" id="A7.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis</h4>
<div class="ltx_para ltx_noindent" id="A7.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS3.SSS0.Px1.p1.1">Current video generation models based on diffusion typically require pre-training or joint training on images and videos. We found this approach unnecessary for video generation; instead, it introduces an artificial separation between spatial and temporal aspects, hindering motion generation. The D-JEPA-based video generation model is trained directly on videos, treating all tokens as standard tokens without incorporating 3D attention or other structural designs. These straightforward yet effective mechanisms enable D-JEPA to generate videos more holistically. Since D-JEPA randomly generates the next token from the entire token sequence, it captures the overall video quality more effectively. It decides when to terminate video generation, thereby avoiding the production of redundant video segments, as illustrated in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A6.F10" title="Figure 10 â€£ Analysis of flow matching loss â€£ Appendix F Flow Matching Loss â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">10</span></a>. Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F16" title="Figure 16 â€£ G.3 Class Conditioned Video Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">16</span></a> also indicates that D-JEPA maintains stability throughout the training process. We also present the FVD metrics in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.T9" title="Table 9 â€£ G.3 Class Conditioned Video Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">9</span></a>, where D-JEPA achieves results second only to LatteÂ <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib71" title="">2024b</a>)</cite>, which is trained on additional image data.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A7.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.4 </span>Multi-Modal Generation</h3>
<div class="ltx_para ltx_noindent" id="A7.SS4.p1">
<p class="ltx_p" id="A7.SS4.p1.1">In this experiment, we aim to demonstrate the potential of D-JEPA as a unified multimodal model. This is an ambitious attempt, as D-JEPA can generate text using <span class="ltx_text ltx_font_italic" id="A7.SS4.p1.1.1">next token prediction</span> and create images, videos, etc., using <span class="ltx_text ltx_font_italic" id="A7.SS4.p1.1.2">next set of tokens prediction</span>. Essentially, we adopted the design philosophy of TransfusionÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite> but replaced the diffusion model with the D-JEPA model.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS4.p2">
<p class="ltx_p" id="A7.SS4.p2.1">To simplify the task, we constructed a model that simultaneously generates text and images. Unlike the text-to-image generation described in App.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.SS2" title="G.2 Text-to-Image Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">G.2</span></a>, image generation in the multimodal mode does not rely on any text embedding model. Text and images are directly used as inputs to the model, which then simultaneously predicts both text and image.</p>
</div>
<figure class="ltx_figure" id="A7.F17">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="314" id="A7.F17.1.g1" src="x32.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="314" id="A7.F17.2.g1" src="x33.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="314" id="A7.F17.3.g1" src="x34.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="315" id="A7.F17.4.g1" src="x35.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="338" id="A7.F17.5.g1" src="x36.png" width="761"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A7.F17.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="346" id="A7.F17.6.g1" src="x37.png" width="761"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Samples of text to image generation by multi-modal models build on the top of D-JEPA.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS4.p3">
<p class="ltx_p" id="A7.SS4.p3.1">During the sampling process, we input the image caption that needs to be generated and let the network continuously predict the next tokens until it samples a â€œ<math alttext="&lt;|\textit{visual\_start}|&gt;" class="ltx_Math" display="inline" id="A7.SS4.p3.1.m1.1"><semantics id="A7.SS4.p3.1.m1.1a"><mrow id="A7.SS4.p3.1.m1.1.2" xref="A7.SS4.p3.1.m1.1.2.cmml"><mi id="A7.SS4.p3.1.m1.1.2.2" xref="A7.SS4.p3.1.m1.1.2.2.cmml"></mi><mo id="A7.SS4.p3.1.m1.1.2.3" xref="A7.SS4.p3.1.m1.1.2.3.cmml">&lt;</mo><mrow id="A7.SS4.p3.1.m1.1.2.4.2" xref="A7.SS4.p3.1.m1.1.2.4.1.cmml"><mo id="A7.SS4.p3.1.m1.1.2.4.2.1" stretchy="false" xref="A7.SS4.p3.1.m1.1.2.4.1.1.cmml">|</mo><mtext class="ltx_mathvariant_italic" id="A7.SS4.p3.1.m1.1.1" xref="A7.SS4.p3.1.m1.1.1a.cmml">visual_start</mtext><mo id="A7.SS4.p3.1.m1.1.2.4.2.2" stretchy="false" xref="A7.SS4.p3.1.m1.1.2.4.1.1.cmml">|</mo></mrow><mo id="A7.SS4.p3.1.m1.1.2.5" xref="A7.SS4.p3.1.m1.1.2.5.cmml">&gt;</mo><mi id="A7.SS4.p3.1.m1.1.2.6" xref="A7.SS4.p3.1.m1.1.2.6.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.1.m1.1b"><apply id="A7.SS4.p3.1.m1.1.2.cmml" xref="A7.SS4.p3.1.m1.1.2"><and id="A7.SS4.p3.1.m1.1.2a.cmml" xref="A7.SS4.p3.1.m1.1.2"></and><apply id="A7.SS4.p3.1.m1.1.2b.cmml" xref="A7.SS4.p3.1.m1.1.2"><lt id="A7.SS4.p3.1.m1.1.2.3.cmml" xref="A7.SS4.p3.1.m1.1.2.3"></lt><csymbol cd="latexml" id="A7.SS4.p3.1.m1.1.2.2.cmml" xref="A7.SS4.p3.1.m1.1.2.2">absent</csymbol><apply id="A7.SS4.p3.1.m1.1.2.4.1.cmml" xref="A7.SS4.p3.1.m1.1.2.4.2"><abs id="A7.SS4.p3.1.m1.1.2.4.1.1.cmml" xref="A7.SS4.p3.1.m1.1.2.4.2.1"></abs><ci id="A7.SS4.p3.1.m1.1.1a.cmml" xref="A7.SS4.p3.1.m1.1.1"><mtext class="ltx_mathvariant_italic" id="A7.SS4.p3.1.m1.1.1.cmml" xref="A7.SS4.p3.1.m1.1.1">visual_start</mtext></ci></apply></apply><apply id="A7.SS4.p3.1.m1.1.2c.cmml" xref="A7.SS4.p3.1.m1.1.2"><gt id="A7.SS4.p3.1.m1.1.2.5.cmml" xref="A7.SS4.p3.1.m1.1.2.5"></gt><share href="https://arxiv.org/html/2410.03755v1#A7.SS4.p3.1.m1.1.2.4.cmml" id="A7.SS4.p3.1.m1.1.2d.cmml" xref="A7.SS4.p3.1.m1.1.2"></share><csymbol cd="latexml" id="A7.SS4.p3.1.m1.1.2.6.cmml" xref="A7.SS4.p3.1.m1.1.2.6">absent</csymbol></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.1.m1.1c">&lt;|\textit{visual\_start}|&gt;</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.1.m1.1d">&lt; | visual_start | &gt;</annotation></semantics></math>â€ control token. Then, it switches to the next set of tokens prediction mode to complete the sampling of the entire image. The specific sampling process and training details follow the methodology described by Â <cite class="ltx_cite ltx_citemacro_cite">Zhou etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite>. We showcase the image generation effects of this novel architecture in Fig.Â <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#A7.F17" title="Figure 17 â€£ G.4 Multi-Modal Generation â€£ Appendix G Comprehensive Experiments â€£ Denoising with a Joint-Embedding Predictive Architecture"><span class="ltx_text ltx_ref_tag">17</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS4.p4">
<p class="ltx_p" id="A7.SS4.p4.1">Empirically, we found that the multimodal model built with D-JEPA can more effectively couple discrete text and other continuous data types in terms of architecture and engineering implementation. Further exploration of this field will be presented in future work.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Limitations</h2>
<section class="ltx_paragraph" id="A8.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Potential performance bottleneck from denoising MLP.</h4>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A8.SS0.SSS0.Px1.p1.1">In the D-JEPA framework, the context encoder, target encoder, and feature predictor all utilize standard visual transformer structures. This work and numerous other studies extensively validated the scalability and capacity for scaling up these structures, suggesting significant potential for D-JEPA. However, diffusion or flow matching loss is implemented using a simple Multi-Layer Perceptron (MLP) structure. Although it is theoretically proven that a 3-layer MLP can fit any function, we have observed in practice that the MLP may become a bottleneck for the final performance of the D-JEPA model. More critically, our experiments indicate that increasing the number of MLP layers or widening the MLP dimensions does not significantly improve performance. Recent works, such as KANÂ <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib68" title="">2024</a>)</cite>, have demonstrated significant advantages over MLPs in various tasks. We also attempted to construct a network of comparable scale using KAN, but so far, it has not resulted in a significant performance improvement. While the current MLP structure has achieved satisfactory results in our experiments, exploring alternative network structures to replace the MLP remains a crucial area for further investigation.</p>
</div>
</section>
<section class="ltx_paragraph" id="A8.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Efficiency issues due to bi-directional attention.</h4>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p1.1">Although D-JEPA employs a generalized next-token prediction strategy, its primary structure is entirely realized through visual transformers, which use bi-directional attention during training and inference. This prevents highly effective key-value caching strategy based on causal attention to reduce computation. Notably, in the feature predictor network, we train with all masked and context tokens together using bi-directional attention. This means that each token must continuously attend to information from context and masked tokens. This behavior during training forces us to feed all tokens into the network simultaneously during sampling, especially at the beginning, leading to substantial unnecessary computational overhead. Simple estimates suggest that this process can result in up to <math alttext="50\%" class="ltx_Math" display="inline" id="A8.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="A8.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="A8.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">50</mn><mo id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A8.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.1">percent</csymbol><cn id="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="A8.SS0.SSS0.Px2.p1.1.m1.1.1.2">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A8.SS0.SSS0.Px2.p1.1.m1.1c">50\%</annotation><annotation encoding="application/x-llamapun" id="A8.SS0.SSS0.Px2.p1.1.m1.1d">50 %</annotation></semantics></math> useless computation for the feature predictor in extreme cases.</p>
</div>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p2.1">Intuitively, when predicting the features of masked tokens, we should only need information from context tokens without attending to other masked tokens. This would allow us to avoid feeding all masked tokens into the network during inference, significantly reducing extra computational costs. Based on this, we attempted to develop a new attention mechanism during training. In this approach, the attention for masked tokens in the feature predictor is restricted to all context tokens and itself, while context tokens always attend to all context tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="A8.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="A8.SS0.SSS0.Px2.p3.1">Surprisingly, training with this new attention mechanism did not effectively reduce the FID on ImageNet (FID remained above 50 after 160 epochs). This aligns with findings in <cite class="ltx_cite ltx_citemacro_cite">Zhou etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib126" title="">2024</a>)</cite>, emphasizing that diffusion models must use bi-directional attention during training to ensure effectiveness. Similar observations were made in the MARÂ <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03755v1#bib.bib66" title="">2024</a>)</cite> context. Therefore, improving the efficiency of the attention module during training and inference for D-JEPA remains a critical issue.</p>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 05:55:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
