<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.15357] Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection</title><meta property="og:description" content="New 3+1D high-resolution radar sensors are gaining importance for 3D object detection in the automotive domain due to their relative affordability and improved detection compared to classic low-resolution radar sensorsâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.15357">

<!--Generated on Wed Feb 28 09:57:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
<span id="id1.id1" class="ltx_text">Ego-Motion Estimation and Dynamic Motion Separation from 3D Point</span> Clouds for Accumulating Data and Improving 3D Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Patrick Palmer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> TU Dortmund
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Institute of Control Theory and Systems Engineering
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 44227 Dortmund
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break">patrick.palmer@tu-dortmund.de
<br class="ltx_break">Martin KrÃ¼ger
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> TU Dortmund
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Institute of Control Theory and Systems Engineering
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 44227 Dortmund
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<br class="ltx_break">martin2.krueger@tu-dortmund.de
<br class="ltx_break">Dr. Richard Altendorfer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> ZF Group
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 56070 Koblenz
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> richard.altendorfer@zf.com
<br class="ltx_break">Univ.-Prof. Dr.-Ing. Prof. h.c. Dr. h.c. Torsten Bertram
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> TU Dortmund
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Institute of Control Theory and Systems Engineering
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 44227 Dortmund
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> torsten.bertram@tu-dortmund.de
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">New 3+1D high-resolution radar sensors are gaining importance for 3D object detection in the automotive domain due to their relative affordability and improved detection compared to classic low-resolution radar sensors. One limitation of high-resolution radar sensors, compared to lidar sensors, is the sparsity of the generated point cloud. This sparsity could be partially overcome by accumulating radar point clouds of subsequent time steps. This contribution analyzes limitations of accumulating radar point clouds on the View-of-Delft dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. By employing different ego-motion estimation approaches, the datasetâ€™s inherent constraints, and possible solutions are analyzed. Additionally, a learning-based instance motion estimation approach is deployed to investigate the influence of dynamic motion on the accumulated point cloud for object detection. Experiments document an improved object detection performance by applying an ego-motion estimation and dynamic motion correction approach.</p>
</div>
<section id="S1" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.3" class="ltx_p">One of the critical challenges of automating vehicles and the driving process is the perception of the environment. Precise knowledge of the traffic scene is necessary to make well-informed decisions on the automated vehicleâ€™s path planning and react adequately to sudden actions of other traffic participants. False, missing or imprecise detections entail errors in the environment model. This increases the risk of accidents and limits the time horizon for safe and comfortable vehicle path planning. Different sensor modalities are utilized in research and production vehicles for environment perception. Research vehicles mainly use high-resolution lidars due to their high information density and accuracy, whereas series production vehicles primarily use low-cost sensors like radars and cameras. An emerging sensor technology that is supposed to bridge the gap between lidar and traditional low-resolution radar sensors are 3+1D high-resolution radar sensors. Compared to traditional radars, these high-resolution radar sensors also measure the elevation angle and generate a denser point cloud while preserving the advantages of radar sensors like the direct estimation of the relative radial velocity <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S1.p1.1.m1.1a"><msub id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml"><mi id="S1.p1.1.m1.1.1.2" xref="S1.p1.1.m1.1.1.2.cmml">v</mi><mrow id="S1.p1.1.m1.1.1.3" xref="S1.p1.1.m1.1.1.3.cmml"><mi id="S1.p1.1.m1.1.1.3.2" xref="S1.p1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S1.p1.1.m1.1.1.3.1" xref="S1.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S1.p1.1.m1.1.1.3.3" xref="S1.p1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><apply id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p1.1.m1.1.1.1.cmml" xref="S1.p1.1.m1.1.1">subscript</csymbol><ci id="S1.p1.1.m1.1.1.2.cmml" xref="S1.p1.1.m1.1.1.2">ğ‘£</ci><apply id="S1.p1.1.m1.1.1.3.cmml" xref="S1.p1.1.m1.1.1.3"><times id="S1.p1.1.m1.1.1.3.1.cmml" xref="S1.p1.1.m1.1.1.3.1"></times><ci id="S1.p1.1.m1.1.1.3.2.cmml" xref="S1.p1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S1.p1.1.m1.1.1.3.3.cmml" xref="S1.p1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">v_{rr}</annotation></semantics></math>, robustness against adverse weather conditions, and relatively low cost. Despite improvements in radar technology, currently available 3+1D radar sensors still suffer from noisy measurements and relatively sparse point clouds (compared to lidar). These limitations constrain the perception performance and thus affect the following modules (and their performance) in an automated driving stack. A common strategy to overcome the sparsity of low-resolution lidar and radar point clouds is the aggregation of information over concurrent time steps by accumulation. This yields a denser point cloud that can be used for perception tasks like 3D object detection.
For static objects, an accumulation can be done by transforming point positions from the previous to the current coordinate frame using the ego-motion alone. Nowadays, ego-motion is mostly estimated by combining GPS, wheel odometry, and inertial measurements (angular rates and accelerations) and is available for most public datasets. Targets from dynamic objects, such as reflections from cars, pedestrians, and cyclists, must be considered separately. A naive accumulation of these points based on the ego-motion alone results in an error, represented by trailing points behind the object. An example can be seen in Fig. <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the bicycle on the bottom left (ID: VIII) has a tail of points outside the bounding box. Due to the radar sensorâ€™s direct measurement of radar radial velocity <math id="S1.p1.2.m2.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S1.p1.2.m2.1a"><msub id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml"><mi id="S1.p1.2.m2.1.1.2" xref="S1.p1.2.m2.1.1.2.cmml">v</mi><mrow id="S1.p1.2.m2.1.1.3" xref="S1.p1.2.m2.1.1.3.cmml"><mi id="S1.p1.2.m2.1.1.3.2" xref="S1.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S1.p1.2.m2.1.1.3.1" xref="S1.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S1.p1.2.m2.1.1.3.3" xref="S1.p1.2.m2.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><apply id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S1.p1.2.m2.1.1.1.cmml" xref="S1.p1.2.m2.1.1">subscript</csymbol><ci id="S1.p1.2.m2.1.1.2.cmml" xref="S1.p1.2.m2.1.1.2">ğ‘£</ci><apply id="S1.p1.2.m2.1.1.3.cmml" xref="S1.p1.2.m2.1.1.3"><times id="S1.p1.2.m2.1.1.3.1.cmml" xref="S1.p1.2.m2.1.1.3.1"></times><ci id="S1.p1.2.m2.1.1.3.2.cmml" xref="S1.p1.2.m2.1.1.3.2">ğ‘Ÿ</ci><ci id="S1.p1.2.m2.1.1.3.3.cmml" xref="S1.p1.2.m2.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">v_{rr}</annotation></semantics></math>, an accurate distinction between static and dynamic points is possible <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. The <math id="S1.p1.3.m3.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S1.p1.3.m3.1a"><msub id="S1.p1.3.m3.1.1" xref="S1.p1.3.m3.1.1.cmml"><mi id="S1.p1.3.m3.1.1.2" xref="S1.p1.3.m3.1.1.2.cmml">v</mi><mrow id="S1.p1.3.m3.1.1.3" xref="S1.p1.3.m3.1.1.3.cmml"><mi id="S1.p1.3.m3.1.1.3.2" xref="S1.p1.3.m3.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S1.p1.3.m3.1.1.3.1" xref="S1.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S1.p1.3.m3.1.1.3.3" xref="S1.p1.3.m3.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.p1.3.m3.1b"><apply id="S1.p1.3.m3.1.1.cmml" xref="S1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S1.p1.3.m3.1.1.1.cmml" xref="S1.p1.3.m3.1.1">subscript</csymbol><ci id="S1.p1.3.m3.1.1.2.cmml" xref="S1.p1.3.m3.1.1.2">ğ‘£</ci><apply id="S1.p1.3.m3.1.1.3.cmml" xref="S1.p1.3.m3.1.1.3"><times id="S1.p1.3.m3.1.1.3.1.cmml" xref="S1.p1.3.m3.1.1.3.1"></times><ci id="S1.p1.3.m3.1.1.3.2.cmml" xref="S1.p1.3.m3.1.1.3.2">ğ‘Ÿ</ci><ci id="S1.p1.3.m3.1.1.3.3.cmml" xref="S1.p1.3.m3.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.3.m3.1c">v_{rr}</annotation></semantics></math> can additionally be used for estimating the velocity over ground of objects. Considering the motion of dynamic objects when accumulating point clouds from subsequent frames leads to improved consistency of the accumulated point cloud. Hence, the accuracy of object detection approaches applied to the point cloud increases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2308.15357/assets/image_frame4933.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="677" height="193" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Birdâ€™s eye view perspective of a traffic scene visualizing an aggregated point cloud, accumulated over five frames. The ego-vehicle is located on the left, represented by the colored coordinate system indicating the sensor mounting position (viewing towards the right). Orange boxes represent annotated ground truth bounding boxes and the purple rectangle indicates a manually added ground truth bounding box. The roman numerals mark the objects identifier (ID). The arrow represents the direction of motion.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text ltx_font_bold">Related Work:</span>
For lidar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and 3+1D high-resolution radar data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> flow-based methods, that only utilize the point coordinates, can accurately estimate the scene flow for a point cloud. The point cloud can be separated into static and dynamic areas using the scene flow. Static points can then be used to estimate the ego-motion, while the instanceâ€™s motion can be derived from the dynamic points. By extending the considered time horizon and employing motion segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> (PCAc) has shown that accurate accumulation of point clouds is possible given only the naively accumulated point clouds.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">As summarized by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, multiple 3+1D radar datasets have been proposed, each suffering from unique limitations, making most of them unfeasible for the ultimate goal of 3D object detection. The View-of-Delft (VoD) dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> meets the requirements. It provides time-continuous labeled objects, non-accumulated radar data, and additional sensor modalities like high-resolution lidar and camera sensor data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The main contributions of the work at hand are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Evaluating ego-motion estimation approaches to accumulate high-resolution radar point clouds on subsequent frames on the VoD dataset.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Adaptation of PCAc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> approach to the VoD dataset and evaluation of the transferability to radar data.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Investigating the influence of different dynamic and static motion correction approaches on the performance of 3D object detection.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Limitations of the VoD dataset</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The VoD dataset is one of very few datasets that include 3+1D high-resolution radar measurements. In addition to the radar sensor, mono camera and high-resolution 64-layer lidar data are provided. Due to the datasetâ€™s focus on urban scenarios where different types of traffic participants share the same space, only a limited view range of up to 51.2m is considered, and the amount of observed pedestrians and cyclist is high compared to other datasets like the Astyx dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
One major limitation of the dataset is the accuracy of labeled objects. Multiple objects are either not labeled or mislabeled. An example is visualized in Fig. <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In the lower part of the image are three bicycles. The foremost one (ID: VIII) is labeled correctly. The middle one (ID: VII) is not labeled at all, and the label for the sternmost one (ID: VI) is not well aligned to the cluster of close targets. The questionable quality of such annotations negatively influences the training because misaligned or missing annotations confuse the training procedure. Due to the time and effort necessary for correcting annotations, only minor label adaptations have been applied to mitigate the problem of object reflection points that lay outside the bounding box. The box is extended by <math id="S2.p1.1.m1.3" class="ltx_Math" alttext="0.2\text{\,}\mathrm{m}" display="inline"><semantics id="S2.p1.1.m1.3a"><mrow id="S2.p1.1.m1.3.3" xref="S2.p1.1.m1.3.3.cmml"><mn id="S2.p1.1.m1.1.1.1.1.1.1" xref="S2.p1.1.m1.1.1.1.1.1.1.cmml">0.2</mn><mtext id="S2.p1.1.m1.2.2.2.2.2.2" xref="S2.p1.1.m1.2.2.2.2.2.2.cmml">Â </mtext><mi class="ltx_unit" mathvariant="normal" id="S2.p1.1.m1.3.3.3.3.3.3" xref="S2.p1.1.m1.3.3.3.3.3.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.3b"><apply id="S2.p1.1.m1.3.3.cmml" xref="S2.p1.1.m1.3.3"><csymbol cd="latexml" id="S2.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.p1.1.m1.2.2.2.2.2.2">times</csymbol><cn type="float" id="S2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1.1.1.1">0.2</cn><csymbol cd="latexml" id="S2.p1.1.m1.3.3.3.3.3.3.cmml" xref="S2.p1.1.m1.3.3.3.3.3.3">meter</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.3c">0.2\text{\,}\mathrm{m}</annotation></semantics></math> in each direction to capture most of the points belonging to an object, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.3" class="ltx_p">The second observed limitation is the unavailability of ground truth ego-motion information. The authors provide an accumulated set of radar scans but do not provide the utilized ego-motion for generating them. This limits the ability to investigate dynamic object motion. Additionally, the reproduction of the accumulated scans is hindered by different sampling frequencies of the radar sensor and the provided single radar scans. The utilized sensor captures the scene with a frequency of <math id="S2.p2.1.m1.3" class="ltx_Math" alttext="13\text{\,}\mathrm{Hz}" display="inline"><semantics id="S2.p2.1.m1.3a"><mrow id="S2.p2.1.m1.3.3" xref="S2.p2.1.m1.3.3.cmml"><mn id="S2.p2.1.m1.1.1.1.1.1.1" xref="S2.p2.1.m1.1.1.1.1.1.1.cmml">13</mn><mtext id="S2.p2.1.m1.2.2.2.2.2.2" xref="S2.p2.1.m1.2.2.2.2.2.2.cmml">Â </mtext><mi class="ltx_unit" id="S2.p2.1.m1.3.3.3.3.3.3" xref="S2.p2.1.m1.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.3b"><apply id="S2.p2.1.m1.3.3.cmml" xref="S2.p2.1.m1.3.3"><csymbol cd="latexml" id="S2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S2.p2.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.p2.1.m1.1.1.1.1.1.1">13</cn><csymbol cd="latexml" id="S2.p2.1.m1.3.3.3.3.3.3.cmml" xref="S2.p2.1.m1.3.3.3.3.3.3">hertz</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.3c">13\text{\,}\mathrm{Hz}</annotation></semantics></math>, but the single-frame data is only provided with a frequency of <math id="S2.p2.2.m2.3" class="ltx_Math" alttext="10\text{\,}\mathrm{Hz}" display="inline"><semantics id="S2.p2.2.m2.3a"><mrow id="S2.p2.2.m2.3.3" xref="S2.p2.2.m2.3.3.cmml"><mn id="S2.p2.2.m2.1.1.1.1.1.1" xref="S2.p2.2.m2.1.1.1.1.1.1.cmml">10</mn><mtext id="S2.p2.2.m2.2.2.2.2.2.2" xref="S2.p2.2.m2.2.2.2.2.2.2.cmml">Â </mtext><mi class="ltx_unit" id="S2.p2.2.m2.3.3.3.3.3.3" xref="S2.p2.2.m2.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.3b"><apply id="S2.p2.2.m2.3.3.cmml" xref="S2.p2.2.m2.3.3"><csymbol cd="latexml" id="S2.p2.2.m2.2.2.2.2.2.2.cmml" xref="S2.p2.2.m2.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S2.p2.2.m2.1.1.1.1.1.1">10</cn><csymbol cd="latexml" id="S2.p2.2.m2.3.3.3.3.3.3.cmml" xref="S2.p2.2.m2.3.3.3.3.3.3">hertz</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.3c">10\text{\,}\mathrm{Hz}</annotation></semantics></math>, to synchronize the measurement of the radar to the other sensor modalities. The provided accumulated point cloud is collected from the base <math id="S2.p2.3.m3.3" class="ltx_Math" alttext="13\text{\,}\mathrm{Hz}" display="inline"><semantics id="S2.p2.3.m3.3a"><mrow id="S2.p2.3.m3.3.3" xref="S2.p2.3.m3.3.3.cmml"><mn id="S2.p2.3.m3.1.1.1.1.1.1" xref="S2.p2.3.m3.1.1.1.1.1.1.cmml">13</mn><mtext id="S2.p2.3.m3.2.2.2.2.2.2" xref="S2.p2.3.m3.2.2.2.2.2.2.cmml">Â </mtext><mi class="ltx_unit" id="S2.p2.3.m3.3.3.3.3.3.3" xref="S2.p2.3.m3.3.3.3.3.3.3.cmml">Hz</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.3b"><apply id="S2.p2.3.m3.3.3.cmml" xref="S2.p2.3.m3.3.3"><csymbol cd="latexml" id="S2.p2.3.m3.2.2.2.2.2.2.cmml" xref="S2.p2.3.m3.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S2.p2.3.m3.1.1.1.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1.1.1.1">13</cn><csymbol cd="latexml" id="S2.p2.3.m3.3.3.3.3.3.3.cmml" xref="S2.p2.3.m3.3.3.3.3.3.3">hertz</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.3c">13\text{\,}\mathrm{Hz}</annotation></semantics></math> data. Certain radar scans are therefore not provided and the time interval between the provided frames varies. Different strategies of estimating ego-motion are investigated in the following chapter to mitigate the missing ego-motion information.</p>
</div>
<section id="S2.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Ego-Motion Estimation</h3>

<div id="S2.SSx1.p1" class="ltx_para">
<p id="S2.SSx1.p1.1" class="ltx_p">The ego-vehicle motion is described as a transformation matrix that consists of the translation and rotation of the ego-vehicle between two consecutive time steps. It can be derived either from an inertial measurement-based system or directly from environmental measurement sensors.</p>
</div>
<div id="S2.SSx1.p2" class="ltx_para">
<p id="S2.SSx1.p2.1" class="ltx_p"><span id="S2.SSx1.p2.1.1" class="ltx_text ltx_font_bold">Ego-Motion-Estimation from Pose (EM-P):</span> The VoD dataset does not directly provide information about the ego-motion. However, transformation matrices from the camera coordinate system to a <span id="S2.SSx1.p2.1.2" class="ltx_text ltx_font_italic">map</span> and a <span id="S2.SSx1.p2.1.3" class="ltx_text ltx_font_italic">world</span> coordinate system are provided. Both transformations only differ in the definition of the point of origin. Hence, the ego-motion is calculated from the transformation between consecutive frames.</p>
</div>
<div id="S2.SSx1.p3" class="ltx_para">
<p id="S2.SSx1.p3.1" class="ltx_p"><span id="S2.SSx1.p3.1.1" class="ltx_text ltx_font_bold">Ego-Motion-Estimation from Point Cloud with GICP (EM-G):</span> Due to limitations observed in the ego-motion from the VoD pose estimation, a method for estimating the motion directly from the recorded point cloud is investigated. Generalized Iterative Closest Point (GICP)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is chosen due to its simple implementation and the assumed sufficient accuracy. It is applied to the lidar and high-resolution radar point cloud separately.</p>
</div>
<div id="S2.SSx1.p4" class="ltx_para">
<p id="S2.SSx1.p4.1" class="ltx_p"><span id="S2.SSx1.p4.1.1" class="ltx_text ltx_font_bold">Averaging of estimated motion over multiple time steps (EM-mG):</span>
Due to the high oscillation of the EM-G output, as can be seen in Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Treatment of Dynamic Objects â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, an averaging of the transformation matrix is employed to reduce implausible fluctuations. The average of the translation and rotation matrices are calculated separately. Due to an observed pattern that repeats every 6 time steps, the translation is averaged by calculating the moving average over the translation at 6 consecutive time steps. An averaging of the rotation matrix is not trivial. One way of averaging utilized in this work is to transform the rotation matrix into a quaternion representation. Then, the average quaternion is calculated using singular value decomposition (SVD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, over the same 6 consecutive time steps. Afterward, the quaternion is re-transformed into the rotation matrix.</p>
</div>
<div id="S2.SSx1.p5" class="ltx_para">
<p id="S2.SSx1.p5.5" class="ltx_p"><span id="S2.SSx1.p5.1.1" class="ltx_text ltx_font_bold">Estimation from measured radar radial velocity (EM-<math id="S2.SSx1.p5.1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S2.SSx1.p5.1.1.m1.1a"><msub id="S2.SSx1.p5.1.1.m1.1.1" xref="S2.SSx1.p5.1.1.m1.1.1.cmml"><mi id="S2.SSx1.p5.1.1.m1.1.1.2" xref="S2.SSx1.p5.1.1.m1.1.1.2.cmml">v</mi><mrow id="S2.SSx1.p5.1.1.m1.1.1.3" xref="S2.SSx1.p5.1.1.m1.1.1.3.cmml"><mi id="S2.SSx1.p5.1.1.m1.1.1.3.2" xref="S2.SSx1.p5.1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SSx1.p5.1.1.m1.1.1.3.1" xref="S2.SSx1.p5.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SSx1.p5.1.1.m1.1.1.3.3" xref="S2.SSx1.p5.1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SSx1.p5.1.1.m1.1b"><apply id="S2.SSx1.p5.1.1.m1.1.1.cmml" xref="S2.SSx1.p5.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SSx1.p5.1.1.m1.1.1.1.cmml" xref="S2.SSx1.p5.1.1.m1.1.1">subscript</csymbol><ci id="S2.SSx1.p5.1.1.m1.1.1.2.cmml" xref="S2.SSx1.p5.1.1.m1.1.1.2">ğ‘£</ci><apply id="S2.SSx1.p5.1.1.m1.1.1.3.cmml" xref="S2.SSx1.p5.1.1.m1.1.1.3"><times id="S2.SSx1.p5.1.1.m1.1.1.3.1.cmml" xref="S2.SSx1.p5.1.1.m1.1.1.3.1"></times><ci id="S2.SSx1.p5.1.1.m1.1.1.3.2.cmml" xref="S2.SSx1.p5.1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S2.SSx1.p5.1.1.m1.1.1.3.3.cmml" xref="S2.SSx1.p5.1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p5.1.1.m1.1c">v_{rr}</annotation></semantics></math>):</span>
One unique feature of the radar point cloud that can be utilized to estimate ego-motion is the direct measurement of <math id="S2.SSx1.p5.2.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S2.SSx1.p5.2.m1.1a"><msub id="S2.SSx1.p5.2.m1.1.1" xref="S2.SSx1.p5.2.m1.1.1.cmml"><mi id="S2.SSx1.p5.2.m1.1.1.2" xref="S2.SSx1.p5.2.m1.1.1.2.cmml">v</mi><mrow id="S2.SSx1.p5.2.m1.1.1.3" xref="S2.SSx1.p5.2.m1.1.1.3.cmml"><mi id="S2.SSx1.p5.2.m1.1.1.3.2" xref="S2.SSx1.p5.2.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SSx1.p5.2.m1.1.1.3.1" xref="S2.SSx1.p5.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S2.SSx1.p5.2.m1.1.1.3.3" xref="S2.SSx1.p5.2.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SSx1.p5.2.m1.1b"><apply id="S2.SSx1.p5.2.m1.1.1.cmml" xref="S2.SSx1.p5.2.m1.1.1"><csymbol cd="ambiguous" id="S2.SSx1.p5.2.m1.1.1.1.cmml" xref="S2.SSx1.p5.2.m1.1.1">subscript</csymbol><ci id="S2.SSx1.p5.2.m1.1.1.2.cmml" xref="S2.SSx1.p5.2.m1.1.1.2">ğ‘£</ci><apply id="S2.SSx1.p5.2.m1.1.1.3.cmml" xref="S2.SSx1.p5.2.m1.1.1.3"><times id="S2.SSx1.p5.2.m1.1.1.3.1.cmml" xref="S2.SSx1.p5.2.m1.1.1.3.1"></times><ci id="S2.SSx1.p5.2.m1.1.1.3.2.cmml" xref="S2.SSx1.p5.2.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S2.SSx1.p5.2.m1.1.1.3.3.cmml" xref="S2.SSx1.p5.2.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p5.2.m1.1c">v_{rr}</annotation></semantics></math>.
The ego-motion can be estimated by applying a least squares-based approach to the static points in the scene, as described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The main difference to alternative approaches is, that only measurements from a single frame are needed. The differentiation of static and dynamic points is done by estimating the static points using a random sample consensus algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Due to the additional information about the elevation angle <math id="S2.SSx1.p5.3.m2.1" class="ltx_Math" alttext="\varepsilon" display="inline"><semantics id="S2.SSx1.p5.3.m2.1a"><mi id="S2.SSx1.p5.3.m2.1.1" xref="S2.SSx1.p5.3.m2.1.1.cmml">Îµ</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p5.3.m2.1b"><ci id="S2.SSx1.p5.3.m2.1.1.cmml" xref="S2.SSx1.p5.3.m2.1.1">ğœ€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p5.3.m2.1c">\varepsilon</annotation></semantics></math> measured by the 3+1D radar sensor, the observation angle <math id="S2.SSx1.p5.4.m3.1" class="ltx_Math" alttext="\varphi" display="inline"><semantics id="S2.SSx1.p5.4.m3.1a"><mi id="S2.SSx1.p5.4.m3.1.1" xref="S2.SSx1.p5.4.m3.1.1.cmml">Ï†</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p5.4.m3.1b"><ci id="S2.SSx1.p5.4.m3.1.1.cmml" xref="S2.SSx1.p5.4.m3.1.1">ğœ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p5.4.m3.1c">\varphi</annotation></semantics></math> is utilized, instead of the azimuth angle <math id="S2.SSx1.p5.5.m4.1" class="ltx_Math" alttext="\vartheta" display="inline"><semantics id="S2.SSx1.p5.5.m4.1a"><mi id="S2.SSx1.p5.5.m4.1.1" xref="S2.SSx1.p5.5.m4.1.1.cmml">Ï‘</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p5.5.m4.1b"><ci id="S2.SSx1.p5.5.m4.1.1.cmml" xref="S2.SSx1.p5.5.m4.1.1">italic-Ï‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p5.5.m4.1c">\vartheta</annotation></semantics></math>. Calculated using the spherical Pythagorean theorem:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.3" class="ltx_Math" alttext="\varphi=\text{cos}^{-1}(\text{cos}(\vartheta)\text{cos}(\varepsilon))" display="block"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml"><mi id="S2.E1.m1.3.3.3" xref="S2.E1.m1.3.3.3.cmml">Ï†</mi><mo id="S2.E1.m1.3.3.2" xref="S2.E1.m1.3.3.2.cmml">=</mo><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.cmml"><msup id="S2.E1.m1.3.3.1.3" xref="S2.E1.m1.3.3.1.3.cmml"><mtext id="S2.E1.m1.3.3.1.3.2" xref="S2.E1.m1.3.3.1.3.2a.cmml">cos</mtext><mrow id="S2.E1.m1.3.3.1.3.3" xref="S2.E1.m1.3.3.1.3.3.cmml"><mo id="S2.E1.m1.3.3.1.3.3a" xref="S2.E1.m1.3.3.1.3.3.cmml">âˆ’</mo><mn id="S2.E1.m1.3.3.1.3.3.2" xref="S2.E1.m1.3.3.1.3.3.2.cmml">1</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mtext id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2a.cmml">cos</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.3.2" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.3.2.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">Ï‘</mi><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.3.2.2" xref="S2.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.1.1a" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mtext id="S2.E1.m1.3.3.1.1.1.1.4" xref="S2.E1.m1.3.3.1.1.1.1.4a.cmml">cos</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.1.1.1b" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.1.1.1.1.5.2" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.5.2.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">Îµ</mi><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.1.5.2.2" xref="S2.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3"><eq id="S2.E1.m1.3.3.2.cmml" xref="S2.E1.m1.3.3.2"></eq><ci id="S2.E1.m1.3.3.3.cmml" xref="S2.E1.m1.3.3.3">ğœ‘</ci><apply id="S2.E1.m1.3.3.1.cmml" xref="S2.E1.m1.3.3.1"><times id="S2.E1.m1.3.3.1.2.cmml" xref="S2.E1.m1.3.3.1.2"></times><apply id="S2.E1.m1.3.3.1.3.cmml" xref="S2.E1.m1.3.3.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.3.1.cmml" xref="S2.E1.m1.3.3.1.3">superscript</csymbol><ci id="S2.E1.m1.3.3.1.3.2a.cmml" xref="S2.E1.m1.3.3.1.3.2"><mtext id="S2.E1.m1.3.3.1.3.2.cmml" xref="S2.E1.m1.3.3.1.3.2">cos</mtext></ci><apply id="S2.E1.m1.3.3.1.3.3.cmml" xref="S2.E1.m1.3.3.1.3.3"><minus id="S2.E1.m1.3.3.1.3.3.1.cmml" xref="S2.E1.m1.3.3.1.3.3"></minus><cn type="integer" id="S2.E1.m1.3.3.1.3.3.2.cmml" xref="S2.E1.m1.3.3.1.3.3.2">1</cn></apply></apply><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1"><times id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1"></times><ci id="S2.E1.m1.3.3.1.1.1.1.2a.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2"><mtext id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">cos</mtext></ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">italic-Ï‘</ci><ci id="S2.E1.m1.3.3.1.1.1.1.4a.cmml" xref="S2.E1.m1.3.3.1.1.1.1.4"><mtext id="S2.E1.m1.3.3.1.1.1.1.4.cmml" xref="S2.E1.m1.3.3.1.1.1.1.4">cos</mtext></ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">ğœ€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">\varphi=\text{cos}^{-1}(\text{cos}(\vartheta)\text{cos}(\varepsilon))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SSx1.p6" class="ltx_para">
<p id="S2.SSx1.p6.2" class="ltx_p"><span id="S2.SSx1.p6.2.1" class="ltx_text ltx_font_bold">Estimation from static objects (EM-SO):</span>
The VoD dataset includes labels and track identifiers for some static objects like <span id="S2.SSx1.p6.2.2" class="ltx_text ltx_font_italic">bicycle racks</span> and <span id="S2.SSx1.p6.2.3" class="ltx_text ltx_font_italic">unused bicycles</span>. The track identifiers enable the re-identification of objects in consecutive frames.
Assuming noise-free data, the rotation <math id="S2.SSx1.p6.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SSx1.p6.1.m1.1a"><mi id="S2.SSx1.p6.1.m1.1.1" xref="S2.SSx1.p6.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p6.1.m1.1b"><ci id="S2.SSx1.p6.1.m1.1.1.cmml" xref="S2.SSx1.p6.1.m1.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p6.1.m1.1c">R</annotation></semantics></math> and translation <math id="S2.SSx1.p6.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SSx1.p6.2.m2.1a"><mi id="S2.SSx1.p6.2.m2.1.1" xref="S2.SSx1.p6.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p6.2.m2.1b"><ci id="S2.SSx1.p6.2.m2.1.1.cmml" xref="S2.SSx1.p6.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p6.2.m2.1c">t</annotation></semantics></math> can be derived by solving:</p>
</div>
<div id="S2.SSx1.p7" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="RC_{k-1}+t=C_{k}" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mrow id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml"><mrow id="S2.E2.m1.1.1.2.2" xref="S2.E2.m1.1.1.2.2.cmml"><mi id="S2.E2.m1.1.1.2.2.2" xref="S2.E2.m1.1.1.2.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.2.2.1" xref="S2.E2.m1.1.1.2.2.1.cmml">â€‹</mo><msub id="S2.E2.m1.1.1.2.2.3" xref="S2.E2.m1.1.1.2.2.3.cmml"><mi id="S2.E2.m1.1.1.2.2.3.2" xref="S2.E2.m1.1.1.2.2.3.2.cmml">C</mi><mrow id="S2.E2.m1.1.1.2.2.3.3" xref="S2.E2.m1.1.1.2.2.3.3.cmml"><mi id="S2.E2.m1.1.1.2.2.3.3.2" xref="S2.E2.m1.1.1.2.2.3.3.2.cmml">k</mi><mo id="S2.E2.m1.1.1.2.2.3.3.1" xref="S2.E2.m1.1.1.2.2.3.3.1.cmml">âˆ’</mo><mn id="S2.E2.m1.1.1.2.2.3.3.3" xref="S2.E2.m1.1.1.2.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.E2.m1.1.1.2.1" xref="S2.E2.m1.1.1.2.1.cmml">+</mo><mi id="S2.E2.m1.1.1.2.3" xref="S2.E2.m1.1.1.2.3.cmml">t</mi></mrow><mo id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml">=</mo><msub id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml">C</mi><mi id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><eq id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"></eq><apply id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2"><plus id="S2.E2.m1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.2.1"></plus><apply id="S2.E2.m1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.2.2"><times id="S2.E2.m1.1.1.2.2.1.cmml" xref="S2.E2.m1.1.1.2.2.1"></times><ci id="S2.E2.m1.1.1.2.2.2.cmml" xref="S2.E2.m1.1.1.2.2.2">ğ‘…</ci><apply id="S2.E2.m1.1.1.2.2.3.cmml" xref="S2.E2.m1.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.2.2.3.1.cmml" xref="S2.E2.m1.1.1.2.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.2.2.3.2.cmml" xref="S2.E2.m1.1.1.2.2.3.2">ğ¶</ci><apply id="S2.E2.m1.1.1.2.2.3.3.cmml" xref="S2.E2.m1.1.1.2.2.3.3"><minus id="S2.E2.m1.1.1.2.2.3.3.1.cmml" xref="S2.E2.m1.1.1.2.2.3.3.1"></minus><ci id="S2.E2.m1.1.1.2.2.3.3.2.cmml" xref="S2.E2.m1.1.1.2.2.3.3.2">ğ‘˜</ci><cn type="integer" id="S2.E2.m1.1.1.2.2.3.3.3.cmml" xref="S2.E2.m1.1.1.2.2.3.3.3">1</cn></apply></apply></apply><ci id="S2.E2.m1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.2.3">ğ‘¡</ci></apply><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3">subscript</csymbol><ci id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2">ğ¶</ci><ci id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">RC_{k-1}+t=C_{k}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SSx1.p8" class="ltx_para">
<p id="S2.SSx1.p8.3" class="ltx_p">Where <math id="S2.SSx1.p8.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.SSx1.p8.1.m1.1a"><mi id="S2.SSx1.p8.1.m1.1.1" xref="S2.SSx1.p8.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p8.1.m1.1b"><ci id="S2.SSx1.p8.1.m1.1.1.cmml" xref="S2.SSx1.p8.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p8.1.m1.1c">C</annotation></semantics></math> represents the center points of all objects at time step <math id="S2.SSx1.p8.2.m2.1" class="ltx_Math" alttext="k-1" display="inline"><semantics id="S2.SSx1.p8.2.m2.1a"><mrow id="S2.SSx1.p8.2.m2.1.1" xref="S2.SSx1.p8.2.m2.1.1.cmml"><mi id="S2.SSx1.p8.2.m2.1.1.2" xref="S2.SSx1.p8.2.m2.1.1.2.cmml">k</mi><mo id="S2.SSx1.p8.2.m2.1.1.1" xref="S2.SSx1.p8.2.m2.1.1.1.cmml">âˆ’</mo><mn id="S2.SSx1.p8.2.m2.1.1.3" xref="S2.SSx1.p8.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SSx1.p8.2.m2.1b"><apply id="S2.SSx1.p8.2.m2.1.1.cmml" xref="S2.SSx1.p8.2.m2.1.1"><minus id="S2.SSx1.p8.2.m2.1.1.1.cmml" xref="S2.SSx1.p8.2.m2.1.1.1"></minus><ci id="S2.SSx1.p8.2.m2.1.1.2.cmml" xref="S2.SSx1.p8.2.m2.1.1.2">ğ‘˜</ci><cn type="integer" id="S2.SSx1.p8.2.m2.1.1.3.cmml" xref="S2.SSx1.p8.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p8.2.m2.1c">k-1</annotation></semantics></math> and <math id="S2.SSx1.p8.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SSx1.p8.3.m3.1a"><mi id="S2.SSx1.p8.3.m3.1.1" xref="S2.SSx1.p8.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SSx1.p8.3.m3.1b"><ci id="S2.SSx1.p8.3.m3.1.1.cmml" xref="S2.SSx1.p8.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SSx1.p8.3.m3.1c">k</annotation></semantics></math>. Due to noise in the data, a least squares-based approach is used to derive the motion. Unfortunately, static objects do not occur in every frame. That limits the usefulness and accuracy of this method significantly and also makes it dependent on the accuracy of the annotation of static objects. Hence, this approach is only considered as a baseline for comparing the previous methods against.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Treatment of Dynamic Objects</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Due to the motion of certain objects an accumulation of the point cloud by just considering ego-motion results in an error for moving objects. For the foremost bicycle on the bottom left in Fig. <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, this is represented by the smearing pattern of points behind the object. This negatively influences the training as objects get represented differently depending on their motion.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Estimation from the provided labels (Dyn-GT):</span>
For a baseline approach the motion of objects can be derived from the labels by estimating the transformation between the center points of objects. This is the best-case baseline to which the other approaches will be compared.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.2" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Relative Radial Velocity (Dyn-<math id="S3.p3.1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S3.p3.1.1.m1.1a"><msub id="S3.p3.1.1.m1.1.1" xref="S3.p3.1.1.m1.1.1.cmml"><mi id="S3.p3.1.1.m1.1.1.2" xref="S3.p3.1.1.m1.1.1.2.cmml">v</mi><mrow id="S3.p3.1.1.m1.1.1.3" xref="S3.p3.1.1.m1.1.1.3.cmml"><mi id="S3.p3.1.1.m1.1.1.3.2" xref="S3.p3.1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.p3.1.1.m1.1.1.3.1" xref="S3.p3.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p3.1.1.m1.1.1.3.3" xref="S3.p3.1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p3.1.1.m1.1b"><apply id="S3.p3.1.1.m1.1.1.cmml" xref="S3.p3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.1.1.m1.1.1.1.cmml" xref="S3.p3.1.1.m1.1.1">subscript</csymbol><ci id="S3.p3.1.1.m1.1.1.2.cmml" xref="S3.p3.1.1.m1.1.1.2">ğ‘£</ci><apply id="S3.p3.1.1.m1.1.1.3.cmml" xref="S3.p3.1.1.m1.1.1.3"><times id="S3.p3.1.1.m1.1.1.3.1.cmml" xref="S3.p3.1.1.m1.1.1.3.1"></times><ci id="S3.p3.1.1.m1.1.1.3.2.cmml" xref="S3.p3.1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.p3.1.1.m1.1.1.3.3.cmml" xref="S3.p3.1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.1.m1.1c">v_{rr}</annotation></semantics></math>):</span>
If an object only moves in a radial direction to the radar sensor, the full motion of the object can be measured accurately. Unfortunately, objects rarely just move in radial direction, which limits this approach.
Nevertheless, a correction by <math id="S3.p3.2.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S3.p3.2.m1.1a"><msub id="S3.p3.2.m1.1.1" xref="S3.p3.2.m1.1.1.cmml"><mi id="S3.p3.2.m1.1.1.2" xref="S3.p3.2.m1.1.1.2.cmml">v</mi><mrow id="S3.p3.2.m1.1.1.3" xref="S3.p3.2.m1.1.1.3.cmml"><mi id="S3.p3.2.m1.1.1.3.2" xref="S3.p3.2.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.p3.2.m1.1.1.3.1" xref="S3.p3.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p3.2.m1.1.1.3.3" xref="S3.p3.2.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p3.2.m1.1b"><apply id="S3.p3.2.m1.1.1.cmml" xref="S3.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.2.m1.1.1.1.cmml" xref="S3.p3.2.m1.1.1">subscript</csymbol><ci id="S3.p3.2.m1.1.1.2.cmml" xref="S3.p3.2.m1.1.1.2">ğ‘£</ci><apply id="S3.p3.2.m1.1.1.3.cmml" xref="S3.p3.2.m1.1.1.3"><times id="S3.p3.2.m1.1.1.3.1.cmml" xref="S3.p3.2.m1.1.1.3.1"></times><ci id="S3.p3.2.m1.1.1.3.2.cmml" xref="S3.p3.2.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.p3.2.m1.1.1.3.3.cmml" xref="S3.p3.2.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m1.1c">v_{rr}</annotation></semantics></math> will result in a good motion correction for all vehicles that move in the same or opposite direction to the ego-vehicle.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">Learning-Based Estimation of Dynamic Motion (Dyn-PCAc):</span>
To directly estimate the dynamic object motion from the point cloud, PCAc
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is adapted to the VoD dataset. PCAc <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is a supervised end-to-end learning-based algorithm that first estimates the ego-motion (EM-PCAc) of the vehicle by separating the scene into static and dynamic areas and employing robust point matching on the static points. Afterward, motion segmentation and instance association steps are executed to derive the instance motion and correct the pointâ€™s position in the accumulated point cloud. When using the estimated ego-motion and the labels of dynamic objects, a ground truth motion set can be derived. This is used during training.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><svg id="S3.F2.pic1" class="ltx_picture" height="403.34" overflow="visible" version="1.1" width="667.15"><g transform="translate(0,403.34) matrix(1 0 0 -1 0 0) translate(52.05,0) translate(0,221.62)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -35.39 -15.41)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0) translate(35.39,0) translate(0,15.41)"><g stroke-width="0.2pt" fill="#000000" stroke="#000000" color="#808080"><path d="M 0 -5.91 L 0 0 M 75.88 -5.91 L 75.88 0 M 151.76 -5.91 L 151.76 0 M 227.63 -5.91 L 227.63 0 M 303.51 -5.91 L 303.51 0 M 379.39 -5.91 L 379.39 0 M 455.27 -5.91 L 455.27 0 M 531.15 -5.91 L 531.15 0 M 607.02 -5.91 L 607.02 0" style="fill:none"></path></g><g stroke-width="0.2pt" fill="#000000" stroke="#000000" color="#808080"><path d="M -5.91 0 L 0 0 M -5.91 58.52 L 0 58.52 M -5.91 117.03 L 0 117.03" style="fill:none"></path></g><g stroke="#000000" fill="#000000" stroke-width="0.4pt"><path d="M 0 0 L 0 134.59 L 607.02 134.59 L 607.02 0 L 0 0 Z" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -17.71 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -30.78 54.06)" fill="#000000" stroke="#000000"><foreignObject width="19.99" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="float" id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1c">0.5</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -17.71 112.57)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1c">1</annotation></semantics></math></foreignObject></g><clipPath id="pgfcp1"><path d="M 0 0 L 607.02 0 L 607.02 134.59 L 0 134.59 Z"></path></clipPath><g clip-path="url(#pgfcp1)"><g stroke-width="0.6pt" fill="#1F77B4" stroke="#1F77B4" color="#1F77B4"><path d="M 0 51.35 L 7.59 56.49 L 15.18 36.5 L 22.76 43.34 L 30.35 57.36 L 37.94 38.17 L 45.53 52.16 L 53.11 59.43 L 60.7 39.08 L 68.29 39.04 L 75.88 64.52 L 83.47 38.47 L 91.05 57.02 L 98.64 61.04 L 106.23 26.55 L 113.82 60.15 L 121.4 61.15 L 128.99 40.02 L 136.58 42.16 L 144.17 78.96 L 151.76 41.99 L 159.34 47.82 L 166.93 60.71 L 174.52 42.16 L 182.11 57.84 L 189.7 61.4 L 197.28 41.49 L 204.87 47.93 L 212.46 63.61 L 220.05 41.71 L 227.63 55.45 L 235.22 62.93 L 242.81 43.25 L 250.4 46.91 L 257.99 60.69 L 265.57 40.26 L 273.16 55.31 L 280.75 62.17 L 288.34 39.73 L 295.92 47.56 L 303.51 61.05 L 311.1 40.19 L 318.69 57.01 L 326.28 57.61 L 333.86 41.36 L 341.45 48.08 L 349.04 60.77 L 356.63 40.68 L 364.21 54.06 L 371.8 60.74 L 379.39 27.24 L 386.98 59.73 L 394.57 61.87 L 402.15 42.72 L 409.74 41.11 L 417.33 77.21 L 424.92 41.92 L 432.5 46.52 L 440.09 62.69 L 447.68 40.21 L 455.27 41.96 L 462.86 77.13 L 470.44 40.21 L 478.03 43.25 L 485.62 60.38 L 493.21 37.45 L 500.79 54.95 L 508.38 56.61 L 515.97 39.37 L 523.56 43.94 L 531.15 60.61 L 538.73 33.31 L 546.32 59.98 L 553.91 57.96 L 561.5 25.6 L 569.09 58.64 L 576.67 59.79 L 584.26 38.5 L 591.85 37.94 L 599.44 73.38 L 607.02 40.05 L 614.61 44.2 L 622.2 58.35 L 629.79 39.52 L 637.38 54.81 L 644.96 61.08 L 652.55 23.52 L 660.14 68.77 L 667.73 50.87" style="fill:none"></path></g><g></g><g stroke-width="0.6pt" fill="#FA7F0E" stroke="#FA7F0E" color="#FA7F0E"><path d="M 0 36.08 L 7.59 70.39 L 15.18 20.99 L 22.76 57.68 L 30.35 52.55 L 37.94 41.2 L 45.53 37.23 L 53.11 74.04 L 60.7 29.32 L 68.29 46.35 L 75.88 59.86 L 83.47 43.25 L 91.05 37.02 L 98.64 79.08 L 106.23 20.73 L 113.82 63.84 L 121.4 57.08 L 128.99 42.91 L 136.58 35.59 L 144.17 76.66 L 151.76 26.13 L 159.34 49.91 L 166.93 64.16 L 174.52 48.39 L 182.11 41.25 L 189.7 78.34 L 197.28 26.41 L 204.87 57.68 L 212.46 65.23 L 220.05 33.01 L 227.63 45.93 L 235.22 75.25 L 242.81 23.04 L 250.4 59.27 L 257.99 57.21 L 265.57 45.92 L 273.16 40.51 L 280.75 76.25 L 288.34 20.83 L 295.92 62.59 L 303.51 59.78 L 311.1 38 L 318.69 39.93 L 326.28 74.16 L 333.86 24.81 L 341.45 53.04 L 349.04 54.96 L 356.63 46.63 L 364.21 41.45 L 371.8 73.27 L 379.39 19.94 L 386.98 63.08 L 394.57 54.04 L 402.15 45.73 L 409.74 33.63 L 417.33 82.19 L 424.92 21.53 L 432.5 66.45 L 440.09 54.96 L 447.68 42.34 L 455.27 37.13 L 462.86 78.6 L 470.44 27.62 L 478.03 53.69 L 485.62 58.39 L 493.21 40.77 L 500.79 42.11 L 508.38 70.16 L 515.97 29.95 L 523.56 53.33 L 531.15 60.86 L 538.73 28.48 L 546.32 49.17 L 553.91 65.78 L 561.5 25.1 L 569.09 55.07 L 576.67 61.6 L 584.26 37.07 L 591.85 42.06 L 599.44 67.16 L 607.02 32.03 L 614.61 49.62 L 622.2 62.02 L 629.79 33.83 L 637.38 48.04 L 644.96 67.12 L 652.55 21.31 L 660.14 62.33 L 667.73 60.75" style="fill:none"></path></g><g></g><g stroke-width="0.6pt" fill="#E377C2" stroke="#E377C2" color="#E377C2"><path d="M 0 45.07 L 7.59 45.51 L 15.18 48.03 L 22.76 45.41 L 30.35 46.1 L 37.94 48.73 L 45.53 46.48 L 53.11 46.67 L 60.7 47.28 L 68.29 48.67 L 75.88 46.78 L 83.47 48 L 91.05 48.34 L 98.64 48.31 L 106.23 49.15 L 113.82 47.72 L 121.4 50.63 L 128.99 50.17 L 136.58 50.11 L 144.17 49.87 L 151.76 49.47 L 159.34 50.37 L 166.93 48.05 L 174.52 49.23 L 182.11 50.14 L 189.7 51.09 L 197.28 51.36 L 204.87 51.41 L 212.46 52.7 L 220.05 52.88 L 227.63 50.32 L 235.22 51.1 L 242.81 50.59 L 250.4 50.03 L 257.99 50.29 L 265.57 48.95 L 273.16 51.1 L 280.75 50.2 L 288.34 50.37 L 295.92 50 L 303.51 50.55 L 311.1 50.98 L 318.69 49.66 L 326.28 49.56 L 333.86 49.22 L 341.45 49.88 L 349.04 48.29 L 356.63 47.48 L 364.21 48.92 L 371.8 49.17 L 379.39 49.03 L 386.98 48.22 L 394.57 49.89 L 402.15 49.73 L 409.74 49.59 L 417.33 48.28 L 424.92 49.77 L 432.5 50.03 L 440.09 50.59 L 447.68 50.75 L 455.27 50.18 L 462.86 50.77 L 470.44 50.17 L 478.03 51.18 L 485.62 49.06 L 493.21 49.63 L 500.79 49.37 L 508.38 50.2 L 515.97 48.79 L 523.56 49.18 L 531.15 49.12 L 538.73 49.53 L 546.32 47.48 L 553.91 48.66 L 561.5 47.93 L 569.09 47.12 L 576.67 47.41 L 584.26 47.53 L 591.85 48.96 L 599.44 47.78 L 607.02 48.01 L 614.61 49.16 L 622.2 48.26 L 629.79 48.33 L 637.38 47.79 L 644.96 48.78 L 652.55 48.78 L 660.14 46.99 L 667.73 49.11" style="fill:none"></path></g><g></g><g stroke-width="0.6pt" fill="#BCBD22" stroke="#BCBD22" color="#BCBD22"><path d="M 0 22.98 L 7.59 89.19 L 15.18 41.72 L 22.76 46.02 L 30.35 28.98 L 37.94 30.13 L 45.53 56.11 L 53.11 78.1 L 60.7 43.06 L 68.29 70.37 L 75.88 55.78 L 83.47 11.42 L 91.05 41.92 L 98.64 82.21 L 106.23 46.2 L 113.82 35.8 L 121.4 47.75 L 128.99 16.91 L 136.58 32.37 L 144.17 64.52 L 151.76 15.83 L 159.34 75.32 L 166.93 76.02 L 174.52 56.35 L 182.11 38.48 L 189.7 58.67 L 197.28 59.2 L 204.87 57.04 L 212.46 74.31 L 220.05 24.56 L 227.63 86.42 L 235.22 94.56 L 242.81 39.51 L 250.4 66.22 L 257.99 120.78 L 265.57 20.06 L 273.16 49.61 L 280.75 102.37 L 288.34 1.9 L 295.92 47.41 L 303.51 80.07 L 311.1 59.78 L 318.69 54.94 L 326.28 59.87 L 333.86 37.57 L 341.45 46.52 L 349.04 25.2 L 356.63 46.56 L 364.21 53.32 L 371.8 57.95 L 379.39 10.06 L 386.98 9.87 L 394.57 26.99 L 402.15 26.62 L 409.74 66.86 L 417.33 80.56 L 424.92 49.86 L 432.5 55.13 L 440.09 52.7 L 447.68 34 L 455.27 25.57 L 462.86 35.42 L 470.44 57.14 L 478.03 37.84 L 485.62 60.81 L 493.21 48.62 L 500.79 53.02 L 508.38 83.96 L 515.97 37.38 L 523.56 65.52 L 531.15 51.9 L 538.73 20.73 L 546.32 29.88 L 553.91 85.54 L 561.5 3.75 L 569.09 45.49 L 576.67 60.93 L 584.26 54.71 L 591.85 10.78 L 599.44 65.11 L 607.02 51.07 L 614.61 43.11 L 622.2 6.83 L 629.79 60.17 L 637.38 37.94 L 644.96 37.7 L 652.55 41.6 L 660.14 63.47 L 667.73 56.84" style="fill:none"></path></g><g></g></g><g fill="#FFFFFF" stroke="#000000"><path d="M 360.78 91.64 h 233.82 v 39.97 h -233.82 Z"></path></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 364.93 94.41)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 25.83)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.61)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(0.42,0)" fill="#1F77B4" stroke="#1F77B4" stroke-width="0.6pt" color="#1F77B4"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 49.5 0) translate(20.83,0) matrix(1.0 0.0 0.0 1.0 -18.06 -3.69)" fill="#000000" stroke="#000000"><foreignObject width="36.13" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.8.8.8.4.4.4.1.1.1.1.1" class="ltx_text">EM-P</span></foreignObject></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 116.22 0) translate(0.42,0)" fill="#FA7F0E" stroke="#FA7F0E" stroke-width="0.6pt" color="#FA7F0E"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 142.98 0) translate(40.12,0) matrix(1.0 0.0 0.0 1.0 -37.35 -3.77)" fill="#000000" stroke="#000000"><foreignObject width="74.7" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.9.9.9.5.5.5.2.2.2.1.1" class="ltx_text">EM-G-Lidar</span></foreignObject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 25.83)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(0.42,0)" fill="#E377C2" stroke="#E377C2" stroke-width="0.6pt" color="#E377C2"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 24.45 0) translate(45.88,0) matrix(1.0 0.0 0.0 1.0 -43.12 -3.77)" fill="#000000" stroke="#000000"><foreignObject width="86.23" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.10.10.10.6.6.6.3.3.1.1.1" class="ltx_text">EM-mG-Lidar</span></foreignObject></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 116.22 0) translate(0.42,0)" fill="#BCBD22" stroke="#BCBD22" stroke-width="0.6pt" color="#BCBD22"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 140.67 0) translate(42.42,0) matrix(1.0 0.0 0.0 1.0 -39.66 -3.77)" fill="#000000" stroke="#000000"><foreignObject width="79.31" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.11.11.11.7.7.7.4.4.2.1.1" class="ltx_text">EM-G-Radar</span></foreignObject></g></g></g></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 -35.39 -221.62)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0) translate(35.39,0) translate(0,47.66)"><g stroke-width="0.2pt" fill="#000000" stroke="#000000" color="#808080"><path d="M 0 -5.91 L 0 0 M 75.88 -5.91 L 75.88 0 M 151.76 -5.91 L 151.76 0 M 227.63 -5.91 L 227.63 0 M 303.51 -5.91 L 303.51 0 M 379.39 -5.91 L 379.39 0 M 455.27 -5.91 L 455.27 0 M 531.15 -5.91 L 531.15 0 M 607.02 -5.91 L 607.02 0" style="fill:none"></path></g><g stroke-width="0.2pt" fill="#000000" stroke="#000000" color="#808080"><path d="M -5.91 0 L 0 0 M -5.91 58.52 L 0 58.52 M -5.91 117.03 L 0 117.03" style="fill:none"></path></g><g stroke="#000000" fill="#000000" stroke-width="0.4pt"><path d="M 0 0 L 0 134.59 L 607.02 134.59 L 607.02 0 L 0 0 Z" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.46 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.12.12.12.5.5.5.1.1" class="ltx_text">0</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 72.42 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.13.13.13.6.6.6.1.1" class="ltx_text">1</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 148.3 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.14.14.14.7.7.7.1.1" class="ltx_text">2</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 224.17 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.15.15.15.8.8.8.1.1" class="ltx_text">3</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 300.05 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.16.16.16.9.9.9.1.1" class="ltx_text">4</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 375.93 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.17.17.17.10.10.10.1.1" class="ltx_text">5</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 451.81 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.18.18.18.11.11.11.1.1" class="ltx_text">6</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 527.69 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.19.19.19.12.12.12.1.1" class="ltx_text">7</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 603.56 -19.71)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.20.20.20.13.13.13.1.1" class="ltx_text">8</span></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -17.71 -4.46)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -30.78 54.06)" fill="#000000" stroke="#000000"><foreignObject width="19.99" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="float" id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.5.5.5.5.5.5.5.5.5.5.5.5.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.1.1.1.1.1.1.1.1.m1.1c">0.5</annotation></semantics></math></foreignObject></g><g transform="matrix(1.0 0.0 0.0 1.0 -17.71 112.57)" fill="#000000" stroke="#000000"><foreignObject width="6.92" height="8.92" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><math id="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1a"><mn id="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1b"><cn type="integer" id="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.6.6.6.6.6.6.6.6.6.6.6.6.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.1.1.1.1.1.1.1.1.m1.1c">1</annotation></semantics></math></foreignObject></g><clipPath id="pgfcp2"><path d="M 0 0 L 607.02 0 L 607.02 134.59 L 0 134.59 Z"></path></clipPath><g clip-path="url(#pgfcp2)"><g stroke-width="0.6pt" fill="#1F77B4" stroke="#1F77B4" color="#1F77B4"><path d="M 0 51.35 L 7.59 56.49 L 15.18 36.5 L 22.76 43.34 L 30.35 57.36 L 37.94 38.17 L 45.53 52.16 L 53.11 59.43 L 60.7 39.08 L 68.29 39.04 L 75.88 64.52 L 83.47 38.47 L 91.05 57.02 L 98.64 61.04 L 106.23 26.55 L 113.82 60.15 L 121.4 61.15 L 128.99 40.02 L 136.58 42.16 L 144.17 78.96 L 151.76 41.99 L 159.34 47.82 L 166.93 60.71 L 174.52 42.16 L 182.11 57.84 L 189.7 61.4 L 197.28 41.49 L 204.87 47.93 L 212.46 63.61 L 220.05 41.71 L 227.63 55.45 L 235.22 62.93 L 242.81 43.25 L 250.4 46.91 L 257.99 60.69 L 265.57 40.26 L 273.16 55.31 L 280.75 62.17 L 288.34 39.73 L 295.92 47.56 L 303.51 61.05 L 311.1 40.19 L 318.69 57.01 L 326.28 57.61 L 333.86 41.36 L 341.45 48.08 L 349.04 60.77 L 356.63 40.68 L 364.21 54.06 L 371.8 60.74 L 379.39 27.24 L 386.98 59.73 L 394.57 61.87 L 402.15 42.72 L 409.74 41.11 L 417.33 77.21 L 424.92 41.92 L 432.5 46.52 L 440.09 62.69 L 447.68 40.21 L 455.27 41.96 L 462.86 77.13 L 470.44 40.21 L 478.03 43.25 L 485.62 60.38 L 493.21 37.45 L 500.79 54.95 L 508.38 56.61 L 515.97 39.37 L 523.56 43.94 L 531.15 60.61 L 538.73 33.31 L 546.32 59.98 L 553.91 57.96 L 561.5 25.6 L 569.09 58.64 L 576.67 59.79 L 584.26 38.5 L 591.85 37.94 L 599.44 73.38 L 607.02 40.05 L 614.61 44.2 L 622.2 58.35 L 629.79 39.52 L 637.38 54.81 L 644.96 61.08 L 652.55 23.52 L 660.14 68.77 L 667.73 50.87" style="fill:none"></path></g><g></g><g stroke-width="0.6pt" fill="#8C564B" stroke="#8C564B" color="#8C564B"><path d="M 0 41.58 L 0 45.45 L 7.59 41.78 L 15.18 51.97 L 22.76 40.49 L 30.35 47.67 L 37.94 39.76 L 45.53 45.23 L 53.11 44.97 L 60.7 52.3 L 68.29 36.99 L 75.88 52.61 L 83.47 40.15 L 91.05 55.28 L 98.64 38.82 L 106.23 53.82 L 113.82 40.35 L 121.4 65.97 L 128.99 26.31 L 136.58 54.68 L 144.17 57.84 L 151.76 38.37 L 159.34 42.21 L 166.93 71.44 L 174.52 30.35 L 182.11 47.49 L 189.7 66.62 L 197.28 34.99 L 204.87 44.24 L 212.46 76.76 L 220.05 25.38 L 227.63 59.86 L 235.22 66.77 L 242.81 33.6 L 250.4 43.47 L 257.99 79.3 L 265.57 26.73 L 273.16 56.78 L 280.75 68.12 L 288.34 37.64 L 295.92 47.5 L 303.51 74.65 L 311.1 28.23 L 318.69 51.16 L 326.28 75.25 L 333.86 28.97 L 341.45 48.98 L 349.04 78.56 L 356.63 30.71 L 364.21 52.42 L 371.8 68.85 L 379.39 32.82 L 386.98 48.51 L 394.57 71.17 L 402.15 32.68 L 409.74 60.8 L 417.33 65.68 L 424.92 42 L 432.5 39.54 L 440.09 25.54 L 447.68 22.92 L 455.27 56.24 L 462.86 69.25 L 470.44 34.04 L 478.03 48.03 L 485.62 72.41 L 493.21 25.25 L 500.79 56.28 L 508.38 69.18 L 515.97 34.16 L 523.56 43.12 L 531.15 78.66 L 538.73 30.1 L 546.32 56.65 L 553.91 67.79 L 561.5 30.68 L 569.09 46.26 L 576.67 78.23 L 584.26 25.12 L 591.85 54.32 L 599.44 68.1 L 607.02 31.25 L 614.61 45.82 L 622.2 36.44 L 629.79 28.86 L 637.38 48.37 L 644.96 61.01 L 652.55 35.31 L 660.14 54.34 L 667.73 56.61 L 675.31 19.45 L 682.9 25.02 L 690.49 58.04 L 698.08 40.48 L 705.67 16.12 L 713.25 67.91 L 720.84 38.98 L 728.43 43.73 L 736.02 75.29 L 743.6 32.62 L 751.19 5.79 L 758.78 23.38 L 766.37 13.76 L 773.96 1.25 L 781.54 8.43 L 789.13 1.39 L 796.72 55.81 L 804.31 0.69 L 811.89 0.31 L 819.48 0.31" style="fill:none"></path></g><g></g><g stroke-width="0.6pt" fill="#D62728" stroke="#D62728" color="#D62728"><path d="M 0 47.17 L 7.59 47.49 L 15.18 47.67 L 22.76 47.97 L 30.35 48.3 L 37.94 48.76 L 45.53 48.92 L 53.11 49.33 L 60.7 49.55 L 68.29 49.88 L 75.88 50.07 L 83.47 50.3 L 91.05 50.66 L 98.64 51.11 L 106.23 51.35 L 113.82 51.67 L 121.4 51.84 L 128.99 52.16 L 136.58 52.4 L 144.17 52.65 L 151.76 52.72 L 159.34 52.95 L 166.93 52.84 L 174.52 52.98 L 182.11 53.01 L 189.7 53.01 L 197.28 53.06 L 204.87 53.12 L 212.46 53.08 L 220.05 52.93 L 227.63 52.88 L 235.22 52.51 L 242.81 52.48 L 250.4 52.49 L 257.99 52.13 L 265.57 52 L 273.16 51.99 L 280.75 51.67 L 288.34 51.68 L 295.92 51.62 L 303.51 51.38 L 311.1 51.29 L 318.69 51.28 L 326.28 51.03 L 333.86 50.92 L 341.45 50.9 L 349.04 50.73 L 356.63 50.78 L 364.21 50.94 L 371.8 51.15 L 379.39 51.22 L 386.98 51.26 L 394.57 51.44 L 402.15 51.54 L 409.74 51.82 L 417.33 52.01 L 424.92 52.15 L 432.5 52.07 L 440.09 51.71 L 447.68 51.6 L 455.27 51.48 L 462.86 51.08 L 470.44 50.76 L 478.03 50.43 L 485.62 50 L 493.21 49.92 L 500.79 49.87 L 508.38 49.45 L 515.97 49.3 L 523.56 49.18 L 531.15 49.04 L 538.73 49 L 546.32 49.18 L 553.91 49.23 L 561.5 49.35 L 569.09 49.35 L 576.67 49.2 L 584.26 49 L 591.85 48.92 L 599.44 48.83 L 607.02 49.01 L 614.61 49.19 L 622.2 49.36 L 629.79 49.54 L 637.38 49.64 L 644.96 49.67 L 652.55 49.62 L 660.14 49.68 L 667.73 49.71" style="fill:none"></path></g><g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 278.87 -39.59)" fill="#000000" stroke="#000000"><foreignObject width="49.28" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.21.21.21.14.14.14.1.1" class="ltx_text">Time [s]</span></foreignObject></g><g fill="#FFFFFF" stroke="#000000"><path d="M 439.83 91.95 h 154.78 v 39.67 h -154.78 Z"></path></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 443.98 94.72)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 25.595)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 8.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(0.42,0)" fill="#1F77B4" stroke="#1F77B4" stroke-width="0.6pt" color="#1F77B4"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 27.06 0) translate(20.83,0) matrix(1.0 0.0 0.0 1.0 -18.06 -3.69)" fill="#000000" stroke="#000000"><foreignObject width="36.13" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.22.22.22.15.15.15.2.2.1.1.1" class="ltx_text">EM-P</span></foreignObject></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 71.33 0) translate(0.42,0)" fill="#8C564B" stroke="#8C564B" stroke-width="0.6pt" color="#8C564B"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 95.78 0) translate(25.35,0) matrix(1.0 0.0 0.0 1.0 -22.58 -3.69)" fill="#000000" stroke="#000000"><foreignObject width="45.16" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.23.23.23.16.16.16.3.3.2.1.1" class="ltx_text">EM-SO</span></foreignObject></g></g><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 25.6)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0) translate(0.42,0)" fill="#D62728" stroke="#D62728" stroke-width="0.6pt" color="#D62728"><path d="M 0 0 L 11.81 0 L 23.62 0" style="fill:none"></path></g><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 24.45 0) translate(23.44,0) matrix(1.0 0.0 0.0 1.0 -20.67 -3.69)" fill="#000000" stroke="#000000"><foreignObject width="41.34" height="11.12" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_text">EM-<math id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><msub id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml">v</mi><mrow id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml"><mi id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.2" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.1" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.3" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><apply id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.2">ğ‘£</ci><apply id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3"><times id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.pic1.7.7.7.7.7.7.7.7.7.7.7.7.4.4.4.4.4.4.4.4.4.4.4.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">v_{rr}</annotation></semantics></math></span></foreignObject></g></g></g></g></g></g></g><path d="M -9.38 -43.38" style="fill:none"></path><g transform="matrix(0.0 1.1 -1.1 0.0 -35.56 -199.35)" fill="#000000" stroke="#000000"><foreignObject width="342.58" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000"><span id="S3.F2.pic1.24.24.24.1.1" class="ltx_text">Longitudinal translation between consecutive frames [m]</span></foreignObject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Translation between frames in driving direction estimated from various sensor modalities for an exemplary scene with an approximately constant velocity of <math id="S3.F2.2.m1.3" class="ltx_Math" alttext="15\text{\,}\mathrm{km}\text{\,}{\mathrm{h}}^{-1}" display="inline"><semantics id="S3.F2.2.m1.3b"><mrow id="S3.F2.2.m1.3.3" xref="S3.F2.2.m1.3.3.cmml"><mn id="S3.F2.2.m1.1.1.1.1.1.1" xref="S3.F2.2.m1.1.1.1.1.1.1.cmml">15</mn><mtext id="S3.F2.2.m1.2.2.2.2.2.2" xref="S3.F2.2.m1.2.2.2.2.2.2.cmml">Â </mtext><mrow id="S3.F2.2.m1.3.3.3.3.3.3" xref="S3.F2.2.m1.3.3.3.3.3.3.cmml"><mi class="ltx_unit" id="S3.F2.2.m1.3.3.3.3.3.3.1.1.1.1.1.1" xref="S3.F2.2.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml">km</mi><mtext id="S3.F2.2.m1.3.3.3.3.3.3.2.2.2.2.2.2" xref="S3.F2.2.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml">Â </mtext><msup id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml"><mi class="ltx_unit" mathvariant="normal" id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.2" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.2.cmml">h</mi><mrow id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.cmml"><mo id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3b" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.cmml">âˆ’</mo><mn id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.2" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.2.cmml">1</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.3c"><apply id="S3.F2.2.m1.3.3.cmml" xref="S3.F2.2.m1.3.3"><csymbol cd="latexml" id="S3.F2.2.m1.2.2.2.2.2.2.cmml" xref="S3.F2.2.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S3.F2.2.m1.1.1.1.1.1.1.cmml" xref="S3.F2.2.m1.1.1.1.1.1.1">15</cn><apply id="S3.F2.2.m1.3.3.3.3.3.3.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3"><csymbol cd="latexml" id="S3.F2.2.m1.3.3.3.3.3.3.2.2.2.2.2.2.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.2.2.2.2.2.2">times</csymbol><csymbol cd="latexml" id="S3.F2.2.m1.3.3.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.1.1.1.1.1.1">kilometer</csymbol><apply id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3"><power id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.1.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3"></power><csymbol cd="latexml" id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.2.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.2">hour</csymbol><apply id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3"><minus id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.1.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3"></minus><cn type="integer" id="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.2.cmml" xref="S3.F2.2.m1.3.3.3.3.3.3.3.3.3.3.3.3.3.2">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.3d">15\text{\,}\mathrm{km}\text{\,}{\mathrm{h}}^{-1}</annotation></semantics></math> in driving direction.</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">For the overall goal of improving the object detection performance the evaluation of the accuracy of the ego-motion estimation as well as the instance motion assignment are analyzed by investigating their influence on the object detection performance. PointPillars <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> is used as the 3D object detection method as implemented in the OpenPCDet framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Minor adaptations to the model configuration were made, as described by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.
PointPillars is chosen over other object detectors due to its popularity for radar-based perception methods, see e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. In previous investigations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> it has shown to provide at least comparable, if not better detection performance than other detectors while also being computationally efficient.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Training Details:</span>
All experiments are carried out with three different reproducible model initializations to reduce performance dependencies on the initialization. The model is trained for at most 125 epochs utilizing a one-cycle learning rate scheduler <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Due to observations that the bulk of training progress happens at low learning rates, the learning rate scheduler is adapted to spend more time at lower learning rates while preserving the one-cycle character. For the VoD test set no labels are provided as the authors intend to provide an evaluation server later, similar to the KITTI dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Hence, we used the validation set for evaluation.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.3" class="ltx_p"><span id="S4.p3.3.1" class="ltx_text ltx_font_bold">Evaluation Metrics:</span>
Similar to KITTI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, we use Average Precision (AP) as the primary performance metric but require a higher minimum intersection over union (IoU) of [70%, 50%, 50%] in [x, y, z] direction for <span id="S4.p3.3.2" class="ltx_text ltx_font_italic">cars</span> and [50%, 50%, 50%] for <span id="S4.p3.3.3" class="ltx_text ltx_font_italic">pedestrians</span> and <span id="S4.p3.3.4" class="ltx_text ltx_font_italic">cyclists</span>. This stricter requirement emphasizes the improved accuracy of the detection position by dynamic motion handling as well as the performance in object height detection by a more significant difference between 3D and 2D Birdâ€™s eye view (BEV) evaluation. The mean Average Precision (mAP) is the mean of the three class-wise APs. The results are specified for two different range regions, short-range (SR): evaluating all objects at distance of <math id="S4.p3.1.m1.3" class="ltx_Math" alttext="0\text{\,}" display="inline"><semantics id="S4.p3.1.m1.3a"><mrow id="S4.p3.1.m1.3.3" xref="S4.p3.1.m1.3.3.cmml"><mn id="S4.p3.1.m1.1.1.1.1.1.1" xref="S4.p3.1.m1.1.1.1.1.1.1.cmml">0</mn><mtext id="S4.p3.1.m1.2.2.2.2.2.2" xref="S4.p3.1.m1.2.2.2.2.2.2.cmml">Â </mtext><mi id="S4.p3.1.m1.3.3.3.3.3.3" xref="S4.p3.1.m1.3.3.3.3.3.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.3b"><apply id="S4.p3.1.m1.3.3.cmml" xref="S4.p3.1.m1.3.3"><csymbol cd="latexml" id="S4.p3.1.m1.2.2.2.2.2.2.cmml" xref="S4.p3.1.m1.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S4.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1.1.1.1">0</cn><csymbol cd="latexml" id="S4.p3.1.m1.3.3.3.3.3.3.cmml" xref="S4.p3.1.m1.3.3.3.3.3.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.3c">0\text{\,}</annotation></semantics></math>-<math id="S4.p3.2.m2.3" class="ltx_Math" alttext="30\text{\,}\mathrm{m}" display="inline"><semantics id="S4.p3.2.m2.3a"><mrow id="S4.p3.2.m2.3.3" xref="S4.p3.2.m2.3.3.cmml"><mn id="S4.p3.2.m2.1.1.1.1.1.1" xref="S4.p3.2.m2.1.1.1.1.1.1.cmml">30</mn><mtext id="S4.p3.2.m2.2.2.2.2.2.2" xref="S4.p3.2.m2.2.2.2.2.2.2.cmml">Â </mtext><mi class="ltx_unit" mathvariant="normal" id="S4.p3.2.m2.3.3.3.3.3.3" xref="S4.p3.2.m2.3.3.3.3.3.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.3b"><apply id="S4.p3.2.m2.3.3.cmml" xref="S4.p3.2.m2.3.3"><csymbol cd="latexml" id="S4.p3.2.m2.2.2.2.2.2.2.cmml" xref="S4.p3.2.m2.2.2.2.2.2.2">times</csymbol><cn type="integer" id="S4.p3.2.m2.1.1.1.1.1.1.cmml" xref="S4.p3.2.m2.1.1.1.1.1.1">30</cn><csymbol cd="latexml" id="S4.p3.2.m2.3.3.3.3.3.3.cmml" xref="S4.p3.2.m2.3.3.3.3.3.3">meter</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.3c">30\text{\,}\mathrm{m}</annotation></semantics></math> from the ego-vehicle and long-range (LR): evaluating all objects at distances <math id="S4.p3.3.m3.3" class="ltx_Math" alttext="&gt;30\text{\,}\mathrm{m}" display="inline"><semantics id="S4.p3.3.m3.3a"><mrow id="S4.p3.3.m3.3.3" xref="S4.p3.3.m3.3.3.cmml"><mrow id="S4.p3.3.m3.1.1.1.1.1.1" xref="S4.p3.3.m3.1.1.1.1.1.1.cmml"><mi id="S4.p3.3.m3.1.1.1.1.1.1.2" xref="S4.p3.3.m3.1.1.1.1.1.1.2.cmml"></mi><mo id="S4.p3.3.m3.1.1.1.1.1.1.1" xref="S4.p3.3.m3.1.1.1.1.1.1.1.cmml">&gt;</mo><mn id="S4.p3.3.m3.1.1.1.1.1.1.3" xref="S4.p3.3.m3.1.1.1.1.1.1.3.cmml">30</mn></mrow><mtext id="S4.p3.3.m3.2.2.2.2.2.2" xref="S4.p3.3.m3.2.2.2.2.2.2.cmml">Â </mtext><mi class="ltx_unit" mathvariant="normal" id="S4.p3.3.m3.3.3.3.3.3.3" xref="S4.p3.3.m3.3.3.3.3.3.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.3b"><apply id="S4.p3.3.m3.3.3.cmml" xref="S4.p3.3.m3.3.3"><csymbol cd="latexml" id="S4.p3.3.m3.2.2.2.2.2.2.cmml" xref="S4.p3.3.m3.2.2.2.2.2.2">times</csymbol><apply id="S4.p3.3.m3.1.1.1.1.1.1.cmml" xref="S4.p3.3.m3.1.1.1.1.1.1"><gt id="S4.p3.3.m3.1.1.1.1.1.1.1.cmml" xref="S4.p3.3.m3.1.1.1.1.1.1.1"></gt><csymbol cd="latexml" id="S4.p3.3.m3.1.1.1.1.1.1.2.cmml" xref="S4.p3.3.m3.1.1.1.1.1.1.2">absent</csymbol><cn type="integer" id="S4.p3.3.m3.1.1.1.1.1.1.3.cmml" xref="S4.p3.3.m3.1.1.1.1.1.1.3">30</cn></apply><csymbol cd="latexml" id="S4.p3.3.m3.3.3.3.3.3.3.cmml" xref="S4.p3.3.m3.3.3.3.3.3.3">meter</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.3c">&gt;30\text{\,}\mathrm{m}</annotation></semantics></math>.
The symmetric Chamfer Distance (sCD) quantifies the distance between (static) points after ego-motion correction for two consecutive time steps and is used as a metric to represent the error of estimated ego-motion. Due to the noisy radar point cloud, this metric is calculated utilizing the lidar point cloud.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Ego-Motion Estimation Results</h3>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>3D object detection results on the VoD dataset quantified as mAP and sCD between the current point cloud and the ego-motion corrected point cloud from the previous time step. All results, irrespective of the ego-motion (EM) correction approach, are generated by applying PointPillars on radar data accumulated over 5 frames, ignoring the motion of dynamic objects. The best results are marked in <span id="S4.T1.5.1" class="ltx_text ltx_font_bold">bold</span>. The arrow marks direction of better score.</figcaption>
<table id="S4.T1.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.3" class="ltx_td ltx_align_top ltx_border_tt"></td>
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_tt" style="width:42.7pt;">
<span id="S4.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.1.1.1.1.1" class="ltx_p">sCD [m] <math id="S4.T1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_align_middle ltx_border_tt" colspan="4">mAP <math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><mo stretchy="false" id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T1.3.4.1" class="ltx_tr">
<td id="S4.T1.3.4.1.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S4.T1.3.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.4.1.1.1.1" class="ltx_p" style="width:71.1pt;"><span id="S4.T1.3.4.1.1.1.1.1" class="ltx_text">EM estimation approach</span></span>
</span>
</td>
<td id="S4.T1.3.4.1.2" class="ltx_td ltx_align_middle" style="width:42.7pt;"></td>
<td id="S4.T1.3.4.1.3" class="ltx_td ltx_align_center ltx_align_middle ltx_border_t" colspan="2">3D</td>
<td id="S4.T1.3.4.1.4" class="ltx_td ltx_align_center ltx_align_middle ltx_border_t" colspan="2">BEV</td>
</tr>
<tr id="S4.T1.3.5.2" class="ltx_tr">
<td id="S4.T1.3.5.2.1" class="ltx_td ltx_align_middle" style="width:42.7pt;"></td>
<td id="S4.T1.3.5.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.5.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.5.2.2.1.1" class="ltx_p">SR</span>
</span>
</td>
<td id="S4.T1.3.5.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.5.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.5.2.3.1.1" class="ltx_p">LR</span>
</span>
</td>
<td id="S4.T1.3.5.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.5.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.5.2.4.1.1" class="ltx_p">SR</span>
</span>
</td>
<td id="S4.T1.3.5.2.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.5.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.5.2.5.1.1" class="ltx_p">LR</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.6.3" class="ltx_tr">
<td id="S4.T1.3.6.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.3.6.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.6.3.1.1.1" class="ltx_p" style="width:71.1pt;">No correction</span>
</span>
</td>
<td id="S4.T1.3.6.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S4.T1.3.6.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.6.3.2.1.1" class="ltx_p">0.285</span>
</span>
</td>
<td id="S4.T1.3.6.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.6.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.6.3.3.1.1" class="ltx_p">32.0</span>
</span>
</td>
<td id="S4.T1.3.6.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.6.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.6.3.4.1.1" class="ltx_p">10.1</span>
</span>
</td>
<td id="S4.T1.3.6.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.6.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.6.3.5.1.1" class="ltx_p">42.9</span>
</span>
</td>
<td id="S4.T1.3.6.3.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.6.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.6.3.6.1.1" class="ltx_p">22.6</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.7.4" class="ltx_tr">
<td id="S4.T1.3.7.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T1.3.7.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.7.4.1.1.1" class="ltx_p" style="width:71.1pt;">EM-P</span>
</span>
</td>
<td id="S4.T1.3.7.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:42.7pt;">
<span id="S4.T1.3.7.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.7.4.2.1.1" class="ltx_p">0.191</span>
</span>
</td>
<td id="S4.T1.3.7.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.7.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.7.4.3.1.1" class="ltx_p">35.1</span>
</span>
</td>
<td id="S4.T1.3.7.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.7.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.7.4.4.1.1" class="ltx_p">12.9</span>
</span>
</td>
<td id="S4.T1.3.7.4.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.7.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.7.4.5.1.1" class="ltx_p">48.6</span>
</span>
</td>
<td id="S4.T1.3.7.4.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_t" style="width:13.5pt;">
<span id="S4.T1.3.7.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.7.4.6.1.1" class="ltx_p">28.8</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.8.5" class="ltx_tr">
<td id="S4.T1.3.8.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.8.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.8.5.1.1.1" class="ltx_p" style="width:71.1pt;">EM-G-Lidar</span>
</span>
</td>
<td id="S4.T1.3.8.5.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S4.T1.3.8.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.8.5.2.1.1" class="ltx_p"><span id="S4.T1.3.8.5.2.1.1.1" class="ltx_text ltx_font_bold">0.180</span></span>
</span>
</td>
<td id="S4.T1.3.8.5.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.8.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.8.5.3.1.1" class="ltx_p">38.4</span>
</span>
</td>
<td id="S4.T1.3.8.5.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.8.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.8.5.4.1.1" class="ltx_p"><span id="S4.T1.3.8.5.4.1.1.1" class="ltx_text ltx_font_bold">14.2</span></span>
</span>
</td>
<td id="S4.T1.3.8.5.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.8.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.8.5.5.1.1" class="ltx_p"><span id="S4.T1.3.8.5.5.1.1.1" class="ltx_text ltx_font_bold">50.5</span></span>
</span>
</td>
<td id="S4.T1.3.8.5.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.8.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.8.5.6.1.1" class="ltx_p"><span id="S4.T1.3.8.5.6.1.1.1" class="ltx_text ltx_font_bold">29.6</span></span>
</span>
</td>
</tr>
<tr id="S4.T1.3.9.6" class="ltx_tr">
<td id="S4.T1.3.9.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.9.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.9.6.1.1.1" class="ltx_p" style="width:71.1pt;">EM-mG-Lidar</span>
</span>
</td>
<td id="S4.T1.3.9.6.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S4.T1.3.9.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.9.6.2.1.1" class="ltx_p">0.235</span>
</span>
</td>
<td id="S4.T1.3.9.6.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.9.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.9.6.3.1.1" class="ltx_p">33.5</span>
</span>
</td>
<td id="S4.T1.3.9.6.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.9.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.9.6.4.1.1" class="ltx_p">9.4</span>
</span>
</td>
<td id="S4.T1.3.9.6.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.9.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.9.6.5.1.1" class="ltx_p">46.3</span>
</span>
</td>
<td id="S4.T1.3.9.6.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.9.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.9.6.6.1.1" class="ltx_p">24.8</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.10.7" class="ltx_tr">
<td id="S4.T1.3.10.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.10.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.10.7.1.1.1" class="ltx_p" style="width:71.1pt;">EM-G-Radar</span>
</span>
</td>
<td id="S4.T1.3.10.7.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S4.T1.3.10.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.10.7.2.1.1" class="ltx_p">0.296</span>
</span>
</td>
<td id="S4.T1.3.10.7.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.10.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.10.7.3.1.1" class="ltx_p">32.3</span>
</span>
</td>
<td id="S4.T1.3.10.7.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.10.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.10.7.4.1.1" class="ltx_p">12.2</span>
</span>
</td>
<td id="S4.T1.3.10.7.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.10.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.10.7.5.1.1" class="ltx_p">44.1</span>
</span>
</td>
<td id="S4.T1.3.10.7.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.10.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.10.7.6.1.1" class="ltx_p">25.6</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.1.1.1" class="ltx_p" style="width:71.1pt;">EM-<math id="S4.T1.3.3.1.1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S4.T1.3.3.1.1.1.m1.1a"><msub id="S4.T1.3.3.1.1.1.m1.1.1" xref="S4.T1.3.3.1.1.1.m1.1.1.cmml"><mi id="S4.T1.3.3.1.1.1.m1.1.1.2" xref="S4.T1.3.3.1.1.1.m1.1.1.2.cmml">v</mi><mrow id="S4.T1.3.3.1.1.1.m1.1.1.3" xref="S4.T1.3.3.1.1.1.m1.1.1.3.cmml"><mi id="S4.T1.3.3.1.1.1.m1.1.1.3.2" xref="S4.T1.3.3.1.1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.T1.3.3.1.1.1.m1.1.1.3.1" xref="S4.T1.3.3.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T1.3.3.1.1.1.m1.1.1.3.3" xref="S4.T1.3.3.1.1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.1.1.1.m1.1b"><apply id="S4.T1.3.3.1.1.1.m1.1.1.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.3.3.1.1.1.m1.1.1.1.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T1.3.3.1.1.1.m1.1.1.2.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1.2">ğ‘£</ci><apply id="S4.T1.3.3.1.1.1.m1.1.1.3.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1.3"><times id="S4.T1.3.3.1.1.1.m1.1.1.3.1.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1.3.1"></times><ci id="S4.T1.3.3.1.1.1.m1.1.1.3.2.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.T1.3.3.1.1.1.m1.1.1.3.3.cmml" xref="S4.T1.3.3.1.1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.1.1.1.m1.1c">v_{rr}</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T1.3.3.2" class="ltx_td ltx_align_justify ltx_align_middle" style="width:42.7pt;">
<span id="S4.T1.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.2.1.1" class="ltx_p">0.235</span>
</span>
</td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.3.1.1" class="ltx_p">32.9</span>
</span>
</td>
<td id="S4.T1.3.3.4" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.4.1.1" class="ltx_p">11.9</span>
</span>
</td>
<td id="S4.T1.3.3.5" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.5.1.1" class="ltx_p">45.6</span>
</span>
</td>
<td id="S4.T1.3.3.6" class="ltx_td ltx_align_justify ltx_align_middle" style="width:13.5pt;">
<span id="S4.T1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.6.1.1" class="ltx_p">27.7</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.11.8" class="ltx_tr">
<td id="S4.T1.3.11.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T1.3.11.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.11.8.1.1.1" class="ltx_p" style="width:71.1pt;">EM-PCAc</span>
</span>
</td>
<td id="S4.T1.3.11.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:42.7pt;">
<span id="S4.T1.3.11.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.11.8.2.1.1" class="ltx_p">0.216</span>
</span>
</td>
<td id="S4.T1.3.11.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:13.5pt;">
<span id="S4.T1.3.11.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.11.8.3.1.1" class="ltx_p"><span id="S4.T1.3.11.8.3.1.1.1" class="ltx_text ltx_font_bold">38.7</span></span>
</span>
</td>
<td id="S4.T1.3.11.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:13.5pt;">
<span id="S4.T1.3.11.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.11.8.4.1.1" class="ltx_p">11.4</span>
</span>
</td>
<td id="S4.T1.3.11.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:13.5pt;">
<span id="S4.T1.3.11.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.11.8.5.1.1" class="ltx_p">48.5</span>
</span>
</td>
<td id="S4.T1.3.11.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_bb" style="width:13.5pt;">
<span id="S4.T1.3.11.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.11.8.6.1.1" class="ltx_p">25.4</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p">From Fig. <a href="#S3.F2" title="Figure 2 â€£ 3 Treatment of Dynamic Objects â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, two categories of ego-motion patterns can be differentiated. Approaches resulting in a smooth motion estimation, EM-mG-Lidar and EM-<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">v</mi><mrow id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.1.3.1" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ğ‘£</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><times id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">v_{rr}</annotation></semantics></math>, and algorithms with large deviations between frames. All deviating motion estimations show a similar pattern, most visible for the EM-G-Lidar estimated motion. This pattern repeats every 6 time steps. An explanation for this might be a time synchronization issue in data recording. This could also explain the apparent noise in the motion estimated from EM-P. Unfortunately, further investigations of this effect are impossible given the provided data.
The amount of noise deviates between the different estimation strategies. Visual analysis shows that GICP-radar-based motion is most noise-prone. This can also be observed regarding the sCD between time steps in Tab. <a href="#S4.T1" title="Table 1 â€£ 4.1 Ego-Motion Estimation Results â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Employing EM-G-Radar for correction results in larger and therefore worse sCD compared to the uncorrected data. The EM-G-Radar reflects the time synchronization issue, and the inherent noisy measurements of the radar point cloud, which results in an insufficient correction in regard to the lidar point cloud, while still improving the object detection on radar data over no correction.
The robust point matching utilized in PCAc yields a better motion estimation from the radar point cloud. It has a significantly lower sCD and higher mAP for the SR 3D-mAP but cannot reach the EM-P and EM-G-Lidar estimation performance.
Comparing the sCD in Tab. <a href="#S4.T1" title="Table 1 â€£ 4.1 Ego-Motion Estimation Results â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> to the mAP shows that a low sCD corresponds to a better object detection performance.
All approaches improve on the uncorrected baseline. For EM-mG-Lidar and EM-<math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msub id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">v</mi><mrow id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.2" xref="S4.SS1.p1.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.1.1.3.1" xref="S4.SS1.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS1.p1.2.m2.1.1.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">ğ‘£</ci><apply id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3"><times id="S4.SS1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3.1"></times><ci id="S4.SS1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.SS1.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">v_{rr}</annotation></semantics></math>, it is observable that the performance is low compared to the other approaches.
This strengthens the assumption that there is an inherent synchronization limitation.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Influence of the Accumulation Horizon</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Different time horizons for point cloud accumulation are investigated to validate the aggregation with respect to the provided single frame data and to investigate the effects of longer time horizons for dynamic object handling.
From Tab. <a href="#S4.T2" title="Table 2 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, it is apparent that a large part of the improvement is already reached when accumulating just 3 frames. Accumulating more frames can result in better performance for some of the considered metrics but is diminished by worse performance in others. Accumulation over 5 frames balances good performance in SR and LR. This is especially apparent when the dynamic motion of objects is considered. A longer time horizon of 10 frames only improves the SR BEV performance, while in other cases, a shorter accumulation horizon results in better performance.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>3D object detection results on the VoD dataset quantified as mAP. All models, irrespective of the accumulation horizon are generated by applying PointPillars on radar data corrected by the EM-P approach and if applicable, dynamic objects were corrected by the baseline method Dyn-GT. The best results, of only ego-motion and the best considering dynamic motion correction are marked in <span id="S4.T2.2.1" class="ltx_text ltx_font_bold">bold</span>.</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.3.1.1" class="ltx_tr">
<td id="S4.T2.3.1.1.1" class="ltx_td ltx_align_top ltx_border_tt"></td>
<td id="S4.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2">3D</td>
<td id="S4.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2">BEV</td>
</tr>
<tr id="S4.T2.3.2.2" class="ltx_tr">
<td id="S4.T2.3.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.2.1.1.1" class="ltx_p" style="width:113.8pt;">Accumulation strategy</span>
</span>
</td>
<td id="S4.T2.3.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.2.2.1.1" class="ltx_p" style="width:13.5pt;">SR</span>
</span>
</td>
<td id="S4.T2.3.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.2.3.1.1" class="ltx_p" style="width:13.5pt;">LR</span>
</span>
</td>
<td id="S4.T2.3.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.2.4.1.1" class="ltx_p" style="width:13.5pt;">SR</span>
</span>
</td>
<td id="S4.T2.3.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.2.2.5.1.1" class="ltx_p" style="width:13.5pt;">LR</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.3.3" class="ltx_tr">
<td id="S4.T2.3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.3.1.1.1" class="ltx_p" style="width:113.8pt;">1 scan</span>
</span>
</td>
<td id="S4.T2.3.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.3.2.1.1" class="ltx_p" style="width:13.5pt;">30.0</span>
</span>
</td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.3.3.1.1" class="ltx_p" style="width:13.5pt;">9.5</span>
</span>
</td>
<td id="S4.T2.3.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.3.4.1.1" class="ltx_p" style="width:13.5pt;">42.7</span>
</span>
</td>
<td id="S4.T2.3.3.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.3.5.1.1" class="ltx_p" style="width:13.5pt;">22.1</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.4.4" class="ltx_tr">
<td id="S4.T2.3.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.4.1.1.1" class="ltx_p" style="width:113.8pt;">3 scans</span>
</span>
</td>
<td id="S4.T2.3.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.4.2.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.4.4.2.1.1.1" class="ltx_text ltx_font_bold">35.9</span></span>
</span>
</td>
<td id="S4.T2.3.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.4.3.1.1" class="ltx_p" style="width:13.5pt;">12.8</span>
</span>
</td>
<td id="S4.T2.3.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.4.4.1.1" class="ltx_p" style="width:13.5pt;">47.2</span>
</span>
</td>
<td id="S4.T2.3.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.4.4.5.1.1" class="ltx_p" style="width:13.5pt;">26.9</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.5.5" class="ltx_tr">
<td id="S4.T2.3.5.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.5.1.1.1" class="ltx_p" style="width:113.8pt;">5 scans</span>
</span>
</td>
<td id="S4.T2.3.5.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.5.2.1.1" class="ltx_p" style="width:13.5pt;">35.1</span>
</span>
</td>
<td id="S4.T2.3.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.5.3.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.5.5.3.1.1.1" class="ltx_text ltx_font_bold">12.9</span></span>
</span>
</td>
<td id="S4.T2.3.5.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.5.4.1.1" class="ltx_p" style="width:13.5pt;">48.6</span>
</span>
</td>
<td id="S4.T2.3.5.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.5.5.5.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.5.5.5.1.1.1" class="ltx_text ltx_font_bold">28.8</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.3.6.6" class="ltx_tr">
<td id="S4.T2.3.6.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.6.1.1.1" class="ltx_p" style="width:113.8pt;">8 scans</span>
</span>
</td>
<td id="S4.T2.3.6.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.6.2.1.1" class="ltx_p" style="width:13.5pt;">35.7</span>
</span>
</td>
<td id="S4.T2.3.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.6.3.1.1" class="ltx_p" style="width:13.5pt;">12.0</span>
</span>
</td>
<td id="S4.T2.3.6.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.6.4.1.1" class="ltx_p" style="width:13.5pt;">49.1</span>
</span>
</td>
<td id="S4.T2.3.6.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.6.6.5.1.1" class="ltx_p" style="width:13.5pt;">26.4</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.7.7" class="ltx_tr">
<td id="S4.T2.3.7.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.7.1.1.1" class="ltx_p" style="width:113.8pt;">10 scans</span>
</span>
</td>
<td id="S4.T2.3.7.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.7.2.1.1" class="ltx_p" style="width:13.5pt;">35.3</span>
</span>
</td>
<td id="S4.T2.3.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.7.3.1.1" class="ltx_p" style="width:13.5pt;">10.2</span>
</span>
</td>
<td id="S4.T2.3.7.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.7.4.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.7.7.4.1.1.1" class="ltx_text ltx_font_bold">49.3</span></span>
</span>
</td>
<td id="S4.T2.3.7.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T2.3.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.7.7.5.1.1" class="ltx_p" style="width:13.5pt;">26.1</span>
</span>
</td>
</tr>
<tr id="S4.T2.3.8.8" class="ltx_tr">
<td id="S4.T2.3.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.8.1.1.1" class="ltx_p" style="width:113.8pt;">5 scans; Dyn-GT</span>
</span>
</td>
<td id="S4.T2.3.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.8.2.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.8.8.2.1.1.1" class="ltx_text ltx_font_bold">36.3</span></span>
</span>
</td>
<td id="S4.T2.3.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.8.3.1.1" class="ltx_p" style="width:13.5pt;">13.5</span>
</span>
</td>
<td id="S4.T2.3.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.8.4.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.8.8.4.1.1.1" class="ltx_text ltx_font_bold">47.6</span></span>
</span>
</td>
<td id="S4.T2.3.8.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T2.3.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.8.8.5.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.8.8.5.1.1.1" class="ltx_text ltx_font_bold">27.1</span></span>
</span>
</td>
</tr>
<tr id="S4.T2.3.9.9" class="ltx_tr">
<td id="S4.T2.3.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T2.3.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.9.1.1.1" class="ltx_p" style="width:113.8pt;">10 scans; Dyn-GT</span>
</span>
</td>
<td id="S4.T2.3.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T2.3.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.9.2.1.1" class="ltx_p" style="width:13.5pt;">35.4</span>
</span>
</td>
<td id="S4.T2.3.9.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T2.3.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.9.3.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T2.3.9.9.3.1.1.1" class="ltx_text ltx_font_bold">15.4</span></span>
</span>
</td>
<td id="S4.T2.3.9.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T2.3.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.9.4.1.1" class="ltx_p" style="width:13.5pt;">47.0</span>
</span>
</td>
<td id="S4.T2.3.9.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T2.3.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.9.9.5.1.1" class="ltx_p" style="width:13.5pt;">26.2</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.15357/assets/Instance_Association_GT.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="317" height="169" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.15357/assets/Instance_Association_Pred.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="326" height="169" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Prediction</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>BEV perspective of the instance association on an accumulated point cloud. The ego-vehicle is located at the origin of the red arrow (outside of image). Blue: static points; points in other colors than blue belong to object instances and the same color indicates the same instance ID.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Learning-Based Estimation of Dynamic Motion and Consideration for the Accumulation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The evaluation in Sec. <a href="#S4.SS1" title="4.1 Ego-Motion Estimation Results â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> has shown that the PCAc approach can estimate the ego-motion comparatively well, concluding that the PCAc approach works well on radar data too. Similar effects can be observed considering the instance association. Fig. <a href="#S4.F3" title="Figure 3 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows that the model can distinguish between different instances, but not all objects are detected correctly. For example, the model could not estimate the purple-colored object in Fig. <a href="#S4.F3.sf1" title="In Figure 3 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3a</span></a>. The dark green colored object in Fig. <a href="#S4.F3.sf1" title="In Figure 3 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3a</span></a> has been estimated correctly, but not all of the points that belong to the object are correctly predicted as part of an object. Above the light green object in Fig. <a href="#S4.F3.sf1" title="In Figure 3 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3a</span></a> is another object (observable in camera data) that is not labeled but predicted in Fig. <a href="#S4.F3.sf2" title="In Figure 3 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3b</span></a>. The red points in <a href="#S4.F3.sf2" title="In Figure 3 â€£ 4.2 Influence of the Accumulation Horizon â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3b</span></a> are predicted as dynamic while not belonging to any object. These effects could be a result of imperfect labels. Similar effects can be observed for the VoD lidar data.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Utilizing the object motion for the separate treatment of dynamic objects in accumulated point cloud for object detection shows a clear advantage for all approaches in Tab. <a href="#S4.T3" title="Table 3 â€£ 4.3 Learning-Based Estimation of Dynamic Motion and Consideration for the Accumulation â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> over just considering the ego-motion in Tab. <a href="#S4.T1" title="Table 1 â€£ 4.1 Ego-Motion Estimation Results â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
The naive approach of correcting the motion by just using <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><msub id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">v</mi><mrow id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml"><mi id="S4.SS3.p2.1.m1.1.1.3.2" xref="S4.SS3.p2.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p2.1.m1.1.1.3.1" xref="S4.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS3.p2.1.m1.1.1.3.3" xref="S4.SS3.p2.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">ğ‘£</ci><apply id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3"><times id="S4.SS3.p2.1.m1.1.1.3.1.cmml" xref="S4.SS3.p2.1.m1.1.1.3.1"></times><ci id="S4.SS3.p2.1.m1.1.1.3.2.cmml" xref="S4.SS3.p2.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.SS3.p2.1.m1.1.1.3.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">v_{rr}</annotation></semantics></math> performs better than the label-based baseline. This could be due to errors in the motion estimation from the labels.
PCAc yields the best results. This is partly due to the inherently improved ego-motion estimation, while the estimation of dynamic motion improves on the results from Tab. <a href="#S4.T1" title="Table 1 â€£ 4.1 Ego-Motion Estimation Results â€£ 4 Experimental Evaluation â€£ Ego-Motion Estimation and Dynamic Motion Separation from 3D Point Clouds for Accumulating Data and Improving 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in all metrics but the SR 3D-mAP measurement.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>
3D object detection results on the VoD dataset quantified as mAP. All models, irrespective of the motion correction approach, are generated by applying PointPillars on radar data accumulated over 5 frames. The best results are marked in <span id="S4.T3.3.1" class="ltx_text ltx_font_bold">bold</span>.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<th id="S4.T3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" rowspan="2">
<span id="S4.T3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.1.1.1" class="ltx_p" style="width:113.8pt;"><span id="S4.T3.1.2.1.1.1.1.1" class="ltx_text">Dynamic motion estimation approach</span></span>
</span>
</th>
<th id="S4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" colspan="2">3D</th>
<th id="S4.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" colspan="2">BEV</th>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<th id="S4.T3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S4.T3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.1.1.1" class="ltx_p" style="width:13.5pt;">SR</span>
</span>
</th>
<th id="S4.T3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S4.T3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.2.1.1" class="ltx_p" style="width:13.5pt;">LR</span>
</span>
</th>
<th id="S4.T3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S4.T3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.3.1.1" class="ltx_p" style="width:13.5pt;">SR</span>
</span>
</th>
<th id="S4.T3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t">
<span id="S4.T3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.4.1.1" class="ltx_p" style="width:13.5pt;">LR</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.4.1" class="ltx_tr">
<td id="S4.T3.1.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.1.1.1.1" class="ltx_p" style="width:113.8pt;">Dyn-GT</span>
</span>
</td>
<td id="S4.T3.1.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.1.2.1.1" class="ltx_p" style="width:13.5pt;">36.3</span>
</span>
</td>
<td id="S4.T3.1.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.1.3.1.1" class="ltx_p" style="width:13.5pt;">13.5</span>
</span>
</td>
<td id="S4.T3.1.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.1.4.1.1" class="ltx_p" style="width:13.5pt;">47.6</span>
</span>
</td>
<td id="S4.T3.1.4.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.1.5.1.1" class="ltx_p" style="width:13.5pt;">27.1</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.5.2" class="ltx_tr">
<td id="S4.T3.1.5.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.2.1.1.1" class="ltx_p" style="width:113.8pt;">Dyn-PCAc</span>
</span>
</td>
<td id="S4.T3.1.5.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.2.2.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T3.1.5.2.2.1.1.1" class="ltx_text ltx_font_bold">38.7</span></span>
</span>
</td>
<td id="S4.T3.1.5.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.2.3.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T3.1.5.2.3.1.1.1" class="ltx_text ltx_font_bold">16.0</span></span>
</span>
</td>
<td id="S4.T3.1.5.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.2.4.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T3.1.5.2.4.1.1.1" class="ltx_text ltx_font_bold">51.4</span></span>
</span>
</td>
<td id="S4.T3.1.5.2.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.2.5.1.1" class="ltx_p" style="width:13.5pt;"><span id="S4.T3.1.5.2.5.1.1.1" class="ltx_text ltx_font_bold">31.1</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.1.1" class="ltx_p" style="width:113.8pt;">Dyn-<math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><msub id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T3.1.1.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.1.1.m1.1.1.2.cmml">v</mi><mrow id="S4.T3.1.1.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.T3.1.1.1.1.1.m1.1.1.3.2" xref="S4.T3.1.1.1.1.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.T3.1.1.1.1.1.m1.1.1.3.1" xref="S4.T3.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T3.1.1.1.1.1.m1.1.1.3.3" xref="S4.T3.1.1.1.1.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T3.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.2">ğ‘£</ci><apply id="S4.T3.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.3"><times id="S4.T3.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.3.1"></times><ci id="S4.T3.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.T3.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">v_{rr}</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T3.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.2.1.1" class="ltx_p" style="width:13.5pt;">37.6</span>
</span>
</td>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.3.1.1" class="ltx_p" style="width:13.5pt;">13.8</span>
</span>
</td>
<td id="S4.T3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T3.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.4.1.1" class="ltx_p" style="width:13.5pt;">50.1</span>
</span>
</td>
<td id="S4.T3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T3.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.5.1.1" class="ltx_p" style="width:13.5pt;">29.0</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This work investigated the limitations of the VoD dataset for radar point cloud accumulation and approaches to mitigate missing ground truth ego-motion. It is shown that an improved ego-motion estimation improves the object detection performance. In addition to a better ego-motion estimation, a learning-based approach to mitigate the accumulation error for dynamic objects is applied to the dataset. Finally, it is shown that the motion of dynamic objects can be derived purely from the radar point cloud and that this improves object detection performance.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">For future work, assuming a highly accurate inertial measurement-based ego-motion estimation will be available, the PCAc should be modified to utilize this motion instead of the estimated motion. This simplifies the architecture and might further improve the instance motion estimation. Furthermore, additional radar features like <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="v_{rr}" display="inline"><semantics id="S5.p2.1.m1.1a"><msub id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mi id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">v</mi><mrow id="S5.p2.1.m1.1.1.3" xref="S5.p2.1.m1.1.1.3.cmml"><mi id="S5.p2.1.m1.1.1.3.2" xref="S5.p2.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.p2.1.m1.1.1.3.1" xref="S5.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S5.p2.1.m1.1.1.3.3" xref="S5.p2.1.m1.1.1.3.3.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1">subscript</csymbol><ci id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">ğ‘£</ci><apply id="S5.p2.1.m1.1.1.3.cmml" xref="S5.p2.1.m1.1.1.3"><times id="S5.p2.1.m1.1.1.3.1.cmml" xref="S5.p2.1.m1.1.1.3.1"></times><ci id="S5.p2.1.m1.1.1.3.2.cmml" xref="S5.p2.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S5.p2.1.m1.1.1.3.3.cmml" xref="S5.p2.1.m1.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">v_{rr}</annotation></semantics></math> and the radar cross-section could be integrated into PCAc for better instance motion estimation. This could also lead to improvements of the ultimate task of 3D object detection. Eventually, the PCAc model and the object detector could be trained as a single end-to-end model to boost the detection performance further.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A.Â Palffy, E.Â Pool, S.Â Baratam, J.Â F.Â P. Kooij, and D.Â M. Gavrila,
â€œMulti-class road user detection with 3+1d radar in the view-of-delft
dataset,â€ <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">IEEE Robotics and Automation Letters</span>, vol.Â 7, no.Â 2,
pp.Â 4961â€“4968, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
O.Â Schumann, M.Â Hahn, J.Â Dickmann, and C.Â WÃ¶hler, â€œSemantic segmentation on
radar point clouds,â€ in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">2018 21st International Conference on
Information Fusion (FUSION)</span>, pp.Â 2179â€“2186, 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Y.Â Long, D.Â Morris, X.Â Liu, M.Â Castro, P.Â Chakravarty, and P.Â Narayanan,
â€œFull-velocity radar returns by radar-camera fusion,â€ in <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">2021 IEEE/CVF
International Conference on Computer Vision (ICCV)</span>, pp.Â 16178â€“16187, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A.Â Dewan, T.Â Caselitz, G.Â D. Tipaldi, and W.Â Burgard, â€œRigid scene flow for 3d
lidar scans,â€ in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">2016 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS)</span>, pp.Â 1765â€“1770, 2016.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X.Â Liu, C.Â R. Qi, and L.Â J. Guibas, â€œFlownet3d: Learning scene flow in 3d
point clouds,â€ in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span>, pp.Â 529â€“537, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
F.Â Ding, Z.Â Pan, Y.Â Deng, J.Â Deng, and C.Â X. Lu, â€œSelf-supervised scene flow
estimation with 4-d automotive radar,â€ <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">IEEE Robotics and Automation
Letters</span>, vol.Â 7, no.Â 3, pp.Â 8233â€“8240, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S.Â Huang, Z.Â Gojcic, J.Â Huang, A.Â Wieser, and K.Â Schindler, â€œDynamic 3d scene
analysis byÂ point cloud accumulation,â€ in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Computer Vision â€“ ECCV
2022</span> (S.Â Avidan, G.Â Brostow, M.Â Cisse, G.Â M. Farinella, and T.Â Hassner,
eds.), (Cham), pp.Â 674â€“690, Springer Nature Switzerland, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y.Â Zhou, L.Â Liu, H.Â Zhao, M.Â LÃ³pez-BenÃ­tez, L.Â Yu, and Y.Â Yue, â€œTowards deep
radar perception for autonomous driving: Datasets, methods, and challenges,â€
<span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Sensors</span>, vol.Â 22, no.Â 11, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M.Â Meyer and G.Â Kuschk, â€œAutomotive radar dataset for deep learning based 3d
object detection,â€ in <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">2019 16th European Radar Conference (EuRAD)</span>,
pp.Â 129â€“132, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
S.Â Baratam, â€œRadar-guided monocular depth estimation and point cloud fusion
for 3d object detection,â€ 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A.Â Segal, D.Â HÃ¤hnel, and S.Â Thrun, â€œGeneralized-icp.,â€ in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Robotics:
Science and Systems</span> (J.Â Trinkle, Y.Â Matsuoka, and J.Â A. Castellanos, eds.),
The MIT Press, 2009.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
F.Â L. Markley, Y.Â Cheng, J.Â L. Crassidis, and Y.Â Oshman, â€œAveraging
quaternions,â€ <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Journal of Guidance, Control, and Dynamics</span>, vol.Â 30,
no.Â 4, pp.Â 1193â€“1197, 2007.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
D.Â Kellner, M.Â Barjenbruch, J.Â Klappstein, J.Â Dickmann, and K.Â Dietmayer,
â€œInstantaneous ego-motion estimation using doppler radar,â€ in <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">16th
International IEEE Conference on Intelligent Transportation Systems (ITSC
2013)</span>, pp.Â 869â€“874, 2013.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M.Â A. Fischler and R.Â C. Bolles, â€œRandom sample consensus: A paradigm for
model fitting with applications to image analysis and automated
cartography,â€ <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Commun. ACM</span>, vol.Â 24, p.Â 381â€“395, jun 1981.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A.Â H. Lang, S.Â Vora, H.Â Caesar, L.Â Zhou, J.Â Yang, and O.Â Beijbom,
â€œPointpillars: Fast encoders for object detection from point clouds,â€ in
<span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR)</span>, pp.Â 12689â€“12697, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
O.Â D. Team, â€œOpenpcdet: An open-source toolbox for 3d object detection from
point clouds,â€ 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
P.Â Palmer, M.Â Krueger, R.Â Altendorfer, G.Â Adam, and T.Â Bertram, â€œReviewing 3d
object detectors in the context of high-resolution 3+1d radar,â€ in <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Accepted for publication on 2023 IEEE/CVF Conference on Computer Vision and
Pattern Recognition Workshop on 3D Vision and Robotics (CVPRW)</span>, pp.Â 1â€“10,
2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
L.Â N. Smith and N.Â Topin, â€œSuper-convergence: very fast training of neural
networks using large learning rates,â€ in <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Artificial Intelligence and
Machine Learning for Multi-Domain Operations Applications</span> (T.Â Pham, ed.),
vol.Â 11006, p.Â 1100612, International Society for Optics and Photonics, SPIE,
2019.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A.Â Geiger, P.Â Lenz, C.Â Stiller, and R.Â Urtasun, â€œVision meets robotics: The
kitti dataset,â€ <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">The International Journal of Robotics Research</span>,
vol.Â 32, no.Â 11, pp.Â 1231â€“1237, 2013.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.15356" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.15357" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2308.15357">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.15357" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.15358" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 09:57:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
