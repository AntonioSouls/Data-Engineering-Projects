<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.05836] Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection</title><meta property="og:description" content="Accurate Named Entity Recognition (NER) is crucial for various information retrieval tasks in industry. However, despite significant progress in traditional NER methods, the extraction of Complex Named Entities remainsâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.05836">

<!--Generated on Thu Feb 29 09:05:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="complex named entity recognition,  weakly supervised object detection,  document understanding,  law,  information extraction">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hsiu-Wei Yang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Thomson Reuters Labs</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_streetaddress">333 Bay St.</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_state">Ontario</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_city">Toronto</span><span id="id5.5.id5" class="ltx_text ltx_affiliation_country">Canada</span><span id="id6.6.id6" class="ltx_text ltx_affiliation_postcode">M5H 2R2</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:leo.yang@thomsonreuters.com">leo.yang@thomsonreuters.com</a>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Abhinav Agrawal
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Thomson Reuters Labs</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Bangalore</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_state">Karnataka</span><span id="id10.4.id4" class="ltx_text ltx_affiliation_country">India</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:abhinav.agrawal@thomsonreuters.com">abhinav.agrawal@thomsonreuters.com</a>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id11.id1" class="ltx_p">Accurate Named Entity Recognition (NER) is crucial for various information retrieval tasks in industry. However, despite significant progress in traditional NER methods, the extraction of Complex Named Entities remains a relatively unexplored area. In this paper, we propose a novel system that combines object detection for Document Layout Analysis (DLA) with weakly supervised learning to address the challenge of extracting discontinuous complex named entities in legal documents. Notably, to the best of our knowledge, this is the first work to apply weak supervision to DLA. Our experimental results show that the model trained solely on pseudo labels outperforms the supervised baseline when gold-standard data is limited, highlighting the effectiveness of our proposed approach in reducing the dependency on annotated data.</p>
</div>
<div class="ltx_keywords">complex named entity recognition, weakly supervised object detection, document understanding, law, information extraction
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval; July 23â€“27, 2023; Taipei, Taiwan</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR â€™23), July 23â€“27, 2023, Taipei, Taiwan</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>10.1145/3539618.3591852</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">isbn: </span>978-1-4503-9408-6/23/07</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Applied computingÂ Law</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Document structure</span></span></span><span id="id10" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Computing methodologiesÂ Information extraction</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Named Entity Recognition (NER) is a long-studied field in Natural Language Processing (NLP) that involves detecting and classifying named entity (NE) mentions.
By correctly identifying NEs in queries or documents, search engines can improve both relevancy and efficiency <cite class="ltx_cite ltx_citemacro_citep">(Voorhees etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2005</a>; Guo etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2009</a>; Khalid etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2008</a>)</cite>.
For example, in the legal domain, knowing which paragraphs contain attorney information can help narrow the search scope for attorney-related queries.
However, traditional NER techniques may not be suitable for the legal NER problems.
In the industry, it is common to see the NEs of interest fall under the challenging category of <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">Complex Named Entity</span>,
which is described as <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">â€œnested, overlapping, and discontinuousâ€</span> <cite class="ltx_cite ltx_citemacro_citep">(Dai, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite> or <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">â€œsemantically ambiguiousâ€</span> <cite class="ltx_cite ltx_citemacro_citep">(Malmasi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this work, we are focused on extracting the discontinuous complex NEs.
Figure <a href="#S1.F1.sf1" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> shows several NEs in the caption page of an appellate brief,
including court name, partiesâ€™ names, filed date, etc.
Among these, the attorney profiles are an example of complex NEs, whose complication is introduced by Optical Character Recognition (OCR) <cite class="ltx_cite ltx_citemacro_citep">(Lopresti, <a href="#bib.bib15" title="" class="ltx_ref">2008</a>)</cite>.
Figure <a href="#S1.F1.sf2" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> depicts the problem: owing to the ambiguity in reading order, the OCRâ€™d text on the left column (blue) intertwines with the text on the right column (purple), violating the contiguity assumption of the traditional NER methods, i.e., a NE mention should be a sequence of contiguous tokens <cite class="ltx_cite ltx_citemacro_citep">(Dai, <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>.
To tackle this, we propose a novel system that incorporates an object detector for Document Layout Analysis (DLA) to alleviate the noise from OCR, especially in cases where the layout is complex.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In addition, it should be emphasized that the solution is required to be efficient in terms of data usage.
Primarily, there are two practical reasons for this. First, the expense of annotating legal documents is significant, as it involves hiring legal professionals who typically charge a higher hourly rate.
Second, frequent changes in business requirements necessitate constant modifications to labeling instructions, rendering recently annotated data imperfect.
In light of these concerns, we devise a weakly supervised method to leverage the available inexact labels.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To summarize, we combine DLA and heuristic rules to solve the complex NER problem.
To the best of our knowledge, this is the first work applying weak supervision to DLA.
The experimental results conclude that the system trained on pseudo labels can outperform the supervised baseline when gold-standard data is limited.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.05836/assets/x1.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="611" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S1.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Caption of the Brief</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.05836/assets/x2.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="123" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S1.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Complexity in OCRâ€™d Text</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.05836/assets/x3.png" id="S1.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="92" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S1.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Exact Label</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S1.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2305.05836/assets/x4.png" id="S1.F1.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S1.F1.sf4.3.2" class="ltx_text" style="font-size:90%;">Inexact Label</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">An example of complex entity extraction from an appellate brief. (a) shows that the attorney profiles in the caption page violate the contiguity assumption for traditional NER problem, i.e., the OCRâ€™d texts in (b) intertwine with each other. We address such an issue by a weakly supervised DLA approach, i.e., training an object detector to generate relevant bounding boxes as in (c), using image-level textual annotations as in (d).</span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>NER in the legal domain</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Legal NER demands tailored solutions due to the limited effectiveness of general-purpose NER methods in legal use cases, as noted by <cite class="ltx_cite ltx_citemacro_citet">Au etÂ al<span class="ltx_text">.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2022</a>)</cite>.
Legal documents are characterized by longer sentence structures and lengthier NEs, presenting challenges to traditional NER methods.
Moreover, OCR errors pose a critical challenge in real-world scenarios, as a single misrecognized character can lead to misspellings (e.g., Claire or Clair) and out-of-vocabulary (OOV) words. To overcome these challenges, <cite class="ltx_cite ltx_citemacro_citet">Trias etÂ al<span class="ltx_text">.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> developed a name correction state machine based on heuristic rules, while <cite class="ltx_cite ltx_citemacro_citet">Skylaki etÂ al<span class="ltx_text">.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> employed Pointer-Generator Networks to handle discontinuous entity mentions and OOV problems. Despite the complexity, capturing long and segmented named entities is a common business need, as seen in attorney profiles and the extraction of legal events <cite class="ltx_cite ltx_citemacro_citep">(Filtz etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Visually Rich Document Understanding</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Business documents, such as invoices and legal documents, are a type of visually rich data that uses both textual information and visual features, such as layout and font style, to convey their message.
Thus, to effectively analyze such data, it requires utilizing a multi-modal approach that jointly learns the textual, visual, and layout knowledge in a single framework <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>; Appalaraju etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2021</a>; Powalski etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.
The related topics include Key Information Extraction (KIE) <cite class="ltx_cite ltx_citemacro_citep">(Park etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Jaume etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>, Document Layout Analysis (DLA) <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2020</a>; Zhong etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>; Pfitzmann etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>, and DocVQA <cite class="ltx_cite ltx_citemacro_citep">(Mathew etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">In this work, we use DLA techniques, instead of the KIE ones that are mainly designed for the traditional NER problems (see more explanation in Section <a href="#S3" title="3. Problem Definition â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
DLA is commonly conducted via object detection, which is well-suited for identifying the boundaries of the elements in a document.
It is independent of OCR, so it can be a remedy for the OCR errors.
For our solution, we adopt LayoutLMv3 <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, which achieved state-of-the-art performance on PubLayNet <cite class="ltx_cite ltx_citemacro_citep">(Zhong etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>, a popular DLA dataset.
Compared with other DLA methods, the additional textual knowledge learned from pre-training advantages its predictions.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Weakly Supervised Object Detection</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Weakly supervised object detection techniques address the problem of inexact supervision <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2021</a>; Shao etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite>.
Instead of using object-level labels, these methods train an object detector using image-level labels, which only indicate the presence or absence of a specific object class in an image. In our work, we are only provided with the text of target NEs in a page, without corresponding bounding boxes, which is analogous to the aforementioned image-level labels. More information about our data is described in Section <a href="#S4.SS1" title="4.1. Exact and Inexact Labels â€£ 4. Our Approach â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Problem Definition</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.7" class="ltx_p">Traditionally, NER is formulated as a BIO sequence tagging problem that labels a sequence of tokens <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="x=\{w_{i}\}_{i=1}^{N}" display="inline"><semantics id="S3.p1.1.m1.1a"><mrow id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">x</mi><mo id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">=</mo><msubsup id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml"><mrow id="S3.p1.1.m1.1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p1.1.m1.1.1.1.1.1.1.2" xref="S3.p1.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S3.p1.1.m1.1.1.1.1.1.1.1" xref="S3.p1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.1.1.1.1.1.2" xref="S3.p1.1.m1.1.1.1.1.1.1.1.2.cmml">w</mi><mi id="S3.p1.1.m1.1.1.1.1.1.1.1.3" xref="S3.p1.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p1.1.m1.1.1.1.1.1.1.3" xref="S3.p1.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p1.1.m1.1.1.1.1.3" xref="S3.p1.1.m1.1.1.1.1.3.cmml"><mi id="S3.p1.1.m1.1.1.1.1.3.2" xref="S3.p1.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S3.p1.1.m1.1.1.1.1.3.1" xref="S3.p1.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p1.1.m1.1.1.1.1.3.3" xref="S3.p1.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p1.1.m1.1.1.1.3" xref="S3.p1.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><eq id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2"></eq><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">ğ‘¥</ci><apply id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.1">superscript</csymbol><apply id="S3.p1.1.m1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.1">subscript</csymbol><set id="S3.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1"><apply id="S3.p1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1.2">ğ‘¤</ci><ci id="S3.p1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.p1.1.m1.1.1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.1.1.3"><eq id="S3.p1.1.m1.1.1.1.1.3.1.cmml" xref="S3.p1.1.m1.1.1.1.1.3.1"></eq><ci id="S3.p1.1.m1.1.1.1.1.3.2.cmml" xref="S3.p1.1.m1.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S3.p1.1.m1.1.1.1.1.3.3.cmml" xref="S3.p1.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.1.m1.1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">x=\{w_{i}\}_{i=1}^{N}</annotation></semantics></math> with a sequence of labels <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="y=\{q_{i}\}_{i=1}^{N}" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">y</mi><mo id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">=</mo><msubsup id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml"><mrow id="S3.p1.2.m2.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.p1.2.m2.1.1.1.1.1.1.2" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><msub id="S3.p1.2.m2.1.1.1.1.1.1.1" xref="S3.p1.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.2" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S3.p1.2.m2.1.1.1.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.p1.2.m2.1.1.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.p1.2.m2.1.1.1.1.3" xref="S3.p1.2.m2.1.1.1.1.3.cmml"><mi id="S3.p1.2.m2.1.1.1.1.3.2" xref="S3.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S3.p1.2.m2.1.1.1.1.3.1" xref="S3.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S3.p1.2.m2.1.1.1.1.3.3" xref="S3.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.p1.2.m2.1.1.1.3" xref="S3.p1.2.m2.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"></eq><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">ğ‘¦</ci><apply id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">superscript</csymbol><apply id="S3.p1.2.m2.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1">subscript</csymbol><set id="S3.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1"><apply id="S3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.p1.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S3.p1.2.m2.1.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.1.3"><eq id="S3.p1.2.m2.1.1.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S3.p1.2.m2.1.1.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S3.p1.2.m2.1.1.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.2.m2.1.1.1.3.cmml" xref="S3.p1.2.m2.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">y=\{q_{i}\}_{i=1}^{N}</annotation></semantics></math>, where <math id="S3.p1.3.m3.3" class="ltx_Math" alttext="q_{i}\in\{B_{t},I_{t}\mid t\in T\}\cup\{O\}" display="inline"><semantics id="S3.p1.3.m3.3a"><mrow id="S3.p1.3.m3.3.3" xref="S3.p1.3.m3.3.3.cmml"><msub id="S3.p1.3.m3.3.3.4" xref="S3.p1.3.m3.3.3.4.cmml"><mi id="S3.p1.3.m3.3.3.4.2" xref="S3.p1.3.m3.3.3.4.2.cmml">q</mi><mi id="S3.p1.3.m3.3.3.4.3" xref="S3.p1.3.m3.3.3.4.3.cmml">i</mi></msub><mo id="S3.p1.3.m3.3.3.3" xref="S3.p1.3.m3.3.3.3.cmml">âˆˆ</mo><mrow id="S3.p1.3.m3.3.3.2" xref="S3.p1.3.m3.3.3.2.cmml"><mrow id="S3.p1.3.m3.3.3.2.2.2" xref="S3.p1.3.m3.3.3.2.2.3.cmml"><mo stretchy="false" id="S3.p1.3.m3.3.3.2.2.2.3" xref="S3.p1.3.m3.3.3.2.2.3.1.cmml">{</mo><mrow id="S3.p1.3.m3.2.2.1.1.1.1.2" xref="S3.p1.3.m3.2.2.1.1.1.1.3.cmml"><msub id="S3.p1.3.m3.2.2.1.1.1.1.1.1" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1.cmml"><mi id="S3.p1.3.m3.2.2.1.1.1.1.1.1.2" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1.2.cmml">B</mi><mi id="S3.p1.3.m3.2.2.1.1.1.1.1.1.3" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.p1.3.m3.2.2.1.1.1.1.2.3" xref="S3.p1.3.m3.2.2.1.1.1.1.3.cmml">,</mo><msub id="S3.p1.3.m3.2.2.1.1.1.1.2.2" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2.cmml"><mi id="S3.p1.3.m3.2.2.1.1.1.1.2.2.2" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2.2.cmml">I</mi><mi id="S3.p1.3.m3.2.2.1.1.1.1.2.2.3" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2.3.cmml">t</mi></msub></mrow><mo fence="true" lspace="0em" rspace="0em" id="S3.p1.3.m3.3.3.2.2.2.4" xref="S3.p1.3.m3.3.3.2.2.3.1.cmml">âˆ£</mo><mrow id="S3.p1.3.m3.3.3.2.2.2.2" xref="S3.p1.3.m3.3.3.2.2.2.2.cmml"><mi id="S3.p1.3.m3.3.3.2.2.2.2.2" xref="S3.p1.3.m3.3.3.2.2.2.2.2.cmml">t</mi><mo id="S3.p1.3.m3.3.3.2.2.2.2.1" xref="S3.p1.3.m3.3.3.2.2.2.2.1.cmml">âˆˆ</mo><mi id="S3.p1.3.m3.3.3.2.2.2.2.3" xref="S3.p1.3.m3.3.3.2.2.2.2.3.cmml">T</mi></mrow><mo stretchy="false" id="S3.p1.3.m3.3.3.2.2.2.5" xref="S3.p1.3.m3.3.3.2.2.3.1.cmml">}</mo></mrow><mo id="S3.p1.3.m3.3.3.2.3" xref="S3.p1.3.m3.3.3.2.3.cmml">âˆª</mo><mrow id="S3.p1.3.m3.3.3.2.4.2" xref="S3.p1.3.m3.3.3.2.4.1.cmml"><mo stretchy="false" id="S3.p1.3.m3.3.3.2.4.2.1" xref="S3.p1.3.m3.3.3.2.4.1.cmml">{</mo><mi id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">O</mi><mo stretchy="false" id="S3.p1.3.m3.3.3.2.4.2.2" xref="S3.p1.3.m3.3.3.2.4.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.3b"><apply id="S3.p1.3.m3.3.3.cmml" xref="S3.p1.3.m3.3.3"><in id="S3.p1.3.m3.3.3.3.cmml" xref="S3.p1.3.m3.3.3.3"></in><apply id="S3.p1.3.m3.3.3.4.cmml" xref="S3.p1.3.m3.3.3.4"><csymbol cd="ambiguous" id="S3.p1.3.m3.3.3.4.1.cmml" xref="S3.p1.3.m3.3.3.4">subscript</csymbol><ci id="S3.p1.3.m3.3.3.4.2.cmml" xref="S3.p1.3.m3.3.3.4.2">ğ‘</ci><ci id="S3.p1.3.m3.3.3.4.3.cmml" xref="S3.p1.3.m3.3.3.4.3">ğ‘–</ci></apply><apply id="S3.p1.3.m3.3.3.2.cmml" xref="S3.p1.3.m3.3.3.2"><union id="S3.p1.3.m3.3.3.2.3.cmml" xref="S3.p1.3.m3.3.3.2.3"></union><apply id="S3.p1.3.m3.3.3.2.2.3.cmml" xref="S3.p1.3.m3.3.3.2.2.2"><csymbol cd="latexml" id="S3.p1.3.m3.3.3.2.2.3.1.cmml" xref="S3.p1.3.m3.3.3.2.2.2.3">conditional-set</csymbol><list id="S3.p1.3.m3.2.2.1.1.1.1.3.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.2"><apply id="S3.p1.3.m3.2.2.1.1.1.1.1.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.2.2.1.1.1.1.1.1.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.p1.3.m3.2.2.1.1.1.1.1.1.2.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1.2">ğµ</ci><ci id="S3.p1.3.m3.2.2.1.1.1.1.1.1.3.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.p1.3.m3.2.2.1.1.1.1.2.2.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.3.m3.2.2.1.1.1.1.2.2.1.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S3.p1.3.m3.2.2.1.1.1.1.2.2.2.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2.2">ğ¼</ci><ci id="S3.p1.3.m3.2.2.1.1.1.1.2.2.3.cmml" xref="S3.p1.3.m3.2.2.1.1.1.1.2.2.3">ğ‘¡</ci></apply></list><apply id="S3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.p1.3.m3.3.3.2.2.2.2"><in id="S3.p1.3.m3.3.3.2.2.2.2.1.cmml" xref="S3.p1.3.m3.3.3.2.2.2.2.1"></in><ci id="S3.p1.3.m3.3.3.2.2.2.2.2.cmml" xref="S3.p1.3.m3.3.3.2.2.2.2.2">ğ‘¡</ci><ci id="S3.p1.3.m3.3.3.2.2.2.2.3.cmml" xref="S3.p1.3.m3.3.3.2.2.2.2.3">ğ‘‡</ci></apply></apply><set id="S3.p1.3.m3.3.3.2.4.1.cmml" xref="S3.p1.3.m3.3.3.2.4.2"><ci id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">ğ‘‚</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.3c">q_{i}\in\{B_{t},I_{t}\mid t\in T\}\cup\{O\}</annotation></semantics></math> and <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">B</annotation></semantics></math>, <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">I</annotation></semantics></math>, <math id="S3.p1.6.m6.1" class="ltx_Math" alttext="O" display="inline"><semantics id="S3.p1.6.m6.1a"><mi id="S3.p1.6.m6.1.1" xref="S3.p1.6.m6.1.1.cmml">O</mi><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.1b"><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">ğ‘‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.1c">O</annotation></semantics></math> denote the <span id="S3.p1.7.1" class="ltx_text ltx_font_bold">B</span>eginning, <span id="S3.p1.7.2" class="ltx_text ltx_font_bold">I</span>nside, and <span id="S3.p1.7.3" class="ltx_text ltx_font_bold">O</span>utside of a NE, respectively, for pre-defined NE types <math id="S3.p1.7.m7.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.p1.7.m7.1a"><mi id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><ci id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">T</annotation></semantics></math>. However, this tagging scheme assumes contiguous token occurrence for a NE, which does not hold in our scenario (see FigureÂ <a href="#S1.F1.sf2" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a>).</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.2" class="ltx_p">Hence, we relax the above formulation and re-define the output <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.p2.1.m1.1a"><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">y</annotation></semantics></math> as a set of unique token groups with predicted types, where each group is a subset of <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.p2.2.m2.1a"><mi id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><ci id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">x</annotation></semantics></math> and each token is only used in one group:</p>
<table id="S3.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equationgroup ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle y" display="inline"><semantics id="S3.E1X.2.1.1.m1.1a"><mi id="S3.E1X.2.1.1.m1.1.1" xref="S3.E1X.2.1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.E1X.2.1.1.m1.1b"><ci id="S3.E1X.2.1.1.m1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.2.1.1.m1.1c">\displaystyle y</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1X.3.2.2.m1.2" class="ltx_Math" alttext="\displaystyle=\{G_{e},t_{e}\mid e\in E\}" display="inline"><semantics id="S3.E1X.3.2.2.m1.2a"><mrow id="S3.E1X.3.2.2.m1.2.2" xref="S3.E1X.3.2.2.m1.2.2.cmml"><mi id="S3.E1X.3.2.2.m1.2.2.4" xref="S3.E1X.3.2.2.m1.2.2.4.cmml"></mi><mo id="S3.E1X.3.2.2.m1.2.2.3" xref="S3.E1X.3.2.2.m1.2.2.3.cmml">=</mo><mrow id="S3.E1X.3.2.2.m1.2.2.2.2" xref="S3.E1X.3.2.2.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1X.3.2.2.m1.2.2.2.2.3" xref="S3.E1X.3.2.2.m1.2.2.2.3.1.cmml">{</mo><mrow id="S3.E1X.3.2.2.m1.1.1.1.1.1.2" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.3.cmml"><msub id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.2" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.2.cmml">G</mi><mi id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.3" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.3.cmml">e</mi></msub><mo id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.3" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.3.cmml">,</mo><msub id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.cmml"><mi id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.2" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.cmml">t</mi><mi id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.3" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.3.cmml">e</mi></msub></mrow><mo fence="true" lspace="0em" rspace="0em" id="S3.E1X.3.2.2.m1.2.2.2.2.4" xref="S3.E1X.3.2.2.m1.2.2.2.3.1.cmml">âˆ£</mo><mrow id="S3.E1X.3.2.2.m1.2.2.2.2.2" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.cmml"><mi id="S3.E1X.3.2.2.m1.2.2.2.2.2.2" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.2.cmml">e</mi><mo id="S3.E1X.3.2.2.m1.2.2.2.2.2.1" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.1.cmml">âˆˆ</mo><mi id="S3.E1X.3.2.2.m1.2.2.2.2.2.3" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.3.cmml">E</mi></mrow><mo stretchy="false" id="S3.E1X.3.2.2.m1.2.2.2.2.5" xref="S3.E1X.3.2.2.m1.2.2.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.3.2.2.m1.2b"><apply id="S3.E1X.3.2.2.m1.2.2.cmml" xref="S3.E1X.3.2.2.m1.2.2"><eq id="S3.E1X.3.2.2.m1.2.2.3.cmml" xref="S3.E1X.3.2.2.m1.2.2.3"></eq><csymbol cd="latexml" id="S3.E1X.3.2.2.m1.2.2.4.cmml" xref="S3.E1X.3.2.2.m1.2.2.4">absent</csymbol><apply id="S3.E1X.3.2.2.m1.2.2.2.3.cmml" xref="S3.E1X.3.2.2.m1.2.2.2.2"><csymbol cd="latexml" id="S3.E1X.3.2.2.m1.2.2.2.3.1.cmml" xref="S3.E1X.3.2.2.m1.2.2.2.2.3">conditional-set</csymbol><list id="S3.E1X.3.2.2.m1.1.1.1.1.1.3.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2"><apply id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.2">ğº</ci><ci id="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.1.1.3">ğ‘’</ci></apply><apply id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.2">ğ‘¡</ci><ci id="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1X.3.2.2.m1.1.1.1.1.1.2.2.3">ğ‘’</ci></apply></list><apply id="S3.E1X.3.2.2.m1.2.2.2.2.2.cmml" xref="S3.E1X.3.2.2.m1.2.2.2.2.2"><in id="S3.E1X.3.2.2.m1.2.2.2.2.2.1.cmml" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.1"></in><ci id="S3.E1X.3.2.2.m1.2.2.2.2.2.2.cmml" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.2">ğ‘’</ci><ci id="S3.E1X.3.2.2.m1.2.2.2.2.2.3.cmml" xref="S3.E1X.3.2.2.m1.2.2.2.2.2.3">ğ¸</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.3.2.2.m1.2c">\displaystyle=\{G_{e},t_{e}\mid e\in E\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S3.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1Xa.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle G_{e}" display="inline"><semantics id="S3.E1Xa.2.1.1.m1.1a"><msub id="S3.E1Xa.2.1.1.m1.1.1" xref="S3.E1Xa.2.1.1.m1.1.1.cmml"><mi id="S3.E1Xa.2.1.1.m1.1.1.2" xref="S3.E1Xa.2.1.1.m1.1.1.2.cmml">G</mi><mi id="S3.E1Xa.2.1.1.m1.1.1.3" xref="S3.E1Xa.2.1.1.m1.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E1Xa.2.1.1.m1.1b"><apply id="S3.E1Xa.2.1.1.m1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.1.1.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.2">ğº</ci><ci id="S3.E1Xa.2.1.1.m1.1.1.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xa.2.1.1.m1.1c">\displaystyle G_{e}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xa.3.2.2.m1.2" class="ltx_Math" alttext="\displaystyle=\{s_{k}\mid s\in x\}_{k=1}^{K_{e}}\textnormal{~{}and~{}}\forall u\neq v\in E,G_{u}\cap G_{v}=\varnothing\textnormal{;}" display="inline"><semantics id="S3.E1Xa.3.2.2.m1.2a"><mrow id="S3.E1Xa.3.2.2.m1.2.2.2" xref="S3.E1Xa.3.2.2.m1.2.2.3.cmml"><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.4.cmml"></mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.5" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.cmml"><msubsup id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.cmml"><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.3.1.cmml">{</mo><msub id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo fence="true" lspace="0em" rspace="0em" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.3.1.cmml">âˆ£</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.2.cmml">s</mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.1.cmml">âˆˆ</mo><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.3.cmml">x</mi></mrow><mo stretchy="false" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.5" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.3.1.cmml">}</mo></mrow><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.2.cmml">k</mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.1.cmml">=</mo><mn id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.3.cmml">1</mn></mrow><msub id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.cmml"><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.2.cmml">K</mi><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.3.cmml">e</mi></msub></msubsup><mo lspace="0em" rspace="0em" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.3" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.3.cmml">â€‹</mo><mtext id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.4" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.4a.cmml">Â andÂ </mtext><mo lspace="0.167em" rspace="0em" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.3a" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.cmml"><mo rspace="0.167em" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.1" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.1.cmml">âˆ€</mo><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.2" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.2.cmml">u</mi></mrow></mrow><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.6" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.6.cmml">â‰ </mo><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.7" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.7.cmml">v</mi><mo id="S3.E1Xa.3.2.2.m1.1.1.1.1.8" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.8.cmml">âˆˆ</mo><mi id="S3.E1Xa.3.2.2.m1.1.1.1.1.9" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.9.cmml">E</mi></mrow><mo id="S3.E1Xa.3.2.2.m1.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.2.2.3a.cmml">,</mo><mrow id="S3.E1Xa.3.2.2.m1.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.cmml"><mrow id="S3.E1Xa.3.2.2.m1.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.cmml"><msub id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.cmml"><mi id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.2" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.2.cmml">G</mi><mi id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.3.cmml">u</mi></msub><mo id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.1" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.1.cmml">âˆ©</mo><msub id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.cmml"><mi id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.2" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.2.cmml">G</mi><mi id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.3" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.3.cmml">v</mi></msub></mrow><mo id="S3.E1Xa.3.2.2.m1.2.2.2.2.1" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.1.cmml">=</mo><mrow id="S3.E1Xa.3.2.2.m1.2.2.2.2.3" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.cmml"><mi mathvariant="normal" id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.2" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.2.cmml">âˆ…</mi><mo lspace="0em" rspace="0em" id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.1" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.1.cmml">â€‹</mo><mtext id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.3" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.3a.cmml">;</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1Xa.3.2.2.m1.2b"><apply id="S3.E1Xa.3.2.2.m1.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.2.2.3a.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"><and id="S3.E1Xa.3.2.2.m1.1.1.1.1a.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"></and><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1b.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"><eq id="S3.E1Xa.3.2.2.m1.1.1.1.1.5.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.5"></eq><csymbol cd="latexml" id="S3.E1Xa.3.2.2.m1.1.1.1.1.4.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.4">absent</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2"><times id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.3"></times><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2">superscript</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="latexml" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.3">conditional-set</csymbol><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.1.1.1.1.1.1.3">ğ‘˜</ci></apply><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2"><in id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.1"></in><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.2">ğ‘ </ci><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.2.2.2.3">ğ‘¥</ci></apply></apply><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4"><eq id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.1"></eq><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.2">ğ‘˜</ci><cn type="integer" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.2.4.3">1</cn></apply></apply><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4">subscript</csymbol><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.2">ğ¾</ci><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.3.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.2.4.3">ğ‘’</ci></apply></apply><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.4a.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.4"><mtext id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.4.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.4">Â andÂ </mtext></ci><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5"><csymbol cd="latexml" id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.1.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.1">for-all</csymbol><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.2.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.2.5.2">ğ‘¢</ci></apply></apply></apply><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1c.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"><neq id="S3.E1Xa.3.2.2.m1.1.1.1.1.6.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.6"></neq><share href="#S3.E1Xa.3.2.2.m1.1.1.1.1.2.cmml" id="S3.E1Xa.3.2.2.m1.1.1.1.1d.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"></share><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.7.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.7">ğ‘£</ci></apply><apply id="S3.E1Xa.3.2.2.m1.1.1.1.1e.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"><in id="S3.E1Xa.3.2.2.m1.1.1.1.1.8.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.8"></in><share href="#S3.E1Xa.3.2.2.m1.1.1.1.1.7.cmml" id="S3.E1Xa.3.2.2.m1.1.1.1.1f.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1"></share><ci id="S3.E1Xa.3.2.2.m1.1.1.1.1.9.cmml" xref="S3.E1Xa.3.2.2.m1.1.1.1.1.9">ğ¸</ci></apply></apply><apply id="S3.E1Xa.3.2.2.m1.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2"><eq id="S3.E1Xa.3.2.2.m1.2.2.2.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.1"></eq><apply id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2"><intersect id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.1"></intersect><apply id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.2">ğº</ci><ci id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.2.3">ğ‘¢</ci></apply><apply id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.1.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.2.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.2">ğº</ci><ci id="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.3.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.2.3.3">ğ‘£</ci></apply></apply><apply id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3"><times id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.1.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.1"></times><emptyset id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.2.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.2"></emptyset><ci id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.3a.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.3"><mtext id="S3.E1Xa.3.2.2.m1.2.2.2.2.3.3.cmml" xref="S3.E1Xa.3.2.2.m1.2.2.2.2.3.3">;</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xa.3.2.2.m1.2c">\displaystyle=\{s_{k}\mid s\in x\}_{k=1}^{K_{e}}\textnormal{~{}and~{}}\forall u\neq v\in E,G_{u}\cap G_{v}=\varnothing\textnormal{;}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S3.p2.9" class="ltx_p"><math id="S3.p2.3.m1.1" class="ltx_Math" alttext="t_{e}\in T" display="inline"><semantics id="S3.p2.3.m1.1a"><mrow id="S3.p2.3.m1.1.1" xref="S3.p2.3.m1.1.1.cmml"><msub id="S3.p2.3.m1.1.1.2" xref="S3.p2.3.m1.1.1.2.cmml"><mi id="S3.p2.3.m1.1.1.2.2" xref="S3.p2.3.m1.1.1.2.2.cmml">t</mi><mi id="S3.p2.3.m1.1.1.2.3" xref="S3.p2.3.m1.1.1.2.3.cmml">e</mi></msub><mo id="S3.p2.3.m1.1.1.1" xref="S3.p2.3.m1.1.1.1.cmml">âˆˆ</mo><mi id="S3.p2.3.m1.1.1.3" xref="S3.p2.3.m1.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m1.1b"><apply id="S3.p2.3.m1.1.1.cmml" xref="S3.p2.3.m1.1.1"><in id="S3.p2.3.m1.1.1.1.cmml" xref="S3.p2.3.m1.1.1.1"></in><apply id="S3.p2.3.m1.1.1.2.cmml" xref="S3.p2.3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.p2.3.m1.1.1.2.1.cmml" xref="S3.p2.3.m1.1.1.2">subscript</csymbol><ci id="S3.p2.3.m1.1.1.2.2.cmml" xref="S3.p2.3.m1.1.1.2.2">ğ‘¡</ci><ci id="S3.p2.3.m1.1.1.2.3.cmml" xref="S3.p2.3.m1.1.1.2.3">ğ‘’</ci></apply><ci id="S3.p2.3.m1.1.1.3.cmml" xref="S3.p2.3.m1.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m1.1c">t_{e}\in T</annotation></semantics></math> denotes the type; <math id="S3.p2.4.m2.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.p2.4.m2.1a"><mi id="S3.p2.4.m2.1.1" xref="S3.p2.4.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.p2.4.m2.1b"><ci id="S3.p2.4.m2.1.1.cmml" xref="S3.p2.4.m2.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m2.1c">E</annotation></semantics></math> is all the NEs; <math id="S3.p2.5.m3.1" class="ltx_Math" alttext="K_{e}" display="inline"><semantics id="S3.p2.5.m3.1a"><msub id="S3.p2.5.m3.1.1" xref="S3.p2.5.m3.1.1.cmml"><mi id="S3.p2.5.m3.1.1.2" xref="S3.p2.5.m3.1.1.2.cmml">K</mi><mi id="S3.p2.5.m3.1.1.3" xref="S3.p2.5.m3.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m3.1b"><apply id="S3.p2.5.m3.1.1.cmml" xref="S3.p2.5.m3.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m3.1.1.1.cmml" xref="S3.p2.5.m3.1.1">subscript</csymbol><ci id="S3.p2.5.m3.1.1.2.cmml" xref="S3.p2.5.m3.1.1.2">ğ¾</ci><ci id="S3.p2.5.m3.1.1.3.cmml" xref="S3.p2.5.m3.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m3.1c">K_{e}</annotation></semantics></math> is the sequence length of <math id="S3.p2.6.m4.1" class="ltx_Math" alttext="e" display="inline"><semantics id="S3.p2.6.m4.1a"><mi id="S3.p2.6.m4.1.1" xref="S3.p2.6.m4.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="S3.p2.6.m4.1b"><ci id="S3.p2.6.m4.1.1.cmml" xref="S3.p2.6.m4.1.1">ğ‘’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m4.1c">e</annotation></semantics></math>.
Note that token <math id="S3.p2.7.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.p2.7.m5.1a"><mi id="S3.p2.7.m5.1.1" xref="S3.p2.7.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.p2.7.m5.1b"><ci id="S3.p2.7.m5.1.1.cmml" xref="S3.p2.7.m5.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m5.1c">s</annotation></semantics></math> here is indexed by <math id="S3.p2.8.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p2.8.m6.1a"><mi id="S3.p2.8.m6.1.1" xref="S3.p2.8.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p2.8.m6.1b"><ci id="S3.p2.8.m6.1.1.cmml" xref="S3.p2.8.m6.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m6.1c">k</annotation></semantics></math> and the order can be different from their indices in <math id="S3.p2.9.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.p2.9.m7.1a"><mi id="S3.p2.9.m7.1.1" xref="S3.p2.9.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.p2.9.m7.1b"><ci id="S3.p2.9.m7.1.1.cmml" xref="S3.p2.9.m7.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m7.1c">x</annotation></semantics></math>.
In other words, the NEs are a set of unordered groups, whose tokens can be collected from arbitrary positions in a document, while the tokens within each group still must be in a specific order.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Our Approach</h2>

<figure id="S4.F2" class="ltx_figure"><img src="/html/2305.05836/assets/x5.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="393" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;">Object-level signal generation via paragraph segmentation and non-sequential token mapping.</span></figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To be more robust to complex layouts, we propose a multi-modal approach to extracting complex NEs in legal documents.
The core of our solution is a weakly supervised object detector for DLA that directly captures relevant paragraphs from document images, before the OCR process.
For training this component, we devise a pseudo label generator to create additional supervisory signal from textual inexact labels.
With the paragraphs being collected in a 2-D fashion and classified, we are allowed to established effective rules (see Section <a href="#S5.SS1.SSS3" title="5.1.3. Post-processing â€£ 5.1. Experimental Settings â€£ 5. Experiments â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.3</span></a>) to group and re-order the detected paragraphs; as a result, each group represents a NE in the final output.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Exact and Inexact Labels</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">For our object detection task, the exact labels are the bounding box (i.e., object-level) annotations of the target NEs on document images, from which we can calculate the overlapped area with the word-level bounding boxes from OCR to map the text.
FigureÂ <a href="#S1.F1.sf3" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a> is an example of the exact labels for attorney profile.
By contrast, the inexact labels are the image-level texts of the NEs, without location information (i.e., the corresponding bounding boxes).
Their literal values are not necessarily copied from the documents, owing to the previous business requirements of reformation.
For instance, as shown in FigureÂ <a href="#S1.F1.sf4" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a>, the annotators were asked to compile the sub-elements of attorney profile in the following order: attorney name, title, bar number, firm name, address, city, state, phone number, fax number, e-mail address, and party designation.
Moreover, the case of words was changed to title case, and extra commas were placed manually to separate the sub-elements.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Pseudo Label Generator</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To produce more object-level signals, we developed a 2-stage pseudo label generator based on our inexact labels.
In the initial stage, we create Regions of Interest (RoI) proposals by applying paragraph segmentation to a document.
In the subsequent stage, a RoI selector that is trained on our inexact labels is used to filter the proposals.
More specifically, this selector learns a non-sequential token mapping between the inexact labels and the OCRâ€™d text,
by which we assess how relevant a proposal is to the target NEs.
Finally, our object detector is fed the selected RoIs to perform weakly supervised learning.
We explain more details as follows:</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Paragraph Segmentation</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.7" class="ltx_p">Although the NE mentions in 1-D OCRâ€™d texts can be interrupted by noise, they are still mostly laid out as paragraphs in document images, from a 2-D perspective.
According to such observation, we devise a morphology-based <cite class="ltx_cite ltx_citemacro_citep">(Doermann etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2014</a>)</cite> algorithm to perform paragraph segmentation.
The input is a set of initial bounding boxes <math id="S4.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="B_{0}" display="inline"><semantics id="S4.SS2.SSS1.p1.1.m1.1a"><msub id="S4.SS2.SSS1.p1.1.m1.1.1" xref="S4.SS2.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS1.p1.1.m1.1.1.2" xref="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml">B</mi><mn id="S4.SS2.SSS1.p1.1.m1.1.1.3" xref="S4.SS2.SSS1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.1.m1.1b"><apply id="S4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.2">ğµ</ci><cn type="integer" id="S4.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.1.m1.1c">B_{0}</annotation></semantics></math>, and the algorithm yields a set of paragraph RoIs <math id="S4.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="B_{h}" display="inline"><semantics id="S4.SS2.SSS1.p1.2.m2.1a"><msub id="S4.SS2.SSS1.p1.2.m2.1.1" xref="S4.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS1.p1.2.m2.1.1.2" xref="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml">B</mi><mi id="S4.SS2.SSS1.p1.2.m2.1.1.3" xref="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.2.m2.1b"><apply id="S4.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.2">ğµ</ci><ci id="S4.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS2.SSS1.p1.2.m2.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.2.m2.1c">B_{h}</annotation></semantics></math> after <math id="S4.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S4.SS2.SSS1.p1.3.m3.1a"><mi id="S4.SS2.SSS1.p1.3.m3.1.1" xref="S4.SS2.SSS1.p1.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.3.m3.1b"><ci id="S4.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS1.p1.3.m3.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.3.m3.1c">h</annotation></semantics></math> times of iteration.
The proposed technique is depicted in the upper part of Figure <a href="#S4.F2" title="Figure 2 â€£ 4. Our Approach â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
To summarize, it dilates the bounding boxes with a kernel <math id="S4.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S4.SS2.SSS1.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS1.p1.4.m4.1.1" xref="S4.SS2.SSS1.p1.4.m4.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.4.m4.1b"><ci id="S4.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS1.p1.4.m4.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.4.m4.1c">\mathcal{K}</annotation></semantics></math> and merges the overlapped ones repeatedly. After each iteration, the RoI of a paragraph is re-defined by the contour of the merged lines. This process continues until one of the two halting conditions is reached.
The first one is patience <math id="S4.SS2.SSS1.p1.5.m5.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S4.SS2.SSS1.p1.5.m5.1a"><mi id="S4.SS2.SSS1.p1.5.m5.1.1" xref="S4.SS2.SSS1.p1.5.m5.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.5.m5.1b"><ci id="S4.SS2.SSS1.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS1.p1.5.m5.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.5.m5.1c">\rho</annotation></semantics></math>: the process is halted if no merger is triggered after <math id="S4.SS2.SSS1.p1.6.m6.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S4.SS2.SSS1.p1.6.m6.1a"><mi id="S4.SS2.SSS1.p1.6.m6.1.1" xref="S4.SS2.SSS1.p1.6.m6.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.6.m6.1b"><ci id="S4.SS2.SSS1.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS1.p1.6.m6.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.6.m6.1c">\rho</annotation></semantics></math> iterations.
The other is aggregation ratio <math id="S4.SS2.SSS1.p1.7.m7.2" class="ltx_Math" alttext="\delta=\frac{|B_{h}|}{|B_{0}|}" display="inline"><semantics id="S4.SS2.SSS1.p1.7.m7.2a"><mrow id="S4.SS2.SSS1.p1.7.m7.2.3" xref="S4.SS2.SSS1.p1.7.m7.2.3.cmml"><mi id="S4.SS2.SSS1.p1.7.m7.2.3.2" xref="S4.SS2.SSS1.p1.7.m7.2.3.2.cmml">Î´</mi><mo id="S4.SS2.SSS1.p1.7.m7.2.3.1" xref="S4.SS2.SSS1.p1.7.m7.2.3.1.cmml">=</mo><mfrac id="S4.SS2.SSS1.p1.7.m7.2.2" xref="S4.SS2.SSS1.p1.7.m7.2.2.cmml"><mrow id="S4.SS2.SSS1.p1.7.m7.1.1.1.1" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.2" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.2.1.cmml">|</mo><msub id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.cmml"><mi id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.2" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.2.cmml">B</mi><mi id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.3" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.3.cmml">h</mi></msub><mo stretchy="false" id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.3" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.2.1.cmml">|</mo></mrow><mrow id="S4.SS2.SSS1.p1.7.m7.2.2.2.1" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.2.cmml"><mo stretchy="false" id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.2" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.2.1.cmml">|</mo><msub id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.cmml"><mi id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.2" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.2.cmml">B</mi><mn id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.3" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.3.cmml">0</mn></msub><mo stretchy="false" id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.3" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.2.1.cmml">|</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS1.p1.7.m7.2b"><apply id="S4.SS2.SSS1.p1.7.m7.2.3.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.3"><eq id="S4.SS2.SSS1.p1.7.m7.2.3.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.3.1"></eq><ci id="S4.SS2.SSS1.p1.7.m7.2.3.2.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.3.2">ğ›¿</ci><apply id="S4.SS2.SSS1.p1.7.m7.2.2.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2"><divide id="S4.SS2.SSS1.p1.7.m7.2.2.3.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2"></divide><apply id="S4.SS2.SSS1.p1.7.m7.1.1.1.2.cmml" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1"><abs id="S4.SS2.SSS1.p1.7.m7.1.1.1.2.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.2"></abs><apply id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.2.cmml" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.2">ğµ</ci><ci id="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.3.cmml" xref="S4.SS2.SSS1.p1.7.m7.1.1.1.1.1.3">â„</ci></apply></apply><apply id="S4.SS2.SSS1.p1.7.m7.2.2.2.2.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1"><abs id="S4.SS2.SSS1.p1.7.m7.2.2.2.2.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.2"></abs><apply id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.1.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1">subscript</csymbol><ci id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.2.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.2">ğµ</ci><cn type="integer" id="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.3.cmml" xref="S4.SS2.SSS1.p1.7.m7.2.2.2.1.1.3">0</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS1.p1.7.m7.2c">\delta=\frac{|B_{h}|}{|B_{0}|}</annotation></semantics></math>, which restricts the minimum number of RoIs.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Non-sequential Token Mapping</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">To enable RoI selection, we need to measure the relevance scores of RoIs based on token coverage,
i.e., a RoI that has more tokens that are used in target NEs should receive a higher score.
However, our inexact labels only provides the literal values of NEs.
Without knowing the 2-D locations, we are not able to directly calculate this coverage.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.3" class="ltx_p">To bridge this gap, we train a sequence-to-sequence model to infer a mapping from inexact labels to OCRâ€™d text, from which we can obtain the associated bounding boxes.
Note that inexact labels and OCRâ€™d text can have inconsistent token ordering (e.g., when inexact labels are re-ordered as in Figure <a href="#S1.F1.sf4" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a>), so tracing the locations via a sequence matching algorithm might not be always feasible.
Inspired byÂ <cite class="ltx_cite ltx_citemacro_citet">Skylaki etÂ al<span class="ltx_text">.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, who exhibited the effectiveness of Pointer-Generator Networks <cite class="ltx_cite ltx_citemacro_citep">(See etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2017</a>)</cite> on legal NER, we exploit the same model and use its copying mechanism as the non-sequential token mapping.
The source (target) sequence for this model is the OCRâ€™d text (the inexact labels of the target NEs).
We observed that the trained model behaves similarly to human annotators â€” the majority of output tokens are copied from the document;
thus, we can rely on the attention score <math id="S4.SS2.SSS2.p2.1.m1.2" class="ltx_Math" alttext="A_{i,j}" display="inline"><semantics id="S4.SS2.SSS2.p2.1.m1.2a"><msub id="S4.SS2.SSS2.p2.1.m1.2.3" xref="S4.SS2.SSS2.p2.1.m1.2.3.cmml"><mi id="S4.SS2.SSS2.p2.1.m1.2.3.2" xref="S4.SS2.SSS2.p2.1.m1.2.3.2.cmml">A</mi><mrow id="S4.SS2.SSS2.p2.1.m1.2.2.2.4" xref="S4.SS2.SSS2.p2.1.m1.2.2.2.3.cmml"><mi id="S4.SS2.SSS2.p2.1.m1.1.1.1.1" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1.cmml">i</mi><mo id="S4.SS2.SSS2.p2.1.m1.2.2.2.4.1" xref="S4.SS2.SSS2.p2.1.m1.2.2.2.3.cmml">,</mo><mi id="S4.SS2.SSS2.p2.1.m1.2.2.2.2" xref="S4.SS2.SSS2.p2.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.1.m1.2b"><apply id="S4.SS2.SSS2.p2.1.m1.2.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.2.3"><csymbol cd="ambiguous" id="S4.SS2.SSS2.p2.1.m1.2.3.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.2.3">subscript</csymbol><ci id="S4.SS2.SSS2.p2.1.m1.2.3.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.2.3.2">ğ´</ci><list id="S4.SS2.SSS2.p2.1.m1.2.2.2.3.cmml" xref="S4.SS2.SSS2.p2.1.m1.2.2.2.4"><ci id="S4.SS2.SSS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p2.1.m1.1.1.1.1">ğ‘–</ci><ci id="S4.SS2.SSS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS2.SSS2.p2.1.m1.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.1.m1.2c">A_{i,j}</annotation></semantics></math> to estimate the location, where <math id="S4.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS2.SSS2.p2.2.m2.1a"><mi id="S4.SS2.SSS2.p2.2.m2.1.1" xref="S4.SS2.SSS2.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.2.m2.1b"><ci id="S4.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS2.p2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.2.m2.1c">i</annotation></semantics></math> (<math id="S4.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.SS2.SSS2.p2.3.m3.1a"><mi id="S4.SS2.SSS2.p2.3.m3.1.1" xref="S4.SS2.SSS2.p2.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p2.3.m3.1b"><ci id="S4.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS2.p2.3.m3.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p2.3.m3.1c">j</annotation></semantics></math>) denotes the encoder (decoder) step.
The lower part of Figure <a href="#S4.F2" title="Figure 2 â€£ 4. Our Approach â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the model and how the attention scores can aid the coverage estimation.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3. </span>Object-Level Signal Generation.</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.13" class="ltx_p">By using the produced RoIs (i.e., paragraph bounding boxes) <math id="S4.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="B_{h}" display="inline"><semantics id="S4.SS2.SSS3.p1.1.m1.1a"><msub id="S4.SS2.SSS3.p1.1.m1.1.1" xref="S4.SS2.SSS3.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS3.p1.1.m1.1.1.2" xref="S4.SS2.SSS3.p1.1.m1.1.1.2.cmml">B</mi><mi id="S4.SS2.SSS3.p1.1.m1.1.1.3" xref="S4.SS2.SSS3.p1.1.m1.1.1.3.cmml">h</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.1.m1.1b"><apply id="S4.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1.2">ğµ</ci><ci id="S4.SS2.SSS3.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS3.p1.1.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.1.m1.1c">B_{h}</annotation></semantics></math> and the token mapping <math id="S4.SS2.SSS3.p1.2.m2.2" class="ltx_Math" alttext="A_{i,j}" display="inline"><semantics id="S4.SS2.SSS3.p1.2.m2.2a"><msub id="S4.SS2.SSS3.p1.2.m2.2.3" xref="S4.SS2.SSS3.p1.2.m2.2.3.cmml"><mi id="S4.SS2.SSS3.p1.2.m2.2.3.2" xref="S4.SS2.SSS3.p1.2.m2.2.3.2.cmml">A</mi><mrow id="S4.SS2.SSS3.p1.2.m2.2.2.2.4" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.3.cmml"><mi id="S4.SS2.SSS3.p1.2.m2.1.1.1.1" xref="S4.SS2.SSS3.p1.2.m2.1.1.1.1.cmml">i</mi><mo id="S4.SS2.SSS3.p1.2.m2.2.2.2.4.1" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S4.SS2.SSS3.p1.2.m2.2.2.2.2" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.2.m2.2b"><apply id="S4.SS2.SSS3.p1.2.m2.2.3.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.3"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.2.m2.2.3.1.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.3">subscript</csymbol><ci id="S4.SS2.SSS3.p1.2.m2.2.3.2.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.3.2">ğ´</ci><list id="S4.SS2.SSS3.p1.2.m2.2.2.2.3.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.4"><ci id="S4.SS2.SSS3.p1.2.m2.1.1.1.1.cmml" xref="S4.SS2.SSS3.p1.2.m2.1.1.1.1">ğ‘–</ci><ci id="S4.SS2.SSS3.p1.2.m2.2.2.2.2.cmml" xref="S4.SS2.SSS3.p1.2.m2.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.2.m2.2c">A_{i,j}</annotation></semantics></math>, we can measure the relevancy of the proposals and preserve the ones satisfying the pre-defined thresholds.
In order to be compatible with our internal explainability tool, we first aggregate the attention scores to line level <math id="S4.SS2.SSS3.p1.3.m3.4" class="ltx_Math" alttext="A_{l,j}=\sum_{i=l_{s}}^{l_{e}}A_{i,j}" display="inline"><semantics id="S4.SS2.SSS3.p1.3.m3.4a"><mrow id="S4.SS2.SSS3.p1.3.m3.4.5" xref="S4.SS2.SSS3.p1.3.m3.4.5.cmml"><msub id="S4.SS2.SSS3.p1.3.m3.4.5.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.2.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.4.5.2.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.2.2.cmml">A</mi><mrow id="S4.SS2.SSS3.p1.3.m3.2.2.2.4" xref="S4.SS2.SSS3.p1.3.m3.2.2.2.3.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.1.1.1.1" xref="S4.SS2.SSS3.p1.3.m3.1.1.1.1.cmml">l</mi><mo id="S4.SS2.SSS3.p1.3.m3.2.2.2.4.1" xref="S4.SS2.SSS3.p1.3.m3.2.2.2.3.cmml">,</mo><mi id="S4.SS2.SSS3.p1.3.m3.2.2.2.2" xref="S4.SS2.SSS3.p1.3.m3.2.2.2.2.cmml">j</mi></mrow></msub><mo rspace="0.111em" id="S4.SS2.SSS3.p1.3.m3.4.5.1" xref="S4.SS2.SSS3.p1.3.m3.4.5.1.cmml">=</mo><mrow id="S4.SS2.SSS3.p1.3.m3.4.5.3" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.cmml"><msubsup id="S4.SS2.SSS3.p1.3.m3.4.5.3.1" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.cmml"><mo id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.2.cmml">âˆ‘</mo><mrow id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.2.cmml">i</mi><mo id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.1" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.1.cmml">=</mo><msub id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.2.cmml">l</mi><mi id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.3" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.3.cmml">s</mi></msub></mrow><msub id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.2.cmml">l</mi><mi id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.3" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.3.cmml">e</mi></msub></msubsup><msub id="S4.SS2.SSS3.p1.3.m3.4.5.3.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.2.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.4.5.3.2.2" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.2.2.cmml">A</mi><mrow id="S4.SS2.SSS3.p1.3.m3.4.4.2.4" xref="S4.SS2.SSS3.p1.3.m3.4.4.2.3.cmml"><mi id="S4.SS2.SSS3.p1.3.m3.3.3.1.1" xref="S4.SS2.SSS3.p1.3.m3.3.3.1.1.cmml">i</mi><mo id="S4.SS2.SSS3.p1.3.m3.4.4.2.4.1" xref="S4.SS2.SSS3.p1.3.m3.4.4.2.3.cmml">,</mo><mi id="S4.SS2.SSS3.p1.3.m3.4.4.2.2" xref="S4.SS2.SSS3.p1.3.m3.4.4.2.2.cmml">j</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.3.m3.4b"><apply id="S4.SS2.SSS3.p1.3.m3.4.5.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5"><eq id="S4.SS2.SSS3.p1.3.m3.4.5.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.1"></eq><apply id="S4.SS2.SSS3.p1.3.m3.4.5.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.2"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m3.4.5.2.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.2">subscript</csymbol><ci id="S4.SS2.SSS3.p1.3.m3.4.5.2.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.2.2">ğ´</ci><list id="S4.SS2.SSS3.p1.3.m3.2.2.2.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.2.2.2.4"><ci id="S4.SS2.SSS3.p1.3.m3.1.1.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.1.1.1.1">ğ‘™</ci><ci id="S4.SS2.SSS3.p1.3.m3.2.2.2.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.2.2.2.2">ğ‘—</ci></list></apply><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3"><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1">superscript</csymbol><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1">subscript</csymbol><sum id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.2"></sum><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3"><eq id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.1"></eq><ci id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.2">ğ‘–</ci><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3">subscript</csymbol><ci id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.2">ğ‘™</ci><ci id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.2.3.3.3">ğ‘ </ci></apply></apply></apply><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3">subscript</csymbol><ci id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.2">ğ‘™</ci><ci id="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.1.3.3">ğ‘’</ci></apply></apply><apply id="S4.SS2.SSS3.p1.3.m3.4.5.3.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.2"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.3.m3.4.5.3.2.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.2">subscript</csymbol><ci id="S4.SS2.SSS3.p1.3.m3.4.5.3.2.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.5.3.2.2">ğ´</ci><list id="S4.SS2.SSS3.p1.3.m3.4.4.2.3.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.4.2.4"><ci id="S4.SS2.SSS3.p1.3.m3.3.3.1.1.cmml" xref="S4.SS2.SSS3.p1.3.m3.3.3.1.1">ğ‘–</ci><ci id="S4.SS2.SSS3.p1.3.m3.4.4.2.2.cmml" xref="S4.SS2.SSS3.p1.3.m3.4.4.2.2">ğ‘—</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.3.m3.4c">A_{l,j}=\sum_{i=l_{s}}^{l_{e}}A_{i,j}</annotation></semantics></math>, where <math id="S4.SS2.SSS3.p1.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.SSS3.p1.4.m4.1a"><mi id="S4.SS2.SSS3.p1.4.m4.1.1" xref="S4.SS2.SSS3.p1.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.4.m4.1b"><ci id="S4.SS2.SSS3.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS3.p1.4.m4.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.4.m4.1c">l</annotation></semantics></math> is a line and <math id="S4.SS2.SSS3.p1.5.m5.1" class="ltx_Math" alttext="l_{s}" display="inline"><semantics id="S4.SS2.SSS3.p1.5.m5.1a"><msub id="S4.SS2.SSS3.p1.5.m5.1.1" xref="S4.SS2.SSS3.p1.5.m5.1.1.cmml"><mi id="S4.SS2.SSS3.p1.5.m5.1.1.2" xref="S4.SS2.SSS3.p1.5.m5.1.1.2.cmml">l</mi><mi id="S4.SS2.SSS3.p1.5.m5.1.1.3" xref="S4.SS2.SSS3.p1.5.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.5.m5.1b"><apply id="S4.SS2.SSS3.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.5.m5.1.1.1.cmml" xref="S4.SS2.SSS3.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.5.m5.1.1.2.cmml" xref="S4.SS2.SSS3.p1.5.m5.1.1.2">ğ‘™</ci><ci id="S4.SS2.SSS3.p1.5.m5.1.1.3.cmml" xref="S4.SS2.SSS3.p1.5.m5.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.5.m5.1c">l_{s}</annotation></semantics></math> (<math id="S4.SS2.SSS3.p1.6.m6.1" class="ltx_Math" alttext="l_{e}" display="inline"><semantics id="S4.SS2.SSS3.p1.6.m6.1a"><msub id="S4.SS2.SSS3.p1.6.m6.1.1" xref="S4.SS2.SSS3.p1.6.m6.1.1.cmml"><mi id="S4.SS2.SSS3.p1.6.m6.1.1.2" xref="S4.SS2.SSS3.p1.6.m6.1.1.2.cmml">l</mi><mi id="S4.SS2.SSS3.p1.6.m6.1.1.3" xref="S4.SS2.SSS3.p1.6.m6.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.6.m6.1b"><apply id="S4.SS2.SSS3.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.6.m6.1.1.1.cmml" xref="S4.SS2.SSS3.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.6.m6.1.1.2.cmml" xref="S4.SS2.SSS3.p1.6.m6.1.1.2">ğ‘™</ci><ci id="S4.SS2.SSS3.p1.6.m6.1.1.3.cmml" xref="S4.SS2.SSS3.p1.6.m6.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.6.m6.1c">l_{e}</annotation></semantics></math>) denotes the starting (ending) index. A line <math id="S4.SS2.SSS3.p1.7.m7.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.SSS3.p1.7.m7.1a"><mi id="S4.SS2.SSS3.p1.7.m7.1.1" xref="S4.SS2.SSS3.p1.7.m7.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.7.m7.1b"><ci id="S4.SS2.SSS3.p1.7.m7.1.1.cmml" xref="S4.SS2.SSS3.p1.7.m7.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.7.m7.1c">l</annotation></semantics></math> is considered active if <math id="S4.SS2.SSS3.p1.8.m8.2" class="ltx_Math" alttext="A_{l,j}/N_{l}&gt;\psi" display="inline"><semantics id="S4.SS2.SSS3.p1.8.m8.2a"><mrow id="S4.SS2.SSS3.p1.8.m8.2.3" xref="S4.SS2.SSS3.p1.8.m8.2.3.cmml"><mrow id="S4.SS2.SSS3.p1.8.m8.2.3.2" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.cmml"><msub id="S4.SS2.SSS3.p1.8.m8.2.3.2.2" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.2.cmml"><mi id="S4.SS2.SSS3.p1.8.m8.2.3.2.2.2" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.2.2.cmml">A</mi><mrow id="S4.SS2.SSS3.p1.8.m8.2.2.2.4" xref="S4.SS2.SSS3.p1.8.m8.2.2.2.3.cmml"><mi id="S4.SS2.SSS3.p1.8.m8.1.1.1.1" xref="S4.SS2.SSS3.p1.8.m8.1.1.1.1.cmml">l</mi><mo id="S4.SS2.SSS3.p1.8.m8.2.2.2.4.1" xref="S4.SS2.SSS3.p1.8.m8.2.2.2.3.cmml">,</mo><mi id="S4.SS2.SSS3.p1.8.m8.2.2.2.2" xref="S4.SS2.SSS3.p1.8.m8.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S4.SS2.SSS3.p1.8.m8.2.3.2.1" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.1.cmml">/</mo><msub id="S4.SS2.SSS3.p1.8.m8.2.3.2.3" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3.cmml"><mi id="S4.SS2.SSS3.p1.8.m8.2.3.2.3.2" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3.2.cmml">N</mi><mi id="S4.SS2.SSS3.p1.8.m8.2.3.2.3.3" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3.3.cmml">l</mi></msub></mrow><mo id="S4.SS2.SSS3.p1.8.m8.2.3.1" xref="S4.SS2.SSS3.p1.8.m8.2.3.1.cmml">&gt;</mo><mi id="S4.SS2.SSS3.p1.8.m8.2.3.3" xref="S4.SS2.SSS3.p1.8.m8.2.3.3.cmml">Ïˆ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.8.m8.2b"><apply id="S4.SS2.SSS3.p1.8.m8.2.3.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3"><gt id="S4.SS2.SSS3.p1.8.m8.2.3.1.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.1"></gt><apply id="S4.SS2.SSS3.p1.8.m8.2.3.2.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2"><divide id="S4.SS2.SSS3.p1.8.m8.2.3.2.1.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.1"></divide><apply id="S4.SS2.SSS3.p1.8.m8.2.3.2.2.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.8.m8.2.3.2.2.1.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.2">subscript</csymbol><ci id="S4.SS2.SSS3.p1.8.m8.2.3.2.2.2.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.2.2">ğ´</ci><list id="S4.SS2.SSS3.p1.8.m8.2.2.2.3.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.2.2.4"><ci id="S4.SS2.SSS3.p1.8.m8.1.1.1.1.cmml" xref="S4.SS2.SSS3.p1.8.m8.1.1.1.1">ğ‘™</ci><ci id="S4.SS2.SSS3.p1.8.m8.2.2.2.2.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.2.2.2">ğ‘—</ci></list></apply><apply id="S4.SS2.SSS3.p1.8.m8.2.3.2.3.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.8.m8.2.3.2.3.1.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3">subscript</csymbol><ci id="S4.SS2.SSS3.p1.8.m8.2.3.2.3.2.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3.2">ğ‘</ci><ci id="S4.SS2.SSS3.p1.8.m8.2.3.2.3.3.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.2.3.3">ğ‘™</ci></apply></apply><ci id="S4.SS2.SSS3.p1.8.m8.2.3.3.cmml" xref="S4.SS2.SSS3.p1.8.m8.2.3.3">ğœ“</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.8.m8.2c">A_{l,j}/N_{l}&gt;\psi</annotation></semantics></math>, and we preserve the paragraphs which have more than <math id="S4.SS2.SSS3.p1.9.m9.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S4.SS2.SSS3.p1.9.m9.1a"><mi id="S4.SS2.SSS3.p1.9.m9.1.1" xref="S4.SS2.SSS3.p1.9.m9.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.9.m9.1b"><ci id="S4.SS2.SSS3.p1.9.m9.1.1.cmml" xref="S4.SS2.SSS3.p1.9.m9.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.9.m9.1c">\phi</annotation></semantics></math> active lines, where <math id="S4.SS2.SSS3.p1.10.m10.1" class="ltx_Math" alttext="N_{l}" display="inline"><semantics id="S4.SS2.SSS3.p1.10.m10.1a"><msub id="S4.SS2.SSS3.p1.10.m10.1.1" xref="S4.SS2.SSS3.p1.10.m10.1.1.cmml"><mi id="S4.SS2.SSS3.p1.10.m10.1.1.2" xref="S4.SS2.SSS3.p1.10.m10.1.1.2.cmml">N</mi><mi id="S4.SS2.SSS3.p1.10.m10.1.1.3" xref="S4.SS2.SSS3.p1.10.m10.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.10.m10.1b"><apply id="S4.SS2.SSS3.p1.10.m10.1.1.cmml" xref="S4.SS2.SSS3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS3.p1.10.m10.1.1.1.cmml" xref="S4.SS2.SSS3.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS2.SSS3.p1.10.m10.1.1.2.cmml" xref="S4.SS2.SSS3.p1.10.m10.1.1.2">ğ‘</ci><ci id="S4.SS2.SSS3.p1.10.m10.1.1.3.cmml" xref="S4.SS2.SSS3.p1.10.m10.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.10.m10.1c">N_{l}</annotation></semantics></math> is the number of words in <math id="S4.SS2.SSS3.p1.11.m11.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S4.SS2.SSS3.p1.11.m11.1a"><mi id="S4.SS2.SSS3.p1.11.m11.1.1" xref="S4.SS2.SSS3.p1.11.m11.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.11.m11.1b"><ci id="S4.SS2.SSS3.p1.11.m11.1.1.cmml" xref="S4.SS2.SSS3.p1.11.m11.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.11.m11.1c">l</annotation></semantics></math>; <math id="S4.SS2.SSS3.p1.12.m12.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S4.SS2.SSS3.p1.12.m12.1a"><mi id="S4.SS2.SSS3.p1.12.m12.1.1" xref="S4.SS2.SSS3.p1.12.m12.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.12.m12.1b"><ci id="S4.SS2.SSS3.p1.12.m12.1.1.cmml" xref="S4.SS2.SSS3.p1.12.m12.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.12.m12.1c">\psi</annotation></semantics></math> and <math id="S4.SS2.SSS3.p1.13.m13.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S4.SS2.SSS3.p1.13.m13.1a"><mi id="S4.SS2.SSS3.p1.13.m13.1.1" xref="S4.SS2.SSS3.p1.13.m13.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS3.p1.13.m13.1b"><ci id="S4.SS2.SSS3.p1.13.m13.1.1.cmml" xref="S4.SS2.SSS3.p1.13.m13.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS3.p1.13.m13.1c">\phi</annotation></semantics></math> are the thresholds.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we test our approach on extracting attorney profiles from appellate briefs. This is one of the most time-consuming processes in our manual workflow, because the profile information is more detailed in this document type, and the amount can exceed 170K documents per year.
At the same time, it is also a challenging machine learning problem due to being complexly laid out, having potential to drive future innovation.
In the following, we explain our experiments further:</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Experimental Settings</h3>

<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1. </span>Datasets.</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">Our dataset consists of approximately 600K legal briefs (in PDF format) across 166 courts in the U.S., dating from 2014 to 2020.
The texts are OCRâ€™d by AWS Textract,<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://aws.amazon.com/textract/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aws.amazon.com/textract/</a></span></span></span> provided with word- and line- level bounding boxes. We have 3 sets of labels:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Inexact</span>: all the briefs are attached with the inexact labels, as shown in FigureÂ <a href="#S1.F1.sf4" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a>;</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><span id="S5.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Gold</span>: 709 documents are annotated as in FigureÂ <a href="#S1.F1.sf3" title="In Figure 1 â€£ 1. Introduction â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a> (i.e., exact label) by a team of 5 subject matter experts. The group index and token order are specified, allowing us to unambiguously derive NEs that meet DefinitionÂ <a href="#S3.E1" title="In 3. Problem Definition â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. These labels are split into training/validation/test sets at 40%/10%/50%, respectively;</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p"><span id="S5.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Pseudo</span>: 4k documents (i.e., 15 times larger than the training set of the exact labels) are separately sampled to be inferred by the proposed approach.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2. </span>Model Configurations</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.2" class="ltx_p">We trained the Pointer-Generator Networks with inexact labels. Notable configuration changes are input/output lengths, which are set to 3,000/400, respectively.
Our object detector, LayoutLMv3 combined with Casade R-CNN <cite class="ltx_cite ltx_citemacro_citep">(Cai and Vasconcelos, <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>, was fine-tuned in three different settings for comparative analysis. They are fine-tuned with Gold, Pseudo, and Pseudo+Gold labels from the checkpoint that was fine-tuned on PubLayNet. The paragraph- (line-) threshold <math id="S5.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S5.SS1.SSS2.p1.1.m1.1a"><mi id="S5.SS1.SSS2.p1.1.m1.1.1" xref="S5.SS1.SSS2.p1.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.1.m1.1b"><ci id="S5.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p1.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.1.m1.1c">\phi</annotation></semantics></math> (<math id="S5.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="S5.SS1.SSS2.p1.2.m2.1a"><mi id="S5.SS1.SSS2.p1.2.m2.1.1" xref="S5.SS1.SSS2.p1.2.m2.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p1.2.m2.1b"><ci id="S5.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p1.2.m2.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p1.2.m2.1c">\psi</annotation></semantics></math>) is 1 (0.1). See Appendix <a href="#A1" title="Appendix A Details of Model Configurations â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for the rest.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3. </span>Post-processing</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">To provide final NE values that meet DefinitionÂ <a href="#S3.E1" title="In 3. Problem Definition â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we applied rule-based processes of grouping and re-ordering.
Since the objects are already classified, we are allowed to build effective rules based on stronger assumptions.
For attorney profile, we impose column-major order<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://en.wikipedia.org/wiki/Row-_and_column-major_order" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/wiki/Row-_and_column-major_order</a></span></span></span> by implementing X-cut <cite class="ltx_cite ltx_citemacro_citep">(Ha etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">1995</a>)</cite>, and grouping is determined by their sizes and designation lines, e.g., â€œAttorneys for Petitionerâ€. See Appendix <a href="#A2" title="Appendix B Details of Post-processing â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a> for more details.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Results and Discussion</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We adopted <em id="S5.SS2.p1.1.1" class="ltx_emph ltx_font_italic">exact match</em> to evaluate our system outputs and present the results in TableÂ <a href="#S5.T1" title="Table 1 â€£ 5.2. Results and Discussion â€£ 5. Experiments â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Note that the three settings were evaluated on Gold-test labels and required no post-processing.
By comparison, it shows that the weakly supervised object detector trained on Pseudo labels outperformed the supervised model trained on Gold labels.
This indicates that our method can effectively produce high-quality signals, and Pseudo labels are comparably informative as Gold labels.
Furthermore, we conducted an ablation analysis by comparing the models trained on Pseudo and Pseudo+Gold labels.
Surprisingly, additional provision of Gold labels does not improve our solution pipeline.
This finding suggests that Pseudo labels can sufficiently cover the information embedded in Gold labels.
We additionally report average <em id="S5.SS2.p1.1.2" class="ltx_emph ltx_font_italic">Edit Distance</em> to reflect the expenses incurred when the systems are deployed to a human-in-the-loop workflow.
The results are similar in all three settings and require approximately five words to be corrected.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Figure <a href="#S5.F3" title="Figure 3 â€£ 5.2. Results and Discussion â€£ 5. Experiments â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents a case study of errors made by the Gold model. On the left, it tends to produce larger objects and incorrectly places one on the barcode, possibly due to a bias caused by limited data and over-sensitivity to common locations, such as the bottom-right area. In the middle, it misses the upper objects, and we attribute to a similar reason â€“ fewer cases have attorney profiles at the top. On the right, both the Gold and Pseudo models produce false positives for the <em id="S5.SS2.p2.1.1" class="ltx_emph ltx_font_italic">pro se</em> profile. This is a tricky problem, since it is excluded by business requirements. The inability of the object detector to read text prevents it from recognizing this pattern. Nonetheless, a simple text-based rule should be able to compensate for this.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>Results of Attorney Profile Extraction: P/R/F1 stand for Precision/Recall/F1-score, respectively.</figcaption>
<table id="S5.T1.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.4.1.1" class="ltx_tr">
<th id="S5.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S5.T1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Dataset</span></th>
<th id="S5.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T1.4.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">P</span></th>
<th id="S5.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T1.4.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">R</span></th>
<th id="S5.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T1.4.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">F1</span></th>
<th id="S5.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T1.4.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Edit Distance</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.4.2.1" class="ltx_tr">
<th id="S5.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">Gold</span></th>
<td id="S5.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.4.2.1.2.1" class="ltx_text" style="font-size:90%;">0.637</span></td>
<td id="S5.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.4.2.1.3.1" class="ltx_text" style="font-size:90%;">0.633</span></td>
<td id="S5.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.4.2.1.4.1" class="ltx_text" style="font-size:90%;">0.635</span></td>
<td id="S5.T1.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.4.2.1.5.1" class="ltx_text" style="font-size:90%;">5.181</span></td>
</tr>
<tr id="S5.T1.4.3.2" class="ltx_tr">
<th id="S5.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S5.T1.4.3.2.1.1" class="ltx_text" style="font-size:90%;">Pseudo</span></th>
<td id="S5.T1.4.3.2.2" class="ltx_td ltx_align_center"><span id="S5.T1.4.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.665</span></td>
<td id="S5.T1.4.3.2.3" class="ltx_td ltx_align_center"><span id="S5.T1.4.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.643</span></td>
<td id="S5.T1.4.3.2.4" class="ltx_td ltx_align_center"><span id="S5.T1.4.3.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.654</span></td>
<td id="S5.T1.4.3.2.5" class="ltx_td ltx_align_center"><span id="S5.T1.4.3.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">5.135</span></td>
</tr>
<tr id="S5.T1.4.4.3" class="ltx_tr">
<th id="S5.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S5.T1.4.4.3.1.1" class="ltx_text" style="font-size:90%;">Pseudo+Gold</span></th>
<td id="S5.T1.4.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.4.4.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.665</span></td>
<td id="S5.T1.4.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.4.4.3.3.1" class="ltx_text" style="font-size:90%;">0.635</span></td>
<td id="S5.T1.4.4.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.4.4.3.4.1" class="ltx_text" style="font-size:90%;">0.650</span></td>
<td id="S5.T1.4.4.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.4.4.3.5.1" class="ltx_text" style="font-size:90%;">5.711</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2305.05836/assets/x6.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S5.F3.3.2" class="ltx_text" style="font-size:90%;">Case Study. Comparison among ground-truth (green), Gold model (orange), and Pseudo model (blue).</span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we have demonstrated an effective weakly supervised approach to extracting complex NEs from legal documents.
Considering the substantial amount of data to process, our solution has the potential to significantly reduce costs and save time.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Company Portrait</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Thomson Reuters</span> is best known for Reuters News but also the leading information provider for legal, corporate, tax, and accounting professionals. They have 60,000 TBs of data and Thomson Reuters Labs has been innovative in AI for 30 years.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Presenter</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p"><span id="Sx2.p1.1.1" class="ltx_text ltx_font_bold">Hsiu-Wei Yang</span> is an Applied Research Scientist at Thomson Reuters Labs in Toronto, Canada. He has a Masterâ€™s degree in Computer Science from University of Waterloo. His research focuses on Information Retrieval and Natural Language Processing.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Appalaraju etÂ al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Srikar Appalaraju, Bhavan
Jasani, BhargavaÂ Urala Kota, Yusheng
Xie, and R. Manmatha. 2021.

</span>
<span class="ltx_bibblock">DocFormer: End-to-End Transformer for Document
Understanding. In <em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV)</em>.
993â€“1003.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Au etÂ al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ting WaiÂ Terence Au,
Vasileios Lampos, and Ingemar Cox.
2022.

</span>
<span class="ltx_bibblock">E-NER â€” An Annotated Named Entity
Recognition Corpus of Legal Text. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Proceedings
of the Natural Legal Language Processing Workshop 2022</em>.
Association for Computational Linguistics,
246â€“255.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai and Vasconcelos (2018)</span>
<span class="ltx_bibblock">
Zhaowei Cai and Nuno
Vasconcelos. 2018.

</span>
<span class="ltx_bibblock">Cascade r-cnn: Delving into high quality object
detection. In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference
on computer vision and pattern recognition</em>. 6154â€“6162.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai (2018)</span>
<span class="ltx_bibblock">
Xiang Dai.
2018.

</span>
<span class="ltx_bibblock">Recognizing complex entity mentions: A review and
future directions. In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of ACL 2018,
Student Research Workshop</em>. 37â€“44.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doermann etÂ al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
David Doermann, Karl
Tombre, etÂ al<span id="bib.bib6.3.1" class="ltx_text">.</span> 2014.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.4.1" class="ltx_emph ltx_font_italic">Handbook of document image processing and
recognition</em>. Vol.Â 1.

</span>
<span class="ltx_bibblock">Springer.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Filtz etÂ al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Erwin Filtz, MarÃ­a
Navas-Loro, Cristiana Santos, Axel
Polleres, and Sabrina Kirrane.
2020.

</span>
<span class="ltx_bibblock">Events matter: Extraction of events from court
decisions.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Legal Knowledge and Information Systems</em>
(2020), 33â€“42.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo etÂ al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Jiafeng Guo, Gu Xu,
Xueqi Cheng, and Hang Li.
2009.

</span>
<span class="ltx_bibblock">Named entity recognition in query. In
<em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd international ACM SIGIR
conference on Research and development in information retrieval</em>.
267â€“274.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ha etÂ al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (1995)</span>
<span class="ltx_bibblock">
Jaekyu Ha, RobertÂ M
Haralick, and IhsinÂ T Phillips.
1995.

</span>
<span class="ltx_bibblock">Recursive XY cut using bounding boxes of connected
components. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of 3rd International
Conference on Document Analysis and Recognition</em>, Vol.Â 2.
IEEE, 952â€“955.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yupan Huang, Tengchao Lv,
Lei Cui, Yutong Lu, and
Furu Wei. 2022.

</span>
<span class="ltx_bibblock">Layoutlmv3: Pre-training for document ai with
unified text and image masking. In <em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 30th ACM International Conference on Multimedia</em>.
4083â€“4091.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Zheng Huang, Kai Chen,
Jianhua He, Xiang Bai,
Dimosthenis Karatzas, Shijian Lu, and
CV Jawahar. 2019.

</span>
<span class="ltx_bibblock">Icdar2019 competition on scanned receipt ocr and
information extraction. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">2019 International
Conference on Document Analysis and Recognition (ICDAR)</em>. IEEE,
1516â€“1520.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaume etÂ al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Guillaume Jaume,
HazimÂ Kemal Ekenel, and Jean-Philippe
Thiran. 2019.

</span>
<span class="ltx_bibblock">Funsd: A dataset for form understanding in noisy
scanned documents. In <em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">2019 International
Conference on Document Analysis and Recognition Workshops (ICDARW)</em>,
Vol.Â 2. IEEE, 1â€“6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khalid etÂ al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
MahboobÂ Alam Khalid,
Valentin Jijkoun, and Maarten
DeÂ Rijke. 2008.

</span>
<span class="ltx_bibblock">The impact of named entity normalization on
information retrieval for question answering. In
<em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Advances in Information Retrieval: 30th European
Conference on IR Research, ECIR 2008, Glasgow, UK, March 30-April 3, 2008.
Proceedings 30</em>. Springer, 705â€“710.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Minghao Li, Yiheng Xu,
Lei Cui, Shaohan Huang,
Furu Wei, Zhoujun Li, and
Ming Zhou. 2020.

</span>
<span class="ltx_bibblock">DocBank: A Benchmark Dataset for Document
Layout Analysis. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th
International Conference on Computational Linguistics</em>.
949â€“960.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lopresti (2008)</span>
<span class="ltx_bibblock">
Daniel Lopresti.
2008.

</span>
<span class="ltx_bibblock">Optical character recognition errors and their
effects on natural language processing. In
<em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the second workshop on Analytics for
Noisy Unstructured Text Data</em>. 9â€“16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malmasi etÂ al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Shervin Malmasi, Anjie
Fang, Besnik Fetahu, Sudipta Kar, and
Oleg Rokhlenko. 2022.

</span>
<span class="ltx_bibblock">Semeval-2022 task 11: Multilingual complex named
entity recognition (multiconer). In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 16th international workshop on semantic evaluation (SemEval-2022)</em>.
1412â€“1437.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew etÂ al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Minesh Mathew, Dimosthenis
Karatzas, and CV Jawahar.
2021.

</span>
<span class="ltx_bibblock">Docvqa: A dataset for vqa on document images. In
<em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF winter conference on
applications of computer vision</em>. 2200â€“2209.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park etÂ al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Seunghyun Park, Seung
Shin, Bado Lee, Junyeop Lee,
Jaeheung Surh, Minjoon Seo, and
Hwalsuk Lee. 2019.

</span>
<span class="ltx_bibblock">CORD: A Consolidated Receipt Dataset for Post-OCR
Parsing.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfitzmann etÂ al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Birgit Pfitzmann,
Christoph Auer, Michele Dolfi,
AhmedÂ S Nassar, and Peter Staar.
2022.

</span>
<span class="ltx_bibblock">DocLayNet: A Large Human-Annotated Dataset for
Document-Layout Segmentation. In <em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>.
3743â€“3751.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Powalski etÂ al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
RafaÅ‚ Powalski,
Åukasz Borchmann, Dawid Jurkiewicz,
Tomasz Dwojak, MichaÅ‚ Pietruszka,
and Gabriela PaÅ‚ka. 2021.

</span>
<span class="ltx_bibblock">Going full-tilt boogie on document understanding
with text-image-layout transformer. In <em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Document
Analysis and Recognitionâ€“ICDAR 2021: 16th International Conference,
Lausanne, Switzerland, September 5â€“10, 2021, Proceedings, Part II 16</em>.
Springer, 732â€“747.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">See etÂ al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Abigail See, PeterÂ J.
Liu, and ChristopherÂ D. Manning.
2017.

</span>
<span class="ltx_bibblock">Get To The Point: Summarization with
Pointer-Generator Networks. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the
55th Annual Meeting of the Association for Computational Linguistics (Volume
1: Long Papers)</em>. 1073â€“1083.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao etÂ al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Feifei Shao, Long Chen,
Jian Shao, Wei Ji,
Shaoning Xiao, Lu Ye,
Yueting Zhuang, and Jun Xiao.
2022.

</span>
<span class="ltx_bibblock">Deep learning for weakly-supervised object
detection and localization: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">Neurocomputing</em> 496
(2022), 192â€“207.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Skylaki etÂ al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Stavroula Skylaki, Ali
Oskooei, Omar Bari, Nadja Herger, and
Zac Kriegman. 2021.

</span>
<span class="ltx_bibblock">Legal Entity Extraction using a Pointer Generator
Network. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">2021 International Conference on Data
Mining Workshops (ICDMW)</em>. IEEE, 653â€“658.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trias etÂ al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Fernando Trias, Hongming
Wang, Sylvain Jaume, and Stratos
Idreos. 2021.

</span>
<span class="ltx_bibblock">Named entity recognition in historic legal text: A
transformer and state machine ensemble method. In
<em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Natural Legal Language
Processing Workshop 2021</em>. 172â€“179.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Voorhees etÂ al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2005)</span>
<span class="ltx_bibblock">
EllenÂ M Voorhees, DonnaÂ K
Harman, etÂ al<span id="bib.bib25.3.1" class="ltx_text">.</span> 2005.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.4.1" class="ltx_emph ltx_font_italic">TREC: Experiment and evaluation in
information retrieval</em>. Vol.Â 63.

</span>
<span class="ltx_bibblock">Citeseer.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dingwen Zhang, Junwei
Han, Gong Cheng, and Ming-Hsuan Yang.
2021.

</span>
<span class="ltx_bibblock">Weakly supervised object localization and
detection: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and
machine intelligence</em> 44, 9
(2021), 5866â€“5885.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong etÂ al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Xu Zhong, Jianbin Tang,
and AntonioÂ Jimeno Yepes.
2019.

</span>
<span class="ltx_bibblock">Publaynet: largest dataset ever for document layout
analysis. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">2019 International Conference on
Document Analysis and Recognition (ICDAR)</em>. IEEE,
1015â€“1022.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Details of Model Configurations</h2>

<div id="A1.p1" class="ltx_para">
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p"><span id="A1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Non-sequential Token Mapping</span>: we trained the Pointer-Generator Networks, implemented by OpenNMT<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://opennmt.net/OpenNMT-py/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://opennmt.net/OpenNMT-py/</a></span></span></span>, with inexact labels. Input and output lengths are changed to 3000 and 400, respectively; batch size is 2; the rest hyper-parameters are set as default. All the documents except for the ones that have gold labels are used, out of which 10K are kept for validation. Totally, it is trained by 780k steps.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p"><span id="A1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Object Detector</span>: following <cite class="ltx_cite ltx_citemacro_citet">Huang etÂ al<span class="ltx_text">.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, LayoutLMv3 feature backbone and Cascade R-CNN <cite class="ltx_cite ltx_citemacro_citep">(Cai and Vasconcelos, <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> are integrated to perform object detection. We use the same configuration and start from the checkpoint fine-tuned on PubLayNet <cite class="ltx_cite ltx_citemacro_citep">(Zhong etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite>. To compare the performance, we further fine-tuned it on gold, pseudo, and pseudo+gold labels, individually.
Confidence threshold is set to 0.5. When there are overlapped objects, only the largest one is returned.</p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.5" class="ltx_p"><span id="A1.I1.i3.p1.5.1" class="ltx_text ltx_font_bold">Others</span>: kernel size <math id="A1.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="A1.I1.i3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A1.I1.i3.p1.1.m1.1.1" xref="A1.I1.i3.p1.1.m1.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="A1.I1.i3.p1.1.m1.1b"><ci id="A1.I1.i3.p1.1.m1.1.1.cmml" xref="A1.I1.i3.p1.1.m1.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i3.p1.1.m1.1c">\mathcal{K}</annotation></semantics></math> is (2,2), patience <math id="A1.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="A1.I1.i3.p1.2.m2.1a"><mi id="A1.I1.i3.p1.2.m2.1.1" xref="A1.I1.i3.p1.2.m2.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="A1.I1.i3.p1.2.m2.1b"><ci id="A1.I1.i3.p1.2.m2.1.1.cmml" xref="A1.I1.i3.p1.2.m2.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i3.p1.2.m2.1c">\rho</annotation></semantics></math> is 3, aggregation rate <math id="A1.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="A1.I1.i3.p1.3.m3.1a"><mi id="A1.I1.i3.p1.3.m3.1.1" xref="A1.I1.i3.p1.3.m3.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="A1.I1.i3.p1.3.m3.1b"><ci id="A1.I1.i3.p1.3.m3.1.1.cmml" xref="A1.I1.i3.p1.3.m3.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i3.p1.3.m3.1c">\delta</annotation></semantics></math> is 0.5, and paragraph- (line-) threshold <math id="A1.I1.i3.p1.4.m4.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="A1.I1.i3.p1.4.m4.1a"><mi id="A1.I1.i3.p1.4.m4.1.1" xref="A1.I1.i3.p1.4.m4.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="A1.I1.i3.p1.4.m4.1b"><ci id="A1.I1.i3.p1.4.m4.1.1.cmml" xref="A1.I1.i3.p1.4.m4.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i3.p1.4.m4.1c">\phi</annotation></semantics></math> (<math id="A1.I1.i3.p1.5.m5.1" class="ltx_Math" alttext="\psi" display="inline"><semantics id="A1.I1.i3.p1.5.m5.1a"><mi id="A1.I1.i3.p1.5.m5.1.1" xref="A1.I1.i3.p1.5.m5.1.1.cmml">Ïˆ</mi><annotation-xml encoding="MathML-Content" id="A1.I1.i3.p1.5.m5.1b"><ci id="A1.I1.i3.p1.5.m5.1.1.cmml" xref="A1.I1.i3.p1.5.m5.1.1">ğœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i3.p1.5.m5.1c">\psi</annotation></semantics></math>) is 1 (0.1).</p>
</div>
</li>
</ul>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Details of Post-processing</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">To obtain the NE results that meet Definition <a href="#S3.E1" title="In 3. Problem Definition â€£ Extracting Complex Named Entities in Legal Documents via Weakly Supervised Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the last process is to separate the collected tokens covered by the predicted objects into groups and determine the token order within each group.
We devised a rule-based and type-specific process to achieve this.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">For attorney profile, we first analyzed and added three attributes to each predicted object: (1) <em id="A2.p2.1.1" class="ltx_emph ltx_font_italic">isMajor</em>: if an object has more than five lines; (2) <em id="A2.p2.1.2" class="ltx_emph ltx_font_italic">isDesignation</em>: if the text of an object has the word <em id="A2.p2.1.3" class="ltx_emph ltx_font_italic">for</em>, e.g., â€œAttorneys <em id="A2.p2.1.4" class="ltx_emph ltx_font_italic">for</em> Petitionerâ€; (3) <em id="A2.p2.1.5" class="ltx_emph ltx_font_italic">columnIndex</em>: the index of the column to which an object belongs, decided by X-cut, i.e., similar to XY-cut <cite class="ltx_cite ltx_citemacro_citep">(Ha etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">1995</a>)</cite> but we only analyze x-axis.
With these attributes along with their coordinates, we sort them in column-major order, which aligns with how attorney profiles are usually read.
Furthermore, within each column, we merge minor objects (i.e., <em id="A2.p2.1.6" class="ltx_emph ltx_font_italic">isMajor=False</em>) into the nearest major ones, but however when a major object is or becomes a designation object (i.e., <em id="A2.p2.1.7" class="ltx_emph ltx_font_italic">isDesignation=True</em>) it stops accepting new minor members.
As a result, each object group represents a NE as our final output.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.05835" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.05836" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.05836">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.05836" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.05837" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 09:05:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
