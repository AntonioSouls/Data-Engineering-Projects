<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>GAMformer: In-Context Learning for Generalized Additive Models</title>
<!--Generated on Sun Oct  6 17:26:13 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.04560v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S1" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S2" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S2.SS1" title="In 2 Background and Related Work ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Generalized Additive Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S2.SS2" title="In 2 Background and Related Work ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>In-Context Learning &amp; Prior-Data Fitted Networks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>GAMformer</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS1" title="In 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Shape Estimation and Predictions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS2" title="In 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Model Architecture</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS2.SSS0.Px1" title="In 3.2 Model Architecture ‣ 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">Feature Preprocessing.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS2.SSS0.Px2" title="In 3.2 Model Architecture ‣ 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">Representation of the shape functions.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS2.SSS0.Px3" title="In 3.2 Model Architecture ‣ 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">Transformer.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS3" title="In 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Training Procedure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS4" title="In 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Higher-order effects</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.SS1" title="In 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Illustrative Examples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.SS2" title="In 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Multi-class Classification on OpenML Tabular Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.SS3" title="In 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Case Study: Intensive Care Unit Mortality Risk</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S5" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Limitations &amp; Broader Impact</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S6" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A1" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Generalized Additive Models: Extended Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Dataset Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS1" title="In Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>TabPFN Test Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2" title="In Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Binary Classification</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2.SSS0.Px1" title="In B.2 Binary Classification ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">Churn dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2.SSS0.Px2" title="In B.2 Binary Classification ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">Adult dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2.SSS0.Px3" title="In B.2 Binary Classification ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">MIMIC-II dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2.SSS0.Px4" title="In B.2 Binary Classification ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">MIMIC-III dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2.SSS0.Px5" title="In B.2 Binary Classification ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title">SUPPORT2 dataset.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Properties of GAMformer</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.SS1" title="In Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Data Scaling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.SS2" title="In Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Class Imbalance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.SS3" title="In Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Noise Robustness</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A4" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Synthetic Data Priors</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A5" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Training Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A6" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Higher-order effects</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A7" title="In GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Shape Functions</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A7.SS1" title="In Appendix G Shape Functions ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.1 </span>MIMIC-II dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A7.SS2" title="In Appendix G Shape Functions ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.2 </span>MIMIC-III dataset</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">GAMformer: In-Context Learning for 
<br class="ltx_break"/>Generalized Additive Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andreas Mueller<sup class="ltx_sup" id="id11.11.id1">1</sup>, Julien Siems<sup class="ltx_sup" id="id12.12.id2">2</sup><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>,
Harsha Nori<sup class="ltx_sup" id="id13.13.id3">1</sup>, David Salinas<sup class="ltx_sup" id="id14.14.id4">2</sup>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id7.7.3">Arber Zela<sup class="ltx_sup" id="id7.7.3.1"><span class="ltx_text ltx_font_medium" id="id7.7.3.1.1">2</span></sup>, Rich Caruana<sup class="ltx_sup" id="id7.7.3.2"><span class="ltx_text ltx_font_medium" id="id7.7.3.2.1">1</span></sup>, Frank Hutter<sup class="ltx_sup" id="id7.7.3.3"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id7.7.3.3.1">3,1</span></sup></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id5">1</sup> Microsoft Research, <sup class="ltx_sup" id="id16.16.id6">2</sup> University of Freiburg, <sup class="ltx_sup" id="id17.17.id7">3</sup> ELLIS Institute Tübingen
</span><span class="ltx_author_notes">Equal contribution. Corresponding author: <span class="ltx_text ltx_font_typewriter" id="id18.18.id1">amueller@microsoft.com</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id19.id1">Generalized Additive Models (GAMs) are widely recognized for their ability to create fully interpretable machine learning models for tabular data. Traditionally, training GAMs involves iterative learning algorithms, such as splines, boosted trees, or neural networks, which refine the additive components through repeated error reduction. In this paper, we introduce <span class="ltx_text ltx_font_italic" id="id19.id1.1">GAMformer</span>, the first method to leverage in-context learning to estimate shape functions of a GAM in a single forward pass, representing a significant departure from the conventional iterative approaches to GAM fitting. Building on previous research applying in-context learning to tabular data, we exclusively use complex, synthetic data to train GAMformer, yet find it extrapolates well to real-world data. Our experiments show that GAMformer performs on par with other leading GAMs across various classification benchmarks while generating highly interpretable shape functions.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The growing importance of interpretability in machine learning is evident, especially in areas where transparency, fairness, and accountability are critical <cite class="ltx_cite ltx_citemacro_citep">(Barocas and Selbst, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib1" title="">2016</a>; Rudin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib2" title="">2022</a>)</cite>. Interpretable models are essential for building trust between humans and AI systems by allowing users to understand the reasoning behind the model’s predictions and decisions <cite class="ltx_cite ltx_citemacro_citep">(Ribeiro et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib3" title="">2016</a>)</cite>. This is crucial in safety-critical fields like healthcare, where incorrect or biased decisions can have severe consequences <cite class="ltx_cite ltx_citemacro_citep">(Caruana et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib4" title="">2015</a>)</cite>. Additionally, interpretability is vital for regulatory compliance in sectors like finance and hiring, where explaining and justifying model outcomes is necessary <cite class="ltx_cite ltx_citemacro_citep">(Arun et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib5" title="">2016</a>; Dattner et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib6" title="">2019</a>)</cite>. Interpretable models also help detect and mitigate bias by revealing the factors influencing predictions, ensuring fair and unbiased decisions across different population groups <cite class="ltx_cite ltx_citemacro_citep">(Mehrabi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib7" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Generalized Additive Models (GAMs) have proven a popular choice for interpretable modeling due to their high accuracy and interpretability. In GAMs, the target variable is expressed as a sum of non-linearly transformed features. This approach strikes a balance between the interpretability of linear models and the flexibility of capturing non-linear relationships between features and the target variable <cite class="ltx_cite ltx_citemacro_citep">(Hastie and Tibshirani, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib8" title="">1987</a>)</cite>. A wide variety of GAMs exist, differing in the non-linear functions used to transform features and the methods employed to fit these functions to training data. Traditionally, GAMs have used splines in conjunction with the backfitting algorithm <cite class="ltx_cite ltx_citemacro_citep">(Hastie and Tibshirani, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib8" title="">1987</a>)</cite>, while Explainable Boosting Machines (EBMs) utilize decision trees and cyclic gradient boosting <cite class="ltx_cite ltx_citemacro_citep">(Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib9" title="">2012</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>; Caruana et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib4" title="">2015</a>)</cite>. More recently, Neural Additive Models (NAMs) have employed multilayer perceptrons (MLPs) optimized via gradient descent <cite class="ltx_cite ltx_citemacro_citep">(Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib11" title="">2021</a>)</cite>. All existing GAM variants share the need for an iterative optimization algorithm to fit the shape functions, which introduces additional hyperparameters for optimization and regularization that require tuning <cite class="ltx_cite ltx_citemacro_citep">(Siems et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib12" title="">2023</a>; Kovács, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib13" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Recently, in-context learning (ICL) has emerged as a powerful paradigm for eliminating explicit optimization in models. This breakthrough was first observed in large language models <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib14" title="">2020a</a>)</cite>, where a model trained in an unsupervised manner on vast amounts of unlabeled data can learn to execute a new task when presented with examples, without any further optimization or updates to its parameters. Since then, ICL has been applied to various domains, including multi-modal foundation models <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib15" title="">2023</a>)</cite> and time-series forecasting <cite class="ltx_cite ltx_citemacro_citep">(Dooley et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib16" title="">2024</a>)</cite>. Of particular relevance to our work is TabPFN <cite class="ltx_cite ltx_citemacro_citep">(Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>; Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib18" title="">2022</a>)</cite>, a transformer model pretrained on complex, synthetic tabular data. This pretraining enables TabPFN to generalize to real-world data when presented with a dataset in the form of in-context examples, demonstrating the potential of ICL.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We introduce GAMformer (see  <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S1.F1" title="In 1 Introduction ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">1</span></a>), the first GAM method to estimate shape functions using ICL in a single forward pass. GAMformer distinguishes itself from existing GAM methods by employing a non-parametric, binned representation of shape functions, thus eliminating the need to impose a specific model class. Similar to TabPFN, our model is trained exclusively on large-scale synthetic datasets, yet demonstrates robust performance on real-world data. During training, GAMformer estimates shape functions for each feature based on the training data’s features and labels. These estimated functions are then utilized to generate predictions for test data points by summing the shape function values across features. The model is trained end-to-end based on the GAM’s predictions, ensuring that it learns to accurately construct shape functions for reliable predictions.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S1.F1.g1" src="x1.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>GAMformer’s forward pass on a new dataset with three features (<math alttext="x_{1}" class="ltx_Math" display="inline" id="S1.F1.5.m1.1"><semantics id="S1.F1.5.m1.1b"><msub id="S1.F1.5.m1.1.1" xref="S1.F1.5.m1.1.1.cmml"><mi id="S1.F1.5.m1.1.1.2" xref="S1.F1.5.m1.1.1.2.cmml">x</mi><mn id="S1.F1.5.m1.1.1.3" xref="S1.F1.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.5.m1.1c"><apply id="S1.F1.5.m1.1.1.cmml" xref="S1.F1.5.m1.1.1"><csymbol cd="ambiguous" id="S1.F1.5.m1.1.1.1.cmml" xref="S1.F1.5.m1.1.1">subscript</csymbol><ci id="S1.F1.5.m1.1.1.2.cmml" xref="S1.F1.5.m1.1.1.2">𝑥</ci><cn id="S1.F1.5.m1.1.1.3.cmml" type="integer" xref="S1.F1.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.5.m1.1d">x_{1}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.5.m1.1e">italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="x_{2}" class="ltx_Math" display="inline" id="S1.F1.6.m2.1"><semantics id="S1.F1.6.m2.1b"><msub id="S1.F1.6.m2.1.1" xref="S1.F1.6.m2.1.1.cmml"><mi id="S1.F1.6.m2.1.1.2" xref="S1.F1.6.m2.1.1.2.cmml">x</mi><mn id="S1.F1.6.m2.1.1.3" xref="S1.F1.6.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.6.m2.1c"><apply id="S1.F1.6.m2.1.1.cmml" xref="S1.F1.6.m2.1.1"><csymbol cd="ambiguous" id="S1.F1.6.m2.1.1.1.cmml" xref="S1.F1.6.m2.1.1">subscript</csymbol><ci id="S1.F1.6.m2.1.1.2.cmml" xref="S1.F1.6.m2.1.1.2">𝑥</ci><cn id="S1.F1.6.m2.1.1.3.cmml" type="integer" xref="S1.F1.6.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.m2.1d">x_{2}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.6.m2.1e">italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="x_{3}" class="ltx_Math" display="inline" id="S1.F1.7.m3.1"><semantics id="S1.F1.7.m3.1b"><msub id="S1.F1.7.m3.1.1" xref="S1.F1.7.m3.1.1.cmml"><mi id="S1.F1.7.m3.1.1.2" xref="S1.F1.7.m3.1.1.2.cmml">x</mi><mn id="S1.F1.7.m3.1.1.3" xref="S1.F1.7.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.7.m3.1c"><apply id="S1.F1.7.m3.1.1.cmml" xref="S1.F1.7.m3.1.1"><csymbol cd="ambiguous" id="S1.F1.7.m3.1.1.1.cmml" xref="S1.F1.7.m3.1.1">subscript</csymbol><ci id="S1.F1.7.m3.1.1.2.cmml" xref="S1.F1.7.m3.1.1.2">𝑥</ci><cn id="S1.F1.7.m3.1.1.3.cmml" type="integer" xref="S1.F1.7.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.7.m3.1d">x_{3}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.7.m3.1e">italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math>) and label <math alttext="y" class="ltx_Math" display="inline" id="S1.F1.8.m4.1"><semantics id="S1.F1.8.m4.1b"><mi id="S1.F1.8.m4.1.1" xref="S1.F1.8.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S1.F1.8.m4.1c"><ci id="S1.F1.8.m4.1.1.cmml" xref="S1.F1.8.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.8.m4.1d">y</annotation><annotation encoding="application/x-llamapun" id="S1.F1.8.m4.1e">italic_y</annotation></semantics></math> and two data points: (1) For each data point, we bin all features, one-hot encode them, embed the resulting vectors and add the label of the data point. (2) We alternate between applying attention across the features and the data points, allowing us to handle varying numbers of each. (3) We decode per-feature shape functions using a shared MLP decoder. (4) We infer the prediction for test data points by looking up and adding each feature’s shape function value (red bins) forming the GAM prediction. (5) Finally, we compute the loss based on the prediction allowing the end-to-end training of the shape function estimation based on (in our case, <em class="ltx_emph ltx_font_italic" id="S1.F1.10.1">synthetic</em>) training datasets.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our main contributions can be summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We introduce GAMformer, the first method to utilize in-context learning with sequence-to-sequence models to form shape functions in a single forward pass, eliminating the need for iterative learning and hyperparameter tuning.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Our experimental results demonstrate GAMformer’s capacity to match the accuracy of leading GAMs on various classification benchmarks.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Our case study on MIMIC-II demonstrates how GAMformer can be applied to real-world data to generate interpretable models and insights of that data.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this section, we provide some background and related work on generalized additive models and in-context learning.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Generalized Additive Models.</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.8">Generalized Additive Models (GAMs) <cite class="ltx_cite ltx_citemacro_citep">(Hastie and Tibshirani, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib8" title="">1987</a>)</cite> emerged as a generalization of Generalized Linear Models <cite class="ltx_cite ltx_citemacro_citep">(Nelder and Wedderburn, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib19" title="">1972</a>)</cite> which include non-linear transformations of the input features. The structure of a GAM is given by:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="g(\mathbb{E}[y|x])=\beta+\sum\nolimits_{i=1}^{p}f_{i}(x_{i})," class="ltx_Math" display="block" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml">g</mi><mo id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml">𝔼</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.2.3.cmml">β</mi><mo id="S2.E1.m1.1.1.1.1.2.2" rspace="0.055em" xref="S2.E1.m1.1.1.1.1.2.2.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.2.1" xref="S2.E1.m1.1.1.1.1.2.1.cmml"><msubsup id="S2.E1.m1.1.1.1.1.2.1.2" xref="S2.E1.m1.1.1.1.1.2.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.2.1.2.2.2" xref="S2.E1.m1.1.1.1.1.2.1.2.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.1.1.2.1.2.2.3" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.2.1.2.2.3.2" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.2.cmml">i</mi><mo id="S2.E1.m1.1.1.1.1.2.1.2.2.3.1" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.1.cmml">=</mo><mn id="S2.E1.m1.1.1.1.1.2.1.2.2.3.3" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.1.1.1.1.2.1.2.3" xref="S2.E1.m1.1.1.1.1.2.1.2.3.cmml">p</mi></msubsup><mrow id="S2.E1.m1.1.1.1.1.2.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.2.1.1.3" xref="S2.E1.m1.1.1.1.1.2.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.2.1.1.3.2" xref="S2.E1.m1.1.1.1.1.2.1.1.3.2.cmml">f</mi><mi id="S2.E1.m1.1.1.1.1.2.1.1.3.3" xref="S2.E1.m1.1.1.1.1.2.1.1.3.3.cmml">i</mi></msub><mo id="S2.E1.m1.1.1.1.1.2.1.1.2" xref="S2.E1.m1.1.1.1.1.2.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.2.1.1.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.2.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.2.cmml">x</mi><mi id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E1.m1.1.1.1.1.2.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"></eq><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3">𝑔</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2"></times><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.3">𝔼</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑥</ci></apply></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"><plus id="S2.E1.m1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2"></plus><ci id="S2.E1.m1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3">𝛽</ci><apply id="S2.E1.m1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1"><apply id="S2.E1.m1.1.1.1.1.2.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.2.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.2.1.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2.2.2"></sum><apply id="S2.E1.m1.1.1.1.1.2.1.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3"><eq id="S2.E1.m1.1.1.1.1.2.1.2.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.1"></eq><ci id="S2.E1.m1.1.1.1.1.2.1.2.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.2">𝑖</ci><cn id="S2.E1.m1.1.1.1.1.2.1.2.2.3.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.2.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.1.1.1.1.2.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.2.3">𝑝</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1"><times id="S2.E1.m1.1.1.1.1.2.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.2.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.3.2">𝑓</ci><ci id="S2.E1.m1.1.1.1.1.2.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.3.3">𝑖</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.2">𝑥</ci><ci id="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.2.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">g(\mathbb{E}[y|x])=\beta+\sum\nolimits_{i=1}^{p}f_{i}(x_{i}),</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">italic_g ( blackboard_E [ italic_y | italic_x ] ) = italic_β + ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.7">where <math alttext="x=(x_{1},\dots x_{p})\in\mathcal{X}\subseteq\mathbb{R}^{p}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.2"><semantics id="S2.SS1.p1.1.m1.2a"><mrow id="S2.SS1.p1.1.m1.2.2" xref="S2.SS1.p1.1.m1.2.2.cmml"><mi id="S2.SS1.p1.1.m1.2.2.4" xref="S2.SS1.p1.1.m1.2.2.4.cmml">x</mi><mo id="S2.SS1.p1.1.m1.2.2.5" xref="S2.SS1.p1.1.m1.2.2.5.cmml">=</mo><mrow id="S2.SS1.p1.1.m1.2.2.2.2" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml"><mo id="S2.SS1.p1.1.m1.2.2.2.2.3" stretchy="false" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">(</mo><msub id="S2.SS1.p1.1.m1.1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.1.1.1.2.cmml">x</mi><mn id="S2.SS1.p1.1.m1.1.1.1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.1.m1.2.2.2.2.4" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><mrow id="S2.SS1.p1.1.m1.2.2.2.2.2" xref="S2.SS1.p1.1.m1.2.2.2.2.2.cmml"><mi id="S2.SS1.p1.1.m1.2.2.2.2.2.2" mathvariant="normal" xref="S2.SS1.p1.1.m1.2.2.2.2.2.2.cmml">…</mi><mo id="S2.SS1.p1.1.m1.2.2.2.2.2.1" xref="S2.SS1.p1.1.m1.2.2.2.2.2.1.cmml">⁢</mo><msub id="S2.SS1.p1.1.m1.2.2.2.2.2.3" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3.cmml"><mi id="S2.SS1.p1.1.m1.2.2.2.2.2.3.2" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3.2.cmml">x</mi><mi id="S2.SS1.p1.1.m1.2.2.2.2.2.3.3" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3.3.cmml">p</mi></msub></mrow><mo id="S2.SS1.p1.1.m1.2.2.2.2.5" stretchy="false" xref="S2.SS1.p1.1.m1.2.2.2.3.cmml">)</mo></mrow><mo id="S2.SS1.p1.1.m1.2.2.6" xref="S2.SS1.p1.1.m1.2.2.6.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.1.m1.2.2.7" xref="S2.SS1.p1.1.m1.2.2.7.cmml">𝒳</mi><mo id="S2.SS1.p1.1.m1.2.2.8" xref="S2.SS1.p1.1.m1.2.2.8.cmml">⊆</mo><msup id="S2.SS1.p1.1.m1.2.2.9" xref="S2.SS1.p1.1.m1.2.2.9.cmml"><mi id="S2.SS1.p1.1.m1.2.2.9.2" xref="S2.SS1.p1.1.m1.2.2.9.2.cmml">ℝ</mi><mi id="S2.SS1.p1.1.m1.2.2.9.3" xref="S2.SS1.p1.1.m1.2.2.9.3.cmml">p</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.2b"><apply id="S2.SS1.p1.1.m1.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2"><and id="S2.SS1.p1.1.m1.2.2a.cmml" xref="S2.SS1.p1.1.m1.2.2"></and><apply id="S2.SS1.p1.1.m1.2.2b.cmml" xref="S2.SS1.p1.1.m1.2.2"><eq id="S2.SS1.p1.1.m1.2.2.5.cmml" xref="S2.SS1.p1.1.m1.2.2.5"></eq><ci id="S2.SS1.p1.1.m1.2.2.4.cmml" xref="S2.SS1.p1.1.m1.2.2.4">𝑥</ci><interval closure="open" id="S2.SS1.p1.1.m1.2.2.2.3.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2"><apply id="S2.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.1.2">𝑥</ci><cn id="S2.SS1.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.1.m1.1.1.1.1.1.3">1</cn></apply><apply id="S2.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2"><times id="S2.SS1.p1.1.m1.2.2.2.2.2.1.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.1"></times><ci id="S2.SS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.2">…</ci><apply id="S2.SS1.p1.1.m1.2.2.2.2.2.3.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.2.2.2.2.2.3.1.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S2.SS1.p1.1.m1.2.2.2.2.2.3.2.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3.2">𝑥</ci><ci id="S2.SS1.p1.1.m1.2.2.2.2.2.3.3.cmml" xref="S2.SS1.p1.1.m1.2.2.2.2.2.3.3">𝑝</ci></apply></apply></interval></apply><apply id="S2.SS1.p1.1.m1.2.2c.cmml" xref="S2.SS1.p1.1.m1.2.2"><in id="S2.SS1.p1.1.m1.2.2.6.cmml" xref="S2.SS1.p1.1.m1.2.2.6"></in><share href="https://arxiv.org/html/2410.04560v1#S2.SS1.p1.1.m1.2.2.2.cmml" id="S2.SS1.p1.1.m1.2.2d.cmml" xref="S2.SS1.p1.1.m1.2.2"></share><ci id="S2.SS1.p1.1.m1.2.2.7.cmml" xref="S2.SS1.p1.1.m1.2.2.7">𝒳</ci></apply><apply id="S2.SS1.p1.1.m1.2.2e.cmml" xref="S2.SS1.p1.1.m1.2.2"><subset id="S2.SS1.p1.1.m1.2.2.8.cmml" xref="S2.SS1.p1.1.m1.2.2.8"></subset><share href="https://arxiv.org/html/2410.04560v1#S2.SS1.p1.1.m1.2.2.7.cmml" id="S2.SS1.p1.1.m1.2.2f.cmml" xref="S2.SS1.p1.1.m1.2.2"></share><apply id="S2.SS1.p1.1.m1.2.2.9.cmml" xref="S2.SS1.p1.1.m1.2.2.9"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.2.2.9.1.cmml" xref="S2.SS1.p1.1.m1.2.2.9">superscript</csymbol><ci id="S2.SS1.p1.1.m1.2.2.9.2.cmml" xref="S2.SS1.p1.1.m1.2.2.9.2">ℝ</ci><ci id="S2.SS1.p1.1.m1.2.2.9.3.cmml" xref="S2.SS1.p1.1.m1.2.2.9.3">𝑝</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.2c">x=(x_{1},\dots x_{p})\in\mathcal{X}\subseteq\mathbb{R}^{p}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.2d">italic_x = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … italic_x start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) ∈ caligraphic_X ⊆ blackboard_R start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT</annotation></semantics></math> is the input with <math alttext="p" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_p</annotation></semantics></math> features, <math alttext="y\in\mathcal{Y}\subseteq\mathbb{R}^{m}" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mrow id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">y</mi><mo id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.3.m3.1.1.4" xref="S2.SS1.p1.3.m3.1.1.4.cmml">𝒴</mi><mo id="S2.SS1.p1.3.m3.1.1.5" xref="S2.SS1.p1.3.m3.1.1.5.cmml">⊆</mo><msup id="S2.SS1.p1.3.m3.1.1.6" xref="S2.SS1.p1.3.m3.1.1.6.cmml"><mi id="S2.SS1.p1.3.m3.1.1.6.2" xref="S2.SS1.p1.3.m3.1.1.6.2.cmml">ℝ</mi><mi id="S2.SS1.p1.3.m3.1.1.6.3" xref="S2.SS1.p1.3.m3.1.1.6.3.cmml">m</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><and id="S2.SS1.p1.3.m3.1.1a.cmml" xref="S2.SS1.p1.3.m3.1.1"></and><apply id="S2.SS1.p1.3.m3.1.1b.cmml" xref="S2.SS1.p1.3.m3.1.1"><in id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3"></in><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">𝑦</ci><ci id="S2.SS1.p1.3.m3.1.1.4.cmml" xref="S2.SS1.p1.3.m3.1.1.4">𝒴</ci></apply><apply id="S2.SS1.p1.3.m3.1.1c.cmml" xref="S2.SS1.p1.3.m3.1.1"><subset id="S2.SS1.p1.3.m3.1.1.5.cmml" xref="S2.SS1.p1.3.m3.1.1.5"></subset><share href="https://arxiv.org/html/2410.04560v1#S2.SS1.p1.3.m3.1.1.4.cmml" id="S2.SS1.p1.3.m3.1.1d.cmml" xref="S2.SS1.p1.3.m3.1.1"></share><apply id="S2.SS1.p1.3.m3.1.1.6.cmml" xref="S2.SS1.p1.3.m3.1.1.6"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.6.1.cmml" xref="S2.SS1.p1.3.m3.1.1.6">superscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.6.2.cmml" xref="S2.SS1.p1.3.m3.1.1.6.2">ℝ</ci><ci id="S2.SS1.p1.3.m3.1.1.6.3.cmml" xref="S2.SS1.p1.3.m3.1.1.6.3">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">y\in\mathcal{Y}\subseteq\mathbb{R}^{m}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_y ∈ caligraphic_Y ⊆ blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT</annotation></semantics></math> is the response variable, and <math alttext="f_{i}:\mathbb{R}\to\mathbb{R}" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><msub id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2.2" xref="S2.SS1.p1.4.m4.1.1.2.2.cmml">f</mi><mi id="S2.SS1.p1.4.m4.1.1.2.3" xref="S2.SS1.p1.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S2.SS1.p1.4.m4.1.1.1" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p1.4.m4.1.1.1.cmml">:</mo><mrow id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml"><mi id="S2.SS1.p1.4.m4.1.1.3.2" xref="S2.SS1.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mo id="S2.SS1.p1.4.m4.1.1.3.1" stretchy="false" xref="S2.SS1.p1.4.m4.1.1.3.1.cmml">→</mo><mi id="S2.SS1.p1.4.m4.1.1.3.3" xref="S2.SS1.p1.4.m4.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><ci id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1">:</ci><apply id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.2.1.cmml" xref="S2.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2">𝑓</ci><ci id="S2.SS1.p1.4.m4.1.1.2.3.cmml" xref="S2.SS1.p1.4.m4.1.1.2.3">𝑖</ci></apply><apply id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3"><ci id="S2.SS1.p1.4.m4.1.1.3.1.cmml" xref="S2.SS1.p1.4.m4.1.1.3.1">→</ci><ci id="S2.SS1.p1.4.m4.1.1.3.2.cmml" xref="S2.SS1.p1.4.m4.1.1.3.2">ℝ</ci><ci id="S2.SS1.p1.4.m4.1.1.3.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">f_{i}:\mathbb{R}\to\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R → blackboard_R</annotation></semantics></math> are univariate functions termed <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.7.1">shape functions</span> that capture the individual contributions of each feature. The intercept <math alttext="\beta\in\mathbb{R}" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mrow id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml">β</mi><mo id="S2.SS1.p1.5.m5.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.cmml">∈</mo><mi id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><in id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1"></in><ci id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2">𝛽</ci><ci id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\beta\in\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">italic_β ∈ blackboard_R</annotation></semantics></math> is a learnable bias term, and <math alttext="g:\mathbb{R}\to\mathbb{R}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.1"><semantics id="S2.SS1.p1.6.m6.1a"><mrow id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml"><mi id="S2.SS1.p1.6.m6.1.1.2" xref="S2.SS1.p1.6.m6.1.1.2.cmml">g</mi><mo id="S2.SS1.p1.6.m6.1.1.1" lspace="0.278em" rspace="0.278em" xref="S2.SS1.p1.6.m6.1.1.1.cmml">:</mo><mrow id="S2.SS1.p1.6.m6.1.1.3" xref="S2.SS1.p1.6.m6.1.1.3.cmml"><mi id="S2.SS1.p1.6.m6.1.1.3.2" xref="S2.SS1.p1.6.m6.1.1.3.2.cmml">ℝ</mi><mo id="S2.SS1.p1.6.m6.1.1.3.1" stretchy="false" xref="S2.SS1.p1.6.m6.1.1.3.1.cmml">→</mo><mi id="S2.SS1.p1.6.m6.1.1.3.3" xref="S2.SS1.p1.6.m6.1.1.3.3.cmml">ℝ</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><apply id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1"><ci id="S2.SS1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1.1">:</ci><ci id="S2.SS1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.p1.6.m6.1.1.2">𝑔</ci><apply id="S2.SS1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.p1.6.m6.1.1.3"><ci id="S2.SS1.p1.6.m6.1.1.3.1.cmml" xref="S2.SS1.p1.6.m6.1.1.3.1">→</ci><ci id="S2.SS1.p1.6.m6.1.1.3.2.cmml" xref="S2.SS1.p1.6.m6.1.1.3.2">ℝ</ci><ci id="S2.SS1.p1.6.m6.1.1.3.3.cmml" xref="S2.SS1.p1.6.m6.1.1.3.3">ℝ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">g:\mathbb{R}\to\mathbb{R}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.1d">italic_g : blackboard_R → blackboard_R</annotation></semantics></math> is the link function that connects the expected outcome to the linear predictor, examples of which include the logit or softmax function for binary or multiclass classification or the identity function for linear regression. The shape functions <math alttext="f_{i}" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m7.1"><semantics id="S2.SS1.p1.7.m7.1a"><msub id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml"><mi id="S2.SS1.p1.7.m7.1.1.2" xref="S2.SS1.p1.7.m7.1.1.2.cmml">f</mi><mi id="S2.SS1.p1.7.m7.1.1.3" xref="S2.SS1.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><apply id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.1.1.2.cmml" xref="S2.SS1.p1.7.m7.1.1.2">𝑓</ci><ci id="S2.SS1.p1.7.m7.1.1.3.cmml" xref="S2.SS1.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m7.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in GAMs, also sometimes called partial dependence plots, allow for an interpretable representation of each feature’s effect, akin to the role of coefficients in linear regression, thus enabling practitioners to inspect the learned potentially non-linear relationships.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Traditional GAMs often use splines and backfitting <cite class="ltx_cite ltx_citemacro_citep">(Hastie and Tibshirani, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib8" title="">1987</a>)</cite>, enhanced by penalized regression splines <cite class="ltx_cite ltx_citemacro_citep">(Wood, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib20" title="">2003</a>)</cite> and fast fitting algorithms <cite class="ltx_cite ltx_citemacro_citep">(Wood, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib21" title="">2001</a>)</cite>. Spline-based GAMs use the backfitting algorithm, iteratively updating each shape function to fit the residuals of others until convergence. More recent advances include Explainable Boosting Machines (EBMs) <cite class="ltx_cite ltx_citemacro_citep">(Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib9" title="">2012</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>; Caruana et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib4" title="">2015</a>)</cite>, which use decision trees to model shape functions via cyclic gradient boosting. This approach learns each feature’s contribution iteratively in a round-robin manner, mitigating collinearity effects and accurately modeling steps in the data, which is crucial for capturing discontinuities like treatment effects in medical data.
On the other hand, Neural Additive Models (NAMs) <cite class="ltx_cite ltx_citemacro_citep">(Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib11" title="">2021</a>)</cite> and follow up works <cite class="ltx_cite ltx_citemacro_citep">(Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib22" title="">2021</a>; Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib23" title="">2022</a>; Radenovic et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib24" title="">2022</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib25" title="">2022</a>; Enouen and Liu, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib26" title="">2022</a>; Bouchiat et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib27" title="">2024</a>)</cite> use multilayer perceptrons (MLPs) as non-linear transformations to model the shape functions <math alttext="f_{i}" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><msub id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">f</mi><mi id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">𝑓</ci><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. As a result, NAMs can be optimized using variants of gradient descent by leveraging automatic differentiation frameworks.
Finally, GAMs have also found applications in time-series forecasting, with models such as Prophet <cite class="ltx_cite ltx_citemacro_citep">(Taylor and Letham, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib28" title="">2018</a>)</cite> and NeuralProphet <cite class="ltx_cite ltx_citemacro_citep">(Triebe et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib29" title="">2021</a>)</cite>. For a more comprehensive related work refer to Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A1" title="Appendix A Generalized Additive Models: Extended Related Work ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>In-Context Learning &amp; Prior-Data Fitted Networks</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In-Context Learning (ICL) was first demonstrated alongside the introduction of GPT-3 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib30" title="">2020b</a>)</cite>, where the authors showed that Transformer models <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib31" title="">2017</a>)</cite> could learn to perform tasks solely from input examples, without explicit training or fine-tuning, after self-supervised pre-training. This capability marks a significant paradigm shift from the traditional machine learning paradigm of in-weights learning, where the parameters of a model are adjusted in order to learn a new task. The discovery of ICL has led to numerous investigations into the mechanisms used by trained transformers that enable ICL. <cite class="ltx_cite ltx_citemacro_cite">Olsson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib32" title="">2022</a>)</cite> found that a two-layer attention-only network can develop “induction heads”, a mechanism that outputs the token succeeding a previous instance of the current token, precisely when its ICL performance increases. <cite class="ltx_cite ltx_citemacro_cite">Chan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib33" title="">2022</a>)</cite> investigated the properties of the data that contribute to the emergence of ICL abilities, while <cite class="ltx_cite ltx_citemacro_cite">Reddy (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib34" title="">2024</a>)</cite> identified factors responsible for the abrupt emergence of induction heads.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.14">Of particular relevance to this paper are Prior-Data-Fitted Networks (PFNs) <cite class="ltx_cite ltx_citemacro_citep">(Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib18" title="">2022</a>; Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite>, which showed that a transformer trained on complex synthetic data generated using random causal graphs can be used for tabular classification. From a Bayesian perspective, such causal graphs <math alttext="\phi" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">italic_ϕ</annotation></semantics></math> sampled from a hypothesis space <math alttext="\Phi" class="ltx_Math" display="inline" id="S2.SS2.p2.2.m2.1"><semantics id="S2.SS2.p2.2.m2.1a"><mi id="S2.SS2.p2.2.m2.1.1" mathvariant="normal" xref="S2.SS2.p2.2.m2.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">\Phi</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.2.m2.1d">roman_Φ</annotation></semantics></math> (the prior), define a mechanism that describes the relationship between the input and output variables. In TabPFNs <cite class="ltx_cite ltx_citemacro_citep">(Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite>, a synthetic dataset <math alttext="D\sim p(D)=\mathbb{E}_{\phi\sim p(\phi)}[p(D|\phi)]" class="ltx_Math" display="inline" id="S2.SS2.p2.3.m3.3"><semantics id="S2.SS2.p2.3.m3.3a"><mrow id="S2.SS2.p2.3.m3.3.3" xref="S2.SS2.p2.3.m3.3.3.cmml"><mi id="S2.SS2.p2.3.m3.3.3.3" xref="S2.SS2.p2.3.m3.3.3.3.cmml">D</mi><mo id="S2.SS2.p2.3.m3.3.3.4" xref="S2.SS2.p2.3.m3.3.3.4.cmml">∼</mo><mrow id="S2.SS2.p2.3.m3.3.3.5" xref="S2.SS2.p2.3.m3.3.3.5.cmml"><mi id="S2.SS2.p2.3.m3.3.3.5.2" xref="S2.SS2.p2.3.m3.3.3.5.2.cmml">p</mi><mo id="S2.SS2.p2.3.m3.3.3.5.1" xref="S2.SS2.p2.3.m3.3.3.5.1.cmml">⁢</mo><mrow id="S2.SS2.p2.3.m3.3.3.5.3.2" xref="S2.SS2.p2.3.m3.3.3.5.cmml"><mo id="S2.SS2.p2.3.m3.3.3.5.3.2.1" stretchy="false" xref="S2.SS2.p2.3.m3.3.3.5.cmml">(</mo><mi id="S2.SS2.p2.3.m3.2.2" xref="S2.SS2.p2.3.m3.2.2.cmml">D</mi><mo id="S2.SS2.p2.3.m3.3.3.5.3.2.2" stretchy="false" xref="S2.SS2.p2.3.m3.3.3.5.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p2.3.m3.3.3.6" xref="S2.SS2.p2.3.m3.3.3.6.cmml">=</mo><mrow id="S2.SS2.p2.3.m3.3.3.1" xref="S2.SS2.p2.3.m3.3.3.1.cmml"><msub id="S2.SS2.p2.3.m3.3.3.1.3" xref="S2.SS2.p2.3.m3.3.3.1.3.cmml"><mi id="S2.SS2.p2.3.m3.3.3.1.3.2" xref="S2.SS2.p2.3.m3.3.3.1.3.2.cmml">𝔼</mi><mrow id="S2.SS2.p2.3.m3.1.1.1" xref="S2.SS2.p2.3.m3.1.1.1.cmml"><mi id="S2.SS2.p2.3.m3.1.1.1.3" xref="S2.SS2.p2.3.m3.1.1.1.3.cmml">ϕ</mi><mo id="S2.SS2.p2.3.m3.1.1.1.2" xref="S2.SS2.p2.3.m3.1.1.1.2.cmml">∼</mo><mrow id="S2.SS2.p2.3.m3.1.1.1.4" xref="S2.SS2.p2.3.m3.1.1.1.4.cmml"><mi id="S2.SS2.p2.3.m3.1.1.1.4.2" xref="S2.SS2.p2.3.m3.1.1.1.4.2.cmml">p</mi><mo id="S2.SS2.p2.3.m3.1.1.1.4.1" xref="S2.SS2.p2.3.m3.1.1.1.4.1.cmml">⁢</mo><mrow id="S2.SS2.p2.3.m3.1.1.1.4.3.2" xref="S2.SS2.p2.3.m3.1.1.1.4.cmml"><mo id="S2.SS2.p2.3.m3.1.1.1.4.3.2.1" stretchy="false" xref="S2.SS2.p2.3.m3.1.1.1.4.cmml">(</mo><mi id="S2.SS2.p2.3.m3.1.1.1.1" xref="S2.SS2.p2.3.m3.1.1.1.1.cmml">ϕ</mi><mo id="S2.SS2.p2.3.m3.1.1.1.4.3.2.2" stretchy="false" xref="S2.SS2.p2.3.m3.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></msub><mo id="S2.SS2.p2.3.m3.3.3.1.2" xref="S2.SS2.p2.3.m3.3.3.1.2.cmml">⁢</mo><mrow id="S2.SS2.p2.3.m3.3.3.1.1.1" xref="S2.SS2.p2.3.m3.3.3.1.1.2.cmml"><mo id="S2.SS2.p2.3.m3.3.3.1.1.1.2" stretchy="false" xref="S2.SS2.p2.3.m3.3.3.1.1.2.1.cmml">[</mo><mrow id="S2.SS2.p2.3.m3.3.3.1.1.1.1" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.cmml"><mi id="S2.SS2.p2.3.m3.3.3.1.1.1.1.3" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.3.cmml">p</mi><mo id="S2.SS2.p2.3.m3.3.3.1.1.1.1.2" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.cmml"><mo id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.2" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.2.cmml">D</mi><mo fence="false" id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.1" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.3" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.3.cmml">ϕ</mi></mrow><mo id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.p2.3.m3.3.3.1.1.1.3" stretchy="false" xref="S2.SS2.p2.3.m3.3.3.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.3b"><apply id="S2.SS2.p2.3.m3.3.3.cmml" xref="S2.SS2.p2.3.m3.3.3"><and id="S2.SS2.p2.3.m3.3.3a.cmml" xref="S2.SS2.p2.3.m3.3.3"></and><apply id="S2.SS2.p2.3.m3.3.3b.cmml" xref="S2.SS2.p2.3.m3.3.3"><csymbol cd="latexml" id="S2.SS2.p2.3.m3.3.3.4.cmml" xref="S2.SS2.p2.3.m3.3.3.4">similar-to</csymbol><ci id="S2.SS2.p2.3.m3.3.3.3.cmml" xref="S2.SS2.p2.3.m3.3.3.3">𝐷</ci><apply id="S2.SS2.p2.3.m3.3.3.5.cmml" xref="S2.SS2.p2.3.m3.3.3.5"><times id="S2.SS2.p2.3.m3.3.3.5.1.cmml" xref="S2.SS2.p2.3.m3.3.3.5.1"></times><ci id="S2.SS2.p2.3.m3.3.3.5.2.cmml" xref="S2.SS2.p2.3.m3.3.3.5.2">𝑝</ci><ci id="S2.SS2.p2.3.m3.2.2.cmml" xref="S2.SS2.p2.3.m3.2.2">𝐷</ci></apply></apply><apply id="S2.SS2.p2.3.m3.3.3c.cmml" xref="S2.SS2.p2.3.m3.3.3"><eq id="S2.SS2.p2.3.m3.3.3.6.cmml" xref="S2.SS2.p2.3.m3.3.3.6"></eq><share href="https://arxiv.org/html/2410.04560v1#S2.SS2.p2.3.m3.3.3.5.cmml" id="S2.SS2.p2.3.m3.3.3d.cmml" xref="S2.SS2.p2.3.m3.3.3"></share><apply id="S2.SS2.p2.3.m3.3.3.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1"><times id="S2.SS2.p2.3.m3.3.3.1.2.cmml" xref="S2.SS2.p2.3.m3.3.3.1.2"></times><apply id="S2.SS2.p2.3.m3.3.3.1.3.cmml" xref="S2.SS2.p2.3.m3.3.3.1.3"><csymbol cd="ambiguous" id="S2.SS2.p2.3.m3.3.3.1.3.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.3">subscript</csymbol><ci id="S2.SS2.p2.3.m3.3.3.1.3.2.cmml" xref="S2.SS2.p2.3.m3.3.3.1.3.2">𝔼</ci><apply id="S2.SS2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.3.m3.1.1.1.2.cmml" xref="S2.SS2.p2.3.m3.1.1.1.2">similar-to</csymbol><ci id="S2.SS2.p2.3.m3.1.1.1.3.cmml" xref="S2.SS2.p2.3.m3.1.1.1.3">italic-ϕ</ci><apply id="S2.SS2.p2.3.m3.1.1.1.4.cmml" xref="S2.SS2.p2.3.m3.1.1.1.4"><times id="S2.SS2.p2.3.m3.1.1.1.4.1.cmml" xref="S2.SS2.p2.3.m3.1.1.1.4.1"></times><ci id="S2.SS2.p2.3.m3.1.1.1.4.2.cmml" xref="S2.SS2.p2.3.m3.1.1.1.4.2">𝑝</ci><ci id="S2.SS2.p2.3.m3.1.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1.1.1">italic-ϕ</ci></apply></apply></apply><apply id="S2.SS2.p2.3.m3.3.3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.3.m3.3.3.1.1.2.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S2.SS2.p2.3.m3.3.3.1.1.1.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1"><times id="S2.SS2.p2.3.m3.3.3.1.1.1.1.2.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.2"></times><ci id="S2.SS2.p2.3.m3.3.3.1.1.1.1.3.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.3">𝑝</ci><apply id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.2">𝐷</ci><ci id="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p2.3.m3.3.3.1.1.1.1.1.1.1.3">italic-ϕ</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.3c">D\sim p(D)=\mathbb{E}_{\phi\sim p(\phi)}[p(D|\phi)]</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.3.m3.3d">italic_D ∼ italic_p ( italic_D ) = blackboard_E start_POSTSUBSCRIPT italic_ϕ ∼ italic_p ( italic_ϕ ) end_POSTSUBSCRIPT [ italic_p ( italic_D | italic_ϕ ) ]</annotation></semantics></math> is repeatedly constructed by propagating samples <math alttext="x\sim p(\mathcal{X})" class="ltx_Math" display="inline" id="S2.SS2.p2.4.m4.1"><semantics id="S2.SS2.p2.4.m4.1a"><mrow id="S2.SS2.p2.4.m4.1.2" xref="S2.SS2.p2.4.m4.1.2.cmml"><mi id="S2.SS2.p2.4.m4.1.2.2" xref="S2.SS2.p2.4.m4.1.2.2.cmml">x</mi><mo id="S2.SS2.p2.4.m4.1.2.1" xref="S2.SS2.p2.4.m4.1.2.1.cmml">∼</mo><mrow id="S2.SS2.p2.4.m4.1.2.3" xref="S2.SS2.p2.4.m4.1.2.3.cmml"><mi id="S2.SS2.p2.4.m4.1.2.3.2" xref="S2.SS2.p2.4.m4.1.2.3.2.cmml">p</mi><mo id="S2.SS2.p2.4.m4.1.2.3.1" xref="S2.SS2.p2.4.m4.1.2.3.1.cmml">⁢</mo><mrow id="S2.SS2.p2.4.m4.1.2.3.3.2" xref="S2.SS2.p2.4.m4.1.2.3.cmml"><mo id="S2.SS2.p2.4.m4.1.2.3.3.2.1" stretchy="false" xref="S2.SS2.p2.4.m4.1.2.3.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml">𝒳</mi><mo id="S2.SS2.p2.4.m4.1.2.3.3.2.2" stretchy="false" xref="S2.SS2.p2.4.m4.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><apply id="S2.SS2.p2.4.m4.1.2.cmml" xref="S2.SS2.p2.4.m4.1.2"><csymbol cd="latexml" id="S2.SS2.p2.4.m4.1.2.1.cmml" xref="S2.SS2.p2.4.m4.1.2.1">similar-to</csymbol><ci id="S2.SS2.p2.4.m4.1.2.2.cmml" xref="S2.SS2.p2.4.m4.1.2.2">𝑥</ci><apply id="S2.SS2.p2.4.m4.1.2.3.cmml" xref="S2.SS2.p2.4.m4.1.2.3"><times id="S2.SS2.p2.4.m4.1.2.3.1.cmml" xref="S2.SS2.p2.4.m4.1.2.3.1"></times><ci id="S2.SS2.p2.4.m4.1.2.3.2.cmml" xref="S2.SS2.p2.4.m4.1.2.3.2">𝑝</ci><ci id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1">𝒳</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">x\sim p(\mathcal{X})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.4.m4.1d">italic_x ∼ italic_p ( caligraphic_X )</annotation></semantics></math> from the input space through a randomly sampled structural causal model (SCM), <math alttext="\phi\sim p(\phi)" class="ltx_Math" display="inline" id="S2.SS2.p2.5.m5.1"><semantics id="S2.SS2.p2.5.m5.1a"><mrow id="S2.SS2.p2.5.m5.1.2" xref="S2.SS2.p2.5.m5.1.2.cmml"><mi id="S2.SS2.p2.5.m5.1.2.2" xref="S2.SS2.p2.5.m5.1.2.2.cmml">ϕ</mi><mo id="S2.SS2.p2.5.m5.1.2.1" xref="S2.SS2.p2.5.m5.1.2.1.cmml">∼</mo><mrow id="S2.SS2.p2.5.m5.1.2.3" xref="S2.SS2.p2.5.m5.1.2.3.cmml"><mi id="S2.SS2.p2.5.m5.1.2.3.2" xref="S2.SS2.p2.5.m5.1.2.3.2.cmml">p</mi><mo id="S2.SS2.p2.5.m5.1.2.3.1" xref="S2.SS2.p2.5.m5.1.2.3.1.cmml">⁢</mo><mrow id="S2.SS2.p2.5.m5.1.2.3.3.2" xref="S2.SS2.p2.5.m5.1.2.3.cmml"><mo id="S2.SS2.p2.5.m5.1.2.3.3.2.1" stretchy="false" xref="S2.SS2.p2.5.m5.1.2.3.cmml">(</mo><mi id="S2.SS2.p2.5.m5.1.1" xref="S2.SS2.p2.5.m5.1.1.cmml">ϕ</mi><mo id="S2.SS2.p2.5.m5.1.2.3.3.2.2" stretchy="false" xref="S2.SS2.p2.5.m5.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m5.1b"><apply id="S2.SS2.p2.5.m5.1.2.cmml" xref="S2.SS2.p2.5.m5.1.2"><csymbol cd="latexml" id="S2.SS2.p2.5.m5.1.2.1.cmml" xref="S2.SS2.p2.5.m5.1.2.1">similar-to</csymbol><ci id="S2.SS2.p2.5.m5.1.2.2.cmml" xref="S2.SS2.p2.5.m5.1.2.2">italic-ϕ</ci><apply id="S2.SS2.p2.5.m5.1.2.3.cmml" xref="S2.SS2.p2.5.m5.1.2.3"><times id="S2.SS2.p2.5.m5.1.2.3.1.cmml" xref="S2.SS2.p2.5.m5.1.2.3.1"></times><ci id="S2.SS2.p2.5.m5.1.2.3.2.cmml" xref="S2.SS2.p2.5.m5.1.2.3.2">𝑝</ci><ci id="S2.SS2.p2.5.m5.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1">italic-ϕ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m5.1c">\phi\sim p(\phi)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.5.m5.1d">italic_ϕ ∼ italic_p ( italic_ϕ )</annotation></semantics></math>, to obtain the corresponding <math alttext="y" class="ltx_Math" display="inline" id="S2.SS2.p2.6.m6.1"><semantics id="S2.SS2.p2.6.m6.1a"><mi id="S2.SS2.p2.6.m6.1.1" xref="S2.SS2.p2.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.6.m6.1b"><ci id="S2.SS2.p2.6.m6.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.6.m6.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.6.m6.1d">italic_y</annotation></semantics></math> values. We denote the dataset containing <math alttext="N" class="ltx_Math" display="inline" id="S2.SS2.p2.7.m7.1"><semantics id="S2.SS2.p2.7.m7.1a"><mi id="S2.SS2.p2.7.m7.1.1" xref="S2.SS2.p2.7.m7.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.7.m7.1b"><ci id="S2.SS2.p2.7.m7.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.7.m7.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.7.m7.1d">italic_N</annotation></semantics></math> such examples as the set <math alttext="D:=\{(x^{(n)},y^{(n)})\}_{n=1}^{N}" class="ltx_Math" display="inline" id="S2.SS2.p2.8.m8.3"><semantics id="S2.SS2.p2.8.m8.3a"><mrow id="S2.SS2.p2.8.m8.3.3" xref="S2.SS2.p2.8.m8.3.3.cmml"><mi id="S2.SS2.p2.8.m8.3.3.3" xref="S2.SS2.p2.8.m8.3.3.3.cmml">D</mi><mo id="S2.SS2.p2.8.m8.3.3.2" lspace="0.278em" rspace="0.278em" xref="S2.SS2.p2.8.m8.3.3.2.cmml">:=</mo><msubsup id="S2.SS2.p2.8.m8.3.3.1" xref="S2.SS2.p2.8.m8.3.3.1.cmml"><mrow id="S2.SS2.p2.8.m8.3.3.1.1.1.1" xref="S2.SS2.p2.8.m8.3.3.1.1.1.2.cmml"><mo id="S2.SS2.p2.8.m8.3.3.1.1.1.1.2" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.2.cmml">{</mo><mrow id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.3.cmml"><mo id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.3" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.3.cmml">(</mo><msup id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.2" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.2.cmml">x</mi><mrow id="S2.SS2.p2.8.m8.1.1.1.3" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.cmml"><mo id="S2.SS2.p2.8.m8.1.1.1.3.1" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.cmml">(</mo><mi id="S2.SS2.p2.8.m8.1.1.1.1" xref="S2.SS2.p2.8.m8.1.1.1.1.cmml">n</mi><mo id="S2.SS2.p2.8.m8.1.1.1.3.2" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.4" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.3.cmml">,</mo><msup id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.cmml"><mi id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.2" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.2.cmml">y</mi><mrow id="S2.SS2.p2.8.m8.2.2.1.3" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.cmml"><mo id="S2.SS2.p2.8.m8.2.2.1.3.1" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.cmml">(</mo><mi id="S2.SS2.p2.8.m8.2.2.1.1" xref="S2.SS2.p2.8.m8.2.2.1.1.cmml">n</mi><mo id="S2.SS2.p2.8.m8.2.2.1.3.2" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.cmml">)</mo></mrow></msup><mo id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.5" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S2.SS2.p2.8.m8.3.3.1.1.1.1.3" stretchy="false" xref="S2.SS2.p2.8.m8.3.3.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS2.p2.8.m8.3.3.1.1.3" xref="S2.SS2.p2.8.m8.3.3.1.1.3.cmml"><mi id="S2.SS2.p2.8.m8.3.3.1.1.3.2" xref="S2.SS2.p2.8.m8.3.3.1.1.3.2.cmml">n</mi><mo id="S2.SS2.p2.8.m8.3.3.1.1.3.1" xref="S2.SS2.p2.8.m8.3.3.1.1.3.1.cmml">=</mo><mn id="S2.SS2.p2.8.m8.3.3.1.1.3.3" xref="S2.SS2.p2.8.m8.3.3.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS2.p2.8.m8.3.3.1.3" xref="S2.SS2.p2.8.m8.3.3.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.8.m8.3b"><apply id="S2.SS2.p2.8.m8.3.3.cmml" xref="S2.SS2.p2.8.m8.3.3"><csymbol cd="latexml" id="S2.SS2.p2.8.m8.3.3.2.cmml" xref="S2.SS2.p2.8.m8.3.3.2">assign</csymbol><ci id="S2.SS2.p2.8.m8.3.3.3.cmml" xref="S2.SS2.p2.8.m8.3.3.3">𝐷</ci><apply id="S2.SS2.p2.8.m8.3.3.1.cmml" xref="S2.SS2.p2.8.m8.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m8.3.3.1.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1">superscript</csymbol><apply id="S2.SS2.p2.8.m8.3.3.1.1.cmml" xref="S2.SS2.p2.8.m8.3.3.1"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m8.3.3.1.1.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1">subscript</csymbol><set id="S2.SS2.p2.8.m8.3.3.1.1.1.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1"><interval closure="open" id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.3.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2"><apply id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS2.p2.8.m8.1.1.1.1.cmml" xref="S2.SS2.p2.8.m8.1.1.1.1">𝑛</ci></apply><apply id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.1.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2">superscript</csymbol><ci id="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S2.SS2.p2.8.m8.2.2.1.1.cmml" xref="S2.SS2.p2.8.m8.2.2.1.1">𝑛</ci></apply></interval></set><apply id="S2.SS2.p2.8.m8.3.3.1.1.3.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.3"><eq id="S2.SS2.p2.8.m8.3.3.1.1.3.1.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.3.1"></eq><ci id="S2.SS2.p2.8.m8.3.3.1.1.3.2.cmml" xref="S2.SS2.p2.8.m8.3.3.1.1.3.2">𝑛</ci><cn id="S2.SS2.p2.8.m8.3.3.1.1.3.3.cmml" type="integer" xref="S2.SS2.p2.8.m8.3.3.1.1.3.3">1</cn></apply></apply><ci id="S2.SS2.p2.8.m8.3.3.1.3.cmml" xref="S2.SS2.p2.8.m8.3.3.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.8.m8.3c">D:=\{(x^{(n)},y^{(n)})\}_{n=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.8.m8.3d">italic_D := { ( italic_x start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ( italic_n ) end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math>. To simulate practical inference scenarios, the dataset <math alttext="D" class="ltx_Math" display="inline" id="S2.SS2.p2.9.m9.1"><semantics id="S2.SS2.p2.9.m9.1a"><mi id="S2.SS2.p2.9.m9.1.1" xref="S2.SS2.p2.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.9.m9.1b"><ci id="S2.SS2.p2.9.m9.1.1.cmml" xref="S2.SS2.p2.9.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.9.m9.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.9.m9.1d">italic_D</annotation></semantics></math> is split into <math alttext="D_{\text{train}}" class="ltx_Math" display="inline" id="S2.SS2.p2.10.m10.1"><semantics id="S2.SS2.p2.10.m10.1a"><msub id="S2.SS2.p2.10.m10.1.1" xref="S2.SS2.p2.10.m10.1.1.cmml"><mi id="S2.SS2.p2.10.m10.1.1.2" xref="S2.SS2.p2.10.m10.1.1.2.cmml">D</mi><mtext id="S2.SS2.p2.10.m10.1.1.3" xref="S2.SS2.p2.10.m10.1.1.3a.cmml">train</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.10.m10.1b"><apply id="S2.SS2.p2.10.m10.1.1.cmml" xref="S2.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.10.m10.1.1.1.cmml" xref="S2.SS2.p2.10.m10.1.1">subscript</csymbol><ci id="S2.SS2.p2.10.m10.1.1.2.cmml" xref="S2.SS2.p2.10.m10.1.1.2">𝐷</ci><ci id="S2.SS2.p2.10.m10.1.1.3a.cmml" xref="S2.SS2.p2.10.m10.1.1.3"><mtext id="S2.SS2.p2.10.m10.1.1.3.cmml" mathsize="70%" xref="S2.SS2.p2.10.m10.1.1.3">train</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.10.m10.1c">D_{\text{train}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.10.m10.1d">italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT</annotation></semantics></math> and the context dataset <math alttext="D_{\text{test}}=D\setminus D_{\text{train}}" class="ltx_Math" display="inline" id="S2.SS2.p2.11.m11.1"><semantics id="S2.SS2.p2.11.m11.1a"><mrow id="S2.SS2.p2.11.m11.1.1" xref="S2.SS2.p2.11.m11.1.1.cmml"><msub id="S2.SS2.p2.11.m11.1.1.2" xref="S2.SS2.p2.11.m11.1.1.2.cmml"><mi id="S2.SS2.p2.11.m11.1.1.2.2" xref="S2.SS2.p2.11.m11.1.1.2.2.cmml">D</mi><mtext id="S2.SS2.p2.11.m11.1.1.2.3" xref="S2.SS2.p2.11.m11.1.1.2.3a.cmml">test</mtext></msub><mo id="S2.SS2.p2.11.m11.1.1.1" xref="S2.SS2.p2.11.m11.1.1.1.cmml">=</mo><mrow id="S2.SS2.p2.11.m11.1.1.3" xref="S2.SS2.p2.11.m11.1.1.3.cmml"><mi id="S2.SS2.p2.11.m11.1.1.3.2" xref="S2.SS2.p2.11.m11.1.1.3.2.cmml">D</mi><mo id="S2.SS2.p2.11.m11.1.1.3.1" xref="S2.SS2.p2.11.m11.1.1.3.1.cmml">∖</mo><msub id="S2.SS2.p2.11.m11.1.1.3.3" xref="S2.SS2.p2.11.m11.1.1.3.3.cmml"><mi id="S2.SS2.p2.11.m11.1.1.3.3.2" xref="S2.SS2.p2.11.m11.1.1.3.3.2.cmml">D</mi><mtext id="S2.SS2.p2.11.m11.1.1.3.3.3" xref="S2.SS2.p2.11.m11.1.1.3.3.3a.cmml">train</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.11.m11.1b"><apply id="S2.SS2.p2.11.m11.1.1.cmml" xref="S2.SS2.p2.11.m11.1.1"><eq id="S2.SS2.p2.11.m11.1.1.1.cmml" xref="S2.SS2.p2.11.m11.1.1.1"></eq><apply id="S2.SS2.p2.11.m11.1.1.2.cmml" xref="S2.SS2.p2.11.m11.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p2.11.m11.1.1.2.1.cmml" xref="S2.SS2.p2.11.m11.1.1.2">subscript</csymbol><ci id="S2.SS2.p2.11.m11.1.1.2.2.cmml" xref="S2.SS2.p2.11.m11.1.1.2.2">𝐷</ci><ci id="S2.SS2.p2.11.m11.1.1.2.3a.cmml" xref="S2.SS2.p2.11.m11.1.1.2.3"><mtext id="S2.SS2.p2.11.m11.1.1.2.3.cmml" mathsize="70%" xref="S2.SS2.p2.11.m11.1.1.2.3">test</mtext></ci></apply><apply id="S2.SS2.p2.11.m11.1.1.3.cmml" xref="S2.SS2.p2.11.m11.1.1.3"><setdiff id="S2.SS2.p2.11.m11.1.1.3.1.cmml" xref="S2.SS2.p2.11.m11.1.1.3.1"></setdiff><ci id="S2.SS2.p2.11.m11.1.1.3.2.cmml" xref="S2.SS2.p2.11.m11.1.1.3.2">𝐷</ci><apply id="S2.SS2.p2.11.m11.1.1.3.3.cmml" xref="S2.SS2.p2.11.m11.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS2.p2.11.m11.1.1.3.3.1.cmml" xref="S2.SS2.p2.11.m11.1.1.3.3">subscript</csymbol><ci id="S2.SS2.p2.11.m11.1.1.3.3.2.cmml" xref="S2.SS2.p2.11.m11.1.1.3.3.2">𝐷</ci><ci id="S2.SS2.p2.11.m11.1.1.3.3.3a.cmml" xref="S2.SS2.p2.11.m11.1.1.3.3.3"><mtext id="S2.SS2.p2.11.m11.1.1.3.3.3.cmml" mathsize="70%" xref="S2.SS2.p2.11.m11.1.1.3.3.3">train</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.11.m11.1c">D_{\text{test}}=D\setminus D_{\text{train}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.11.m11.1d">italic_D start_POSTSUBSCRIPT test end_POSTSUBSCRIPT = italic_D ∖ italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT</annotation></semantics></math>. The transformer model parses the pairs <math alttext="(x_{\text{train}},y_{\text{train}})\in D_{\text{train}}" class="ltx_Math" display="inline" id="S2.SS2.p2.12.m12.2"><semantics id="S2.SS2.p2.12.m12.2a"><mrow id="S2.SS2.p2.12.m12.2.2" xref="S2.SS2.p2.12.m12.2.2.cmml"><mrow id="S2.SS2.p2.12.m12.2.2.2.2" xref="S2.SS2.p2.12.m12.2.2.2.3.cmml"><mo id="S2.SS2.p2.12.m12.2.2.2.2.3" stretchy="false" xref="S2.SS2.p2.12.m12.2.2.2.3.cmml">(</mo><msub id="S2.SS2.p2.12.m12.1.1.1.1.1" xref="S2.SS2.p2.12.m12.1.1.1.1.1.cmml"><mi id="S2.SS2.p2.12.m12.1.1.1.1.1.2" xref="S2.SS2.p2.12.m12.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.SS2.p2.12.m12.1.1.1.1.1.3" xref="S2.SS2.p2.12.m12.1.1.1.1.1.3a.cmml">train</mtext></msub><mo id="S2.SS2.p2.12.m12.2.2.2.2.4" xref="S2.SS2.p2.12.m12.2.2.2.3.cmml">,</mo><msub id="S2.SS2.p2.12.m12.2.2.2.2.2" xref="S2.SS2.p2.12.m12.2.2.2.2.2.cmml"><mi id="S2.SS2.p2.12.m12.2.2.2.2.2.2" xref="S2.SS2.p2.12.m12.2.2.2.2.2.2.cmml">y</mi><mtext id="S2.SS2.p2.12.m12.2.2.2.2.2.3" xref="S2.SS2.p2.12.m12.2.2.2.2.2.3a.cmml">train</mtext></msub><mo id="S2.SS2.p2.12.m12.2.2.2.2.5" stretchy="false" xref="S2.SS2.p2.12.m12.2.2.2.3.cmml">)</mo></mrow><mo id="S2.SS2.p2.12.m12.2.2.3" xref="S2.SS2.p2.12.m12.2.2.3.cmml">∈</mo><msub id="S2.SS2.p2.12.m12.2.2.4" xref="S2.SS2.p2.12.m12.2.2.4.cmml"><mi id="S2.SS2.p2.12.m12.2.2.4.2" xref="S2.SS2.p2.12.m12.2.2.4.2.cmml">D</mi><mtext id="S2.SS2.p2.12.m12.2.2.4.3" xref="S2.SS2.p2.12.m12.2.2.4.3a.cmml">train</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.12.m12.2b"><apply id="S2.SS2.p2.12.m12.2.2.cmml" xref="S2.SS2.p2.12.m12.2.2"><in id="S2.SS2.p2.12.m12.2.2.3.cmml" xref="S2.SS2.p2.12.m12.2.2.3"></in><interval closure="open" id="S2.SS2.p2.12.m12.2.2.2.3.cmml" xref="S2.SS2.p2.12.m12.2.2.2.2"><apply id="S2.SS2.p2.12.m12.1.1.1.1.1.cmml" xref="S2.SS2.p2.12.m12.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.12.m12.1.1.1.1.1.1.cmml" xref="S2.SS2.p2.12.m12.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p2.12.m12.1.1.1.1.1.2.cmml" xref="S2.SS2.p2.12.m12.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS2.p2.12.m12.1.1.1.1.1.3a.cmml" xref="S2.SS2.p2.12.m12.1.1.1.1.1.3"><mtext id="S2.SS2.p2.12.m12.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.SS2.p2.12.m12.1.1.1.1.1.3">train</mtext></ci></apply><apply id="S2.SS2.p2.12.m12.2.2.2.2.2.cmml" xref="S2.SS2.p2.12.m12.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.p2.12.m12.2.2.2.2.2.1.cmml" xref="S2.SS2.p2.12.m12.2.2.2.2.2">subscript</csymbol><ci id="S2.SS2.p2.12.m12.2.2.2.2.2.2.cmml" xref="S2.SS2.p2.12.m12.2.2.2.2.2.2">𝑦</ci><ci id="S2.SS2.p2.12.m12.2.2.2.2.2.3a.cmml" xref="S2.SS2.p2.12.m12.2.2.2.2.2.3"><mtext id="S2.SS2.p2.12.m12.2.2.2.2.2.3.cmml" mathsize="70%" xref="S2.SS2.p2.12.m12.2.2.2.2.2.3">train</mtext></ci></apply></interval><apply id="S2.SS2.p2.12.m12.2.2.4.cmml" xref="S2.SS2.p2.12.m12.2.2.4"><csymbol cd="ambiguous" id="S2.SS2.p2.12.m12.2.2.4.1.cmml" xref="S2.SS2.p2.12.m12.2.2.4">subscript</csymbol><ci id="S2.SS2.p2.12.m12.2.2.4.2.cmml" xref="S2.SS2.p2.12.m12.2.2.4.2">𝐷</ci><ci id="S2.SS2.p2.12.m12.2.2.4.3a.cmml" xref="S2.SS2.p2.12.m12.2.2.4.3"><mtext id="S2.SS2.p2.12.m12.2.2.4.3.cmml" mathsize="70%" xref="S2.SS2.p2.12.m12.2.2.4.3">train</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.12.m12.2c">(x_{\text{train}},y_{\text{train}})\in D_{\text{train}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.12.m12.2d">( italic_x start_POSTSUBSCRIPT train end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ) ∈ italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT</annotation></semantics></math>, as well as <math alttext="x_{\text{test}}" class="ltx_Math" display="inline" id="S2.SS2.p2.13.m13.1"><semantics id="S2.SS2.p2.13.m13.1a"><msub id="S2.SS2.p2.13.m13.1.1" xref="S2.SS2.p2.13.m13.1.1.cmml"><mi id="S2.SS2.p2.13.m13.1.1.2" xref="S2.SS2.p2.13.m13.1.1.2.cmml">x</mi><mtext id="S2.SS2.p2.13.m13.1.1.3" xref="S2.SS2.p2.13.m13.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.13.m13.1b"><apply id="S2.SS2.p2.13.m13.1.1.cmml" xref="S2.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.13.m13.1.1.1.cmml" xref="S2.SS2.p2.13.m13.1.1">subscript</csymbol><ci id="S2.SS2.p2.13.m13.1.1.2.cmml" xref="S2.SS2.p2.13.m13.1.1.2">𝑥</ci><ci id="S2.SS2.p2.13.m13.1.1.3a.cmml" xref="S2.SS2.p2.13.m13.1.1.3"><mtext id="S2.SS2.p2.13.m13.1.1.3.cmml" mathsize="70%" xref="S2.SS2.p2.13.m13.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.13.m13.1c">x_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.13.m13.1d">italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math>, as single input tokens and its parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS2.p2.14.m14.1"><semantics id="S2.SS2.p2.14.m14.1a"><mi id="S2.SS2.p2.14.m14.1.1" xref="S2.SS2.p2.14.m14.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.14.m14.1b"><ci id="S2.SS2.p2.14.m14.1.1.cmml" xref="S2.SS2.p2.14.m14.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.14.m14.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.14.m14.1d">italic_θ</annotation></semantics></math> are updated to minimize the negative log likelihood on the test held-out examples:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbb{E}_{(D_{\text{train}}\cup(x_{\text{test}},y_{\text{test}}))\sim p(D)}[%
-\log q_{\theta}(y_{\text{test}}|x_{\text{test}},D_{\text{train}})]." class="ltx_Math" display="block" id="S2.E2.m1.3"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.3.2" xref="S2.E2.m1.3.3.1.1.3.2.cmml">𝔼</mi><mrow id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml"><mrow id="S2.E2.m1.2.2.2.2.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><mo id="S2.E2.m1.2.2.2.2.1.2" stretchy="false" xref="S2.E2.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S2.E2.m1.2.2.2.2.1.1" xref="S2.E2.m1.2.2.2.2.1.1.cmml"><msub id="S2.E2.m1.2.2.2.2.1.1.4" xref="S2.E2.m1.2.2.2.2.1.1.4.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.4.2" xref="S2.E2.m1.2.2.2.2.1.1.4.2.cmml">D</mi><mtext id="S2.E2.m1.2.2.2.2.1.1.4.3" xref="S2.E2.m1.2.2.2.2.1.1.4.3a.cmml">train</mtext></msub><mo id="S2.E2.m1.2.2.2.2.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.3.cmml">∪</mo><mrow id="S2.E2.m1.2.2.2.2.1.1.2.2" xref="S2.E2.m1.2.2.2.2.1.1.2.3.cmml"><mo id="S2.E2.m1.2.2.2.2.1.1.2.2.3" stretchy="false" xref="S2.E2.m1.2.2.2.2.1.1.2.3.cmml">(</mo><msub id="S2.E2.m1.2.2.2.2.1.1.1.1.1" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.1.1.1.2" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E2.m1.2.2.2.2.1.1.1.1.1.3" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S2.E2.m1.2.2.2.2.1.1.2.2.4" xref="S2.E2.m1.2.2.2.2.1.1.2.3.cmml">,</mo><msub id="S2.E2.m1.2.2.2.2.1.1.2.2.2" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2.cmml"><mi id="S2.E2.m1.2.2.2.2.1.1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2.2.cmml">y</mi><mtext id="S2.E2.m1.2.2.2.2.1.1.2.2.2.3" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2.3a.cmml">test</mtext></msub><mo id="S2.E2.m1.2.2.2.2.1.1.2.2.5" stretchy="false" xref="S2.E2.m1.2.2.2.2.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.2.2.2.2.1.3" stretchy="false" xref="S2.E2.m1.2.2.2.2.1.1.cmml">)</mo></mrow><mo id="S2.E2.m1.2.2.2.3" xref="S2.E2.m1.2.2.2.3.cmml">∼</mo><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.4.cmml"><mi id="S2.E2.m1.2.2.2.4.2" xref="S2.E2.m1.2.2.2.4.2.cmml">p</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.4.1.cmml">⁢</mo><mrow id="S2.E2.m1.2.2.2.4.3.2" xref="S2.E2.m1.2.2.2.4.cmml"><mo id="S2.E2.m1.2.2.2.4.3.2.1" stretchy="false" xref="S2.E2.m1.2.2.2.4.cmml">(</mo><mi id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">D</mi><mo id="S2.E2.m1.2.2.2.4.3.2.2" stretchy="false" xref="S2.E2.m1.2.2.2.4.cmml">)</mo></mrow></mrow></mrow></msub><mo id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml">⁢</mo><mrow id="S2.E2.m1.3.3.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.2.cmml"><mo id="S2.E2.m1.3.3.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.3.3.1.1.1.2.1.cmml">[</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml"><mo id="S2.E2.m1.3.3.1.1.1.1.1a" rspace="0.167em" xref="S2.E2.m1.3.3.1.1.1.1.1.cmml">−</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.3.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="S2.E2.m1.3.3.1.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.2.cmml">q</mi><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="S2.E2.m1.3.3.1.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.cmml">y</mi><mtext id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.3a.cmml">test</mtext></msub><mo fence="false" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml"><msub id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">D</mi><mtext id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3a.cmml">train</mtext></msub></mrow></mrow><mo id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m1.3.3.1.1.1.1.3" stretchy="false" xref="S2.E2.m1.3.3.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.E2.m1.3.3.1.2" lspace="0em" xref="S2.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><times id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"></times><apply id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2">𝔼</ci><apply id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"><csymbol cd="latexml" id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.3">similar-to</csymbol><apply id="S2.E2.m1.2.2.2.2.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1"><union id="S2.E2.m1.2.2.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.3"></union><apply id="S2.E2.m1.2.2.2.2.1.1.4.cmml" xref="S2.E2.m1.2.2.2.2.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.1.1.4.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.4">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.1.1.4.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.4.2">𝐷</ci><ci id="S2.E2.m1.2.2.2.2.1.1.4.3a.cmml" xref="S2.E2.m1.2.2.2.2.1.1.4.3"><mtext id="S2.E2.m1.2.2.2.2.1.1.4.3.cmml" mathsize="50%" xref="S2.E2.m1.2.2.2.2.1.1.4.3">train</mtext></ci></apply><interval closure="open" id="S2.E2.m1.2.2.2.2.1.1.2.3.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2.2"><apply id="S2.E2.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.2">𝑥</ci><ci id="S2.E2.m1.2.2.2.2.1.1.1.1.1.3a.cmml" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.3"><mtext id="S2.E2.m1.2.2.2.2.1.1.1.1.1.3.cmml" mathsize="50%" xref="S2.E2.m1.2.2.2.2.1.1.1.1.1.3">test</mtext></ci></apply><apply id="S2.E2.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.2.2.1.1.2.2.2.1.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.2.2.2.2.1.1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2.2">𝑦</ci><ci id="S2.E2.m1.2.2.2.2.1.1.2.2.2.3a.cmml" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2.3"><mtext id="S2.E2.m1.2.2.2.2.1.1.2.2.2.3.cmml" mathsize="50%" xref="S2.E2.m1.2.2.2.2.1.1.2.2.2.3">test</mtext></ci></apply></interval></apply><apply id="S2.E2.m1.2.2.2.4.cmml" xref="S2.E2.m1.2.2.2.4"><times id="S2.E2.m1.2.2.2.4.1.cmml" xref="S2.E2.m1.2.2.2.4.1"></times><ci id="S2.E2.m1.2.2.2.4.2.cmml" xref="S2.E2.m1.2.2.2.4.2">𝑝</ci><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">𝐷</ci></apply></apply></apply><apply id="S2.E2.m1.3.3.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.3.3.1.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E2.m1.3.3.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"><minus id="S2.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1"></minus><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1"><times id="S2.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3"><log id="S2.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.1"></log><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.2">𝑞</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.2">𝑦</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.3a.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.3"><mtext id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.3.cmml" mathsize="70%" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.4.3">test</mtext></ci></apply><list id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2"><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3"><mtext id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3">test</mtext></ci></apply><apply id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.2">𝐷</ci><ci id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3a.cmml" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3"><mtext id="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S2.E2.m1.3.3.1.1.1.1.1.1.1.1.1.2.2.2.3">train</mtext></ci></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">\mathbb{E}_{(D_{\text{train}}\cup(x_{\text{test}},y_{\text{test}}))\sim p(D)}[%
-\log q_{\theta}(y_{\text{test}}|x_{\text{test}},D_{\text{train}})].</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.3d">blackboard_E start_POSTSUBSCRIPT ( italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ∪ ( italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT ) ) ∼ italic_p ( italic_D ) end_POSTSUBSCRIPT [ - roman_log italic_q start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ) ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p2.16"><cite class="ltx_cite ltx_citemacro_citet">Müller et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib18" title="">2022</a>)</cite> showed that by minimizing this loss, TabPFN approximates the true posterior predictive distribution</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p(y_{\text{test}}|x_{\text{test}},D_{\text{train}})=\int_{\Phi}p(y_{\text{test%
}}|x_{\text{test}},\phi)p(\phi|D_{\text{train}})d\phi\propto\int_{\Phi}p(y_{%
\text{test}}|x_{\text{test}},\phi)p(D_{\text{train}}|\phi)p(\phi)d\phi" class="ltx_Math" display="block" id="S2.E3.m1.8"><semantics id="S2.E3.m1.8a"><mrow id="S2.E3.m1.8.8" xref="S2.E3.m1.8.8.cmml"><mrow id="S2.E3.m1.4.4.1" xref="S2.E3.m1.4.4.1.cmml"><mi id="S2.E3.m1.4.4.1.3" xref="S2.E3.m1.4.4.1.3.cmml">p</mi><mo id="S2.E3.m1.4.4.1.2" xref="S2.E3.m1.4.4.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.4.4.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.cmml"><mo id="S2.E3.m1.4.4.1.1.1.2" stretchy="false" xref="S2.E3.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.cmml"><msub id="S2.E3.m1.4.4.1.1.1.1.4" xref="S2.E3.m1.4.4.1.1.1.1.4.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.4.2" xref="S2.E3.m1.4.4.1.1.1.1.4.2.cmml">y</mi><mtext id="S2.E3.m1.4.4.1.1.1.1.4.3" xref="S2.E3.m1.4.4.1.1.1.1.4.3a.cmml">test</mtext></msub><mo fence="false" id="S2.E3.m1.4.4.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.3.cmml">|</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.2.2" xref="S2.E3.m1.4.4.1.1.1.1.2.3.cmml"><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E3.m1.4.4.1.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S2.E3.m1.4.4.1.1.1.1.2.2.3" xref="S2.E3.m1.4.4.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E3.m1.4.4.1.1.1.1.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.2.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2.2.cmml">D</mi><mtext id="S2.E3.m1.4.4.1.1.1.1.2.2.2.3" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2.3a.cmml">train</mtext></msub></mrow></mrow><mo id="S2.E3.m1.4.4.1.1.1.3" stretchy="false" xref="S2.E3.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.8.8.7" rspace="0.111em" xref="S2.E3.m1.8.8.7.cmml">=</mo><mrow id="S2.E3.m1.6.6.3" xref="S2.E3.m1.6.6.3.cmml"><msub id="S2.E3.m1.6.6.3.3" xref="S2.E3.m1.6.6.3.3.cmml"><mo id="S2.E3.m1.6.6.3.3.2" xref="S2.E3.m1.6.6.3.3.2.cmml">∫</mo><mi id="S2.E3.m1.6.6.3.3.3" mathvariant="normal" xref="S2.E3.m1.6.6.3.3.3.cmml">Φ</mi></msub><mrow id="S2.E3.m1.6.6.3.2" xref="S2.E3.m1.6.6.3.2.cmml"><mi id="S2.E3.m1.6.6.3.2.4" xref="S2.E3.m1.6.6.3.2.4.cmml">p</mi><mo id="S2.E3.m1.6.6.3.2.3" xref="S2.E3.m1.6.6.3.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.5.5.2.1.1.1" xref="S2.E3.m1.5.5.2.1.1.1.1.cmml"><mo id="S2.E3.m1.5.5.2.1.1.1.2" stretchy="false" xref="S2.E3.m1.5.5.2.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.5.5.2.1.1.1.1" xref="S2.E3.m1.5.5.2.1.1.1.1.cmml"><msub id="S2.E3.m1.5.5.2.1.1.1.1.3" xref="S2.E3.m1.5.5.2.1.1.1.1.3.cmml"><mi id="S2.E3.m1.5.5.2.1.1.1.1.3.2" xref="S2.E3.m1.5.5.2.1.1.1.1.3.2.cmml">y</mi><mtext id="S2.E3.m1.5.5.2.1.1.1.1.3.3" xref="S2.E3.m1.5.5.2.1.1.1.1.3.3a.cmml">test</mtext></msub><mo fence="false" id="S2.E3.m1.5.5.2.1.1.1.1.2" xref="S2.E3.m1.5.5.2.1.1.1.1.2.cmml">|</mo><mrow id="S2.E3.m1.5.5.2.1.1.1.1.1.1" xref="S2.E3.m1.5.5.2.1.1.1.1.1.2.cmml"><msub id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.2" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.3" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S2.E3.m1.5.5.2.1.1.1.1.1.1.2" xref="S2.E3.m1.5.5.2.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">ϕ</mi></mrow></mrow><mo id="S2.E3.m1.5.5.2.1.1.1.3" stretchy="false" xref="S2.E3.m1.5.5.2.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E3.m1.6.6.3.2.3a" xref="S2.E3.m1.6.6.3.2.3.cmml">⁢</mo><mi id="S2.E3.m1.6.6.3.2.5" xref="S2.E3.m1.6.6.3.2.5.cmml">p</mi><mo id="S2.E3.m1.6.6.3.2.3b" xref="S2.E3.m1.6.6.3.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.6.6.3.2.2.1" xref="S2.E3.m1.6.6.3.2.2.1.1.cmml"><mo id="S2.E3.m1.6.6.3.2.2.1.2" stretchy="false" xref="S2.E3.m1.6.6.3.2.2.1.1.cmml">(</mo><mrow id="S2.E3.m1.6.6.3.2.2.1.1" xref="S2.E3.m1.6.6.3.2.2.1.1.cmml"><mi id="S2.E3.m1.6.6.3.2.2.1.1.2" xref="S2.E3.m1.6.6.3.2.2.1.1.2.cmml">ϕ</mi><mo fence="false" id="S2.E3.m1.6.6.3.2.2.1.1.1" xref="S2.E3.m1.6.6.3.2.2.1.1.1.cmml">|</mo><msub id="S2.E3.m1.6.6.3.2.2.1.1.3" xref="S2.E3.m1.6.6.3.2.2.1.1.3.cmml"><mi id="S2.E3.m1.6.6.3.2.2.1.1.3.2" xref="S2.E3.m1.6.6.3.2.2.1.1.3.2.cmml">D</mi><mtext id="S2.E3.m1.6.6.3.2.2.1.1.3.3" xref="S2.E3.m1.6.6.3.2.2.1.1.3.3a.cmml">train</mtext></msub></mrow><mo id="S2.E3.m1.6.6.3.2.2.1.3" stretchy="false" xref="S2.E3.m1.6.6.3.2.2.1.1.cmml">)</mo></mrow><mo id="S2.E3.m1.6.6.3.2.3c" lspace="0em" xref="S2.E3.m1.6.6.3.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.6.6.3.2.6" xref="S2.E3.m1.6.6.3.2.6.cmml"><mo id="S2.E3.m1.6.6.3.2.6.1" rspace="0em" xref="S2.E3.m1.6.6.3.2.6.1.cmml">𝑑</mo><mi id="S2.E3.m1.6.6.3.2.6.2" xref="S2.E3.m1.6.6.3.2.6.2.cmml">ϕ</mi></mrow></mrow></mrow><mo id="S2.E3.m1.8.8.8" rspace="0.111em" xref="S2.E3.m1.8.8.8.cmml">∝</mo><mrow id="S2.E3.m1.8.8.5" xref="S2.E3.m1.8.8.5.cmml"><msub id="S2.E3.m1.8.8.5.3" xref="S2.E3.m1.8.8.5.3.cmml"><mo id="S2.E3.m1.8.8.5.3.2" xref="S2.E3.m1.8.8.5.3.2.cmml">∫</mo><mi id="S2.E3.m1.8.8.5.3.3" mathvariant="normal" xref="S2.E3.m1.8.8.5.3.3.cmml">Φ</mi></msub><mrow id="S2.E3.m1.8.8.5.2" xref="S2.E3.m1.8.8.5.2.cmml"><mi id="S2.E3.m1.8.8.5.2.4" xref="S2.E3.m1.8.8.5.2.4.cmml">p</mi><mo id="S2.E3.m1.8.8.5.2.3" xref="S2.E3.m1.8.8.5.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.7.7.4.1.1.1" xref="S2.E3.m1.7.7.4.1.1.1.1.cmml"><mo id="S2.E3.m1.7.7.4.1.1.1.2" stretchy="false" xref="S2.E3.m1.7.7.4.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.7.7.4.1.1.1.1" xref="S2.E3.m1.7.7.4.1.1.1.1.cmml"><msub id="S2.E3.m1.7.7.4.1.1.1.1.3" xref="S2.E3.m1.7.7.4.1.1.1.1.3.cmml"><mi id="S2.E3.m1.7.7.4.1.1.1.1.3.2" xref="S2.E3.m1.7.7.4.1.1.1.1.3.2.cmml">y</mi><mtext id="S2.E3.m1.7.7.4.1.1.1.1.3.3" xref="S2.E3.m1.7.7.4.1.1.1.1.3.3a.cmml">test</mtext></msub><mo fence="false" id="S2.E3.m1.7.7.4.1.1.1.1.2" xref="S2.E3.m1.7.7.4.1.1.1.1.2.cmml">|</mo><mrow id="S2.E3.m1.7.7.4.1.1.1.1.1.1" xref="S2.E3.m1.7.7.4.1.1.1.1.1.2.cmml"><msub id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.2" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.3" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S2.E3.m1.7.7.4.1.1.1.1.1.1.2" xref="S2.E3.m1.7.7.4.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">ϕ</mi></mrow></mrow><mo id="S2.E3.m1.7.7.4.1.1.1.3" stretchy="false" xref="S2.E3.m1.7.7.4.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E3.m1.8.8.5.2.3a" xref="S2.E3.m1.8.8.5.2.3.cmml">⁢</mo><mi id="S2.E3.m1.8.8.5.2.5" xref="S2.E3.m1.8.8.5.2.5.cmml">p</mi><mo id="S2.E3.m1.8.8.5.2.3b" xref="S2.E3.m1.8.8.5.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.8.8.5.2.2.1" xref="S2.E3.m1.8.8.5.2.2.1.1.cmml"><mo id="S2.E3.m1.8.8.5.2.2.1.2" stretchy="false" xref="S2.E3.m1.8.8.5.2.2.1.1.cmml">(</mo><mrow id="S2.E3.m1.8.8.5.2.2.1.1" xref="S2.E3.m1.8.8.5.2.2.1.1.cmml"><msub id="S2.E3.m1.8.8.5.2.2.1.1.2" xref="S2.E3.m1.8.8.5.2.2.1.1.2.cmml"><mi id="S2.E3.m1.8.8.5.2.2.1.1.2.2" xref="S2.E3.m1.8.8.5.2.2.1.1.2.2.cmml">D</mi><mtext id="S2.E3.m1.8.8.5.2.2.1.1.2.3" xref="S2.E3.m1.8.8.5.2.2.1.1.2.3a.cmml">train</mtext></msub><mo fence="false" id="S2.E3.m1.8.8.5.2.2.1.1.1" xref="S2.E3.m1.8.8.5.2.2.1.1.1.cmml">|</mo><mi id="S2.E3.m1.8.8.5.2.2.1.1.3" xref="S2.E3.m1.8.8.5.2.2.1.1.3.cmml">ϕ</mi></mrow><mo id="S2.E3.m1.8.8.5.2.2.1.3" stretchy="false" xref="S2.E3.m1.8.8.5.2.2.1.1.cmml">)</mo></mrow><mo id="S2.E3.m1.8.8.5.2.3c" xref="S2.E3.m1.8.8.5.2.3.cmml">⁢</mo><mi id="S2.E3.m1.8.8.5.2.6" xref="S2.E3.m1.8.8.5.2.6.cmml">p</mi><mo id="S2.E3.m1.8.8.5.2.3d" xref="S2.E3.m1.8.8.5.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.8.8.5.2.7.2" xref="S2.E3.m1.8.8.5.2.cmml"><mo id="S2.E3.m1.8.8.5.2.7.2.1" stretchy="false" xref="S2.E3.m1.8.8.5.2.cmml">(</mo><mi id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml">ϕ</mi><mo id="S2.E3.m1.8.8.5.2.7.2.2" stretchy="false" xref="S2.E3.m1.8.8.5.2.cmml">)</mo></mrow><mo id="S2.E3.m1.8.8.5.2.3e" lspace="0em" xref="S2.E3.m1.8.8.5.2.3.cmml">⁢</mo><mrow id="S2.E3.m1.8.8.5.2.8" xref="S2.E3.m1.8.8.5.2.8.cmml"><mo id="S2.E3.m1.8.8.5.2.8.1" rspace="0em" xref="S2.E3.m1.8.8.5.2.8.1.cmml">𝑑</mo><mi id="S2.E3.m1.8.8.5.2.8.2" xref="S2.E3.m1.8.8.5.2.8.2.cmml">ϕ</mi></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.8b"><apply id="S2.E3.m1.8.8.cmml" xref="S2.E3.m1.8.8"><and id="S2.E3.m1.8.8a.cmml" xref="S2.E3.m1.8.8"></and><apply id="S2.E3.m1.8.8b.cmml" xref="S2.E3.m1.8.8"><eq id="S2.E3.m1.8.8.7.cmml" xref="S2.E3.m1.8.8.7"></eq><apply id="S2.E3.m1.4.4.1.cmml" xref="S2.E3.m1.4.4.1"><times id="S2.E3.m1.4.4.1.2.cmml" xref="S2.E3.m1.4.4.1.2"></times><ci id="S2.E3.m1.4.4.1.3.cmml" xref="S2.E3.m1.4.4.1.3">𝑝</ci><apply id="S2.E3.m1.4.4.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.3">conditional</csymbol><apply id="S2.E3.m1.4.4.1.1.1.1.4.cmml" xref="S2.E3.m1.4.4.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.4.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.4">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.4.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.4.2">𝑦</ci><ci id="S2.E3.m1.4.4.1.1.1.1.4.3a.cmml" xref="S2.E3.m1.4.4.1.1.1.1.4.3"><mtext id="S2.E3.m1.4.4.1.1.1.1.4.3.cmml" mathsize="70%" xref="S2.E3.m1.4.4.1.1.1.1.4.3">test</mtext></ci></apply><list id="S2.E3.m1.4.4.1.1.1.1.2.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.2.2"><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.3a.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.3"><mtext id="S2.E3.m1.4.4.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.3">test</mtext></ci></apply><apply id="S2.E3.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2.2">𝐷</ci><ci id="S2.E3.m1.4.4.1.1.1.1.2.2.2.3a.cmml" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2.3"><mtext id="S2.E3.m1.4.4.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S2.E3.m1.4.4.1.1.1.1.2.2.2.3">train</mtext></ci></apply></list></apply></apply><apply id="S2.E3.m1.6.6.3.cmml" xref="S2.E3.m1.6.6.3"><apply id="S2.E3.m1.6.6.3.3.cmml" xref="S2.E3.m1.6.6.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.3.3.1.cmml" xref="S2.E3.m1.6.6.3.3">subscript</csymbol><int id="S2.E3.m1.6.6.3.3.2.cmml" xref="S2.E3.m1.6.6.3.3.2"></int><ci id="S2.E3.m1.6.6.3.3.3.cmml" xref="S2.E3.m1.6.6.3.3.3">Φ</ci></apply><apply id="S2.E3.m1.6.6.3.2.cmml" xref="S2.E3.m1.6.6.3.2"><times id="S2.E3.m1.6.6.3.2.3.cmml" xref="S2.E3.m1.6.6.3.2.3"></times><ci id="S2.E3.m1.6.6.3.2.4.cmml" xref="S2.E3.m1.6.6.3.2.4">𝑝</ci><apply id="S2.E3.m1.5.5.2.1.1.1.1.cmml" xref="S2.E3.m1.5.5.2.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.5.5.2.1.1.1.1.2.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.2">conditional</csymbol><apply id="S2.E3.m1.5.5.2.1.1.1.1.3.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.2.1.1.1.1.3.1.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.5.5.2.1.1.1.1.3.2.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.3.2">𝑦</ci><ci id="S2.E3.m1.5.5.2.1.1.1.1.3.3a.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.3.3"><mtext id="S2.E3.m1.5.5.2.1.1.1.1.3.3.cmml" mathsize="70%" xref="S2.E3.m1.5.5.2.1.1.1.1.3.3">test</mtext></ci></apply><list id="S2.E3.m1.5.5.2.1.1.1.1.1.2.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1"><apply id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.3a.cmml" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.3"><mtext id="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E3.m1.5.5.2.1.1.1.1.1.1.1.3">test</mtext></ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">italic-ϕ</ci></list></apply><ci id="S2.E3.m1.6.6.3.2.5.cmml" xref="S2.E3.m1.6.6.3.2.5">𝑝</ci><apply id="S2.E3.m1.6.6.3.2.2.1.1.cmml" xref="S2.E3.m1.6.6.3.2.2.1"><csymbol cd="latexml" id="S2.E3.m1.6.6.3.2.2.1.1.1.cmml" xref="S2.E3.m1.6.6.3.2.2.1.1.1">conditional</csymbol><ci id="S2.E3.m1.6.6.3.2.2.1.1.2.cmml" xref="S2.E3.m1.6.6.3.2.2.1.1.2">italic-ϕ</ci><apply id="S2.E3.m1.6.6.3.2.2.1.1.3.cmml" xref="S2.E3.m1.6.6.3.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.3.2.2.1.1.3.1.cmml" xref="S2.E3.m1.6.6.3.2.2.1.1.3">subscript</csymbol><ci id="S2.E3.m1.6.6.3.2.2.1.1.3.2.cmml" xref="S2.E3.m1.6.6.3.2.2.1.1.3.2">𝐷</ci><ci id="S2.E3.m1.6.6.3.2.2.1.1.3.3a.cmml" xref="S2.E3.m1.6.6.3.2.2.1.1.3.3"><mtext id="S2.E3.m1.6.6.3.2.2.1.1.3.3.cmml" mathsize="70%" xref="S2.E3.m1.6.6.3.2.2.1.1.3.3">train</mtext></ci></apply></apply><apply id="S2.E3.m1.6.6.3.2.6.cmml" xref="S2.E3.m1.6.6.3.2.6"><csymbol cd="latexml" id="S2.E3.m1.6.6.3.2.6.1.cmml" xref="S2.E3.m1.6.6.3.2.6.1">differential-d</csymbol><ci id="S2.E3.m1.6.6.3.2.6.2.cmml" xref="S2.E3.m1.6.6.3.2.6.2">italic-ϕ</ci></apply></apply></apply></apply><apply id="S2.E3.m1.8.8c.cmml" xref="S2.E3.m1.8.8"><csymbol cd="latexml" id="S2.E3.m1.8.8.8.cmml" xref="S2.E3.m1.8.8.8">proportional-to</csymbol><share href="https://arxiv.org/html/2410.04560v1#S2.E3.m1.6.6.3.cmml" id="S2.E3.m1.8.8d.cmml" xref="S2.E3.m1.8.8"></share><apply id="S2.E3.m1.8.8.5.cmml" xref="S2.E3.m1.8.8.5"><apply id="S2.E3.m1.8.8.5.3.cmml" xref="S2.E3.m1.8.8.5.3"><csymbol cd="ambiguous" id="S2.E3.m1.8.8.5.3.1.cmml" xref="S2.E3.m1.8.8.5.3">subscript</csymbol><int id="S2.E3.m1.8.8.5.3.2.cmml" xref="S2.E3.m1.8.8.5.3.2"></int><ci id="S2.E3.m1.8.8.5.3.3.cmml" xref="S2.E3.m1.8.8.5.3.3">Φ</ci></apply><apply id="S2.E3.m1.8.8.5.2.cmml" xref="S2.E3.m1.8.8.5.2"><times id="S2.E3.m1.8.8.5.2.3.cmml" xref="S2.E3.m1.8.8.5.2.3"></times><ci id="S2.E3.m1.8.8.5.2.4.cmml" xref="S2.E3.m1.8.8.5.2.4">𝑝</ci><apply id="S2.E3.m1.7.7.4.1.1.1.1.cmml" xref="S2.E3.m1.7.7.4.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.7.7.4.1.1.1.1.2.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.2">conditional</csymbol><apply id="S2.E3.m1.7.7.4.1.1.1.1.3.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.4.1.1.1.1.3.1.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.7.7.4.1.1.1.1.3.2.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.3.2">𝑦</ci><ci id="S2.E3.m1.7.7.4.1.1.1.1.3.3a.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.3.3"><mtext id="S2.E3.m1.7.7.4.1.1.1.1.3.3.cmml" mathsize="70%" xref="S2.E3.m1.7.7.4.1.1.1.1.3.3">test</mtext></ci></apply><list id="S2.E3.m1.7.7.4.1.1.1.1.1.2.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1"><apply id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.3a.cmml" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.3"><mtext id="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S2.E3.m1.7.7.4.1.1.1.1.1.1.1.3">test</mtext></ci></apply><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">italic-ϕ</ci></list></apply><ci id="S2.E3.m1.8.8.5.2.5.cmml" xref="S2.E3.m1.8.8.5.2.5">𝑝</ci><apply id="S2.E3.m1.8.8.5.2.2.1.1.cmml" xref="S2.E3.m1.8.8.5.2.2.1"><csymbol cd="latexml" id="S2.E3.m1.8.8.5.2.2.1.1.1.cmml" xref="S2.E3.m1.8.8.5.2.2.1.1.1">conditional</csymbol><apply id="S2.E3.m1.8.8.5.2.2.1.1.2.cmml" xref="S2.E3.m1.8.8.5.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.8.8.5.2.2.1.1.2.1.cmml" xref="S2.E3.m1.8.8.5.2.2.1.1.2">subscript</csymbol><ci id="S2.E3.m1.8.8.5.2.2.1.1.2.2.cmml" xref="S2.E3.m1.8.8.5.2.2.1.1.2.2">𝐷</ci><ci id="S2.E3.m1.8.8.5.2.2.1.1.2.3a.cmml" xref="S2.E3.m1.8.8.5.2.2.1.1.2.3"><mtext id="S2.E3.m1.8.8.5.2.2.1.1.2.3.cmml" mathsize="70%" xref="S2.E3.m1.8.8.5.2.2.1.1.2.3">train</mtext></ci></apply><ci id="S2.E3.m1.8.8.5.2.2.1.1.3.cmml" xref="S2.E3.m1.8.8.5.2.2.1.1.3">italic-ϕ</ci></apply><ci id="S2.E3.m1.8.8.5.2.6.cmml" xref="S2.E3.m1.8.8.5.2.6">𝑝</ci><ci id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3">italic-ϕ</ci><apply id="S2.E3.m1.8.8.5.2.8.cmml" xref="S2.E3.m1.8.8.5.2.8"><csymbol cd="latexml" id="S2.E3.m1.8.8.5.2.8.1.cmml" xref="S2.E3.m1.8.8.5.2.8.1">differential-d</csymbol><ci id="S2.E3.m1.8.8.5.2.8.2.cmml" xref="S2.E3.m1.8.8.5.2.8.2">italic-ϕ</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.8c">p(y_{\text{test}}|x_{\text{test}},D_{\text{train}})=\int_{\Phi}p(y_{\text{test%
}}|x_{\text{test}},\phi)p(\phi|D_{\text{train}})d\phi\propto\int_{\Phi}p(y_{%
\text{test}}|x_{\text{test}},\phi)p(D_{\text{train}}|\phi)p(\phi)d\phi</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.8d">italic_p ( italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ) = ∫ start_POSTSUBSCRIPT roman_Φ end_POSTSUBSCRIPT italic_p ( italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_ϕ ) italic_p ( italic_ϕ | italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ) italic_d italic_ϕ ∝ ∫ start_POSTSUBSCRIPT roman_Φ end_POSTSUBSCRIPT italic_p ( italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_ϕ ) italic_p ( italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT | italic_ϕ ) italic_p ( italic_ϕ ) italic_d italic_ϕ</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p2.15">on a new input point from the test set <math alttext="x_{\text{test}}" class="ltx_Math" display="inline" id="S2.SS2.p2.15.m1.1"><semantics id="S2.SS2.p2.15.m1.1a"><msub id="S2.SS2.p2.15.m1.1.1" xref="S2.SS2.p2.15.m1.1.1.cmml"><mi id="S2.SS2.p2.15.m1.1.1.2" xref="S2.SS2.p2.15.m1.1.1.2.cmml">x</mi><mtext id="S2.SS2.p2.15.m1.1.1.3" xref="S2.SS2.p2.15.m1.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.15.m1.1b"><apply id="S2.SS2.p2.15.m1.1.1.cmml" xref="S2.SS2.p2.15.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p2.15.m1.1.1.1.cmml" xref="S2.SS2.p2.15.m1.1.1">subscript</csymbol><ci id="S2.SS2.p2.15.m1.1.1.2.cmml" xref="S2.SS2.p2.15.m1.1.1.2">𝑥</ci><ci id="S2.SS2.p2.15.m1.1.1.3a.cmml" xref="S2.SS2.p2.15.m1.1.1.3"><mtext id="S2.SS2.p2.15.m1.1.1.3.cmml" mathsize="70%" xref="S2.SS2.p2.15.m1.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.15.m1.1c">x_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.15.m1.1d">italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math> up to an additive constant. This paradigm has since been extended to time-series forecasting <cite class="ltx_cite ltx_citemacro_citep">(Dooley et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib16" title="">2024</a>)</cite>, hyperparameter optimization <cite class="ltx_cite ltx_citemacro_citep">(Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib35" title="">2023a</a>; Adriaensen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib36" title="">2024</a>; Rakotoarison et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib37" title="">2024</a>)</cite> and the prediction of neural network weights <cite class="ltx_cite ltx_citemacro_citep">(Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib38" title="">2023b</a>)</cite>. Similarly, Conditional Neural Processes <cite class="ltx_cite ltx_citemacro_citep">(Garnelo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib39" title="">2018</a>)</cite> also perform a form of ICL, using a neural architecture with weights meta-learned on real data. <cite class="ltx_cite ltx_citemacro_citep">(Nguyen and Grover, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib40" title="">2022</a>)</cite> extended Neural Processes to a transformer architecture, leading to an architecture similar to PFNs. <em class="ltx_emph ltx_font_italic" id="S2.SS2.p2.15.1">GAMformer</em> builds on top of TabPFN by training a transformer on synthetically generated datasets to estimate the shape function per feature and computing predictions by adding the individual shape function values.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>GAMformer</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.4">We first provide a high-level overview of how GAMformer works before delving into the details of each of its components. GAMformer follows a two-step approach that first fits a GAM on training data <math alttext="D_{\text{train}}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><msub id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">D</mi><mtext id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3a.cmml">train</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">𝐷</ci><ci id="S3.p1.1.m1.1.1.3a.cmml" xref="S3.p1.1.m1.1.1.3"><mtext id="S3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.p1.1.m1.1.1.3">train</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">D_{\text{train}}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT</annotation></semantics></math> and then predicts on test data <math alttext="x_{\text{test}}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">x</mi><mtext id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">𝑥</ci><ci id="S3.p1.2.m2.1.1.3a.cmml" xref="S3.p1.2.m2.1.1.3"><mtext id="S3.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.p1.2.m2.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">x_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math>, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">1</span></a>. Initially, a transformer estimates shape functions using ICL on the training dataset <math alttext="D_{\text{train}}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">D</mi><mtext id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3a.cmml">train</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">𝐷</ci><ci id="S3.p1.3.m3.1.1.3a.cmml" xref="S3.p1.3.m3.1.1.3"><mtext id="S3.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.p1.3.m3.1.1.3">train</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">D_{\text{train}}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT</annotation></semantics></math>. Next, predictions are computed by aggregating the shape function values for each test data point <math alttext="x_{\text{test}}" class="ltx_Math" display="inline" id="S3.p1.4.m4.1"><semantics id="S3.p1.4.m4.1a"><msub id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml"><mi id="S3.p1.4.m4.1.1.2" xref="S3.p1.4.m4.1.1.2.cmml">x</mi><mtext id="S3.p1.4.m4.1.1.3" xref="S3.p1.4.m4.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><apply id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p1.4.m4.1.1.1.cmml" xref="S3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.p1.4.m4.1.1.2.cmml" xref="S3.p1.4.m4.1.1.2">𝑥</ci><ci id="S3.p1.4.m4.1.1.3a.cmml" xref="S3.p1.4.m4.1.1.3"><mtext id="S3.p1.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.p1.4.m4.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">x_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.1d">italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math>. This methodology replaces the traditional data fitting process of GAM variants with a single forward pass of a pre-trained transformer model, eliminating the need for optimization and regularization hyperparameters. We now describe each model component in more detail.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Shape Estimation and Predictions</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.8">We obtain the shape functions with ICL by applying a transformer on the training input points and labels:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\tilde{f}=\mathcal{T}_{\theta}(x_{\text{train}},y_{\text{train}})\in\mathbb{R}%
^{p\times n_{\text{bins}}\times m}," class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E4.m1.1.1.1.1.4" xref="S3.E4.m1.1.1.1.1.4.cmml"><mi id="S3.E4.m1.1.1.1.1.4.2" xref="S3.E4.m1.1.1.1.1.4.2.cmml">f</mi><mo id="S3.E4.m1.1.1.1.1.4.1" xref="S3.E4.m1.1.1.1.1.4.1.cmml">~</mo></mover><mo id="S3.E4.m1.1.1.1.1.5" xref="S3.E4.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml"><msub id="S3.E4.m1.1.1.1.1.2.4" xref="S3.E4.m1.1.1.1.1.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.2.4.2" xref="S3.E4.m1.1.1.1.1.2.4.2.cmml">𝒯</mi><mi id="S3.E4.m1.1.1.1.1.2.4.3" xref="S3.E4.m1.1.1.1.1.2.4.3.cmml">θ</mi></msub><mo id="S3.E4.m1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.2.3.cmml">⁢</mo><mrow id="S3.E4.m1.1.1.1.1.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml"><mo id="S3.E4.m1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mtext id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3a.cmml">train</mtext></msub><mo id="S3.E4.m1.1.1.1.1.2.2.2.4" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E4.m1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2.2.2.2" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2.cmml">y</mi><mtext id="S3.E4.m1.1.1.1.1.2.2.2.2.3" xref="S3.E4.m1.1.1.1.1.2.2.2.2.3a.cmml">train</mtext></msub><mo id="S3.E4.m1.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E4.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.6" xref="S3.E4.m1.1.1.1.1.6.cmml">∈</mo><msup id="S3.E4.m1.1.1.1.1.7" xref="S3.E4.m1.1.1.1.1.7.cmml"><mi id="S3.E4.m1.1.1.1.1.7.2" xref="S3.E4.m1.1.1.1.1.7.2.cmml">ℝ</mi><mrow id="S3.E4.m1.1.1.1.1.7.3" xref="S3.E4.m1.1.1.1.1.7.3.cmml"><mi id="S3.E4.m1.1.1.1.1.7.3.2" xref="S3.E4.m1.1.1.1.1.7.3.2.cmml">p</mi><mo id="S3.E4.m1.1.1.1.1.7.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.1.1.1.1.7.3.1.cmml">×</mo><msub id="S3.E4.m1.1.1.1.1.7.3.3" xref="S3.E4.m1.1.1.1.1.7.3.3.cmml"><mi id="S3.E4.m1.1.1.1.1.7.3.3.2" xref="S3.E4.m1.1.1.1.1.7.3.3.2.cmml">n</mi><mtext id="S3.E4.m1.1.1.1.1.7.3.3.3" xref="S3.E4.m1.1.1.1.1.7.3.3.3a.cmml">bins</mtext></msub><mo id="S3.E4.m1.1.1.1.1.7.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.1.1.1.1.7.3.1.cmml">×</mo><mi id="S3.E4.m1.1.1.1.1.7.3.4" xref="S3.E4.m1.1.1.1.1.7.3.4.cmml">m</mi></mrow></msup></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><and id="S3.E4.m1.1.1.1.1a.cmml" xref="S3.E4.m1.1.1.1"></and><apply id="S3.E4.m1.1.1.1.1b.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.5.cmml" xref="S3.E4.m1.1.1.1.1.5"></eq><apply id="S3.E4.m1.1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.1.4"><ci id="S3.E4.m1.1.1.1.1.4.1.cmml" xref="S3.E4.m1.1.1.1.1.4.1">~</ci><ci id="S3.E4.m1.1.1.1.1.4.2.cmml" xref="S3.E4.m1.1.1.1.1.4.2">𝑓</ci></apply><apply id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"><times id="S3.E4.m1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3"></times><apply id="S3.E4.m1.1.1.1.1.2.4.cmml" xref="S3.E4.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.4.1.cmml" xref="S3.E4.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.4.2.cmml" xref="S3.E4.m1.1.1.1.1.2.4.2">𝒯</ci><ci id="S3.E4.m1.1.1.1.1.2.4.3.cmml" xref="S3.E4.m1.1.1.1.1.2.4.3">𝜃</ci></apply><interval closure="open" id="S3.E4.m1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2"><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3"><mtext id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">train</mtext></ci></apply><apply id="S3.E4.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.2">𝑦</ci><ci id="S3.E4.m1.1.1.1.1.2.2.2.2.3a.cmml" xref="S3.E4.m1.1.1.1.1.2.2.2.2.3"><mtext id="S3.E4.m1.1.1.1.1.2.2.2.2.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.1.1.2.2.2.2.3">train</mtext></ci></apply></interval></apply></apply><apply id="S3.E4.m1.1.1.1.1c.cmml" xref="S3.E4.m1.1.1.1"><in id="S3.E4.m1.1.1.1.1.6.cmml" xref="S3.E4.m1.1.1.1.1.6"></in><share href="https://arxiv.org/html/2410.04560v1#S3.E4.m1.1.1.1.1.2.cmml" id="S3.E4.m1.1.1.1.1d.cmml" xref="S3.E4.m1.1.1.1"></share><apply id="S3.E4.m1.1.1.1.1.7.cmml" xref="S3.E4.m1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.7.1.cmml" xref="S3.E4.m1.1.1.1.1.7">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.7.2.cmml" xref="S3.E4.m1.1.1.1.1.7.2">ℝ</ci><apply id="S3.E4.m1.1.1.1.1.7.3.cmml" xref="S3.E4.m1.1.1.1.1.7.3"><times id="S3.E4.m1.1.1.1.1.7.3.1.cmml" xref="S3.E4.m1.1.1.1.1.7.3.1"></times><ci id="S3.E4.m1.1.1.1.1.7.3.2.cmml" xref="S3.E4.m1.1.1.1.1.7.3.2">𝑝</ci><apply id="S3.E4.m1.1.1.1.1.7.3.3.cmml" xref="S3.E4.m1.1.1.1.1.7.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.7.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.7.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.7.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.7.3.3.2">𝑛</ci><ci id="S3.E4.m1.1.1.1.1.7.3.3.3a.cmml" xref="S3.E4.m1.1.1.1.1.7.3.3.3"><mtext id="S3.E4.m1.1.1.1.1.7.3.3.3.cmml" mathsize="50%" xref="S3.E4.m1.1.1.1.1.7.3.3.3">bins</mtext></ci></apply><ci id="S3.E4.m1.1.1.1.1.7.3.4.cmml" xref="S3.E4.m1.1.1.1.1.7.3.4">𝑚</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\tilde{f}=\mathcal{T}_{\theta}(x_{\text{train}},y_{\text{train}})\in\mathbb{R}%
^{p\times n_{\text{bins}}\times m},</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">over~ start_ARG italic_f end_ARG = caligraphic_T start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT train end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_p × italic_n start_POSTSUBSCRIPT bins end_POSTSUBSCRIPT × italic_m end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.3">where <math alttext="p,m" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.2"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.3.2" xref="S3.SS1.p1.1.m1.2.3.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">p</mi><mo id="S3.SS1.p1.1.m1.2.3.2.1" xref="S3.SS1.p1.1.m1.2.3.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><list id="S3.SS1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.3.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑝</ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">𝑚</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">p,m</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.2d">italic_p , italic_m</annotation></semantics></math> and <math alttext="n_{\text{bins}}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">n</mi><mtext id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3a.cmml">bins</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑛</ci><ci id="S3.SS1.p1.2.m2.1.1.3a.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><mtext id="S3.SS1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p1.2.m2.1.1.3">bins</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">n_{\text{bins}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_n start_POSTSUBSCRIPT bins end_POSTSUBSCRIPT</annotation></semantics></math> are respectively the numbers of features, classes and bins. To get predictions on a new test point <math alttext="x_{\text{test}}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">x</mi><mtext id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑥</ci><ci id="S3.SS1.p1.3.m3.1.1.3a.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><mtext id="S3.SS1.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p1.3.m3.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">x_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math>, we first bin each feature value and then apply the estimated shape function:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="g\left(\tilde{y}_{\text{test}}\right)=\sum_{i=1}^{p}\tilde{f}_{ij_{x_{i}}}\in%
\mathbb{R}^{m}," class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.3.cmml">g</mi><mo id="S3.E5.m1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E5.m1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.2.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mtext id="S3.E5.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S3.E5.m1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.1.1.1.1.3" rspace="0.111em" xref="S3.E5.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.4" xref="S3.E5.m1.1.1.1.1.4.cmml"><munderover id="S3.E5.m1.1.1.1.1.4.1" xref="S3.E5.m1.1.1.1.1.4.1.cmml"><mo id="S3.E5.m1.1.1.1.1.4.1.2.2" movablelimits="false" xref="S3.E5.m1.1.1.1.1.4.1.2.2.cmml">∑</mo><mrow id="S3.E5.m1.1.1.1.1.4.1.2.3" xref="S3.E5.m1.1.1.1.1.4.1.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.4.1.2.3.2" xref="S3.E5.m1.1.1.1.1.4.1.2.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.1.1.4.1.2.3.1" xref="S3.E5.m1.1.1.1.1.4.1.2.3.1.cmml">=</mo><mn id="S3.E5.m1.1.1.1.1.4.1.2.3.3" xref="S3.E5.m1.1.1.1.1.4.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E5.m1.1.1.1.1.4.1.3" xref="S3.E5.m1.1.1.1.1.4.1.3.cmml">p</mi></munderover><msub id="S3.E5.m1.1.1.1.1.4.2" xref="S3.E5.m1.1.1.1.1.4.2.cmml"><mover accent="true" id="S3.E5.m1.1.1.1.1.4.2.2" xref="S3.E5.m1.1.1.1.1.4.2.2.cmml"><mi id="S3.E5.m1.1.1.1.1.4.2.2.2" xref="S3.E5.m1.1.1.1.1.4.2.2.2.cmml">f</mi><mo id="S3.E5.m1.1.1.1.1.4.2.2.1" xref="S3.E5.m1.1.1.1.1.4.2.2.1.cmml">~</mo></mover><mrow id="S3.E5.m1.1.1.1.1.4.2.3" xref="S3.E5.m1.1.1.1.1.4.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1.4.2.3.2" xref="S3.E5.m1.1.1.1.1.4.2.3.2.cmml">i</mi><mo id="S3.E5.m1.1.1.1.1.4.2.3.1" xref="S3.E5.m1.1.1.1.1.4.2.3.1.cmml">⁢</mo><msub id="S3.E5.m1.1.1.1.1.4.2.3.3" xref="S3.E5.m1.1.1.1.1.4.2.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.4.2.3.3.2" xref="S3.E5.m1.1.1.1.1.4.2.3.3.2.cmml">j</mi><msub id="S3.E5.m1.1.1.1.1.4.2.3.3.3" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.4.2.3.3.3.2" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3.2.cmml">x</mi><mi id="S3.E5.m1.1.1.1.1.4.2.3.3.3.3" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3.3.cmml">i</mi></msub></msub></mrow></msub></mrow><mo id="S3.E5.m1.1.1.1.1.5" xref="S3.E5.m1.1.1.1.1.5.cmml">∈</mo><msup id="S3.E5.m1.1.1.1.1.6" xref="S3.E5.m1.1.1.1.1.6.cmml"><mi id="S3.E5.m1.1.1.1.1.6.2" xref="S3.E5.m1.1.1.1.1.6.2.cmml">ℝ</mi><mi id="S3.E5.m1.1.1.1.1.6.3" xref="S3.E5.m1.1.1.1.1.6.3.cmml">m</mi></msup></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><and id="S3.E5.m1.1.1.1.1a.cmml" xref="S3.E5.m1.1.1.1"></and><apply id="S3.E5.m1.1.1.1.1b.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"></eq><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3">𝑔</ci><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2"><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2">𝑦</ci></apply><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3"><mtext id="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3">test</mtext></ci></apply></apply><apply id="S3.E5.m1.1.1.1.1.4.cmml" xref="S3.E5.m1.1.1.1.1.4"><apply id="S3.E5.m1.1.1.1.1.4.1.cmml" xref="S3.E5.m1.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.4.1.1.cmml" xref="S3.E5.m1.1.1.1.1.4.1">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.4.1.2.cmml" xref="S3.E5.m1.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.4.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.4.1">subscript</csymbol><sum id="S3.E5.m1.1.1.1.1.4.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.4.1.2.2"></sum><apply id="S3.E5.m1.1.1.1.1.4.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.4.1.2.3"><eq id="S3.E5.m1.1.1.1.1.4.1.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.4.1.2.3.1"></eq><ci id="S3.E5.m1.1.1.1.1.4.1.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.4.1.2.3.2">𝑖</ci><cn id="S3.E5.m1.1.1.1.1.4.1.2.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.1.1.4.1.2.3.3">1</cn></apply></apply><ci id="S3.E5.m1.1.1.1.1.4.1.3.cmml" xref="S3.E5.m1.1.1.1.1.4.1.3">𝑝</ci></apply><apply id="S3.E5.m1.1.1.1.1.4.2.cmml" xref="S3.E5.m1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.4.2.1.cmml" xref="S3.E5.m1.1.1.1.1.4.2">subscript</csymbol><apply id="S3.E5.m1.1.1.1.1.4.2.2.cmml" xref="S3.E5.m1.1.1.1.1.4.2.2"><ci id="S3.E5.m1.1.1.1.1.4.2.2.1.cmml" xref="S3.E5.m1.1.1.1.1.4.2.2.1">~</ci><ci id="S3.E5.m1.1.1.1.1.4.2.2.2.cmml" xref="S3.E5.m1.1.1.1.1.4.2.2.2">𝑓</ci></apply><apply id="S3.E5.m1.1.1.1.1.4.2.3.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3"><times id="S3.E5.m1.1.1.1.1.4.2.3.1.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.1"></times><ci id="S3.E5.m1.1.1.1.1.4.2.3.2.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.2">𝑖</ci><apply id="S3.E5.m1.1.1.1.1.4.2.3.3.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.4.2.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.4.2.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3.2">𝑗</ci><apply id="S3.E5.m1.1.1.1.1.4.2.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.4.2.3.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.4.2.3.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3.2">𝑥</ci><ci id="S3.E5.m1.1.1.1.1.4.2.3.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.4.2.3.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply><apply id="S3.E5.m1.1.1.1.1c.cmml" xref="S3.E5.m1.1.1.1"><in id="S3.E5.m1.1.1.1.1.5.cmml" xref="S3.E5.m1.1.1.1.1.5"></in><share href="https://arxiv.org/html/2410.04560v1#S3.E5.m1.1.1.1.1.4.cmml" id="S3.E5.m1.1.1.1.1d.cmml" xref="S3.E5.m1.1.1.1"></share><apply id="S3.E5.m1.1.1.1.1.6.cmml" xref="S3.E5.m1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.6.1.cmml" xref="S3.E5.m1.1.1.1.1.6">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.6.2.cmml" xref="S3.E5.m1.1.1.1.1.6.2">ℝ</ci><ci id="S3.E5.m1.1.1.1.1.6.3.cmml" xref="S3.E5.m1.1.1.1.1.6.3">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">g\left(\tilde{y}_{\text{test}}\right)=\sum_{i=1}^{p}\tilde{f}_{ij_{x_{i}}}\in%
\mathbb{R}^{m},</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_g ( over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT test end_POSTSUBSCRIPT ) = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT over~ start_ARG italic_f end_ARG start_POSTSUBSCRIPT italic_i italic_j start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.7">where <math alttext="j_{x_{i}}\in[n_{\text{bins}}]" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m1.1"><semantics id="S3.SS1.p1.4.m1.1a"><mrow id="S3.SS1.p1.4.m1.1.1" xref="S3.SS1.p1.4.m1.1.1.cmml"><msub id="S3.SS1.p1.4.m1.1.1.3" xref="S3.SS1.p1.4.m1.1.1.3.cmml"><mi id="S3.SS1.p1.4.m1.1.1.3.2" xref="S3.SS1.p1.4.m1.1.1.3.2.cmml">j</mi><msub id="S3.SS1.p1.4.m1.1.1.3.3" xref="S3.SS1.p1.4.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.4.m1.1.1.3.3.2" xref="S3.SS1.p1.4.m1.1.1.3.3.2.cmml">x</mi><mi id="S3.SS1.p1.4.m1.1.1.3.3.3" xref="S3.SS1.p1.4.m1.1.1.3.3.3.cmml">i</mi></msub></msub><mo id="S3.SS1.p1.4.m1.1.1.2" xref="S3.SS1.p1.4.m1.1.1.2.cmml">∈</mo><mrow id="S3.SS1.p1.4.m1.1.1.1.1" xref="S3.SS1.p1.4.m1.1.1.1.2.cmml"><mo id="S3.SS1.p1.4.m1.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.4.m1.1.1.1.2.1.cmml">[</mo><msub id="S3.SS1.p1.4.m1.1.1.1.1.1" xref="S3.SS1.p1.4.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.4.m1.1.1.1.1.1.2" xref="S3.SS1.p1.4.m1.1.1.1.1.1.2.cmml">n</mi><mtext id="S3.SS1.p1.4.m1.1.1.1.1.1.3" xref="S3.SS1.p1.4.m1.1.1.1.1.1.3a.cmml">bins</mtext></msub><mo id="S3.SS1.p1.4.m1.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.4.m1.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m1.1b"><apply id="S3.SS1.p1.4.m1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1"><in id="S3.SS1.p1.4.m1.1.1.2.cmml" xref="S3.SS1.p1.4.m1.1.1.2"></in><apply id="S3.SS1.p1.4.m1.1.1.3.cmml" xref="S3.SS1.p1.4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m1.1.1.3.1.cmml" xref="S3.SS1.p1.4.m1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.4.m1.1.1.3.2.cmml" xref="S3.SS1.p1.4.m1.1.1.3.2">𝑗</ci><apply id="S3.SS1.p1.4.m1.1.1.3.3.cmml" xref="S3.SS1.p1.4.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.4.m1.1.1.3.3">subscript</csymbol><ci id="S3.SS1.p1.4.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.4.m1.1.1.3.3.2">𝑥</ci><ci id="S3.SS1.p1.4.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.4.m1.1.1.3.3.3">𝑖</ci></apply></apply><apply id="S3.SS1.p1.4.m1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.4.m1.1.1.1.2.1.cmml" xref="S3.SS1.p1.4.m1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS1.p1.4.m1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m1.1.1.1.1.1.2">𝑛</ci><ci id="S3.SS1.p1.4.m1.1.1.1.1.1.3a.cmml" xref="S3.SS1.p1.4.m1.1.1.1.1.1.3"><mtext id="S3.SS1.p1.4.m1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p1.4.m1.1.1.1.1.1.3">bins</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m1.1c">j_{x_{i}}\in[n_{\text{bins}}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m1.1d">italic_j start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ∈ [ italic_n start_POSTSUBSCRIPT bins end_POSTSUBSCRIPT ]</annotation></semantics></math> denotes the bin index corresponding to the <math alttext="i-" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m2.1"><semantics id="S3.SS1.p1.5.m2.1a"><mrow id="S3.SS1.p1.5.m2.1.1" xref="S3.SS1.p1.5.m2.1.1.cmml"><mi id="S3.SS1.p1.5.m2.1.1.2" xref="S3.SS1.p1.5.m2.1.1.2.cmml">i</mi><mo id="S3.SS1.p1.5.m2.1.1.3" xref="S3.SS1.p1.5.m2.1.1.3.cmml">−</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m2.1b"><apply id="S3.SS1.p1.5.m2.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1"><csymbol cd="latexml" id="S3.SS1.p1.5.m2.1.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1">limit-from</csymbol><ci id="S3.SS1.p1.5.m2.1.1.2.cmml" xref="S3.SS1.p1.5.m2.1.1.2">𝑖</ci><minus id="S3.SS1.p1.5.m2.1.1.3.cmml" xref="S3.SS1.p1.5.m2.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m2.1c">i-</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m2.1d">italic_i -</annotation></semantics></math>th feature of <math alttext="x_{\text{test}}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m3.1"><semantics id="S3.SS1.p1.6.m3.1a"><msub id="S3.SS1.p1.6.m3.1.1" xref="S3.SS1.p1.6.m3.1.1.cmml"><mi id="S3.SS1.p1.6.m3.1.1.2" xref="S3.SS1.p1.6.m3.1.1.2.cmml">x</mi><mtext id="S3.SS1.p1.6.m3.1.1.3" xref="S3.SS1.p1.6.m3.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m3.1b"><apply id="S3.SS1.p1.6.m3.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m3.1.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m3.1.1.2.cmml" xref="S3.SS1.p1.6.m3.1.1.2">𝑥</ci><ci id="S3.SS1.p1.6.m3.1.1.3a.cmml" xref="S3.SS1.p1.6.m3.1.1.3"><mtext id="S3.SS1.p1.6.m3.1.1.3.cmml" mathsize="70%" xref="S3.SS1.p1.6.m3.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m3.1c">x_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m3.1d">italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math>. We now give more details on the binning and the architecture used for <math alttext="\mathcal{T}_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m4.1"><semantics id="S3.SS1.p1.7.m4.1a"><msub id="S3.SS1.p1.7.m4.1.1" xref="S3.SS1.p1.7.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.7.m4.1.1.2" xref="S3.SS1.p1.7.m4.1.1.2.cmml">𝒯</mi><mi id="S3.SS1.p1.7.m4.1.1.3" xref="S3.SS1.p1.7.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m4.1b"><apply id="S3.SS1.p1.7.m4.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.1.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m4.1.1.2.cmml" xref="S3.SS1.p1.7.m4.1.1.2">𝒯</ci><ci id="S3.SS1.p1.7.m4.1.1.3.cmml" xref="S3.SS1.p1.7.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m4.1c">\mathcal{T}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m4.1d">caligraphic_T start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.E4" title="Equation 4 ‣ 3.1 Shape Estimation and Predictions ‣ 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">4</span></a> before discussing the pre-training.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Architecture</h3>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Feature Preprocessing.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">Prior to being passed through the transformer, all features of each data point are binned, one-hot encoded, and finally embedded using an MLP. We use <math alttext="n_{\text{bins}}=64" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><msub id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2.cmml">n</mi><mtext id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.3a.cmml">bins</mtext></msub><mo id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1"><eq id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.1"></eq><apply id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.2">𝑛</ci><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.3a.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.3"><mtext id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.3.cmml" mathsize="70%" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.2.3">bins</mtext></ci></apply><cn id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">n_{\text{bins}}=64</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.1.m1.1d">italic_n start_POSTSUBSCRIPT bins end_POSTSUBSCRIPT = 64</annotation></semantics></math> bins for each feature, allocating bins based on the quantiles of the feature in the training dataset. Similarly to TabPFN, we embed the label of each datapoint and add it to the embedding of each feature. Categorical features are equally distributed across the 64 bins according to their ratios.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Representation of the shape functions.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">To accurately represent the shape functions, we chose to predict a discrete representation for each feature by discretizing it into 64 bins. An alternative approach would have been to predict the weights of a Neural Additive Model (NAM), similar to the method employed by Mothernet <cite class="ltx_cite ltx_citemacro_citep">(Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib38" title="">2023b</a>)</cite>. However, we decided against this approach to more naturally represent sudden discontinuities in the shape functions<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We refer to our case study on MIMIC-II for an illustration of this effect.</span></span></span>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Transformer.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px3.p1.1">The preprocessed training datapoints are processed by a transformer architecture consisting of 12 layers, each with a dual-module design that sequentially applies self-attention—first over the features and then over the data points. This design, inspired by <cite class="ltx_cite ltx_citemacro_citep">(Lorch et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib41" title="">2022</a>)</cite>, ensures that our model is agnostic to the number of features and data points, and is equivariant with respect to the order of both. As a result, unlike TabPFN <cite class="ltx_cite ltx_citemacro_citep">(Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite>, our approach does not require padding to a fixed maximum number of features.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px3.p2.3">After the transformer layers, we compute the average embeddings for each class based on training labels enabling multi-class classification (limited to 10 classes in our experiments). This averaging yields one embedding per class per feature which we denote <math alttext="h\in\mathbb{R}^{p\times d\times m}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p2.1.m1.1"><semantics id="S3.SS2.SSS0.Px3.p2.1.m1.1a"><mrow id="S3.SS2.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2.cmml">h</mi><mo id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.2" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.2" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.2.cmml">p</mi><mo id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.3" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.3.cmml">d</mi><mo id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.4" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.4.cmml">m</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.1.m1.1b"><apply id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1"><in id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1"></in><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2">ℎ</ci><apply id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3"><times id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.2">𝑝</ci><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.3">𝑑</ci><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.4.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.3.3.4">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.1.m1.1c">h\in\mathbb{R}^{p\times d\times m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p2.1.m1.1d">italic_h ∈ blackboard_R start_POSTSUPERSCRIPT italic_p × italic_d × italic_m end_POSTSUPERSCRIPT</annotation></semantics></math> where <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p2.2.m2.1"><semantics id="S3.SS2.SSS0.Px3.p2.2.m2.1a"><mi id="S3.SS2.SSS0.Px3.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.2.m2.1b"><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.2.m2.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p2.2.m2.1d">italic_d</annotation></semantics></math> denotes the embedding dimension of the transformer<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>This embedding is equivariant with respect to input features but not invariant to class ordering due to distinct class encodings in the input layer.</span></span></span>. Each embedding is then passed through a shared decoder MLP to produce the binned shape functions <math alttext="\tilde{f}\in\mathbb{R}^{p\times n_{\text{bins}}\times m}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px3.p2.3.m3.1"><semantics id="S3.SS2.SSS0.Px3.p2.3.m3.1a"><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml"><mover accent="true" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.2.cmml">f</mi><mo id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.2.cmml">p</mi><mo id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.1.cmml">×</mo><msub id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.2.cmml">n</mi><mtext id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.3a.cmml">bins</mtext></msub><mo id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.1a" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.4" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.4.cmml">m</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.3.m3.1b"><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1"><in id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1"></in><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2"><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.1">~</ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.2">𝑓</ci></apply><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3"><times id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.1"></times><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.2">𝑝</ci><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.2">𝑛</ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.3a.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.3"><mtext id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.3.cmml" mathsize="50%" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.3.3">bins</mtext></ci></apply><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.4.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.3.3.4">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.3.m3.1c">\tilde{f}\in\mathbb{R}^{p\times n_{\text{bins}}\times m}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px3.p2.3.m3.1d">over~ start_ARG italic_f end_ARG ∈ blackboard_R start_POSTSUPERSCRIPT italic_p × italic_n start_POSTSUBSCRIPT bins end_POSTSUBSCRIPT × italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>. This architecture is parameter-efficient as it allows sharing of parameters across features and classes. The model comprises 40k parameters in the encoder layer, 50.5M parameters in the transformer layers, and 0.3M parameters in the decoder, resulting in a total of 50.8M parameters. Note that while the shape function estimation scales quadratically in the number of features and datapoints, the inference only scales linearly in both.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Training Procedure</h3>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">We train with SGD on synthetic data priors, a method introduced in Prior-Data Fitted Networks (PFNs) <cite class="ltx_cite ltx_citemacro_citep">(Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib18" title="">2022</a>; Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite>. These priors are designed to be diverse, facilitating the generation of realistic tabular datasets and enabling extrapolation to real-world data. We utilize two types of priors for training: (1) Structural Causal Models, which involve sampling random causal graphs and generating data from them, and (2) Gaussian Processes, where random Gaussian Processes are sampled and used to generate data. For more details on the synthetic data generation process, we refer to <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A4" title="Appendix D Synthetic Data Priors ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">D</span></a>. During training, the synthetic data is randomly split into train and test datasets. To obtain the parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_θ</annotation></semantics></math> of Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.E4" title="Equation 4 ‣ 3.1 Shape Estimation and Predictions ‣ 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">4</span></a> we minimize a cross-entropy loss between the estimated GAM prediction and ground truth labels on the test dataset <math alttext="D_{\text{test}}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">D</mi><mtext id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3a.cmml">test</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝐷</ci><ci id="S3.SS3.p1.2.m2.1.1.3a.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><mtext id="S3.SS3.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS3.p1.2.m2.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">D_{\text{test}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT test end_POSTSUBSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\theta^{*}\in\text{argmin}_{\theta}\mathbb{E}_{(D_{\text{train}}\cup(x_{\text{%
test}},y_{\text{test}}))\sim p(D)}\left[\mathcal{L}(\tilde{y}_{\text{test}},y_%
{\text{test}})\right]" class="ltx_Math" display="block" id="S3.E6.m1.3"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3" xref="S3.E6.m1.3.3.cmml"><msup id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml"><mi id="S3.E6.m1.3.3.3.2" xref="S3.E6.m1.3.3.3.2.cmml">θ</mi><mo id="S3.E6.m1.3.3.3.3" xref="S3.E6.m1.3.3.3.3.cmml">∗</mo></msup><mo id="S3.E6.m1.3.3.2" xref="S3.E6.m1.3.3.2.cmml">∈</mo><mrow id="S3.E6.m1.3.3.1" xref="S3.E6.m1.3.3.1.cmml"><msub id="S3.E6.m1.3.3.1.3" xref="S3.E6.m1.3.3.1.3.cmml"><mtext id="S3.E6.m1.3.3.1.3.2" xref="S3.E6.m1.3.3.1.3.2a.cmml">argmin</mtext><mi id="S3.E6.m1.3.3.1.3.3" xref="S3.E6.m1.3.3.1.3.3.cmml">θ</mi></msub><mo id="S3.E6.m1.3.3.1.2" xref="S3.E6.m1.3.3.1.2.cmml">⁢</mo><msub id="S3.E6.m1.3.3.1.4" xref="S3.E6.m1.3.3.1.4.cmml"><mi id="S3.E6.m1.3.3.1.4.2" xref="S3.E6.m1.3.3.1.4.2.cmml">𝔼</mi><mrow id="S3.E6.m1.2.2.2" xref="S3.E6.m1.2.2.2.cmml"><mrow id="S3.E6.m1.2.2.2.2.1" xref="S3.E6.m1.2.2.2.2.1.1.cmml"><mo id="S3.E6.m1.2.2.2.2.1.2" stretchy="false" xref="S3.E6.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S3.E6.m1.2.2.2.2.1.1" xref="S3.E6.m1.2.2.2.2.1.1.cmml"><msub id="S3.E6.m1.2.2.2.2.1.1.4" xref="S3.E6.m1.2.2.2.2.1.1.4.cmml"><mi id="S3.E6.m1.2.2.2.2.1.1.4.2" xref="S3.E6.m1.2.2.2.2.1.1.4.2.cmml">D</mi><mtext id="S3.E6.m1.2.2.2.2.1.1.4.3" xref="S3.E6.m1.2.2.2.2.1.1.4.3a.cmml">train</mtext></msub><mo id="S3.E6.m1.2.2.2.2.1.1.3" xref="S3.E6.m1.2.2.2.2.1.1.3.cmml">∪</mo><mrow id="S3.E6.m1.2.2.2.2.1.1.2.2" xref="S3.E6.m1.2.2.2.2.1.1.2.3.cmml"><mo id="S3.E6.m1.2.2.2.2.1.1.2.2.3" stretchy="false" xref="S3.E6.m1.2.2.2.2.1.1.2.3.cmml">(</mo><msub id="S3.E6.m1.2.2.2.2.1.1.1.1.1" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.cmml"><mi id="S3.E6.m1.2.2.2.2.1.1.1.1.1.2" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.2.cmml">x</mi><mtext id="S3.E6.m1.2.2.2.2.1.1.1.1.1.3" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S3.E6.m1.2.2.2.2.1.1.2.2.4" xref="S3.E6.m1.2.2.2.2.1.1.2.3.cmml">,</mo><msub id="S3.E6.m1.2.2.2.2.1.1.2.2.2" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2.cmml"><mi id="S3.E6.m1.2.2.2.2.1.1.2.2.2.2" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2.2.cmml">y</mi><mtext id="S3.E6.m1.2.2.2.2.1.1.2.2.2.3" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2.3a.cmml">test</mtext></msub><mo id="S3.E6.m1.2.2.2.2.1.1.2.2.5" stretchy="false" xref="S3.E6.m1.2.2.2.2.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.2.2.2.2.1.3" stretchy="false" xref="S3.E6.m1.2.2.2.2.1.1.cmml">)</mo></mrow><mo id="S3.E6.m1.2.2.2.3" xref="S3.E6.m1.2.2.2.3.cmml">∼</mo><mrow id="S3.E6.m1.2.2.2.4" xref="S3.E6.m1.2.2.2.4.cmml"><mi id="S3.E6.m1.2.2.2.4.2" xref="S3.E6.m1.2.2.2.4.2.cmml">p</mi><mo id="S3.E6.m1.2.2.2.4.1" xref="S3.E6.m1.2.2.2.4.1.cmml">⁢</mo><mrow id="S3.E6.m1.2.2.2.4.3.2" xref="S3.E6.m1.2.2.2.4.cmml"><mo id="S3.E6.m1.2.2.2.4.3.2.1" stretchy="false" xref="S3.E6.m1.2.2.2.4.cmml">(</mo><mi id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml">D</mi><mo id="S3.E6.m1.2.2.2.4.3.2.2" stretchy="false" xref="S3.E6.m1.2.2.2.4.cmml">)</mo></mrow></mrow></mrow></msub><mo id="S3.E6.m1.3.3.1.2a" xref="S3.E6.m1.3.3.1.2.cmml">⁢</mo><mrow id="S3.E6.m1.3.3.1.1.1" xref="S3.E6.m1.3.3.1.1.2.cmml"><mo id="S3.E6.m1.3.3.1.1.1.2" xref="S3.E6.m1.3.3.1.1.2.1.cmml">[</mo><mrow id="S3.E6.m1.3.3.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.3.3.1.1.1.1.4" xref="S3.E6.m1.3.3.1.1.1.1.4.cmml">ℒ</mi><mo id="S3.E6.m1.3.3.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.3.cmml">⁢</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.2.2" xref="S3.E6.m1.3.3.1.1.1.1.2.3.cmml"><mo id="S3.E6.m1.3.3.1.1.1.1.2.2.3" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.2.3.cmml">(</mo><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.2.cmml">y</mi><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mtext id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3a.cmml">test</mtext></msub><mo id="S3.E6.m1.3.3.1.1.1.1.2.2.4" xref="S3.E6.m1.3.3.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E6.m1.3.3.1.1.1.1.2.2.2" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.2.2.2.2" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2.2.cmml">y</mi><mtext id="S3.E6.m1.3.3.1.1.1.1.2.2.2.3" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2.3a.cmml">test</mtext></msub><mo id="S3.E6.m1.3.3.1.1.1.1.2.2.5" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.1.1.1.3" xref="S3.E6.m1.3.3.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.cmml" xref="S3.E6.m1.3.3"><in id="S3.E6.m1.3.3.2.cmml" xref="S3.E6.m1.3.3.2"></in><apply id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.1.cmml" xref="S3.E6.m1.3.3.3">superscript</csymbol><ci id="S3.E6.m1.3.3.3.2.cmml" xref="S3.E6.m1.3.3.3.2">𝜃</ci><times id="S3.E6.m1.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3"></times></apply><apply id="S3.E6.m1.3.3.1.cmml" xref="S3.E6.m1.3.3.1"><times id="S3.E6.m1.3.3.1.2.cmml" xref="S3.E6.m1.3.3.1.2"></times><apply id="S3.E6.m1.3.3.1.3.cmml" xref="S3.E6.m1.3.3.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.3.1.cmml" xref="S3.E6.m1.3.3.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.3.2a.cmml" xref="S3.E6.m1.3.3.1.3.2"><mtext id="S3.E6.m1.3.3.1.3.2.cmml" xref="S3.E6.m1.3.3.1.3.2">argmin</mtext></ci><ci id="S3.E6.m1.3.3.1.3.3.cmml" xref="S3.E6.m1.3.3.1.3.3">𝜃</ci></apply><apply id="S3.E6.m1.3.3.1.4.cmml" xref="S3.E6.m1.3.3.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.4.1.cmml" xref="S3.E6.m1.3.3.1.4">subscript</csymbol><ci id="S3.E6.m1.3.3.1.4.2.cmml" xref="S3.E6.m1.3.3.1.4.2">𝔼</ci><apply id="S3.E6.m1.2.2.2.cmml" xref="S3.E6.m1.2.2.2"><csymbol cd="latexml" id="S3.E6.m1.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.3">similar-to</csymbol><apply id="S3.E6.m1.2.2.2.2.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1"><union id="S3.E6.m1.2.2.2.2.1.1.3.cmml" xref="S3.E6.m1.2.2.2.2.1.1.3"></union><apply id="S3.E6.m1.2.2.2.2.1.1.4.cmml" xref="S3.E6.m1.2.2.2.2.1.1.4"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.1.4.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.4">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.1.1.4.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.4.2">𝐷</ci><ci id="S3.E6.m1.2.2.2.2.1.1.4.3a.cmml" xref="S3.E6.m1.2.2.2.2.1.1.4.3"><mtext id="S3.E6.m1.2.2.2.2.1.1.4.3.cmml" mathsize="50%" xref="S3.E6.m1.2.2.2.2.1.1.4.3">train</mtext></ci></apply><interval closure="open" id="S3.E6.m1.2.2.2.2.1.1.2.3.cmml" xref="S3.E6.m1.2.2.2.2.1.1.2.2"><apply id="S3.E6.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.2">𝑥</ci><ci id="S3.E6.m1.2.2.2.2.1.1.1.1.1.3a.cmml" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.3"><mtext id="S3.E6.m1.2.2.2.2.1.1.1.1.1.3.cmml" mathsize="50%" xref="S3.E6.m1.2.2.2.2.1.1.1.1.1.3">test</mtext></ci></apply><apply id="S3.E6.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.1.1.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.1.1.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2.2">𝑦</ci><ci id="S3.E6.m1.2.2.2.2.1.1.2.2.2.3a.cmml" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2.3"><mtext id="S3.E6.m1.2.2.2.2.1.1.2.2.2.3.cmml" mathsize="50%" xref="S3.E6.m1.2.2.2.2.1.1.2.2.2.3">test</mtext></ci></apply></interval></apply><apply id="S3.E6.m1.2.2.2.4.cmml" xref="S3.E6.m1.2.2.2.4"><times id="S3.E6.m1.2.2.2.4.1.cmml" xref="S3.E6.m1.2.2.2.4.1"></times><ci id="S3.E6.m1.2.2.2.4.2.cmml" xref="S3.E6.m1.2.2.2.4.2">𝑝</ci><ci id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1">𝐷</ci></apply></apply></apply><apply id="S3.E6.m1.3.3.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.3.3.1.1.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.2">delimited-[]</csymbol><apply id="S3.E6.m1.3.3.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1"><times id="S3.E6.m1.3.3.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.3"></times><ci id="S3.E6.m1.3.3.1.1.1.1.4.cmml" xref="S3.E6.m1.3.3.1.1.1.1.4">ℒ</ci><interval closure="open" id="S3.E6.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.2"><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2"><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.2">𝑦</ci></apply><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3a.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3"><mtext id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3">test</mtext></ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.2.2.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.2.2.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2.2">𝑦</ci><ci id="S3.E6.m1.3.3.1.1.1.1.2.2.2.3a.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2.3"><mtext id="S3.E6.m1.3.3.1.1.1.1.2.2.2.3.cmml" mathsize="70%" xref="S3.E6.m1.3.3.1.1.1.1.2.2.2.3">test</mtext></ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\theta^{*}\in\text{argmin}_{\theta}\mathbb{E}_{(D_{\text{train}}\cup(x_{\text{%
test}},y_{\text{test}}))\sim p(D)}\left[\mathcal{L}(\tilde{y}_{\text{test}},y_%
{\text{test}})\right]</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.3d">italic_θ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT ∈ argmin start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT ( italic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ∪ ( italic_x start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT ) ) ∼ italic_p ( italic_D ) end_POSTSUBSCRIPT [ caligraphic_L ( over~ start_ARG italic_y end_ARG start_POSTSUBSCRIPT test end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT test end_POSTSUBSCRIPT ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p1.3">Additional details on the training are given in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A5" title="Appendix E Training Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">GAMformer’s core contribution is the substitution of the data fitting process of traditional GAM variants with a single forward pass of a pre-trained transformer model, which is presented with data through in-context examples. Consequently, GAMformer replaces the manually crafted fitting procedures used in methods like EBMs <cite class="ltx_cite ltx_citemacro_citep">(Caruana et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib4" title="">2015</a>)</cite>, where the boosting procedure is restricted to one feature at a time in a round-robin manner, or the joint optimization of all shape functions in NAMs <cite class="ltx_cite ltx_citemacro_citep">(Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib11" title="">2021</a>)</cite> using SGD. Note that in both traditional GAM fitting and GAMformer, the output of the processes remains the same; a main effects GAM fitted to a given dataset represented by its shape functions.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Higher-order effects</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.4">We now describe how GAMformer can be extended to handle higher-orders effects. We extend GAMformer to model higher-order effects, specifically pairwise interactions, by incorporating feature products, resulting in up to <math alttext="\mathcal{O}(p^{2})" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">𝒪</mi><mo id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS4.p1.1.m1.1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS4.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S3.SS4.p1.1.m1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS4.p1.1.m1.1.1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.1.1.1.2.cmml">p</mi><mn id="S3.SS4.p1.1.m1.1.1.1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.SS4.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S3.SS4.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><times id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2"></times><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">𝒪</ci><apply id="S3.SS4.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.1.1.1.2">𝑝</ci><cn id="S3.SS4.p1.1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS4.p1.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">\mathcal{O}(p^{2})</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">caligraphic_O ( italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math> potential features. GAMformer can accommodate this by performing ICL on concatenated original data and higher-order effects, represented as feature vectors in <math alttext="\mathbb{R}^{p+P}" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m2.1"><semantics id="S3.SS4.p1.2.m2.1a"><msup id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">ℝ</mi><mrow id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.p1.2.m2.1.1.3.2" xref="S3.SS4.p1.2.m2.1.1.3.2.cmml">p</mi><mo id="S3.SS4.p1.2.m2.1.1.3.1" xref="S3.SS4.p1.2.m2.1.1.3.1.cmml">+</mo><mi id="S3.SS4.p1.2.m2.1.1.3.3" xref="S3.SS4.p1.2.m2.1.1.3.3.cmml">P</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">ℝ</ci><apply id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3"><plus id="S3.SS4.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.p1.2.m2.1.1.3.1"></plus><ci id="S3.SS4.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.p1.2.m2.1.1.3.2">𝑝</ci><ci id="S3.SS4.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">\mathbb{R}^{p+P}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m2.1d">blackboard_R start_POSTSUPERSCRIPT italic_p + italic_P end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="P" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m3.1"><semantics id="S3.SS4.p1.3.m3.1a"><mi id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><ci id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m3.1d">italic_P</annotation></semantics></math> denotes the number of pair interactions. However, increasing feature dimensions beyond the <math alttext="10" class="ltx_Math" display="inline" id="S3.SS4.p1.4.m4.1"><semantics id="S3.SS4.p1.4.m4.1a"><mn id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><cn id="S3.SS4.p1.4.m4.1.1.cmml" type="integer" xref="S3.SS4.p1.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.4.m4.1d">10</annotation></semantics></math> used in pretraining is problematic and adds complexity to shape function estimation. To mitigate this, we rank the most informative pairs via the FAST method <cite class="ltx_cite ltx_citemacro_citep">(Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>)</cite> and the optimal number of pairs is determined as a hyperparameter through cross-validation during inference.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">After pretraining GAMformer on the synthetic datasets, we evaluate it on both illustrative and real-world tasks in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.SS1" title="4.1 Illustrative Examples ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">4.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.SS2" title="4.2 Multi-class Classification on OpenML Tabular Datasets ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">4.2</span></a>, respectively. Moreover, in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.SS3" title="4.3 Case Study: Intensive Care Unit Mortality Risk ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we highlight its potential to assist in decision-making in a clinical setting by predicting the mortality rate of patients in the intensive care unit (ICU). We compare to Explainable Boosting Machines (EBMs) <cite class="ltx_cite ltx_citemacro_citep">(Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib9" title="">2012</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>; Caruana et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib4" title="">2015</a>)</cite> in terms of estimated shape function quality, as well as to other state-of-the-art tabular classification models such as XGBoost <cite class="ltx_cite ltx_citemacro_citep">(Chen and Guestrin, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib42" title="">2016</a>)</cite> and TabPFN <cite class="ltx_cite ltx_citemacro_citep">(Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite> in terms of predictive performance. On the downstream datasets, differently from EBM and the other baselines, GAMformer requires <em class="ltx_emph ltx_font_italic" id="S4.p1.1.1">only a single forward pass</em> of the transformer model to estimate the shape functions and construct prediction on the entire test set, without any parameter updates.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Illustrative Examples</h3>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.F2.3" style="width:397.5pt;height:138.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(34.5pt,-12.0pt) scale(1.21025596424311,1.21025596424311) ;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="103" id="S4.F2.1.g1" src="x2.png" width="135"/><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="103" id="S4.F2.2.g2" src="x3.png" width="111"/><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="104" id="S4.F2.3.g3" src="x4.png" width="187"/>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Shape functions derived from GAMformer and EBMs applied to the linear, binary classification problem <math alttext="f(x_{1},x_{2},x_{3})=\mathbb{I}((-1)x_{1}+0x_{2}+x_{3}&gt;0)" class="ltx_Math" display="inline" id="S4.F2.5.m1.4"><semantics id="S4.F2.5.m1.4b"><mrow id="S4.F2.5.m1.4.4" xref="S4.F2.5.m1.4.4.cmml"><mrow id="S4.F2.5.m1.3.3.3" xref="S4.F2.5.m1.3.3.3.cmml"><mi id="S4.F2.5.m1.3.3.3.5" xref="S4.F2.5.m1.3.3.3.5.cmml">f</mi><mo id="S4.F2.5.m1.3.3.3.4" xref="S4.F2.5.m1.3.3.3.4.cmml">⁢</mo><mrow id="S4.F2.5.m1.3.3.3.3.3" xref="S4.F2.5.m1.3.3.3.3.4.cmml"><mo id="S4.F2.5.m1.3.3.3.3.3.4" stretchy="false" xref="S4.F2.5.m1.3.3.3.3.4.cmml">(</mo><msub id="S4.F2.5.m1.1.1.1.1.1.1" xref="S4.F2.5.m1.1.1.1.1.1.1.cmml"><mi id="S4.F2.5.m1.1.1.1.1.1.1.2" xref="S4.F2.5.m1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S4.F2.5.m1.1.1.1.1.1.1.3" xref="S4.F2.5.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.F2.5.m1.3.3.3.3.3.5" xref="S4.F2.5.m1.3.3.3.3.4.cmml">,</mo><msub id="S4.F2.5.m1.2.2.2.2.2.2" xref="S4.F2.5.m1.2.2.2.2.2.2.cmml"><mi id="S4.F2.5.m1.2.2.2.2.2.2.2" xref="S4.F2.5.m1.2.2.2.2.2.2.2.cmml">x</mi><mn id="S4.F2.5.m1.2.2.2.2.2.2.3" xref="S4.F2.5.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.F2.5.m1.3.3.3.3.3.6" xref="S4.F2.5.m1.3.3.3.3.4.cmml">,</mo><msub id="S4.F2.5.m1.3.3.3.3.3.3" xref="S4.F2.5.m1.3.3.3.3.3.3.cmml"><mi id="S4.F2.5.m1.3.3.3.3.3.3.2" xref="S4.F2.5.m1.3.3.3.3.3.3.2.cmml">x</mi><mn id="S4.F2.5.m1.3.3.3.3.3.3.3" xref="S4.F2.5.m1.3.3.3.3.3.3.3.cmml">3</mn></msub><mo id="S4.F2.5.m1.3.3.3.3.3.7" stretchy="false" xref="S4.F2.5.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S4.F2.5.m1.4.4.5" xref="S4.F2.5.m1.4.4.5.cmml">=</mo><mrow id="S4.F2.5.m1.4.4.4" xref="S4.F2.5.m1.4.4.4.cmml"><mi id="S4.F2.5.m1.4.4.4.3" xref="S4.F2.5.m1.4.4.4.3.cmml">𝕀</mi><mo id="S4.F2.5.m1.4.4.4.2" xref="S4.F2.5.m1.4.4.4.2.cmml">⁢</mo><mrow id="S4.F2.5.m1.4.4.4.1.1" xref="S4.F2.5.m1.4.4.4.1.1.1.cmml"><mo id="S4.F2.5.m1.4.4.4.1.1.2" stretchy="false" xref="S4.F2.5.m1.4.4.4.1.1.1.cmml">(</mo><mrow id="S4.F2.5.m1.4.4.4.1.1.1" xref="S4.F2.5.m1.4.4.4.1.1.1.cmml"><mrow id="S4.F2.5.m1.4.4.4.1.1.1.1" xref="S4.F2.5.m1.4.4.4.1.1.1.1.cmml"><mrow id="S4.F2.5.m1.4.4.4.1.1.1.1.1" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.cmml"><mrow id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1b" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.2.cmml">1</mn></mrow><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.1.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.2.cmml">⁢</mo><msub id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.cmml"><mi id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.2.cmml">x</mi><mn id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.3" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.2.cmml">+</mo><mrow id="S4.F2.5.m1.4.4.4.1.1.1.1.3" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.cmml"><mn id="S4.F2.5.m1.4.4.4.1.1.1.1.3.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.2.cmml">0</mn><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.3.1" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.1.cmml">⁢</mo><msub id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.cmml"><mi id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.2.cmml">x</mi><mn id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.3" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.3.cmml">2</mn></msub></mrow><mo id="S4.F2.5.m1.4.4.4.1.1.1.1.2b" xref="S4.F2.5.m1.4.4.4.1.1.1.1.2.cmml">+</mo><msub id="S4.F2.5.m1.4.4.4.1.1.1.1.4" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4.cmml"><mi id="S4.F2.5.m1.4.4.4.1.1.1.1.4.2" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4.2.cmml">x</mi><mn id="S4.F2.5.m1.4.4.4.1.1.1.1.4.3" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4.3.cmml">3</mn></msub></mrow><mo id="S4.F2.5.m1.4.4.4.1.1.1.2" xref="S4.F2.5.m1.4.4.4.1.1.1.2.cmml">&gt;</mo><mn id="S4.F2.5.m1.4.4.4.1.1.1.3" xref="S4.F2.5.m1.4.4.4.1.1.1.3.cmml">0</mn></mrow><mo id="S4.F2.5.m1.4.4.4.1.1.3" stretchy="false" xref="S4.F2.5.m1.4.4.4.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.5.m1.4c"><apply id="S4.F2.5.m1.4.4.cmml" xref="S4.F2.5.m1.4.4"><eq id="S4.F2.5.m1.4.4.5.cmml" xref="S4.F2.5.m1.4.4.5"></eq><apply id="S4.F2.5.m1.3.3.3.cmml" xref="S4.F2.5.m1.3.3.3"><times id="S4.F2.5.m1.3.3.3.4.cmml" xref="S4.F2.5.m1.3.3.3.4"></times><ci id="S4.F2.5.m1.3.3.3.5.cmml" xref="S4.F2.5.m1.3.3.3.5">𝑓</ci><vector id="S4.F2.5.m1.3.3.3.3.4.cmml" xref="S4.F2.5.m1.3.3.3.3.3"><apply id="S4.F2.5.m1.1.1.1.1.1.1.cmml" xref="S4.F2.5.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F2.5.m1.1.1.1.1.1.1.1.cmml" xref="S4.F2.5.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.F2.5.m1.1.1.1.1.1.1.2.cmml" xref="S4.F2.5.m1.1.1.1.1.1.1.2">𝑥</ci><cn id="S4.F2.5.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.F2.5.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.F2.5.m1.2.2.2.2.2.2.cmml" xref="S4.F2.5.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.F2.5.m1.2.2.2.2.2.2.1.cmml" xref="S4.F2.5.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.F2.5.m1.2.2.2.2.2.2.2.cmml" xref="S4.F2.5.m1.2.2.2.2.2.2.2">𝑥</ci><cn id="S4.F2.5.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S4.F2.5.m1.2.2.2.2.2.2.3">2</cn></apply><apply id="S4.F2.5.m1.3.3.3.3.3.3.cmml" xref="S4.F2.5.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.F2.5.m1.3.3.3.3.3.3.1.cmml" xref="S4.F2.5.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S4.F2.5.m1.3.3.3.3.3.3.2.cmml" xref="S4.F2.5.m1.3.3.3.3.3.3.2">𝑥</ci><cn id="S4.F2.5.m1.3.3.3.3.3.3.3.cmml" type="integer" xref="S4.F2.5.m1.3.3.3.3.3.3.3">3</cn></apply></vector></apply><apply id="S4.F2.5.m1.4.4.4.cmml" xref="S4.F2.5.m1.4.4.4"><times id="S4.F2.5.m1.4.4.4.2.cmml" xref="S4.F2.5.m1.4.4.4.2"></times><ci id="S4.F2.5.m1.4.4.4.3.cmml" xref="S4.F2.5.m1.4.4.4.3">𝕀</ci><apply id="S4.F2.5.m1.4.4.4.1.1.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1"><gt id="S4.F2.5.m1.4.4.4.1.1.1.2.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.2"></gt><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1"><plus id="S4.F2.5.m1.4.4.4.1.1.1.1.2.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.2"></plus><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1"><times id="S4.F2.5.m1.4.4.4.1.1.1.1.1.2.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.2"></times><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1"><minus id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1"></minus><cn id="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.1.1.1.2">1</cn></apply><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3">subscript</csymbol><ci id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.2.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.2">𝑥</ci><cn id="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.F2.5.m1.4.4.4.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.3.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3"><times id="S4.F2.5.m1.4.4.4.1.1.1.1.3.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.1"></times><cn id="S4.F2.5.m1.4.4.4.1.1.1.1.3.2.cmml" type="integer" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.2">0</cn><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3">subscript</csymbol><ci id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.2.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.2">𝑥</ci><cn id="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.3.cmml" type="integer" xref="S4.F2.5.m1.4.4.4.1.1.1.1.3.3.3">2</cn></apply></apply><apply id="S4.F2.5.m1.4.4.4.1.1.1.1.4.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.F2.5.m1.4.4.4.1.1.1.1.4.1.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4">subscript</csymbol><ci id="S4.F2.5.m1.4.4.4.1.1.1.1.4.2.cmml" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4.2">𝑥</ci><cn id="S4.F2.5.m1.4.4.4.1.1.1.1.4.3.cmml" type="integer" xref="S4.F2.5.m1.4.4.4.1.1.1.1.4.3">3</cn></apply></apply><cn id="S4.F2.5.m1.4.4.4.1.1.1.3.cmml" type="integer" xref="S4.F2.5.m1.4.4.4.1.1.1.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.m1.4d">f(x_{1},x_{2},x_{3})=\mathbb{I}((-1)x_{1}+0x_{2}+x_{3}&gt;0)</annotation><annotation encoding="application/x-llamapun" id="S4.F2.5.m1.4e">italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = blackboard_I ( ( - 1 ) italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + 0 italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT &gt; 0 )</annotation></semantics></math>. We use a twin y axis with GAMformer and EBM on left and right, respectively. All models shown result from a 30-fold cross-validation over 1500 data points.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Before demonstrating GAMformer on real-world tabular data, we first investigate its behavior on synthetic data where the data-generation process is known. This allows us to validate the effectiveness of GAMformer in capturing the underlying relationships between features and the target variable. All considered examples are binary classification and hence we only show one shape function per class and per feature. In the context of GAMs with a logit link function (used for binary classification), log-odds is the unit of the predictors. Therefore, the shape functions’ output values are on the log-odds scale, which are then transformed to overall prediction probabilities after summing via the logistic function. For all metrics reported in the paper, we use ROC-AUC (Receiver Operating Characteristic - Area Under the Curve).</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="400" id="S4.F3.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Robustness analysis (linear, binary classification): GAMformer consistently outperforms or matches EBM across various sample sizes and feature counts, showcasing its efficiency</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.2.1">Linear, binary classification.</span> We begin by evaluating GAMformer and, for comparison, EBMs on data generated by the linear, binary classification problem <math alttext="f(x_{1},x_{2},x_{3})=\mathbb{I}((-1)x_{1}+0x_{2}+x_{3}&gt;0)" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.4"><semantics id="S4.SS1.p2.1.m1.4a"><mrow id="S4.SS1.p2.1.m1.4.4" xref="S4.SS1.p2.1.m1.4.4.cmml"><mrow id="S4.SS1.p2.1.m1.3.3.3" xref="S4.SS1.p2.1.m1.3.3.3.cmml"><mi id="S4.SS1.p2.1.m1.3.3.3.5" xref="S4.SS1.p2.1.m1.3.3.3.5.cmml">f</mi><mo id="S4.SS1.p2.1.m1.3.3.3.4" xref="S4.SS1.p2.1.m1.3.3.3.4.cmml">⁢</mo><mrow id="S4.SS1.p2.1.m1.3.3.3.3.3" xref="S4.SS1.p2.1.m1.3.3.3.3.4.cmml"><mo id="S4.SS1.p2.1.m1.3.3.3.3.3.4" stretchy="false" xref="S4.SS1.p2.1.m1.3.3.3.3.4.cmml">(</mo><msub id="S4.SS1.p2.1.m1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.1.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p2.1.m1.3.3.3.3.3.5" xref="S4.SS1.p2.1.m1.3.3.3.3.4.cmml">,</mo><msub id="S4.SS1.p2.1.m1.2.2.2.2.2.2" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2.cmml"><mi id="S4.SS1.p2.1.m1.2.2.2.2.2.2.2" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.2.2.2.2.2.2.3" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p2.1.m1.3.3.3.3.3.6" xref="S4.SS1.p2.1.m1.3.3.3.3.4.cmml">,</mo><msub id="S4.SS1.p2.1.m1.3.3.3.3.3.3" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3.cmml"><mi id="S4.SS1.p2.1.m1.3.3.3.3.3.3.2" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.3.3.3.3.3.3.3" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3.3.cmml">3</mn></msub><mo id="S4.SS1.p2.1.m1.3.3.3.3.3.7" stretchy="false" xref="S4.SS1.p2.1.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S4.SS1.p2.1.m1.4.4.5" xref="S4.SS1.p2.1.m1.4.4.5.cmml">=</mo><mrow id="S4.SS1.p2.1.m1.4.4.4" xref="S4.SS1.p2.1.m1.4.4.4.cmml"><mi id="S4.SS1.p2.1.m1.4.4.4.3" xref="S4.SS1.p2.1.m1.4.4.4.3.cmml">𝕀</mi><mo id="S4.SS1.p2.1.m1.4.4.4.2" xref="S4.SS1.p2.1.m1.4.4.4.2.cmml">⁢</mo><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.cmml"><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.2" stretchy="false" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.cmml"><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.cmml"><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1a" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">−</mo><mn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.2.cmml">1</mn></mrow><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.2.cmml">⁢</mo><msub id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.cmml"><mi id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.2.cmml">+</mo><mrow id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.cmml"><mn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.2.cmml">0</mn><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.1" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.1.cmml">⁢</mo><msub id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.cmml"><mi id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.3.cmml">2</mn></msub></mrow><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.2a" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.2.cmml">+</mo><msub id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.cmml"><mi id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.2.cmml">x</mi><mn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.3.cmml">3</mn></msub></mrow><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.1.2" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.2.cmml">&gt;</mo><mn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.3" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.3.cmml">0</mn></mrow><mo id="S4.SS1.p2.1.m1.4.4.4.1.1.3" stretchy="false" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.4b"><apply id="S4.SS1.p2.1.m1.4.4.cmml" xref="S4.SS1.p2.1.m1.4.4"><eq id="S4.SS1.p2.1.m1.4.4.5.cmml" xref="S4.SS1.p2.1.m1.4.4.5"></eq><apply id="S4.SS1.p2.1.m1.3.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3.3"><times id="S4.SS1.p2.1.m1.3.3.3.4.cmml" xref="S4.SS1.p2.1.m1.3.3.3.4"></times><ci id="S4.SS1.p2.1.m1.3.3.3.5.cmml" xref="S4.SS1.p2.1.m1.3.3.3.5">𝑓</ci><vector id="S4.SS1.p2.1.m1.3.3.3.3.4.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3.3"><apply id="S4.SS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.SS1.p2.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.2.2.2.2.2.2.1.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p2.1.m1.2.2.2.2.2.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.2.2.2.2.2.2.3">2</cn></apply><apply id="S4.SS1.p2.1.m1.3.3.3.3.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.3.3.3.3.3.3.1.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.3.3.3.3.3.3.2.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.3.3.3.3.3.3.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.3.3.3.3.3.3.3">3</cn></apply></vector></apply><apply id="S4.SS1.p2.1.m1.4.4.4.cmml" xref="S4.SS1.p2.1.m1.4.4.4"><times id="S4.SS1.p2.1.m1.4.4.4.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.2"></times><ci id="S4.SS1.p2.1.m1.4.4.4.3.cmml" xref="S4.SS1.p2.1.m1.4.4.4.3">𝕀</ci><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1"><gt id="S4.SS1.p2.1.m1.4.4.4.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.2"></gt><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1"><plus id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.2"></plus><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1"><times id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.2"></times><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1"><minus id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1"></minus><cn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.1.1.1.2">1</cn></apply><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3"><times id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.1"></times><cn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.2.cmml" type="integer" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.2">0</cn><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.3.3.3">2</cn></apply></apply><apply id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.1.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4">subscript</csymbol><ci id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.2.cmml" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.2">𝑥</ci><cn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.1.4.3">3</cn></apply></apply><cn id="S4.SS1.p2.1.m1.4.4.4.1.1.1.3.cmml" type="integer" xref="S4.SS1.p2.1.m1.4.4.4.1.1.1.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.4c">f(x_{1},x_{2},x_{3})=\mathbb{I}((-1)x_{1}+0x_{2}+x_{3}&gt;0)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.4d">italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = blackboard_I ( ( - 1 ) italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + 0 italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT &gt; 0 )</annotation></semantics></math>, where <math alttext="\mathbb{I}" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">𝕀</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">𝕀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">\mathbb{I}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">blackboard_I</annotation></semantics></math> is the indicator function. We sample 2000 data points uniformly and independently from the interval [-2, 2] and split the data into 1500 training points and 500 test points. The results, shown in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F2" title="In 4.1 Illustrative Examples ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>, demonstrate that both GAMformer and EBMs accurately estimate the slopes for each feature and achieve an ROC AUC of 1.0 on the test dataset. However, the shape functions learned by GAMformer are noticeably smoother, suggesting that it may have captured some bias towards smoother models during pretraining. Additionally, we compared the effect of varying the number of datapoints or features in this example on EBMs and GAMformer in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F3" title="In 4.1 Illustrative Examples ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a>. Our findings indicate that GAMformer consistently outperforms EBMs across various sample sizes and feature counts.</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S4.F4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.F4.2" style="width:431.9pt;height:168.7pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S4.F4.2.2"><span class="ltx_text" id="S4.F4.2.2.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="183" id="S4.F4.1.1.1.g1" src="x6.png" width="245"/> <img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="184" id="S4.F4.2.2.2.g2" src="x7.png" width="347"/></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>(a) Shape functions derived from GAMformer and EBMs applied to the polynomial, binary classification problem <math alttext="f(x_{1},x_{2})=\mathbb{I}(x_{1}+x_{2}^{2}&gt;0)" class="ltx_Math" display="inline" id="S4.F4.4.m1.3"><semantics id="S4.F4.4.m1.3b"><mrow id="S4.F4.4.m1.3.3" xref="S4.F4.4.m1.3.3.cmml"><mrow id="S4.F4.4.m1.2.2.2" xref="S4.F4.4.m1.2.2.2.cmml"><mi id="S4.F4.4.m1.2.2.2.4" xref="S4.F4.4.m1.2.2.2.4.cmml">f</mi><mo id="S4.F4.4.m1.2.2.2.3" xref="S4.F4.4.m1.2.2.2.3.cmml">⁢</mo><mrow id="S4.F4.4.m1.2.2.2.2.2" xref="S4.F4.4.m1.2.2.2.2.3.cmml"><mo id="S4.F4.4.m1.2.2.2.2.2.3" stretchy="false" xref="S4.F4.4.m1.2.2.2.2.3.cmml">(</mo><msub id="S4.F4.4.m1.1.1.1.1.1.1" xref="S4.F4.4.m1.1.1.1.1.1.1.cmml"><mi id="S4.F4.4.m1.1.1.1.1.1.1.2" xref="S4.F4.4.m1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S4.F4.4.m1.1.1.1.1.1.1.3" xref="S4.F4.4.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.F4.4.m1.2.2.2.2.2.4" xref="S4.F4.4.m1.2.2.2.2.3.cmml">,</mo><msub id="S4.F4.4.m1.2.2.2.2.2.2" xref="S4.F4.4.m1.2.2.2.2.2.2.cmml"><mi id="S4.F4.4.m1.2.2.2.2.2.2.2" xref="S4.F4.4.m1.2.2.2.2.2.2.2.cmml">x</mi><mn id="S4.F4.4.m1.2.2.2.2.2.2.3" xref="S4.F4.4.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.F4.4.m1.2.2.2.2.2.5" stretchy="false" xref="S4.F4.4.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.F4.4.m1.3.3.4" xref="S4.F4.4.m1.3.3.4.cmml">=</mo><mrow id="S4.F4.4.m1.3.3.3" xref="S4.F4.4.m1.3.3.3.cmml"><mi id="S4.F4.4.m1.3.3.3.3" xref="S4.F4.4.m1.3.3.3.3.cmml">𝕀</mi><mo id="S4.F4.4.m1.3.3.3.2" xref="S4.F4.4.m1.3.3.3.2.cmml">⁢</mo><mrow id="S4.F4.4.m1.3.3.3.1.1" xref="S4.F4.4.m1.3.3.3.1.1.1.cmml"><mo id="S4.F4.4.m1.3.3.3.1.1.2" stretchy="false" xref="S4.F4.4.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S4.F4.4.m1.3.3.3.1.1.1" xref="S4.F4.4.m1.3.3.3.1.1.1.cmml"><mrow id="S4.F4.4.m1.3.3.3.1.1.1.2" xref="S4.F4.4.m1.3.3.3.1.1.1.2.cmml"><msub id="S4.F4.4.m1.3.3.3.1.1.1.2.2" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2.cmml"><mi id="S4.F4.4.m1.3.3.3.1.1.1.2.2.2" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2.2.cmml">x</mi><mn id="S4.F4.4.m1.3.3.3.1.1.1.2.2.3" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S4.F4.4.m1.3.3.3.1.1.1.2.1" xref="S4.F4.4.m1.3.3.3.1.1.1.2.1.cmml">+</mo><msubsup id="S4.F4.4.m1.3.3.3.1.1.1.2.3" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.cmml"><mi id="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.2" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.2.cmml">x</mi><mn id="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.3" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.3.cmml">2</mn><mn id="S4.F4.4.m1.3.3.3.1.1.1.2.3.3" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.3.cmml">2</mn></msubsup></mrow><mo id="S4.F4.4.m1.3.3.3.1.1.1.1" xref="S4.F4.4.m1.3.3.3.1.1.1.1.cmml">&gt;</mo><mn id="S4.F4.4.m1.3.3.3.1.1.1.3" xref="S4.F4.4.m1.3.3.3.1.1.1.3.cmml">0</mn></mrow><mo id="S4.F4.4.m1.3.3.3.1.1.3" stretchy="false" xref="S4.F4.4.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.4.m1.3c"><apply id="S4.F4.4.m1.3.3.cmml" xref="S4.F4.4.m1.3.3"><eq id="S4.F4.4.m1.3.3.4.cmml" xref="S4.F4.4.m1.3.3.4"></eq><apply id="S4.F4.4.m1.2.2.2.cmml" xref="S4.F4.4.m1.2.2.2"><times id="S4.F4.4.m1.2.2.2.3.cmml" xref="S4.F4.4.m1.2.2.2.3"></times><ci id="S4.F4.4.m1.2.2.2.4.cmml" xref="S4.F4.4.m1.2.2.2.4">𝑓</ci><interval closure="open" id="S4.F4.4.m1.2.2.2.2.3.cmml" xref="S4.F4.4.m1.2.2.2.2.2"><apply id="S4.F4.4.m1.1.1.1.1.1.1.cmml" xref="S4.F4.4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.F4.4.m1.1.1.1.1.1.1.1.cmml" xref="S4.F4.4.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.F4.4.m1.1.1.1.1.1.1.2.cmml" xref="S4.F4.4.m1.1.1.1.1.1.1.2">𝑥</ci><cn id="S4.F4.4.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.F4.4.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.F4.4.m1.2.2.2.2.2.2.cmml" xref="S4.F4.4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.F4.4.m1.2.2.2.2.2.2.1.cmml" xref="S4.F4.4.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.F4.4.m1.2.2.2.2.2.2.2.cmml" xref="S4.F4.4.m1.2.2.2.2.2.2.2">𝑥</ci><cn id="S4.F4.4.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S4.F4.4.m1.2.2.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S4.F4.4.m1.3.3.3.cmml" xref="S4.F4.4.m1.3.3.3"><times id="S4.F4.4.m1.3.3.3.2.cmml" xref="S4.F4.4.m1.3.3.3.2"></times><ci id="S4.F4.4.m1.3.3.3.3.cmml" xref="S4.F4.4.m1.3.3.3.3">𝕀</ci><apply id="S4.F4.4.m1.3.3.3.1.1.1.cmml" xref="S4.F4.4.m1.3.3.3.1.1"><gt id="S4.F4.4.m1.3.3.3.1.1.1.1.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.1"></gt><apply id="S4.F4.4.m1.3.3.3.1.1.1.2.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2"><plus id="S4.F4.4.m1.3.3.3.1.1.1.2.1.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.1"></plus><apply id="S4.F4.4.m1.3.3.3.1.1.1.2.2.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.F4.4.m1.3.3.3.1.1.1.2.2.1.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2">subscript</csymbol><ci id="S4.F4.4.m1.3.3.3.1.1.1.2.2.2.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2.2">𝑥</ci><cn id="S4.F4.4.m1.3.3.3.1.1.1.2.2.3.cmml" type="integer" xref="S4.F4.4.m1.3.3.3.1.1.1.2.2.3">1</cn></apply><apply id="S4.F4.4.m1.3.3.3.1.1.1.2.3.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.F4.4.m1.3.3.3.1.1.1.2.3.1.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3">superscript</csymbol><apply id="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.1.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3">subscript</csymbol><ci id="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.2.cmml" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.2">𝑥</ci><cn id="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.3.cmml" type="integer" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.2.3">2</cn></apply><cn id="S4.F4.4.m1.3.3.3.1.1.1.2.3.3.cmml" type="integer" xref="S4.F4.4.m1.3.3.3.1.1.1.2.3.3">2</cn></apply></apply><cn id="S4.F4.4.m1.3.3.3.1.1.1.3.cmml" type="integer" xref="S4.F4.4.m1.3.3.3.1.1.1.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.m1.3d">f(x_{1},x_{2})=\mathbb{I}(x_{1}+x_{2}^{2}&gt;0)</annotation><annotation encoding="application/x-llamapun" id="S4.F4.4.m1.3e">italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = blackboard_I ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT &gt; 0 )</annotation></semantics></math>. All models result from a 30-fold cross-validation over 1500 data points are shown.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.6"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.6.1">Polynomial, binary classification.</span> To further validate the robustness of GAMformer, we evaluate it on data generated by a more complex function <math alttext="f(x_{1},x_{2})=\mathbb{I}(x_{1}+x_{2}^{2}&gt;0)" class="ltx_Math" display="inline" id="S4.SS1.p3.1.m1.3"><semantics id="S4.SS1.p3.1.m1.3a"><mrow id="S4.SS1.p3.1.m1.3.3" xref="S4.SS1.p3.1.m1.3.3.cmml"><mrow id="S4.SS1.p3.1.m1.2.2.2" xref="S4.SS1.p3.1.m1.2.2.2.cmml"><mi id="S4.SS1.p3.1.m1.2.2.2.4" xref="S4.SS1.p3.1.m1.2.2.2.4.cmml">f</mi><mo id="S4.SS1.p3.1.m1.2.2.2.3" xref="S4.SS1.p3.1.m1.2.2.2.3.cmml">⁢</mo><mrow id="S4.SS1.p3.1.m1.2.2.2.2.2" xref="S4.SS1.p3.1.m1.2.2.2.2.3.cmml"><mo id="S4.SS1.p3.1.m1.2.2.2.2.2.3" stretchy="false" xref="S4.SS1.p3.1.m1.2.2.2.2.3.cmml">(</mo><msub id="S4.SS1.p3.1.m1.1.1.1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.1.1.1.1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S4.SS1.p3.1.m1.1.1.1.1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.p3.1.m1.2.2.2.2.2.4" xref="S4.SS1.p3.1.m1.2.2.2.2.3.cmml">,</mo><msub id="S4.SS1.p3.1.m1.2.2.2.2.2.2" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2.cmml"><mi id="S4.SS1.p3.1.m1.2.2.2.2.2.2.2" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2.2.cmml">x</mi><mn id="S4.SS1.p3.1.m1.2.2.2.2.2.2.3" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.p3.1.m1.2.2.2.2.2.5" stretchy="false" xref="S4.SS1.p3.1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S4.SS1.p3.1.m1.3.3.4" xref="S4.SS1.p3.1.m1.3.3.4.cmml">=</mo><mrow id="S4.SS1.p3.1.m1.3.3.3" xref="S4.SS1.p3.1.m1.3.3.3.cmml"><mi id="S4.SS1.p3.1.m1.3.3.3.3" xref="S4.SS1.p3.1.m1.3.3.3.3.cmml">𝕀</mi><mo id="S4.SS1.p3.1.m1.3.3.3.2" xref="S4.SS1.p3.1.m1.3.3.3.2.cmml">⁢</mo><mrow id="S4.SS1.p3.1.m1.3.3.3.1.1" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.cmml"><mo id="S4.SS1.p3.1.m1.3.3.3.1.1.2" stretchy="false" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S4.SS1.p3.1.m1.3.3.3.1.1.1" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.cmml"><mrow id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.cmml"><msub id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.cmml"><mi id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.2" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.2.cmml">x</mi><mn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.3" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.3.cmml">1</mn></msub><mo id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.1" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.1.cmml">+</mo><msubsup id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.cmml"><mi id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.2" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.2.cmml">x</mi><mn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.3" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.3.cmml">2</mn><mn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.3" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.3.cmml">2</mn></msubsup></mrow><mo id="S4.SS1.p3.1.m1.3.3.3.1.1.1.1" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.1.cmml">&gt;</mo><mn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.3" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.3.cmml">0</mn></mrow><mo id="S4.SS1.p3.1.m1.3.3.3.1.1.3" stretchy="false" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.3b"><apply id="S4.SS1.p3.1.m1.3.3.cmml" xref="S4.SS1.p3.1.m1.3.3"><eq id="S4.SS1.p3.1.m1.3.3.4.cmml" xref="S4.SS1.p3.1.m1.3.3.4"></eq><apply id="S4.SS1.p3.1.m1.2.2.2.cmml" xref="S4.SS1.p3.1.m1.2.2.2"><times id="S4.SS1.p3.1.m1.2.2.2.3.cmml" xref="S4.SS1.p3.1.m1.2.2.2.3"></times><ci id="S4.SS1.p3.1.m1.2.2.2.4.cmml" xref="S4.SS1.p3.1.m1.2.2.2.4">𝑓</ci><interval closure="open" id="S4.SS1.p3.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.p3.1.m1.2.2.2.2.2"><apply id="S4.SS1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1.2">𝑥</ci><cn id="S4.SS1.p3.1.m1.1.1.1.1.1.1.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S4.SS1.p3.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.2.2.2.2.2.2.1.cmml" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p3.1.m1.2.2.2.2.2.2.2.cmml" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2.2">𝑥</ci><cn id="S4.SS1.p3.1.m1.2.2.2.2.2.2.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.2.2.2.2.2.2.3">2</cn></apply></interval></apply><apply id="S4.SS1.p3.1.m1.3.3.3.cmml" xref="S4.SS1.p3.1.m1.3.3.3"><times id="S4.SS1.p3.1.m1.3.3.3.2.cmml" xref="S4.SS1.p3.1.m1.3.3.3.2"></times><ci id="S4.SS1.p3.1.m1.3.3.3.3.cmml" xref="S4.SS1.p3.1.m1.3.3.3.3">𝕀</ci><apply id="S4.SS1.p3.1.m1.3.3.3.1.1.1.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1"><gt id="S4.SS1.p3.1.m1.3.3.3.1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.1"></gt><apply id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2"><plus id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.1.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.1"></plus><apply id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.1.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2">subscript</csymbol><ci id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.2.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.2">𝑥</ci><cn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.2.3">1</cn></apply><apply id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.1.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3">superscript</csymbol><apply id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.1.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3">subscript</csymbol><ci id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.2.cmml" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.2">𝑥</ci><cn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.2.3">2</cn></apply><cn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.2.3.3">2</cn></apply></apply><cn id="S4.SS1.p3.1.m1.3.3.3.1.1.1.3.cmml" type="integer" xref="S4.SS1.p3.1.m1.3.3.3.1.1.1.3">0</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.3c">f(x_{1},x_{2})=\mathbb{I}(x_{1}+x_{2}^{2}&gt;0)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.1.m1.3d">italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = blackboard_I ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT &gt; 0 )</annotation></semantics></math>. The experimental setup remains the same as for the logistic regression case.
The results, presented in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F4" title="In 4.1 Illustrative Examples ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>, show that both GAMformer and EBMs successfully capture the quadratic relationship in <math alttext="x_{2}" class="ltx_Math" display="inline" id="S4.SS1.p3.2.m2.1"><semantics id="S4.SS1.p3.2.m2.1a"><msub id="S4.SS1.p3.2.m2.1.1" xref="S4.SS1.p3.2.m2.1.1.cmml"><mi id="S4.SS1.p3.2.m2.1.1.2" xref="S4.SS1.p3.2.m2.1.1.2.cmml">x</mi><mn id="S4.SS1.p3.2.m2.1.1.3" xref="S4.SS1.p3.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.2.m2.1b"><apply id="S4.SS1.p3.2.m2.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.2.m2.1.1.1.cmml" xref="S4.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p3.2.m2.1.1.2.cmml" xref="S4.SS1.p3.2.m2.1.1.2">𝑥</ci><cn id="S4.SS1.p3.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.p3.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.2.m2.1c">x_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.2.m2.1d">italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> and the linear contribution of <math alttext="x_{1}" class="ltx_Math" display="inline" id="S4.SS1.p3.3.m3.1"><semantics id="S4.SS1.p3.3.m3.1a"><msub id="S4.SS1.p3.3.m3.1.1" xref="S4.SS1.p3.3.m3.1.1.cmml"><mi id="S4.SS1.p3.3.m3.1.1.2" xref="S4.SS1.p3.3.m3.1.1.2.cmml">x</mi><mn id="S4.SS1.p3.3.m3.1.1.3" xref="S4.SS1.p3.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.3.m3.1b"><apply id="S4.SS1.p3.3.m3.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p3.3.m3.1.1.1.cmml" xref="S4.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p3.3.m3.1.1.2.cmml" xref="S4.SS1.p3.3.m3.1.1.2">𝑥</ci><cn id="S4.SS1.p3.3.m3.1.1.3.cmml" type="integer" xref="S4.SS1.p3.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.3.m3.1c">x_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.3.m3.1d">italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> up to <math alttext="x_{1}\leq 0" class="ltx_Math" display="inline" id="S4.SS1.p3.4.m4.1"><semantics id="S4.SS1.p3.4.m4.1a"><mrow id="S4.SS1.p3.4.m4.1.1" xref="S4.SS1.p3.4.m4.1.1.cmml"><msub id="S4.SS1.p3.4.m4.1.1.2" xref="S4.SS1.p3.4.m4.1.1.2.cmml"><mi id="S4.SS1.p3.4.m4.1.1.2.2" xref="S4.SS1.p3.4.m4.1.1.2.2.cmml">x</mi><mn id="S4.SS1.p3.4.m4.1.1.2.3" xref="S4.SS1.p3.4.m4.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.p3.4.m4.1.1.1" xref="S4.SS1.p3.4.m4.1.1.1.cmml">≤</mo><mn id="S4.SS1.p3.4.m4.1.1.3" xref="S4.SS1.p3.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.4.m4.1b"><apply id="S4.SS1.p3.4.m4.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1"><leq id="S4.SS1.p3.4.m4.1.1.1.cmml" xref="S4.SS1.p3.4.m4.1.1.1"></leq><apply id="S4.SS1.p3.4.m4.1.1.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p3.4.m4.1.1.2.1.cmml" xref="S4.SS1.p3.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS1.p3.4.m4.1.1.2.2.cmml" xref="S4.SS1.p3.4.m4.1.1.2.2">𝑥</ci><cn id="S4.SS1.p3.4.m4.1.1.2.3.cmml" type="integer" xref="S4.SS1.p3.4.m4.1.1.2.3">1</cn></apply><cn id="S4.SS1.p3.4.m4.1.1.3.cmml" type="integer" xref="S4.SS1.p3.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.4.m4.1c">x_{1}\leq 0</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.4.m4.1d">italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≤ 0</annotation></semantics></math>. For <math alttext="x_{1}&gt;0" class="ltx_Math" display="inline" id="S4.SS1.p3.5.m5.1"><semantics id="S4.SS1.p3.5.m5.1a"><mrow id="S4.SS1.p3.5.m5.1.1" xref="S4.SS1.p3.5.m5.1.1.cmml"><msub id="S4.SS1.p3.5.m5.1.1.2" xref="S4.SS1.p3.5.m5.1.1.2.cmml"><mi id="S4.SS1.p3.5.m5.1.1.2.2" xref="S4.SS1.p3.5.m5.1.1.2.2.cmml">x</mi><mn id="S4.SS1.p3.5.m5.1.1.2.3" xref="S4.SS1.p3.5.m5.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.p3.5.m5.1.1.1" xref="S4.SS1.p3.5.m5.1.1.1.cmml">&gt;</mo><mn id="S4.SS1.p3.5.m5.1.1.3" xref="S4.SS1.p3.5.m5.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.5.m5.1b"><apply id="S4.SS1.p3.5.m5.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1"><gt id="S4.SS1.p3.5.m5.1.1.1.cmml" xref="S4.SS1.p3.5.m5.1.1.1"></gt><apply id="S4.SS1.p3.5.m5.1.1.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p3.5.m5.1.1.2.1.cmml" xref="S4.SS1.p3.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS1.p3.5.m5.1.1.2.2.cmml" xref="S4.SS1.p3.5.m5.1.1.2.2">𝑥</ci><cn id="S4.SS1.p3.5.m5.1.1.2.3.cmml" type="integer" xref="S4.SS1.p3.5.m5.1.1.2.3">1</cn></apply><cn id="S4.SS1.p3.5.m5.1.1.3.cmml" type="integer" xref="S4.SS1.p3.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.5.m5.1c">x_{1}&gt;0</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.5.m5.1d">italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT &gt; 0</annotation></semantics></math>, <math alttext="f" class="ltx_Math" display="inline" id="S4.SS1.p3.6.m6.1"><semantics id="S4.SS1.p3.6.m6.1a"><mi id="S4.SS1.p3.6.m6.1.1" xref="S4.SS1.p3.6.m6.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.6.m6.1b"><ci id="S4.SS1.p3.6.m6.1.1.cmml" xref="S4.SS1.p3.6.m6.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.6.m6.1c">f</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p3.6.m6.1d">italic_f</annotation></semantics></math> always predicts true, resulting in a constant contribution. Consistent with the previous experiment, GAMformer produces smoother shape functions. Again both models achieve an ROC AUC of 1.0 on the test dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.2.1">Classification Boundaries.</span>
We visualize the classification boundaries of GAMformer compared to TabPFN and EBM on the scikit-learn <cite class="ltx_cite ltx_citemacro_citep">(Pedregosa et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib43" title="">2011</a>)</cite> test datasets in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F5" title="In 4.1 Illustrative Examples ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a>. We find that GAMformer performs similarly to TabPFN and EBMs on most of the example datasets. LA-NAM <cite class="ltx_cite ltx_citemacro_citep">(Bouchiat et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib27" title="">2024</a>)</cite> (main effects only), a Bayesian version of NAMs <cite class="ltx_cite ltx_citemacro_citep">(Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib11" title="">2021</a>)</cite>, provides good uncertainty estimates despite exhibiting slightly worse predictive performance. It is worth noting that GAMformer, EBM and LA-NAM struggle with accurately modeling the ‘XOR’ dataset (bottom row) due to the absence of higher-order feature interaction terms in these models. This is resolved by incorporating second-order effects (EBM<sup class="ltx_sup" id="S4.SS1.p4.2.2">∗</sup> and GAMformer<sup class="ltx_sup" id="S4.SS1.p4.2.3">∗</sup>; see Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S3.SS4" title="3.4 Higher-order effects ‣ 3 GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">3.4</span></a> for details), allowing them to effectively learn the non-linear decision boundary of the ‘XOR’ function.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="313" id="S4.F5.g1" src="x8.png" width="753"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Visualization of classification boundaries for various baseline classifiers and GAMformer on scikit-learn dataset examples <cite class="ltx_cite ltx_citemacro_citep">(Pedregosa et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib43" title="">2011</a>)</cite>, in the lower right corner we show the ROC-AUC on a validation split. Due to the absence of higher-order feature interaction terms in both GAMformer and EBM (main effects), the ’XOR’ dataset (bottom row) is not accurately modeled by them. Incorporating second-order effects solves the problem (EBM<sup class="ltx_sup" id="S4.F5.7.1">∗</sup> and GAMformer<sup class="ltx_sup" id="S4.F5.8.2">∗</sup>).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Multi-class Classification on OpenML Tabular Datasets</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To assess the transferability of pretraining on synthetic data to real-world tabular data, we evaluate GAMformer’s performance on the test datasets from TabPFN <cite class="ltx_cite ltx_citemacro_citep">(Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite>, which include up to 2000 datapoints (see <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS1" title="B.1 TabPFN Test Datasets ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">B.1</span></a> for dataset details).
<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F6" title="In 4.3 Case Study: Intensive Care Unit Mortality Risk ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a> reports Critical Diagrams (CD) from <cite class="ltx_cite ltx_citemacro_citet">Demšar (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib44" title="">2006</a>)</cite> showing the average rank across datasets for each method, with statistically tied methods grouped by horizontal bars. Our method outperforms EBM when using only main effects. With pair effects, both GAMformer* and EBM* show slight improvements, matching XGBoost’s performance. We also compare against GAMs from the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.1.1">mgcv</span> R <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/gam" title="">https://www.rdocumentation.org/packages/mgcv/versions/1.9-1/topics/gam</a></span></span></span> library. mgcv GAM models the relationships between features and output variables by combining parametric and non-parametric terms. The non-parametric components are represented by splines, thus capturing nonlinear relationships. In mgcv GAM the degree of smoothness in every spline is automatically selected using Restricted Maximum Likelihood (REML) <cite class="ltx_cite ltx_citemacro_citep">(Wood, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib45" title="">2010</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We note that the small difference in performance between XGBoost and GAMformer suggests that the trade-offs in model capacity when choosing a main effects only GAM are often less significant than expected. As a result, the substantial interpretability benefits offered by the GAM model class become even more appealing, making it a viable choice for many applications. We present additional results on five binary classification datasets used by <cite class="ltx_cite ltx_citemacro_citet">Chang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib22" title="">2021</a>)</cite> in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.SS2" title="B.2 Binary Classification ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">B.2</span></a>. Despite these datasets falling outside the recommended range of 2000 datapoints, GAMformer still demonstrates comparable performance to more complex models.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Case Study: Intensive Care Unit Mortality Risk</h3>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">In this case study, we examine shape functions derived from GAMformer and EBMs (main effects only) using the MIMIC-II dataset <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib46" title="">2011a</a>)</cite>, a publicly available critical care dataset for predicting mortality risk based on various demographic and biophysical indicators. Our analysis focuses on four key clinical variables: Age, Heart Rate (HR), PFratio (PaO2/FiO2 ratio), and Glasgow Coma Scale (GCS), as shown in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F7" title="In 4.3 Case Study: Intensive Care Unit Mortality Risk ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">7</span></a> (remaining variables in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A7.SS1" title="G.1 MIMIC-II dataset ‣ Appendix G Shape Functions ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">G.1</span></a>). Further results on the MIMIC-III dataset are available in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A7.SS2" title="G.2 MIMIC-III dataset ‣ Appendix G Shape Functions ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">G.2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="223" id="S4.F6.g1" src="x9.png" width="829"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Critical Difference diagram demonstrating GAMformer’s competitive performance against state-of-the-art baselines across diverse datasets. Lower ranks indicate superior performance; connected algorithms are not statistically significantly different (<math alttext="p=0.05" class="ltx_Math" display="inline" id="S4.F6.2.m1.1"><semantics id="S4.F6.2.m1.1b"><mrow id="S4.F6.2.m1.1.1" xref="S4.F6.2.m1.1.1.cmml"><mi id="S4.F6.2.m1.1.1.2" xref="S4.F6.2.m1.1.1.2.cmml">p</mi><mo id="S4.F6.2.m1.1.1.1" xref="S4.F6.2.m1.1.1.1.cmml">=</mo><mn id="S4.F6.2.m1.1.1.3" xref="S4.F6.2.m1.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F6.2.m1.1c"><apply id="S4.F6.2.m1.1.1.cmml" xref="S4.F6.2.m1.1.1"><eq id="S4.F6.2.m1.1.1.1.cmml" xref="S4.F6.2.m1.1.1.1"></eq><ci id="S4.F6.2.m1.1.1.2.cmml" xref="S4.F6.2.m1.1.1.2">𝑝</ci><cn id="S4.F6.2.m1.1.1.3.cmml" type="float" xref="S4.F6.2.m1.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.2.m1.1d">p=0.05</annotation><annotation encoding="application/x-llamapun" id="S4.F6.2.m1.1e">italic_p = 0.05</annotation></semantics></math>).</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.F7.4" style="width:381.2pt;height:119.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S4.F7.4.4"><span class="ltx_text" id="S4.F7.4.4.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="104" id="S4.F7.1.1.1.g1" src="x10.png" width="124"/>
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="104" id="S4.F7.2.2.2.g2" src="x11.png" width="106"/>
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="104" id="S4.F7.3.3.3.g3" src="x12.png" width="99"/>
<img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="105" id="S4.F7.4.4.4.g4" src="x13.png" width="178"/></span></p>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Shape functions derived from GAMformer and EBMs applied to the MIMIC-II dataset for critical clinical variables. The data density plot is shown above each figure. The results are based on 30 models for both GAMformer and EBMs, each fitted on 10,000 randomly selected data points.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">For Age, the GAMformer shape function shows a steady increase in the log-odds of adverse outcomes with advancing age, stabilizing at older ages. The data density plot reveals a higher concentration of data points in middle age, with fewer at the extremes. The shape function exhibits less variance where data is denser, indicating the model’s reliability in these regions. Overall, the shape function highlights increased risk in elderly patients due to declining physiological reserves and multiple chronic conditions. Heart Rate (HR) exhibits a complex relationship with adverse outcomes. Both GAMformer and EBMs capture a U-shaped risk profile, indicating increased risk at very high and very low heart rates, underscoring the importance of maintaining HR within a normal range. PFratio, a lung function and oxygenation efficiency measure, shows a steep risk increase as values decrease. Lower PFratio values, critical in diagnosing and managing conditions like Acute Respiratory Distress Syndrome (ARDS), indicate worse lung function. Notably, both models display a sharp drop in risk at a PFratio of approximately 325, likely an artifact from data preprocessing where missing values were imputed at the mean, previously pointed out by <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib47" title="">2023</a>)</cite> for MIMIC-2. In healthcare, missing values often suggest healthier patients, as data collection was deemed unnecessary by professionals. Here, patients with missing PFratio values, representing the majority, have lower risk than those with collected values. GAMformer more precisely isolates these missing value patients, demonstrating its potential to detect data processing artifacts better than prior GAM algorithms. For the Glasgow Coma Scale (GCS), which measures the level consciousness, there is a strong negative correlation with adverse outcomes. Lower GCS scores, indicating reduced consciousness, are associated with significantly higher mortality risk. Our findings show that GAMformer effectively handles categorical data, identifying patterns similar to those detected by EBMs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations &amp; Broader Impact</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">Limitations.</span> While GAMformer introduces a novel approach to estimating Generalized Additive Models (GAMs), it is important to acknowledge its current limitations. This work primarily focuses on main and second-order effect GAMs and does not account for higher-order interactions, which are addressed in other GAM implementations, such as EBMs <cite class="ltx_cite ltx_citemacro_citep">(Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>; Nori et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib48" title="">2019</a>; Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib22" title="">2021</a>)</cite>. Future research could explore incorporating these interactions to enhance the model’s expressiveness and predictive capabilities.
Another limitation of the current GAMformer model is its difficulty in improving predictions when presented with datasets that exceed twice the size of the data it saw during training (c.f. <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.F8" title="In C.1 Data Scaling ‣ Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">8</span></a>). This issue is related to the well-known challenge of length extrapolation in sequence-to-sequence models, including transformers <cite class="ltx_cite ltx_citemacro_citep">(Grazzi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib49" title="">2024</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib50" title="">2024</a>)</cite>. Addressing this limitation may require exposing the model to a larger variety of number of examples during training. However, due to computational constraints, the experiments in this work were limited to a maximum of 500 datapoints during training. Future studies with increased computational resources could investigate the model’s performance on larger datasets and develop strategies to mitigate the length extrapolation problem.
The GAMformer model’s transformer-based architecture scales quadratically with both the number of training data points and features, posing a similar challenge to handling large datasets as faced by TabPFN <cite class="ltx_cite ltx_citemacro_citep">(Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>)</cite>. Novel, scalable transformer alternatives, such as the recently proposed Mamba <cite class="ltx_cite ltx_citemacro_citep">(Gu and Dao, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib51" title="">2023</a>)</cite> or Gated Linear Attention <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib52" title="">2024</a>)</cite>, may prove useful in overcoming this issue.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Broader Impact.</span> As a versatile machine learning model for tabular data, GAMformer offers both positive and negative societal impacts. Positively, it can generate novel insights in fields like medicine, enhancing disease diagnosis and treatment. However, it can also be misused to not mitigate but exploit biases, such as adjusting insurance premiums based on ethnicity, leading to discrimination.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this paper, we introduce GAMformer, a novel approach to creating GAMs using in-context learning with transformer models. By leveraging a single forward pass to form shape functions, GAMformer overcomes the limitations of traditional GAM algorithms that require iterative learning processes and hence hyperparameter tuning. Our approach uses non-parametric, binned representations of shape functions, resulting in significant improvements in efficiency and accuracy across various classification benchmarks. Extensive experiments demonstrate that GAMformer approaches the accuracy of leading GAM variants while exhibiting robustness to label noise and class imbalance. The model’s ability to generalize beyond the number of examples seen during training highlights its adaptability and potential for practical applications.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">GAMformer is fundamentally different from the iterative optimization methods traditionally used, and offers a new research direction for interpretable models on tabular data. Further, our case study on the MIMIC-II dataset showcases that interpreting GAMformer’s shape functions can yield qualitative insights and uncover flaws in datasets similar to state of the art GAM methods. This work contributes to the development of more transparent and explainable AI systems, with potential applications in various domains where interpretability is crucial. Future research can expand on this initial new paradigm, and explore scalable alternatives to transformers to handle larger datasets.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.2">This research was partially supported by the following sources: TAILOR, a project funded by EU Horizon 2020 research and innovation programme under GA No 952215; the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under grant number 417962828; the European Research Council (ERC) Consolidator Grant “Deep Learning 2.0” (grant no. 101045765). Frank Hutter acknowledges financial support by the Hector Foundation. The authors acknowledge support from ELLIS and ELIZA. Funded by the European Union. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the ERC. Neither the European Union nor the ERC can be held responsible for them.</p>
<img alt="[Uncaptioned image]" class="ltx_graphics ltx_centering ltx_img_landscape" height="35" id="Sx1.p1.1.g1" src="extracted/5905168/figures/ERC_grant.jpeg" width="165"/>
<p class="ltx_p" id="Sx1.p1.3">.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barocas and Selbst [2016]</span>
<span class="ltx_bibblock">
Solon Barocas and Andrew D Selbst.

</span>
<span class="ltx_bibblock">Big Data’s Disparate Impact.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">California Law Review</em>, pages 671–732, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rudin et al. [2022]</span>
<span class="ltx_bibblock">
Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova, and Chudi
Zhong.

</span>
<span class="ltx_bibblock">Interpretable Machine Learning: Fundamental Principles and 10 Grand
Challenges.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Statistic Surveys</em>, 16:1–85, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ribeiro et al. [2016]</span>
<span class="ltx_bibblock">
Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.

</span>
<span class="ltx_bibblock">" why should i trust you?" explaining the predictions of any
classifier.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 22nd ACM SIGKDD international conference
on knowledge discovery and data mining</em>, pages 1135–1144, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caruana et al. [2015]</span>
<span class="ltx_bibblock">
Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie
Elhadad.

</span>
<span class="ltx_bibblock">Intelligible models for healthcare: Predicting pneumonia risk and
hospital 30-day readmission.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 21th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining</em>, pages 1721–1730, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arun et al. [2016]</span>
<span class="ltx_bibblock">
Kumar Arun, Garg Ishan, and Kaur Sanmeet.

</span>
<span class="ltx_bibblock">Loan approval prediction based on machine learning approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IOSR Journal of Computer Engineering</em>, 18(3):18–21, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dattner et al. [2019]</span>
<span class="ltx_bibblock">
Ben Dattner, Tomas Chamorro-Premuzic, Richard Buchband, and Lucinda Schettler.

</span>
<span class="ltx_bibblock">The legal and ethical implications of using AI in hiring.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Harvard Business Review</em>, 25, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehrabi et al. [2021]</span>
<span class="ltx_bibblock">
Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan.

</span>
<span class="ltx_bibblock">A survey on bias and fairness in machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ACM Comput. Surv.</em>, 54(6), jul 2021.

</span>
<span class="ltx_bibblock">ISSN 0360-0300.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3457607</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hastie and Tibshirani [1987]</span>
<span class="ltx_bibblock">
Trevor Hastie and Robert Tibshirani.

</span>
<span class="ltx_bibblock">Generalized Additive Models: Some applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Journal of the American Statistical Association</em>, 82(398):371–386, 1987.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lou et al. [2012]</span>
<span class="ltx_bibblock">
Yin Lou, Rich Caruana, and Johannes Gehrke.

</span>
<span class="ltx_bibblock">Intelligible Models for Classification and Regression.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 18th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining</em>, pages 150–158, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lou et al. [2013]</span>
<span class="ltx_bibblock">
Yin Lou, Rich Caruana, Johannes Gehrke, and Giles Hooker.

</span>
<span class="ltx_bibblock">Accurate intelligible models with pairwise interactions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 19th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining</em>, pages 623–631, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. [2021]</span>
<span class="ltx_bibblock">
Rishabh Agarwal, Levi Melnick, Nicholas Frosst, Xuezhou Zhang, Ben Lengerich,
Rich Caruana, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Neural Additive Models: Interpretable Machine Learning With Neural
Nets.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems 34</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siems et al. [2023]</span>
<span class="ltx_bibblock">
Julien Siems, Konstantin Ditschuneit, Winfried Ripken, Alma Lindborg,
Maximilian Schambach, Johannes Otterbach, and Martin Genzel.

</span>
<span class="ltx_bibblock">Curve Your Enthusiasm: Concurvity Regularization in Differentiable
Generalized Additive Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Advances in Neural Information Processing Systems</em>,
volume 37. Curran Associates, Inc., 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kovács [2022]</span>
<span class="ltx_bibblock">
László Kovács.

</span>
<span class="ltx_bibblock">Feature selection algorithms in generalized additive models under
concurvity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Computational Statistics</em>, pages 1–33, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. [2020a]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss,
G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter,
C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark,
C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H. Larochelle, M. Ranzato, R. Hadsell, M.-F. Balcan, and H. Lin,
editors, <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 34th International Conference on Advances
in Neural Information Processing Systems (NeurIPS’20)</em>, pages 1877–1901,
2020a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2023]</span>
<span class="ltx_bibblock">
Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Fanyi Pu, Jingkang Yang,
Chunyuan Li, and Ziwei Liu.

</span>
<span class="ltx_bibblock">Mimic-it: Multi-modal in-context instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2306.05425</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dooley et al. [2024]</span>
<span class="ltx_bibblock">
Samuel Dooley, Gurnoor Singh Khurana, Chirag Mohapatra, Siddartha V Naidu, and
Colin White.

</span>
<span class="ltx_bibblock">ForecastPFN: Synthetically-trained zero-shot forecasting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hollmann et al. [2023]</span>
<span class="ltx_bibblock">
N. Hollmann, S. Müller, K. Eggensperger, and F. Hutter.

</span>
<span class="ltx_bibblock">TabPFN: A transformer that solves small tabular classification
problems in a second.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">International Conference on Learning Representations
(ICLR’23)</em>, 2023.

</span>
<span class="ltx_bibblock">Published online: <a class="ltx_ref ltx_url ltx_font_typewriter" href="iclr.cc" title="">iclr.cc</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Müller et al. [2022]</span>
<span class="ltx_bibblock">
S. Müller, N. Hollmann, S. Arango, J. Grabocka, and F. Hutter.

</span>
<span class="ltx_bibblock">Transformers can do Bayesian inference.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the International Conference on Learning
Representations (ICLR’22)</em>, 2022.

</span>
<span class="ltx_bibblock">Published online: <a class="ltx_ref ltx_url ltx_font_typewriter" href="iclr.cc" title="">iclr.cc</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nelder and Wedderburn [1972]</span>
<span class="ltx_bibblock">
John Ashworth Nelder and Robert WM Wedderburn.

</span>
<span class="ltx_bibblock">Generalized Linear Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Journal of the Royal Statistical Society: Series A (General)</em>,
135(3):370–384, 1972.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood [2003]</span>
<span class="ltx_bibblock">
Simon N Wood.

</span>
<span class="ltx_bibblock">Thin plate regression splines.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Journal of the Royal Statistical Society Series B: Statistical
Methodology</em>, 65(1):95–114, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood [2001]</span>
<span class="ltx_bibblock">
Simon N Wood.

</span>
<span class="ltx_bibblock">MGCV: GAMs and generalized ridge regression for R.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">R news</em>, 1(2):20–25, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. [2021]</span>
<span class="ltx_bibblock">
Chun-Hao Chang, Rich Caruana, and Anna Goldenberg.

</span>
<span class="ltx_bibblock">NODE-GAM: Neural Generalized Additive Model for Interpretable Deep
Learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Conference on Learning Representations</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. [2022]</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Filip Radenovic, and Dhruv Mahajan.

</span>
<span class="ltx_bibblock">Scalable Interpretability via Polynomials.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Advances in Neural Information Processing Systems 35</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radenovic et al. [2022]</span>
<span class="ltx_bibblock">
Filip Radenovic, Abhimanyu Dubey, and Dhruv Mahajan.

</span>
<span class="ltx_bibblock">Neural Basis Models for Interpretability.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Advances in Neural Information Processing Systems 35</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2022]</span>
<span class="ltx_bibblock">
Shiyun Xu, Zhiqi Bu, Pratik Chaudhari, and Ian J Barnett.

</span>
<span class="ltx_bibblock">Sparse neural additive model: Interpretable deep learning with
feature selection via group sparsity.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ICLR 2022 Workshop on PAIR 2Struct: Privacy, Accountability,
Interpretability, Robustness, Reasoning on Structured Data</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Enouen and Liu [2022]</span>
<span class="ltx_bibblock">
James Enouen and Yan Liu.

</span>
<span class="ltx_bibblock">Sparse interaction additive networks via feature interaction
detection and sparse selection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in Neural Information Processing Systems 35</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bouchiat et al. [2024]</span>
<span class="ltx_bibblock">
K. Bouchiat, A. Immer, H. Yèche, G. Rätsch, and V. Fortuin.

</span>
<span class="ltx_bibblock">Improving neural additive models with bayesian principles.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 41st International Conference on Machine
Learning (ICML)</em>, volume 235 of <em class="ltx_emph ltx_font_italic" id="bib.bib27.2.2">Proceedings of Machine Learning
Research</em>, pages 4416–4443. PMLR, July 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.mlr.press/v235/bouchiat24a.html" title="">https://proceedings.mlr.press/v235/bouchiat24a.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor and Letham [2018]</span>
<span class="ltx_bibblock">
Sean J Taylor and Benjamin Letham.

</span>
<span class="ltx_bibblock">Forecasting at Scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">The American Statistician</em>, 72(1):37–45,
2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Triebe et al. [2021]</span>
<span class="ltx_bibblock">
Oskar Triebe, Hansika Hewamalage, Polina Pilyugina, Nikolay Laptev, Christoph
Bergmeir, and Ram Rajagopal.

</span>
<span class="ltx_bibblock">NeuralProphet: Explainable forecasting at scale.

</span>
<span class="ltx_bibblock">Preprint arXiv:2111.15397, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. [2020b]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in neural information processing systems</em>,
33:1877–1901, 2020b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. [2017]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Advances in Neural Information Processing Systems</em>,
volume 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olsson et al. [2022]</span>
<span class="ltx_bibblock">
Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma,
Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, et al.

</span>
<span class="ltx_bibblock">In-context learning and induction heads.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2209.11895</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et al. [2022]</span>
<span class="ltx_bibblock">
Stephanie Chan, Adam Santoro, Andrew Lampinen, Jane Wang, Aaditya Singh, Pierre
Richemond, James McClelland, and Felix Hill.

</span>
<span class="ltx_bibblock">Data distributional properties drive emergent in-context learning in
transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Advances in Neural Information Processing Systems</em>,
35:18878–18891, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddy [2024]</span>
<span class="ltx_bibblock">
Gautam Reddy.

</span>
<span class="ltx_bibblock">The mechanistic basis of data dependence and abrupt learning in an
in-context classification task.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Müller et al. [2023a]</span>
<span class="ltx_bibblock">
S. Müller, M. Feurer, N. Hollmann, and F. Hutter.

</span>
<span class="ltx_bibblock">Pfns4bo: In-context learning for bayesian optimization.

</span>
<span class="ltx_bibblock">In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and
J. Scarlett, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 40th International Conference
on Machine Learning (ICML’23)</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib35.2.2">Proceedings of Machine
Learning Research</em>. PMLR, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adriaensen et al. [2024]</span>
<span class="ltx_bibblock">
Steven Adriaensen, Herilalaina Rakotoarison, Samuel Müller, and Frank
Hutter.

</span>
<span class="ltx_bibblock">Efficient bayesian learning curve extrapolation using prior-data
fitted networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rakotoarison et al. [2024]</span>
<span class="ltx_bibblock">
Herilalaina Rakotoarison, Steven Adriaensen, Neeratyoy Mallik, Samir Garibov,
Edward Bergman, and Frank Hutter.

</span>
<span class="ltx_bibblock">In-Context Freeze-Thaw Bayesian Optimization for Hyperparameter
Optimization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">International Conference on Machine Learning</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Müller et al. [2023b]</span>
<span class="ltx_bibblock">
Andreas Müller, Carlo Curino, and Raghu Ramakrishnan.

</span>
<span class="ltx_bibblock">Mothernet: A foundational hypernetwork for tabular classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2312.08598</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garnelo et al. [2018]</span>
<span class="ltx_bibblock">
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David
Saxton, Murray Shanahan, Yee Whye Teh, Danilo Rezende, and SM Ali Eslami.

</span>
<span class="ltx_bibblock">Conditional Neural Processes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">International conference on machine learning</em>, pages
1704–1713. PMLR, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen and Grover [2022]</span>
<span class="ltx_bibblock">
Tung Nguyen and Aditya Grover.

</span>
<span class="ltx_bibblock">Transformer neural processes: Uncertainty-aware meta learning via
sequence modeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">International Conference on Machine Learning</em>, pages
16569–16594. PMLR, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lorch et al. [2022]</span>
<span class="ltx_bibblock">
Lars Lorch, Scott Sussex, Jonas Rothfuss, Andreas Krause, and Bernhard
Schölkopf.

</span>
<span class="ltx_bibblock">Amortized inference for causal structure learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Advances in Neural Information Processing Systems</em>,
35:13104–13118, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Guestrin [2016]</span>
<span class="ltx_bibblock">
Tianqi Chen and Carlos Guestrin.

</span>
<span class="ltx_bibblock">XGBoost: A scalable tree boosting system.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining</em>, KDD ’16, pages 785–794, New York,
NY, USA, 2016. ACM.

</span>
<span class="ltx_bibblock">ISBN 978-1-4503-4232-2.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/2939672.2939785</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pedregosa et al. [2011]</span>
<span class="ltx_bibblock">
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.

</span>
<span class="ltx_bibblock">Scikit-learn: Machine learning in Python.

</span>
<span class="ltx_bibblock">12:2825–2830, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Demšar [2006]</span>
<span class="ltx_bibblock">
J. Demšar.

</span>
<span class="ltx_bibblock">Statistical comparisons of classifiers over multiple data sets.

</span>
<span class="ltx_bibblock">7:1–30, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wood [2010]</span>
<span class="ltx_bibblock">
Simon N. Wood.

</span>
<span class="ltx_bibblock">Fast Stable Restricted Maximum Likelihood and Marginal Likelihood
Estimation of Semiparametric Generalized Linear Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Journal of the Royal Statistical Society Series B: Statistical
Methodology</em>, 73(1):3–36, 09 2010.

</span>
<span class="ltx_bibblock">ISSN 1369-7412.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1111/j.1467-9868.2010.00749.x</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2011a]</span>
<span class="ltx_bibblock">
Joon Lee, Daniel J Scott, Mauricio Villarroel, Gari D Clifford, Mohammed Saeed,
and Roger G Mark.

</span>
<span class="ltx_bibblock">Open-access mimic-ii database for intensive care research.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">2011 Annual International Conference of the IEEE Engineering
in Medicine and Biology Society</em>, pages 8315–8318. IEEE, 2011a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2023]</span>
<span class="ltx_bibblock">
Zhi Chen, Sarah Tan, Urszula Chajewska, Cynthia Rudin, and Rich Caruna.

</span>
<span class="ltx_bibblock">Missing values and imputation in healthcare data: Can interpretable
machine learning help?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Conference on Health, Inference, and Learning</em>, pages
86–99. PMLR, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et al. [2019]</span>
<span class="ltx_bibblock">
Harsha Nori, Samuel Jenkins, Paul Koch, and Rich Caruana.

</span>
<span class="ltx_bibblock">InterpretML: A unified framework for machine learning
interpretability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:1909.09223</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grazzi et al. [2024]</span>
<span class="ltx_bibblock">
Riccardo Grazzi, Julien Niklas Siems, Simon Schrodi, Thomas Brox, and Frank
Hutter.

</span>
<span class="ltx_bibblock">Is Mamba Capable of In-Context Learning?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">ICLR 2024 Workshop on Mathematical and Empirical
Understanding of Foundation Models</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. [2024]</span>
<span class="ltx_bibblock">
Yongchao Zhou, Uri Alon, Xinyun Chen, Xuezhi Wang, Rishabh Agarwal, and Denny
Zhou.

</span>
<span class="ltx_bibblock">Transformers can achieve length generalization but not robustly.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">ICLR 2024 Workshop on Mathematical and Empirical
Understanding of Foundation Models</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu and Dao [2023]</span>
<span class="ltx_bibblock">
Albert Gu and Tri Dao.

</span>
<span class="ltx_bibblock">Mamba: Linear-time sequence modeling with selective state spaces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2312.00752</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2024]</span>
<span class="ltx_bibblock">
Songlin Yang, Bailin Wang, Yikang Shen, Rameswar Panda, and Yoon Kim.

</span>
<span class="ltx_bibblock">Gated linear attention transformers with hardware-efficient training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Forty-first International Conference on Machine Learning</em>,
2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2024]</span>
<span class="ltx_bibblock">
Ziming Liu, Yixuan Wang, Sachin Vaidya, Fabian Ruehle, James Halverson, Marin
Soljačić, Thomas Y Hou, and Max Tegmark.

</span>
<span class="ltx_bibblock">KAN: Kolmogorov-Arnold Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2404.19756</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vanschoren et al. [2014]</span>
<span class="ltx_bibblock">
J. Vanschoren, J. van Rijn, B. Bischl, and L. Torgo.

</span>
<span class="ltx_bibblock">OpenML: Networked science in machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">SIGKDD Explor. Newsl.</em>, 15(2):49–60, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Servén and Brummitt [2018]</span>
<span class="ltx_bibblock">
Daniel Servén and Charlie Brummitt.

</span>
<span class="ltx_bibblock">pyGAM: Generalized Additive Models in Python.

</span>
<span class="ltx_bibblock">URL: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zenodo.org/records/1476122" title="">https://zenodo.org/records/1476122</a>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua and Graff [2017]</span>
<span class="ltx_bibblock">
Dheeru Dua and Casey Graff.

</span>
<span class="ltx_bibblock">UCI Machine Learning Repository, 2017.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://archive.ics.uci.edu/ml" title="">http://archive.ics.uci.edu/ml</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2011b]</span>
<span class="ltx_bibblock">
Joon Lee, Daniel J. Scott, Mauricio Villarroel, Gari D. Clifford, Mohammed
Saeed, and Roger G. Mark.

</span>
<span class="ltx_bibblock">Open-Access MIMIC-II Database for Intensive Care Research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">2011 Annual International Conference of the IEEE Engineering in
Medicine and Biology Society</em>, 2011:8315–8318, 2011b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. [2016]</span>
<span class="ltx_bibblock">
Alistair E.W. Johnson, Tom J. Pollard, Lu Shen, Li-wei H. Lehman, Mengling
Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi,
and Roger G. Mark.

</span>
<span class="ltx_bibblock">MIMIC-III, a freely accessible critical care database.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Scientific Data</em>, 3(1), 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1038/sdata.2016.35</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Connors Jr et al. [1996]</span>
<span class="ltx_bibblock">
Alfred F Connors Jr, Neal V Dawson, Charles Thomas, Frank E Harrell Jr, Norman
Desbiens, William J Fulkerson, Peter Kussin, Paul Bellamy, Lee Goldman, and
William A Knaus.

</span>
<span class="ltx_bibblock">Outcomes following acute exacerbation of severe chronic obstructive
lung disease. The SUPPORT investigators (Study to Understand Prognoses and
Preferences for Outcomes and Risks of Treatments).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">American Journal of Respiratory and Critical Care Medicine</em>,
154(4):959–967, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasmussen and Williams [2006]</span>
<span class="ltx_bibblock">
C. Rasmussen and C. Williams.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Gaussian Processes for Machine Learning</em>.

</span>
<span class="ltx_bibblock">The MIT Press, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter [2019]</span>
<span class="ltx_bibblock">
I. Loshchilov and F. Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Proceedings of the International Conference on Learning
Representations (ICLR’19)</em>, 2019.

</span>
<span class="ltx_bibblock">Published online: <a class="ltx_ref ltx_url ltx_font_typewriter" href="iclr.cc" title="">iclr.cc</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Generalized Additive Models: Extended Related Work</h2>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">As with many families of machine learning algorithms, the differences among GAM algorithms lie in (a) the functional form of the shape functions <math alttext="f_{i}" class="ltx_Math" display="inline" id="A1.p1.1.m1.1"><semantics id="A1.p1.1.m1.1a"><msub id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mi id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml">f</mi><mi id="A1.p1.1.m1.1.1.3" xref="A1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">𝑓</ci><ci id="A1.p1.1.m1.1.1.3.cmml" xref="A1.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, (b) the learning algorithm used for their estimation and (c) regularity assumptions and regularization. Two important properties that all GAMs share are (1) the ability to learn non-linear transformations for each feature and (2) additively combining these shape functions (prior to applying the link function) to create modularity that aids interpretability by allowing users to examine shape functions one-at-a-time.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">Typically, GAMs have relied on splines and backfitting algorithms for estimation <cite class="ltx_cite ltx_citemacro_citep">[Hastie and Tibshirani, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib8" title="">1987</a>]</cite>, with subsequent works focusing on improving efficiency and stability through penalized regression splines <cite class="ltx_cite ltx_citemacro_citep">[Wood, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib20" title="">2003</a>]</cite> and fast, stable fitting algorithms <cite class="ltx_cite ltx_citemacro_citep">[Wood, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib21" title="">2001</a>]</cite>. Spline-based GAMs are typically fitted using the backfitting algorithm, an iterative procedure that starts with initial estimates of the smooth functions for each predictor variable. The algorithm then repeatedly updates each function by fitting a weighted additive model to the residuals of the other functions until convergence is achieved. The weights are determined by the current estimates of the other functions and the link function in the case of generalized additive models.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p3">
<p class="ltx_p" id="A1.p3.1">Modern approaches leverage machine learning advances. Explainable Boosting Machines (EBMs) <cite class="ltx_cite ltx_citemacro_citep">[Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib9" title="">2012</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>, Caruana et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib4" title="">2015</a>]</cite> model the shape functions using decision trees, which are fitted using a variant of gradient boosting called cyclic gradient boosting. The model iteratively learns the contribution of each feature and interaction term in a round-robin fashion, using a low learning rate to ensure that the order of features does not affect the final model. This cyclic training procedure helps mitigate the effects of colinearity among predictors by providing opportunity for data-driven credit attribution among the features while preventing multiple counting of evidence. EBMs are also popular because they can accurately capture steps in the shape functions, which is important for modeling discontinuities in data, such as treatment effects in medical data.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p4">
<p class="ltx_p" id="A1.p4.1">More recently, Neural Additive Models (NAMs) <cite class="ltx_cite ltx_citemacro_citep">[Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib11" title="">2021</a>]</cite> and follow up works <cite class="ltx_cite ltx_citemacro_citep">[Chang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib22" title="">2021</a>, Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib23" title="">2022</a>, Radenovic et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib24" title="">2022</a>, Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib25" title="">2022</a>, Enouen and Liu, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib26" title="">2022</a>, Bouchiat et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib27" title="">2024</a>]</cite> use multilayer perceptrons (MLPs), as non-linear transformations, to model the shape functions <math alttext="f_{i}" class="ltx_Math" display="inline" id="A1.p4.1.m1.1"><semantics id="A1.p4.1.m1.1a"><msub id="A1.p4.1.m1.1.1" xref="A1.p4.1.m1.1.1.cmml"><mi id="A1.p4.1.m1.1.1.2" xref="A1.p4.1.m1.1.1.2.cmml">f</mi><mi id="A1.p4.1.m1.1.1.3" xref="A1.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A1.p4.1.m1.1b"><apply id="A1.p4.1.m1.1.1.cmml" xref="A1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p4.1.m1.1.1.1.cmml" xref="A1.p4.1.m1.1.1">subscript</csymbol><ci id="A1.p4.1.m1.1.1.2.cmml" xref="A1.p4.1.m1.1.1.2">𝑓</ci><ci id="A1.p4.1.m1.1.1.3.cmml" xref="A1.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p4.1.m1.1c">f_{i}</annotation><annotation encoding="application/x-llamapun" id="A1.p4.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. As a result, NAMs can be optimized using variants of gradient descent by leveraging automatic differentiation frameworks.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.p5">
<p class="ltx_p" id="A1.p5.1">Finally, GAMs have also found applications in time-series forecasting, with models such as Prophet <cite class="ltx_cite ltx_citemacro_citep">[Taylor and Letham, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib28" title="">2018</a>]</cite> and NeuralProphet <cite class="ltx_cite ltx_citemacro_citep">[Triebe et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib29" title="">2021</a>]</cite>. Interestingly, the 1-layer versions of the recently proposed Kolmogorov-Arnold Networks (KANs) <cite class="ltx_cite ltx_citemacro_citep">[Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib53" title="">2024</a>]</cite> may be viewed as GAMs with spline based shape functions.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Dataset Details</h2>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">In this section, we provide details on the datasets used in our empirical evaluations of GAMformer and other baselines in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4" title="4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">4</span></a> of the main paper.</p>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>TabPFN Test Datasets</h3>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">As test dataset, we used the 30 datasets used in <cite class="ltx_cite ltx_citemacro_citet">Hollmann et al. [<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>]</cite> which were obtained from OpenML <cite class="ltx_cite ltx_citemacro_citep">[Vanschoren et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib54" title="">2014</a>]</cite>. These were chosen because they contain up to 2000 samples, 100 features and 10 classes, show in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A2.T1" title="Table 1 ‣ B.1 TabPFN Test Datasets ‣ Appendix B Dataset Details ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="A2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Test dataset names and properties, taken from <cite class="ltx_cite ltx_citemacro_citet">Hollmann et al. [<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>]</cite>. Here <em class="ltx_emph ltx_font_italic" id="A2.T1.5.1">did</em> is the OpenML Dataset ID, <em class="ltx_emph ltx_font_italic" id="A2.T1.6.2">d</em> the number of features, <em class="ltx_emph ltx_font_italic" id="A2.T1.7.3">n</em> the number of instances, and <em class="ltx_emph ltx_font_italic" id="A2.T1.8.4">k</em> the number of classes in each dataset.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<table class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A2.T1.9">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T1.9.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T1.9.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">did</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T1.9.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">name</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T1.9.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">d</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T1.9.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">n</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T1.9.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">k</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T1.9.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="A2.T1.9.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">11</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T1.9.2.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">balance-scale</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T1.9.2.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T1.9.2.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">625</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T1.9.2.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">3</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.3.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">14</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">mfeat-fourier</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">77</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">2000</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.3.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.4.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.4.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">15</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.4.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">breast-w</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.4.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.4.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">699</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.4.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.5.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.5.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">16</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.5.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">mfeat-karhunen</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.5.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">65</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.5.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">2000</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.5.4.5" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.6.5">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.6.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">18</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.6.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">mfeat-morphological</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.6.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">7</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.6.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">2000</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.6.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.7.6">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.7.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">22</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.7.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">mfeat-zernike</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.7.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">48</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.7.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">2000</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.7.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.8.7">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.8.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">23</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.8.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">cmc</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.8.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.8.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">1473</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.8.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">3</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.9.8">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.9.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">29</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.9.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">credit-approval</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.9.8.3" style="padding-left:4.0pt;padding-right:4.0pt;">16</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.9.8.4" style="padding-left:4.0pt;padding-right:4.0pt;">690</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.9.8.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.10.9">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.10.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">31</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.10.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">credit-g</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.10.9.3" style="padding-left:4.0pt;padding-right:4.0pt;">21</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.10.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">1000</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.10.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.11.10">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.11.10.1" style="padding-left:4.0pt;padding-right:4.0pt;">37</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.11.10.2" style="padding-left:4.0pt;padding-right:4.0pt;">diabetes</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.11.10.3" style="padding-left:4.0pt;padding-right:4.0pt;">9</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.11.10.4" style="padding-left:4.0pt;padding-right:4.0pt;">768</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.11.10.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.12.11">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.12.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">50</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.12.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">tic-tac-toe</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.12.11.3" style="padding-left:4.0pt;padding-right:4.0pt;">10</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.12.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">958</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.12.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.13.12">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.13.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">54</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.13.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">vehicle</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.13.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">19</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.13.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">846</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.13.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">4</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.14.13">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.14.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">188</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.14.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">eucalyptus</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.14.13.3" style="padding-left:4.0pt;padding-right:4.0pt;">20</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.14.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">736</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.14.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">5</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.15.14">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.9.15.14.1" style="padding-left:4.0pt;padding-right:4.0pt;">458</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.9.15.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">analcatdata_authorship</th>
<td class="ltx_td ltx_align_right" id="A2.T1.9.15.14.3" style="padding-left:4.0pt;padding-right:4.0pt;">71</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.15.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">841</td>
<td class="ltx_td ltx_align_right" id="A2.T1.9.15.14.5" style="padding-left:4.0pt;padding-right:4.0pt;">4</td>
</tr>
<tr class="ltx_tr" id="A2.T1.9.16.15">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="A2.T1.9.16.15.1" style="padding-left:4.0pt;padding-right:4.0pt;">469</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A2.T1.9.16.15.2" style="padding-left:4.0pt;padding-right:4.0pt;">analcatdata_dmft</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T1.9.16.15.3" style="padding-left:4.0pt;padding-right:4.0pt;">5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T1.9.16.15.4" style="padding-left:4.0pt;padding-right:4.0pt;">797</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T1.9.16.15.5" style="padding-left:4.0pt;padding-right:4.0pt;">6</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle" id="A2.T1.10">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T1.10.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T1.10.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">did</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A2.T1.10.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">name</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T1.10.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">d</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T1.10.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">n</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="A2.T1.10.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">k</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T1.10.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_t" id="A2.T1.10.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">1049</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T1.10.2.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">pc4</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T1.10.2.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">38</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T1.10.2.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">1458</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A2.T1.10.2.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.3.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">1050</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">pc3</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">38</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">1563</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.3.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.4.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.4.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">1063</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.4.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">kc2</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.4.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">22</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.4.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">522</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.4.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.5.4">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.5.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">1068</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.5.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">pc1</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.5.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">22</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.5.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">1109</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.5.4.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.6.5">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.6.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">1462</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.6.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">banknote-authentication</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.6.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">5</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.6.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">1372</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.6.5.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.7.6">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.7.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">1464</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.7.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">blood-transfusion-…</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.7.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">5</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.7.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">748</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.7.6.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.8.7">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.8.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">1480</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.8.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">ilpd</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.8.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">11</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.8.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">583</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.8.7.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.9.8">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.9.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">1494</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.9.8.2" style="padding-left:4.0pt;padding-right:4.0pt;">qsar-biodeg</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.9.8.3" style="padding-left:4.0pt;padding-right:4.0pt;">42</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.9.8.4" style="padding-left:4.0pt;padding-right:4.0pt;">1055</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.9.8.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.10.9">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.10.9.1" style="padding-left:4.0pt;padding-right:4.0pt;">1510</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.10.9.2" style="padding-left:4.0pt;padding-right:4.0pt;">wdbc</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.10.9.3" style="padding-left:4.0pt;padding-right:4.0pt;">31</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.10.9.4" style="padding-left:4.0pt;padding-right:4.0pt;">569</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.10.9.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.11.10">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.11.10.1" style="padding-left:4.0pt;padding-right:4.0pt;">6332</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.11.10.2" style="padding-left:4.0pt;padding-right:4.0pt;">cylinder-bands</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.11.10.3" style="padding-left:4.0pt;padding-right:4.0pt;">40</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.11.10.4" style="padding-left:4.0pt;padding-right:4.0pt;">540</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.11.10.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.12.11">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.12.11.1" style="padding-left:4.0pt;padding-right:4.0pt;">23381</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.12.11.2" style="padding-left:4.0pt;padding-right:4.0pt;">dresses-sales</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.12.11.3" style="padding-left:4.0pt;padding-right:4.0pt;">13</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.12.11.4" style="padding-left:4.0pt;padding-right:4.0pt;">500</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.12.11.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.13.12">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.13.12.1" style="padding-left:4.0pt;padding-right:4.0pt;">40966</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.13.12.2" style="padding-left:4.0pt;padding-right:4.0pt;">MiceProtein</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.13.12.3" style="padding-left:4.0pt;padding-right:4.0pt;">82</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.13.12.4" style="padding-left:4.0pt;padding-right:4.0pt;">1080</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.13.12.5" style="padding-left:4.0pt;padding-right:4.0pt;">8</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.14.13">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.14.13.1" style="padding-left:4.0pt;padding-right:4.0pt;">40975</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.14.13.2" style="padding-left:4.0pt;padding-right:4.0pt;">car</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.14.13.3" style="padding-left:4.0pt;padding-right:4.0pt;">7</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.14.13.4" style="padding-left:4.0pt;padding-right:4.0pt;">1728</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.14.13.5" style="padding-left:4.0pt;padding-right:4.0pt;">4</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.15.14">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="A2.T1.10.15.14.1" style="padding-left:4.0pt;padding-right:4.0pt;">40982</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T1.10.15.14.2" style="padding-left:4.0pt;padding-right:4.0pt;">steel-plates-fault</th>
<td class="ltx_td ltx_align_right" id="A2.T1.10.15.14.3" style="padding-left:4.0pt;padding-right:4.0pt;">28</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.15.14.4" style="padding-left:4.0pt;padding-right:4.0pt;">1941</td>
<td class="ltx_td ltx_align_right" id="A2.T1.10.15.14.5" style="padding-left:4.0pt;padding-right:4.0pt;">7</td>
</tr>
<tr class="ltx_tr" id="A2.T1.10.16.15">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb" id="A2.T1.10.16.15.1" style="padding-left:4.0pt;padding-right:4.0pt;">40994</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A2.T1.10.16.15.2" style="padding-left:4.0pt;padding-right:4.0pt;">climate-model-…</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T1.10.16.15.3" style="padding-left:4.0pt;padding-right:4.0pt;">21</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T1.10.16.15.4" style="padding-left:4.0pt;padding-right:4.0pt;">540</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A2.T1.10.16.15.5" style="padding-left:4.0pt;padding-right:4.0pt;">2</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Binary Classification</h3>
<figure class="ltx_table" id="A2.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of GAMformer with other GAM variants and full complexity models on various datasets. We report ROC-AUC (%) (higher is better) and the standard error over 10 fold cross-validation. We also report results by pyGAM <cite class="ltx_cite ltx_citemacro_citep">[Servén and Brummitt, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib55" title="">2018</a>]</cite>.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T2.35" style="width:397.5pt;height:76.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-128.5pt,24.7pt) scale(0.607258349670131,0.607258349670131) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T2.35.35">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T2.35.35.36.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="A2.T2.35.35.36.1.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" colspan="5" id="A2.T2.35.35.36.1.2"><span class="ltx_text ltx_font_italic" id="A2.T2.35.35.36.1.2.1">GAMs</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" colspan="2" id="A2.T2.35.35.36.1.3"><span class="ltx_text ltx_font_italic" id="A2.T2.35.35.36.1.3.1">Full Complexity</span></th>
</tr>
<tr class="ltx_tr" id="A2.T2.35.35.37.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="A2.T2.35.35.37.2.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.2">GAMformer (ours)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.3">EBM (Main effects)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.4">Logistic Regression</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.5">pyGAM (Main effects)</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.6">EBM</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.7">XGBoost</th>
<th class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T2.35.35.37.2.8">Random Forest</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T2.7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A2.T2.7.7.7.8">Churn</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T2.1.1.1.1">81.69 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.1.1.1.1.m1.1"><semantics id="A2.T2.1.1.1.1.m1.1a"><mo id="A2.T2.1.1.1.1.m1.1.1" xref="A2.T2.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A2.T2.1.1.1.1.m1.1.1.cmml" xref="A2.T2.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.1.1.1.1.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T2.2.2.2.2">83.59 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.2.2.2.2.m1.1"><semantics id="A2.T2.2.2.2.2.m1.1a"><mo id="A2.T2.2.2.2.2.m1.1.1" xref="A2.T2.2.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.2.2.2.2.m1.1b"><csymbol cd="latexml" id="A2.T2.2.2.2.2.m1.1.1.cmml" xref="A2.T2.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.2.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.2.2.2.2.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T2.3.3.3.3">81.66 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.3.3.3.3.m1.1"><semantics id="A2.T2.3.3.3.3.m1.1a"><mo id="A2.T2.3.3.3.3.m1.1.1" xref="A2.T2.3.3.3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.3.3.3.3.m1.1b"><csymbol cd="latexml" id="A2.T2.3.3.3.3.m1.1.1.cmml" xref="A2.T2.3.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.3.3.3.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.3.3.3.3.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T2.4.4.4.4">82.03 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.4.4.4.4.m1.1"><semantics id="A2.T2.4.4.4.4.m1.1a"><mo id="A2.T2.4.4.4.4.m1.1.1" xref="A2.T2.4.4.4.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.4.4.4.4.m1.1b"><csymbol cd="latexml" id="A2.T2.4.4.4.4.m1.1.1.cmml" xref="A2.T2.4.4.4.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.4.4.4.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.4.4.4.4.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T2.5.5.5.5">83.68 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.5.5.5.5.m1.1"><semantics id="A2.T2.5.5.5.5.m1.1a"><mo id="A2.T2.5.5.5.5.m1.1.1" xref="A2.T2.5.5.5.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.5.5.5.5.m1.1b"><csymbol cd="latexml" id="A2.T2.5.5.5.5.m1.1.1.cmml" xref="A2.T2.5.5.5.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.5.5.5.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.5.5.5.5.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T2.6.6.6.6">83.53 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.6.6.6.6.m1.1"><semantics id="A2.T2.6.6.6.6.m1.1a"><mo id="A2.T2.6.6.6.6.m1.1.1" xref="A2.T2.6.6.6.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.6.6.6.6.m1.1b"><csymbol cd="latexml" id="A2.T2.6.6.6.6.m1.1.1.cmml" xref="A2.T2.6.6.6.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.6.6.6.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.6.6.6.6.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="A2.T2.7.7.7.7">82.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.7.7.7.7.m1.1"><semantics id="A2.T2.7.7.7.7.m1.1a"><mo id="A2.T2.7.7.7.7.m1.1.1" xref="A2.T2.7.7.7.7.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.7.7.7.7.m1.1b"><csymbol cd="latexml" id="A2.T2.7.7.7.7.m1.1.1.cmml" xref="A2.T2.7.7.7.7.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.7.7.7.7.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.7.7.7.7.m1.1d">±</annotation></semantics></math> 0.0</td>
</tr>
<tr class="ltx_tr" id="A2.T2.14.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.14.14.14.8">Support2</th>
<td class="ltx_td ltx_align_left" id="A2.T2.8.8.8.1">80.84 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.8.8.8.1.m1.1"><semantics id="A2.T2.8.8.8.1.m1.1a"><mo id="A2.T2.8.8.8.1.m1.1.1" xref="A2.T2.8.8.8.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.8.8.8.1.m1.1b"><csymbol cd="latexml" id="A2.T2.8.8.8.1.m1.1.1.cmml" xref="A2.T2.8.8.8.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.8.8.8.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.8.8.8.1.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left" id="A2.T2.9.9.9.2">82.36 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.9.9.9.2.m1.1"><semantics id="A2.T2.9.9.9.2.m1.1a"><mo id="A2.T2.9.9.9.2.m1.1.1" xref="A2.T2.9.9.9.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.9.9.9.2.m1.1b"><csymbol cd="latexml" id="A2.T2.9.9.9.2.m1.1.1.cmml" xref="A2.T2.9.9.9.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.9.9.9.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.9.9.9.2.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.10.10.10.3">81.1 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.10.10.10.3.m1.1"><semantics id="A2.T2.10.10.10.3.m1.1a"><mo id="A2.T2.10.10.10.3.m1.1.1" xref="A2.T2.10.10.10.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.10.10.10.3.m1.1b"><csymbol cd="latexml" id="A2.T2.10.10.10.3.m1.1.1.cmml" xref="A2.T2.10.10.10.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.10.10.10.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.10.10.10.3.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.11.11.11.4">81.74 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.11.11.11.4.m1.1"><semantics id="A2.T2.11.11.11.4.m1.1a"><mo id="A2.T2.11.11.11.4.m1.1.1" xref="A2.T2.11.11.11.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.11.11.11.4.m1.1b"><csymbol cd="latexml" id="A2.T2.11.11.11.4.m1.1.1.cmml" xref="A2.T2.11.11.11.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.11.11.11.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.11.11.11.4.m1.1d">±</annotation></semantics></math> 0.2</td>
<td class="ltx_td ltx_align_left" id="A2.T2.12.12.12.5">83.51 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.12.12.12.5.m1.1"><semantics id="A2.T2.12.12.12.5.m1.1a"><mo id="A2.T2.12.12.12.5.m1.1.1" xref="A2.T2.12.12.12.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.12.12.12.5.m1.1b"><csymbol cd="latexml" id="A2.T2.12.12.12.5.m1.1.1.cmml" xref="A2.T2.12.12.12.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.12.12.12.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.12.12.12.5.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.13.13.13.6">84.03 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.13.13.13.6.m1.1"><semantics id="A2.T2.13.13.13.6.m1.1a"><mo id="A2.T2.13.13.13.6.m1.1.1" xref="A2.T2.13.13.13.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.13.13.13.6.m1.1b"><csymbol cd="latexml" id="A2.T2.13.13.13.6.m1.1.1.cmml" xref="A2.T2.13.13.13.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.13.13.13.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.13.13.13.6.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A2.T2.14.14.14.7">83.93 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.14.14.14.7.m1.1"><semantics id="A2.T2.14.14.14.7.m1.1a"><mo id="A2.T2.14.14.14.7.m1.1.1" xref="A2.T2.14.14.14.7.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.14.14.14.7.m1.1b"><csymbol cd="latexml" id="A2.T2.14.14.14.7.m1.1.1.cmml" xref="A2.T2.14.14.14.7.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.14.14.14.7.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.14.14.14.7.m1.1d">±</annotation></semantics></math> 0.0</td>
</tr>
<tr class="ltx_tr" id="A2.T2.21.21.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.21.21.21.8">Adult</th>
<td class="ltx_td ltx_align_left" id="A2.T2.15.15.15.1">90.05 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.15.15.15.1.m1.1"><semantics id="A2.T2.15.15.15.1.m1.1a"><mo id="A2.T2.15.15.15.1.m1.1.1" xref="A2.T2.15.15.15.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.15.15.15.1.m1.1b"><csymbol cd="latexml" id="A2.T2.15.15.15.1.m1.1.1.cmml" xref="A2.T2.15.15.15.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.15.15.15.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.15.15.15.1.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.16.16.16.2">93.05 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.16.16.16.2.m1.1"><semantics id="A2.T2.16.16.16.2.m1.1a"><mo id="A2.T2.16.16.16.2.m1.1.1" xref="A2.T2.16.16.16.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.16.16.16.2.m1.1b"><csymbol cd="latexml" id="A2.T2.16.16.16.2.m1.1.1.cmml" xref="A2.T2.16.16.16.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.16.16.16.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.16.16.16.2.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.17.17.17.3">90.73 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.17.17.17.3.m1.1"><semantics id="A2.T2.17.17.17.3.m1.1a"><mo id="A2.T2.17.17.17.3.m1.1.1" xref="A2.T2.17.17.17.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.17.17.17.3.m1.1b"><csymbol cd="latexml" id="A2.T2.17.17.17.3.m1.1.1.cmml" xref="A2.T2.17.17.17.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.17.17.17.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.17.17.17.3.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.18.18.18.4">91.55 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.18.18.18.4.m1.1"><semantics id="A2.T2.18.18.18.4.m1.1a"><mo id="A2.T2.18.18.18.4.m1.1.1" xref="A2.T2.18.18.18.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.18.18.18.4.m1.1b"><csymbol cd="latexml" id="A2.T2.18.18.18.4.m1.1.1.cmml" xref="A2.T2.18.18.18.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.18.18.18.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.18.18.18.4.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.19.19.19.5">93.07 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.19.19.19.5.m1.1"><semantics id="A2.T2.19.19.19.5.m1.1a"><mo id="A2.T2.19.19.19.5.m1.1.1" xref="A2.T2.19.19.19.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.19.19.19.5.m1.1b"><csymbol cd="latexml" id="A2.T2.19.19.19.5.m1.1.1.cmml" xref="A2.T2.19.19.19.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.19.19.19.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.19.19.19.5.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.20.20.20.6">93.16 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.20.20.20.6.m1.1"><semantics id="A2.T2.20.20.20.6.m1.1a"><mo id="A2.T2.20.20.20.6.m1.1.1" xref="A2.T2.20.20.20.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.20.20.20.6.m1.1b"><csymbol cd="latexml" id="A2.T2.20.20.20.6.m1.1.1.cmml" xref="A2.T2.20.20.20.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.20.20.20.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.20.20.20.6.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A2.T2.21.21.21.7">91.8 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.21.21.21.7.m1.1"><semantics id="A2.T2.21.21.21.7.m1.1a"><mo id="A2.T2.21.21.21.7.m1.1.1" xref="A2.T2.21.21.21.7.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.21.21.21.7.m1.1b"><csymbol cd="latexml" id="A2.T2.21.21.21.7.m1.1.1.cmml" xref="A2.T2.21.21.21.7.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.21.21.21.7.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.21.21.21.7.m1.1d">±</annotation></semantics></math> 0.0</td>
</tr>
<tr class="ltx_tr" id="A2.T2.28.28.28">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A2.T2.28.28.28.8">MIMIC-2</th>
<td class="ltx_td ltx_align_left" id="A2.T2.22.22.22.1">82.22 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.22.22.22.1.m1.1"><semantics id="A2.T2.22.22.22.1.m1.1a"><mo id="A2.T2.22.22.22.1.m1.1.1" xref="A2.T2.22.22.22.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.22.22.22.1.m1.1b"><csymbol cd="latexml" id="A2.T2.22.22.22.1.m1.1.1.cmml" xref="A2.T2.22.22.22.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.22.22.22.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.22.22.22.1.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.23.23.23.2">85.15 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.23.23.23.2.m1.1"><semantics id="A2.T2.23.23.23.2.m1.1a"><mo id="A2.T2.23.23.23.2.m1.1.1" xref="A2.T2.23.23.23.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.23.23.23.2.m1.1b"><csymbol cd="latexml" id="A2.T2.23.23.23.2.m1.1.1.cmml" xref="A2.T2.23.23.23.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.23.23.23.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.23.23.23.2.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.24.24.24.3">81.62 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.24.24.24.3.m1.1"><semantics id="A2.T2.24.24.24.3.m1.1a"><mo id="A2.T2.24.24.24.3.m1.1.1" xref="A2.T2.24.24.24.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.24.24.24.3.m1.1b"><csymbol cd="latexml" id="A2.T2.24.24.24.3.m1.1.1.cmml" xref="A2.T2.24.24.24.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.24.24.24.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.24.24.24.3.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left" id="A2.T2.25.25.25.4">83.89 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.25.25.25.4.m1.1"><semantics id="A2.T2.25.25.25.4.m1.1a"><mo id="A2.T2.25.25.25.4.m1.1.1" xref="A2.T2.25.25.25.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.25.25.25.4.m1.1b"><csymbol cd="latexml" id="A2.T2.25.25.25.4.m1.1.1.cmml" xref="A2.T2.25.25.25.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.25.25.25.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.25.25.25.4.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left" id="A2.T2.26.26.26.5">86.36 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.26.26.26.5.m1.1"><semantics id="A2.T2.26.26.26.5.m1.1a"><mo id="A2.T2.26.26.26.5.m1.1.1" xref="A2.T2.26.26.26.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.26.26.26.5.m1.1b"><csymbol cd="latexml" id="A2.T2.26.26.26.5.m1.1.1.cmml" xref="A2.T2.26.26.26.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.26.26.26.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.26.26.26.5.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left" id="A2.T2.27.27.27.6">87.29 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.27.27.27.6.m1.1"><semantics id="A2.T2.27.27.27.6.m1.1a"><mo id="A2.T2.27.27.27.6.m1.1.1" xref="A2.T2.27.27.27.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.27.27.27.6.m1.1b"><csymbol cd="latexml" id="A2.T2.27.27.27.6.m1.1.1.cmml" xref="A2.T2.27.27.27.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.27.27.27.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.27.27.27.6.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="A2.T2.28.28.28.7">87.31 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.28.28.28.7.m1.1"><semantics id="A2.T2.28.28.28.7.m1.1a"><mo id="A2.T2.28.28.28.7.m1.1.1" xref="A2.T2.28.28.28.7.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.28.28.28.7.m1.1b"><csymbol cd="latexml" id="A2.T2.28.28.28.7.m1.1.1.cmml" xref="A2.T2.28.28.28.7.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.28.28.28.7.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.28.28.28.7.m1.1d">±</annotation></semantics></math> 0.0</td>
</tr>
<tr class="ltx_tr" id="A2.T2.35.35.35">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A2.T2.35.35.35.8">MIMIC-3</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T2.29.29.29.1">74.41 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.29.29.29.1.m1.1"><semantics id="A2.T2.29.29.29.1.m1.1a"><mo id="A2.T2.29.29.29.1.m1.1.1" xref="A2.T2.29.29.29.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.29.29.29.1.m1.1b"><csymbol cd="latexml" id="A2.T2.29.29.29.1.m1.1.1.cmml" xref="A2.T2.29.29.29.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.29.29.29.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.29.29.29.1.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T2.30.30.30.2">81.14 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.30.30.30.2.m1.1"><semantics id="A2.T2.30.30.30.2.m1.1a"><mo id="A2.T2.30.30.30.2.m1.1.1" xref="A2.T2.30.30.30.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.30.30.30.2.m1.1b"><csymbol cd="latexml" id="A2.T2.30.30.30.2.m1.1.1.cmml" xref="A2.T2.30.30.30.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.30.30.30.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.30.30.30.2.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T2.31.31.31.3">78.05 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.31.31.31.3.m1.1"><semantics id="A2.T2.31.31.31.3.m1.1a"><mo id="A2.T2.31.31.31.3.m1.1.1" xref="A2.T2.31.31.31.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.31.31.31.3.m1.1b"><csymbol cd="latexml" id="A2.T2.31.31.31.3.m1.1.1.cmml" xref="A2.T2.31.31.31.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.31.31.31.3.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.31.31.31.3.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T2.32.32.32.4">79.95 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.32.32.32.4.m1.1"><semantics id="A2.T2.32.32.32.4.m1.1a"><mo id="A2.T2.32.32.32.4.m1.1.1" xref="A2.T2.32.32.32.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.32.32.32.4.m1.1b"><csymbol cd="latexml" id="A2.T2.32.32.32.4.m1.1.1.cmml" xref="A2.T2.32.32.32.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.32.32.32.4.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.32.32.32.4.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T2.33.33.33.5">82.52 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.33.33.33.5.m1.1"><semantics id="A2.T2.33.33.33.5.m1.1a"><mo id="A2.T2.33.33.33.5.m1.1.1" xref="A2.T2.33.33.33.5.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.33.33.33.5.m1.1b"><csymbol cd="latexml" id="A2.T2.33.33.33.5.m1.1.1.cmml" xref="A2.T2.33.33.33.5.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.33.33.33.5.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.33.33.33.5.m1.1d">±</annotation></semantics></math> 0.1</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T2.34.34.34.6">83.32 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.34.34.34.6.m1.1"><semantics id="A2.T2.34.34.34.6.m1.1a"><mo id="A2.T2.34.34.34.6.m1.1.1" xref="A2.T2.34.34.34.6.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.34.34.34.6.m1.1b"><csymbol cd="latexml" id="A2.T2.34.34.34.6.m1.1.1.cmml" xref="A2.T2.34.34.34.6.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.34.34.34.6.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.34.34.34.6.m1.1d">±</annotation></semantics></math> 0.0</td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="A2.T2.35.35.35.7">81.28 <math alttext="\pm" class="ltx_Math" display="inline" id="A2.T2.35.35.35.7.m1.1"><semantics id="A2.T2.35.35.35.7.m1.1a"><mo id="A2.T2.35.35.35.7.m1.1.1" xref="A2.T2.35.35.35.7.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A2.T2.35.35.35.7.m1.1b"><csymbol cd="latexml" id="A2.T2.35.35.35.7.m1.1.1.cmml" xref="A2.T2.35.35.35.7.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.35.35.35.7.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A2.T2.35.35.35.7.m1.1d">±</annotation></semantics></math> 0.1</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Churn dataset.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px1.p1.1">The <a class="ltx_ref ltx_href" href="https://www.kaggle.com/datasets/blastchar/telco-customer-churn" title="">Telco Customer Churn Dataset</a> is a binary classification dataset for predicting potential subscription churners in a telecom company, containing customer information and churn-related features.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Adult dataset.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px2.p1.1">The Adult dataset <cite class="ltx_cite ltx_citemacro_cite">Dua and Graff [<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib56" title="">2017</a>]</cite>, also known as the “Census Income” dataset, is a widely-used benchmark for binary classification, predicting whether an individual’s annual income exceeds $50,000 based on 14 attributes from the 1994 United States Census Bureau data.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">MIMIC-II dataset.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px3.p1.1">The MIMIC-II dataset <cite class="ltx_cite ltx_citemacro_cite">Lee et al. [<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib57" title="">2011b</a>]</cite> is a publicly-available database of clinical data from diverse ICU patients, integrating demographics, vital signs, lab results, medications, procedures, notes, and imaging reports, along with mortality outcomes.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">MIMIC-III dataset.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px4.p1.1">The MIMIC-III dataset <cite class="ltx_cite ltx_citemacro_cite">Johnson et al. [<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib58" title="">2016</a>]</cite> expands on MIMIC-II, with a larger patient cohort, more recent records, enhanced data granularity, and the inclusion of free-text imaging report interpretations.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS2.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">SUPPORT2 dataset.</h4>
<div class="ltx_para ltx_noindent" id="A2.SS2.SSS0.Px5.p1">
<p class="ltx_p" id="A2.SS2.SSS0.Px5.p1.1">The SUPPORT2 dataset <cite class="ltx_cite ltx_citemacro_cite">Connors Jr et al. [<a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib59" title="">1996</a>]</cite> contains medical information from critically ill hospitalized adults, compiled to study the relationships between medical decision-making, patient preferences, and treatment outcomes, with variables spanning demographics, physiology, diagnostics, treatments, and survival/quality of life outcomes.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Properties of GAMformer</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Data Scaling</h3>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">To assess GAMformer’s ability to generalize to datasets containing more datapoints than it saw during training, i.e. larger context sizes, we conducted an experiment that varied the number of training data points and evaluated the impact on ROC-AUC performance using a consistent validation split. To ensure the robustness of our findings, we sampled training datasets three times with replacement for each training size. The results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.F8" title="Figure 8 ‣ C.1 Data Scaling ‣ Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">8</span></a> demonstrate that GAMformer’s ROC-AUC improves across datasets when the number of training examples is up to twice the number of training examples seen during training. For comparison, we also evaluated the performance of EBMs under the same conditions. While EBMs also exhibited improvements in ROC-AUC with increased training data, they achieved higher accuracy when provided with a larger number of examples. This observation highlights a limitation of GAMformer in its ability to fully leverage additional training samples.</p>
</div>
<figure class="ltx_figure" id="A3.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="438" id="A3.F8.sf1.g1" src="x14.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>MIMIC-II</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="508" id="A3.F8.sf2.g1" src="x15.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>MIMIC-III</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="506" id="A3.F8.sf3.g1" src="x16.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span>Adult</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="262" id="A3.F8.sf4.g1" src="x17.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Support 2 <span class="ltx_text" id="A3.F8.sf4.2.1" style="color:#FFFFFF;">———————</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Demonstration of the ability of GAMformer to scale beyond the datapoints seen during training while leveraging the additional data points to increase its performance. The dashed vertical line denotes the number of in-context examples seen during training (500).</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Class Imbalance</h3>
<figure class="ltx_figure" id="A3.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel" id="A3.F9.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="517" id="A3.F9.sf1.g1" src="x18.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Imbalanced Data</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel" id="A3.F9.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="288" id="A3.F9.sf2.g1" src="x19.png" width="548"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Noisy Labels <span class="ltx_text" id="A3.F9.sf2.2.1" style="color:#FFFFFF;">—————</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Comparison of GAMformer and EBMs in terms of (a) performance on class imbalanced data and (b) robustness to noisy labels. The shaded areas represent the 5% and 95% confidence intervals estimated using 1000 bootstrap samples.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">To compare GAMformer’s sensitivity to class imbalance with that of EBMs, we conduct the following analysis. First, we sample 300 data points from two centroids in a 20-dimensional feature space, creating a binary classification problem. We then vary the ratio of the two classes to introduce increasing levels of imbalance in the sampled data. Next, we split the data into train and test sets using a 75% to 25% split and evaluate the performance using the AUC-ROC metric. We repeat the experiment 10 times for each data ratio. Our results are shown in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.F9.sf1" title="In Figure 9 ‣ C.2 Class Imbalance ‣ Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">9(a)</span></a>, the shaded area are the 5%, 95% confidence intervals estimated using 1000 bootstrap samples. We see that GAMformer performs on average better than EBMs in this setting and shows no inherent sensitivity to class imbalance.</p>
</div>
</section>
<section class="ltx_subsection" id="A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Noise Robustness</h3>
<div class="ltx_para ltx_noindent" id="A3.SS3.p1">
<p class="ltx_p" id="A3.SS3.p1.1">To gain a deeper understanding of GAMformers’ sensitivity to noisy or incorrect labels, we conducted an experiment similar to the one described in <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.SS2" title="C.2 Class Imbalance ‣ Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">C.2</span></a>. We generated 300 data points and randomly perturbed the labels in the train split with increasing probability (75%, 25% train/test split), repeating each experiment 10 times. <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#A3.F9.sf2" title="In Figure 9 ‣ C.2 Class Imbalance ‣ Appendix C Properties of GAMformer ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">9(b)</span></a> illustrates our findings. Once again, we observed that GAMformer exhibits a sensitivity to noisy labels comparable to that of EBMs.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Synthetic Data Priors</h2>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">We use the same synthetic data generation process proposed in Prior-Data-Fitted Networks (PFNs) <cite class="ltx_cite ltx_citemacro_citep">[Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>, Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib18" title="">2022</a>]</cite> and provide a brief summary of the process.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">TabPFN is trained on two synthetic data priors, which are mixed during training.TabPFN introduced a synthetic data prior based on Structural Causal Models (SCMs). SCMs are particularly suitable for modeling tabular data as they capture causal relationships between columns, a strong prior in human reasoning. An SCM comprises a set of structural assignments (mechanisms) where each mechanism is defined by a deterministic function and a noise variable, structured within a Directed Acyclic Graph (DAG). The causal relationships are represented by directed edges from causes to effects, facilitating the modeling of complex dependencies within the data.
To instantiate a PFN prior based on SCMs, one defines a sampling procedure to create supervised learning tasks. Each dataset is generated from a randomly sampled SCM, including its DAG structure and deterministic functions. Nodes in the causal graph are selected to represent features and targets, and samples are generated by propagating noise variables through the graph. This process results in features and targets that are conditionally dependent through the DAG structure, capturing both forward and backward causation <cite class="ltx_cite ltx_citemacro_citep">[Hollmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib17" title="">2023</a>]</cite>. This allows for the generation of diverse datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p3">
<p class="ltx_p" id="A4.p3.1">The second prior samples of synthetic data using Gaussian Processes (GPs) <cite class="ltx_cite ltx_citemacro_citep">[Rasmussen and Williams, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib60" title="">2006</a>]</cite> with a constant mean function and a radial basis function (RBF) kernel to define the covariance structure. Hyperparameters such as noise level, output scale, and length scale are sampled from predefined distributions to introduce variability. Depending on the configuration, input data points can be sampled uniformly, normally, or as equidistant points and the target column is generated by passing the input data through the GP. This prior gives the model the ability to learn smoother functions.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p4">
<p class="ltx_p" id="A4.p4.1">For multi-class prediction, scalar labels are transformed into discrete class labels by partitioning the scalar values into intervals corresponding to different classes, ensuring the synthetic data is suitable for imbalanced multi-class classification tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p5">
<p class="ltx_p" id="A4.p5.2">Finally, both priors are combined by sampling batches of data from each prior with different probabilities during training. In all of our experiments we sampled from the SCM and GP prior with probability <math alttext="0.96" class="ltx_Math" display="inline" id="A4.p5.1.m1.1"><semantics id="A4.p5.1.m1.1a"><mn id="A4.p5.1.m1.1.1" xref="A4.p5.1.m1.1.1.cmml">0.96</mn><annotation-xml encoding="MathML-Content" id="A4.p5.1.m1.1b"><cn id="A4.p5.1.m1.1.1.cmml" type="float" xref="A4.p5.1.m1.1.1">0.96</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p5.1.m1.1c">0.96</annotation><annotation encoding="application/x-llamapun" id="A4.p5.1.m1.1d">0.96</annotation></semantics></math> and <math alttext="0.04" class="ltx_Math" display="inline" id="A4.p5.2.m2.1"><semantics id="A4.p5.2.m2.1a"><mn id="A4.p5.2.m2.1.1" xref="A4.p5.2.m2.1.1.cmml">0.04</mn><annotation-xml encoding="MathML-Content" id="A4.p5.2.m2.1b"><cn id="A4.p5.2.m2.1.1.cmml" type="float" xref="A4.p5.2.m2.1.1">0.04</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p5.2.m2.1c">0.04</annotation><annotation encoding="application/x-llamapun" id="A4.p5.2.m2.1d">0.04</annotation></semantics></math>, respectively.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Training Details</h2>
<div class="ltx_para ltx_noindent" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">In GAMformer, we used a transformer model with 12 hidden layers, 512 embedding size and 4 heads per attention. To bin the shape functions and all features we used 64 bins.
For training, we use the AdamW <cite class="ltx_cite ltx_citemacro_citep">[Loshchilov and Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib61" title="">2019</a>]</cite> optimizer (<math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="A5.p1.1.m1.1"><semantics id="A5.p1.1.m1.1a"><mrow id="A5.p1.1.m1.1.1" xref="A5.p1.1.m1.1.1.cmml"><msub id="A5.p1.1.m1.1.1.2" xref="A5.p1.1.m1.1.1.2.cmml"><mi id="A5.p1.1.m1.1.1.2.2" xref="A5.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="A5.p1.1.m1.1.1.2.3" xref="A5.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="A5.p1.1.m1.1.1.1" xref="A5.p1.1.m1.1.1.1.cmml">=</mo><mn id="A5.p1.1.m1.1.1.3" xref="A5.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.p1.1.m1.1b"><apply id="A5.p1.1.m1.1.1.cmml" xref="A5.p1.1.m1.1.1"><eq id="A5.p1.1.m1.1.1.1.cmml" xref="A5.p1.1.m1.1.1.1"></eq><apply id="A5.p1.1.m1.1.1.2.cmml" xref="A5.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A5.p1.1.m1.1.1.2.1.cmml" xref="A5.p1.1.m1.1.1.2">subscript</csymbol><ci id="A5.p1.1.m1.1.1.2.2.cmml" xref="A5.p1.1.m1.1.1.2.2">𝛽</ci><cn id="A5.p1.1.m1.1.1.2.3.cmml" type="integer" xref="A5.p1.1.m1.1.1.2.3">1</cn></apply><cn id="A5.p1.1.m1.1.1.3.cmml" type="float" xref="A5.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.1.m1.1c">\beta_{1}=0.9</annotation><annotation encoding="application/x-llamapun" id="A5.p1.1.m1.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9</annotation></semantics></math>) and cosine learning rate schedule with initial learning rate of 3e-5, 20 warm up epochs and minimum learning rate of 1e-8 for 25 days on a A100 GPU with 80Gb of memory. We used mixed precision training. Each epoch (arbitrarily) consists of 65536 synthetic datasets; the model trained for 1800 epochs, meaning it saw over 100M synthetic datasets. We used a batch size of 8, that we doubled at epoch 20, 50, 200 and 1000. Each synthetic dataset consisted of 500 samples that were split into training and test portions using using a uniform sampling of the training fraction, and used a number of features drawn uniformly between 1 and 10.</p>
</div>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Higher-order effects</h2>
<div class="ltx_para ltx_noindent" id="A6.p1">
<p class="ltx_p" id="A6.p1.3">To handle higher-order effects, we compute the best pairs with the FAST algorithm <cite class="ltx_cite ltx_citemacro_citep">[Lou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib10" title="">2013</a>]</cite> and evaluate GAMformer on the top pairs using the following ratios of features:</p>
<table class="ltx_equation ltx_eqn_table" id="A6.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{P}=[0.01p,0.05p,0.1p,0.2p,0.4p,0.8p,0.9p]" class="ltx_Math" display="block" id="A6.Ex1.m1.7"><semantics id="A6.Ex1.m1.7a"><mrow id="A6.Ex1.m1.7.7" xref="A6.Ex1.m1.7.7.cmml"><mi class="ltx_font_mathcaligraphic" id="A6.Ex1.m1.7.7.9" xref="A6.Ex1.m1.7.7.9.cmml">𝒫</mi><mo id="A6.Ex1.m1.7.7.8" xref="A6.Ex1.m1.7.7.8.cmml">=</mo><mrow id="A6.Ex1.m1.7.7.7.7" xref="A6.Ex1.m1.7.7.7.8.cmml"><mo id="A6.Ex1.m1.7.7.7.7.8" stretchy="false" xref="A6.Ex1.m1.7.7.7.8.cmml">[</mo><mrow id="A6.Ex1.m1.1.1.1.1.1" xref="A6.Ex1.m1.1.1.1.1.1.cmml"><mn id="A6.Ex1.m1.1.1.1.1.1.2" xref="A6.Ex1.m1.1.1.1.1.1.2.cmml">0.01</mn><mo id="A6.Ex1.m1.1.1.1.1.1.1" xref="A6.Ex1.m1.1.1.1.1.1.1.cmml">⁢</mo><mi id="A6.Ex1.m1.1.1.1.1.1.3" xref="A6.Ex1.m1.1.1.1.1.1.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.9" xref="A6.Ex1.m1.7.7.7.8.cmml">,</mo><mrow id="A6.Ex1.m1.2.2.2.2.2" xref="A6.Ex1.m1.2.2.2.2.2.cmml"><mn id="A6.Ex1.m1.2.2.2.2.2.2" xref="A6.Ex1.m1.2.2.2.2.2.2.cmml">0.05</mn><mo id="A6.Ex1.m1.2.2.2.2.2.1" xref="A6.Ex1.m1.2.2.2.2.2.1.cmml">⁢</mo><mi id="A6.Ex1.m1.2.2.2.2.2.3" xref="A6.Ex1.m1.2.2.2.2.2.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.10" xref="A6.Ex1.m1.7.7.7.8.cmml">,</mo><mrow id="A6.Ex1.m1.3.3.3.3.3" xref="A6.Ex1.m1.3.3.3.3.3.cmml"><mn id="A6.Ex1.m1.3.3.3.3.3.2" xref="A6.Ex1.m1.3.3.3.3.3.2.cmml">0.1</mn><mo id="A6.Ex1.m1.3.3.3.3.3.1" xref="A6.Ex1.m1.3.3.3.3.3.1.cmml">⁢</mo><mi id="A6.Ex1.m1.3.3.3.3.3.3" xref="A6.Ex1.m1.3.3.3.3.3.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.11" xref="A6.Ex1.m1.7.7.7.8.cmml">,</mo><mrow id="A6.Ex1.m1.4.4.4.4.4" xref="A6.Ex1.m1.4.4.4.4.4.cmml"><mn id="A6.Ex1.m1.4.4.4.4.4.2" xref="A6.Ex1.m1.4.4.4.4.4.2.cmml">0.2</mn><mo id="A6.Ex1.m1.4.4.4.4.4.1" xref="A6.Ex1.m1.4.4.4.4.4.1.cmml">⁢</mo><mi id="A6.Ex1.m1.4.4.4.4.4.3" xref="A6.Ex1.m1.4.4.4.4.4.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.12" xref="A6.Ex1.m1.7.7.7.8.cmml">,</mo><mrow id="A6.Ex1.m1.5.5.5.5.5" xref="A6.Ex1.m1.5.5.5.5.5.cmml"><mn id="A6.Ex1.m1.5.5.5.5.5.2" xref="A6.Ex1.m1.5.5.5.5.5.2.cmml">0.4</mn><mo id="A6.Ex1.m1.5.5.5.5.5.1" xref="A6.Ex1.m1.5.5.5.5.5.1.cmml">⁢</mo><mi id="A6.Ex1.m1.5.5.5.5.5.3" xref="A6.Ex1.m1.5.5.5.5.5.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.13" xref="A6.Ex1.m1.7.7.7.8.cmml">,</mo><mrow id="A6.Ex1.m1.6.6.6.6.6" xref="A6.Ex1.m1.6.6.6.6.6.cmml"><mn id="A6.Ex1.m1.6.6.6.6.6.2" xref="A6.Ex1.m1.6.6.6.6.6.2.cmml">0.8</mn><mo id="A6.Ex1.m1.6.6.6.6.6.1" xref="A6.Ex1.m1.6.6.6.6.6.1.cmml">⁢</mo><mi id="A6.Ex1.m1.6.6.6.6.6.3" xref="A6.Ex1.m1.6.6.6.6.6.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.14" xref="A6.Ex1.m1.7.7.7.8.cmml">,</mo><mrow id="A6.Ex1.m1.7.7.7.7.7" xref="A6.Ex1.m1.7.7.7.7.7.cmml"><mn id="A6.Ex1.m1.7.7.7.7.7.2" xref="A6.Ex1.m1.7.7.7.7.7.2.cmml">0.9</mn><mo id="A6.Ex1.m1.7.7.7.7.7.1" xref="A6.Ex1.m1.7.7.7.7.7.1.cmml">⁢</mo><mi id="A6.Ex1.m1.7.7.7.7.7.3" xref="A6.Ex1.m1.7.7.7.7.7.3.cmml">p</mi></mrow><mo id="A6.Ex1.m1.7.7.7.7.15" stretchy="false" xref="A6.Ex1.m1.7.7.7.8.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.Ex1.m1.7b"><apply id="A6.Ex1.m1.7.7.cmml" xref="A6.Ex1.m1.7.7"><eq id="A6.Ex1.m1.7.7.8.cmml" xref="A6.Ex1.m1.7.7.8"></eq><ci id="A6.Ex1.m1.7.7.9.cmml" xref="A6.Ex1.m1.7.7.9">𝒫</ci><list id="A6.Ex1.m1.7.7.7.8.cmml" xref="A6.Ex1.m1.7.7.7.7"><apply id="A6.Ex1.m1.1.1.1.1.1.cmml" xref="A6.Ex1.m1.1.1.1.1.1"><times id="A6.Ex1.m1.1.1.1.1.1.1.cmml" xref="A6.Ex1.m1.1.1.1.1.1.1"></times><cn id="A6.Ex1.m1.1.1.1.1.1.2.cmml" type="float" xref="A6.Ex1.m1.1.1.1.1.1.2">0.01</cn><ci id="A6.Ex1.m1.1.1.1.1.1.3.cmml" xref="A6.Ex1.m1.1.1.1.1.1.3">𝑝</ci></apply><apply id="A6.Ex1.m1.2.2.2.2.2.cmml" xref="A6.Ex1.m1.2.2.2.2.2"><times id="A6.Ex1.m1.2.2.2.2.2.1.cmml" xref="A6.Ex1.m1.2.2.2.2.2.1"></times><cn id="A6.Ex1.m1.2.2.2.2.2.2.cmml" type="float" xref="A6.Ex1.m1.2.2.2.2.2.2">0.05</cn><ci id="A6.Ex1.m1.2.2.2.2.2.3.cmml" xref="A6.Ex1.m1.2.2.2.2.2.3">𝑝</ci></apply><apply id="A6.Ex1.m1.3.3.3.3.3.cmml" xref="A6.Ex1.m1.3.3.3.3.3"><times id="A6.Ex1.m1.3.3.3.3.3.1.cmml" xref="A6.Ex1.m1.3.3.3.3.3.1"></times><cn id="A6.Ex1.m1.3.3.3.3.3.2.cmml" type="float" xref="A6.Ex1.m1.3.3.3.3.3.2">0.1</cn><ci id="A6.Ex1.m1.3.3.3.3.3.3.cmml" xref="A6.Ex1.m1.3.3.3.3.3.3">𝑝</ci></apply><apply id="A6.Ex1.m1.4.4.4.4.4.cmml" xref="A6.Ex1.m1.4.4.4.4.4"><times id="A6.Ex1.m1.4.4.4.4.4.1.cmml" xref="A6.Ex1.m1.4.4.4.4.4.1"></times><cn id="A6.Ex1.m1.4.4.4.4.4.2.cmml" type="float" xref="A6.Ex1.m1.4.4.4.4.4.2">0.2</cn><ci id="A6.Ex1.m1.4.4.4.4.4.3.cmml" xref="A6.Ex1.m1.4.4.4.4.4.3">𝑝</ci></apply><apply id="A6.Ex1.m1.5.5.5.5.5.cmml" xref="A6.Ex1.m1.5.5.5.5.5"><times id="A6.Ex1.m1.5.5.5.5.5.1.cmml" xref="A6.Ex1.m1.5.5.5.5.5.1"></times><cn id="A6.Ex1.m1.5.5.5.5.5.2.cmml" type="float" xref="A6.Ex1.m1.5.5.5.5.5.2">0.4</cn><ci id="A6.Ex1.m1.5.5.5.5.5.3.cmml" xref="A6.Ex1.m1.5.5.5.5.5.3">𝑝</ci></apply><apply id="A6.Ex1.m1.6.6.6.6.6.cmml" xref="A6.Ex1.m1.6.6.6.6.6"><times id="A6.Ex1.m1.6.6.6.6.6.1.cmml" xref="A6.Ex1.m1.6.6.6.6.6.1"></times><cn id="A6.Ex1.m1.6.6.6.6.6.2.cmml" type="float" xref="A6.Ex1.m1.6.6.6.6.6.2">0.8</cn><ci id="A6.Ex1.m1.6.6.6.6.6.3.cmml" xref="A6.Ex1.m1.6.6.6.6.6.3">𝑝</ci></apply><apply id="A6.Ex1.m1.7.7.7.7.7.cmml" xref="A6.Ex1.m1.7.7.7.7.7"><times id="A6.Ex1.m1.7.7.7.7.7.1.cmml" xref="A6.Ex1.m1.7.7.7.7.7.1"></times><cn id="A6.Ex1.m1.7.7.7.7.7.2.cmml" type="float" xref="A6.Ex1.m1.7.7.7.7.7.2">0.9</cn><ci id="A6.Ex1.m1.7.7.7.7.7.3.cmml" xref="A6.Ex1.m1.7.7.7.7.7.3">𝑝</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.Ex1.m1.7c">\mathcal{P}=[0.01p,0.05p,0.1p,0.2p,0.4p,0.8p,0.9p]</annotation><annotation encoding="application/x-llamapun" id="A6.Ex1.m1.7d">caligraphic_P = [ 0.01 italic_p , 0.05 italic_p , 0.1 italic_p , 0.2 italic_p , 0.4 italic_p , 0.8 italic_p , 0.9 italic_p ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A6.p1.2">where we recall that <math alttext="p" class="ltx_Math" display="inline" id="A6.p1.1.m1.1"><semantics id="A6.p1.1.m1.1a"><mi id="A6.p1.1.m1.1.1" xref="A6.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A6.p1.1.m1.1b"><ci id="A6.p1.1.m1.1.1.cmml" xref="A6.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A6.p1.1.m1.1d">italic_p</annotation></semantics></math> denotes the number of features. We round off each ratio to determine the number of target pair features, evaluate performance on hold-out validation data from the training set, and select the number of pairs with the best validation performance. The model is then fitted on the entire training dataset. This involves doing <math alttext="|\mathcal{P}|+1" class="ltx_Math" display="inline" id="A6.p1.2.m2.1"><semantics id="A6.p1.2.m2.1a"><mrow id="A6.p1.2.m2.1.2" xref="A6.p1.2.m2.1.2.cmml"><mrow id="A6.p1.2.m2.1.2.2.2" xref="A6.p1.2.m2.1.2.2.1.cmml"><mo id="A6.p1.2.m2.1.2.2.2.1" stretchy="false" xref="A6.p1.2.m2.1.2.2.1.1.cmml">|</mo><mi class="ltx_font_mathcaligraphic" id="A6.p1.2.m2.1.1" xref="A6.p1.2.m2.1.1.cmml">𝒫</mi><mo id="A6.p1.2.m2.1.2.2.2.2" stretchy="false" xref="A6.p1.2.m2.1.2.2.1.1.cmml">|</mo></mrow><mo id="A6.p1.2.m2.1.2.1" xref="A6.p1.2.m2.1.2.1.cmml">+</mo><mn id="A6.p1.2.m2.1.2.3" xref="A6.p1.2.m2.1.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.p1.2.m2.1b"><apply id="A6.p1.2.m2.1.2.cmml" xref="A6.p1.2.m2.1.2"><plus id="A6.p1.2.m2.1.2.1.cmml" xref="A6.p1.2.m2.1.2.1"></plus><apply id="A6.p1.2.m2.1.2.2.1.cmml" xref="A6.p1.2.m2.1.2.2.2"><abs id="A6.p1.2.m2.1.2.2.1.1.cmml" xref="A6.p1.2.m2.1.2.2.2.1"></abs><ci id="A6.p1.2.m2.1.1.cmml" xref="A6.p1.2.m2.1.1">𝒫</ci></apply><cn id="A6.p1.2.m2.1.2.3.cmml" type="integer" xref="A6.p1.2.m2.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.2.m2.1c">|\mathcal{P}|+1</annotation><annotation encoding="application/x-llamapun" id="A6.p1.2.m2.1d">| caligraphic_P | + 1</annotation></semantics></math> forward passes, which is unproblematic as doing one forward pass is very fast, even on a CPU. One could also vectorialize all computations which we do not do given the low fitting time.

<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Shape Functions</h2>
<div class="ltx_para ltx_noindent" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">In this section, we show complementary results on the shape functions estimates from GAMformer and EBM (main effects only) on the MIMIC-II <cite class="ltx_cite ltx_citemacro_citep">[Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#bib.bib46" title="">2011a</a>]</cite> (complementary to the plots in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04560v1#S4.F7" title="Figure 7 ‣ 4.3 Case Study: Intensive Care Unit Mortality Risk ‣ 4 Experiments ‣ GAMformer: In-Context Learning for Generalized Additive Models"><span class="ltx_text ltx_ref_tag">7</span></a>) and on the MIMIC-III datasets.</p>
</div>
<section class="ltx_subsection" id="A7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>MIMIC-II dataset</h3>
<figure class="ltx_figure" id="A7.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F10.g1" src="x20.png" width="128"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F10.g2" src="x21.png" width="111"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F10.g3" src="x22.png" width="101"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="107" id="A7.F10.g4" src="x23.png" width="178"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="104" id="A7.F10.g5" src="x24.png" width="129"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F10.g6" src="x25.png" width="110"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F10.g7" src="x26.png" width="108"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="103" id="A7.F10.g8" src="x27.png" width="178"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="108" id="A7.F10.g9" src="x28.png" width="133"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="107" id="A7.F10.g10" src="x29.png" width="99"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="106" id="A7.F10.g11" src="x30.png" width="110"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="107" id="A7.F10.g12" src="x31.png" width="178"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="101" id="A7.F10.g13" src="x32.png" width="187"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>The remaining shape functions derived from GAMformer and EBMs on the <span class="ltx_text ltx_font_bold" id="A7.F10.2.1">MIMIC-II dataset</span> for critical clinical variables. The plot above each figure shows the data density. There are interesting differences between the EBM and GAMformer shape plots for several of the categorical variables. Although different GAM algorithms do not usually learn identical functions, we are investigating to better understand these differences.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>MIMIC-III dataset</h3>
<figure class="ltx_figure" id="A7.F11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="103" id="A7.F11.g1" src="x33.png" width="128"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="103" id="A7.F11.g2" src="x34.png" width="104"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="102" id="A7.F11.g3" src="x35.png" width="101"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="103" id="A7.F11.g4" src="x36.png" width="178"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="101" id="A7.F11.g5" src="x37.png" width="128"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="101" id="A7.F11.g6" src="x38.png" width="104"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="99" id="A7.F11.g7" src="x39.png" width="104"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="102" id="A7.F11.g8" src="x40.png" width="173"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="107" id="A7.F11.g9" src="x41.png" width="127"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="106" id="A7.F11.g10" src="x42.png" width="110"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="107" id="A7.F11.g11" src="x43.png" width="112"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="107" id="A7.F11.g12" src="x44.png" width="178"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="105" id="A7.F11.g13" src="x45.png" width="134"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F11.g14" src="x46.png" width="104"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F11.g15" src="x47.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="105" id="A7.F11.g16" src="x48.png" width="175"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="104" id="A7.F11.g17" src="x49.png" width="130"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F11.g18" src="x50.png" width="106"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F11.g19" src="x51.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="106" id="A7.F11.g20" src="x52.png" width="175"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F11.g21" src="x53.png" width="130"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F11.g22" src="x54.png" width="106"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F11.g23" src="x55.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="106" id="A7.F11.g24" src="x56.png" width="173"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="104" id="A7.F11.g25" src="x57.png" width="130"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F11.g26" src="x58.png" width="106"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F11.g27" src="x59.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="104" id="A7.F11.g28" src="x60.png" width="174"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>The shape functions derived from GAMformer and EBMs on the <span class="ltx_text ltx_font_bold" id="A7.F11.2.1">MIMIC-III dataset</span> for critical clinical variables. The plot above each figure shows the data density. The results are based on 30 models for both GAMformer and EBMs, each fitted on 10,000 randomly selected data points. There are interesting differences between the EBM and GAMformer shape plots for several of the categorical variables. Although different GAM algorithms do not usually learn identical functions, we are investigating to better understand these differences.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_figure" id="A7.F12">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F12.g1" src="x61.png" width="125"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F12.g2" src="x62.png" width="108"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F12.g3" src="x63.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="104" id="A7.F12.g4" src="x64.png" width="174"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="103" id="A7.F12.g5" src="x65.png" width="129"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F12.g6" src="x66.png" width="108"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F12.g7" src="x67.png" width="113"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="107" id="A7.F12.g8" src="x68.png" width="173"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="106" id="A7.F12.g9" src="x69.png" width="134"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F12.g10" src="x70.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F12.g11" src="x71.png" width="107"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="106" id="A7.F12.g12" src="x72.png" width="179"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="105" id="A7.F12.g13" src="x73.png" width="132"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="104" id="A7.F12.g14" src="x74.png" width="101"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="105" id="A7.F12.g15" src="x75.png" width="110"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="105" id="A7.F12.g16" src="x76.png" width="179"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="106" id="A7.F12.g17" src="x77.png" width="132"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="106" id="A7.F12.g18" src="x78.png" width="108"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="107" id="A7.F12.g19" src="x79.png" width="112"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="108" id="A7.F12.g20" src="x80.png" width="179"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="107" id="A7.F12.g21" src="x81.png" width="135"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="106" id="A7.F12.g22" src="x82.png" width="103"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="108" id="A7.F12.g23" src="x83.png" width="110"/></div>
<div class="ltx_flex_cell ltx_flex_size_4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="107" id="A7.F12.g24" src="x84.png" width="179"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="112" id="A7.F12.g25" src="x85.png" width="135"/></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" height="111" id="A7.F12.g26" src="x86.png" width="113"/></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="112" id="A7.F12.g27" src="x87.png" width="187"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>The remaining shape functions derived from GAMformer and EBMs applied to the <span class="ltx_text ltx_font_bold" id="A7.F12.2.1">MIMIC-III dataset</span> for critical clinical variables. The plot above each figure shows the data density in the training set. The results are based on 30 models for both GAMformer and EBMs, each fitted on 10,000 randomly selected data points.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Oct  6 17:26:13 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
