<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.07011] Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers</title><meta property="og:description" content="We present Region-aware Open-vocabulary Vision Transformers (RO-ViT)
‚Äì a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection.
At the pretrain‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.07011">

<!--Generated on Thu Feb 29 07:03:17 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Region-Aware Pretraining for Open-Vocabulary Object Detection with 
<br class="ltx_break">Vision Transformers</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Dahun Kim ‚ÄÉ‚ÄÉ‚ÄÉAnelia Angelova ‚ÄÉ‚ÄÉ‚ÄÉWeicheng Kuo
<br class="ltx_break">Google Research, Brain Team
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.1" class="ltx_p">We present Region-aware Open-vocabulary Vision Transformers (RO-ViT)
‚Äì a contrastive image-text pretraining recipe to bridge the gap between image-level pretraining and open-vocabulary object detection.
At the pretraining phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of positional embeddings at region-level in the detection finetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to better learn the informative yet difficult examples. Finally, we leverage recent advances in novel object proposals to improve open-vocabulary detection finetuning. We evaluate our full model on the LVIS and COCO open-vocabulary detection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 34.1 <math id="id1.1.m1.1" class="ltx_Math" alttext="AP_{r}" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">‚Äã</mo><msub id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml"><mi id="id1.1.m1.1.1.3.2" xref="id1.1.m1.1.1.3.2.cmml">P</mi><mi id="id1.1.m1.1.1.3.3" xref="id1.1.m1.1.1.3.3.cmml">r</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><times id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1"></times><ci id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">ùê¥</ci><apply id="id1.1.m1.1.1.3.cmml" xref="id1.1.m1.1.1.3"><csymbol cd="ambiguous" id="id1.1.m1.1.1.3.1.cmml" xref="id1.1.m1.1.1.3">subscript</csymbol><ci id="id1.1.m1.1.1.3.2.cmml" xref="id1.1.m1.1.1.3.2">ùëÉ</ci><ci id="id1.1.m1.1.1.3.3.cmml" xref="id1.1.m1.1.1.3.3">ùëü</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">AP_{r}</annotation></semantics></math> on LVIS, surpassing the best existing approach by +7.8 points in addition to competitive zero-shot transfer detection. Surprisingly, RO-ViT improves the image-level representation as well and achieves the state of the art on 9 out of 12 metrics on COCO and Flickr image-text retrieval benchmarks, outperforming competitive approaches with larger models.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>project page: <a target="_blank" href="https://github.com/mcahny/rovit" title="" class="ltx_ref ltx_href">https://github.com/mcahny/rovit</a></span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2305.07011/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="415" height="401" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.6.2" class="ltx_text" style="font-size:90%;">Existing vision-language models are designed for image-level tasks, <em id="S1.F1.6.2.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.F1.6.2.2" class="ltx_text"></span>, classification and retrieval. In this paper, we aim to enhance the image-text pretraining for region-level downstream task: open-vocabulary object detection. At pretraining, we propose to randomly crop and resize regions of positional embeddings (PE) instead of using the whole image PE. This better matches the use of PE at region-level in the detection finetuning and results in better performance in detection and surprisingly also retrieval task.
</span></figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The ability to detect objects in the visual world is a hallmark of computer vision and machine intelligence. It is key to enable many applications, e.g. autonomous agents adapting to new environments with many novel objects, a shopping system handling fine-grained user queries such as ‚Äúfedora‚Äù, ‚Äúbonnet‚Äù outside of the training vocabulary. However, modern object detectors typically rely on manual annotations of regions and class labels, which limits their vocabulary size to an order of <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="10^{3}" display="inline"><semantics id="S1.p1.1.m1.1a"><msup id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml"><mn id="S1.p1.1.m1.1.1.2" xref="S1.p1.1.m1.1.1.2.cmml">10</mn><mn id="S1.p1.1.m1.1.1.3" xref="S1.p1.1.m1.1.1.3.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><apply id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p1.1.m1.1.1.1.cmml" xref="S1.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S1.p1.1.m1.1.1.2.cmml" xref="S1.p1.1.m1.1.1.2">10</cn><cn type="integer" id="S1.p1.1.m1.1.1.3.cmml" xref="S1.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">10^{3}</annotation></semantics></math> and it is prohibitively expensive to scale up further. This is orders of magnitude smaller than the objects we encounter in the visual world.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recently, the open-vocabulary detection task (OVD) has been proposed to overcome such limitation by leveraging abundant image-text pairs for training and ingesting the text queries provided by users at test time¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. By treating the categories as text embeddings rather than discrete ids, open-vocabulary detectors can flexibly predict a wide range of objects unseen during the training time. Most existing works leverage image-text pre-training which contains rich semantic knowledge of open-vocabulary concepts. Knowledge distillation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, weak supervision¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, self-training¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, and frozen model¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> have been proposed, and CNN backbones are most commonly used. With the growing popularity of vision transformers in image understanding¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, multimodal¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, and self-supervised tasks¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, it is important to understand how to build capable open-vocabulary detectors with vision transformers¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To our best knowledge, all existing works assume pretrained Vision-Language Models (VLM) are given, and develop adaptation or finetuning recipes to bridge the gap between image-level pretraining and object-level finetuning¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. Since the VLMs are designed for image-level tasks <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p3.1.2" class="ltx_text"></span> classification, retrieval, the notion of objects/regions are not adequately utilized in the pretraining process. We believe it would be beneficial for open-vocabulary detection if we bake in locality information in the image-text pretraining.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We present RO-ViT, a simple recipe to pretrain vision transformers in a region-aware manner for open-vocabulary object detection. Standard pretraining typically uses full-image positional embeddings, which does not generalize well to detection tasks. Thus, we propose a novel positional embedding scheme called ‚ÄúCropped Positional Embedding‚Äù which better matches the use of region crops in detection finetuning (see Fig.¬†<a href="#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). In addition, we found it beneficial to replace the softmax cross entropy loss with focal loss in contrastive learning, which affords us more control to learn from harder and more informative examples. Finally, we leverage recent advances in novel object proposals¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> to improve open-vocabulary detection finetuning. The motivation is that existing approaches often miss novel objects in the object proposal stage because the proposals tend to overfit to the foreground categories.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.3" class="ltx_p">We evaluate the approach on the standard LVIS and COCO open-vocabulary benchmarks. On LVIS, our best model achieves a state-of-the-art 34.1 AP<sub id="S1.p5.3.1" class="ltx_sub"><span id="S1.p5.3.1.1" class="ltx_text ltx_font_italic">r</span></sub> at the system level, surpassing the best existing approach by +7.8 AP<sub id="S1.p5.3.2" class="ltx_sub"><span id="S1.p5.3.2.1" class="ltx_text ltx_font_italic">r</span></sub>. Compared to the best existing ViT-based approach, ours outperforms by a healthy margin of +9.5 AP<sub id="S1.p5.3.3" class="ltx_sub"><span id="S1.p5.3.3.1" class="ltx_text ltx_font_italic">r</span></sub>. Our LVIS-trained model outperforms existing baselines on transfer detection to Objects365 without re-training. Although not explicitly optimized for retrieval, RO-ViT surprisingly achieves the state-of-the-art performance on 9 out of 12 metrics in image-text retrieval benchmark and outperforms strong baselines with standard positional embeddings, cross entropy loss, and larger model capacity. We conduct ablations to confirm the benefits of each proposed component. Visualization of the learnt positional embeddings shows that our approach (CPE) leads to more symmetrical and diverse patterns than the baseline. In summary:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose RO-ViT to bridge the positional embeddings in image-text pretraining to open-vocabulary detection finetuning.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We show that image-text pretraining with focal loss is more effective than existing softmax CE loss.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We improve the open-vocabulary detection finetuning recipe with novel object proposals.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">RO-ViT achieves the state of the art on the LVIS open-vocabulary detection benchmark, and 9 out 12 metrics on COCO and Flickr image-text retrieval benchmarks.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We hope these findings will facilitate the research community to further explore open-vocabulary detection from the perspective of image-text pretraining with potential benefits for both region-level and image-level tasks.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Learning open-vocabulary and zero-shot recognition.</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">Building general representation for open-vocabulary and zero-shot recognition is a fundamental machine learning task. DeViSE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and ConSE¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> are pioneering works to learn a shared image-text embedding space for zero-shot recognition by convolutional networks. As image and language often co-occur on the internet, the community has explored learning such representation from various data sources including image tags¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, captions/text descriptions¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, alt-texts¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, and image search queries¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Recently, contrastive learning has become a popular paradigm to learn from large image-text corpus due to its simplicity and scalability, where increasing model size and data yield consistent improvement on open-vocabulary classification benchmarks. The aforementioned works focus on image-level recognition, whereas we study how to best tailor them for region-level understanding.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Self-supervised representation learning for localization.</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">Due to the challenge to scale up labeling for localization tasks, many efforts have been made to learn locality-sensitive representation in a self-supervised manner. Existing approaches roughly fall into the contrastive or generative paradigms. Contrastive approaches typically involve region or point-level contrastive learning using sliding windows¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, object proposals¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, or point samples¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Most existing contrastive methods are CNN-based, while ViT backbones have been popular recently with generative approaches¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and has shown promise with contrastive approaches¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Masked image modeling is commonly used to learn the ViT features for localization tasks. Even though these self-supervised methods are well-suited for standard localization tasks, they lack the image-text correspondence necessary for open-vocabulary recognition. Thus, we study contrastive image-text representation learning for open-vocabulary detection with ViTs.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Open-vocabulary object detection and segmentation.</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Zero-shot detection was proposed to scale up detection models beyond their limited training categories. Popular approaches accomplish this by learning the alignment between region visual representation and category word embeddings¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> or hallucinating visual features with a generative model¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. Without any visual knowledge of the novel categories, zero-shot detectors tend to struggle with low performance. This motivates the open-vocabulary detection benchmark¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> to bridge the gap between zero-shot and fully-supervised detection.</p>
</div>
<div id="S2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p2.1" class="ltx_p">With the rise of image-text pretraining, many works have explored adapting these pretrained models to open-vocabulary detection and segmentation ¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. For example, ViLD¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> proposes to distill the image-text knowledge into the detector. DetPro¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> improves ViLD by incorporating the idea of prompt optimization¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. Moreover, region-text self-training has been shown effective on image caption data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, classification data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, or even unlabeled data¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. Weak supervision¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> and phrase grounding¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> approaches have also been proposed. In terms of architecture, CNNs are most commonly used but vision transformers have recently been adopted as well¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. While existing works typically assume image-text pretrained models are given and focus on finetuning or adaptation strategies, our focus is to improve the upstream image-text pretraining with vision transformers.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2305.07011/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.13.4.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.6.3" class="ltx_text ltx_font_bold" style="font-size:90%;">RO-ViT framework overview.<span id="S3.F2.6.3.4" class="ltx_text ltx_font_medium"> Our Region-aware Open-vocabulary Vision Transformer (</span>RO-ViT<span id="S3.F2.6.3.5" class="ltx_text ltx_font_medium">) attempts to bridge the gap between the image-level vision-language model (VLM) pretraining and downstream open-vocabulary detection. For the pretraining, we propose Cropped Positional Embedding (</span>CPE<span id="S3.F2.6.3.6" class="ltx_text ltx_font_medium">) which randomly crops and resizes a <span id="S3.F2.6.3.6.1" class="ltx_text ltx_font_italic">region</span> of positional embeddings instead of using the whole-image PE. In addition, we use </span>focal<span id="S3.F2.6.3.3" class="ltx_text ltx_font_medium"> loss instead of the common softmax cross entropy loss for contrastive learning. The pretrained ViT backbone is transferred to the downstream open-vocabulary detection by replacing the global average pooling with detector heads. RO-ViT detector takes the whole-image positional embeddings as input, and the detections are used to crop out region embeddings from the ViT backbone features. The region embeddings then match with the cached category embeddings to obtain the VLM score <math id="S3.F2.4.1.1.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.F2.4.1.1.m1.1b"><mi id="S3.F2.4.1.1.m1.1.1" xref="S3.F2.4.1.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.F2.4.1.1.m1.1c"><ci id="S3.F2.4.1.1.m1.1.1.cmml" xref="S3.F2.4.1.1.m1.1.1">ùëß</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.1.1.m1.1d">z</annotation></semantics></math>, which is combined with the detection score <math id="S3.F2.5.2.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.F2.5.2.2.m2.1b"><mi id="S3.F2.5.2.2.m2.1.1" xref="S3.F2.5.2.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.F2.5.2.2.m2.1c"><ci id="S3.F2.5.2.2.m2.1.1.cmml" xref="S3.F2.5.2.2.m2.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.5.2.2.m2.1d">p</annotation></semantics></math> into the open-vocabulary detection score <math id="S3.F2.6.3.3.m3.1" class="ltx_Math" alttext="s^{\text{OVD}}" display="inline"><semantics id="S3.F2.6.3.3.m3.1b"><msup id="S3.F2.6.3.3.m3.1.1" xref="S3.F2.6.3.3.m3.1.1.cmml"><mi id="S3.F2.6.3.3.m3.1.1.2" xref="S3.F2.6.3.3.m3.1.1.2.cmml">s</mi><mtext id="S3.F2.6.3.3.m3.1.1.3" xref="S3.F2.6.3.3.m3.1.1.3a.cmml">OVD</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.6.3.3.m3.1c"><apply id="S3.F2.6.3.3.m3.1.1.cmml" xref="S3.F2.6.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.6.3.3.m3.1.1.1.cmml" xref="S3.F2.6.3.3.m3.1.1">superscript</csymbol><ci id="S3.F2.6.3.3.m3.1.1.2.cmml" xref="S3.F2.6.3.3.m3.1.1.2">ùë†</ci><ci id="S3.F2.6.3.3.m3.1.1.3a.cmml" xref="S3.F2.6.3.3.m3.1.1.3"><mtext mathsize="70%" id="S3.F2.6.3.3.m3.1.1.3.cmml" xref="S3.F2.6.3.3.m3.1.1.3">OVD</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.3.3.m3.1d">s^{\text{OVD}}</annotation></semantics></math> (see Equation ¬†<a href="#S3.E1" title="Equation 1 ‚Ä£ Open-vocabulary object detector. ‚Ä£ 3.1 Preliminaries ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
</span></span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">In this paper we address the problem of open-vocabulary detection. At training time, the model has access to the detection labels of <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S3.p1.1.m1.1a"><msub id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">C</mi><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ùê∂</ci><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">C_{B}</annotation></semantics></math> base categories, but needs to detect objects from a set of <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="C_{N}" display="inline"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">C</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ùê∂</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">ùëÅ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">C_{N}</annotation></semantics></math> novel categories at test time. We follow existing works¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> to leverage pretrained vision and language models (VLM)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Unlike existing works, we explore how to best pretrain our own VLMs with vision transformers¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> for open-vocabulary detection.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Preliminaries</h3>

<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Contrastive image-text pretraining.</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">Two-tower contrastive image-text learning involves an image encoder and a text encoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. The text tower is typically transformer encoder, whereas the image tower can be CNN-based or ViT as in our case. Given a set of image-text corpus, the model learns to bring each image and its corresponding text together and push other non-matching texts away in the embedding space. The most common objective is softmax cross-entropy loss. The image/text embeddings are typically obtained by taking the pre-pended class token embedding, self-attention pooling, or average pooling. We use the global average pooling followed by L2 normalization for both image and text embeddings.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Open-vocabulary object detector.</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.3" class="ltx_p">An open-vocabulary object detector is trained with the labels of <math id="S3.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">C_{B}</annotation></semantics></math> base categories, but needs to detect the union of base and novel categories (<math id="S3.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="C_{B}\cup C_{N}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.2.m2.1a"><mrow id="S3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.3.cmml">B</mi></msub><mo id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml">‚à™</mo><msub id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1"><union id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.1"></union><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.2.3">ùêµ</ci></apply><apply id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.3.3">ùëÅ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.2.m2.1c">C_{B}\cup C_{N}</annotation></semantics></math>) at test time. Most object detectors use K-way classifiers because the number of categories are the same between train and test time. To deal with additional categories at test time, the common practice is to replace the conventional fixed-size classifier fully-connected layer with the text embeddings of base categories¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. It is important that the text embeddings come from the matching text encoder of the image encoder during pretraining, so that the open-vocabulary knowledge would be preserved. We represent the background category by a ‚Äúbackground‚Äù phrase and the proposals not matched to any annotations in <math id="S3.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.3.m3.1c">C_{B}</annotation></semantics></math> are labeled as background.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p2.11" class="ltx_p">During training, we compute the detection scores <math id="S3.SS1.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.1.m1.1a"><msub id="S3.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml">p</mi><mi id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2">ùëù</ci><ci id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.1.m1.1c">p_{i}</annotation></semantics></math> for each region <math id="S3.SS1.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.2.m2.1a"><mi id="S3.SS1.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.2.m2.1b"><ci id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.2.m2.1c">i</annotation></semantics></math> as the cosine similarity between the RoI-Align feature (<em id="S3.SS1.SSS0.Px2.p2.11.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS1.SSS0.Px2.p2.11.2" class="ltx_text"></span>, region embedding) and the text embeddings of <math id="S3.SS1.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.3.m3.1a"><msub id="S3.SS1.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.2" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.3" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.3.m3.1b"><apply id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.3.m3.1c">C_{B}</annotation></semantics></math>, followed by a softmax. At test time, we expand the text embeddings from <math id="S3.SS1.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.4.m4.1a"><msub id="S3.SS1.SSS0.Px2.p2.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.2" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.3" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.4.m4.1b"><apply id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.4.m4.1c">C_{B}</annotation></semantics></math> to <math id="S3.SS1.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="C_{B}\cup C_{N}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.5.m5.1a"><mrow id="S3.SS1.SSS0.Px2.p2.5.m5.1.1" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.2" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.3" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.3.cmml">B</mi></msub><mo id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1.cmml">‚à™</mo><msub id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.2" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.3" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.5.m5.1b"><apply id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1"><union id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1"></union><apply id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.3">ùêµ</ci></apply><apply id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.3">ùëÅ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.5.m5.1c">C_{B}\cup C_{N}</annotation></semantics></math> plus the ‚Äúbackground‚Äù category for open-vocabulary detection. We extract the VLM embedding of region <math id="S3.SS1.SSS0.Px2.p2.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.6.m6.1a"><mi id="S3.SS1.SSS0.Px2.p2.6.m6.1.1" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.6.m6.1b"><ci id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.6.m6.1c">i</annotation></semantics></math> by RoI-Align on the output feature map of the ViT backbone, and compute the VLM region scores <math id="S3.SS1.SSS0.Px2.p2.7.m7.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.7.m7.1a"><msub id="S3.SS1.SSS0.Px2.p2.7.m7.1.1" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.2" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1.2.cmml">z</mi><mi id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.3" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.7.m7.1b"><apply id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1.2">ùëß</ci><ci id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.7.m7.1c">z_{i}</annotation></semantics></math> as the cosine similarity with the <math id="S3.SS1.SSS0.Px2.p2.8.m8.1" class="ltx_Math" alttext="C_{B}\cup C_{N}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.8.m8.1a"><mrow id="S3.SS1.SSS0.Px2.p2.8.m8.1.1" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.2" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.3" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.3.cmml">B</mi></msub><mo id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.1" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.1.cmml">‚à™</mo><msub id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.2" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.3" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.8.m8.1b"><apply id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1"><union id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.1"></union><apply id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.2.3">ùêµ</ci></apply><apply id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.3.3">ùëÅ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.8.m8.1c">C_{B}\cup C_{N}</annotation></semantics></math> text embeddings. Similarly, the detection scores <math id="S3.SS1.SSS0.Px2.p2.9.m9.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.9.m9.1a"><msub id="S3.SS1.SSS0.Px2.p2.9.m9.1.1" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.cmml">p</mi><mi id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.9.m9.1b"><apply id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2">ùëù</ci><ci id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.9.m9.1c">p_{i}</annotation></semantics></math> are now computed with the <math id="S3.SS1.SSS0.Px2.p2.10.m10.1" class="ltx_Math" alttext="C_{B}\cup C_{N}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.10.m10.1a"><mrow id="S3.SS1.SSS0.Px2.p2.10.m10.1.1" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.2" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.3" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.3.cmml">B</mi></msub><mo id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.1" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.1.cmml">‚à™</mo><msub id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.2" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.2.cmml">C</mi><mi id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.3" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.3.cmml">N</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.10.m10.1b"><apply id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1"><union id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.1"></union><apply id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.2.3">ùêµ</ci></apply><apply id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.2">ùê∂</ci><ci id="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p2.10.m10.1.1.3.3">ùëÅ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.10.m10.1c">C_{B}\cup C_{N}</annotation></semantics></math> text embeddings. The combined open-vocabulary detection score <math id="S3.SS1.SSS0.Px2.p2.11.m11.1" class="ltx_Math" alttext="{s_{i}}^{\text{OVD}}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.11.m11.1a"><mmultiscripts id="S3.SS1.SSS0.Px2.p2.11.m11.1.1" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.2" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.2.cmml">s</mi><mi id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.3" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.3.cmml">i</mi><mrow id="S3.SS1.SSS0.Px2.p2.11.m11.1.1a" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.cmml"></mrow><mrow id="S3.SS1.SSS0.Px2.p2.11.m11.1.1b" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.cmml"></mrow><mtext id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.3" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.3a.cmml">OVD</mtext></mmultiscripts><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.11.m11.1b"><apply id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1">superscript</csymbol><apply id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.2">ùë†</ci><ci id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.2.3">ùëñ</ci></apply><ci id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.3a.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px2.p2.11.m11.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.11.m11.1.1.3">OVD</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.11.m11.1c">{s_{i}}^{\text{OVD}}</annotation></semantics></math> is obtained by geometric means¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="{s_{i}}^{\text{OVD}}=\begin{cases}z_{i}^{(1-\alpha)}\cdot p_{i}^{\alpha}&amp;\text{if }i\in C_{B}\\
z_{i}^{(1-\beta)}\cdot p_{i}^{\beta}&amp;\text{if }i\in C_{N}\end{cases}" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.5" xref="S3.E1.m1.4.5.cmml"><mmultiscripts id="S3.E1.m1.4.5.2" xref="S3.E1.m1.4.5.2.cmml"><mi id="S3.E1.m1.4.5.2.2.2" xref="S3.E1.m1.4.5.2.2.2.cmml">s</mi><mi id="S3.E1.m1.4.5.2.2.3" xref="S3.E1.m1.4.5.2.2.3.cmml">i</mi><mrow id="S3.E1.m1.4.5.2a" xref="S3.E1.m1.4.5.2.cmml"></mrow><mrow id="S3.E1.m1.4.5.2b" xref="S3.E1.m1.4.5.2.cmml"></mrow><mtext id="S3.E1.m1.4.5.2.3" xref="S3.E1.m1.4.5.2.3a.cmml">OVD</mtext></mmultiscripts><mo id="S3.E1.m1.4.5.1" xref="S3.E1.m1.4.5.1.cmml">=</mo><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.5.3.1.cmml"><mo id="S3.E1.m1.4.4.5" xref="S3.E1.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E1.m1.4.4.4" xref="S3.E1.m1.4.5.3.1.cmml"><mtr id="S3.E1.m1.4.4.4a" xref="S3.E1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4b" xref="S3.E1.m1.4.5.3.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><msubsup id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml">z</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">Œ±</mi></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">‚ãÖ</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.1.1.4.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.4.2.2" xref="S3.E1.m1.1.1.1.1.1.1.4.2.2.cmml">p</mi><mi id="S3.E1.m1.1.1.1.1.1.1.4.2.3" xref="S3.E1.m1.1.1.1.1.1.1.4.2.3.cmml">i</mi><mi id="S3.E1.m1.1.1.1.1.1.1.4.3" xref="S3.E1.m1.1.1.1.1.1.1.4.3.cmml">Œ±</mi></msubsup></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4c" xref="S3.E1.m1.4.5.3.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.1.cmml"><mrow id="S3.E1.m1.2.2.2.2.2.1.2" xref="S3.E1.m1.2.2.2.2.2.1.2.cmml"><mtext id="S3.E1.m1.2.2.2.2.2.1.2.2" xref="S3.E1.m1.2.2.2.2.2.1.2.2a.cmml">if¬†</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.2.1.2.1" xref="S3.E1.m1.2.2.2.2.2.1.2.1.cmml">‚Äã</mo><mi id="S3.E1.m1.2.2.2.2.2.1.2.3" xref="S3.E1.m1.2.2.2.2.2.1.2.3.cmml">i</mi></mrow><mo id="S3.E1.m1.2.2.2.2.2.1.1" xref="S3.E1.m1.2.2.2.2.2.1.1.cmml">‚àà</mo><msub id="S3.E1.m1.2.2.2.2.2.1.3" xref="S3.E1.m1.2.2.2.2.2.1.3.cmml"><mi id="S3.E1.m1.2.2.2.2.2.1.3.2" xref="S3.E1.m1.2.2.2.2.2.1.3.2.cmml">C</mi><mi id="S3.E1.m1.2.2.2.2.2.1.3.3" xref="S3.E1.m1.2.2.2.2.2.1.3.3.cmml">B</mi></msub></mrow></mtd></mtr><mtr id="S3.E1.m1.4.4.4d" xref="S3.E1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4e" xref="S3.E1.m1.4.5.3.1.cmml"><mrow id="S3.E1.m1.3.3.3.3.1.1" xref="S3.E1.m1.3.3.3.3.1.1.cmml"><msubsup id="S3.E1.m1.3.3.3.3.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.3.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.3.2.2" xref="S3.E1.m1.3.3.3.3.1.1.3.2.2.cmml">z</mi><mi id="S3.E1.m1.3.3.3.3.1.1.3.2.3" xref="S3.E1.m1.3.3.3.3.1.1.3.2.3.cmml">i</mi><mrow id="S3.E1.m1.3.3.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mn id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml">‚àí</mo><mi id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.3.cmml">Œ≤</mi></mrow><mo stretchy="false" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></msubsup><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.3.3.3.3.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.2.cmml">‚ãÖ</mo><msubsup id="S3.E1.m1.3.3.3.3.1.1.4" xref="S3.E1.m1.3.3.3.3.1.1.4.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.4.2.2" xref="S3.E1.m1.3.3.3.3.1.1.4.2.2.cmml">p</mi><mi id="S3.E1.m1.3.3.3.3.1.1.4.2.3" xref="S3.E1.m1.3.3.3.3.1.1.4.2.3.cmml">i</mi><mi id="S3.E1.m1.3.3.3.3.1.1.4.3" xref="S3.E1.m1.3.3.3.3.1.1.4.3.cmml">Œ≤</mi></msubsup></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.4.4.4f" xref="S3.E1.m1.4.5.3.1.cmml"><mrow id="S3.E1.m1.4.4.4.4.2.1" xref="S3.E1.m1.4.4.4.4.2.1.cmml"><mrow id="S3.E1.m1.4.4.4.4.2.1.2" xref="S3.E1.m1.4.4.4.4.2.1.2.cmml"><mtext id="S3.E1.m1.4.4.4.4.2.1.2.2" xref="S3.E1.m1.4.4.4.4.2.1.2.2a.cmml">if¬†</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.4.4.4.4.2.1.2.1" xref="S3.E1.m1.4.4.4.4.2.1.2.1.cmml">‚Äã</mo><mi id="S3.E1.m1.4.4.4.4.2.1.2.3" xref="S3.E1.m1.4.4.4.4.2.1.2.3.cmml">i</mi></mrow><mo id="S3.E1.m1.4.4.4.4.2.1.1" xref="S3.E1.m1.4.4.4.4.2.1.1.cmml">‚àà</mo><msub id="S3.E1.m1.4.4.4.4.2.1.3" xref="S3.E1.m1.4.4.4.4.2.1.3.cmml"><mi id="S3.E1.m1.4.4.4.4.2.1.3.2" xref="S3.E1.m1.4.4.4.4.2.1.3.2.cmml">C</mi><mi id="S3.E1.m1.4.4.4.4.2.1.3.3" xref="S3.E1.m1.4.4.4.4.2.1.3.3.cmml">N</mi></msub></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.5.cmml" xref="S3.E1.m1.4.5"><eq id="S3.E1.m1.4.5.1.cmml" xref="S3.E1.m1.4.5.1"></eq><apply id="S3.E1.m1.4.5.2.cmml" xref="S3.E1.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.5.2.1.cmml" xref="S3.E1.m1.4.5.2">superscript</csymbol><apply id="S3.E1.m1.4.5.2.2.cmml" xref="S3.E1.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.5.2.2.1.cmml" xref="S3.E1.m1.4.5.2">subscript</csymbol><ci id="S3.E1.m1.4.5.2.2.2.cmml" xref="S3.E1.m1.4.5.2.2.2">ùë†</ci><ci id="S3.E1.m1.4.5.2.2.3.cmml" xref="S3.E1.m1.4.5.2.2.3">ùëñ</ci></apply><ci id="S3.E1.m1.4.5.2.3a.cmml" xref="S3.E1.m1.4.5.2.3"><mtext mathsize="70%" id="S3.E1.m1.4.5.2.3.cmml" xref="S3.E1.m1.4.5.2.3">OVD</mtext></ci></apply><apply id="S3.E1.m1.4.5.3.1.cmml" xref="S3.E1.m1.4.4"><csymbol cd="latexml" id="S3.E1.m1.4.5.3.1.1.cmml" xref="S3.E1.m1.4.4.5">cases</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">‚ãÖ</ci><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.2">ùëß</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2.3">ùëñ</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3">ùõº</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.4.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.4.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4.2.2">ùëù</ci><ci id="S3.E1.m1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4.2.3">ùëñ</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.4.3">ùõº</ci></apply></apply><apply id="S3.E1.m1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1"><in id="S3.E1.m1.2.2.2.2.2.1.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.1"></in><apply id="S3.E1.m1.2.2.2.2.2.1.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.2"><times id="S3.E1.m1.2.2.2.2.2.1.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.2.1"></times><ci id="S3.E1.m1.2.2.2.2.2.1.2.2a.cmml" xref="S3.E1.m1.2.2.2.2.2.1.2.2"><mtext id="S3.E1.m1.2.2.2.2.2.1.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.2.2">if¬†</mtext></ci><ci id="S3.E1.m1.2.2.2.2.2.1.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.2.3">ùëñ</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.1.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.1.3.1.cmml" xref="S3.E1.m1.2.2.2.2.2.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.1.3.2.cmml" xref="S3.E1.m1.2.2.2.2.2.1.3.2">ùê∂</ci><ci id="S3.E1.m1.2.2.2.2.2.1.3.3.cmml" xref="S3.E1.m1.2.2.2.2.2.1.3.3">ùêµ</ci></apply></apply><apply id="S3.E1.m1.3.3.3.3.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1"><ci id="S3.E1.m1.3.3.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2">‚ãÖ</ci><apply id="S3.E1.m1.3.3.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.3.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.3">superscript</csymbol><apply id="S3.E1.m1.3.3.3.3.1.1.3.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.3">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.3.2.2">ùëß</ci><ci id="S3.E1.m1.3.3.3.3.1.1.3.2.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.3.2.3">ùëñ</ci></apply><apply id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1"><minus id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.2">1</cn><ci id="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1.1.1.3">ùõΩ</ci></apply></apply><apply id="S3.E1.m1.3.3.3.3.1.1.4.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.4.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4">superscript</csymbol><apply id="S3.E1.m1.3.3.3.3.1.1.4.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.4.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.4.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4.2.2">ùëù</ci><ci id="S3.E1.m1.3.3.3.3.1.1.4.2.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4.2.3">ùëñ</ci></apply><ci id="S3.E1.m1.3.3.3.3.1.1.4.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.4.3">ùõΩ</ci></apply></apply><apply id="S3.E1.m1.4.4.4.4.2.1.cmml" xref="S3.E1.m1.4.4.4.4.2.1"><in id="S3.E1.m1.4.4.4.4.2.1.1.cmml" xref="S3.E1.m1.4.4.4.4.2.1.1"></in><apply id="S3.E1.m1.4.4.4.4.2.1.2.cmml" xref="S3.E1.m1.4.4.4.4.2.1.2"><times id="S3.E1.m1.4.4.4.4.2.1.2.1.cmml" xref="S3.E1.m1.4.4.4.4.2.1.2.1"></times><ci id="S3.E1.m1.4.4.4.4.2.1.2.2a.cmml" xref="S3.E1.m1.4.4.4.4.2.1.2.2"><mtext id="S3.E1.m1.4.4.4.4.2.1.2.2.cmml" xref="S3.E1.m1.4.4.4.4.2.1.2.2">if¬†</mtext></ci><ci id="S3.E1.m1.4.4.4.4.2.1.2.3.cmml" xref="S3.E1.m1.4.4.4.4.2.1.2.3">ùëñ</ci></apply><apply id="S3.E1.m1.4.4.4.4.2.1.3.cmml" xref="S3.E1.m1.4.4.4.4.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.4.4.2.1.3.1.cmml" xref="S3.E1.m1.4.4.4.4.2.1.3">subscript</csymbol><ci id="S3.E1.m1.4.4.4.4.2.1.3.2.cmml" xref="S3.E1.m1.4.4.4.4.2.1.3.2">ùê∂</ci><ci id="S3.E1.m1.4.4.4.4.2.1.3.3.cmml" xref="S3.E1.m1.4.4.4.4.2.1.3.3">ùëÅ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">{s_{i}}^{\text{OVD}}=\begin{cases}z_{i}^{(1-\alpha)}\cdot p_{i}^{\alpha}&amp;\text{if }i\in C_{B}\\
z_{i}^{(1-\beta)}\cdot p_{i}^{\beta}&amp;\text{if }i\in C_{N}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px2.p2.13" class="ltx_p">, where <math id="S3.SS1.SSS0.Px2.p2.12.m1.4" class="ltx_Math" alttext="\alpha,\beta\in[0,1]" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.12.m1.4a"><mrow id="S3.SS1.SSS0.Px2.p2.12.m1.4.5" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.cmml"><mrow id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.2.2" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.2.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.12.m1.3.3" xref="S3.SS1.SSS0.Px2.p2.12.m1.3.3.cmml">Œ±</mi><mo id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.2.2.1" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.2.1.cmml">,</mo><mi id="S3.SS1.SSS0.Px2.p2.12.m1.4.4" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.4.cmml">Œ≤</mi></mrow><mo id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.1" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.1.cmml">‚àà</mo><mrow id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.2" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.2.1" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.1.cmml">[</mo><mn id="S3.SS1.SSS0.Px2.p2.12.m1.1.1" xref="S3.SS1.SSS0.Px2.p2.12.m1.1.1.cmml">0</mn><mo id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.2.2" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p2.12.m1.2.2" xref="S3.SS1.SSS0.Px2.p2.12.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.2.3" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.12.m1.4b"><apply id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5"><in id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.1.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.1"></in><list id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.2.2"><ci id="S3.SS1.SSS0.Px2.p2.12.m1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.3.3">ùõº</ci><ci id="S3.SS1.SSS0.Px2.p2.12.m1.4.4.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.4">ùõΩ</ci></list><interval closure="closed" id="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.4.5.3.2"><cn type="integer" id="S3.SS1.SSS0.Px2.p2.12.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.1.1">0</cn><cn type="integer" id="S3.SS1.SSS0.Px2.p2.12.m1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.12.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.12.m1.4c">\alpha,\beta\in[0,1]</annotation></semantics></math> control the weights for base and novel categories. The background score comes directly from the detection score <math id="S3.SS1.SSS0.Px2.p2.13.m2.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p2.13.m2.1a"><msub id="S3.SS1.SSS0.Px2.p2.13.m2.1.1" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.13.m2.1.1.2" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1.2.cmml">p</mi><mi id="S3.SS1.SSS0.Px2.p2.13.m2.1.1.3" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.13.m2.1b"><apply id="S3.SS1.SSS0.Px2.p2.13.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.13.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.13.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1.2">ùëù</ci><ci id="S3.SS1.SSS0.Px2.p2.13.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.13.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.13.m2.1c">p_{i}</annotation></semantics></math>, because the VLM score with ‚Äúbackground‚Äù phrase tends to be not as reliable.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p3.1" class="ltx_p">We adopt Mask R-CNN heads in our detector and use <span id="S3.SS1.SSS0.Px2.p3.1.1" class="ltx_text ltx_font_italic">class-agnostic</span> box regression and mask prediction heads following existing works¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. Note that we use a contrastively pretrained ViT to initialize our detector backbone, and adopt the simple feature pyramid and windowed attention to handle higher-resolution image inputs as proposed by Li¬†<em id="S3.SS1.SSS0.Px2.p3.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.SS1.SSS0.Px2.p3.1.3" class="ltx_text"></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Region-Aware Image-Text Pretraining</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Existing vision-language models are trained to match an image as a whole to a text description¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. However, the pretraining is unaware of the alignment between its region-level representations and text tokens, which is essential to downstream open-vocabulary detection. We propose a novel Cropped Positional Embeddings (CPE) to bridge this gap, and also find it beneficial to learn from hard examples with a focal loss. Our improvements introduce no extra parameters and minimal computation costs.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Cropped Positional Embedding (CPE).</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">The positional embeddings are important to transformers as they provide the information of where each element in the set comes from. This information is often useful for downstream recognition and localization tasks.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">There is a mismatch between the way the positional embeddings are used in existing contrastive pretraining approaches and open-vocabulary detection finetuning. The pretraining approaches typically apply full-image positional embeddings¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> during training, and use the same positional embeddings for downstream tasks, <em id="S3.SS2.SSS0.Px1.p2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS2.SSS0.Px1.p2.1.2" class="ltx_text"></span>, zero-shot recognition. However, the recognition occurs at region-level for open-vocabulary detection finetuning, which requires the full-image positional embeddings to generalize to regions that they never see during the pretraining.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p3.4" class="ltx_p">To bridge this gap, we propose Cropped Positional Embedding (CPE) (see center of Figure¬†<a href="#S3.F2" title="Figure 2 ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). First, we up-sample the positional embeddings from the image size typical for pretraining, <em id="S3.SS2.SSS0.Px1.p3.4.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS2.SSS0.Px1.p3.4.2" class="ltx_text"></span>, 224 to that typical for detection tasks, <em id="S3.SS2.SSS0.Px1.p3.4.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS2.SSS0.Px1.p3.4.4" class="ltx_text"></span>, 1024. Then we randomly crop and resize a region from the up-sampled positional embeddings and use that as the image-level positional embeddings during pretraining. The regions are uniformly sampled from the normalized coordinates as <math id="S3.SS2.SSS0.Px1.p3.1.m1.2" class="ltx_Math" alttext="x_{1}\thicksim\text{Uniform}(0,1)" display="inline"><semantics id="S3.SS2.SSS0.Px1.p3.1.m1.2a"><mrow id="S3.SS2.SSS0.Px1.p3.1.m1.2.3" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.cmml"><msub id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.cmml"><mi id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.2" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.2.cmml">x</mi><mn id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.3" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.1" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.1.cmml">‚àº</mo><mrow id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.cmml"><mtext id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.2" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.2a.cmml">Uniform</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.1" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.1.cmml">‚Äã</mo><mrow id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.2" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.2.1" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.1.cmml">(</mo><mn id="S3.SS2.SSS0.Px1.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p3.1.m1.1.1.cmml">0</mn><mo id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.2.2" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.1.cmml">,</mo><mn id="S3.SS2.SSS0.Px1.p3.1.m1.2.2" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.2.3" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p3.1.m1.2b"><apply id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3"><ci id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.1">‚àº</ci><apply id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.1.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.2">ùë•</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.3.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.2.3">1</cn></apply><apply id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3"><times id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.1"></times><ci id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.2a.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.2"><mtext id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.2">Uniform</mtext></ci><interval closure="open" id="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.3.3.3.2"><cn type="integer" id="S3.SS2.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.1.1">0</cn><cn type="integer" id="S3.SS2.SSS0.Px1.p3.1.m1.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.1.m1.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p3.1.m1.2c">x_{1}\thicksim\text{Uniform}(0,1)</annotation></semantics></math>, <math id="S3.SS2.SSS0.Px1.p3.2.m2.2" class="ltx_Math" alttext="y_{1}\thicksim\text{Uniform}(0,1)" display="inline"><semantics id="S3.SS2.SSS0.Px1.p3.2.m2.2a"><mrow id="S3.SS2.SSS0.Px1.p3.2.m2.2.3" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.cmml"><msub id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.cmml"><mi id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.2" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.2.cmml">y</mi><mn id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.3" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.1" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.1.cmml">‚àº</mo><mrow id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.cmml"><mtext id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.2" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.2a.cmml">Uniform</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.1" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.1.cmml">‚Äã</mo><mrow id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.2" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.2.1" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.1.cmml">(</mo><mn id="S3.SS2.SSS0.Px1.p3.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p3.2.m2.1.1.cmml">0</mn><mo id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.2.2" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.1.cmml">,</mo><mn id="S3.SS2.SSS0.Px1.p3.2.m2.2.2" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.2.3" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p3.2.m2.2b"><apply id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3"><ci id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.1">‚àº</ci><apply id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.1.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.2">ùë¶</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.3.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.2.3">1</cn></apply><apply id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3"><times id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.1"></times><ci id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.2a.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.2"><mtext id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.2.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.2">Uniform</mtext></ci><interval closure="open" id="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.3.3.3.2"><cn type="integer" id="S3.SS2.SSS0.Px1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.1.1">0</cn><cn type="integer" id="S3.SS2.SSS0.Px1.p3.2.m2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.2.m2.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p3.2.m2.2c">y_{1}\thicksim\text{Uniform}(0,1)</annotation></semantics></math>, <math id="S3.SS2.SSS0.Px1.p3.3.m3.2" class="ltx_Math" alttext="x_{2}\thicksim\text{Uniform}(x_{1},1)" display="inline"><semantics id="S3.SS2.SSS0.Px1.p3.3.m3.2a"><mrow id="S3.SS2.SSS0.Px1.p3.3.m3.2.2" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.cmml"><msub id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.2" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.2.cmml">x</mi><mn id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.3" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.2" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.2.cmml">‚àº</mo><mrow id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.cmml"><mtext id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.3" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.3a.cmml">Uniform</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.2" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.2.cmml">‚Äã</mo><mrow id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.2.cmml">(</mo><msub id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.2.cmml">x</mi><mn id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.2.cmml">,</mo><mn id="S3.SS2.SSS0.Px1.p3.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p3.3.m3.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.4" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p3.3.m3.2b"><apply id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2"><ci id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.2">‚àº</ci><apply id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.2">ùë•</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.3.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.3.3">2</cn></apply><apply id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1"><times id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.2"></times><ci id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.3a.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.3"><mtext id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.3.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.3">Uniform</mtext></ci><interval closure="open" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1"><apply id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.2">ùë•</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.2.2.1.1.1.1.3">1</cn></apply><cn type="integer" id="S3.SS2.SSS0.Px1.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.3.m3.1.1">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p3.3.m3.2c">x_{2}\thicksim\text{Uniform}(x_{1},1)</annotation></semantics></math>, <math id="S3.SS2.SSS0.Px1.p3.4.m4.2" class="ltx_Math" alttext="y_{2}\thicksim\text{Uniform}(y_{1},1)" display="inline"><semantics id="S3.SS2.SSS0.Px1.p3.4.m4.2a"><mrow id="S3.SS2.SSS0.Px1.p3.4.m4.2.2" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.cmml"><msub id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.cmml"><mi id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.2" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.2.cmml">y</mi><mn id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.3" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.2" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.2.cmml">‚àº</mo><mrow id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.cmml"><mtext id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.3" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.3a.cmml">Uniform</mtext><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.2" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.2.cmml">‚Äã</mo><mrow id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.2.cmml">(</mo><msub id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.2" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.2.cmml">y</mi><mn id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.3" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.2.cmml">,</mo><mn id="S3.SS2.SSS0.Px1.p3.4.m4.1.1" xref="S3.SS2.SSS0.Px1.p3.4.m4.1.1.cmml">1</mn><mo stretchy="false" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.4" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p3.4.m4.2b"><apply id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2"><ci id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.2.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.2">‚àº</ci><apply id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.2">ùë¶</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.3.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.3.3">2</cn></apply><apply id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1"><times id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.2"></times><ci id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.3a.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.3"><mtext id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.3.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.3">Uniform</mtext></ci><interval closure="open" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1"><apply id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.2">ùë¶</ci><cn type="integer" id="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.2.2.1.1.1.1.3">1</cn></apply><cn type="integer" id="S3.SS2.SSS0.Px1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px1.p3.4.m4.1.1">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p3.4.m4.2c">y_{2}\thicksim\text{Uniform}(y_{1},1)</annotation></semantics></math>, while keeping the crop scale ratio in [0.1, 1.0].</p>
</div>
<div id="S3.SS2.SSS0.Px1.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p4.1" class="ltx_p">Intuitively, this causes the model to view an image not as a full image in itself, but as a region crop from some larger unknown image. This better matches the downstream use case of detection where recognition occurs at region- rather than image-level.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Focal Loss.</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.4" class="ltx_p">We desire to have finer control over how hard examples are weighted than what the softmax cross entropy loss can provide. Focal loss offers a natural option to tune the weights of hard examples¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> . Let <math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><msub id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">v</mi><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2">ùë£</ci><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">v_{i}</annotation></semantics></math> and <math id="S3.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="l_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a"><msub id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">l</mi><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2">ùëô</ci><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">l_{i}</annotation></semantics></math> be the normalized image and text embeddings, and the image-to-text (I2T) contrastive losses be <math id="S3.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="L_{\text{softmax}}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.3.m3.1a"><msub id="S3.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">L</mi><mtext id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3a.cmml">softmax</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2">ùêø</ci><ci id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3a.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3">softmax</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.3.m3.1c">L_{\text{softmax}}</annotation></semantics></math> and <math id="S3.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="L_{\text{focal}}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.4.m4.1a"><msub id="S3.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.2" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml">L</mi><mtext id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.3" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.3a.cmml">focal</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.4.m4.1b"><apply id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.2">ùêø</ci><ci id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.3a.cmml" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.3">focal</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.4.m4.1c">L_{\text{focal}}</annotation></semantics></math> for the softmax (baseline) or focal loss (RO-ViT). We define the losses mathematically below:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.3" class="ltx_Math" alttext="L_{\text{softmax}}=-{1\over{B}}\sum_{i=1}^{B}\log({\text{exp}(v_{i}l_{i}/\tau)\over{\sum_{j=1}^{B}\text{exp}(v_{i}l_{j}/\tau)}})" display="block"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.4" xref="S3.E2.m1.3.4.cmml"><msub id="S3.E2.m1.3.4.2" xref="S3.E2.m1.3.4.2.cmml"><mi id="S3.E2.m1.3.4.2.2" xref="S3.E2.m1.3.4.2.2.cmml">L</mi><mtext id="S3.E2.m1.3.4.2.3" xref="S3.E2.m1.3.4.2.3a.cmml">softmax</mtext></msub><mo id="S3.E2.m1.3.4.1" xref="S3.E2.m1.3.4.1.cmml">=</mo><mrow id="S3.E2.m1.3.4.3" xref="S3.E2.m1.3.4.3.cmml"><mo id="S3.E2.m1.3.4.3a" xref="S3.E2.m1.3.4.3.cmml">‚àí</mo><mrow id="S3.E2.m1.3.4.3.2" xref="S3.E2.m1.3.4.3.2.cmml"><mfrac id="S3.E2.m1.3.4.3.2.2" xref="S3.E2.m1.3.4.3.2.2.cmml"><mn id="S3.E2.m1.3.4.3.2.2.2" xref="S3.E2.m1.3.4.3.2.2.2.cmml">1</mn><mi id="S3.E2.m1.3.4.3.2.2.3" xref="S3.E2.m1.3.4.3.2.2.3.cmml">B</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.4.3.2.1" xref="S3.E2.m1.3.4.3.2.1.cmml">‚Äã</mo><mrow id="S3.E2.m1.3.4.3.2.3" xref="S3.E2.m1.3.4.3.2.3.cmml"><munderover id="S3.E2.m1.3.4.3.2.3.1" xref="S3.E2.m1.3.4.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E2.m1.3.4.3.2.3.1.2.2" xref="S3.E2.m1.3.4.3.2.3.1.2.2.cmml">‚àë</mo><mrow id="S3.E2.m1.3.4.3.2.3.1.2.3" xref="S3.E2.m1.3.4.3.2.3.1.2.3.cmml"><mi id="S3.E2.m1.3.4.3.2.3.1.2.3.2" xref="S3.E2.m1.3.4.3.2.3.1.2.3.2.cmml">i</mi><mo id="S3.E2.m1.3.4.3.2.3.1.2.3.1" xref="S3.E2.m1.3.4.3.2.3.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.3.4.3.2.3.1.2.3.3" xref="S3.E2.m1.3.4.3.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.3.4.3.2.3.1.3" xref="S3.E2.m1.3.4.3.2.3.1.3.cmml">B</mi></munderover><mrow id="S3.E2.m1.3.4.3.2.3.2.2" xref="S3.E2.m1.3.4.3.2.3.2.1.cmml"><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">log</mi><mo id="S3.E2.m1.3.4.3.2.3.2.2a" xref="S3.E2.m1.3.4.3.2.3.2.1.cmml">‚Å°</mo><mrow id="S3.E2.m1.3.4.3.2.3.2.2.1" xref="S3.E2.m1.3.4.3.2.3.2.1.cmml"><mo stretchy="false" id="S3.E2.m1.3.4.3.2.3.2.2.1.1" xref="S3.E2.m1.3.4.3.2.3.2.1.cmml">(</mo><mfrac id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mtext id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml">v</mi><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.2.1" xref="S3.E2.m1.1.1.1.1.1.1.2.1.cmml">‚Äã</mo><msub id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.2.3.2.cmml">l</mi><mi id="S3.E2.m1.1.1.1.1.1.1.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.3.cmml">i</mi></msub></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">œÑ</mi></mrow><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml"><msubsup id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mo id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml">‚àë</mo><mrow id="S3.E2.m1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.3.cmml"><mi id="S3.E2.m1.2.2.2.2.2.3.2" xref="S3.E2.m1.2.2.2.2.2.3.2.cmml">j</mi><mo id="S3.E2.m1.2.2.2.2.2.3.1" xref="S3.E2.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.2.2.2.2.3.3" xref="S3.E2.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">B</mi></msubsup><mrow id="S3.E2.m1.2.2.2.1" xref="S3.E2.m1.2.2.2.1.cmml"><mtext id="S3.E2.m1.2.2.2.1.3" xref="S3.E2.m1.2.2.2.1.3a.cmml">exp</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.1.2" xref="S3.E2.m1.2.2.2.1.2.cmml">‚Äã</mo><mrow id="S3.E2.m1.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.2.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.2.1.1.1.1.2.cmml"><msub id="S3.E2.m1.2.2.2.1.1.1.1.2.2" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.1.2.2.2" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2.2.cmml">v</mi><mi id="S3.E2.m1.2.2.2.1.1.1.1.2.2.3" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.1.1.1.1.2.1" xref="S3.E2.m1.2.2.2.1.1.1.1.2.1.cmml">‚Äã</mo><msub id="S3.E2.m1.2.2.2.1.1.1.1.2.3" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3.cmml"><mi id="S3.E2.m1.2.2.2.1.1.1.1.2.3.2" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3.2.cmml">l</mi><mi id="S3.E2.m1.2.2.2.1.1.1.1.2.3.3" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3.3.cmml">j</mi></msub></mrow><mo id="S3.E2.m1.2.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.2.1.1.1.1.1.cmml">/</mo><mi id="S3.E2.m1.2.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.1.3.cmml">œÑ</mi></mrow><mo stretchy="false" id="S3.E2.m1.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac><mo stretchy="false" id="S3.E2.m1.3.4.3.2.3.2.2.1.2" xref="S3.E2.m1.3.4.3.2.3.2.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.4.cmml" xref="S3.E2.m1.3.4"><eq id="S3.E2.m1.3.4.1.cmml" xref="S3.E2.m1.3.4.1"></eq><apply id="S3.E2.m1.3.4.2.cmml" xref="S3.E2.m1.3.4.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.4.2.1.cmml" xref="S3.E2.m1.3.4.2">subscript</csymbol><ci id="S3.E2.m1.3.4.2.2.cmml" xref="S3.E2.m1.3.4.2.2">ùêø</ci><ci id="S3.E2.m1.3.4.2.3a.cmml" xref="S3.E2.m1.3.4.2.3"><mtext mathsize="70%" id="S3.E2.m1.3.4.2.3.cmml" xref="S3.E2.m1.3.4.2.3">softmax</mtext></ci></apply><apply id="S3.E2.m1.3.4.3.cmml" xref="S3.E2.m1.3.4.3"><minus id="S3.E2.m1.3.4.3.1.cmml" xref="S3.E2.m1.3.4.3"></minus><apply id="S3.E2.m1.3.4.3.2.cmml" xref="S3.E2.m1.3.4.3.2"><times id="S3.E2.m1.3.4.3.2.1.cmml" xref="S3.E2.m1.3.4.3.2.1"></times><apply id="S3.E2.m1.3.4.3.2.2.cmml" xref="S3.E2.m1.3.4.3.2.2"><divide id="S3.E2.m1.3.4.3.2.2.1.cmml" xref="S3.E2.m1.3.4.3.2.2"></divide><cn type="integer" id="S3.E2.m1.3.4.3.2.2.2.cmml" xref="S3.E2.m1.3.4.3.2.2.2">1</cn><ci id="S3.E2.m1.3.4.3.2.2.3.cmml" xref="S3.E2.m1.3.4.3.2.2.3">ùêµ</ci></apply><apply id="S3.E2.m1.3.4.3.2.3.cmml" xref="S3.E2.m1.3.4.3.2.3"><apply id="S3.E2.m1.3.4.3.2.3.1.cmml" xref="S3.E2.m1.3.4.3.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.4.3.2.3.1.1.cmml" xref="S3.E2.m1.3.4.3.2.3.1">superscript</csymbol><apply id="S3.E2.m1.3.4.3.2.3.1.2.cmml" xref="S3.E2.m1.3.4.3.2.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.4.3.2.3.1.2.1.cmml" xref="S3.E2.m1.3.4.3.2.3.1">subscript</csymbol><sum id="S3.E2.m1.3.4.3.2.3.1.2.2.cmml" xref="S3.E2.m1.3.4.3.2.3.1.2.2"></sum><apply id="S3.E2.m1.3.4.3.2.3.1.2.3.cmml" xref="S3.E2.m1.3.4.3.2.3.1.2.3"><eq id="S3.E2.m1.3.4.3.2.3.1.2.3.1.cmml" xref="S3.E2.m1.3.4.3.2.3.1.2.3.1"></eq><ci id="S3.E2.m1.3.4.3.2.3.1.2.3.2.cmml" xref="S3.E2.m1.3.4.3.2.3.1.2.3.2">ùëñ</ci><cn type="integer" id="S3.E2.m1.3.4.3.2.3.1.2.3.3.cmml" xref="S3.E2.m1.3.4.3.2.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.3.4.3.2.3.1.3.cmml" xref="S3.E2.m1.3.4.3.2.3.1.3">ùêµ</ci></apply><apply id="S3.E2.m1.3.4.3.2.3.2.1.cmml" xref="S3.E2.m1.3.4.3.2.3.2.2"><log id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3"></log><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><divide id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2"></divide><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><ci id="S3.E2.m1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.3"><mtext id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">exp</mtext></ci><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><divide id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></divide><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><times id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.1"></times><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2">ùë£</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.3">ùëñ</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3.2">ùëô</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3.3">ùëñ</ci></apply></apply><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">ùúè</ci></apply></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2">superscript</csymbol><apply id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2">subscript</csymbol><sum id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"></sum><apply id="S3.E2.m1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.3"><eq id="S3.E2.m1.2.2.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.2.2.3.1"></eq><ci id="S3.E2.m1.2.2.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.2.2.3.2">ùëó</ci><cn type="integer" id="S3.E2.m1.2.2.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3">ùêµ</ci></apply><apply id="S3.E2.m1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.1"><times id="S3.E2.m1.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.1.2"></times><ci id="S3.E2.m1.2.2.2.1.3a.cmml" xref="S3.E2.m1.2.2.2.1.3"><mtext id="S3.E2.m1.2.2.2.1.3.cmml" xref="S3.E2.m1.2.2.2.1.3">exp</mtext></ci><apply id="S3.E2.m1.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1"><divide id="S3.E2.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.1"></divide><apply id="S3.E2.m1.2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2"><times id="S3.E2.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.1"></times><apply id="S3.E2.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2.2">ùë£</ci><ci id="S3.E2.m1.2.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.2.3">ùëñ</ci></apply><apply id="S3.E2.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E2.m1.2.2.2.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3.2">ùëô</ci><ci id="S3.E2.m1.2.2.2.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.2.3.3">ùëó</ci></apply></apply><ci id="S3.E2.m1.2.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.1.1.1.1.3">ùúè</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">L_{\text{softmax}}=-{1\over{B}}\sum_{i=1}^{B}\log({\text{exp}(v_{i}l_{i}/\tau)\over{\sum_{j=1}^{B}\text{exp}(v_{i}l_{j}/\tau)}})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="L_{\text{focal}}=-{1\over{B}}\sum_{i=1}^{B}\sum_{j=1}^{B}(1-p_{i})^{\gamma}\text{log}(p_{i})" display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mi id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml">L</mi><mtext id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3a.cmml">focal</mtext></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><mo id="S3.E3.m1.2.2.2a" xref="S3.E3.m1.2.2.2.cmml">‚àí</mo><mrow id="S3.E3.m1.2.2.2.2" xref="S3.E3.m1.2.2.2.2.cmml"><mfrac id="S3.E3.m1.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.4.cmml"><mn id="S3.E3.m1.2.2.2.2.4.2" xref="S3.E3.m1.2.2.2.2.4.2.cmml">1</mn><mi id="S3.E3.m1.2.2.2.2.4.3" xref="S3.E3.m1.2.2.2.2.4.3.cmml">B</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.3.cmml">‚Äã</mo><mrow id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.cmml"><munderover id="S3.E3.m1.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.3.cmml"><mo movablelimits="false" rspace="0em" id="S3.E3.m1.2.2.2.2.2.3.2.2" xref="S3.E3.m1.2.2.2.2.2.3.2.2.cmml">‚àë</mo><mrow id="S3.E3.m1.2.2.2.2.2.3.2.3" xref="S3.E3.m1.2.2.2.2.2.3.2.3.cmml"><mi id="S3.E3.m1.2.2.2.2.2.3.2.3.2" xref="S3.E3.m1.2.2.2.2.2.3.2.3.2.cmml">i</mi><mo id="S3.E3.m1.2.2.2.2.2.3.2.3.1" xref="S3.E3.m1.2.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E3.m1.2.2.2.2.2.3.2.3.3" xref="S3.E3.m1.2.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.2.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.2.3.3.cmml">B</mi></munderover><mrow id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><munderover id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml"><mo movablelimits="false" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.3.2.2" xref="S3.E3.m1.2.2.2.2.2.2.3.2.2.cmml">‚àë</mo><mrow id="S3.E3.m1.2.2.2.2.2.2.3.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.3.2.3.2" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.2.cmml">j</mi><mo id="S3.E3.m1.2.2.2.2.2.2.3.2.3.1" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E3.m1.2.2.2.2.2.2.3.2.3.3" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.2.2.2.2.2.2.3.3" xref="S3.E3.m1.2.2.2.2.2.2.3.3.cmml">B</mi></munderover><mrow id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml"><msup id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">‚àí</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml">Œ≥</mi></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.2.3.cmml">‚Äã</mo><mtext id="S3.E3.m1.2.2.2.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.2.2.2.4a.cmml">log</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.2.3a" xref="S3.E3.m1.2.2.2.2.2.2.2.3.cmml">‚Äã</mo><mrow id="S3.E3.m1.2.2.2.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.2.2.2.2.2.2.1.2" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.cmml">(</mo><msub id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.2" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.2.cmml">p</mi><mi id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.3" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.2.2.2.2.2.2.2.2.1.3" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2">ùêø</ci><ci id="S3.E3.m1.2.2.4.3a.cmml" xref="S3.E3.m1.2.2.4.3"><mtext mathsize="70%" id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3">focal</mtext></ci></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><minus id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2"></minus><apply id="S3.E3.m1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2"><times id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.3"></times><apply id="S3.E3.m1.2.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.2.4"><divide id="S3.E3.m1.2.2.2.2.4.1.cmml" xref="S3.E3.m1.2.2.2.2.4"></divide><cn type="integer" id="S3.E3.m1.2.2.2.2.4.2.cmml" xref="S3.E3.m1.2.2.2.2.4.2">1</cn><ci id="S3.E3.m1.2.2.2.2.4.3.cmml" xref="S3.E3.m1.2.2.2.2.4.3">ùêµ</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2"><apply id="S3.E3.m1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.3">superscript</csymbol><apply id="S3.E3.m1.2.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.3.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.3">subscript</csymbol><sum id="S3.E3.m1.2.2.2.2.2.3.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2.2"></sum><apply id="S3.E3.m1.2.2.2.2.2.3.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2.3"><eq id="S3.E3.m1.2.2.2.2.2.3.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2.3.1"></eq><ci id="S3.E3.m1.2.2.2.2.2.3.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2.3.2">ùëñ</ci><cn type="integer" id="S3.E3.m1.2.2.2.2.2.3.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.2.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.3.3">ùêµ</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><apply id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3">superscript</csymbol><apply id="S3.E3.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3">subscript</csymbol><sum id="S3.E3.m1.2.2.2.2.2.2.3.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.2"></sum><apply id="S3.E3.m1.2.2.2.2.2.2.3.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3"><eq id="S3.E3.m1.2.2.2.2.2.2.3.2.3.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.1"></eq><ci id="S3.E3.m1.2.2.2.2.2.2.3.2.3.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.2">ùëó</ci><cn type="integer" id="S3.E3.m1.2.2.2.2.2.2.3.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3.3">ùêµ</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2"><times id="S3.E3.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.3"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2">1</cn><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2">ùëù</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3">ùëñ</ci></apply></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">ùõæ</ci></apply><ci id="S3.E3.m1.2.2.2.2.2.2.2.4a.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.4"><mtext id="S3.E3.m1.2.2.2.2.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.4">log</mtext></ci><apply id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.2">ùëù</ci><ci id="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2.2.1.1.3">ùëñ</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">L_{\text{focal}}=-{1\over{B}}\sum_{i=1}^{B}\sum_{j=1}^{B}(1-p_{i})^{\gamma}\text{log}(p_{i})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p3.1" class="ltx_p">, where <math id="S3.SS2.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.1.m1.1a"><msub id="S3.SS2.SSS0.Px2.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.2.cmml">p</mi><mi id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.2">ùëù</ci><ci id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.1.m1.1c">p_{i}</annotation></semantics></math> denotes the true class probability as below:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.4" class="ltx_Math" alttext="p_{i}=\begin{cases}\sigma(v_{i}l_{j}/\tau)&amp;\text{if }i=j\\
1-\sigma(v_{i}l_{j}/\tau)&amp;\text{if }i\neq j\end{cases}" display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.5" xref="S3.E4.m1.4.5.cmml"><msub id="S3.E4.m1.4.5.2" xref="S3.E4.m1.4.5.2.cmml"><mi id="S3.E4.m1.4.5.2.2" xref="S3.E4.m1.4.5.2.2.cmml">p</mi><mi id="S3.E4.m1.4.5.2.3" xref="S3.E4.m1.4.5.2.3.cmml">i</mi></msub><mo id="S3.E4.m1.4.5.1" xref="S3.E4.m1.4.5.1.cmml">=</mo><mrow id="S3.E4.m1.4.4" xref="S3.E4.m1.4.5.3.1.cmml"><mo id="S3.E4.m1.4.4.5" xref="S3.E4.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E4.m1.4.4.4" xref="S3.E4.m1.4.5.3.1.cmml"><mtr id="S3.E4.m1.4.4.4a" xref="S3.E4.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4b" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">œÉ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">v</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">‚Äã</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">l</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">j</mi></msub></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml">œÑ</mi></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4c" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1" xref="S3.E4.m1.2.2.2.2.2.1.cmml"><mrow id="S3.E4.m1.2.2.2.2.2.1.2" xref="S3.E4.m1.2.2.2.2.2.1.2.cmml"><mtext id="S3.E4.m1.2.2.2.2.2.1.2.2" xref="S3.E4.m1.2.2.2.2.2.1.2.2a.cmml">if¬†</mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.1.2.1" xref="S3.E4.m1.2.2.2.2.2.1.2.1.cmml">‚Äã</mo><mi id="S3.E4.m1.2.2.2.2.2.1.2.3" xref="S3.E4.m1.2.2.2.2.2.1.2.3.cmml">i</mi></mrow><mo id="S3.E4.m1.2.2.2.2.2.1.1" xref="S3.E4.m1.2.2.2.2.2.1.1.cmml">=</mo><mi id="S3.E4.m1.2.2.2.2.2.1.3" xref="S3.E4.m1.2.2.2.2.2.1.3.cmml">j</mi></mrow></mtd></mtr><mtr id="S3.E4.m1.4.4.4d" xref="S3.E4.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4e" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.3.3.3.3.1.1" xref="S3.E4.m1.3.3.3.3.1.1.cmml"><mn id="S3.E4.m1.3.3.3.3.1.1.3" xref="S3.E4.m1.3.3.3.3.1.1.3.cmml">1</mn><mo id="S3.E4.m1.3.3.3.3.1.1.2" xref="S3.E4.m1.3.3.3.3.1.1.2.cmml">‚àí</mo><mrow id="S3.E4.m1.3.3.3.3.1.1.1" xref="S3.E4.m1.3.3.3.3.1.1.1.cmml"><mi id="S3.E4.m1.3.3.3.3.1.1.1.3" xref="S3.E4.m1.3.3.3.3.1.1.1.3.cmml">œÉ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.3.3.1.1.1.2" xref="S3.E4.m1.3.3.3.3.1.1.1.2.cmml">‚Äã</mo><mrow id="S3.E4.m1.3.3.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.3.3.1.1.1.1.1.2" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.cmml"><msub id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.2.cmml">v</mi><mi id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.1" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.1.cmml">‚Äã</mo><msub id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.2" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.2.cmml">l</mi><mi id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.3" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.3.cmml">j</mi></msub></mrow><mo id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.1.cmml">/</mo><mi id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.3.cmml">œÑ</mi></mrow><mo stretchy="false" id="S3.E4.m1.3.3.3.3.1.1.1.1.1.3" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E4.m1.4.4.4f" xref="S3.E4.m1.4.5.3.1.cmml"><mrow id="S3.E4.m1.4.4.4.4.2.1" xref="S3.E4.m1.4.4.4.4.2.1.cmml"><mrow id="S3.E4.m1.4.4.4.4.2.1.2" xref="S3.E4.m1.4.4.4.4.2.1.2.cmml"><mtext id="S3.E4.m1.4.4.4.4.2.1.2.2" xref="S3.E4.m1.4.4.4.4.2.1.2.2a.cmml">if¬†</mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.4.4.2.1.2.1" xref="S3.E4.m1.4.4.4.4.2.1.2.1.cmml">‚Äã</mo><mi id="S3.E4.m1.4.4.4.4.2.1.2.3" xref="S3.E4.m1.4.4.4.4.2.1.2.3.cmml">i</mi></mrow><mo id="S3.E4.m1.4.4.4.4.2.1.1" xref="S3.E4.m1.4.4.4.4.2.1.1.cmml">‚â†</mo><mi id="S3.E4.m1.4.4.4.4.2.1.3" xref="S3.E4.m1.4.4.4.4.2.1.3.cmml">j</mi></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.5.cmml" xref="S3.E4.m1.4.5"><eq id="S3.E4.m1.4.5.1.cmml" xref="S3.E4.m1.4.5.1"></eq><apply id="S3.E4.m1.4.5.2.cmml" xref="S3.E4.m1.4.5.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.5.2.1.cmml" xref="S3.E4.m1.4.5.2">subscript</csymbol><ci id="S3.E4.m1.4.5.2.2.cmml" xref="S3.E4.m1.4.5.2.2">ùëù</ci><ci id="S3.E4.m1.4.5.2.3.cmml" xref="S3.E4.m1.4.5.2.3">ùëñ</ci></apply><apply id="S3.E4.m1.4.5.3.1.cmml" xref="S3.E4.m1.4.4"><csymbol cd="latexml" id="S3.E4.m1.4.5.3.1.1.cmml" xref="S3.E4.m1.4.4.5">cases</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">ùúé</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><divide id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"></divide><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1"></times><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.2">ùë£</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.3">ùëñ</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.2">ùëô</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.3">ùëó</ci></apply></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3">ùúè</ci></apply></apply><apply id="S3.E4.m1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1"><eq id="S3.E4.m1.2.2.2.2.2.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.1"></eq><apply id="S3.E4.m1.2.2.2.2.2.1.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2"><times id="S3.E4.m1.2.2.2.2.2.1.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.1"></times><ci id="S3.E4.m1.2.2.2.2.2.1.2.2a.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.2"><mtext id="S3.E4.m1.2.2.2.2.2.1.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.2">if¬†</mtext></ci><ci id="S3.E4.m1.2.2.2.2.2.1.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.2.3">ùëñ</ci></apply><ci id="S3.E4.m1.2.2.2.2.2.1.3.cmml" xref="S3.E4.m1.2.2.2.2.2.1.3">ùëó</ci></apply><apply id="S3.E4.m1.3.3.3.3.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1"><minus id="S3.E4.m1.3.3.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.3.3.1.1.2"></minus><cn type="integer" id="S3.E4.m1.3.3.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.3.3.1.1.3">1</cn><apply id="S3.E4.m1.3.3.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1"><times id="S3.E4.m1.3.3.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.2"></times><ci id="S3.E4.m1.3.3.3.3.1.1.1.3.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.3">ùúé</ci><apply id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1"><divide id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.1"></divide><apply id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2"><times id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.1"></times><apply id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.2">ùë£</ci><ci id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.2.3">ùëñ</ci></apply><apply id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.2">ùëô</ci><ci id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.2.3.3">ùëó</ci></apply></apply><ci id="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.3.3.1.1.1.1.1.1.3">ùúè</ci></apply></apply></apply><apply id="S3.E4.m1.4.4.4.4.2.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1"><neq id="S3.E4.m1.4.4.4.4.2.1.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1.1"></neq><apply id="S3.E4.m1.4.4.4.4.2.1.2.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2"><times id="S3.E4.m1.4.4.4.4.2.1.2.1.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.1"></times><ci id="S3.E4.m1.4.4.4.4.2.1.2.2a.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.2"><mtext id="S3.E4.m1.4.4.4.4.2.1.2.2.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.2">if¬†</mtext></ci><ci id="S3.E4.m1.4.4.4.4.2.1.2.3.cmml" xref="S3.E4.m1.4.4.4.4.2.1.2.3">ùëñ</ci></apply><ci id="S3.E4.m1.4.4.4.4.2.1.3.cmml" xref="S3.E4.m1.4.4.4.4.2.1.3">ùëó</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">p_{i}=\begin{cases}\sigma(v_{i}l_{j}/\tau)&amp;\text{if }i=j\\
1-\sigma(v_{i}l_{j}/\tau)&amp;\text{if }i\neq j\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px2.p3.2" class="ltx_p">Here <math id="S3.SS2.SSS0.Px2.p3.2.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.2.m1.1a"><mi id="S3.SS2.SSS0.Px2.p3.2.m1.1.1" xref="S3.SS2.SSS0.Px2.p3.2.m1.1.1.cmml">œÉ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.2.m1.1b"><ci id="S3.SS2.SSS0.Px2.p3.2.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m1.1.1">ùúé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.2.m1.1c">\sigma</annotation></semantics></math> denotes the sigmoid function. We adopt the simpler non alpha-balanced form of focal loss¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. The text-to-image (T2I) contrastive losses are symmetrical with the I2T losses by simply exchanging the inner/outer summation loops. The total loss is the sum of both I2T and T2I losses.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Open-vocabulary Detector Finetuning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p">Here we present two simple techniques to improve the downstream open-vocabulary detector (Sec.¬†<a href="#S3.SS1" title="3.1 Preliminaries ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>). Despite the backbone features pretrained from the vast open-vocabulary data, the added detector layers (neck and heads) are newly trained with the downstream detection dataset (<em id="S3.SS3.p1.2.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS3.p1.2.2" class="ltx_text"></span>, LVIS base categories). Existing approaches often miss novel/unlabeled objects in the object proposal stage because the proposals tend to classify them as background. To remedy this, we leverage recent advances in novel object proposal method¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and adopt the localization quality-based objectness (<em id="S3.SS3.p1.2.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p1.2.4" class="ltx_text"></span>, centerness score) instead of object-or-not binary classification score. Following¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, we use a single anchor per location and combine the predicted objectness score <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="o_{i}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">o</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ùëú</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">o_{i}</annotation></semantics></math> with the ensemble detection score in Equation¬†<a href="#S3.E1" title="Equation 1 ‚Ä£ Open-vocabulary object detector. ‚Ä£ 3.1 Preliminaries ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> to obtain the final OVD score as: <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="{S_{i}}^{\text{OVD}}={o_{i}}^{\delta}\cdot{s_{i}}^{\text{OVD}.}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.2" xref="S3.SS3.p1.2.m2.1.2.cmml"><mmultiscripts id="S3.SS3.p1.2.m2.1.2.2" xref="S3.SS3.p1.2.m2.1.2.2.cmml"><mi id="S3.SS3.p1.2.m2.1.2.2.2.2" xref="S3.SS3.p1.2.m2.1.2.2.2.2.cmml">S</mi><mi id="S3.SS3.p1.2.m2.1.2.2.2.3" xref="S3.SS3.p1.2.m2.1.2.2.2.3.cmml">i</mi><mrow id="S3.SS3.p1.2.m2.1.2.2a" xref="S3.SS3.p1.2.m2.1.2.2.cmml"></mrow><mrow id="S3.SS3.p1.2.m2.1.2.2b" xref="S3.SS3.p1.2.m2.1.2.2.cmml"></mrow><mtext id="S3.SS3.p1.2.m2.1.2.2.3" xref="S3.SS3.p1.2.m2.1.2.2.3a.cmml">OVD</mtext></mmultiscripts><mo id="S3.SS3.p1.2.m2.1.2.1" xref="S3.SS3.p1.2.m2.1.2.1.cmml">=</mo><mrow id="S3.SS3.p1.2.m2.1.2.3" xref="S3.SS3.p1.2.m2.1.2.3.cmml"><mmultiscripts id="S3.SS3.p1.2.m2.1.2.3.2" xref="S3.SS3.p1.2.m2.1.2.3.2.cmml"><mi id="S3.SS3.p1.2.m2.1.2.3.2.2.2" xref="S3.SS3.p1.2.m2.1.2.3.2.2.2.cmml">o</mi><mi id="S3.SS3.p1.2.m2.1.2.3.2.2.3" xref="S3.SS3.p1.2.m2.1.2.3.2.2.3.cmml">i</mi><mrow id="S3.SS3.p1.2.m2.1.2.3.2a" xref="S3.SS3.p1.2.m2.1.2.3.2.cmml"></mrow><mrow id="S3.SS3.p1.2.m2.1.2.3.2b" xref="S3.SS3.p1.2.m2.1.2.3.2.cmml"></mrow><mi id="S3.SS3.p1.2.m2.1.2.3.2.3" xref="S3.SS3.p1.2.m2.1.2.3.2.3.cmml">Œ¥</mi></mmultiscripts><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.2.m2.1.2.3.1" xref="S3.SS3.p1.2.m2.1.2.3.1.cmml">‚ãÖ</mo><mmultiscripts id="S3.SS3.p1.2.m2.1.2.3.3" xref="S3.SS3.p1.2.m2.1.2.3.3.cmml"><mi id="S3.SS3.p1.2.m2.1.2.3.3.2.2" xref="S3.SS3.p1.2.m2.1.2.3.3.2.2.cmml">s</mi><mi id="S3.SS3.p1.2.m2.1.2.3.3.2.3" xref="S3.SS3.p1.2.m2.1.2.3.3.2.3.cmml">i</mi><mrow id="S3.SS3.p1.2.m2.1.2.3.3a" xref="S3.SS3.p1.2.m2.1.2.3.3.cmml"></mrow><mrow id="S3.SS3.p1.2.m2.1.2.3.3b" xref="S3.SS3.p1.2.m2.1.2.3.3.cmml"></mrow><mrow id="S3.SS3.p1.2.m2.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.2.cmml"><mtext id="S3.SS3.p1.2.m2.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1a.cmml">OVD</mtext><mo lspace="0em" id="S3.SS3.p1.2.m2.1.1.1.3.1" xref="S3.SS3.p1.2.m2.1.1.1.2.cmml">.</mo></mrow></mmultiscripts></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.2.cmml" xref="S3.SS3.p1.2.m2.1.2"><eq id="S3.SS3.p1.2.m2.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.1"></eq><apply id="S3.SS3.p1.2.m2.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.2">superscript</csymbol><apply id="S3.SS3.p1.2.m2.1.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.2.2.2">ùëÜ</ci><ci id="S3.SS3.p1.2.m2.1.2.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.2.2.3">ùëñ</ci></apply><ci id="S3.SS3.p1.2.m2.1.2.2.3a.cmml" xref="S3.SS3.p1.2.m2.1.2.2.3"><mtext mathsize="70%" id="S3.SS3.p1.2.m2.1.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.2.3">OVD</mtext></ci></apply><apply id="S3.SS3.p1.2.m2.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.3"><ci id="S3.SS3.p1.2.m2.1.2.3.1.cmml" xref="S3.SS3.p1.2.m2.1.2.3.1">‚ãÖ</ci><apply id="S3.SS3.p1.2.m2.1.2.3.2.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.3.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2">superscript</csymbol><apply id="S3.SS3.p1.2.m2.1.2.3.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.3.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.2.3.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2.2.2">ùëú</ci><ci id="S3.SS3.p1.2.m2.1.2.3.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2.2.3">ùëñ</ci></apply><ci id="S3.SS3.p1.2.m2.1.2.3.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.3.2.3">ùõø</ci></apply><apply id="S3.SS3.p1.2.m2.1.2.3.3.cmml" xref="S3.SS3.p1.2.m2.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.3.3.1.cmml" xref="S3.SS3.p1.2.m2.1.2.3.3">superscript</csymbol><apply id="S3.SS3.p1.2.m2.1.2.3.3.2.cmml" xref="S3.SS3.p1.2.m2.1.2.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.2.3.3.2.1.cmml" xref="S3.SS3.p1.2.m2.1.2.3.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.2.3.3.2.2.cmml" xref="S3.SS3.p1.2.m2.1.2.3.3.2.2">ùë†</ci><ci id="S3.SS3.p1.2.m2.1.2.3.3.2.3.cmml" xref="S3.SS3.p1.2.m2.1.2.3.3.2.3">ùëñ</ci></apply><list id="S3.SS3.p1.2.m2.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3"><ci id="S3.SS3.p1.2.m2.1.1.1.1a.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1"><mtext mathsize="70%" id="S3.SS3.p1.2.m2.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1">OVD</mtext></ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">{S_{i}}^{\text{OVD}}={o_{i}}^{\delta}\cdot{s_{i}}^{\text{OVD}.}</annotation></semantics></math>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.12" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S3.T1.1.1.2.1" class="ltx_text" style="font-size:80%;">method</span></td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.1.1.3.1" class="ltx_text" style="font-size:80%;">pretrained</span></td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.1.1.4.1" class="ltx_text" style="font-size:80%;">detector</span></td>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S3.T1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">AP<sub id="S3.T1.1.1.1.1.2" class="ltx_sub"><span id="S3.T1.1.1.1.1.2.1" class="ltx_text ltx_font_medium ltx_font_italic">r</span></sub></span></td>
<td id="S3.T1.1.1.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="2"><span id="S3.T1.1.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></td>
</tr>
<tr id="S3.T1.12.13.1" class="ltx_tr">
<td id="S3.T1.12.13.1.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.13.1.1.1" class="ltx_text" style="font-size:80%;">model</span></td>
<td id="S3.T1.12.13.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.13.1.2.1" class="ltx_text" style="font-size:80%;">backbone</span></td>
</tr>
<tr id="S3.T1.12.14.2" class="ltx_tr">
<td id="S3.T1.12.14.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.14.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ConvNet based:</span></td>
<td id="S3.T1.12.14.2.2" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S3.T1.12.14.2.3" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S3.T1.12.14.2.4" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S3.T1.12.14.2.5" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr id="S3.T1.12.15.3" class="ltx_tr">
<td id="S3.T1.12.15.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.15.3.1.1" class="ltx_text" style="font-size:80%;">DetPro-Cascade¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.15.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S3.T1.12.15.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.15.3.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.15.3.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.15.3.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.15.3.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S3.T1.12.15.3.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.15.3.4.1" class="ltx_text" style="font-size:80%;">20.0</span></td>
<td id="S3.T1.12.15.3.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.15.3.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.0</span></td>
</tr>
<tr id="S3.T1.12.16.4" class="ltx_tr">
<td id="S3.T1.12.16.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.16.4.1.1" class="ltx_text" style="font-size:80%;">Detic-CN2¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.16.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S3.T1.12.16.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.16.4.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.16.4.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.16.4.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.16.4.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S3.T1.12.16.4.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.16.4.4.1" class="ltx_text" style="font-size:80%;">24.6</span></td>
<td id="S3.T1.12.16.4.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.16.4.5.1" class="ltx_text" style="font-size:80%;color:#808080;">32.4</span></td>
</tr>
<tr id="S3.T1.12.17.5" class="ltx_tr">
<td id="S3.T1.12.17.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.17.5.1.1" class="ltx_text" style="font-size:80%;">RegionCLIP¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.17.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib62" title="" class="ltx_ref">62</a><span id="S3.T1.12.17.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.17.5.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.17.5.2.1" class="ltx_text" style="font-size:80%;">R-50x4</span></td>
<td id="S3.T1.12.17.5.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.17.5.3.1" class="ltx_text" style="font-size:80%;">R-50x4</span></td>
<td id="S3.T1.12.17.5.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.17.5.4.1" class="ltx_text" style="font-size:80%;">22.0</span></td>
<td id="S3.T1.12.17.5.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.17.5.5.1" class="ltx_text" style="font-size:80%;color:#808080;">32.3</span></td>
</tr>
<tr id="S3.T1.12.18.6" class="ltx_tr">
<td id="S3.T1.12.18.6.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.18.6.1.1" class="ltx_text" style="font-size:80%;">ViLD-Ens¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.18.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S3.T1.12.18.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.18.6.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.18.6.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.18.6.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.18.6.3.1" class="ltx_text" style="font-size:80%;">R-152</span></td>
<td id="S3.T1.12.18.6.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.18.6.4.1" class="ltx_text" style="font-size:80%;">18.7</span></td>
<td id="S3.T1.12.18.6.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.18.6.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.0</span></td>
</tr>
<tr id="S3.T1.12.19.7" class="ltx_tr">
<td id="S3.T1.12.19.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.19.7.1.1" class="ltx_text" style="font-size:80%;">ViLD-Ens¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.19.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S3.T1.12.19.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.19.7.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.19.7.2.1" class="ltx_text" style="font-size:80%;">ViT-L/14</span></td>
<td id="S3.T1.12.19.7.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.19.7.3.1" class="ltx_text" style="font-size:80%;">EffNet-B7</span></td>
<td id="S3.T1.12.19.7.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.19.7.4.1" class="ltx_text" style="font-size:80%;">21.7</span></td>
<td id="S3.T1.12.19.7.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.19.7.5.1" class="ltx_text" style="font-size:80%;color:#808080;">29.6</span></td>
</tr>
<tr id="S3.T1.12.20.8" class="ltx_tr">
<td id="S3.T1.12.20.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.20.8.1.1" class="ltx_text" style="font-size:80%;">ViLD-Ens¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.20.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S3.T1.12.20.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.20.8.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.20.8.2.1" class="ltx_text" style="font-size:80%;">EffNet-B7</span></td>
<td id="S3.T1.12.20.8.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.20.8.3.1" class="ltx_text" style="font-size:80%;">EffNet-B7</span></td>
<td id="S3.T1.12.20.8.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.20.8.4.1" class="ltx_text" style="font-size:80%;">26.3</span></td>
<td id="S3.T1.12.20.8.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.20.8.5.1" class="ltx_text" style="font-size:80%;color:#808080;">29.3</span></td>
</tr>
<tr id="S3.T1.12.21.9" class="ltx_tr">
<td id="S3.T1.12.21.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.21.9.1.1" class="ltx_text" style="font-size:80%;">VL-PLM¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.21.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib59" title="" class="ltx_ref">59</a><span id="S3.T1.12.21.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.21.9.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.21.9.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.21.9.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.21.9.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S3.T1.12.21.9.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.21.9.4.1" class="ltx_text" style="font-size:80%;">17.2</span></td>
<td id="S3.T1.12.21.9.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.21.9.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.0</span></td>
</tr>
<tr id="S3.T1.12.22.10" class="ltx_tr">
<td id="S3.T1.12.22.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.22.10.1.1" class="ltx_text" style="font-size:80%;">OV-DETR¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.22.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib55" title="" class="ltx_ref">55</a><span id="S3.T1.12.22.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.22.10.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.22.10.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.22.10.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.22.10.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S3.T1.12.22.10.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.22.10.4.1" class="ltx_text" style="font-size:80%;">17.4</span></td>
<td id="S3.T1.12.22.10.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.22.10.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.6</span></td>
</tr>
<tr id="S3.T1.12.23.11" class="ltx_tr">
<td id="S3.T1.12.23.11.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.23.11.1.1" class="ltx_text" style="font-size:80%;">Rasheed¬†</span><em id="S3.T1.12.23.11.1.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">et al</em><span id="S3.T1.12.23.11.1.3" class="ltx_text" style="font-size:80%;">.</span><span id="S3.T1.12.23.11.1.4" class="ltx_text"></span><span id="S3.T1.12.23.11.1.5" class="ltx_text" style="font-size:80%;">¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.23.11.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib42" title="" class="ltx_ref">42</a><span id="S3.T1.12.23.11.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.23.11.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.23.11.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.23.11.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.23.11.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S3.T1.12.23.11.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.23.11.4.1" class="ltx_text" style="font-size:80%;">21.1</span></td>
<td id="S3.T1.12.23.11.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.23.11.5.1" class="ltx_text" style="font-size:80%;color:#808080;">25.9</span></td>
</tr>
<tr id="S3.T1.12.24.12" class="ltx_tr">
<td id="S3.T1.12.24.12.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.12.24.12.1.1" class="ltx_text" style="font-size:80%;">PromptDet¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.12.24.12.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S3.T1.12.24.12.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.12.24.12.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.24.12.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S3.T1.12.24.12.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.24.12.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S3.T1.12.24.12.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.24.12.4.1" class="ltx_text" style="font-size:80%;">21.4</span></td>
<td id="S3.T1.12.24.12.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.24.12.5.1" class="ltx_text" style="font-size:80%;color:#808080;">25.3</span></td>
</tr>
<tr id="S3.T1.12.25.13" class="ltx_tr">
<td id="S3.T1.12.25.13.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.25.13.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ViT based:</span></td>
<td id="S3.T1.12.25.13.2" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S3.T1.12.25.13.3" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S3.T1.12.25.13.4" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
<td id="S3.T1.12.25.13.5" class="ltx_td ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<td id="S3.T1.3.3.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.3.3.3.1" class="ltx_text" style="font-size:80%;">OWL-ViT¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.3.3.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib36" title="" class="ltx_ref">36</a><span id="S3.T1.3.3.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.3.3.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.3.3.4.1" class="ltx_text" style="font-size:80%;">ViT-H/14</span></td>
<td id="S3.T1.3.3.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.3.3.5.1" class="ltx_text" style="font-size:80%;">ViT-H/14</span></td>
<td id="S3.T1.2.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.2.2.1.1" class="ltx_text" style="font-size:80%;color:#808080;">23.3<sup id="S3.T1.2.2.1.1.1" class="ltx_sup"><span id="S3.T1.2.2.1.1.1.1" class="ltx_text" style="color:#000000;">‚àó</span></sup></span></td>
<td id="S3.T1.3.3.2" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.3.3.2.1" class="ltx_text" style="font-size:80%;color:#808080;">35.3<sup id="S3.T1.3.3.2.1.1" class="ltx_sup">‚àó</sup></span></td>
</tr>
<tr id="S3.T1.5.5" class="ltx_tr">
<td id="S3.T1.5.5.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.5.5.3.1" class="ltx_text" style="font-size:80%;">OWL-ViT¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.T1.5.5.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib36" title="" class="ltx_ref">36</a><span id="S3.T1.5.5.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S3.T1.5.5.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.5.5.4.1" class="ltx_text" style="font-size:80%;">ViT-L/14</span></td>
<td id="S3.T1.5.5.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.5.5.5.1" class="ltx_text" style="font-size:80%;">ViT-L/14</span></td>
<td id="S3.T1.4.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.4.4.1.1" class="ltx_text" style="font-size:80%;color:#808080;">25.6<sup id="S3.T1.4.4.1.1.1" class="ltx_sup"><span id="S3.T1.4.4.1.1.1.1" class="ltx_text" style="color:#000000;">‚àó</span></sup></span></td>
<td id="S3.T1.5.5.2" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.5.5.2.1" class="ltx_text" style="font-size:80%;color:#808080;">34.7<sup id="S3.T1.5.5.2.1.1" class="ltx_sup">‚àó</sup></span></td>
</tr>
<tr id="S3.T1.7.7" class="ltx_tr">
<td id="S3.T1.7.7.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.7.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.7.7.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.7.7.4.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S3.T1.7.7.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.7.7.5.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S3.T1.6.6.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S3.T1.6.6.1.1" class="ltx_text" style="font-size:80%;">28.4</span><sup id="S3.T1.6.6.1.2" class="ltx_sup"><span id="S3.T1.6.6.1.2.1" class="ltx_text" style="font-size:80%;">‚àó</span></sup>
</td>
<td id="S3.T1.7.7.2" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.7.7.2.1" class="ltx_text" style="font-size:80%;color:#808080;">31.9<sup id="S3.T1.7.7.2.1.1" class="ltx_sup">‚àó</sup></span></td>
</tr>
<tr id="S3.T1.9.9" class="ltx_tr">
<td id="S3.T1.9.9.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.9.9.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.9.9.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.9.9.4.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S3.T1.9.9.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.9.9.5.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S3.T1.8.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.8.8.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">33.6<sup id="S3.T1.8.8.1.1.1" class="ltx_sup"><span id="S3.T1.8.8.1.1.1.1" class="ltx_text ltx_font_medium">‚àó</span></sup></span></td>
<td id="S3.T1.9.9.2" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.9.9.2.1" class="ltx_text" style="font-size:80%;color:#808080;">36.2<sup id="S3.T1.9.9.2.1.1" class="ltx_sup">‚àó</sup></span></td>
</tr>
<tr id="S3.T1.11.11" class="ltx_tr">
<td id="S3.T1.11.11.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.11.11.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.11.11.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.11.11.4.1" class="ltx_text" style="font-size:80%;">ViT-H/16</span></td>
<td id="S3.T1.11.11.5" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.11.11.5.1" class="ltx_text" style="font-size:80%;">ViT-H/16</span></td>
<td id="S3.T1.10.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.10.10.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">35.1<sup id="S3.T1.10.10.1.1.1" class="ltx_sup"><span id="S3.T1.10.10.1.1.1.1" class="ltx_text ltx_font_medium">‚àó</span></sup></span></td>
<td id="S3.T1.11.11.2" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.11.11.2.1" class="ltx_text" style="font-size:80%;color:#808080;">37.4<sup id="S3.T1.11.11.2.1.1" class="ltx_sup">‚àó</sup></span></td>
</tr>
<tr id="S3.T1.12.26.14" class="ltx_tr">
<td id="S3.T1.12.26.14.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.26.14.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.12.26.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.26.14.2.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S3.T1.12.26.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.26.14.3.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S3.T1.12.26.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.26.14.4.1" class="ltx_text" style="font-size:80%;">28.0</span></td>
<td id="S3.T1.12.26.14.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.26.14.5.1" class="ltx_text" style="font-size:80%;color:#808080;">30.2</span></td>
</tr>
<tr id="S3.T1.12.27.15" class="ltx_tr">
<td id="S3.T1.12.27.15.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.27.15.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.12.27.15.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.27.15.2.1" class="ltx_text" style="font-size:80%;">ViT-L/14</span></td>
<td id="S3.T1.12.27.15.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.27.15.3.1" class="ltx_text" style="font-size:80%;">ViT-L/14</span></td>
<td id="S3.T1.12.27.15.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.27.15.4.1" class="ltx_text" style="font-size:80%;">31.4</span></td>
<td id="S3.T1.12.27.15.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.27.15.5.1" class="ltx_text" style="font-size:80%;color:#808080;">34.0</span></td>
</tr>
<tr id="S3.T1.12.28.16" class="ltx_tr">
<td id="S3.T1.12.28.16.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.28.16.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.12.28.16.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.28.16.2.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S3.T1.12.28.16.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.28.16.3.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S3.T1.12.28.16.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.28.16.4.1" class="ltx_text" style="font-size:80%;">32.1</span></td>
<td id="S3.T1.12.28.16.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.28.16.5.1" class="ltx_text" style="font-size:80%;color:#808080;">34.0</span></td>
</tr>
<tr id="S3.T1.12.12" class="ltx_tr">
<td id="S3.T1.12.12.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.12.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours) <math id="S3.T1.12.12.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S3.T1.12.12.1.1.m1.1a"><mo id="S3.T1.12.12.1.1.m1.1.1" xref="S3.T1.12.12.1.1.m1.1.1.cmml">‚Ä†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.12.12.1.1.m1.1b"><ci id="S3.T1.12.12.1.1.m1.1.1.cmml" xref="S3.T1.12.12.1.1.m1.1.1">‚Ä†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.12.12.1.1.m1.1c">\dagger</annotation></semantics></math></span></td>
<td id="S3.T1.12.12.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.12.2.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S3.T1.12.12.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.12.3.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S3.T1.12.12.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.12.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">32.4</span></td>
<td id="S3.T1.12.12.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.12.5.1" class="ltx_text" style="font-size:80%;color:#808080;">32.9</span></td>
</tr>
<tr id="S3.T1.12.29.17" class="ltx_tr">
<td id="S3.T1.12.29.17.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.29.17.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S3.T1.12.29.17.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.29.17.2.1" class="ltx_text" style="font-size:80%;">ViT-H/16</span></td>
<td id="S3.T1.12.29.17.3" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.29.17.3.1" class="ltx_text" style="font-size:80%;">ViT-H/16</span></td>
<td id="S3.T1.12.29.17.4" class="ltx_td ltx_align_left ltx_border_r" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.29.17.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">34.1</span></td>
<td id="S3.T1.12.29.17.5" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;"><span id="S3.T1.12.29.17.5.1" class="ltx_text" style="font-size:80%;color:#808080;">35.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.33.5.1" class="ltx_text" style="font-size:113%;">Table 1</span>: </span><span id="S3.T1.20.4" class="ltx_text ltx_font_bold" style="font-size:113%;">LVIS open-vocabulary object detection (mask AP).<span id="S3.T1.20.4.3" class="ltx_text ltx_font_medium"> RO-ViT outperforms the best existing approach by </span>+7.8 AP<sub id="S3.T1.20.4.4" class="ltx_sub"><span id="S3.T1.20.4.4.1" class="ltx_text ltx_font_medium ltx_font_italic">r</span></sub><span id="S3.T1.20.4.5" class="ltx_text ltx_font_medium"> on novel categories. When using ViT-Base, Large and Huge RO-ViT outperforms OWL-ViT based on ViT-Large by </span>+2.8<span id="S3.T1.20.4.6" class="ltx_text ltx_font_medium">, </span>+8.0<span id="S3.T1.20.4.7" class="ltx_text ltx_font_medium"> and </span>+9.5 AP<sub id="S3.T1.20.4.8" class="ltx_sub"><span id="S3.T1.20.4.8.1" class="ltx_text ltx_font_medium ltx_font_italic">r</span></sub><span id="S3.T1.20.4.2" class="ltx_text ltx_font_medium">, respectively. All methods use the same instance-level supervision from LVIS base categories for detection training. <math id="S3.T1.19.3.1.m1.1" class="ltx_Math" alttext="*" display="inline"><semantics id="S3.T1.19.3.1.m1.1b"><mo id="S3.T1.19.3.1.m1.1.1" xref="S3.T1.19.3.1.m1.1.1.cmml">‚àó</mo><annotation-xml encoding="MathML-Content" id="S3.T1.19.3.1.m1.1c"><times id="S3.T1.19.3.1.m1.1.1.cmml" xref="S3.T1.19.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.19.3.1.m1.1d">*</annotation></semantics></math>: reports box AP. <math id="S3.T1.20.4.2.m2.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S3.T1.20.4.2.m2.1b"><mo id="S3.T1.20.4.2.m2.1.1" xref="S3.T1.20.4.2.m2.1.1.cmml">‚Ä†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.20.4.2.m2.1c"><ci id="S3.T1.20.4.2.m2.1.1.cmml" xref="S3.T1.20.4.2.m2.1.1">‚Ä†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.20.4.2.m2.1d">\dagger</annotation></semantics></math>: trained on LAION-2B instead of ALIGN.</span></span></figcaption>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.4" class="ltx_p">Additionally, we replace the standard classifier and mask output layer with the normalized layers¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. This L2-normalizes the weights <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">ùë§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">w</annotation></semantics></math> and features <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mi id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><ci id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">ùë•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">x</annotation></semantics></math> as: <math id="S3.SS3.p2.3.m3.6" class="ltx_Math" alttext="f(x;w,b,\tau)={\tau\over\|w\|_{2}\|x\|_{2}}w^{T}x+b" display="inline"><semantics id="S3.SS3.p2.3.m3.6a"><mrow id="S3.SS3.p2.3.m3.6.7" xref="S3.SS3.p2.3.m3.6.7.cmml"><mrow id="S3.SS3.p2.3.m3.6.7.2" xref="S3.SS3.p2.3.m3.6.7.2.cmml"><mi id="S3.SS3.p2.3.m3.6.7.2.2" xref="S3.SS3.p2.3.m3.6.7.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.6.7.2.1" xref="S3.SS3.p2.3.m3.6.7.2.1.cmml">‚Äã</mo><mrow id="S3.SS3.p2.3.m3.6.7.2.3.2" xref="S3.SS3.p2.3.m3.6.7.2.3.1.cmml"><mo stretchy="false" id="S3.SS3.p2.3.m3.6.7.2.3.2.1" xref="S3.SS3.p2.3.m3.6.7.2.3.1.cmml">(</mo><mi id="S3.SS3.p2.3.m3.3.3" xref="S3.SS3.p2.3.m3.3.3.cmml">x</mi><mo id="S3.SS3.p2.3.m3.6.7.2.3.2.2" xref="S3.SS3.p2.3.m3.6.7.2.3.1.cmml">;</mo><mi id="S3.SS3.p2.3.m3.4.4" xref="S3.SS3.p2.3.m3.4.4.cmml">w</mi><mo id="S3.SS3.p2.3.m3.6.7.2.3.2.3" xref="S3.SS3.p2.3.m3.6.7.2.3.1.cmml">,</mo><mi id="S3.SS3.p2.3.m3.5.5" xref="S3.SS3.p2.3.m3.5.5.cmml">b</mi><mo id="S3.SS3.p2.3.m3.6.7.2.3.2.4" xref="S3.SS3.p2.3.m3.6.7.2.3.1.cmml">,</mo><mi id="S3.SS3.p2.3.m3.6.6" xref="S3.SS3.p2.3.m3.6.6.cmml">œÑ</mi><mo stretchy="false" id="S3.SS3.p2.3.m3.6.7.2.3.2.5" xref="S3.SS3.p2.3.m3.6.7.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.SS3.p2.3.m3.6.7.1" xref="S3.SS3.p2.3.m3.6.7.1.cmml">=</mo><mrow id="S3.SS3.p2.3.m3.6.7.3" xref="S3.SS3.p2.3.m3.6.7.3.cmml"><mrow id="S3.SS3.p2.3.m3.6.7.3.2" xref="S3.SS3.p2.3.m3.6.7.3.2.cmml"><mfrac id="S3.SS3.p2.3.m3.2.2" xref="S3.SS3.p2.3.m3.2.2.cmml"><mi id="S3.SS3.p2.3.m3.2.2.4" xref="S3.SS3.p2.3.m3.2.2.4.cmml">œÑ</mi><mrow id="S3.SS3.p2.3.m3.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.cmml"><msub id="S3.SS3.p2.3.m3.2.2.2.4" xref="S3.SS3.p2.3.m3.2.2.2.4.cmml"><mrow id="S3.SS3.p2.3.m3.2.2.2.4.2.2" xref="S3.SS3.p2.3.m3.2.2.2.4.2.1.cmml"><mo stretchy="false" id="S3.SS3.p2.3.m3.2.2.2.4.2.2.1" xref="S3.SS3.p2.3.m3.2.2.2.4.2.1.1.cmml">‚Äñ</mo><mi id="S3.SS3.p2.3.m3.1.1.1.1" xref="S3.SS3.p2.3.m3.1.1.1.1.cmml">w</mi><mo stretchy="false" id="S3.SS3.p2.3.m3.2.2.2.4.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.4.2.1.1.cmml">‚Äñ</mo></mrow><mn id="S3.SS3.p2.3.m3.2.2.2.4.3" xref="S3.SS3.p2.3.m3.2.2.2.4.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.2.2.2.3" xref="S3.SS3.p2.3.m3.2.2.2.3.cmml">‚Äã</mo><msub id="S3.SS3.p2.3.m3.2.2.2.5" xref="S3.SS3.p2.3.m3.2.2.2.5.cmml"><mrow id="S3.SS3.p2.3.m3.2.2.2.5.2.2" xref="S3.SS3.p2.3.m3.2.2.2.5.2.1.cmml"><mo stretchy="false" id="S3.SS3.p2.3.m3.2.2.2.5.2.2.1" xref="S3.SS3.p2.3.m3.2.2.2.5.2.1.1.cmml">‚Äñ</mo><mi id="S3.SS3.p2.3.m3.2.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.2.cmml">x</mi><mo stretchy="false" id="S3.SS3.p2.3.m3.2.2.2.5.2.2.2" xref="S3.SS3.p2.3.m3.2.2.2.5.2.1.1.cmml">‚Äñ</mo></mrow><mn id="S3.SS3.p2.3.m3.2.2.2.5.3" xref="S3.SS3.p2.3.m3.2.2.2.5.3.cmml">2</mn></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.6.7.3.2.1" xref="S3.SS3.p2.3.m3.6.7.3.2.1.cmml">‚Äã</mo><msup id="S3.SS3.p2.3.m3.6.7.3.2.2" xref="S3.SS3.p2.3.m3.6.7.3.2.2.cmml"><mi id="S3.SS3.p2.3.m3.6.7.3.2.2.2" xref="S3.SS3.p2.3.m3.6.7.3.2.2.2.cmml">w</mi><mi id="S3.SS3.p2.3.m3.6.7.3.2.2.3" xref="S3.SS3.p2.3.m3.6.7.3.2.2.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS3.p2.3.m3.6.7.3.2.1a" xref="S3.SS3.p2.3.m3.6.7.3.2.1.cmml">‚Äã</mo><mi id="S3.SS3.p2.3.m3.6.7.3.2.3" xref="S3.SS3.p2.3.m3.6.7.3.2.3.cmml">x</mi></mrow><mo id="S3.SS3.p2.3.m3.6.7.3.1" xref="S3.SS3.p2.3.m3.6.7.3.1.cmml">+</mo><mi id="S3.SS3.p2.3.m3.6.7.3.3" xref="S3.SS3.p2.3.m3.6.7.3.3.cmml">b</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.6b"><apply id="S3.SS3.p2.3.m3.6.7.cmml" xref="S3.SS3.p2.3.m3.6.7"><eq id="S3.SS3.p2.3.m3.6.7.1.cmml" xref="S3.SS3.p2.3.m3.6.7.1"></eq><apply id="S3.SS3.p2.3.m3.6.7.2.cmml" xref="S3.SS3.p2.3.m3.6.7.2"><times id="S3.SS3.p2.3.m3.6.7.2.1.cmml" xref="S3.SS3.p2.3.m3.6.7.2.1"></times><ci id="S3.SS3.p2.3.m3.6.7.2.2.cmml" xref="S3.SS3.p2.3.m3.6.7.2.2">ùëì</ci><list id="S3.SS3.p2.3.m3.6.7.2.3.1.cmml" xref="S3.SS3.p2.3.m3.6.7.2.3.2"><ci id="S3.SS3.p2.3.m3.3.3.cmml" xref="S3.SS3.p2.3.m3.3.3">ùë•</ci><ci id="S3.SS3.p2.3.m3.4.4.cmml" xref="S3.SS3.p2.3.m3.4.4">ùë§</ci><ci id="S3.SS3.p2.3.m3.5.5.cmml" xref="S3.SS3.p2.3.m3.5.5">ùëè</ci><ci id="S3.SS3.p2.3.m3.6.6.cmml" xref="S3.SS3.p2.3.m3.6.6">ùúè</ci></list></apply><apply id="S3.SS3.p2.3.m3.6.7.3.cmml" xref="S3.SS3.p2.3.m3.6.7.3"><plus id="S3.SS3.p2.3.m3.6.7.3.1.cmml" xref="S3.SS3.p2.3.m3.6.7.3.1"></plus><apply id="S3.SS3.p2.3.m3.6.7.3.2.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2"><times id="S3.SS3.p2.3.m3.6.7.3.2.1.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2.1"></times><apply id="S3.SS3.p2.3.m3.2.2.cmml" xref="S3.SS3.p2.3.m3.2.2"><divide id="S3.SS3.p2.3.m3.2.2.3.cmml" xref="S3.SS3.p2.3.m3.2.2"></divide><ci id="S3.SS3.p2.3.m3.2.2.4.cmml" xref="S3.SS3.p2.3.m3.2.2.4">ùúè</ci><apply id="S3.SS3.p2.3.m3.2.2.2.cmml" xref="S3.SS3.p2.3.m3.2.2.2"><times id="S3.SS3.p2.3.m3.2.2.2.3.cmml" xref="S3.SS3.p2.3.m3.2.2.2.3"></times><apply id="S3.SS3.p2.3.m3.2.2.2.4.cmml" xref="S3.SS3.p2.3.m3.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.2.2.2.4.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.4">subscript</csymbol><apply id="S3.SS3.p2.3.m3.2.2.2.4.2.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.4.2.2"><csymbol cd="latexml" id="S3.SS3.p2.3.m3.2.2.2.4.2.1.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.4.2.2.1">norm</csymbol><ci id="S3.SS3.p2.3.m3.1.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1.1.1">ùë§</ci></apply><cn type="integer" id="S3.SS3.p2.3.m3.2.2.2.4.3.cmml" xref="S3.SS3.p2.3.m3.2.2.2.4.3">2</cn></apply><apply id="S3.SS3.p2.3.m3.2.2.2.5.cmml" xref="S3.SS3.p2.3.m3.2.2.2.5"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.2.2.2.5.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.5">subscript</csymbol><apply id="S3.SS3.p2.3.m3.2.2.2.5.2.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.5.2.2"><csymbol cd="latexml" id="S3.SS3.p2.3.m3.2.2.2.5.2.1.1.cmml" xref="S3.SS3.p2.3.m3.2.2.2.5.2.2.1">norm</csymbol><ci id="S3.SS3.p2.3.m3.2.2.2.2.cmml" xref="S3.SS3.p2.3.m3.2.2.2.2">ùë•</ci></apply><cn type="integer" id="S3.SS3.p2.3.m3.2.2.2.5.3.cmml" xref="S3.SS3.p2.3.m3.2.2.2.5.3">2</cn></apply></apply></apply><apply id="S3.SS3.p2.3.m3.6.7.3.2.2.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.6.7.3.2.2.1.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2.2">superscript</csymbol><ci id="S3.SS3.p2.3.m3.6.7.3.2.2.2.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2.2.2">ùë§</ci><ci id="S3.SS3.p2.3.m3.6.7.3.2.2.3.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2.2.3">ùëá</ci></apply><ci id="S3.SS3.p2.3.m3.6.7.3.2.3.cmml" xref="S3.SS3.p2.3.m3.6.7.3.2.3">ùë•</ci></apply><ci id="S3.SS3.p2.3.m3.6.7.3.3.cmml" xref="S3.SS3.p2.3.m3.6.7.3.3">ùëè</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.6c">f(x;w,b,\tau)={\tau\over\|w\|_{2}\|x\|_{2}}w^{T}x+b</annotation></semantics></math>, where <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">œÑ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">ùúè</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\tau</annotation></semantics></math> = 20. Although we do <span id="S3.SS3.p2.4.1" class="ltx_text ltx_font_italic">not</span> have rare categories at training (<em id="S3.SS3.p2.4.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p2.4.3" class="ltx_text"></span>, open-vocabulary setting), we empirically found it beneficial (see Sec.¬†<a href="#S4" title="4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.2.3.1" class="ltx_tr">
<td id="S4.T2.2.3.1.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;" rowspan="2"><span id="S4.T2.2.3.1.1.1" class="ltx_text" style="font-size:80%;">method</span></td>
<td id="S4.T2.2.3.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.3.1.2.1" class="ltx_text" style="font-size:80%;">pretrained</span></td>
<td id="S4.T2.2.3.1.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.3.1.3.1" class="ltx_text" style="font-size:80%;">detector</span></td>
<td id="S4.T2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;" rowspan="2"><span id="S4.T2.2.3.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">novel AP</span></td>
<td id="S4.T2.2.3.1.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;" rowspan="2"><span id="S4.T2.2.3.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></td>
</tr>
<tr id="S4.T2.2.4.2" class="ltx_tr">
<td id="S4.T2.2.4.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.4.2.1.1" class="ltx_text" style="font-size:80%;">model</span></td>
<td id="S4.T2.2.4.2.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.4.2.2.1" class="ltx_text" style="font-size:80%;">backbone</span></td>
</tr>
<tr id="S4.T2.2.5.3" class="ltx_tr">
<td id="S4.T2.2.5.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.5.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ConvNet based:</span></td>
<td id="S4.T2.2.5.3.2" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.5.3.3" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.5.3.4" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.5.3.5" class="ltx_td ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
</tr>
<tr id="S4.T2.2.6.4" class="ltx_tr">
<td id="S4.T2.2.6.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.6.4.1.1" class="ltx_text" style="font-size:80%;">ViLD¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.6.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S4.T2.2.6.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T2.2.6.4.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.6.4.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S4.T2.2.6.4.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.6.4.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.6.4.4.1" class="ltx_text" style="font-size:80%;">27.6</span></td>
<td id="S4.T2.2.6.4.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.6.4.5.1" class="ltx_text" style="font-size:80%;color:#808080;">51.3</span></td>
</tr>
<tr id="S4.T2.2.7.5" class="ltx_tr">
<td id="S4.T2.2.7.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.7.5.1.1" class="ltx_text" style="font-size:80%;">OV-DETR¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.7.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib55" title="" class="ltx_ref">55</a><span id="S4.T2.2.7.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T2.2.7.5.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.7.5.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S4.T2.2.7.5.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.7.5.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.7.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.7.5.4.1" class="ltx_text" style="font-size:80%;">29.4</span></td>
<td id="S4.T2.2.7.5.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.7.5.5.1" class="ltx_text" style="font-size:80%;color:#808080;">52.7</span></td>
</tr>
<tr id="S4.T2.2.8.6" class="ltx_tr">
<td id="S4.T2.2.8.6.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.8.6.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">w/ pseudo box labels:</span></td>
<td id="S4.T2.2.8.6.2" class="ltx_td ltx_border_r" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.8.6.3" class="ltx_td ltx_border_r" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.8.6.4" class="ltx_td ltx_border_r" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.8.6.5" class="ltx_td" style="padding:0.5pt 5.0pt;"></td>
</tr>
<tr id="S4.T2.2.9.7" class="ltx_tr">
<td id="S4.T2.2.9.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.9.7.1.1" class="ltx_text" style="font-size:80%;">XPM¬†</span><em id="S4.T2.2.9.7.1.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">et al</em><span id="S4.T2.2.9.7.1.3" class="ltx_text" style="font-size:80%;">.</span><span id="S4.T2.2.9.7.1.4" class="ltx_text"></span><span id="S4.T2.2.9.7.1.5" class="ltx_text" style="font-size:80%;">¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.9.7.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S4.T2.2.9.7.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T2.2.9.7.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.9.7.2.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.9.7.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.9.7.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.9.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.9.7.4.1" class="ltx_text" style="font-size:80%;">27.0</span></td>
<td id="S4.T2.2.9.7.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.9.7.5.1" class="ltx_text" style="font-size:80%;color:#808080;">41.2</span></td>
</tr>
<tr id="S4.T2.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.1.1.1.1" class="ltx_text" style="font-size:80%;">RegionCLIP¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.1.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib62" title="" class="ltx_ref">62</a><span id="S4.T2.1.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S4.T2.1.1.1.4" class="ltx_text" style="font-size:80%;"> </span><math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mo mathsize="80%" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">‚Ä†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">‚Ä†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\dagger</annotation></semantics></math>
</td>
<td id="S4.T2.1.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.1.1.2.1" class="ltx_text" style="font-size:80%;">R-50x4</span></td>
<td id="S4.T2.1.1.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.1.1.3.1" class="ltx_text" style="font-size:80%;">R-50x4</span></td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.1.1.4.1" class="ltx_text" style="font-size:80%;">39.3</span></td>
<td id="S4.T2.1.1.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.1.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">55.7</span></td>
</tr>
<tr id="S4.T2.2.10.8" class="ltx_tr">
<td id="S4.T2.2.10.8.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.10.8.1.1" class="ltx_text" style="font-size:80%;">PromptDet¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.10.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S4.T2.2.10.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T2.2.10.8.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.10.8.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S4.T2.2.10.8.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.10.8.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.10.8.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.10.8.4.1" class="ltx_text" style="font-size:80%;">26.6</span></td>
<td id="S4.T2.2.10.8.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.10.8.5.1" class="ltx_text" style="font-size:80%;color:#808080;">50.6</span></td>
</tr>
<tr id="S4.T2.2.11.9" class="ltx_tr">
<td id="S4.T2.2.11.9.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.11.9.1.1" class="ltx_text" style="font-size:80%;">VL-PLM¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.11.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib59" title="" class="ltx_ref">59</a><span id="S4.T2.2.11.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T2.2.11.9.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.11.9.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S4.T2.2.11.9.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.11.9.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.11.9.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.11.9.4.1" class="ltx_text" style="font-size:80%;">34.4</span></td>
<td id="S4.T2.2.11.9.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.11.9.5.1" class="ltx_text" style="font-size:80%;color:#808080;">53.5</span></td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<td id="S4.T2.2.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.2.1.1" class="ltx_text" style="font-size:80%;">Rasheed¬†</span><em id="S4.T2.2.2.1.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">et al</em><span id="S4.T2.2.2.1.3" class="ltx_text" style="font-size:80%;">.</span><span id="S4.T2.2.2.1.4" class="ltx_text"></span><span id="S4.T2.2.2.1.5" class="ltx_text" style="font-size:80%;">¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.2.1.6.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib42" title="" class="ltx_ref">42</a><span id="S4.T2.2.2.1.7.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S4.T2.2.2.1.8" class="ltx_text" style="font-size:80%;"> </span><math id="S4.T2.2.2.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.2.2.1.m1.1a"><mo mathsize="80%" id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml">‚Ä°</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><ci id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">‚Ä°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">\ddagger</annotation></semantics></math>
</td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.2.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.2.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.2.4.1" class="ltx_text" style="font-size:80%;">36.9</span></td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.2.5.1" class="ltx_text" style="font-size:80%;color:#808080;">51.5</span></td>
</tr>
<tr id="S4.T2.2.12.10" class="ltx_tr">
<td id="S4.T2.2.12.10.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.12.10.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">w/ weak supervision:</span></td>
<td id="S4.T2.2.12.10.2" class="ltx_td ltx_border_r" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.12.10.3" class="ltx_td ltx_border_r" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.12.10.4" class="ltx_td ltx_border_r" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.12.10.5" class="ltx_td" style="padding:0.5pt 5.0pt;"></td>
</tr>
<tr id="S4.T2.2.13.11" class="ltx_tr">
<td id="S4.T2.2.13.11.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;">
<span id="S4.T2.2.13.11.1.1" class="ltx_text" style="font-size:80%;">Detic-CN2¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.13.11.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S4.T2.2.13.11.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S4.T2.2.13.11.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.13.11.2.1" class="ltx_text" style="font-size:80%;">ViT-B/32</span></td>
<td id="S4.T2.2.13.11.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.13.11.3.1" class="ltx_text" style="font-size:80%;">R-50</span></td>
<td id="S4.T2.2.13.11.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.13.11.4.1" class="ltx_text" style="font-size:80%;">24.6</span></td>
<td id="S4.T2.2.13.11.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.13.11.5.1" class="ltx_text" style="font-size:80%;color:#808080;">32.4</span></td>
</tr>
<tr id="S4.T2.2.14.12" class="ltx_tr">
<td id="S4.T2.2.14.12.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.14.12.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ViT based:*</span></td>
<td id="S4.T2.2.14.12.2" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.14.12.3" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.14.12.4" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
<td id="S4.T2.2.14.12.5" class="ltx_td ltx_border_t" style="padding:0.5pt 5.0pt;"></td>
</tr>
<tr id="S4.T2.2.15.13" class="ltx_tr">
<td id="S4.T2.2.15.13.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.15.13.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S4.T2.2.15.13.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.15.13.2.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.T2.2.15.13.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.15.13.3.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.T2.2.15.13.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.15.13.4.1" class="ltx_text" style="font-size:80%;">30.2</span></td>
<td id="S4.T2.2.15.13.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.15.13.5.1" class="ltx_text" style="font-size:80%;color:#808080;">41.5</span></td>
</tr>
<tr id="S4.T2.2.16.14" class="ltx_tr">
<td id="S4.T2.2.16.14.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.16.14.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></td>
<td id="S4.T2.2.16.14.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.16.14.2.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.T2.2.16.14.3" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.16.14.3.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.T2.2.16.14.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.16.14.4.1" class="ltx_text" style="font-size:80%;">33.0</span></td>
<td id="S4.T2.2.16.14.5" class="ltx_td ltx_align_center" style="padding:0.5pt 5.0pt;"><span id="S4.T2.2.16.14.5.1" class="ltx_text" style="font-size:80%;color:#808080;">47.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.23.3.1" class="ltx_text" style="font-size:113%;">Table 2</span>: </span><span id="S4.T2.6.2" class="ltx_text ltx_font_bold" style="font-size:113%;">COCO open-vocabulary object detection (box AP50).<span id="S4.T2.6.2.2" class="ltx_text ltx_font_medium"> RO-ViT represents the first ViT-based approach and demonstrates a very competitive novel AP without using pseudo labeling or weak supervision. <math id="S4.T2.5.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T2.5.1.1.m1.1b"><mo id="S4.T2.5.1.1.m1.1.1" xref="S4.T2.5.1.1.m1.1.1.cmml">‚Ä†</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.1.1.m1.1c"><ci id="S4.T2.5.1.1.m1.1.1.cmml" xref="S4.T2.5.1.1.m1.1.1">‚Ä†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.1.1.m1.1d">\dagger</annotation></semantics></math>: RegionCLIP uses an off-the-shelf RPN during its pretraining. <math id="S4.T2.6.2.2.m2.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.6.2.2.m2.1b"><mo id="S4.T2.6.2.2.m2.1.1" xref="S4.T2.6.2.2.m2.1.1.cmml">‚Ä°</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.2.2.m2.1c"><ci id="S4.T2.6.2.2.m2.1.1.cmml" xref="S4.T2.6.2.2.m2.1.1">‚Ä°</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.2.2.m2.1d">\ddagger</annotation></semantics></math>: Rasheed¬†<em id="S4.T2.6.2.2.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.T2.6.2.2.2" class="ltx_text"></span> uses an external MViT detector¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> during pretraining. *: The other ViT-based method¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> report their results on LVIS only.
</span></span></figcaption>
</figure>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pretraining details.</h4>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.5" class="ltx_p">Our pretraining is performed from scratch. We adopt the ViT-B/16 and ViT-L/16 as the image encoder. The input image size is 224<math id="S4.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><mo id="S4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><times id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">\times</annotation></semantics></math>224 which results in 14<math id="S4.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.2.m2.1a"><mo id="S4.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.2.m2.1b"><times id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.2.m2.1c">\times</annotation></semantics></math>14 positional embeddings with patch size 16<math id="S4.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.3.m3.1a"><mo id="S4.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.3.m3.1b"><times id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.3.m3.1c">\times</annotation></semantics></math>16. To generate the Cropped Positional Embedding (CPE), we first interpolate the positional embeddings to size 64<math id="S4.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.4.m4.1a"><mo id="S4.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.4.m4.1b"><times id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.4.m4.1c">\times</annotation></semantics></math>64. We randomly crop a region with the scale ratio in [0.1, 1.0], and the aspect ratio in [0.5, 2.0]. The region crop is resized back to the size 14<math id="S4.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.5.m5.1a"><mo id="S4.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.5.m5.1b"><times id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.5.m5.1c">\times</annotation></semantics></math>14 (<em id="S4.SS0.SSS0.Px1.p1.5.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS0.SSS0.Px1.p1.5.2" class="ltx_text"></span>, CPE), and is added to the patch embeddings. We use the global average pooling at the last ViT layer to obtain the image embedding. The text encoder is a 12-layer Transformer following¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, with maximum text length 64. Both image and text embeddings are L2 normalized. While most experiments train on ALIGN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> dataset, we report that training on the publicly available LAION-2B¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> dataset results in comparable performance (Table¬†<a href="#S3.T1" title="Table 1 ‚Ä£ 3.3 Open-vocabulary Detector Finetuning ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). We use a batch size 4096 for ablation and 16384 to compare with other methods.
We use the AdamW optimizer with learning rate 5e-4 and a linear warmup of 10k steps, and train for 500k iterations.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Downstream detection details.</h4>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.3" class="ltx_p">We train RO-ViT with base categories <math id="S4.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">C</mi><mi id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.2">ùê∂</ci><ci id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">C_{B}</annotation></semantics></math> for 46.1k/11.3k iterations with image size 1024, large scale jittering¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, batch size 256/128, the SGD optimizer with weight decay 1e-4/1e-2, momentum 0.9 and an initial learning rate of 0.36/0.02 for LVIS/COCO datasets. The pretrained positional embeddings are bilinearly interpolated to adjust to the size of patch embeddings of higher resolution¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. We set the backbone learning rate lower (<em id="S4.SS0.SSS0.Px2.p1.3.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS0.SSS0.Px2.p1.3.2" class="ltx_text"></span>, 0.1<math id="S4.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><mo id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><times id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">\times</annotation></semantics></math>) than the rest of the model to retain the pretraining knowledge during detection finetuning. We use the score combination of (<math id="S4.SS0.SSS0.Px2.p1.3.m3.3" class="ltx_Math" alttext="\alpha,\beta,\delta" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.3.m3.3a"><mrow id="S4.SS0.SSS0.Px2.p1.3.m3.3.4.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.4.1.cmml"><mi id="S4.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">Œ±</mi><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.4.2.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.4.1.cmml">,</mo><mi id="S4.SS0.SSS0.Px2.p1.3.m3.2.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2.cmml">Œ≤</mi><mo id="S4.SS0.SSS0.Px2.p1.3.m3.3.4.2.2" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.4.1.cmml">,</mo><mi id="S4.SS0.SSS0.Px2.p1.3.m3.3.3" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3.cmml">Œ¥</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.3.m3.3b"><list id="S4.SS0.SSS0.Px2.p1.3.m3.3.4.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.4.2"><ci id="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1">ùõº</ci><ci id="S4.SS0.SSS0.Px2.p1.3.m3.2.2.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.2.2">ùõΩ</ci><ci id="S4.SS0.SSS0.Px2.p1.3.m3.3.3.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.3.3">ùõø</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.3.m3.3c">\alpha,\beta,\delta</annotation></semantics></math>) = (0.65, 0.3, 3) in Sec.¬†<a href="#S3.SS3" title="3.3 Open-vocabulary Detector Finetuning ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>. We use CLIP¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> prompt templates and take the average text embeddings of each category.
We use OLN-RPN¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> at the RPN stage which uses centerness as objectness, a single anchor per location and IoU loss. The RPN NMS threshold is set to 0.7 at training and 1.0 at testing.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.4.1.1" class="ltx_tr">
<th id="S4.T3.4.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"></th>
<th id="S4.T3.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.1.1.2.1" class="ltx_text" style="font-size:80%;">image</span></th>
<td id="S4.T3.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;" colspan="6"><span id="S4.T3.4.1.1.3.1" class="ltx_text" style="font-size:80%;">MS COCO (5K test set)</span></td>
<td id="S4.T3.4.1.1.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;" colspan="6"><span id="S4.T3.4.1.1.4.1" class="ltx_text" style="font-size:80%;">Flickr30K (1K test set)</span></td>
</tr>
<tr id="S4.T3.4.2.2" class="ltx_tr">
<th id="S4.T3.4.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"></th>
<th id="S4.T3.4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.2.2.2.1" class="ltx_text" style="font-size:80%;">backbone</span></th>
<td id="S4.T3.4.2.2.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;" colspan="3"><span id="S4.T3.4.2.2.3.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;"><span id="S4.T3.4.2.2.3.1.1" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span>image-to-text<span id="S4.T3.4.2.2.3.1.2" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span></span></td>
<td id="S4.T3.4.2.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;" colspan="3"><span id="S4.T3.4.2.2.4.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;"><span id="S4.T3.4.2.2.4.1.1" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span>text-to-image<span id="S4.T3.4.2.2.4.1.2" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span></span></td>
<td id="S4.T3.4.2.2.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;" colspan="3"><span id="S4.T3.4.2.2.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;"><span id="S4.T3.4.2.2.5.1.1" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span>image-to-text<span id="S4.T3.4.2.2.5.1.2" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span></span></td>
<td id="S4.T3.4.2.2.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;" colspan="3"><span id="S4.T3.4.2.2.6.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;"><span id="S4.T3.4.2.2.6.1.1" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span>text-to-image<span id="S4.T3.4.2.2.6.1.2" class="ltx_text" style="color:#FFFFFF;">‚Äî‚Äî-</span></span></td>
</tr>
<tr id="S4.T3.4.3.3" class="ltx_tr">
<th id="S4.T3.4.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.1.1" class="ltx_text" style="font-size:80%;">method</span></th>
<th id="S4.T3.4.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.2.1" class="ltx_text" style="font-size:80%;">size</span></th>
<td id="S4.T3.4.3.3.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.3.1" class="ltx_text" style="font-size:80%;">R@1</span></td>
<td id="S4.T3.4.3.3.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.4.1" class="ltx_text" style="font-size:80%;">R@5</span></td>
<td id="S4.T3.4.3.3.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.5.1" class="ltx_text" style="font-size:80%;">R@10</span></td>
<td id="S4.T3.4.3.3.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.6.1" class="ltx_text" style="font-size:80%;">R@1</span></td>
<td id="S4.T3.4.3.3.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.7.1" class="ltx_text" style="font-size:80%;">R@5</span></td>
<td id="S4.T3.4.3.3.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.8.1" class="ltx_text" style="font-size:80%;">R@10</span></td>
<td id="S4.T3.4.3.3.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.9.1" class="ltx_text" style="font-size:80%;">R@1</span></td>
<td id="S4.T3.4.3.3.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.10.1" class="ltx_text" style="font-size:80%;">R@5</span></td>
<td id="S4.T3.4.3.3.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.11.1" class="ltx_text" style="font-size:80%;">R10</span></td>
<td id="S4.T3.4.3.3.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.12.1" class="ltx_text" style="font-size:80%;">R@1</span></td>
<td id="S4.T3.4.3.3.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.13.1" class="ltx_text" style="font-size:80%;">R@5</span></td>
<td id="S4.T3.4.3.3.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.3.3.14.1" class="ltx_text" style="font-size:80%;">R@10</span></td>
</tr>
<tr id="S4.T3.4.4.4" class="ltx_tr">
<th id="S4.T3.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.4.4.1.1" class="ltx_text" style="font-size:80%;">CLIP¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.4.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="S4.T3.4.4.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.2.1" class="ltx_text" style="font-size:80%;">302M</span></th>
<td id="S4.T3.4.4.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.3.1" class="ltx_text" style="font-size:80%;">58.4</span></td>
<td id="S4.T3.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.4.1" class="ltx_text" style="font-size:80%;">81.5</span></td>
<td id="S4.T3.4.4.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.5.1" class="ltx_text" style="font-size:80%;">88.1</span></td>
<td id="S4.T3.4.4.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.6.1" class="ltx_text" style="font-size:80%;">37.8</span></td>
<td id="S4.T3.4.4.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.7.1" class="ltx_text" style="font-size:80%;">62.4</span></td>
<td id="S4.T3.4.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.8.1" class="ltx_text" style="font-size:80%;">72.2</span></td>
<td id="S4.T3.4.4.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.9.1" class="ltx_text" style="font-size:80%;">88.0</span></td>
<td id="S4.T3.4.4.4.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.10.1" class="ltx_text" style="font-size:80%;">98.7</span></td>
<td id="S4.T3.4.4.4.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.11.1" class="ltx_text" style="font-size:80%;">99.4</span></td>
<td id="S4.T3.4.4.4.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.12.1" class="ltx_text" style="font-size:80%;">68.7</span></td>
<td id="S4.T3.4.4.4.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.13.1" class="ltx_text" style="font-size:80%;">90.6</span></td>
<td id="S4.T3.4.4.4.14" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.4.4.14.1" class="ltx_text" style="font-size:80%;">95.2</span></td>
</tr>
<tr id="S4.T3.4.5.5" class="ltx_tr">
<th id="S4.T3.4.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.5.5.1.1" class="ltx_text" style="font-size:80%;">ALIGN¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.5.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S4.T3.4.5.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.2.1" class="ltx_text" style="font-size:80%;">408M</span></th>
<td id="S4.T3.4.5.5.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.3.1" class="ltx_text" style="font-size:80%;">58.6</span></td>
<td id="S4.T3.4.5.5.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.4.1" class="ltx_text" style="font-size:80%;">83.0</span></td>
<td id="S4.T3.4.5.5.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.5.1" class="ltx_text" style="font-size:80%;">89.7</span></td>
<td id="S4.T3.4.5.5.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.6.1" class="ltx_text" style="font-size:80%;">45.6</span></td>
<td id="S4.T3.4.5.5.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.7.1" class="ltx_text" style="font-size:80%;">69.8</span></td>
<td id="S4.T3.4.5.5.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.8.1" class="ltx_text" style="font-size:80%;">78.6</span></td>
<td id="S4.T3.4.5.5.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.9.1" class="ltx_text" style="font-size:80%;">88.6</span></td>
<td id="S4.T3.4.5.5.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.10.1" class="ltx_text" style="font-size:80%;">98.7</span></td>
<td id="S4.T3.4.5.5.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.11.1" class="ltx_text" style="font-size:80%;">99.7</span></td>
<td id="S4.T3.4.5.5.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.12.1" class="ltx_text" style="font-size:80%;">75.7</span></td>
<td id="S4.T3.4.5.5.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.13.1" class="ltx_text" style="font-size:80%;">93.8</span></td>
<td id="S4.T3.4.5.5.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.5.5.14.1" class="ltx_text" style="font-size:80%;">96.8</span></td>
</tr>
<tr id="S4.T3.4.6.6" class="ltx_tr">
<th id="S4.T3.4.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.6.6.1.1" class="ltx_text" style="font-size:80%;">FLAVA¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.6.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib46" title="" class="ltx_ref">46</a><span id="S4.T3.4.6.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.2.1" class="ltx_text" style="font-size:80%;">86M</span></th>
<td id="S4.T3.4.6.6.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.3.1" class="ltx_text" style="font-size:80%;">42.7</span></td>
<td id="S4.T3.4.6.6.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.4.1" class="ltx_text" style="font-size:80%;">76.8</span></td>
<td id="S4.T3.4.6.6.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.4.6.6.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.6.1" class="ltx_text" style="font-size:80%;">38.4</span></td>
<td id="S4.T3.4.6.6.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.7.1" class="ltx_text" style="font-size:80%;">67.5</span></td>
<td id="S4.T3.4.6.6.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.4.6.6.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.9.1" class="ltx_text" style="font-size:80%;">67.7</span></td>
<td id="S4.T3.4.6.6.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.10.1" class="ltx_text" style="font-size:80%;">94.0</span></td>
<td id="S4.T3.4.6.6.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.4.6.6.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.12.1" class="ltx_text" style="font-size:80%;">65.2</span></td>
<td id="S4.T3.4.6.6.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.13.1" class="ltx_text" style="font-size:80%;">89.4</span></td>
<td id="S4.T3.4.6.6.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.6.6.14.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S4.T3.4.7.7" class="ltx_tr">
<th id="S4.T3.4.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.7.7.1.1" class="ltx_text" style="font-size:80%;">FILIP¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.7.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib52" title="" class="ltx_ref">52</a><span id="S4.T3.4.7.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.2.1" class="ltx_text" style="font-size:80%;">302M</span></th>
<td id="S4.T3.4.7.7.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.3.1" class="ltx_text" style="font-size:80%;">61.3</span></td>
<td id="S4.T3.4.7.7.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.4.1" class="ltx_text" style="font-size:80%;">84.3</span></td>
<td id="S4.T3.4.7.7.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.5.1" class="ltx_text" style="font-size:80%;">90.4</span></td>
<td id="S4.T3.4.7.7.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.6.1" class="ltx_text" style="font-size:80%;">45.9</span></td>
<td id="S4.T3.4.7.7.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.7.1" class="ltx_text" style="font-size:80%;">70.6</span></td>
<td id="S4.T3.4.7.7.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.8.1" class="ltx_text" style="font-size:80%;">79.3</span></td>
<td id="S4.T3.4.7.7.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.9.1" class="ltx_text" style="font-size:80%;">89.8</span></td>
<td id="S4.T3.4.7.7.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.10.1" class="ltx_text" style="font-size:80%;">99.2</span></td>
<td id="S4.T3.4.7.7.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.11.1" class="ltx_text" style="font-size:80%;">99.8</span></td>
<td id="S4.T3.4.7.7.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.12.1" class="ltx_text" style="font-size:80%;">75.0</span></td>
<td id="S4.T3.4.7.7.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.13.1" class="ltx_text" style="font-size:80%;">93.4</span></td>
<td id="S4.T3.4.7.7.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.7.7.14.1" class="ltx_text" style="font-size:80%;">96.3</span></td>
</tr>
<tr id="S4.T3.4.8.8" class="ltx_tr">
<th id="S4.T3.4.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.8.8.1.1" class="ltx_text" style="font-size:80%;">Florence¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.8.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S4.T3.4.8.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.2.1" class="ltx_text" style="font-size:80%;">637M</span></th>
<td id="S4.T3.4.8.8.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.3.1" class="ltx_text" style="font-size:80%;">64.7</span></td>
<td id="S4.T3.4.8.8.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.4.1" class="ltx_text" style="font-size:80%;">85.9</span></td>
<td id="S4.T3.4.8.8.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.4.8.8.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.6.1" class="ltx_text" style="font-size:80%;">47.2</span></td>
<td id="S4.T3.4.8.8.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.7.1" class="ltx_text" style="font-size:80%;">71.4</span></td>
<td id="S4.T3.4.8.8.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.4.8.8.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.9.1" class="ltx_text" style="font-size:80%;">90.9</span></td>
<td id="S4.T3.4.8.8.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.10.1" class="ltx_text" style="font-size:80%;">99.1</span></td>
<td id="S4.T3.4.8.8.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S4.T3.4.8.8.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.12.1" class="ltx_text" style="font-size:80%;">76.7</span></td>
<td id="S4.T3.4.8.8.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.13.1" class="ltx_text" style="font-size:80%;">93.6</span></td>
<td id="S4.T3.4.8.8.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.8.8.14.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S4.T3.4.9.9" class="ltx_tr">
<th id="S4.T3.4.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.9.9.1.1" class="ltx_text" style="font-size:80%;">CoCa-Large¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.9.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib53" title="" class="ltx_ref">53</a><span id="S4.T3.4.9.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.2.1" class="ltx_text" style="font-size:80%;">303M</span></th>
<td id="S4.T3.4.9.9.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.3.1" class="ltx_text" style="font-size:80%;">65.4</span></td>
<td id="S4.T3.4.9.9.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.4.1" class="ltx_text" style="font-size:80%;">85.6</span></td>
<td id="S4.T3.4.9.9.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.5.1" class="ltx_text" style="font-size:80%;">91.4</span></td>
<td id="S4.T3.4.9.9.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.6.1" class="ltx_text" style="font-size:80%;">50.1</span></td>
<td id="S4.T3.4.9.9.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.7.1" class="ltx_text" style="font-size:80%;">73.8</span></td>
<td id="S4.T3.4.9.9.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.8.1" class="ltx_text" style="font-size:80%;">81.8</span></td>
<td id="S4.T3.4.9.9.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.9.1" class="ltx_text" style="font-size:80%;">91.4</span></td>
<td id="S4.T3.4.9.9.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.10.1" class="ltx_text" style="font-size:80%;">99.2</span></td>
<td id="S4.T3.4.9.9.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">99.9</span></td>
<td id="S4.T3.4.9.9.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.12.1" class="ltx_text" style="font-size:80%;">79.0</span></td>
<td id="S4.T3.4.9.9.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.13.1" class="ltx_text" style="font-size:80%;">95.1</span></td>
<td id="S4.T3.4.9.9.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.9.9.14.1" class="ltx_text" style="font-size:80%;">97.4</span></td>
</tr>
<tr id="S4.T3.4.10.10" class="ltx_tr">
<th id="S4.T3.4.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.T3.4.10.10.1.1" class="ltx_text" style="font-size:80%;">CoCa¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T3.4.10.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib53" title="" class="ltx_ref">53</a><span id="S4.T3.4.10.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T3.4.10.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.2.1" class="ltx_text" style="font-size:80%;">1B</span></th>
<td id="S4.T3.4.10.10.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.3.1" class="ltx_text" style="font-size:80%;">66.3</span></td>
<td id="S4.T3.4.10.10.4" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.4.1" class="ltx_text" style="font-size:80%;">86.2</span></td>
<td id="S4.T3.4.10.10.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.5.1" class="ltx_text" style="font-size:80%;">91.8</span></td>
<td id="S4.T3.4.10.10.6" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.6.1" class="ltx_text" style="font-size:80%;">51.2</span></td>
<td id="S4.T3.4.10.10.7" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.7.1" class="ltx_text" style="font-size:80%;">74.2</span></td>
<td id="S4.T3.4.10.10.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.8.1" class="ltx_text" style="font-size:80%;">82.0</span></td>
<td id="S4.T3.4.10.10.9" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">92.5</span></td>
<td id="S4.T3.4.10.10.10" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">99.5</span></td>
<td id="S4.T3.4.10.10.11" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">99.9</span></td>
<td id="S4.T3.4.10.10.12" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.12.1" class="ltx_text" style="font-size:80%;">80.4</span></td>
<td id="S4.T3.4.10.10.13" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.13.1" class="ltx_text" style="font-size:80%;">95.7</span></td>
<td id="S4.T3.4.10.10.14" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.10.10.14.1" class="ltx_text ltx_font_bold" style="font-size:80%;">97.7</span></td>
</tr>
<tr id="S4.T3.4.11.11" class="ltx_tr">
<th id="S4.T3.4.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></th>
<th id="S4.T3.4.11.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.2.1" class="ltx_text" style="font-size:80%;">303M</span></th>
<td id="S4.T3.4.11.11.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.9</span></td>
<td id="S4.T3.4.11.11.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">87.8</span></td>
<td id="S4.T3.4.11.11.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">92.2</span></td>
<td id="S4.T3.4.11.11.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">51.8</span></td>
<td id="S4.T3.4.11.11.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">75.0</span></td>
<td id="S4.T3.4.11.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">83.0</span></td>
<td id="S4.T3.4.11.11.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.9.1" class="ltx_text" style="font-size:80%;">92.1</span></td>
<td id="S4.T3.4.11.11.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.10.1" class="ltx_text" style="font-size:80%;">99.4</span></td>
<td id="S4.T3.4.11.11.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.11.1" class="ltx_text" style="font-size:80%;">99.7</span></td>
<td id="S4.T3.4.11.11.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">80.7</span></td>
<td id="S4.T3.4.11.11.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.13.1" class="ltx_text ltx_font_bold" style="font-size:80%;">96.1</span></td>
<td id="S4.T3.4.11.11.14" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.T3.4.11.11.14.1" class="ltx_text ltx_font_bold" style="font-size:80%;">97.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.9.2.1" class="ltx_text" style="font-size:113%;">Table 3</span>: </span><span id="S4.T3.2.1" class="ltx_text ltx_font_bold" style="font-size:113%;">Zero-shot image-text retrieval results on COCO and Flickr30K benchmarks.<span id="S4.T3.2.1.1" class="ltx_text ltx_font_medium"> We compare with dual-encoder methods. We achieve state-of-the-art results on COCO benchmark. We outperform CoCa-Large with the same backbone by +3.5 / +1.7 R@1, and even surpass CoCa with 3<math id="S4.T3.2.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T3.2.1.1.m1.1b"><mo id="S4.T3.2.1.1.m1.1.1" xref="S4.T3.2.1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.1.1.m1.1c"><times id="S4.T3.2.1.1.m1.1.1.cmml" xref="S4.T3.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.1.1.m1.1d">\times</annotation></semantics></math> larger backbone (ViT-Giant) by +2.6 / +0.6 R@1 on image-to-text / text-to-image retrieval. We also match or outperform the state-of-the-art methods on Flickr benchmark
</span></span></figcaption>
</figure>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Open-vocabulary Object Detection</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">LVIS benchmark.</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.3" class="ltx_p">We conduct evaluation on the LVIS dataset¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> which contains a large and diverse set of 1203 object categories suitable for open-vocabulary detection. Following the existing works¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, we use the frequent and common categories as base categories <math id="S4.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="C_{B}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.1a"><msub id="S4.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">C</mi><mi id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">B</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.2">ùê∂</ci><ci id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.3">ùêµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.1c">C_{B}</annotation></semantics></math> for training, and hold out the rare categories as novel categories <math id="S4.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="C_{N}" display="inline"><semantics id="S4.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S4.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">C</mi><mi id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.2">ùê∂</ci><ci id="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px1.p1.2.m2.1.1.3">ùëÅ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.2.m2.1c">C_{N}</annotation></semantics></math> for testing. Mask AP<sub id="S4.SS1.SSS0.Px1.p1.3.1" class="ltx_sub"><span id="S4.SS1.SSS0.Px1.p1.3.1.1" class="ltx_text ltx_font_italic">r</span></sub> is the main benchmark metric. We report the mean over three runs following¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="S4.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p2.3" class="ltx_p">As shown in Table¬†<a href="#S3.T1" title="Table 1 ‚Ä£ 3.3 Open-vocabulary Detector Finetuning ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our best model achieves 34.1 AP<sub id="S4.SS1.SSS0.Px1.p2.3.1" class="ltx_sub"><span id="S4.SS1.SSS0.Px1.p2.3.1.1" class="ltx_text ltx_font_italic">r</span></sub>, which significantly outperforms best existing ViT-based approach OWL-ViT¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> by <span id="S4.SS1.SSS0.Px1.p2.3.2" class="ltx_text ltx_font_bold">+9.5</span> points. Notably, our method with smaller ViT-B/16 backbone surpasses OWL-ViT with ViT-L/14 by <span id="S4.SS1.SSS0.Px1.p2.3.3" class="ltx_text ltx_font_bold">+2.8</span> AP<sub id="S4.SS1.SSS0.Px1.p2.3.4" class="ltx_sub"><span id="S4.SS1.SSS0.Px1.p2.3.4.1" class="ltx_text ltx_font_italic">r</span></sub>. Compared to the best existing approach (ViLD-Ens with EffNet-B7 backbone), we outperform by +7.8 AP<sub id="S4.SS1.SSS0.Px1.p2.3.5" class="ltx_sub"><span id="S4.SS1.SSS0.Px1.p2.3.5.1" class="ltx_text ltx_font_italic">r</span></sub>. We note that RO-ViT is simply trained end-to-end with the cross-entropy loss without the employment of LVIS-tailored losses such as federated loss¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, weak supervision¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, or self-training¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">COCO benchmark.</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">We also present the comparison on the COCO benchmark where the setup uses 48 base categories for training and 17 novel categories for testing¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. The main metric is AP50 of novel categories.
Due to the smaller number of training categories, we observe a tendency to overfit to these categories. Unlike most competing methods, RO-ViT does <span id="S4.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">not</span> use any auxiliary objectives to mitigate overfitting such as pseudo box/mask labels¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, knowledge distillation¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, weak supervision¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. Still, Table¬†<a href="#S4.T2" title="Table 2 ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that RO-ViT is very competitive among the other methods trained with various sources. In addition, RO-ViT represents the first ViT-based method to be reported on this benchmark, as the other method OWL-ViT¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> only benchmarks on LVIS.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Image-Text Retrieval</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Apart from evaluating region-level representation through open-vocabulary detection, we evaluate the <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">image-level</span> representation of RO-ViT in image-text retrieval through the MS-COCO¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and Flickr30K¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> benchmarks. We further train RO-ViT (ViT-L/16), the same model as the last row of Table¬†<a href="#S3.T1" title="Table 1 ‚Ä£ 3.3 Open-vocabulary Detector Finetuning ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and ¬†<a href="#S4.T4" title="Table 4 ‚Ä£ 4.2 Image-Text Retrieval ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, for 40K iterations more at a higher resolution <em id="S4.SS2.p1.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS2.p1.1.3" class="ltx_text"></span> 448, following the standard of existing works¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Table¬†<a href="#S4.T3" title="Table 3 ‚Ä£ Downstream detection details. ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the comparison with other dual-encoder methods on zero-shot image-to-text (I2T) and text-to-image (T2I) retrieval. Surprisingly, RO-ViT outperform all published works on the MS COCO benchmark, and is on par with the state of the art¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> on Flickr. Compared to CoCa¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> with the same backbone capacity (ViT-L), RO-ViT outperforms on 11 out of 12 image-text retrieval metrics. Our model has 303M parameters and achieves the best performance overall. This shows that our pretraining method not only improves the region-level representation for open-vocabulary detection but also the global image-level representation for retrieval.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.1.1.1.1" class="ltx_text" style="font-size:80%;">method</span></th>
<th id="S4.T4.2.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.1.1.2.1" class="ltx_text" style="font-size:80%;">backbone</span></th>
<td id="S4.T4.2.1.1.3" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.1.1.3.1" class="ltx_text" style="font-size:80%;">AP</span></td>
<td id="S4.T4.2.1.1.4" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;">
<span id="S4.T4.2.1.1.4.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.T4.2.1.1.4.2" class="ltx_sub"><span id="S4.T4.2.1.1.4.2.1" class="ltx_text" style="font-size:80%;">50</span></sub>
</td>
<td id="S4.T4.2.1.1.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;">
<span id="S4.T4.2.1.1.5.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.T4.2.1.1.5.2" class="ltx_sub"><span id="S4.T4.2.1.1.5.2.1" class="ltx_text" style="font-size:80%;">75</span></sub>
</td>
</tr>
<tr id="S4.T4.2.2.2" class="ltx_tr">
<th id="S4.T4.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;">
<span id="S4.T4.2.2.2.1.1" class="ltx_text" style="font-size:80%;">supervised¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.2.2.2.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S4.T4.2.2.2.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T4.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.2.2.2.1" class="ltx_text" style="font-size:80%;">R-50</span></th>
<td id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.2.2.3.1" class="ltx_text" style="font-size:80%;">25.6</span></td>
<td id="S4.T4.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.2.2.4.1" class="ltx_text" style="font-size:80%;">38.6</span></td>
<td id="S4.T4.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.2.2.5.1" class="ltx_text" style="font-size:80%;">28.0</span></td>
</tr>
<tr id="S4.T4.2.3.3" class="ltx_tr">
<th id="S4.T4.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;">
<span id="S4.T4.2.3.3.1.1" class="ltx_text" style="font-size:80%;">ViLD¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.2.3.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S4.T4.2.3.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T4.2.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.3.3.2.1" class="ltx_text" style="font-size:80%;">R-50</span></th>
<td id="S4.T4.2.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.3.3.3.1" class="ltx_text" style="font-size:80%;">11.8</span></td>
<td id="S4.T4.2.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.3.3.4.1" class="ltx_text" style="font-size:80%;">18.2</span></td>
<td id="S4.T4.2.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.3.3.5.1" class="ltx_text" style="font-size:80%;">12.6</span></td>
</tr>
<tr id="S4.T4.2.4.4" class="ltx_tr">
<th id="S4.T4.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 8.0pt;">
<span id="S4.T4.2.4.4.1.1" class="ltx_text" style="font-size:80%;">DetPro¬†</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.2.4.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S4.T4.2.4.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T4.2.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.4.4.2.1" class="ltx_text" style="font-size:80%;">R-50</span></th>
<td id="S4.T4.2.4.4.3" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.4.4.3.1" class="ltx_text" style="font-size:80%;">12.1</span></td>
<td id="S4.T4.2.4.4.4" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.4.4.4.1" class="ltx_text" style="font-size:80%;">18.8</span></td>
<td id="S4.T4.2.4.4.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.4.4.5.1" class="ltx_text" style="font-size:80%;">12.9</span></td>
</tr>
<tr id="S4.T4.2.5.5" class="ltx_tr">
<th id="S4.T4.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.5.5.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></th>
<th id="S4.T4.2.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.5.5.2.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></th>
<td id="S4.T4.2.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.5.5.3.1" class="ltx_text" style="font-size:80%;">14.0</span></td>
<td id="S4.T4.2.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.5.5.4.1" class="ltx_text" style="font-size:80%;">22.3</span></td>
<td id="S4.T4.2.5.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.5.5.5.1" class="ltx_text" style="font-size:80%;">14.9</span></td>
</tr>
<tr id="S4.T4.2.6.6" class="ltx_tr">
<th id="S4.T4.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.6.6.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">RO-ViT (ours)</span></th>
<th id="S4.T4.2.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.6.6.2.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></th>
<td id="S4.T4.2.6.6.3" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.6.6.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">17.1</span></td>
<td id="S4.T4.2.6.6.4" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.6.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">26.9</span></td>
<td id="S4.T4.2.6.6.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.T4.2.6.6.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">18.5</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.6.1.1" class="ltx_text" style="font-size:113%;">Table 4</span>: </span><span id="S4.T4.7.2" class="ltx_text ltx_font_bold" style="font-size:113%;">Transfer detection on Objects365 (Box APs).<span id="S4.T4.7.2.1" class="ltx_text ltx_font_medium"> All models are trained on the LVIS base categories and tested on Objects365 dataset, without finetuning.</span></span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S4.F3.sf1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F3.sf1.1.1" class="ltx_tr">
<th id="S4.F3.sf1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.1.2.1" class="ltx_text" style="font-size:80%;">pretraining method</span></th>
<td id="S4.F3.sf1.1.1.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CPE</span></td>
<td id="S4.F3.sf1.1.1.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">focal</span></td>
<td id="S4.F3.sf1.1.1.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.1.1.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.F3.sf1.1.1.1.2" class="ltx_sub"><span id="S4.F3.sf1.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">r</span></sub>
</td>
<td id="S4.F3.sf1.1.1.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></td>
</tr>
<tr id="S4.F3.sf1.1.2.1" class="ltx_tr">
<th id="S4.F3.sf1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.2.1.1.1" class="ltx_text" style="font-size:80%;">base</span></th>
<td id="S4.F3.sf1.1.2.1.2" class="ltx_td ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.2.1.3" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.2.1.4.1" class="ltx_text" style="font-size:80%;">21.4 </span><span id="S4.F3.sf1.1.2.1.4.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.2.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.6</span></td>
</tr>
<tr id="S4.F3.sf1.1.3.2" class="ltx_tr">
<th id="S4.F3.sf1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.3.2.1.1" class="ltx_text" style="font-size:80%;">no PE</span></th>
<td id="S4.F3.sf1.1.3.2.2" class="ltx_td" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.3.2.3" class="ltx_td ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.3.2.4.1" class="ltx_text" style="font-size:80%;">18.7 </span><span id="S4.F3.sf1.1.3.2.4.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf1.1.3.2.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.3.2.5.1" class="ltx_text" style="font-size:80%;color:#808080;">25.2</span></td>
</tr>
<tr id="S4.F3.sf1.1.4.3" class="ltx_tr">
<th id="S4.F3.sf1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.4.3.1.1" class="ltx_text" style="font-size:80%;">SinCos PE</span></th>
<td id="S4.F3.sf1.1.4.3.2" class="ltx_td" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.4.3.3" class="ltx_td ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.4.3.4.1" class="ltx_text" style="font-size:80%;">21.7 </span><span id="S4.F3.sf1.1.4.3.4.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf1.1.4.3.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.4.3.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.9</span></td>
</tr>
<tr id="S4.F3.sf1.1.5.4" class="ltx_tr">
<th id="S4.F3.sf1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.5.4.1.1" class="ltx_text" style="font-size:80%;">feat Crop-Resize</span></th>
<td id="S4.F3.sf1.1.5.4.2" class="ltx_td" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.5.4.3" class="ltx_td ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.5.4.4.1" class="ltx_text" style="font-size:80%;">20.6 </span><span id="S4.F3.sf1.1.5.4.4.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf1.1.5.4.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.5.4.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.6</span></td>
</tr>
<tr id="S4.F3.sf1.1.6.5" class="ltx_tr">
<th id="S4.F3.sf1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.6.5.1.1" class="ltx_text" style="font-size:80%;">ours</span></th>
<td id="S4.F3.sf1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.6.5.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf1.1.6.5.3" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.6.5.4.1" class="ltx_text" style="font-size:80%;">23.8 (</span><span id="S4.F3.sf1.1.6.5.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+2.4</span><span id="S4.F3.sf1.1.6.5.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.6.5.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.4</span></td>
</tr>
<tr id="S4.F3.sf1.1.7.6" class="ltx_tr">
<th id="S4.F3.sf1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.7.6.1.1" class="ltx_text" style="font-size:80%;">ours</span></th>
<td id="S4.F3.sf1.1.7.6.2" class="ltx_td" style="padding-top:0.4pt;padding-bottom:0.4pt;"></td>
<td id="S4.F3.sf1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.7.6.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.7.6.4.1" class="ltx_text" style="font-size:80%;">21.9 (</span><span id="S4.F3.sf1.1.7.6.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+0.5</span><span id="S4.F3.sf1.1.7.6.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf1.1.7.6.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.7.6.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.4</span></td>
</tr>
<tr id="S4.F3.sf1.1.8.7" class="ltx_tr">
<th id="S4.F3.sf1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.8.7.1.1" class="ltx_text" style="font-size:80%;">ours</span></th>
<td id="S4.F3.sf1.1.8.7.2" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.8.7.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.8.7.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf1.1.8.7.4.1" class="ltx_text" style="font-size:80%;">24.3 (</span><span id="S4.F3.sf1.1.8.7.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+2.9</span><span id="S4.F3.sf1.1.8.7.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf1.1.8.7.5" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf1.1.8.7.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.4.1.1" class="ltx_text" style="font-size:113%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S4.F3.sf2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.F3.sf2.1.1" class="ltx_tr">
<th id="S4.F3.sf2.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.1.2.1" class="ltx_text" style="font-size:80%;">frozen backbone</span></th>
<th id="S4.F3.sf2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf2.1.1.1.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.F3.sf2.1.1.1.2" class="ltx_sub"><span id="S4.F3.sf2.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">r</span></sub>
</th>
<th id="S4.F3.sf2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.1.3.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></th>
</tr>
<tr id="S4.F3.sf2.1.2.1" class="ltx_tr">
<th id="S4.F3.sf2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.2.1.1.1" class="ltx_text" style="font-size:80%;">base</span></th>
<th id="S4.F3.sf2.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf2.1.2.1.2.1" class="ltx_text" style="font-size:80%;">9.7 </span><span id="S4.F3.sf2.1.2.1.2.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</th>
<th id="S4.F3.sf2.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.2.1.3.1" class="ltx_text" style="font-size:80%;color:#808080;">12.2</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.F3.sf2.1.3.1" class="ltx_tr">
<th id="S4.F3.sf2.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.3.1.1.1" class="ltx_text" style="font-size:80%;">CPE</span></th>
<td id="S4.F3.sf2.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf2.1.3.1.2.1" class="ltx_text" style="font-size:80%;">16.2 (</span><span id="S4.F3.sf2.1.3.1.2.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+6.5</span><span id="S4.F3.sf2.1.3.1.2.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf2.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.3.1.3.1" class="ltx_text" style="font-size:80%;color:#808080;">17.1</span></td>
</tr>
<tr id="S4.F3.sf2.1.4.2" class="ltx_tr">
<th id="S4.F3.sf2.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.4.2.1.1" class="ltx_text" style="font-size:80%;">CPE + focal</span></th>
<td id="S4.F3.sf2.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf2.1.4.2.2.1" class="ltx_text" style="font-size:80%;">16.5 (</span><span id="S4.F3.sf2.1.4.2.2.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+6.8</span><span id="S4.F3.sf2.1.4.2.2.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf2.1.4.2.3" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf2.1.4.2.3.1" class="ltx_text" style="font-size:80%;color:#808080;">17.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.4.1.1" class="ltx_text" style="font-size:113%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S4.F3.sf3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.F3.sf3.1.1" class="ltx_tr">
<th id="S4.F3.sf3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.1.2.1" class="ltx_text" style="font-size:80%;">bblr</span></th>
<th id="S4.F3.sf3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;">
<span id="S4.F3.sf3.1.1.1.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.F3.sf3.1.1.1.2" class="ltx_sub"><span id="S4.F3.sf3.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">r</span></sub>
</th>
<th id="S4.F3.sf3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.1.3.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.F3.sf3.1.2.1" class="ltx_tr">
<th id="S4.F3.sf3.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.2.1.1.1" class="ltx_text" style="font-size:80%;">0.0</span></th>
<td id="S4.F3.sf3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.2.1.2.1" class="ltx_text" style="font-size:80%;">16.5</span></td>
<td id="S4.F3.sf3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.2.1.3.1" class="ltx_text" style="font-size:80%;color:#808080;">17.1</span></td>
</tr>
<tr id="S4.F3.sf3.1.3.2" class="ltx_tr">
<th id="S4.F3.sf3.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.3.2.1.1" class="ltx_text" style="font-size:80%;">0.001</span></th>
<td id="S4.F3.sf3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.3.2.2.1" class="ltx_text" style="font-size:80%;">19.7</span></td>
<td id="S4.F3.sf3.1.3.2.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.3.2.3.1" class="ltx_text" style="font-size:80%;color:#808080;">22.9</span></td>
</tr>
<tr id="S4.F3.sf3.1.4.3" class="ltx_tr">
<th id="S4.F3.sf3.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.4.3.1.1" class="ltx_text" style="font-size:80%;">0.01</span></th>
<td id="S4.F3.sf3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.4.3.2.1" class="ltx_text" style="font-size:80%;">20.4</span></td>
<td id="S4.F3.sf3.1.4.3.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.4.3.3.1" class="ltx_text" style="font-size:80%;color:#808080;">23.0</span></td>
</tr>
<tr id="S4.F3.sf3.1.5.4" class="ltx_tr">
<th id="S4.F3.sf3.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.5.4.1.1" class="ltx_text" style="font-size:80%;">0.1</span></th>
<td id="S4.F3.sf3.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.5.4.2.1" class="ltx_text" style="font-size:80%;">24.3</span></td>
<td id="S4.F3.sf3.1.5.4.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.5.4.3.1" class="ltx_text" style="font-size:80%;color:#808080;">27.6</span></td>
</tr>
<tr id="S4.F3.sf3.1.6.5" class="ltx_tr">
<th id="S4.F3.sf3.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.6.5.1.1" class="ltx_text" style="font-size:80%;">1.0</span></th>
<td id="S4.F3.sf3.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.6.5.2.1" class="ltx_text" style="font-size:80%;">17.9</span></td>
<td id="S4.F3.sf3.1.6.5.3" class="ltx_td ltx_align_center" style="padding-top:0.4pt;padding-bottom:0.4pt;"><span id="S4.F3.sf3.1.6.5.3.1" class="ltx_text" style="font-size:80%;color:#808080;">25.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf3.4.1.1" class="ltx_text" style="font-size:113%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S4.F3.sf4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F3.sf4.1.1" class="ltx_tr">
<td id="S4.F3.sf4.1.1.2" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.1.2.1" class="ltx_text" style="font-size:80%;">backbone</span></td>
<td id="S4.F3.sf4.1.1.3" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.1.3.1" class="ltx_text" style="font-size:80%;">loc.obj.</span></td>
<td id="S4.F3.sf4.1.1.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.1.4.1" class="ltx_text" style="font-size:80%;">norm.lyr</span></td>
<td id="S4.F3.sf4.1.1.1" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.1.1.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.F3.sf4.1.1.1.2" class="ltx_sub"><span id="S4.F3.sf4.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">r</span></sub>
</td>
<td id="S4.F3.sf4.1.1.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></td>
</tr>
<tr id="S4.F3.sf4.1.2.1" class="ltx_tr">
<td id="S4.F3.sf4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.2.1.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf4.1.2.1.2" class="ltx_td ltx_border_t" style="padding:0.4pt 8.0pt;"></td>
<td id="S4.F3.sf4.1.2.1.3" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"></td>
<td id="S4.F3.sf4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.2.1.4.1" class="ltx_text" style="font-size:80%;">21.4 </span><span id="S4.F3.sf4.1.2.1.4.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf4.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.2.1.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.6</span></td>
</tr>
<tr id="S4.F3.sf4.1.3.2" class="ltx_tr">
<td id="S4.F3.sf4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.3.2.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf4.1.3.2.2" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.3.2.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf4.1.3.2.3" class="ltx_td ltx_border_r" style="padding:0.4pt 8.0pt;"></td>
<td id="S4.F3.sf4.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.3.2.4.1" class="ltx_text" style="font-size:80%;">23.4 (</span><span id="S4.F3.sf4.1.3.2.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+2.0</span><span id="S4.F3.sf4.1.3.2.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf4.1.3.2.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.3.2.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.2</span></td>
</tr>
<tr id="S4.F3.sf4.1.4.3" class="ltx_tr">
<td id="S4.F3.sf4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.4.3.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf4.1.4.3.2" class="ltx_td" style="padding:0.4pt 8.0pt;"></td>
<td id="S4.F3.sf4.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.4.3.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.4.3.4.1" class="ltx_text" style="font-size:80%;">22.0 (</span><span id="S4.F3.sf4.1.4.3.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+0.6</span><span id="S4.F3.sf4.1.4.3.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf4.1.4.3.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.4.3.5.1" class="ltx_text" style="font-size:80%;color:#808080;">26.8</span></td>
</tr>
<tr id="S4.F3.sf4.1.5.4" class="ltx_tr">
<td id="S4.F3.sf4.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.5.4.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf4.1.5.4.2" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.5.4.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf4.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.5.4.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf4.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.5.4.4.1" class="ltx_text" style="font-size:80%;">23.9 (</span><span id="S4.F3.sf4.1.5.4.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+2.5</span><span id="S4.F3.sf4.1.5.4.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf4.1.5.4.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.5.4.5.1" class="ltx_text" style="font-size:80%;color:#808080;">27.5</span></td>
</tr>
<tr id="S4.F3.sf4.1.6.5" class="ltx_tr">
<td id="S4.F3.sf4.1.6.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.6.5.1.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.F3.sf4.1.6.5.2" class="ltx_td ltx_border_t" style="padding:0.4pt 8.0pt;"></td>
<td id="S4.F3.sf4.1.6.5.3" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;"></td>
<td id="S4.F3.sf4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.6.5.4.1" class="ltx_text" style="font-size:80%;">25.1 </span><span id="S4.F3.sf4.1.6.5.4.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf4.1.6.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.6.5.5.1" class="ltx_text" style="font-size:80%;color:#808080;">30.1</span></td>
</tr>
<tr id="S4.F3.sf4.1.7.6" class="ltx_tr">
<td id="S4.F3.sf4.1.7.6.1" class="ltx_td ltx_align_left ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.7.6.1.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.F3.sf4.1.7.6.2" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.7.6.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf4.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.7.6.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf4.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 8.0pt;">
<span id="S4.F3.sf4.1.7.6.4.1" class="ltx_text" style="font-size:80%;">27.2 (</span><span id="S4.F3.sf4.1.7.6.4.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+1.9</span><span id="S4.F3.sf4.1.7.6.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf4.1.7.6.5" class="ltx_td ltx_align_center" style="padding:0.4pt 8.0pt;"><span id="S4.F3.sf4.1.7.6.5.1" class="ltx_text" style="font-size:80%;color:#808080;">30.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf4.4.1.1" class="ltx_text" style="font-size:113%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<table id="S4.F3.sf5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.F3.sf5.1.1" class="ltx_tr">
<td id="S4.F3.sf5.1.1.2" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.1.2.1" class="ltx_text" style="font-size:80%;">backbone</span></td>
<td id="S4.F3.sf5.1.1.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.1.3.1" class="ltx_text" style="font-size:80%;">batch</span></td>
<td id="S4.F3.sf5.1.1.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.1.4.1" class="ltx_text" style="font-size:80%;">imp.(d)</span></td>
<td id="S4.F3.sf5.1.1.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CPE + focal</span></td>
<td id="S4.F3.sf5.1.1.1" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.1.1.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="S4.F3.sf5.1.1.1.2" class="ltx_sub"><span id="S4.F3.sf5.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">r</span></sub>
</td>
<td id="S4.F3.sf5.1.1.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.1.6.1" class="ltx_text" style="font-size:80%;color:#808080;">AP</span></td>
</tr>
<tr id="S4.F3.sf5.1.2.1" class="ltx_tr">
<td id="S4.F3.sf5.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.2.1.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.2.1.2.1" class="ltx_text" style="font-size:80%;">4096</span></td>
<td id="S4.F3.sf5.1.2.1.3" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.F3.sf5.1.2.1.4" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.F3.sf5.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.2.1.5.1" class="ltx_text" style="font-size:80%;">21.4 </span><span id="S4.F3.sf5.1.2.1.5.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf5.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.2.1.6.1" class="ltx_text" style="font-size:80%;color:#808080;">26.6</span></td>
</tr>
<tr id="S4.F3.sf5.1.3.2" class="ltx_tr">
<td id="S4.F3.sf5.1.3.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.3.2.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf5.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.3.2.2.1" class="ltx_text" style="font-size:80%;">4096</span></td>
<td id="S4.F3.sf5.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.3.2.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.3.2.4" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.F3.sf5.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.3.2.5.1" class="ltx_text" style="font-size:80%;">23.9 </span><span id="S4.F3.sf5.1.3.2.5.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf5.1.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.3.2.6.1" class="ltx_text" style="font-size:80%;color:#808080;">27.5</span></td>
</tr>
<tr id="S4.F3.sf5.1.4.3" class="ltx_tr">
<td id="S4.F3.sf5.1.4.3.1" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.4.3.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf5.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.4.3.2.1" class="ltx_text" style="font-size:80%;">4096</span></td>
<td id="S4.F3.sf5.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.4.3.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.4.3.4.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.4.3.5.1" class="ltx_text" style="font-size:80%;">26.2 (</span><span id="S4.F3.sf5.1.4.3.5.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+2.3</span><span id="S4.F3.sf5.1.4.3.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf5.1.4.3.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.4.3.6.1" class="ltx_text" style="font-size:80%;color:#808080;">29.2</span></td>
</tr>
<tr id="S4.F3.sf5.1.5.4" class="ltx_tr">
<td id="S4.F3.sf5.1.5.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.5.4.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf5.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.5.4.2.1" class="ltx_text" style="font-size:80%;">16384</span></td>
<td id="S4.F3.sf5.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.5.4.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.5.4.4" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.F3.sf5.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.5.4.5.1" class="ltx_text" style="font-size:80%;">26.4 </span><span id="S4.F3.sf5.1.5.4.5.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf5.1.5.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.5.4.6.1" class="ltx_text" style="font-size:80%;color:#808080;">30.3</span></td>
</tr>
<tr id="S4.F3.sf5.1.6.5" class="ltx_tr">
<td id="S4.F3.sf5.1.6.5.1" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.6.5.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.F3.sf5.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.6.5.2.1" class="ltx_text" style="font-size:80%;">16384</span></td>
<td id="S4.F3.sf5.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.6.5.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.6.5.4.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.6.5.5.1" class="ltx_text" style="font-size:80%;">28.0 (</span><span id="S4.F3.sf5.1.6.5.5.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+1.6</span><span id="S4.F3.sf5.1.6.5.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf5.1.6.5.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.6.5.6.1" class="ltx_text" style="font-size:80%;color:#808080;">30.2</span></td>
</tr>
<tr id="S4.F3.sf5.1.7.6" class="ltx_tr">
<td id="S4.F3.sf5.1.7.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.7.6.1.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.F3.sf5.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.7.6.2.1" class="ltx_text" style="font-size:80%;">4096</span></td>
<td id="S4.F3.sf5.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.7.6.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.7.6.4" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.F3.sf5.1.7.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.7.6.5.1" class="ltx_text" style="font-size:80%;">27.2 </span><span id="S4.F3.sf5.1.7.6.5.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf5.1.7.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.7.6.6.1" class="ltx_text" style="font-size:80%;color:#808080;">30.6</span></td>
</tr>
<tr id="S4.F3.sf5.1.8.7" class="ltx_tr">
<td id="S4.F3.sf5.1.8.7.1" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.8.7.1.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.F3.sf5.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.8.7.2.1" class="ltx_text" style="font-size:80%;">4096</span></td>
<td id="S4.F3.sf5.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.8.7.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.8.7.4.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.8.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.8.7.5.1" class="ltx_text" style="font-size:80%;">29.9 (</span><span id="S4.F3.sf5.1.8.7.5.2" class="ltx_text" style="font-size:80%;color:#3166FF;">+2.7</span><span id="S4.F3.sf5.1.8.7.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.F3.sf5.1.8.7.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.8.7.6.1" class="ltx_text" style="font-size:80%;color:#808080;">31.1</span></td>
</tr>
<tr id="S4.F3.sf5.1.9.8" class="ltx_tr">
<td id="S4.F3.sf5.1.9.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.9.8.1.1" class="ltx_text" style="font-size:80%;">ViT-L/16</span></td>
<td id="S4.F3.sf5.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.9.8.2.1" class="ltx_text" style="font-size:80%;">16384</span></td>
<td id="S4.F3.sf5.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.9.8.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.9.8.4.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.F3.sf5.1.9.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;">
<span id="S4.F3.sf5.1.9.8.5.1" class="ltx_text" style="font-size:80%;">32.1 </span><span id="S4.F3.sf5.1.9.8.5.2" class="ltx_text" style="font-size:80%;color:#FFFFFF;">(+0.0)</span>
</td>
<td id="S4.F3.sf5.1.9.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.F3.sf5.1.9.8.6.1" class="ltx_text" style="font-size:80%;color:#808080;">34.0</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf5.4.1.1" class="ltx_text" style="font-size:113%;">(e)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.6.2.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ablation studies.<span id="S4.T5.2.1.1" class="ltx_text ltx_font_medium"> We follow LVIS open-vocabulary detection benchmark. We train on base (‚Äòfrequent‚Äô + ‚Äòcommon‚Äô) categories, test on novel (‚Äòrare‚Äô) categories, and report AP<sub id="S4.T5.2.1.1.1" class="ltx_sub"><span id="S4.T5.2.1.1.1.1" class="ltx_text ltx_font_italic">r</span></sub>. We use ViT-B/16 backbone and contrastive batch size 4096 unless otherwise noted.</span></span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Transfer Object Detection</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We evaluate the generalization ability of RO-ViT in zero-shot transfer detection. We use the same detector trained on the LVIS base categories (Sec.¬†<a href="#S4.SS1" title="4.1 Open-vocabulary Object Detection ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) and test on Objects365-v1 validation split¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> following the setup of ViLD¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We replace the LVIS with Objects365 vocabulary embeddings to perform the transfer detection without finetuning.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Table¬†<a href="#S4.T4" title="Table 4 ‚Ä£ 4.2 Image-Text Retrieval ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes the box AP scores in comparison with prior works. Our best model achieves 17.1 AP, which outperforms existing works ViLD by +5.3 AP and DetPro by +5.0 AP. Due to the different backbone capacity (R50 vs ViT), we note that this comparison is to showcase that RO-ViT can achieve strong cross-dataset detection generalization. For transfer detection, we assume all categories are novel and set <math id="S4.SS3.p2.1.m1.2" class="ltx_Math" alttext="\alpha,\beta" display="inline"><semantics id="S4.SS3.p2.1.m1.2a"><mrow id="S4.SS3.p2.1.m1.2.3.2" xref="S4.SS3.p2.1.m1.2.3.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">Œ±</mi><mo id="S4.SS3.p2.1.m1.2.3.2.1" xref="S4.SS3.p2.1.m1.2.3.1.cmml">,</mo><mi id="S4.SS3.p2.1.m1.2.2" xref="S4.SS3.p2.1.m1.2.2.cmml">Œ≤</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.2b"><list id="S4.SS3.p2.1.m1.2.3.1.cmml" xref="S4.SS3.p2.1.m1.2.3.2"><ci id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">ùõº</ci><ci id="S4.SS3.p2.1.m1.2.2.cmml" xref="S4.SS3.p2.1.m1.2.2">ùõΩ</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.2c">\alpha,\beta</annotation></semantics></math>=(0.0, 0.65) in Equation¬†<a href="#S3.E1" title="Equation 1 ‚Ä£ Open-vocabulary object detector. ‚Ä£ 3.1 Preliminaries ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We provide ablation studies on the LVIS open-vocabulary detection and image-text retrieval benchmarks.</p>
</div>
<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pretraining strategy.</h4>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px1.p1.2" class="ltx_p">Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:ablation:pretraining</span> ablates our proposed methods in the contrastive image-text pretraining. We start with ‚Äúbase‚Äù that uses the common full-image positional embeddings and cross entropy loss. We explore different PE and observe that removing the positional embeddings hurts the performance (no PE), while sinusoidal PE (SinCos PE) yields a similar performance to the baseline. We also try the random crop and resize on the last backbone feature map (‚Äúfeat Crop-Resize‚Äù) to use region features during pretraining but see no improvement.
In contrast, our proposed Cropped Positional Embedding (CPE) offers a clear benefit of +2.4 AP<sub id="S4.SS4.SSS0.Px1.p1.2.1" class="ltx_sub"><span id="S4.SS4.SSS0.Px1.p1.2.1.1" class="ltx_text ltx_font_italic">r</span></sub> and focal contrastive loss (focal) yields additional gains. Our method achieves a gain of +2.9 AP<sub id="S4.SS4.SSS0.Px1.p1.2.2" class="ltx_sub"><span id="S4.SS4.SSS0.Px1.p1.2.2.1" class="ltx_text ltx_font_italic">r</span></sub> in total. This shows that CPE can learn strong region-level representations, and our focal contrastive learning helps preserving the knowledge about the pretrained image-text concepts, both of which are essential for open-vocabulary detection.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.2.1.1" class="ltx_tr">
<th id="S4.T6.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;" rowspan="2"><span id="S4.T6.2.1.1.1.1" class="ltx_text" style="font-size:80%;">backbone</span></th>
<th id="S4.T6.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;" rowspan="2"><span id="S4.T6.2.1.1.2.1" class="ltx_text" style="font-size:80%;">focal</span></th>
<th id="S4.T6.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding:0.4pt 7.0pt;" rowspan="2"><span id="S4.T6.2.1.1.3.1" class="ltx_text" style="font-size:80%;">CPE</span></th>
<th id="S4.T6.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;" colspan="2"><span id="S4.T6.2.1.1.4.1" class="ltx_text" style="font-size:80%;">MS COCO</span></th>
<th id="S4.T6.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;" colspan="2"><span id="S4.T6.2.1.1.5.1" class="ltx_text" style="font-size:80%;">Flickr30K</span></th>
</tr>
<tr id="S4.T6.2.2.2" class="ltx_tr">
<th id="S4.T6.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.2.2.1.1" class="ltx_text" style="font-size:80%;">I2T</span></th>
<th id="S4.T6.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.2.2.2.1" class="ltx_text" style="font-size:80%;">T2I</span></th>
<th id="S4.T6.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.2.2.3.1" class="ltx_text" style="font-size:80%;">I2T</span></th>
<th id="S4.T6.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.2.2.4.1" class="ltx_text" style="font-size:80%;">T2I</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.2.3.1" class="ltx_tr">
<td id="S4.T6.2.3.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.3.1.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.T6.2.3.1.2" class="ltx_td ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.T6.2.3.1.3" class="ltx_td ltx_border_r ltx_border_t" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.T6.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.3.1.4.1" class="ltx_text" style="font-size:80%;">59.1</span></td>
<td id="S4.T6.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.3.1.5.1" class="ltx_text" style="font-size:80%;">42.5</span></td>
<td id="S4.T6.2.3.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.3.1.6.1" class="ltx_text" style="font-size:80%;">84.8</span></td>
<td id="S4.T6.2.3.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.3.1.7.1" class="ltx_text" style="font-size:80%;">70.9</span></td>
</tr>
<tr id="S4.T6.2.4.2" class="ltx_tr">
<td id="S4.T6.2.4.2.1" class="ltx_td ltx_align_left" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.4.2.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.T6.2.4.2.2" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.4.2.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.T6.2.4.2.3" class="ltx_td ltx_border_r" style="padding:0.4pt 7.0pt;"></td>
<td id="S4.T6.2.4.2.4" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.4.2.4.1" class="ltx_text" style="font-size:80%;">60.3</span></td>
<td id="S4.T6.2.4.2.5" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.4.2.5.1" class="ltx_text" style="font-size:80%;">44.0</span></td>
<td id="S4.T6.2.4.2.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.4.2.6.1" class="ltx_text" style="font-size:80%;">85.4</span></td>
<td id="S4.T6.2.4.2.7" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.4.2.7.1" class="ltx_text" style="font-size:80%;">71.6</span></td>
</tr>
<tr id="S4.T6.2.5.3" class="ltx_tr">
<td id="S4.T6.2.5.3.1" class="ltx_td ltx_align_left" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.1.1" class="ltx_text" style="font-size:80%;">ViT-B/16</span></td>
<td id="S4.T6.2.5.3.2" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.T6.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.T6.2.5.3.4" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.4.1" class="ltx_text" style="font-size:80%;">62.2</span></td>
<td id="S4.T6.2.5.3.5" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.5.1" class="ltx_text" style="font-size:80%;">44.2</span></td>
<td id="S4.T6.2.5.3.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.6.1" class="ltx_text" style="font-size:80%;">86.5</span></td>
<td id="S4.T6.2.5.3.7" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.5.3.7.1" class="ltx_text" style="font-size:80%;">71.8</span></td>
</tr>
<tr id="S4.T6.2.6.4" class="ltx_tr">
<td id="S4.T6.2.6.4.1" class="ltx_td ltx_align_left" style="padding:0.4pt 7.0pt;">
<span id="S4.T6.2.6.4.1.1" class="ltx_text" style="font-size:80%;">ViT-</span><span id="S4.T6.2.6.4.1.2" class="ltx_text ltx_font_bold" style="font-size:80%;">L</span><span id="S4.T6.2.6.4.1.3" class="ltx_text" style="font-size:80%;">/16</span>
</td>
<td id="S4.T6.2.6.4.2" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.6.4.2.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.T6.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.6.4.3.1" class="ltx_text" style="font-size:80%;">‚úì</span></td>
<td id="S4.T6.2.6.4.4" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.6.4.4.1" class="ltx_text" style="font-size:80%;">67.0</span></td>
<td id="S4.T6.2.6.4.5" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.6.4.5.1" class="ltx_text" style="font-size:80%;">49.7</span></td>
<td id="S4.T6.2.6.4.6" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.6.4.6.1" class="ltx_text" style="font-size:80%;">89.5</span></td>
<td id="S4.T6.2.6.4.7" class="ltx_td ltx_align_center" style="padding:0.4pt 7.0pt;"><span id="S4.T6.2.6.4.7.1" class="ltx_text" style="font-size:80%;">77.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.6.1.1" class="ltx_text" style="font-size:113%;">Table 6</span>: </span><span id="S4.T6.7.2" class="ltx_text ltx_font_bold" style="font-size:113%;">Pretraining evaluation on zero-shot image-text retrieval (Recall@1).<span id="S4.T6.7.2.1" class="ltx_text ltx_font_medium"> We evaluate the image-level representation of our pretrained model on COCO and Flickr30k retrieval tasks. We ablate the focal contrastive loss, Cropped Positional Embedding (CPE) and backbone size.</span></span></figcaption>
</figure>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Image-text retrieval.</h4>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p1.1" class="ltx_p">In Table¬†<a href="#S4.T6" title="Table 6 ‚Ä£ Pretraining strategy. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we demonstrate that our proposed focal contrastive loss and Cropped Positional Embedding (CPE) both improve the image-text retrieval. We use a batch size of 16384 , image size 224, and ViT-B/16 backbone as our baseline, and report Recall@1 metrics on MS COCO and Flickr datasets. We first observe that focal loss brings clear improvements on all metrics, and adding CPE brings further improvements with a total of +3.1 / +1.7 image-to-text (I2T) and +1.7 / +0.9 text-to-image (T2I) improvements on the MS COCO / Flickr datasets. By replacing ViT-B/16 with ViT-L/16, we observe marked improvements of +4.8 / +5.5 / +3.0 / +5.4 on these metrics, showing that our recipe is highly scalable with backbone capacity.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Frozen backbone study.</h4>

<div id="S4.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px3.p1.1" class="ltx_p">We investigate the effectiveness of the <span id="S4.SS4.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">frozen</span> backbone features in open-vocabulary detection in Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:ablation:frozen</span>. This evaluation setting is more rigorous for representation learning because finetuning an entire network evaluates not only the quality of the representations but also the initialization and optimization method, as discussed in Goyal¬†<em id="S4.SS4.SSS0.Px3.p1.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S4.SS4.SSS0.Px3.p1.1.3" class="ltx_text"></span>¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. During the detection finetuning, all ViT backbone layers are frozen, and only the added detector layers (neck and heads) are trained. We observe frozen RO-ViT backbone improves the baseline by +6.8 AP<sub id="S4.SS4.SSS0.Px3.p1.1.4" class="ltx_sub"><span id="S4.SS4.SSS0.Px3.p1.1.4.1" class="ltx_text ltx_font_italic">r</span></sub>, a much larger margin compared to the full-finetuning setting. This study shows the region-aware representation of RO-ViT is critical for downstream detection tasks.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Backbone learning rate ratio.</h4>

<div id="S4.SS4.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px4.p1.2" class="ltx_p">As discussed in¬†Sec.¬†<a href="#S3.SS1" title="3.1 Preliminaries ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, our open-vocabulary object detector depends on the pretrained knowledge in the backbone to recognize novel categories beyond the detector annotations. Therefore, it is important to set the backbone learning rates lower than the rest of the detector layers to prevent forgetting in the finetuning process. We present ablations on the learning rate ratio between the backbone and the detector layers in Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:ablation:bblr</span>. We found 0.1<math id="S4.SS4.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS4.SSS0.Px4.p1.1.m1.1a"><mo id="S4.SS4.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px4.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px4.p1.1.m1.1b"><times id="S4.SS4.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px4.p1.1.m1.1c">\times</annotation></semantics></math> to be the sweet spot. Higher ratios lead to forgetting and hurts the AP<sub id="S4.SS4.SSS0.Px4.p1.2.1" class="ltx_sub"><span id="S4.SS4.SSS0.Px4.p1.2.1.1" class="ltx_text ltx_font_italic">r</span></sub>, and lower ratios hurt the ability to adapt to detection tasks and hurts AP overall.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Downstream detector improvements.</h4>

<div id="S4.SS4.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px5.p1.1" class="ltx_p">In addition, Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:ablation:detector</span> demonstrates our improvements in the downstream detector. Learning the objectness by localization quality, <em id="S4.SS4.SSS0.Px5.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS4.SSS0.Px5.p1.1.2" class="ltx_text"></span>, centerness (‚Äúloc.obj.‚Äù)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and leveraging it into detection score improves AP<sub id="S4.SS4.SSS0.Px5.p1.1.3" class="ltx_sub"><span id="S4.SS4.SSS0.Px5.p1.1.3.1" class="ltx_text ltx_font_italic">r</span></sub> by a clear gain of +1.9 points compared to using the conventional binary-classification in the proposal. This indicates the novel, unlabeled objects are indeed often missed in the proposal stage, which may limit the final open-vocabulary detection performance. Localization-quality based objectness helps remedy this.
The use of normalized activation in the last layers of the classifier and mask heads additionally improves the performance.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Scalability with respect to model size and batch size.</h4>

<div id="S4.SS4.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px6.p1.7" class="ltx_p">While increasing the model capacity and batch size have been beneficial for contrastive learning in general¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, we study their benefits in the downstream open-vocabulary detection in Table¬†<span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:ablation:scale</span>. Note the detector improvements presented in Sec.¬†<a href="#S3.SS3" title="3.3 Open-vocabulary Detector Finetuning ‚Ä£ 3 Method ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> are applied. We first observe increasing the batch size from the default 4096 to 16384 shows gains of +2.1<math id="S4.SS4.SSS0.Px6.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS4.SSS0.Px6.p1.1.m1.1a"><mo id="S4.SS4.SSS0.Px6.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px6.p1.1.m1.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px6.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS4.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px6.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px6.p1.1.m1.1c">\sim</annotation></semantics></math>2.5 AP<sub id="S4.SS4.SSS0.Px6.p1.7.1" class="ltx_sub"><span id="S4.SS4.SSS0.Px6.p1.7.1.1" class="ltx_text ltx_font_italic">r</span></sub> for both ViT-B/L. Then, we notice upgrading ViT-B to ViT-L brings +3.3<math id="S4.SS4.SSS0.Px6.p1.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS4.SSS0.Px6.p1.3.m3.1a"><mo id="S4.SS4.SSS0.Px6.p1.3.m3.1.1" xref="S4.SS4.SSS0.Px6.p1.3.m3.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px6.p1.3.m3.1b"><csymbol cd="latexml" id="S4.SS4.SSS0.Px6.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS0.Px6.p1.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px6.p1.3.m3.1c">\sim</annotation></semantics></math>3.7 AP<sub id="S4.SS4.SSS0.Px6.p1.7.2" class="ltx_sub"><span id="S4.SS4.SSS0.Px6.p1.7.2.1" class="ltx_text ltx_font_italic">r</span></sub> gain across different batch sizes. Last but not least, the gain of our proposed ‚ÄúCPE + focal‚Äù pretraining is consistent among all settings by improving +2.2<math id="S4.SS4.SSS0.Px6.p1.5.m5.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS4.SSS0.Px6.p1.5.m5.1a"><mo id="S4.SS4.SSS0.Px6.p1.5.m5.1.1" xref="S4.SS4.SSS0.Px6.p1.5.m5.1.1.cmml">‚àº</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px6.p1.5.m5.1b"><csymbol cd="latexml" id="S4.SS4.SSS0.Px6.p1.5.m5.1.1.cmml" xref="S4.SS4.SSS0.Px6.p1.5.m5.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px6.p1.5.m5.1c">\sim</annotation></semantics></math>2.7 AP<sub id="S4.SS4.SSS0.Px6.p1.7.3" class="ltx_sub"><span id="S4.SS4.SSS0.Px6.p1.7.3.1" class="ltx_text ltx_font_italic">r</span></sub>. Putting everything together, RO-ViT achieves 32.1 AP<sub id="S4.SS4.SSS0.Px6.p1.7.4" class="ltx_sub"><span id="S4.SS4.SSS0.Px6.p1.7.4.1" class="ltx_text ltx_font_italic">r</span></sub>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2305.07011/assets/figures/pe.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Visualization of learned positional embeddings.<span id="S4.F3.4.2.1" class="ltx_text ltx_font_medium"> Tiles show the cosine similarity between the positional embedding of the patch (at the indicated row-column position) and the positional embeddings of all other patches. ViT-B/16 backbone is used.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Visualization of Positional Embeddings</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">In Fig.¬†<a href="#S4.F3" title="Figure 3 ‚Ä£ Scalability with respect to model size and batch size. ‚Ä£ 4.4 Ablation Study ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we visualize and compare the learned positional embeddings of RO-ViT with the baseline, based on ViT-B/16 backbone. Each tile is the cosine similarity between positional embeddings of one patch and all other patches. The brightness patterns show in both models, closer patches have more similar positional embeddings, indicating the encoded distance and locality within the image.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">We observe a few differences between RO-ViT positional embeddings and the baselines. First, RO-ViT forms more distinct clusters at different patch locations, <em id="S4.SS5.p2.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS5.p2.1.2" class="ltx_text"></span>, ours shows symmetrical global pattern around the center patch, while the baseline has similar patterns on opposite ends of the image (<em id="S4.SS5.p2.1.3" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS5.p2.1.4" class="ltx_text"></span>, the pattern in top-left patch is similar to the bottom-right patch).
Also, the brightness patterns of RO-ViT tend to be more concentrated and strong (<em id="S4.SS5.p2.1.5" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS5.p2.1.6" class="ltx_text"></span>, near 1 or -1). To summarize, the visualization indicates RO-ViT positional embeddings acquire more structure and symmetry than the baseline in the pretraining process.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We present RO-ViT‚Äì a contrastive image-text pretraining framework to bridge the gap between image-level pretraining and open-vocabulary detection finetuning. Our methods are simple, scalable, and easy to apply to any contrastive backbones with minimal computation overhead and no increase in parameters. Experiments show that our RO-ViT achieves the state-of-the-art on LVIS open-vocabulary detection benchmark. Moreover, RO-ViT achieves state of the art on 9 out of 12 metrics of image-text retrieval benchmark, showing that the learnt representation is not only beneficial at region-level but also highly effective on image-level. We hope this study can help the research on open-vocabulary detection from the perspective of image-text pretraining which can benefit both region-level and image-level tasks.</p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds,
Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina
Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew
Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo
Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Flamingo: a visual language model for few-shot learning, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Luƒçiƒá,
and Cordelia Schmid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Vivit: A video vision transformer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 6836‚Äì6846, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Yutong Bai, Xinlei Chen, Alexander Kirillov, Alan Yuille, and Alexander¬†C.
Berg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Point-level region contrast for object detection pre-training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 16061‚Äì16070, June 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Ankan Bansal, Karan Sikka, Gaurav Sharma, Rama Chellappa, and Ajay Divakaran.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Zero-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Hangbo Bao, Li Dong, and Furu Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Beit: Bert pre-training of image transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.08254</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv√© J√©gou, Julien Mairal,
Piotr Bojanowski, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Emerging properties in self-supervised vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 9650‚Äì9660, October 2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
Dollar, and C.¬†Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco captions: Data collection and evaluation server.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">https://arxiv.org/abs/1504.00325</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Xinlei Chen and Abhinav Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Webly supervised learning of convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Berkan Demirel, Ramazan¬†Gokberk Cinbis, and Nazli Ikizler-Cinbis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Zero-shot object detection by hybrid region embedding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">BMVC</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Karan Desai and Justin Johnson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Virtex: Learning visual representations from textual annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Santosh¬†K Divvala, Ali Farhadi, and Carlos Guestrin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Learning everything about anything: Webly-supervised visual concept
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et¬†al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at
scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.11929</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Yu Du, Fangyun Wei, Zihe Zhang, Miaojing Shi, Yue Gao, and Guoqi Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Learning to prompt for open-vocabulary object detection with
vision-language model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Chengjian Feng, Yujie Zhong, Zequn Jie, Xiangxiang Chu, Haibing Ren, Xiaolin
Wei, Weidi Xie, and Lin Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Promptdet: Towards open-vocabulary detection using uncurated images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 701‚Äì717.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Andrea Frome, Greg¬†S Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Marc‚ÄôAurelio
Ranzato, and Tomas Mikolov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Devise: A deep visual-semantic embedding model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung-Yi Lin, Ekin¬†D Cubuk,
Quoc¬†V Le, and Barret Zoph.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Simple copy-paste is a strong data augmentation method for instance
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Golnaz Ghiasi, Xiuye Gu, Yin Cui, and Tsung-Yi Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Scaling open-vocabulary image segmentation with image-level labels.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 540‚Äì557.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Priya Goyal, Piotr Doll√°r, Ross Girshick, Pieter Noordhuis, Lukasz
Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Accurate, large minibatch sgd: Training imagenet in 1 hour.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1706.02677</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Kristen Grauman, Andrew Westbury, Eugene Byrne, Zachary Chavis, Antonino
Furnari, Rohit Girdhar, Jackson Hamburger, Hao Jiang, Miao Liu, Xingyu Liu,
et¬†al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Ego4d: Around the world in 3,000 hours of egocentric video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 18995‚Äì19012, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, and Yin Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary object detection via vision and language knowledge
distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Agrim Gupta, Piotr Dollar, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Lvis: A dataset for large vocabulary instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Nasir Hayat, Munawar Hayat, Shafin Rahman, Salman Khan, Syed¬†Waqas Zamir, and
Fahad¬†Shahbaz Khan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Synthesizing the unseen for zero-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ACCV</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, and Ross
Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Masked autoencoders are scalable vision learners.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 16000‚Äì16009, June 2022.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Xiangteng He and Yuxin Peng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Fine-grained image classification via combining vision and language.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Olivier¬†J. H√©naff, Skanda Koppula, Jean-Baptiste Alayrac, Aaron van¬†den Oord,
Oriol Vinyals, and Jo√£o Carreira.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Efficient visual pretraining with contrastive detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 10086‚Äì10096, October 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Dat Huynh, Jason Kuen, Zhe Lin, Jiuxiang Gu, and Ehsan Elhamifar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary instance segmentation via robust cross-modal
pseudo-labeling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 7020‚Äì7031, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc¬†V
Le, Yunhsuan Sung, Zhen Li, and Tom Duerig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Scaling up visual and vision-language representation learning with
noisy text supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Armand Joulin, Laurens van¬†der Maaten, Allan Jabri, and Nicolas Vasilache.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Learning visual features from large weakly supervised data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Dahun Kim, Tsung-Yi Lin, Anelia Angelova, In¬†So Kweon, and Weicheng Kuo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Learning open-world object proposals without learning to classify.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 7(2):5453‚Äì5460, 2022.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Weicheng Kuo, Yin Cui, Xiuye Gu, AJ Piergiovanni, and Anelia Angelova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">F-vlm: Open-vocabulary object detection upon frozen vision and
language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2209.15639</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Boyi Li, Kilian¬†Q Weinberger, Serge Belongie, Vladlen Koltun, and Ren√©
Ranftl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Language-driven semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.03546</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Liunian¬†Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li,
Yiwu Zhong, Lijuan Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, Kai-Wei Chang,
and Jianfeng Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Grounded language-image pre-training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Exploring plain vision transformer backbones for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll√°r.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Focal loss for dense object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 2980‚Äì2988, 2017.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Muhammad Maaz, Hanoona Rasheed, Salman Khan, Fahad¬†Shahbaz Khan, Rao¬†Muhammad
Anwer, and Ming-Hsuan Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Class-agnostic object detection with multi-modal transformer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision‚ÄìECCV 2022: 17th European Conference, Tel
Aviv, Israel, October 23‚Äì27, 2022, Proceedings, Part X</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 512‚Äì531.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk
Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa
Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil
Houlsby.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Simple open-vocabulary object detection with vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens,
Andrea Frome, Greg¬†S Corrado, and Jeffrey Dean.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Zero-shot learning by convex combination of semantic embeddings.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">2014.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Hieu Pham, Zihang Dai, Golnaz Ghiasi, Hanxiao Liu, Adams¬†Wei Yu, Minh-Thang
Luong, Mingxing Tan, and Quoc¬†V. Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Combined scaling for zero-shot transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, abs/2111.10050, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Bryan¬†A Plummer, Liwei Wang, Chris¬†M Cervantes, Juan¬†C Caicedo, Julia
Hockenmaier, and Svetlana Lazebnik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Flickr30k entities: Collecting region-to-phrase correspondences for
richer image-to-sentence models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 2641‚Äì2649, 2015.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jong¬†Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
Gretchen Krueger, and Ilya Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Learning transferable visual models from natural language
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Shafin Rahman, Salman Khan, and Nick Barnes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Improved visual-semantic alignment for zero-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Hanoona Rasheed, Muhammad Maaz, Muhammad¬†Uzair Khattak, Salman Khan, and
Fahad¬†Shahbaz Khan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Bridging the gap between object and image-level representations for
open-vocabulary detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2207.03482</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Mert¬†Bulent Sariyildiz, Julien Perez, and Diane Larlus.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Learning visual representations with caption annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk,
Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran
Komatsuzaki.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Laion-400m: Open dataset of clip-filtered 400 million image-text
pairs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.02114</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Shuai Shao, Zeming Li, Tianyuan Zhang, Chao Peng, Gang Yu, Xiangyu Zhang, Jing
Li, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Objects365: A large-scale, high-quality dataset for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech
Galuba, Marcus Rohrbach, and Douwe Kiela.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Flava: A foundational language and vision alignment model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, pages 15638‚Äì15650, 2022.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Josiah Wang, Katja Markert, Mark Everingham, et¬†al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Learning models for object recognition from natural language
descriptions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">BMVC</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, 2009.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong,
Kai Chen, Ziwei Liu, Chen¬†Change Loy, and Dahua Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Seesaw loss for long-tailed instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib48.5.3" class="ltx_text" style="font-size:90%;">, pages 9695‚Äì9704, 2021.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Zirui Wang, Jiahui Yu, Adams¬†Wei Yu, Zihang Dai, Yulia Tsvetkov, and Yuan Cao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Simvlm: Simple visual language model pretraining with weak
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2108.10904</span><span id="bib.bib49.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Fangyun Wei, Yue Gao, Zhirong Wu, Han Hu, and Stephen Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Aligning pretraining for detection via object-level contrastive
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Tete Xiao, Colorado¬†J Reed, Xiaolong Wang, Kurt Keutzer, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Region similarity representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, pages 10539‚Äì10548, October 2021.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Lewei Yao, Runhui Huang, Lu Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiaodan
Liang, Zhenguo Li, Xin Jiang, and Chunjing Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Filip: Fine-grained interactive language-image pre-training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
Yonghui Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Coca: Contrastive captioners are image-text foundation models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">TMLR</span><span id="bib.bib53.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao,
Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, Ce Liu, Mengchen Liu,
Zicheng Liu, Yumao Lu, Yu Shi, Lijuan Wang, Jianfeng Wang, Bin Xiao, Zhen
Xiao, Jianwei Yang, Michael Zeng, Luowei Zhou, and Pengchuan Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Florence: A new foundation model for computer vision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.11432</span><span id="bib.bib54.4.2" class="ltx_text" style="font-size:90%;">, November 2021.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Yuhang Zang, Wei Li, Kaiyang Zhou, Chen Huang, and Chen¬†Change Loy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary detr with conditional matching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.11876</span><span id="bib.bib55.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Alireza Zareian, Kevin¬†Dela Rosa, Derek¬†Hao Hu, and Shih-Fu Chang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary object detection using captions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Xiaohua Zhai, Xiao Wang, Basil Mustafa, Andreas Steiner, Daniel Keysers,
Alexander Kolesnikov, and Lucas Beyer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Lit: Zero-shot transfer with locked-image text tuning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib57.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib57.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Bowen Zhang, Zhi Tian, Quan Tang, Xiangxiang Chu, Xiaolin Wei, Chunhua Shen,
and Yifan Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Segvit: Semantic segmentation with plain vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2210.05844</span><span id="bib.bib58.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
Shiyu Zhao, Zhixing Zhang, Samuel Schulter, Long Zhao, Anastasis Stathopoulos,
Manmohan Chandraker, Dimitris Metaxas, et¬†al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">Exploiting unlabeled data with vision and language models for object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib59.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib59.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Ye Zheng, Ruoran Huang, Chuanqi Han, Xi Huang, and Li Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">Background learnable cascade for zero-shot object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ACCV</span><span id="bib.bib60.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
Yiwu Zhong, Jing Shi, Jianwei Yang, Chenliang Xu, and Yin Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">Learning to generate scene graph from natural language supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib61.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib61.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Yiwu Zhong, Jianwei Yang, Pengchuan Zhang, Chunyuan Li, Noel Codella,
Liunian¬†Harold Li, Luowei Zhou, Xiyang Dai, Lu Yuan, Yin Li, and Jianfeng
Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">Regionclip: Region-based language-image pretraining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib62.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib62.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
Chong Zhou, Chen¬†Change Loy, and Bo Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.2.1" class="ltx_text" style="font-size:90%;">Extract free dense labels from clip.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib63.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
Kaiyang Zhou, Jingkang Yang, Chen¬†Change Loy, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.2.1" class="ltx_text" style="font-size:90%;">Conditional prompt learning for vision-language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib64.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib64.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
Xingyi Zhou, Rohit Girdhar, Armand Joulin, Philipp Kr√§henb√ºhl, and
Ishan Misra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text" style="font-size:90%;">Detecting twenty-thousand classes using image-level supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib65.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib65.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
Pengkai Zhu, Hanxiao Wang, and Venkatesh Saligrama.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text" style="font-size:90%;">Don‚Äôt even look once: Synthesizing features for zero-shot detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib66.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib66.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

<div id="Ax1.p1" class="ltx_para">
<p id="Ax1.p1.1" class="ltx_p">In the supplementary materials, we provide our detection visualizations along with our application on ego-centric data. We also provide more implementation details with used hyper-parameters and discuss the current limitations in the proposed RO-ViT in the hope to inspire more future research.</p>
</div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Table¬†<a href="#A3.T7" title="Table 7 ‚Ä£ Appendix C Application on Ego-centric Data ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> summarizes the hyper-parameters used in the image-text pretraining and open-vocabulary detection finetuning.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Detection Visualization</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We visualize our RO-ViT outputs on LVIS novel categories (Sec.¬†<a href="#S4.SS1" title="4.1 Open-vocabulary Object Detection ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>) and transfer detection (Sec.¬†<a href="#S4.SS3" title="4.3 Transfer Object Detection ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>) onto Objects365 in Fig.¬†<a href="#A2.F5" title="Figure 5 ‚Ä£ Appendix B Detection Visualization ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#A2.F5" title="Figure 5 ‚Ä£ Appendix B Detection Visualization ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, respectively.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">We use the ViT-B/16 backbone for visualization. The model was trained on the LVIS base categories following Sec.¬†<a href="#S4.SS1" title="4.1 Open-vocabulary Object Detection ‚Ä£ 4 Experimental Results ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> of the paper. On LVIS, we only show the novel categories for clarity. RO-ViT is able to detect many novel objects (<em id="A2.p2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.p2.1.2" class="ltx_text"></span>, <span id="A2.p2.1.3" class="ltx_text ltx_font_italic">fishbowl, sombrero, shepherd dog, gargoyle, persimmon, chinaware, gourd, satchel</span>, and <span id="A2.p2.1.4" class="ltx_text ltx_font_italic">washbasin</span>). We also visualize the transfer detection on Objects365 by replacing the vocabulary without finetuning. RO-ViT can detect a wide range of objects in complex scenes (<em id="A2.p2.1.5" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.p2.1.6" class="ltx_text"></span>, <span id="A2.p2.1.7" class="ltx_text ltx_font_italic">power outlet, binocular, glasses, traffic sign</span>, and <span id="A2.p2.1.8" class="ltx_text ltx_font_italic">shrimp</span>).</p>
</div>
<figure id="A2.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2305.07011/assets/figures/lvis_9.png" id="A2.F5.g1" class="ltx_graphics ltx_figure_panel ltx_img_square" width="419" height="419" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A2.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="A2.F5.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">LVIS novel category visualization (prediction).<span id="A2.F5.4.2.1" class="ltx_text ltx_font_medium"> We only show the novel categories for clarity. RO-ViT detects many novel categories (pointed by the red arrows) that it has never seen during detection training (<em id="A2.F5.4.2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.F5.4.2.1.2" class="ltx_text"></span>, <span id="A2.F5.4.2.1.3" class="ltx_text ltx_font_italic">fishbowl, sombrero, shepherd dog, gargoyle, persimmon, chinaware, gourd, satchel</span>, and <span id="A2.F5.4.2.1.4" class="ltx_text ltx_font_italic">washbasin</span>). </span></span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2305.07011/assets/figures/obj365_6.png" id="A2.F5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="419" height="279" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F5.6.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="A2.F5.7.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Objects365 transfer detection visualization (prediction).<span id="A2.F5.7.2.1" class="ltx_text ltx_font_medium"> Our trained RO-ViT is able to perform on a new dataset without any finetuning, and captures many challenging categories including novel categories (pointed by red arrows, <em id="A2.F5.7.2.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A2.F5.7.2.1.2" class="ltx_text"></span>, <span id="A2.F5.7.2.1.3" class="ltx_text ltx_font_italic">power outlet</span> and <span id="A2.F5.7.2.1.4" class="ltx_text ltx_font_italic">shrimp</span>).</span></span></figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Application on Ego-centric Data</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">A main advantage of open-vocabulary detection is to deal with out-of-distribution data with categories given by the users on the fly. We test RO-ViT‚Äôs transfer detection to a real-world ego-centric data, Ego4D¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. We use the same RO-ViT trained on LVIS base categories with ViiT-B/16 backbone, as in Sec.¬†<a href="#A2" title="Appendix B Detection Visualization ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>, <em id="A3.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="A3.p1.1.2" class="ltx_text"></span>, the model has been never trained on Ego4D.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">The categories are provided by the user‚Äôs visual inspection of the video, and are as follows.</p>
</div>
<div id="A3.p3" class="ltx_para">
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p">For the indoor scene: <span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">plate, cabinet, stove, towel, cleaning rag, ventilator, knob, sauce and seasoning, steel lid, window, window blinds, plant, light switch, light, door, carpet, exit sign, doormat, hair, door lock, tree, poster on the wall, sticker on the wall, faucet, recycle bin, rack, hand, can, carton, trash, Christmas tree, plastic container, fridge</span>.</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p">For the grocery store scene: <span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">exit sign, poster, chocolate bar, bag of candy, bag of cookies, snack, oreo, soy sauce, apple, pear, orange, grapes, price tag, cereal, instant noodle/ramen, cracker, ATM machine, instant noodle, wooden basket, red ramen bowls, magazine, drugs and medicine, Mayo, Ketchup, Cup noodle, burrito, Lays/Sun chips, seasoning sauce, black carton, salad dressing, canned food</span>.</p>
</div>
</li>
</ul>
</div>
<div id="A3.p4" class="ltx_para">
<p id="A3.p4.1" class="ltx_p">Fig.¬†<a href="#A3.F6" title="Figure 6 ‚Ä£ Appendix C Application on Ego-centric Data ‚Ä£ Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows our RO-ViT prediction. Despite the large domain shift and heavy camera motions, RO-ViT is able to capture many objects in the ego-centric videos. Specifically, it is able to detect many novel categories never seen during training (<em id="A3.p4.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A3.p4.1.2" class="ltx_text"></span>, <span id="A3.p4.1.3" class="ltx_text ltx_font_italic">light switch, exit sign, recycle bin, seasoning sauce, salad dressing, bag of cookies, canned food, and red ramen bowls</span>).</p>
</div>
<figure id="A3.T7" class="ltx_table">
<table id="A3.T7.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T7.3.4.1" class="ltx_tr">
<th id="A3.T7.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;" rowspan="2"><span id="A3.T7.3.4.1.1.1" class="ltx_text" style="font-size:80%;">configuration</span></th>
<td id="A3.T7.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.4.1.2.1" class="ltx_text" style="font-size:80%;">contrastive</span></td>
<td id="A3.T7.3.4.1.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.4.1.3.1" class="ltx_text" style="font-size:80%;">open-vocab. detection</span></td>
</tr>
<tr id="A3.T7.3.5.2" class="ltx_tr">
<td id="A3.T7.3.5.2.1" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.5.2.1.1" class="ltx_text" style="font-size:80%;">image-text pretraining</span></td>
<td id="A3.T7.3.5.2.2" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.5.2.2.1" class="ltx_text" style="font-size:80%;">finetuning (LVIS)</span></td>
</tr>
<tr id="A3.T7.3.6.3" class="ltx_tr">
<th id="A3.T7.3.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.6.3.1.1" class="ltx_text" style="font-size:80%;">optimizer</span></th>
<td id="A3.T7.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.6.3.2.1" class="ltx_text" style="font-size:80%;">AdamW</span></td>
<td id="A3.T7.3.6.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.6.3.3.1" class="ltx_text" style="font-size:80%;">SGD</span></td>
</tr>
<tr id="A3.T7.2.2" class="ltx_tr">
<th id="A3.T7.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.2.2.3.1" class="ltx_text" style="font-size:80%;">momentum</span></th>
<td id="A3.T7.1.1.1" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;">
<math id="A3.T7.1.1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A3.T7.1.1.1.m1.1a"><mi mathsize="80%" id="A3.T7.1.1.1.m1.1.1" xref="A3.T7.1.1.1.m1.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="A3.T7.1.1.1.m1.1b"><ci id="A3.T7.1.1.1.m1.1.1.cmml" xref="A3.T7.1.1.1.m1.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.1.1.1.m1.1c">\beta</annotation></semantics></math><span id="A3.T7.1.1.1.1" class="ltx_text" style="font-size:80%;">=0.9</span>
</td>
<td id="A3.T7.2.2.2" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;">
<math id="A3.T7.2.2.2.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A3.T7.2.2.2.m1.1a"><mi mathsize="80%" id="A3.T7.2.2.2.m1.1.1" xref="A3.T7.2.2.2.m1.1.1.cmml">Œ≤</mi><annotation-xml encoding="MathML-Content" id="A3.T7.2.2.2.m1.1b"><ci id="A3.T7.2.2.2.m1.1.1.cmml" xref="A3.T7.2.2.2.m1.1.1">ùõΩ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.2.2.2.m1.1c">\beta</annotation></semantics></math><span id="A3.T7.2.2.2.1" class="ltx_text" style="font-size:80%;">=0.9</span>
</td>
</tr>
<tr id="A3.T7.3.7.4" class="ltx_tr">
<th id="A3.T7.3.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.7.4.1.1" class="ltx_text" style="font-size:80%;">weight decay</span></th>
<td id="A3.T7.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.7.4.2.1" class="ltx_text" style="font-size:80%;">1e-2</span></td>
<td id="A3.T7.3.7.4.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.7.4.3.1" class="ltx_text" style="font-size:80%;">1e-4</span></td>
</tr>
<tr id="A3.T7.3.8.5" class="ltx_tr">
<th id="A3.T7.3.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.8.5.1.1" class="ltx_text" style="font-size:80%;">learning rate</span></th>
<td id="A3.T7.3.8.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.8.5.2.1" class="ltx_text" style="font-size:80%;">5e-4 (linear decay)</span></td>
<td id="A3.T7.3.8.5.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.8.5.3.1" class="ltx_text" style="font-size:80%;">0.36 (B) / 0.18 (L)</span></td>
</tr>
<tr id="A3.T7.3.3" class="ltx_tr">
<th id="A3.T7.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.3.2.1" class="ltx_text" style="font-size:80%;">step decay factor</span></th>
<td id="A3.T7.3.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.3.3.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="A3.T7.3.3.1" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;">
<span id="A3.T7.3.3.1.1" class="ltx_text" style="font-size:80%;">0.1</span><math id="A3.T7.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="A3.T7.3.3.1.m1.1a"><mo mathsize="80%" id="A3.T7.3.3.1.m1.1.1" xref="A3.T7.3.3.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="A3.T7.3.3.1.m1.1b"><times id="A3.T7.3.3.1.m1.1.1.cmml" xref="A3.T7.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="A3.T7.3.3.1.m1.1c">\times</annotation></semantics></math>
</td>
</tr>
<tr id="A3.T7.3.9.6" class="ltx_tr">
<th id="A3.T7.3.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.9.6.1.1" class="ltx_text" style="font-size:80%;">step decay schedule</span></th>
<td id="A3.T7.3.9.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.9.6.2.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="A3.T7.3.9.6.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.9.6.3.1" class="ltx_text" style="font-size:80%;">[0.8, 0.9, 0.95]</span></td>
</tr>
<tr id="A3.T7.3.10.7" class="ltx_tr">
<th id="A3.T7.3.10.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.10.7.1.1" class="ltx_text" style="font-size:80%;">backbone lr ratio</span></th>
<td id="A3.T7.3.10.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.10.7.2.1" class="ltx_text" style="font-size:80%;">N/A</span></td>
<td id="A3.T7.3.10.7.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.10.7.3.1" class="ltx_text" style="font-size:80%;">0.1 (B) / 0.5 (L)</span></td>
</tr>
<tr id="A3.T7.3.11.8" class="ltx_tr">
<th id="A3.T7.3.11.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.11.8.1.1" class="ltx_text" style="font-size:80%;">warmup steps</span></th>
<td id="A3.T7.3.11.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.11.8.2.1" class="ltx_text" style="font-size:80%;">1e4</span></td>
<td id="A3.T7.3.11.8.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.11.8.3.1" class="ltx_text" style="font-size:80%;">1k</span></td>
</tr>
<tr id="A3.T7.3.12.9" class="ltx_tr">
<th id="A3.T7.3.12.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.12.9.1.1" class="ltx_text" style="font-size:80%;">total steps</span></th>
<td id="A3.T7.3.12.9.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.12.9.2.1" class="ltx_text" style="font-size:80%;">5e5</span></td>
<td id="A3.T7.3.12.9.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.12.9.3.1" class="ltx_text" style="font-size:80%;">46.1k (B) / 36.8k (L)</span></td>
</tr>
<tr id="A3.T7.3.13.10" class="ltx_tr">
<th id="A3.T7.3.13.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.13.10.1.1" class="ltx_text" style="font-size:80%;">batch size</span></th>
<td id="A3.T7.3.13.10.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.13.10.2.1" class="ltx_text" style="font-size:80%;">4096 or 16384</span></td>
<td id="A3.T7.3.13.10.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.13.10.3.1" class="ltx_text" style="font-size:80%;">256 (B) / 128 (L)</span></td>
</tr>
<tr id="A3.T7.3.14.11" class="ltx_tr">
<th id="A3.T7.3.14.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.14.11.1.1" class="ltx_text" style="font-size:80%;">image size</span></th>
<td id="A3.T7.3.14.11.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.14.11.2.1" class="ltx_text" style="font-size:80%;">224</span></td>
<td id="A3.T7.3.14.11.3" class="ltx_td ltx_align_center" style="padding:0.4pt 2.0pt;"><span id="A3.T7.3.14.11.3.1" class="ltx_text" style="font-size:80%;">1024</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="A3.T7.8.1.1" class="ltx_text" style="font-size:113%;">Table 7</span>: </span><span id="A3.T7.9.2" class="ltx_text ltx_font_bold" style="font-size:113%;">RO-ViT hyper-parameters<span id="A3.T7.9.2.1" class="ltx_text ltx_font_medium"> for image-text pretraining and open-vocabulary detection finetuning. B and L denote ViT-B/16 and ViT-L/16 backbones respectively.</span></span></figcaption>
</figure>
<figure id="A3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2305.07011/assets/figures/indoor.png" id="A3.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="598" height="274" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A3.F6.1" class="ltx_p ltx_figure_panel ltx_align_center">(a) <span id="A3.F6.1.1" class="ltx_text ltx_font_bold">Indoor scene. 
<br class="ltx_break"><img src="/html/2305.07011/assets/figures/grocery.png" id="A3.F6.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="274" alt="Refer to caption"> 
<br class="ltx_break">(b) Grocery store scene. 
<br class="ltx_break"></span></p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering ltx_font_bold"><span class="ltx_tag ltx_tag_figure"><span id="A3.F6.5.1.1" class="ltx_text ltx_font_medium" style="font-size:90%;">Figure 6</span>: </span><span id="A3.F6.6.2" class="ltx_text" style="font-size:90%;">Ego4D transfer detection visualization (prediction). Ego4D¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> is a real-world and out-of-distribution data. Despite large domain shift and heavy camera movement, RO-ViT is able to detect novel, unseen objects (<em id="A3.F6.6.2.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="A3.F6.6.2.2" class="ltx_text"></span>, <span id="A3.F6.6.2.3" class="ltx_text ltx_font_medium ltx_font_italic">light switch, exit sign, recycle bin, seasoning sauce, salad dressing, bag of cookies, canned food, and red ramen bowls</span>).</span></figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Limitations</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">RO-ViT leverages the knowledge in pretrained Vision Language Models (VLM). Therefore, the biases of trained VLMs can proparate into the downstream detector. In this paper, we use RO-ViT to demonstrate its capabilities and compare with existing works in open-vocabulary detection. We recommend careful analysis of ethical risks before using it for other purposes.</p>
</div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Dataset License</h2>

<div id="A5.p1" class="ltx_para">
<ul id="A5.I1" class="ltx_itemize">
<li id="A5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A5.I1.i1.p1" class="ltx_para">
<p id="A5.I1.i1.p1.1" class="ltx_p">LVIS¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>: CC BY 4.0 + COCO license</p>
</div>
</li>
<li id="A5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A5.I1.i2.p1" class="ltx_para">
<p id="A5.I1.i2.p1.1" class="ltx_p">COCO Captions (retrieval)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>: CC BY</p>
</div>
</li>
<li id="A5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A5.I1.i3.p1" class="ltx_para">
<p id="A5.I1.i3.p1.1" class="ltx_p">Flickr30k (retrieval)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>: Custom (research-only, non-commercial)</p>
</div>
</li>
<li id="A5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A5.I1.i4.p1" class="ltx_para">
<p id="A5.I1.i4.p1.1" class="ltx_p">Objects365¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>: Custom (research-only, non-commercial)</p>
</div>
</li>
<li id="A5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span> 
<div id="A5.I1.i5.p1" class="ltx_para">
<p id="A5.I1.i5.p1.1" class="ltx_p">Ego4D¬†<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>: <a target="_blank" href="https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ego4d-data.org/pdfs/Ego4D-Licenses-Draft.pdf</a></p>
</div>
</li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.07010" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.07011" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.07011">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.07011" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.07012" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 07:03:17 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
