<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2003.14179] A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video</title><meta property="og:description" content="Spatio-temporal information is key to resolve occlusion and depth ambiguity in 3D pose estimation. Previous methods have focused on either temporal contexts or local-to-global architectures that embed fixed-length spat…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2003.14179">

<!--Generated on Sat Mar  2 12:10:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
2D-to-3D human pose,  video pose estimation,  graph attention,  spatio-temporal networks
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\useunder</span>
<p id="p1.2" class="ltx_p"><span id="p1.2.1" class="ltx_text ltx_ulem_uline"></span><span id="p1.2.2" class="ltx_ERROR undefined">\ul</span>





</p>
</div>
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Junfa Liu<sup id="id10.10.id1" class="ltx_sup"><span id="id10.10.id1.1" class="ltx_text ltx_font_italic">1†</span></sup>, Juan Rojas<sup id="id11.11.id2" class="ltx_sup"><span id="id11.11.id2.1" class="ltx_text ltx_font_italic">2†∗</span></sup>, Zhijun Liang<sup id="id12.12.id3" class="ltx_sup"><span id="id12.12.id3.1" class="ltx_text ltx_font_italic">1</span></sup>, Yihui Li<sup id="id13.13.id4" class="ltx_sup"><span id="id13.13.id4.1" class="ltx_text ltx_font_italic">1</span></sup>, and Yisheng Guan<sup id="id14.14.id5" class="ltx_sup"><span id="id14.14.id5.1" class="ltx_text ltx_font_italic">1∗</span></sup>
</span><span class="ltx_author_notes"><sup id="id15.15.id1" class="ltx_sup"><span id="id15.15.id1.1" class="ltx_text ltx_font_italic">1</span></sup>The Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, 510006 Guangzhou, China. <sup id="id16.16.id2" class="ltx_sup"><span id="id16.16.id2.1" class="ltx_text ltx_font_italic">2</span></sup>Dept. of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China. <math id="id8.8.m3.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="id8.8.m3.1a"><mo id="id8.8.m3.1.1" xref="id8.8.m3.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id8.8.m3.1b"><ci id="id8.8.m3.1.1.cmml" xref="id8.8.m3.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id8.8.m3.1c">{\dagger}</annotation></semantics></math> Equal contribution. <math id="id9.9.m4.1" class="ltx_Math" alttext="\ast" display="inline"><semantics id="id9.9.m4.1a"><mo id="id9.9.m4.1.1" xref="id9.9.m4.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="id9.9.m4.1b"><ci id="id9.9.m4.1.1.cmml" xref="id9.9.m4.1.1">∗</ci></annotation-xml><annotation encoding="application/x-tex" id="id9.9.m4.1c">\ast</annotation></semantics></math> Corresponding authors (<a href="ysguan@gdut.edu.cn" title="" class="ltx_ref ltx_url ltx_font_typewriter">ysguan@gdut.edu.cn</a> and <a href="juan.rojas@cuhk.edu.cn" title="" class="ltx_ref ltx_url ltx_font_typewriter">juan.rojas@cuhk.edu.cn</a>). The work in this paper is in part supported by the Frontier and Key Technology Innovation Special Funds of Guangdong Province (Grant No. 2017B050506008) and the Key R&amp;D Program of Guangdong Province (Grant No. 2019B090915001).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id17.id1" class="ltx_p">Spatio-temporal information is key to resolve occlusion and depth ambiguity in 3D pose estimation. Previous methods have focused on either temporal contexts or local-to-global architectures that embed fixed-length spatio-temporal information. To date, there have not been effective proposals to simultaneously and flexibly capture varying spatio-temporal sequences and effectively achieves real-time 3D pose estimation.
In this work, we improve the learning of kinematic constraints in the human skeleton: posture, local kinematic connections, and symmetry by modeling local and global spatial information via attention mechanisms. To adapt to single- and multi-frame estimation, the dilated temporal model is employed to process varying skeleton sequences. Also, importantly, we carefully design the interleaving of spatial semantics with temporal dependencies to achieve a synergistic effect.
To this end, we propose a simple yet effective graph attention spatio-temporal convolutional network (GAST-Net) that comprises of interleaved temporal convolutional and graph attention blocks.
Experiments on two challenging benchmark datasets (Human3.6M and HumanEva-I) and YouTube videos demonstrate that our approach effectively mitigates depth ambiguity and self-occlusion, generalizes to half upper body estimation, and achieves competitive performance on 2D-to-3D video pose estimation. Code, video, and supplementary information is available at: <a target="_blank" href="http://www.juanrojas.net/gast/" title="" class="ltx_ref ltx_href">http://www.juanrojas.net/gast/</a></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
2D-to-3D human pose, video pose estimation, graph attention, spatio-temporal networks

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">INTRODUCTION</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">3D human pose estimation from video is a very active research area that impacts domains like action recognition, virtual reality, and human-robot interaction. Previously, 3D pose estimation was computed using depth sensors, motion capture, or multi-view images in indoor environments. However, with recent advances in 2D human pose estimation through deep learning along with massive availability of in-the-wild data, there has been great progress in solving 3D pose estimation from monocular images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> only use 2D human pose representations and achieve competitive performance and generalization, which avoid the influence of background noise and human external appearance. Additionally, compared to processing RGB images, 2D-to-3D methods leverage 2D keypoints (which use less computation) and enable longer-term frame estimations. In this paper, we focus on 2D-to-3D estimation.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Estimating 3D poses from 2D keypoints remains an ill-posed problem due to: (i) depth ambiguity: caused by a many-to-one 3D-to-2D pose mapping as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (a); (ii) self-occlusions: caused under certain human poses as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (a-e)); and (iii) prediction errors: caused by inaccurate human pose models as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (c,d).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2003.14179/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="168" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Pose estimation reconstruction under depth ambiguities, self-occlusion, and biased 2D poses. Row 1: 2D pose estimation, where red is the prediction with errors. Row 2, 3: our reconstructions from two different perspectives.
</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To mitigate depth ambiguity, some works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> introduce weakly supervised methods to regular the rationality of the generated 3D structure. For example, Drover <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">et al. <cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.1.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S1.p3.1.1.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> utilizes an adversarial framework to impose a prior on the 3D structure via random 2D-to-3D projections. Even so, self-occlusion still remains difficult to solve as well as jittery motions in estimated video.
To address these problems, temporal modeling has used joint-coordinated vectors in sequence-to-sequence models to generate smoother motion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. However, the vector representation of joint sequences lacks expressivity for spatial relations, which is critical to mitigate depth ambiguities and self-occlusions.
To make full use of spatio-temporal information, Cai <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">et al. <cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.2.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S1.p3.1.2.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> designs a local-to-global networks to construct spatial configurations and temporal consistencies, which takes 2D keypoints sequence as a spatio-temporal graph. But, The use of graph convolutional networks to encode temporal relationships cannot effectively model long-term dependencies. This network architecture is also limit to input fixed length.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Despite considerable progress in 2D-to-3D video-based methods, none of them integrate the following significant characteristics:</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">(i) Extract more informative contextual spatio-temporal information from the hierarchical structure of 2D keypoint sequences and posture semantics to resolve depth ambiguities, mitigate self-occlusions, and smoothen motion.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">(ii) Flexible input frame length handling, noting that videos effectively exhibit varying length sequences.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">(iii) Real-time estimation of 3D poses without redundant intermediate frame calculations. Real-time estimation facilitates the downstream combination of high-semantic visual tasks; such as combining skeleton-based action recognition with human-robot interaction in real-time.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2003.14179/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="120" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Schematic overview of the GAST-Net framework. The input consists of consecutive 2D pose estimates from RGB images. The output is a sequence of reconstructed 3D poses from the corresponding 2D keypoints. GAST-Net synergistically interleaves 3 components: (a) a dilated temporal convolutional model (with 2D keypoint sequences as input (bottom) and 3D pose estimates as output (top)) with (b) a set of local attention mechanisms for visualized joints (<em id="S1.F2.2.1" class="ltx_emph ltx_font_italic">i.e.</em> the right-wrist) including local kinematic dependencies and symmetric relations, and (c) a global attention mechanism that informs about posture semantics.</figcaption>
</figure>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">These challenges inspire us to study richer spatio-temporal representations and flexibly interleave spatial and temporal information. To this end, we contribute an interleaved graph-attention spatio-temporal network that better learns three aspects of human kinematic constraints via graph attention blocks and leverages dilated convolutions to model long-term temporal contexts. The graph attention block learns skeletal joint symmetries, local kinematic relations in distal joints, and global postural joint semantics. The dilated temporal convolutional networks (TCNs) can flexibly capture varying sequences and work with causal convolutions to achieve real-time pose estimation<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> (see Fig. <a href="#S1.F2" title="Figure 2 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (a)). For single-frame scenarios, dilated convolutions can be replaced with strided convolutions to quickly inference without need to retrain a new model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. In our works, we understand spatial and temporal data to be heterogeneous. As such we treat them independently but interleave them in a synergistic manner allowing us to leverage the benefits of TCNs.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">With regards to temporal modeling, we base our design on the dilated temporal convolutions of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, but extend it to tackle three-dimensional spatio-temporal sequences.
With regards to spatial modeling, local spatial features from local connections and symmetries are modeled via graph convolution networks (GCNs) and referred to as “Local Attention Graph’s” in our system (see Fig. <a href="#S1.F2" title="Figure 2 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (b)).
For global spatial features, we draw inspiration from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and leverage graph attention networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to express posture semantics with data-driven learning. These blocks are referred to as “Global Attention Graph’s” and depicted in Fig. <a href="#S1.F2" title="Figure 2 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (c).
The graph attention block effectively express the hierarchical symmetrical structure of the human body and adaptively extracts global semantic information over time. Particularly, local- and global-spatial blocks are interleaved with temporal blocks to effectively extract and fuse spatio-temporal features of 2D keypoint sequences (see Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2003.14179/assets/x3.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>(a) An instantiation of GAST-Net for 3D pose estimation. The GAST-Net consists of 2 Temporal Convolution Blocks and 3 Graph Attention Blocks. Given a 2D pose sequence, the output is a sample 1-frame prediction. Dimensions are enclosed in parenthesis: <em id="S1.F3.2.1" class="ltx_emph ltx_font_italic">e.g.</em> (27, 17, 2) denotes a receptive field of 27 frames, 17 joints, and 2 channels. (b) The graph attention block architecture. The left dotted box indicates the local graph attention layer. The right dotted box indicates the global graph attention layer. The layer outputs is concatenated followed by a 2D convolution layer before outputting the spatio-temporal features.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Works</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">2D-to-3D Pose Estimation</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Since Martinez <em id="S2.SS1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> proposed a simple and effective linear layer to lift 2D joint locations to 3D positions, many works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> have sought to generate accurate 3D pose estimation from underlying 2D keypoints. Wandt <em id="S2.SS1.p1.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, proposed a semi-supervised approach to solve overfitting by projecting a generated 3D pose back to the 2D image and comparing it with the ground truth. Wang <em id="S2.SS1.p1.1.3" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, designed a novel stereo network with a geometric search scheme to generate a high quality 3D pose in the wild without the need of indoor 3D input. Even so, generating accurate 3D poses from a single image is an ill-posed problem. Recent works have exploited temporal information to obtain more robust and smooth 3D poses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. For instance, Hossain <span id="S2.SS1.p1.1.4" class="ltx_text ltx_font_italic">et al. <cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS1.p1.1.4.1.1" class="ltx_text ltx_font_upright">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S2.SS1.p1.1.4.2.2" class="ltx_text ltx_font_upright">]</span></cite></span> proposed a 2-layered normalized LSTM network with residual connections that first encode 2D poses into a fixed feature vector and then decode it to a 3D pose. But, encoding the two-dimensional poses into a one-dimensional vector ignores the expression of the spatial configuration of 2D poses. Other recent works incorporate spatial configuration constraints and temporal information to estimate 3D poses <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Wang <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> <span id="S2.SS1.p1.1.5" class="ltx_text ltx_font_italic">et al. </span>designed a U-shaped graph convolutional network to aggregate long-range information through temporal pooling operations. Cai <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> <span id="S2.SS1.p1.1.6" class="ltx_text ltx_font_italic">et al. </span>exploited graph pooling and graph upsampling to process and consolidate features across scales. However, their local-to-global network architectures are limit to embed fixed-length spatio-temporal sequences.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Spatio-Temporal Graph</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">GCNs generalize convolutions to graph-structured data and are roughly classified into spectral-based and spatial-based categories <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Spatial-based GCNs are more relevant to our work. Our spatial network uses both GCNs proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to obtain local and global features of each joint. Due to the outstanding performance of GCNs in non-European data, there are many recent works also modeling skeleton sequence as spatio-temporal graphs to understand human tasks including skeleton-based action recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and motion prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Our approach bears some similarity with adaptive graph convolutional blocks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> that extends the topology of the graph and combines common convolutional networks to integrate the spatio-temporal information. But our works has four distinct features: (i) instead of setting the local spatial configuration to three subsets based on gravity, our approach aims to model the symmetrical hierarchy of the human body as well as the kinematic joint constraints; (ii) our local and global adjacency matrices are applied to different graph convolutions to explicitly extract diverse spatial semantics; (iii) the dilated convolution is used to effectively model long-term temporal information; and (iv) as with the inception module, we exploit concatenation to better integrate the three-steam spatio-temporal features.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Approach</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Given a sequence of 2D pose predictions from videos, our goal is to output a sequence of 3D coordinates based on a root joint—the pelvis (See Fig. <a href="#S3.F4" title="Figure 4 ‣ III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (a)). In this section, we introduce our interleaved graph attention spatio-temporal network. The temporal component is designed from dilated TCNs to tackle long-term patterns (Sec. <a href="#S3.SS1" title="III-A Temporal Convolutional Network ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>). As for the spatial components, we have a local spatial attention network (Sec. <a href="#S3.SS2" title="III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>) to model the hierarchical and symmetrical structure of the human skeleton and a global spatial attention network (Sec. <a href="#S3.SS3" title="III-C Global Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>) to adaptively extract global semantic information to better encode the human body’s spatial characteristic.
Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (a) depicts an instantiation of the proposed framework with a receptive field size of 27 frames, whilst Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (b) depicts the graph attention block which is composed of local and global spatial blocks.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Temporal Convolutional Network</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.10" class="ltx_p">The original temporal dilated convolutional model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> consists of an input layer, an output layer and <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">B</annotation></semantics></math> temporal convolutional blocks that flexibly control the receptive field by setting the kernel size and the dilation factor of the convolution. Each block first performs a 1D convolution with kernel size <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">k</annotation></semantics></math> and dilation factor <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="d=k^{B}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">d</mi><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">=</mo><msup id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">k</mi><mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">B</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><eq id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></eq><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝑑</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">𝑘</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">𝐵</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">d=k^{B}</annotation></semantics></math>, followed by a convolution with kernel size 1. The main difference compared to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> is that we represent the input 2D pose sequence as a three-dimensional vector <math id="S3.SS1.p1.4.m4.3" class="ltx_Math" alttext="(T,N,C)" display="inline"><semantics id="S3.SS1.p1.4.m4.3a"><mrow id="S3.SS1.p1.4.m4.3.4.2" xref="S3.SS1.p1.4.m4.3.4.1.cmml"><mo stretchy="false" id="S3.SS1.p1.4.m4.3.4.2.1" xref="S3.SS1.p1.4.m4.3.4.1.cmml">(</mo><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">T</mi><mo id="S3.SS1.p1.4.m4.3.4.2.2" xref="S3.SS1.p1.4.m4.3.4.1.cmml">,</mo><mi id="S3.SS1.p1.4.m4.2.2" xref="S3.SS1.p1.4.m4.2.2.cmml">N</mi><mo id="S3.SS1.p1.4.m4.3.4.2.3" xref="S3.SS1.p1.4.m4.3.4.1.cmml">,</mo><mi id="S3.SS1.p1.4.m4.3.3" xref="S3.SS1.p1.4.m4.3.3.cmml">C</mi><mo stretchy="false" id="S3.SS1.p1.4.m4.3.4.2.4" xref="S3.SS1.p1.4.m4.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.3b"><vector id="S3.SS1.p1.4.m4.3.4.1.cmml" xref="S3.SS1.p1.4.m4.3.4.2"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑇</ci><ci id="S3.SS1.p1.4.m4.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2">𝑁</ci><ci id="S3.SS1.p1.4.m4.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3">𝐶</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.3c">(T,N,C)</annotation></semantics></math>, where <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">T</annotation></semantics></math> is the number of receptive fields, <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">N</annotation></semantics></math> is the number of joints in each frame, and <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">C</annotation></semantics></math> is the number of coordinate dimensions <math id="S3.SS1.p1.8.m8.2" class="ltx_Math" alttext="(x,y)" display="inline"><semantics id="S3.SS1.p1.8.m8.2a"><mrow id="S3.SS1.p1.8.m8.2.3.2" xref="S3.SS1.p1.8.m8.2.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.8.m8.2.3.2.1" xref="S3.SS1.p1.8.m8.2.3.1.cmml">(</mo><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">x</mi><mo id="S3.SS1.p1.8.m8.2.3.2.2" xref="S3.SS1.p1.8.m8.2.3.1.cmml">,</mo><mi id="S3.SS1.p1.8.m8.2.2" xref="S3.SS1.p1.8.m8.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS1.p1.8.m8.2.3.2.3" xref="S3.SS1.p1.8.m8.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.2b"><interval closure="open" id="S3.SS1.p1.8.m8.2.3.1.cmml" xref="S3.SS1.p1.8.m8.2.3.2"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝑥</ci><ci id="S3.SS1.p1.8.m8.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.2c">(x,y)</annotation></semantics></math>. To save the spatial information across time steps, we replace the original 1D convolution with 2D convolutions for a kernel size of <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="k\times 1" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">k</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.9.m9.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.cmml">×</mo><mn id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><times id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1"></times><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">𝑘</ci><cn type="integer" id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">k\times 1</annotation></semantics></math>. Simultaneously, each batch normalization is changed to 2D, and it is added at the beginning to normalize the input data. The dropout is only employed at the second convolution layer of blocks to improve generalization. Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows an instantiation of GAST-Net for a receptive field size of 27 frames with <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="B=2" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mrow id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml">B</mi><mo id="S3.SS1.p1.10.m10.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><eq id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1"></eq><ci id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2">𝐵</ci><cn type="integer" id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">B=2</annotation></semantics></math> blocks. Note that according to the network characteristics of TCNs, our proposed model can train under varying numbers of long-sequence receptive fields as needed.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Local Attention Graph</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.10" class="ltx_p">At any given frame in time, 2D keypoints represent the joints of the human skeleton. The skeleton is naturally represented by an undirected graph with joints as nodes and human-links as edges. We construct a skeleton graph of 2D keypoints for a given frame based on the SemGCN proposed by Zhao <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. We define the skeletal 2D poses as a graph <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="\mathcal{G}=(\mathcal{V},\mathcal{E})" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.3" xref="S3.SS2.p1.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.2.cmml">𝒢</mi><mo id="S3.SS2.p1.1.m1.2.3.1" xref="S3.SS2.p1.1.m1.2.3.1.cmml">=</mo><mrow id="S3.SS2.p1.1.m1.2.3.3.2" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p1.1.m1.2.3.3.2.1" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">𝒱</mi><mo id="S3.SS2.p1.1.m1.2.3.3.2.2" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.2.2" xref="S3.SS2.p1.1.m1.2.2.cmml">ℰ</mi><mo stretchy="false" id="S3.SS2.p1.1.m1.2.3.3.2.3" xref="S3.SS2.p1.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><apply id="S3.SS2.p1.1.m1.2.3.cmml" xref="S3.SS2.p1.1.m1.2.3"><eq id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.1"></eq><ci id="S3.SS2.p1.1.m1.2.3.2.cmml" xref="S3.SS2.p1.1.m1.2.3.2">𝒢</ci><interval closure="open" id="S3.SS2.p1.1.m1.2.3.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.3.2"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝒱</ci><ci id="S3.SS2.p1.1.m1.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2">ℰ</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">\mathcal{G}=(\mathcal{V},\mathcal{E})</annotation></semantics></math>, where <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathcal{V}</annotation></semantics></math> is the set of <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">N</annotation></semantics></math> nodes and <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{E}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathcal{E}</annotation></semantics></math> edges. <math id="S3.SS2.p1.5.m5.3" class="ltx_Math" alttext="X=\{x_{1},x_{2},\dots,x_{N}\mid x_{i}\in\mathbb{R}^{1\times C}\}" display="inline"><semantics id="S3.SS2.p1.5.m5.3a"><mrow id="S3.SS2.p1.5.m5.3.3" xref="S3.SS2.p1.5.m5.3.3.cmml"><mi id="S3.SS2.p1.5.m5.3.3.4" xref="S3.SS2.p1.5.m5.3.3.4.cmml">X</mi><mo id="S3.SS2.p1.5.m5.3.3.3" xref="S3.SS2.p1.5.m5.3.3.3.cmml">=</mo><mrow id="S3.SS2.p1.5.m5.3.3.2.2" xref="S3.SS2.p1.5.m5.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS2.p1.5.m5.3.3.2.2.3" xref="S3.SS2.p1.5.m5.3.3.2.3.1.cmml">{</mo><mrow id="S3.SS2.p1.5.m5.2.2.1.1.1.3" xref="S3.SS2.p1.5.m5.2.2.1.1.1.4.cmml"><msub id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.2" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.2.cmml">x</mi><mn id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.3" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.5.m5.2.2.1.1.1.3.4" xref="S3.SS2.p1.5.m5.2.2.1.1.1.4.cmml">,</mo><msub id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.cmml"><mi id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.2" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.2.cmml">x</mi><mn id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.3" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.5.m5.2.2.1.1.1.3.5" xref="S3.SS2.p1.5.m5.2.2.1.1.1.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">…</mi><mo id="S3.SS2.p1.5.m5.2.2.1.1.1.3.6" xref="S3.SS2.p1.5.m5.2.2.1.1.1.4.cmml">,</mo><msub id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.cmml"><mi id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.2" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.2.cmml">x</mi><mi id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.3" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.3.cmml">N</mi></msub></mrow><mo fence="true" lspace="0em" rspace="0em" id="S3.SS2.p1.5.m5.3.3.2.2.4" xref="S3.SS2.p1.5.m5.3.3.2.3.1.cmml">∣</mo><mrow id="S3.SS2.p1.5.m5.3.3.2.2.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.cmml"><msub id="S3.SS2.p1.5.m5.3.3.2.2.2.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2.cmml"><mi id="S3.SS2.p1.5.m5.3.3.2.2.2.2.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2.2.cmml">x</mi><mi id="S3.SS2.p1.5.m5.3.3.2.2.2.2.3" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS2.p1.5.m5.3.3.2.2.2.1" xref="S3.SS2.p1.5.m5.3.3.2.2.2.1.cmml">∈</mo><msup id="S3.SS2.p1.5.m5.3.3.2.2.2.3" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.cmml"><mi id="S3.SS2.p1.5.m5.3.3.2.2.2.3.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.cmml"><mn id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.2" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.1" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.1.cmml">×</mo><mi id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.3" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.3.cmml">C</mi></mrow></msup></mrow><mo stretchy="false" id="S3.SS2.p1.5.m5.3.3.2.2.5" xref="S3.SS2.p1.5.m5.3.3.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.3b"><apply id="S3.SS2.p1.5.m5.3.3.cmml" xref="S3.SS2.p1.5.m5.3.3"><eq id="S3.SS2.p1.5.m5.3.3.3.cmml" xref="S3.SS2.p1.5.m5.3.3.3"></eq><ci id="S3.SS2.p1.5.m5.3.3.4.cmml" xref="S3.SS2.p1.5.m5.3.3.4">𝑋</ci><apply id="S3.SS2.p1.5.m5.3.3.2.3.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.3.3.2.3.1.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.3">conditional-set</csymbol><list id="S3.SS2.p1.5.m5.2.2.1.1.1.4.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3"><apply id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.1.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.2.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.2">𝑥</ci><cn type="integer" id="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.2.2.3">2</cn></apply><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">…</ci><apply id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.1.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.2.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.2">𝑥</ci><ci id="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.3.cmml" xref="S3.SS2.p1.5.m5.2.2.1.1.1.3.3.3">𝑁</ci></apply></list><apply id="S3.SS2.p1.5.m5.3.3.2.2.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2"><in id="S3.SS2.p1.5.m5.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.1"></in><apply id="S3.SS2.p1.5.m5.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.3.3.2.2.2.2.1.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.5.m5.3.3.2.2.2.2.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2.2">𝑥</ci><ci id="S3.SS2.p1.5.m5.3.3.2.2.2.2.3.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.2.3">𝑖</ci></apply><apply id="S3.SS2.p1.5.m5.3.3.2.2.2.3.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.3.3.2.2.2.3.1.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3">superscript</csymbol><ci id="S3.SS2.p1.5.m5.3.3.2.2.2.3.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.2">ℝ</ci><apply id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3"><times id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.1.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.1"></times><cn type="integer" id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.2.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.2">1</cn><ci id="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.3.cmml" xref="S3.SS2.p1.5.m5.3.3.2.2.2.3.3.3">𝐶</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.3c">X=\{x_{1},x_{2},\dots,x_{N}\mid x_{i}\in\mathbb{R}^{1\times C}\}</annotation></semantics></math> is the set of node features with <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">C</annotation></semantics></math> channels. The structure of the graph can be initialized by a first-order adjacency matrix <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="A\in\mathbb{R}^{N\times N}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mrow id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">A</mi><mo id="S3.SS2.p1.7.m7.1.1.1" xref="S3.SS2.p1.7.m7.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml"><mi id="S3.SS2.p1.7.m7.1.1.3.2" xref="S3.SS2.p1.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.7.m7.1.1.3.3" xref="S3.SS2.p1.7.m7.1.1.3.3.cmml"><mi id="S3.SS2.p1.7.m7.1.1.3.3.2" xref="S3.SS2.p1.7.m7.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.7.m7.1.1.3.3.1" xref="S3.SS2.p1.7.m7.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p1.7.m7.1.1.3.3.3" xref="S3.SS2.p1.7.m7.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><in id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1.1"></in><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">𝐴</ci><apply id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.7.m7.1.1.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3"><times id="S3.SS2.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3.1"></times><ci id="S3.SS2.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3.2">𝑁</ci><ci id="S3.SS2.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">A\in\mathbb{R}^{N\times N}</annotation></semantics></math> that indicates the existing connections between joints and an identity matrix <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">I</annotation></semantics></math> indicating self-connections. <math id="S3.SS2.p1.9.m9.1" class="ltx_Math" alttext="\widetilde{A}=(A+I)" display="inline"><semantics id="S3.SS2.p1.9.m9.1a"><mrow id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml"><mover accent="true" id="S3.SS2.p1.9.m9.1.1.3" xref="S3.SS2.p1.9.m9.1.1.3.cmml"><mi id="S3.SS2.p1.9.m9.1.1.3.2" xref="S3.SS2.p1.9.m9.1.1.3.2.cmml">A</mi><mo id="S3.SS2.p1.9.m9.1.1.3.1" xref="S3.SS2.p1.9.m9.1.1.3.1.cmml">~</mo></mover><mo id="S3.SS2.p1.9.m9.1.1.2" xref="S3.SS2.p1.9.m9.1.1.2.cmml">=</mo><mrow id="S3.SS2.p1.9.m9.1.1.1.1" xref="S3.SS2.p1.9.m9.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p1.9.m9.1.1.1.1.2" xref="S3.SS2.p1.9.m9.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.9.m9.1.1.1.1.1" xref="S3.SS2.p1.9.m9.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.9.m9.1.1.1.1.1.2" xref="S3.SS2.p1.9.m9.1.1.1.1.1.2.cmml">A</mi><mo id="S3.SS2.p1.9.m9.1.1.1.1.1.1" xref="S3.SS2.p1.9.m9.1.1.1.1.1.1.cmml">+</mo><mi id="S3.SS2.p1.9.m9.1.1.1.1.1.3" xref="S3.SS2.p1.9.m9.1.1.1.1.1.3.cmml">I</mi></mrow><mo stretchy="false" id="S3.SS2.p1.9.m9.1.1.1.1.3" xref="S3.SS2.p1.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><apply id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1"><eq id="S3.SS2.p1.9.m9.1.1.2.cmml" xref="S3.SS2.p1.9.m9.1.1.2"></eq><apply id="S3.SS2.p1.9.m9.1.1.3.cmml" xref="S3.SS2.p1.9.m9.1.1.3"><ci id="S3.SS2.p1.9.m9.1.1.3.1.cmml" xref="S3.SS2.p1.9.m9.1.1.3.1">~</ci><ci id="S3.SS2.p1.9.m9.1.1.3.2.cmml" xref="S3.SS2.p1.9.m9.1.1.3.2">𝐴</ci></apply><apply id="S3.SS2.p1.9.m9.1.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1.1.1"><plus id="S3.SS2.p1.9.m9.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1.1.1.1.1"></plus><ci id="S3.SS2.p1.9.m9.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.9.m9.1.1.1.1.1.2">𝐴</ci><ci id="S3.SS2.p1.9.m9.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.9.m9.1.1.1.1.1.3">𝐼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">\widetilde{A}=(A+I)</annotation></semantics></math> expresses the convolutional kernel in GCNs. According to the definition of SemGCN, given the node features of the <math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><mi id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><ci id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">l</annotation></semantics></math>-th layer, the output features of the subsequent layer are obtained through the following convolution:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="X^{(l+1)}=\rho(M\odot\widetilde{A})X^{\left(l\right)}W," display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><msup id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.3.2" xref="S3.E1.m1.3.3.1.1.3.2.cmml">X</mi><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">l</mi><mo id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.cmml">)</mo></mrow></msup><mo id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.3.cmml">ρ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.3.3.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml">⊙</mo><mover accent="true" id="S3.E1.m1.3.3.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.cmml">A</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.1.3.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.2a" xref="S3.E1.m1.3.3.1.1.1.2.cmml">​</mo><msup id="S3.E1.m1.3.3.1.1.1.4" xref="S3.E1.m1.3.3.1.1.1.4.cmml"><mi id="S3.E1.m1.3.3.1.1.1.4.2" xref="S3.E1.m1.3.3.1.1.1.4.2.cmml">X</mi><mrow id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.3.3.1.1.1.4.cmml"><mo id="S3.E1.m1.2.2.1.3.1" xref="S3.E1.m1.3.3.1.1.1.4.cmml">(</mo><mi id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml">l</mi><mo id="S3.E1.m1.2.2.1.3.2" xref="S3.E1.m1.3.3.1.1.1.4.cmml">)</mo></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.2b" xref="S3.E1.m1.3.3.1.1.1.2.cmml">​</mo><mi id="S3.E1.m1.3.3.1.1.1.5" xref="S3.E1.m1.3.3.1.1.1.5.cmml">W</mi></mrow></mrow><mo id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"></eq><apply id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.3">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.3.2">𝑋</ci><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"></plus><ci id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2">𝑙</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">1</cn></apply></apply><apply id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"><times id="S3.E1.m1.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.3">𝜌</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1">direct-product</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.2">𝑀</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3"><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.1">~</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.3.2">𝐴</ci></apply></apply><apply id="S3.E1.m1.3.3.1.1.1.4.cmml" xref="S3.E1.m1.3.3.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.4.1.cmml" xref="S3.E1.m1.3.3.1.1.1.4">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.4.2.cmml" xref="S3.E1.m1.3.3.1.1.1.4.2">𝑋</ci><ci id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1">𝑙</ci></apply><ci id="S3.E1.m1.3.3.1.1.1.5.cmml" xref="S3.E1.m1.3.3.1.1.1.5">𝑊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">X^{(l+1)}=\rho(M\odot\widetilde{A})X^{\left(l\right)}W,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.14" class="ltx_p">where <math id="S3.SS2.p1.11.m1.1" class="ltx_Math" alttext="W\in\mathbb{R}^{C_{l}\times C_{l+1}}" display="inline"><semantics id="S3.SS2.p1.11.m1.1a"><mrow id="S3.SS2.p1.11.m1.1.1" xref="S3.SS2.p1.11.m1.1.1.cmml"><mi id="S3.SS2.p1.11.m1.1.1.2" xref="S3.SS2.p1.11.m1.1.1.2.cmml">W</mi><mo id="S3.SS2.p1.11.m1.1.1.1" xref="S3.SS2.p1.11.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.11.m1.1.1.3" xref="S3.SS2.p1.11.m1.1.1.3.cmml"><mi id="S3.SS2.p1.11.m1.1.1.3.2" xref="S3.SS2.p1.11.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.11.m1.1.1.3.3" xref="S3.SS2.p1.11.m1.1.1.3.3.cmml"><msub id="S3.SS2.p1.11.m1.1.1.3.3.2" xref="S3.SS2.p1.11.m1.1.1.3.3.2.cmml"><mi id="S3.SS2.p1.11.m1.1.1.3.3.2.2" xref="S3.SS2.p1.11.m1.1.1.3.3.2.2.cmml">C</mi><mi id="S3.SS2.p1.11.m1.1.1.3.3.2.3" xref="S3.SS2.p1.11.m1.1.1.3.3.2.3.cmml">l</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.11.m1.1.1.3.3.1" xref="S3.SS2.p1.11.m1.1.1.3.3.1.cmml">×</mo><msub id="S3.SS2.p1.11.m1.1.1.3.3.3" xref="S3.SS2.p1.11.m1.1.1.3.3.3.cmml"><mi id="S3.SS2.p1.11.m1.1.1.3.3.3.2" xref="S3.SS2.p1.11.m1.1.1.3.3.3.2.cmml">C</mi><mrow id="S3.SS2.p1.11.m1.1.1.3.3.3.3" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.cmml"><mi id="S3.SS2.p1.11.m1.1.1.3.3.3.3.2" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.2.cmml">l</mi><mo id="S3.SS2.p1.11.m1.1.1.3.3.3.3.1" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.1.cmml">+</mo><mn id="S3.SS2.p1.11.m1.1.1.3.3.3.3.3" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m1.1b"><apply id="S3.SS2.p1.11.m1.1.1.cmml" xref="S3.SS2.p1.11.m1.1.1"><in id="S3.SS2.p1.11.m1.1.1.1.cmml" xref="S3.SS2.p1.11.m1.1.1.1"></in><ci id="S3.SS2.p1.11.m1.1.1.2.cmml" xref="S3.SS2.p1.11.m1.1.1.2">𝑊</ci><apply id="S3.SS2.p1.11.m1.1.1.3.cmml" xref="S3.SS2.p1.11.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.11.m1.1.1.3.1.cmml" xref="S3.SS2.p1.11.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.11.m1.1.1.3.2.cmml" xref="S3.SS2.p1.11.m1.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.11.m1.1.1.3.3.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3"><times id="S3.SS2.p1.11.m1.1.1.3.3.1.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.1"></times><apply id="S3.SS2.p1.11.m1.1.1.3.3.2.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.11.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p1.11.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.2.2">𝐶</ci><ci id="S3.SS2.p1.11.m1.1.1.3.3.2.3.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.2.3">𝑙</ci></apply><apply id="S3.SS2.p1.11.m1.1.1.3.3.3.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.11.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.11.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3.2">𝐶</ci><apply id="S3.SS2.p1.11.m1.1.1.3.3.3.3.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3"><plus id="S3.SS2.p1.11.m1.1.1.3.3.3.3.1.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.1"></plus><ci id="S3.SS2.p1.11.m1.1.1.3.3.3.3.2.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.2">𝑙</ci><cn type="integer" id="S3.SS2.p1.11.m1.1.1.3.3.3.3.3.cmml" xref="S3.SS2.p1.11.m1.1.1.3.3.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m1.1c">W\in\mathbb{R}^{C_{l}\times C_{l+1}}</annotation></semantics></math> is a learnable matrix used to transform output channels, <math id="S3.SS2.p1.12.m2.1" class="ltx_Math" alttext="M\in\mathbb{R}^{N\times N}" display="inline"><semantics id="S3.SS2.p1.12.m2.1a"><mrow id="S3.SS2.p1.12.m2.1.1" xref="S3.SS2.p1.12.m2.1.1.cmml"><mi id="S3.SS2.p1.12.m2.1.1.2" xref="S3.SS2.p1.12.m2.1.1.2.cmml">M</mi><mo id="S3.SS2.p1.12.m2.1.1.1" xref="S3.SS2.p1.12.m2.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.12.m2.1.1.3" xref="S3.SS2.p1.12.m2.1.1.3.cmml"><mi id="S3.SS2.p1.12.m2.1.1.3.2" xref="S3.SS2.p1.12.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.12.m2.1.1.3.3" xref="S3.SS2.p1.12.m2.1.1.3.3.cmml"><mi id="S3.SS2.p1.12.m2.1.1.3.3.2" xref="S3.SS2.p1.12.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.12.m2.1.1.3.3.1" xref="S3.SS2.p1.12.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p1.12.m2.1.1.3.3.3" xref="S3.SS2.p1.12.m2.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m2.1b"><apply id="S3.SS2.p1.12.m2.1.1.cmml" xref="S3.SS2.p1.12.m2.1.1"><in id="S3.SS2.p1.12.m2.1.1.1.cmml" xref="S3.SS2.p1.12.m2.1.1.1"></in><ci id="S3.SS2.p1.12.m2.1.1.2.cmml" xref="S3.SS2.p1.12.m2.1.1.2">𝑀</ci><apply id="S3.SS2.p1.12.m2.1.1.3.cmml" xref="S3.SS2.p1.12.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.12.m2.1.1.3.1.cmml" xref="S3.SS2.p1.12.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.12.m2.1.1.3.2.cmml" xref="S3.SS2.p1.12.m2.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.12.m2.1.1.3.3.cmml" xref="S3.SS2.p1.12.m2.1.1.3.3"><times id="S3.SS2.p1.12.m2.1.1.3.3.1.cmml" xref="S3.SS2.p1.12.m2.1.1.3.3.1"></times><ci id="S3.SS2.p1.12.m2.1.1.3.3.2.cmml" xref="S3.SS2.p1.12.m2.1.1.3.3.2">𝑁</ci><ci id="S3.SS2.p1.12.m2.1.1.3.3.3.cmml" xref="S3.SS2.p1.12.m2.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m2.1c">M\in\mathbb{R}^{N\times N}</annotation></semantics></math> is a learnable mask matrix, <math id="S3.SS2.p1.13.m3.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S3.SS2.p1.13.m3.1a"><mo id="S3.SS2.p1.13.m3.1.1" xref="S3.SS2.p1.13.m3.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.13.m3.1b"><csymbol cd="latexml" id="S3.SS2.p1.13.m3.1.1.cmml" xref="S3.SS2.p1.13.m3.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.13.m3.1c">\odot</annotation></semantics></math> is an element-wise multiplication operation, and <math id="S3.SS2.p1.14.m4.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS2.p1.14.m4.1a"><mi id="S3.SS2.p1.14.m4.1.1" xref="S3.SS2.p1.14.m4.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.14.m4.1b"><ci id="S3.SS2.p1.14.m4.1.1.cmml" xref="S3.SS2.p1.14.m4.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.14.m4.1c">\rho</annotation></semantics></math> is a Softmax nonlinearity that normalizes the contribution of the features of a node to a corresponding neighboring node in a graph.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">By introducing a set of mask matrices <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="M_{c}\in\mathbb{R}^{N\times N}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><msub id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2.2" xref="S3.SS2.p2.1.m1.1.1.2.2.cmml">M</mi><mi id="S3.SS2.p2.1.m1.1.1.2.3" xref="S3.SS2.p2.1.m1.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.3.2" xref="S3.SS2.p2.1.m1.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.1.m1.1.1.3.3.1" xref="S3.SS2.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p2.1.m1.1.1.3.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><in id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></in><apply id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.2.1.cmml" xref="S3.SS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2.2">𝑀</ci><ci id="S3.SS2.p2.1.m1.1.1.2.3.cmml" xref="S3.SS2.p2.1.m1.1.1.2.3">𝑐</ci></apply><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3"><times id="S3.SS2.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.2">𝑁</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">M_{c}\in\mathbb{R}^{N\times N}</annotation></semantics></math> for the channels of the output node features, Eqtn. <a href="#S3.E1" title="In III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> can be extended to:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.3" class="ltx_math_unparsed" alttext="X^{(l+1)}=\mathop{\left|\right|}\limits_{c=1}^{C_{l+1}}\rho(M_{c}\odot\widetilde{A})X^{\left(l\right)}w_{c}," display="block"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1"><mrow id="S3.E2.m1.3.3.1.1"><msup id="S3.E2.m1.3.3.1.1.3"><mi id="S3.E2.m1.3.3.1.1.3.2">X</mi><mrow id="S3.E2.m1.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2">(</mo><mrow id="S3.E2.m1.1.1.1.1.1"><mi id="S3.E2.m1.1.1.1.1.1.2">l</mi><mo id="S3.E2.m1.1.1.1.1.1.1">+</mo><mn id="S3.E2.m1.1.1.1.1.1.3">1</mn></mrow><mo stretchy="false" id="S3.E2.m1.1.1.1.1.3">)</mo></mrow></msup><mo rspace="0em" id="S3.E2.m1.3.3.1.1.2">=</mo><mrow id="S3.E2.m1.3.3.1.1.1"><munderover id="S3.E2.m1.3.3.1.1.1.2"><mrow id="S3.E2.m1.3.3.1.1.1.2.2.2"><mo fence="false" rspace="0.167em" id="S3.E2.m1.3.3.1.1.1.2.2.2.1">|</mo><mo fence="false" rspace="0.167em" id="S3.E2.m1.3.3.1.1.1.2.2.2.2">|</mo></mrow><mrow id="S3.E2.m1.3.3.1.1.1.2.2.3"><mi id="S3.E2.m1.3.3.1.1.1.2.2.3.2">c</mi><mo id="S3.E2.m1.3.3.1.1.1.2.2.3.1">=</mo><mn id="S3.E2.m1.3.3.1.1.1.2.2.3.3">1</mn></mrow><msub id="S3.E2.m1.3.3.1.1.1.2.3"><mi id="S3.E2.m1.3.3.1.1.1.2.3.2">C</mi><mrow id="S3.E2.m1.3.3.1.1.1.2.3.3"><mi id="S3.E2.m1.3.3.1.1.1.2.3.3.2">l</mi><mo id="S3.E2.m1.3.3.1.1.1.2.3.3.1">+</mo><mn id="S3.E2.m1.3.3.1.1.1.2.3.3.3">1</mn></mrow></msub></munderover><mrow id="S3.E2.m1.3.3.1.1.1.1"><mi id="S3.E2.m1.3.3.1.1.1.1.3">ρ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.1.1.2">​</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1"><mo stretchy="false" id="S3.E2.m1.3.3.1.1.1.1.1.1.2">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1"><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.2">M</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2.3">c</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1">⊙</mo><mover accent="true" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.3"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.3.2">A</mi><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.3.1">~</mo></mover></mrow><mo stretchy="false" id="S3.E2.m1.3.3.1.1.1.1.1.1.3">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.1.1.2a">​</mo><msup id="S3.E2.m1.3.3.1.1.1.1.4"><mi id="S3.E2.m1.3.3.1.1.1.1.4.2">X</mi><mrow id="S3.E2.m1.2.2.1.3"><mo id="S3.E2.m1.2.2.1.3.1">(</mo><mi id="S3.E2.m1.2.2.1.1">l</mi><mo id="S3.E2.m1.2.2.1.3.2">)</mo></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.1.1.2b">​</mo><msub id="S3.E2.m1.3.3.1.1.1.1.5"><mi id="S3.E2.m1.3.3.1.1.1.1.5.2">w</mi><mi id="S3.E2.m1.3.3.1.1.1.1.5.3">c</mi></msub></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2">,</mo></mrow><annotation encoding="application/x-tex" id="S3.E2.m1.3b">X^{(l+1)}=\mathop{\left|\right|}\limits_{c=1}^{C_{l+1}}\rho(M_{c}\odot\widetilde{A})X^{\left(l\right)}w_{c},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.5" class="ltx_p">where <math id="S3.SS2.p2.2.m1.1" class="ltx_Math" alttext="\parallel" display="inline"><semantics id="S3.SS2.p2.2.m1.1a"><mo id="S3.SS2.p2.2.m1.1.1" xref="S3.SS2.p2.2.m1.1.1.cmml">∥</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m1.1b"><csymbol cd="latexml" id="S3.SS2.p2.2.m1.1.1.cmml" xref="S3.SS2.p2.2.m1.1.1">parallel-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m1.1c">\parallel</annotation></semantics></math> denotes a channel-wise concatenation and <math id="S3.SS2.p2.3.m2.1" class="ltx_Math" alttext="w_{c}" display="inline"><semantics id="S3.SS2.p2.3.m2.1a"><msub id="S3.SS2.p2.3.m2.1.1" xref="S3.SS2.p2.3.m2.1.1.cmml"><mi id="S3.SS2.p2.3.m2.1.1.2" xref="S3.SS2.p2.3.m2.1.1.2.cmml">w</mi><mi id="S3.SS2.p2.3.m2.1.1.3" xref="S3.SS2.p2.3.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m2.1b"><apply id="S3.SS2.p2.3.m2.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m2.1.1.1.cmml" xref="S3.SS2.p2.3.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m2.1.1.2.cmml" xref="S3.SS2.p2.3.m2.1.1.2">𝑤</ci><ci id="S3.SS2.p2.3.m2.1.1.3.cmml" xref="S3.SS2.p2.3.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m2.1c">w_{c}</annotation></semantics></math> is the <math id="S3.SS2.p2.4.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p2.4.m3.1a"><mi id="S3.SS2.p2.4.m3.1.1" xref="S3.SS2.p2.4.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m3.1b"><ci id="S3.SS2.p2.4.m3.1.1.cmml" xref="S3.SS2.p2.4.m3.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m3.1c">c</annotation></semantics></math>-th row of matrix <math id="S3.SS2.p2.5.m4.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p2.5.m4.1a"><mi id="S3.SS2.p2.5.m4.1.1" xref="S3.SS2.p2.5.m4.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m4.1b"><ci id="S3.SS2.p2.5.m4.1.1.cmml" xref="S3.SS2.p2.5.m4.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m4.1c">W</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Eqtn. <a href="#S3.E2" title="In III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> jointly learns the unique semantics across neighboring nodes. However, and very notably, this first-order neighbor representation poorly models (i) the symmetrical structure of a torso-centered human body and (ii) kinematic constraints in the human body.
Thus, we propose that structural knowledge pertaining to symmetrical functions in the human body is explicitly considered.
Furthermore, another reason why first-order neighbor representations struggle to model human spatial relations is that joint constraints are confined to first-order neighboring joints. More precisely, distal joints like the wrist, ankle, and head, located at the end of the kinematic chain, only have one first-order neighboring joint. As such, their position in space are not effectively located due to the first-order neighborhood. Such joints are the largest single source of modeling errors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Nonetheless, we exploit the relationship across sub-segments of the kinematic chain; that is, the lower limbs (ankle-knee-hip), upper limbs (wrist-elbow-shoulder), and the axial-body (head-neck-thorax) to mitigate location ambiguity.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.2" class="ltx_p">Based on the aforementioned limitations, we design two novel convolution kernels:
(i) a symmetric matrix <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\widetilde{A}_{s}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msub id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mover accent="true" id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2.2" xref="S3.SS2.p4.1.m1.1.1.2.2.cmml">A</mi><mo id="S3.SS2.p4.1.m1.1.1.2.1" xref="S3.SS2.p4.1.m1.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2"><ci id="S3.SS2.p4.1.m1.1.1.2.1.cmml" xref="S3.SS2.p4.1.m1.1.1.2.1">~</ci><ci id="S3.SS2.p4.1.m1.1.1.2.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2.2">𝐴</ci></apply><ci id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\widetilde{A}_{s}</annotation></semantics></math> (See Fig. <a href="#S3.F4" title="Figure 4 ‣ III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (b)) that encodes the human skeleton symmetrical structure for joints that have a symmetrical counterpart (<em id="S3.SS2.p4.2.1" class="ltx_emph ltx_font_italic">i.e.</em> limb joints).
(ii) an adjacency matrix <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><msub id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mover accent="true" id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2.2" xref="S3.SS2.p4.2.m2.1.1.2.2.cmml">A</mi><mo id="S3.SS2.p4.2.m2.1.1.2.1" xref="S3.SS2.p4.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2"><ci id="S3.SS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1.2.1">~</ci><ci id="S3.SS2.p4.2.m2.1.1.2.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2.2">𝐴</ci></apply><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">\widetilde{A}_{c}</annotation></semantics></math> (See Fig. <a href="#S3.F4" title="Figure 4 ‣ III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (c)) that explicitly encodes first- and second-order (kinematic) connections for distal joints (<em id="S3.SS2.p4.2.2" class="ltx_emph ltx_font_italic">i.e.</em> ankle-knee, ankle-hip). The rest of the nodes are only modeled through first-order connections.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">Note that each of these two convolution kernels are applied to two distinct GCNs; where each GCNs is followed by batch normalization and rectified linear units as shown in the right dotted box of Fig. <a href="#S1.F3" title="Figure 3 ‣ I INTRODUCTION ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (b).</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2003.14179/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="212" height="73" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>(a) A human skeleton graph with 17 joints; (b) A symmetrical matrix <math id="S3.F4.3.m1.1" class="ltx_Math" alttext="\widetilde{A}_{s}" display="inline"><semantics id="S3.F4.3.m1.1b"><msub id="S3.F4.3.m1.1.1" xref="S3.F4.3.m1.1.1.cmml"><mover accent="true" id="S3.F4.3.m1.1.1.2" xref="S3.F4.3.m1.1.1.2.cmml"><mi id="S3.F4.3.m1.1.1.2.2" xref="S3.F4.3.m1.1.1.2.2.cmml">A</mi><mo id="S3.F4.3.m1.1.1.2.1" xref="S3.F4.3.m1.1.1.2.1.cmml">~</mo></mover><mi id="S3.F4.3.m1.1.1.3" xref="S3.F4.3.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F4.3.m1.1c"><apply id="S3.F4.3.m1.1.1.cmml" xref="S3.F4.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F4.3.m1.1.1.1.cmml" xref="S3.F4.3.m1.1.1">subscript</csymbol><apply id="S3.F4.3.m1.1.1.2.cmml" xref="S3.F4.3.m1.1.1.2"><ci id="S3.F4.3.m1.1.1.2.1.cmml" xref="S3.F4.3.m1.1.1.2.1">~</ci><ci id="S3.F4.3.m1.1.1.2.2.cmml" xref="S3.F4.3.m1.1.1.2.2">𝐴</ci></apply><ci id="S3.F4.3.m1.1.1.3.cmml" xref="S3.F4.3.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.3.m1.1d">\widetilde{A}_{s}</annotation></semantics></math>; (c) An adjacency matrix <math id="S3.F4.4.m2.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S3.F4.4.m2.1b"><msub id="S3.F4.4.m2.1.1" xref="S3.F4.4.m2.1.1.cmml"><mover accent="true" id="S3.F4.4.m2.1.1.2" xref="S3.F4.4.m2.1.1.2.cmml"><mi id="S3.F4.4.m2.1.1.2.2" xref="S3.F4.4.m2.1.1.2.2.cmml">A</mi><mo id="S3.F4.4.m2.1.1.2.1" xref="S3.F4.4.m2.1.1.2.1.cmml">~</mo></mover><mi id="S3.F4.4.m2.1.1.3" xref="S3.F4.4.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F4.4.m2.1c"><apply id="S3.F4.4.m2.1.1.cmml" xref="S3.F4.4.m2.1.1"><csymbol cd="ambiguous" id="S3.F4.4.m2.1.1.1.cmml" xref="S3.F4.4.m2.1.1">subscript</csymbol><apply id="S3.F4.4.m2.1.1.2.cmml" xref="S3.F4.4.m2.1.1.2"><ci id="S3.F4.4.m2.1.1.2.1.cmml" xref="S3.F4.4.m2.1.1.2.1">~</ci><ci id="S3.F4.4.m2.1.1.2.2.cmml" xref="S3.F4.4.m2.1.1.2.2">𝐴</ci></apply><ci id="S3.F4.4.m2.1.1.3.cmml" xref="S3.F4.4.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.m2.1d">\widetilde{A}_{c}</annotation></semantics></math>.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Global Attention Graph</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.8" class="ltx_p">The relationship across disconnected joints, those that exist across sub-segments of the skeleton (<span id="S3.SS3.p1.8.1" class="ltx_text ltx_font_italic">e.g. </span>wrist-ankle), play a key role in encoding global postural and constraint information (think running). As such, disconnected joint representation aid in addressing depth ambiguities and occlusions. To adaptively and effectively encode non-local relationships, we propose a global end-to-end GCN with a multi-head attention mechanism that extends the mechanism introduced in Eqtn. <a href="#S3.E2" title="In III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> from first-order relationships to global relationships. The global attention mechanism is first presented in Eqtn. <a href="#S3.E3" title="In III-C Global Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and then explained in further detail.</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_math_unparsed" alttext="X^{(l+1)}=\mathop{\left|\right|}\limits_{k=1}^{K}\left(B_{k}+C_{k}\right)X^{(l)}W_{k}" display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3"><msup id="S3.E3.m1.3.3.3"><mi id="S3.E3.m1.3.3.3.2">X</mi><mrow id="S3.E3.m1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2">(</mo><mrow id="S3.E3.m1.1.1.1.1.1"><mi id="S3.E3.m1.1.1.1.1.1.2">l</mi><mo id="S3.E3.m1.1.1.1.1.1.1">+</mo><mn id="S3.E3.m1.1.1.1.1.1.3">1</mn></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.3">)</mo></mrow></msup><mo rspace="0em" id="S3.E3.m1.3.3.2">=</mo><mrow id="S3.E3.m1.3.3.1"><munderover id="S3.E3.m1.3.3.1.2"><mrow id="S3.E3.m1.3.3.1.2.2.2"><mo fence="false" rspace="0.167em" id="S3.E3.m1.3.3.1.2.2.2.1">|</mo><mo fence="false" rspace="0.167em" id="S3.E3.m1.3.3.1.2.2.2.2">|</mo></mrow><mrow id="S3.E3.m1.3.3.1.2.2.3"><mi id="S3.E3.m1.3.3.1.2.2.3.2">k</mi><mo id="S3.E3.m1.3.3.1.2.2.3.1">=</mo><mn id="S3.E3.m1.3.3.1.2.2.3.3">1</mn></mrow><mi id="S3.E3.m1.3.3.1.2.3">K</mi></munderover><mrow id="S3.E3.m1.3.3.1.1"><mrow id="S3.E3.m1.3.3.1.1.1.1"><mo id="S3.E3.m1.3.3.1.1.1.1.2">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1"><msub id="S3.E3.m1.3.3.1.1.1.1.1.2"><mi id="S3.E3.m1.3.3.1.1.1.1.1.2.2">B</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.2.3">k</mi></msub><mo id="S3.E3.m1.3.3.1.1.1.1.1.1">+</mo><msub id="S3.E3.m1.3.3.1.1.1.1.1.3"><mi id="S3.E3.m1.3.3.1.1.1.1.1.3.2">C</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.3.3">k</mi></msub></mrow><mo id="S3.E3.m1.3.3.1.1.1.1.3">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2">​</mo><msup id="S3.E3.m1.3.3.1.1.3"><mi id="S3.E3.m1.3.3.1.1.3.2">X</mi><mrow id="S3.E3.m1.2.2.1.3"><mo stretchy="false" id="S3.E3.m1.2.2.1.3.1">(</mo><mi id="S3.E3.m1.2.2.1.1">l</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.3.2">)</mo></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.2a">​</mo><msub id="S3.E3.m1.3.3.1.1.4"><mi id="S3.E3.m1.3.3.1.1.4.2">W</mi><mi id="S3.E3.m1.3.3.1.1.4.3">k</mi></msub></mrow></mrow></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.3b">X^{(l+1)}=\mathop{\left|\right|}\limits_{k=1}^{K}\left(B_{k}+C_{k}\right)X^{(l)}W_{k}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.7" class="ltx_p">where, <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">K</annotation></semantics></math> is the number of attention heads, <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="B_{k}\in\mathbb{R}^{N\times N}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><msub id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2.2" xref="S3.SS3.p1.2.m2.1.1.2.2.cmml">B</mi><mi id="S3.SS3.p1.2.m2.1.1.2.3" xref="S3.SS3.p1.2.m2.1.1.2.3.cmml">k</mi></msub><mo id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.3.2" xref="S3.SS3.p1.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.2.m2.1.1.3.3.1" xref="S3.SS3.p1.2.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p1.2.m2.1.1.3.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><in id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"></in><apply id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2.2">𝐵</ci><ci id="S3.SS3.p1.2.m2.1.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.2.3">𝑘</ci></apply><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">ℝ</ci><apply id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3"><times id="S3.SS3.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3.1"></times><ci id="S3.SS3.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">B_{k}\in\mathbb{R}^{N\times N}</annotation></semantics></math> is an adaptive global adjacency matrix, <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="C_{k}\in\mathbb{R}^{N\times N}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><msub id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2.2" xref="S3.SS3.p1.3.m3.1.1.2.2.cmml">C</mi><mi id="S3.SS3.p1.3.m3.1.1.2.3" xref="S3.SS3.p1.3.m3.1.1.2.3.cmml">k</mi></msub><mo id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml"><mi id="S3.SS3.p1.3.m3.1.1.3.2" xref="S3.SS3.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p1.3.m3.1.1.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS3.p1.3.m3.1.1.3.3.2" xref="S3.SS3.p1.3.m3.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.3.m3.1.1.3.3.1" xref="S3.SS3.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.p1.3.m3.1.1.3.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><in id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1"></in><apply id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.2.1.cmml" xref="S3.SS3.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2.2">𝐶</ci><ci id="S3.SS3.p1.3.m3.1.1.2.3.cmml" xref="S3.SS3.p1.3.m3.1.1.2.3">𝑘</ci></apply><apply id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.3.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S3.SS3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3"><times id="S3.SS3.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3.1"></times><ci id="S3.SS3.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3.2">𝑁</ci><ci id="S3.SS3.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3.3">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">C_{k}\in\mathbb{R}^{N\times N}</annotation></semantics></math> is a learnable global adjacency matrix, and <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="W_{k}\in\mathbb{R}^{C_{l}\times(C_{l}/K)}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mrow id="S3.SS3.p1.4.m4.1.2" xref="S3.SS3.p1.4.m4.1.2.cmml"><msub id="S3.SS3.p1.4.m4.1.2.2" xref="S3.SS3.p1.4.m4.1.2.2.cmml"><mi id="S3.SS3.p1.4.m4.1.2.2.2" xref="S3.SS3.p1.4.m4.1.2.2.2.cmml">W</mi><mi id="S3.SS3.p1.4.m4.1.2.2.3" xref="S3.SS3.p1.4.m4.1.2.2.3.cmml">k</mi></msub><mo id="S3.SS3.p1.4.m4.1.2.1" xref="S3.SS3.p1.4.m4.1.2.1.cmml">∈</mo><msup id="S3.SS3.p1.4.m4.1.2.3" xref="S3.SS3.p1.4.m4.1.2.3.cmml"><mi id="S3.SS3.p1.4.m4.1.2.3.2" xref="S3.SS3.p1.4.m4.1.2.3.2.cmml">ℝ</mi><mrow id="S3.SS3.p1.4.m4.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.cmml"><msub id="S3.SS3.p1.4.m4.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.3.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.3.2" xref="S3.SS3.p1.4.m4.1.1.1.3.2.cmml">C</mi><mi id="S3.SS3.p1.4.m4.1.1.1.3.3" xref="S3.SS3.p1.4.m4.1.1.1.3.3.cmml">l</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.4.m4.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.2.cmml">×</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.2" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.2.cmml">C</mi><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.3.cmml">l</mi></msub><mo id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.cmml">/</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S3.SS3.p1.4.m4.1.1.1.1.1.3" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.2.cmml" xref="S3.SS3.p1.4.m4.1.2"><in id="S3.SS3.p1.4.m4.1.2.1.cmml" xref="S3.SS3.p1.4.m4.1.2.1"></in><apply id="S3.SS3.p1.4.m4.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.2.2.1.cmml" xref="S3.SS3.p1.4.m4.1.2.2">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.2.2.2.cmml" xref="S3.SS3.p1.4.m4.1.2.2.2">𝑊</ci><ci id="S3.SS3.p1.4.m4.1.2.2.3.cmml" xref="S3.SS3.p1.4.m4.1.2.2.3">𝑘</ci></apply><apply id="S3.SS3.p1.4.m4.1.2.3.cmml" xref="S3.SS3.p1.4.m4.1.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.2.3.1.cmml" xref="S3.SS3.p1.4.m4.1.2.3">superscript</csymbol><ci id="S3.SS3.p1.4.m4.1.2.3.2.cmml" xref="S3.SS3.p1.4.m4.1.2.3.2">ℝ</ci><apply id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1"><times id="S3.SS3.p1.4.m4.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.2"></times><apply id="S3.SS3.p1.4.m4.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.3.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.1.3.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.2">𝐶</ci><ci id="S3.SS3.p1.4.m4.1.1.1.3.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.3.3">𝑙</ci></apply><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1"><divide id="S3.SS3.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.1"></divide><apply id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.2">𝐶</ci><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.2.3">𝑙</ci></apply><ci id="S3.SS3.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.1.1.3">𝐾</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">W_{k}\in\mathbb{R}^{C_{l}\times(C_{l}/K)}</annotation></semantics></math> is a transformed matrix. In this work we set <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="K=4" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mrow id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.2" xref="S3.SS3.p1.5.m5.1.1.2.cmml">K</mi><mo id="S3.SS3.p1.5.m5.1.1.1" xref="S3.SS3.p1.5.m5.1.1.1.cmml">=</mo><mn id="S3.SS3.p1.5.m5.1.1.3" xref="S3.SS3.p1.5.m5.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><apply id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1"><eq id="S3.SS3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1"></eq><ci id="S3.SS3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.2">𝐾</ci><cn type="integer" id="S3.SS3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">K=4</annotation></semantics></math> parallel attention heads. Next, we discuss the redefined adjacency matrix <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><msub id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.2" xref="S3.SS3.p1.6.m6.1.1.2.cmml">B</mi><mi id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2">𝐵</ci><ci id="S3.SS3.p1.6.m6.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">B_{k}</annotation></semantics></math> and the global adjacency matrix <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><msub id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml">C</mi><mi id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2">𝐶</ci><ci id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">C_{k}</annotation></semantics></math> in detail.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.8" class="ltx_p"><math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">B</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝐵</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">B_{k}</annotation></semantics></math> expresses a data-dependent matrix which learns a unique graph for each node. We adopt the attention coefficient function proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to determine whether a connection exists between nodes and how strong the connection is. That is, given two node features <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">𝑥</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">x_{i}</annotation></semantics></math> and <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml">x</mi><mi id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2">𝑥</ci><ci id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">x_{j}</annotation></semantics></math>, we first apply two embedding functions <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mi id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><ci id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\theta</annotation></semantics></math> and <math id="S3.SS3.p2.5.m5.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mi id="S3.SS3.p2.5.m5.1.1" xref="S3.SS3.p2.5.m5.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.5.m5.1b"><ci id="S3.SS3.p2.5.m5.1.1.cmml" xref="S3.SS3.p2.5.m5.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">\phi</annotation></semantics></math> to downsample the features of each node from <math id="S3.SS3.p2.6.m6.1" class="ltx_Math" alttext="C_{l}" display="inline"><semantics id="S3.SS3.p2.6.m6.1a"><msub id="S3.SS3.p2.6.m6.1.1" xref="S3.SS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.2" xref="S3.SS3.p2.6.m6.1.1.2.cmml">C</mi><mi id="S3.SS3.p2.6.m6.1.1.3" xref="S3.SS3.p2.6.m6.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.1b"><apply id="S3.SS3.p2.6.m6.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.2">𝐶</ci><ci id="S3.SS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.1c">C_{l}</annotation></semantics></math> to <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="C_{l}/K" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><mrow id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><msub id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml"><mi id="S3.SS3.p2.7.m7.1.1.2.2" xref="S3.SS3.p2.7.m7.1.1.2.2.cmml">C</mi><mi id="S3.SS3.p2.7.m7.1.1.2.3" xref="S3.SS3.p2.7.m7.1.1.2.3.cmml">l</mi></msub><mo id="S3.SS3.p2.7.m7.1.1.1" xref="S3.SS3.p2.7.m7.1.1.1.cmml">/</mo><mi id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><divide id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1.1"></divide><apply id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.1.1.2.1.cmml" xref="S3.SS3.p2.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS3.p2.7.m7.1.1.2.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2.2">𝐶</ci><ci id="S3.SS3.p2.7.m7.1.1.2.3.cmml" xref="S3.SS3.p2.7.m7.1.1.2.3">𝑙</ci></apply><ci id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">C_{l}/K</annotation></semantics></math> channels. Since the number of channels for each node is reduced, the total computational cost for multi-attention is similar to that of single-headed attention with full channels. Then we concatenate the two embedded features, and compute their dot product with a weight vector <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="w_{f}" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><msub id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml"><mi id="S3.SS3.p2.8.m8.1.1.2" xref="S3.SS3.p2.8.m8.1.1.2.cmml">w</mi><mi id="S3.SS3.p2.8.m8.1.1.3" xref="S3.SS3.p2.8.m8.1.1.3.cmml">f</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><apply id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.8.m8.1.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p2.8.m8.1.1.2.cmml" xref="S3.SS3.p2.8.m8.1.1.2">𝑤</ci><ci id="S3.SS3.p2.8.m8.1.1.3.cmml" xref="S3.SS3.p2.8.m8.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">w_{f}</annotation></semantics></math> to produce a scalar output. To facilitate coefficient comparisons across nodes, the scalar outputs are normalized by the softmax function. The operation is presented in Eqtn. <a href="#S3.E4" title="In III-C Global Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\alpha_{ij}=\frac{e^{\sigma\left(w_{f}\cdot[\theta(x_{i})\Arrowvert\phi(x_{j})]\right)}}{\sum_{k=1}^{N}e^{\sigma\left(w_{f}\cdot[\theta(x_{i})\Arrowvert\phi(x_{k})]\right)}}," display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.2.2" xref="S3.E4.m1.3.3.1.1.2.2.cmml">α</mi><mrow id="S3.E4.m1.3.3.1.1.2.3" xref="S3.E4.m1.3.3.1.1.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.2.3.2" xref="S3.E4.m1.3.3.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.3" xref="S3.E4.m1.3.3.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><msup id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml">e</mi><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml">w</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml">f</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">θ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">∥</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup><mrow id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml"><msubsup id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.cmml"><mo id="S3.E4.m1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.cmml">∑</mo><mrow id="S3.E4.m1.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.3.cmml"><mi id="S3.E4.m1.2.2.2.2.2.3.2" xref="S3.E4.m1.2.2.2.2.2.3.2.cmml">k</mi><mo id="S3.E4.m1.2.2.2.2.2.3.1" xref="S3.E4.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.2.2.2.2.2.3.3" xref="S3.E4.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.3.cmml">N</mi></msubsup><msup id="S3.E4.m1.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml"><mi id="S3.E4.m1.2.2.2.3.2" xref="S3.E4.m1.2.2.2.3.2.cmml">e</mi><mrow id="S3.E4.m1.2.2.2.1.1" xref="S3.E4.m1.2.2.2.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.3" xref="S3.E4.m1.2.2.2.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.1.1.2" xref="S3.E4.m1.2.2.2.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.cmml"><mo id="S3.E4.m1.2.2.2.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.cmml"><msub id="S3.E4.m1.2.2.2.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.3.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3.2.cmml">w</mi><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.3.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3.3.cmml">f</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.2.2.2.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.2.1.cmml">[</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.cmml">θ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.3.cmml">∥</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.3.cmml">ϕ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.2.cmml">​</mo><mrow id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.cmml">(</mo><msub id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.cmml"><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.2" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E4.m1.2.2.2.1.1.1.1.3" xref="S3.E4.m1.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow></mfrac></mrow><mo id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"></eq><apply id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.2">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.2.2">𝛼</ci><apply id="S3.E4.m1.3.3.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.2.3"><times id="S3.E4.m1.3.3.1.1.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.2.3.1"></times><ci id="S3.E4.m1.3.3.1.1.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.2.3.2">𝑖</ci><ci id="S3.E4.m1.3.3.1.1.2.3.3.cmml" xref="S3.E4.m1.3.3.1.1.2.3.3">𝑗</ci></apply></apply><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><divide id="S3.E4.m1.2.2.3.cmml" xref="S3.E4.m1.2.2"></divide><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3">𝑒</ci><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3">𝜎</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2">⋅</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2">𝑤</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3">𝑓</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝜃</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.2"></times><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">italic-ϕ</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.2">𝑥</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></apply></apply><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"><apply id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2">superscript</csymbol><apply id="S3.E4.m1.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2">subscript</csymbol><sum id="S3.E4.m1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2"></sum><apply id="S3.E4.m1.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.3"><eq id="S3.E4.m1.2.2.2.2.2.3.1.cmml" xref="S3.E4.m1.2.2.2.2.2.3.1"></eq><ci id="S3.E4.m1.2.2.2.2.2.3.2.cmml" xref="S3.E4.m1.2.2.2.2.2.3.2">𝑘</ci><cn type="integer" id="S3.E4.m1.2.2.2.2.2.3.3.cmml" xref="S3.E4.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.3">𝑁</ci></apply><apply id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.3.1.cmml" xref="S3.E4.m1.2.2.2.3">superscript</csymbol><ci id="S3.E4.m1.2.2.2.3.2.cmml" xref="S3.E4.m1.2.2.2.3.2">𝑒</ci><apply id="S3.E4.m1.2.2.2.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1"><times id="S3.E4.m1.2.2.2.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.2"></times><ci id="S3.E4.m1.2.2.2.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.3">𝜎</ci><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1"><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.2">⋅</ci><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3.2">𝑤</ci><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.3.3">𝑓</ci></apply><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.3">conditional</csymbol><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.3">𝜃</ci><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.2"></times><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.3">italic-ϕ</ci><apply id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.2.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.2">𝑥</ci><ci id="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.3.cmml" xref="S3.E4.m1.2.2.2.1.1.1.1.1.1.1.1.2.1.1.1.3">𝑘</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\alpha_{ij}=\frac{e^{\sigma\left(w_{f}\cdot[\theta(x_{i})\Arrowvert\phi(x_{j})]\right)}}{\sum_{k=1}^{N}e^{\sigma\left(w_{f}\cdot[\theta(x_{i})\Arrowvert\phi(x_{k})]\right)}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.13" class="ltx_p">where <math id="S3.SS3.p2.9.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p2.9.m1.1a"><mi id="S3.SS3.p2.9.m1.1.1" xref="S3.SS3.p2.9.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.9.m1.1b"><ci id="S3.SS3.p2.9.m1.1.1.cmml" xref="S3.SS3.p2.9.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.9.m1.1c">\theta</annotation></semantics></math> and <math id="S3.SS3.p2.10.m2.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS3.p2.10.m2.1a"><mi id="S3.SS3.p2.10.m2.1.1" xref="S3.SS3.p2.10.m2.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.10.m2.1b"><ci id="S3.SS3.p2.10.m2.1.1.cmml" xref="S3.SS3.p2.10.m2.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.10.m2.1c">\phi</annotation></semantics></math> are convolutions with the kernel size 1; <math id="S3.SS3.p2.11.m3.1" class="ltx_math_unparsed" alttext="[\cdot\Arrowvert\cdot]" display="inline"><semantics id="S3.SS3.p2.11.m3.1a"><mrow id="S3.SS3.p2.11.m3.1b"><mo stretchy="false" id="S3.SS3.p2.11.m3.1.1">[</mo><mo lspace="0em" rspace="0em" id="S3.SS3.p2.11.m3.1.2">⋅</mo><mo lspace="0em" rspace="0em" id="S3.SS3.p2.11.m3.1.3">∥</mo><mo lspace="0em" rspace="0em" id="S3.SS3.p2.11.m3.1.4">⋅</mo><mo stretchy="false" id="S3.SS3.p2.11.m3.1.5">]</mo></mrow><annotation encoding="application/x-tex" id="S3.SS3.p2.11.m3.1c">[\cdot\Arrowvert\cdot]</annotation></semantics></math> denotes concatenation, and <math id="S3.SS3.p2.12.m4.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS3.p2.12.m4.1a"><mi id="S3.SS3.p2.12.m4.1.1" xref="S3.SS3.p2.12.m4.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.12.m4.1b"><ci id="S3.SS3.p2.12.m4.1.1.cmml" xref="S3.SS3.p2.12.m4.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.12.m4.1c">\sigma</annotation></semantics></math> denotes a LeakyReLU nonlinearity with negative input slope <math id="S3.SS3.p2.13.m5.1" class="ltx_Math" alttext="\alpha=0.2" display="inline"><semantics id="S3.SS3.p2.13.m5.1a"><mrow id="S3.SS3.p2.13.m5.1.1" xref="S3.SS3.p2.13.m5.1.1.cmml"><mi id="S3.SS3.p2.13.m5.1.1.2" xref="S3.SS3.p2.13.m5.1.1.2.cmml">α</mi><mo id="S3.SS3.p2.13.m5.1.1.1" xref="S3.SS3.p2.13.m5.1.1.1.cmml">=</mo><mn id="S3.SS3.p2.13.m5.1.1.3" xref="S3.SS3.p2.13.m5.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.13.m5.1b"><apply id="S3.SS3.p2.13.m5.1.1.cmml" xref="S3.SS3.p2.13.m5.1.1"><eq id="S3.SS3.p2.13.m5.1.1.1.cmml" xref="S3.SS3.p2.13.m5.1.1.1"></eq><ci id="S3.SS3.p2.13.m5.1.1.2.cmml" xref="S3.SS3.p2.13.m5.1.1.2">𝛼</ci><cn type="float" id="S3.SS3.p2.13.m5.1.1.3.cmml" xref="S3.SS3.p2.13.m5.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.13.m5.1c">\alpha=0.2</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.11" class="ltx_p"><math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝐶</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">C_{k}</annotation></semantics></math> is a learnable adjacency matrix, inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, with an initialization value of zero. The value of <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝐶</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">C_{k}</annotation></semantics></math> is not limited to special node features like <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">B</mi><mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝐵</ci><ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">B_{k}</annotation></semantics></math>, which is updated during the training process. The elements of <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">𝐶</ci><ci id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">C_{k}</annotation></semantics></math> are arbitrary. They indicate the existence and strength of connections between two joints. It plays a similar role to the attention mechanism performed by <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="M_{c}" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><msub id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mi id="S3.SS3.p3.5.m5.1.1.2" xref="S3.SS3.p3.5.m5.1.1.2.cmml">M</mi><mi id="S3.SS3.p3.5.m5.1.1.3" xref="S3.SS3.p3.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2">𝑀</ci><ci id="S3.SS3.p3.5.m5.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">M_{c}</annotation></semantics></math> in Eqtn. <a href="#S3.E2" title="In III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. However, note how in Eqtn. <a href="#S3.E2" title="In III-B Local Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <math id="S3.SS3.p3.6.m6.1" class="ltx_Math" alttext="M_{c}" display="inline"><semantics id="S3.SS3.p3.6.m6.1a"><msub id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml"><mi id="S3.SS3.p3.6.m6.1.1.2" xref="S3.SS3.p3.6.m6.1.1.2.cmml">M</mi><mi id="S3.SS3.p3.6.m6.1.1.3" xref="S3.SS3.p3.6.m6.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><apply id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p3.6.m6.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2">𝑀</ci><ci id="S3.SS3.p3.6.m6.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">M_{c}</annotation></semantics></math> is dot multiplied with <math id="S3.SS3.p3.7.m7.1" class="ltx_Math" alttext="\widetilde{A}" display="inline"><semantics id="S3.SS3.p3.7.m7.1a"><mover accent="true" id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml"><mi id="S3.SS3.p3.7.m7.1.1.2" xref="S3.SS3.p3.7.m7.1.1.2.cmml">A</mi><mo id="S3.SS3.p3.7.m7.1.1.1" xref="S3.SS3.p3.7.m7.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b"><apply id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1"><ci id="S3.SS3.p3.7.m7.1.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1.1">~</ci><ci id="S3.SS3.p3.7.m7.1.1.2.cmml" xref="S3.SS3.p3.7.m7.1.1.2">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">\widetilde{A}</annotation></semantics></math>, and if any of the elements in <math id="S3.SS3.p3.8.m8.1" class="ltx_Math" alttext="\widetilde{A}" display="inline"><semantics id="S3.SS3.p3.8.m8.1a"><mover accent="true" id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml"><mi id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">A</mi><mo id="S3.SS3.p3.8.m8.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b"><apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1"><ci id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1">~</ci><ci id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">\widetilde{A}</annotation></semantics></math> is 0, the product will always be 0 irrespective the value of <math id="S3.SS3.p3.9.m9.1" class="ltx_Math" alttext="M_{c}" display="inline"><semantics id="S3.SS3.p3.9.m9.1a"><msub id="S3.SS3.p3.9.m9.1.1" xref="S3.SS3.p3.9.m9.1.1.cmml"><mi id="S3.SS3.p3.9.m9.1.1.2" xref="S3.SS3.p3.9.m9.1.1.2.cmml">M</mi><mi id="S3.SS3.p3.9.m9.1.1.3" xref="S3.SS3.p3.9.m9.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m9.1b"><apply id="S3.SS3.p3.9.m9.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.9.m9.1.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.p3.9.m9.1.1.2.cmml" xref="S3.SS3.p3.9.m9.1.1.2">𝑀</ci><ci id="S3.SS3.p3.9.m9.1.1.3.cmml" xref="S3.SS3.p3.9.m9.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m9.1c">M_{c}</annotation></semantics></math>. Thus, no new connections can be created in the original physical graph. From this perspective, <math id="S3.SS3.p3.10.m10.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S3.SS3.p3.10.m10.1a"><msub id="S3.SS3.p3.10.m10.1.1" xref="S3.SS3.p3.10.m10.1.1.cmml"><mi id="S3.SS3.p3.10.m10.1.1.2" xref="S3.SS3.p3.10.m10.1.1.2.cmml">C</mi><mi id="S3.SS3.p3.10.m10.1.1.3" xref="S3.SS3.p3.10.m10.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m10.1b"><apply id="S3.SS3.p3.10.m10.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m10.1.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1">subscript</csymbol><ci id="S3.SS3.p3.10.m10.1.1.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2">𝐶</ci><ci id="S3.SS3.p3.10.m10.1.1.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m10.1c">C_{k}</annotation></semantics></math> is more flexible than <math id="S3.SS3.p3.11.m11.1" class="ltx_Math" alttext="M_{c}" display="inline"><semantics id="S3.SS3.p3.11.m11.1a"><msub id="S3.SS3.p3.11.m11.1.1" xref="S3.SS3.p3.11.m11.1.1.cmml"><mi id="S3.SS3.p3.11.m11.1.1.2" xref="S3.SS3.p3.11.m11.1.1.2.cmml">M</mi><mi id="S3.SS3.p3.11.m11.1.1.3" xref="S3.SS3.p3.11.m11.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m11.1b"><apply id="S3.SS3.p3.11.m11.1.1.cmml" xref="S3.SS3.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.11.m11.1.1.1.cmml" xref="S3.SS3.p3.11.m11.1.1">subscript</csymbol><ci id="S3.SS3.p3.11.m11.1.1.2.cmml" xref="S3.SS3.p3.11.m11.1.1.2">𝑀</ci><ci id="S3.SS3.p3.11.m11.1.1.3.cmml" xref="S3.SS3.p3.11.m11.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m11.1c">M_{c}</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Datasets</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We evaluate our method on two publicly available datasets: Human3.6M <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and HumanEva-I <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Human3.6M captures data through four synchronized cameras at 50 Hz and contains 3.6 million video frames with 11 professional subjects performing 15 daily activities (<em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em> walking and sitting). Following previous methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we employ subjects 1, 5, 6, 7, 8 for training and 9, 11 for testing. HumanEva-I, is a much smaller dataset and captures data through three camera views at 60 Hz. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, the time-series data from three actions (walk, jog, box) is split between training and testing.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We use two common evaluation protocols in our experiments. Protocol #1 calculates the mean per joint positioning error (MPJPE) between the ground truth and the predicted 3D coordinates across all cameras and joints. Protocol #2 employs a rigid alignment (Procrustes analysis) with the ground truth before calculating the mean per joint positioning error (P-MPJPE).</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Training &amp; Inference</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">GAST-Net was trained with receptive fields of sizes 9, 27, 81 and 243 to verify the effectiveness of our model architecture. To make the model lightweight, for networks with receptive fields of 9 and 27, we increase the number of output channels of the first dilated convolutional layer to 128, while the network with 81 and 243 receptive fields is set to 64 and 32 channels respectively. Note that our loss function only computes the MPJPE between the predicted 3D location and ground truth without using any tricks (<em id="S5.SS1.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em> motion constraint and pose regulation).</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS1.5.1.1" class="ltx_text">V-A</span>1 </span>Training &amp; Inference Strategy</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">To train the proposed model, we use Pavllo’s optimized training strategy for single-frame predictions instead of the layer-by-layer implementation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
For single-frame scenarios, dilated convolutions are known to waste a large number of computations. To reduce the inefficiency, dilated convolutions are replaced with strided convolutions. At inference, we switch and consider the entire video sequence. We change from the optimized training strategy to the layer-by-layer implementation to make faster predictions.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS2.5.1.1" class="ltx_text">V-A</span>2 </span>Implementation Details</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Note that the different datasets have different joint setups. In Human 3.6M we predict poses using a 17-joint skeleton and in HumanEva-I, we use 15-joints. Also, we noted that high frame rates lead to information redundancy that negatively affects the encoding of global semantics over time. For this reason, we decided to downsample the Human3.6M dataset from 50 FPS to 10 FPS. On the other hand, as the duration of videos in the HumanEva-I dataset is short, no downsampling is performed here. With regards to real-time estimation, long video durations are not suitable for fast estimation; as such we do not perform downsampling for the 243 receptive field model. Finally, we adopt horizontal flip augmentation at both training and testing time.
</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p id="S5.SS1.SSS2.p2.6" class="ltx_p">We implement our method with the PyTorch framework and train end-to-end. For Human3.6M, we optimize with Amsgrad with a mini-batch size of <math id="S5.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="b=128" display="inline"><semantics id="S5.SS1.SSS2.p2.1.m1.1a"><mrow id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml"><mi id="S5.SS1.SSS2.p2.1.m1.1.1.2" xref="S5.SS1.SSS2.p2.1.m1.1.1.2.cmml">b</mi><mo id="S5.SS1.SSS2.p2.1.m1.1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p2.1.m1.1.1.3" xref="S5.SS1.SSS2.p2.1.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.1b"><apply id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1"><eq id="S5.SS1.SSS2.p2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1.1"></eq><ci id="S5.SS1.SSS2.p2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1.2">𝑏</ci><cn type="integer" id="S5.SS1.SSS2.p2.1.m1.1.1.3.cmml" xref="S5.SS1.SSS2.p2.1.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.1c">b=128</annotation></semantics></math>, and train for 80 epochs. The learning rate starts at 0.001 and then applies a learning shrink factor <math id="S5.SS1.SSS2.p2.2.m2.1" class="ltx_Math" alttext="\alpha=0.95" display="inline"><semantics id="S5.SS1.SSS2.p2.2.m2.1a"><mrow id="S5.SS1.SSS2.p2.2.m2.1.1" xref="S5.SS1.SSS2.p2.2.m2.1.1.cmml"><mi id="S5.SS1.SSS2.p2.2.m2.1.1.2" xref="S5.SS1.SSS2.p2.2.m2.1.1.2.cmml">α</mi><mo id="S5.SS1.SSS2.p2.2.m2.1.1.1" xref="S5.SS1.SSS2.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p2.2.m2.1.1.3" xref="S5.SS1.SSS2.p2.2.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.2.m2.1b"><apply id="S5.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS2.p2.2.m2.1.1"><eq id="S5.SS1.SSS2.p2.2.m2.1.1.1.cmml" xref="S5.SS1.SSS2.p2.2.m2.1.1.1"></eq><ci id="S5.SS1.SSS2.p2.2.m2.1.1.2.cmml" xref="S5.SS1.SSS2.p2.2.m2.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.SSS2.p2.2.m2.1.1.3.cmml" xref="S5.SS1.SSS2.p2.2.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.2.m2.1c">\alpha=0.95</annotation></semantics></math> in each epoch. The dropout rate <math id="S5.SS1.SSS2.p2.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S5.SS1.SSS2.p2.3.m3.1a"><mi id="S5.SS1.SSS2.p2.3.m3.1.1" xref="S5.SS1.SSS2.p2.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.3.m3.1b"><ci id="S5.SS1.SSS2.p2.3.m3.1.1.cmml" xref="S5.SS1.SSS2.p2.3.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.3.m3.1c">p</annotation></semantics></math> in each dropout layer is set to 0.05. For HumanEva-I, we use <math id="S5.SS1.SSS2.p2.4.m4.1" class="ltx_Math" alttext="b=32" display="inline"><semantics id="S5.SS1.SSS2.p2.4.m4.1a"><mrow id="S5.SS1.SSS2.p2.4.m4.1.1" xref="S5.SS1.SSS2.p2.4.m4.1.1.cmml"><mi id="S5.SS1.SSS2.p2.4.m4.1.1.2" xref="S5.SS1.SSS2.p2.4.m4.1.1.2.cmml">b</mi><mo id="S5.SS1.SSS2.p2.4.m4.1.1.1" xref="S5.SS1.SSS2.p2.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p2.4.m4.1.1.3" xref="S5.SS1.SSS2.p2.4.m4.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.4.m4.1b"><apply id="S5.SS1.SSS2.p2.4.m4.1.1.cmml" xref="S5.SS1.SSS2.p2.4.m4.1.1"><eq id="S5.SS1.SSS2.p2.4.m4.1.1.1.cmml" xref="S5.SS1.SSS2.p2.4.m4.1.1.1"></eq><ci id="S5.SS1.SSS2.p2.4.m4.1.1.2.cmml" xref="S5.SS1.SSS2.p2.4.m4.1.1.2">𝑏</ci><cn type="integer" id="S5.SS1.SSS2.p2.4.m4.1.1.3.cmml" xref="S5.SS1.SSS2.p2.4.m4.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.4.m4.1c">b=32</annotation></semantics></math>, <math id="S5.SS1.SSS2.p2.5.m5.1" class="ltx_Math" alttext="\alpha=0.98" display="inline"><semantics id="S5.SS1.SSS2.p2.5.m5.1a"><mrow id="S5.SS1.SSS2.p2.5.m5.1.1" xref="S5.SS1.SSS2.p2.5.m5.1.1.cmml"><mi id="S5.SS1.SSS2.p2.5.m5.1.1.2" xref="S5.SS1.SSS2.p2.5.m5.1.1.2.cmml">α</mi><mo id="S5.SS1.SSS2.p2.5.m5.1.1.1" xref="S5.SS1.SSS2.p2.5.m5.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p2.5.m5.1.1.3" xref="S5.SS1.SSS2.p2.5.m5.1.1.3.cmml">0.98</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.5.m5.1b"><apply id="S5.SS1.SSS2.p2.5.m5.1.1.cmml" xref="S5.SS1.SSS2.p2.5.m5.1.1"><eq id="S5.SS1.SSS2.p2.5.m5.1.1.1.cmml" xref="S5.SS1.SSS2.p2.5.m5.1.1.1"></eq><ci id="S5.SS1.SSS2.p2.5.m5.1.1.2.cmml" xref="S5.SS1.SSS2.p2.5.m5.1.1.2">𝛼</ci><cn type="float" id="S5.SS1.SSS2.p2.5.m5.1.1.3.cmml" xref="S5.SS1.SSS2.p2.5.m5.1.1.3">0.98</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.5.m5.1c">\alpha=0.98</annotation></semantics></math>, <math id="S5.SS1.SSS2.p2.6.m6.1" class="ltx_Math" alttext="p=0.5" display="inline"><semantics id="S5.SS1.SSS2.p2.6.m6.1a"><mrow id="S5.SS1.SSS2.p2.6.m6.1.1" xref="S5.SS1.SSS2.p2.6.m6.1.1.cmml"><mi id="S5.SS1.SSS2.p2.6.m6.1.1.2" xref="S5.SS1.SSS2.p2.6.m6.1.1.2.cmml">p</mi><mo id="S5.SS1.SSS2.p2.6.m6.1.1.1" xref="S5.SS1.SSS2.p2.6.m6.1.1.1.cmml">=</mo><mn id="S5.SS1.SSS2.p2.6.m6.1.1.3" xref="S5.SS1.SSS2.p2.6.m6.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.6.m6.1b"><apply id="S5.SS1.SSS2.p2.6.m6.1.1.cmml" xref="S5.SS1.SSS2.p2.6.m6.1.1"><eq id="S5.SS1.SSS2.p2.6.m6.1.1.1.cmml" xref="S5.SS1.SSS2.p2.6.m6.1.1.1"></eq><ci id="S5.SS1.SSS2.p2.6.m6.1.1.2.cmml" xref="S5.SS1.SSS2.p2.6.m6.1.1.2">𝑝</ci><cn type="float" id="S5.SS1.SSS2.p2.6.m6.1.1.3.cmml" xref="S5.SS1.SSS2.p2.6.m6.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.6.m6.1c">p=0.5</annotation></semantics></math>, and train for 200 epochs.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Ablation Studies</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">In our ablation studies, as with those in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we will use 2D poses detected from Cascaded Pyramidal Networks (CPNs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> in our 27 receptive fields model.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS1.5.1.1" class="ltx_text">V-B</span>1 </span>Effects of Spatial Semantics</h4>

<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table I: </span>Ablation study on different spatial semantics in our network architecture on Human3.6M under both protocols.</figcaption>
<table id="S5.T1.8.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.8.8.9.1" class="ltx_tr">
<th id="S5.T1.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Method (T=27, CPN)</th>
<th id="S5.T1.8.8.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">MPJPE (mm)</th>
<th id="S5.T1.8.8.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">P-MPJPE (mm)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.8.8.10.1" class="ltx_tr">
<th id="S5.T1.8.8.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Baseline</th>
<td id="S5.T1.8.8.10.1.2" class="ltx_td ltx_align_center ltx_border_t">60.9</td>
<td id="S5.T1.8.8.10.1.3" class="ltx_td ltx_align_center ltx_border_t">50.5</td>
</tr>
<tr id="S5.T1.2.2.2" class="ltx_tr">
<th id="S5.T1.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">+ Local <math id="S5.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="GCN_{s}" display="inline"><semantics id="S5.T1.1.1.1.1.m1.1a"><mrow id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml"><mi id="S5.T1.1.1.1.1.m1.1.1.2" xref="S5.T1.1.1.1.1.m1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S5.T1.1.1.1.1.m1.1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.1.cmml">​</mo><mi id="S5.T1.1.1.1.1.m1.1.1.3" xref="S5.T1.1.1.1.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.T1.1.1.1.1.m1.1.1.1a" xref="S5.T1.1.1.1.1.m1.1.1.1.cmml">​</mo><msub id="S5.T1.1.1.1.1.m1.1.1.4" xref="S5.T1.1.1.1.1.m1.1.1.4.cmml"><mi id="S5.T1.1.1.1.1.m1.1.1.4.2" xref="S5.T1.1.1.1.1.m1.1.1.4.2.cmml">N</mi><mi id="S5.T1.1.1.1.1.m1.1.1.4.3" xref="S5.T1.1.1.1.1.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1"><times id="S5.T1.1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1.1"></times><ci id="S5.T1.1.1.1.1.m1.1.1.2.cmml" xref="S5.T1.1.1.1.1.m1.1.1.2">𝐺</ci><ci id="S5.T1.1.1.1.1.m1.1.1.3.cmml" xref="S5.T1.1.1.1.1.m1.1.1.3">𝐶</ci><apply id="S5.T1.1.1.1.1.m1.1.1.4.cmml" xref="S5.T1.1.1.1.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.T1.1.1.1.1.m1.1.1.4.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1.4">subscript</csymbol><ci id="S5.T1.1.1.1.1.m1.1.1.4.2.cmml" xref="S5.T1.1.1.1.1.m1.1.1.4.2">𝑁</ci><ci id="S5.T1.1.1.1.1.m1.1.1.4.3.cmml" xref="S5.T1.1.1.1.1.m1.1.1.4.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">GCN_{s}</annotation></semantics></math> with <math id="S5.T1.2.2.2.2.m2.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S5.T1.2.2.2.2.m2.1a"><msub id="S5.T1.2.2.2.2.m2.1.1" xref="S5.T1.2.2.2.2.m2.1.1.cmml"><mover accent="true" id="S5.T1.2.2.2.2.m2.1.1.2" xref="S5.T1.2.2.2.2.m2.1.1.2.cmml"><mi id="S5.T1.2.2.2.2.m2.1.1.2.2" xref="S5.T1.2.2.2.2.m2.1.1.2.2.cmml">A</mi><mo id="S5.T1.2.2.2.2.m2.1.1.2.1" xref="S5.T1.2.2.2.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S5.T1.2.2.2.2.m2.1.1.3" xref="S5.T1.2.2.2.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.2.m2.1b"><apply id="S5.T1.2.2.2.2.m2.1.1.cmml" xref="S5.T1.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T1.2.2.2.2.m2.1.1.1.cmml" xref="S5.T1.2.2.2.2.m2.1.1">subscript</csymbol><apply id="S5.T1.2.2.2.2.m2.1.1.2.cmml" xref="S5.T1.2.2.2.2.m2.1.1.2"><ci id="S5.T1.2.2.2.2.m2.1.1.2.1.cmml" xref="S5.T1.2.2.2.2.m2.1.1.2.1">~</ci><ci id="S5.T1.2.2.2.2.m2.1.1.2.2.cmml" xref="S5.T1.2.2.2.2.m2.1.1.2.2">𝐴</ci></apply><ci id="S5.T1.2.2.2.2.m2.1.1.3.cmml" xref="S5.T1.2.2.2.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.2.m2.1c">\widetilde{A}_{c}</annotation></semantics></math>
</th>
<td id="S5.T1.2.2.2.3" class="ltx_td ltx_align_center">55.4</td>
<td id="S5.T1.2.2.2.4" class="ltx_td ltx_align_center">44.0</td>
</tr>
<tr id="S5.T1.4.4.4" class="ltx_tr">
<th id="S5.T1.4.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">+ Local <math id="S5.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="GCN_{s}" display="inline"><semantics id="S5.T1.3.3.3.1.m1.1a"><mrow id="S5.T1.3.3.3.1.m1.1.1" xref="S5.T1.3.3.3.1.m1.1.1.cmml"><mi id="S5.T1.3.3.3.1.m1.1.1.2" xref="S5.T1.3.3.3.1.m1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S5.T1.3.3.3.1.m1.1.1.1" xref="S5.T1.3.3.3.1.m1.1.1.1.cmml">​</mo><mi id="S5.T1.3.3.3.1.m1.1.1.3" xref="S5.T1.3.3.3.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.T1.3.3.3.1.m1.1.1.1a" xref="S5.T1.3.3.3.1.m1.1.1.1.cmml">​</mo><msub id="S5.T1.3.3.3.1.m1.1.1.4" xref="S5.T1.3.3.3.1.m1.1.1.4.cmml"><mi id="S5.T1.3.3.3.1.m1.1.1.4.2" xref="S5.T1.3.3.3.1.m1.1.1.4.2.cmml">N</mi><mi id="S5.T1.3.3.3.1.m1.1.1.4.3" xref="S5.T1.3.3.3.1.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.1.m1.1b"><apply id="S5.T1.3.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.3.1.m1.1.1"><times id="S5.T1.3.3.3.1.m1.1.1.1.cmml" xref="S5.T1.3.3.3.1.m1.1.1.1"></times><ci id="S5.T1.3.3.3.1.m1.1.1.2.cmml" xref="S5.T1.3.3.3.1.m1.1.1.2">𝐺</ci><ci id="S5.T1.3.3.3.1.m1.1.1.3.cmml" xref="S5.T1.3.3.3.1.m1.1.1.3">𝐶</ci><apply id="S5.T1.3.3.3.1.m1.1.1.4.cmml" xref="S5.T1.3.3.3.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.T1.3.3.3.1.m1.1.1.4.1.cmml" xref="S5.T1.3.3.3.1.m1.1.1.4">subscript</csymbol><ci id="S5.T1.3.3.3.1.m1.1.1.4.2.cmml" xref="S5.T1.3.3.3.1.m1.1.1.4.2">𝑁</ci><ci id="S5.T1.3.3.3.1.m1.1.1.4.3.cmml" xref="S5.T1.3.3.3.1.m1.1.1.4.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.1.m1.1c">GCN_{s}</annotation></semantics></math> with <math id="S5.T1.4.4.4.2.m2.1" class="ltx_Math" alttext="\widetilde{A}_{s}" display="inline"><semantics id="S5.T1.4.4.4.2.m2.1a"><msub id="S5.T1.4.4.4.2.m2.1.1" xref="S5.T1.4.4.4.2.m2.1.1.cmml"><mover accent="true" id="S5.T1.4.4.4.2.m2.1.1.2" xref="S5.T1.4.4.4.2.m2.1.1.2.cmml"><mi id="S5.T1.4.4.4.2.m2.1.1.2.2" xref="S5.T1.4.4.4.2.m2.1.1.2.2.cmml">A</mi><mo id="S5.T1.4.4.4.2.m2.1.1.2.1" xref="S5.T1.4.4.4.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S5.T1.4.4.4.2.m2.1.1.3" xref="S5.T1.4.4.4.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.2.m2.1b"><apply id="S5.T1.4.4.4.2.m2.1.1.cmml" xref="S5.T1.4.4.4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T1.4.4.4.2.m2.1.1.1.cmml" xref="S5.T1.4.4.4.2.m2.1.1">subscript</csymbol><apply id="S5.T1.4.4.4.2.m2.1.1.2.cmml" xref="S5.T1.4.4.4.2.m2.1.1.2"><ci id="S5.T1.4.4.4.2.m2.1.1.2.1.cmml" xref="S5.T1.4.4.4.2.m2.1.1.2.1">~</ci><ci id="S5.T1.4.4.4.2.m2.1.1.2.2.cmml" xref="S5.T1.4.4.4.2.m2.1.1.2.2">𝐴</ci></apply><ci id="S5.T1.4.4.4.2.m2.1.1.3.cmml" xref="S5.T1.4.4.4.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.2.m2.1c">\widetilde{A}_{s}</annotation></semantics></math>
</th>
<td id="S5.T1.4.4.4.3" class="ltx_td ltx_align_center">51.9</td>
<td id="S5.T1.4.4.4.4" class="ltx_td ltx_align_center">40.9</td>
</tr>
<tr id="S5.T1.6.6.6" class="ltx_tr">
<th id="S5.T1.6.6.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">+ Global <math id="S5.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="GCN_{s}" display="inline"><semantics id="S5.T1.5.5.5.1.m1.1a"><mrow id="S5.T1.5.5.5.1.m1.1.1" xref="S5.T1.5.5.5.1.m1.1.1.cmml"><mi id="S5.T1.5.5.5.1.m1.1.1.2" xref="S5.T1.5.5.5.1.m1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S5.T1.5.5.5.1.m1.1.1.1" xref="S5.T1.5.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S5.T1.5.5.5.1.m1.1.1.3" xref="S5.T1.5.5.5.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.T1.5.5.5.1.m1.1.1.1a" xref="S5.T1.5.5.5.1.m1.1.1.1.cmml">​</mo><msub id="S5.T1.5.5.5.1.m1.1.1.4" xref="S5.T1.5.5.5.1.m1.1.1.4.cmml"><mi id="S5.T1.5.5.5.1.m1.1.1.4.2" xref="S5.T1.5.5.5.1.m1.1.1.4.2.cmml">N</mi><mi id="S5.T1.5.5.5.1.m1.1.1.4.3" xref="S5.T1.5.5.5.1.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.1.m1.1b"><apply id="S5.T1.5.5.5.1.m1.1.1.cmml" xref="S5.T1.5.5.5.1.m1.1.1"><times id="S5.T1.5.5.5.1.m1.1.1.1.cmml" xref="S5.T1.5.5.5.1.m1.1.1.1"></times><ci id="S5.T1.5.5.5.1.m1.1.1.2.cmml" xref="S5.T1.5.5.5.1.m1.1.1.2">𝐺</ci><ci id="S5.T1.5.5.5.1.m1.1.1.3.cmml" xref="S5.T1.5.5.5.1.m1.1.1.3">𝐶</ci><apply id="S5.T1.5.5.5.1.m1.1.1.4.cmml" xref="S5.T1.5.5.5.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.T1.5.5.5.1.m1.1.1.4.1.cmml" xref="S5.T1.5.5.5.1.m1.1.1.4">subscript</csymbol><ci id="S5.T1.5.5.5.1.m1.1.1.4.2.cmml" xref="S5.T1.5.5.5.1.m1.1.1.4.2">𝑁</ci><ci id="S5.T1.5.5.5.1.m1.1.1.4.3.cmml" xref="S5.T1.5.5.5.1.m1.1.1.4.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.1.m1.1c">GCN_{s}</annotation></semantics></math> with <math id="S5.T1.6.6.6.2.m2.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.T1.6.6.6.2.m2.1a"><msub id="S5.T1.6.6.6.2.m2.1.1" xref="S5.T1.6.6.6.2.m2.1.1.cmml"><mi id="S5.T1.6.6.6.2.m2.1.1.2" xref="S5.T1.6.6.6.2.m2.1.1.2.cmml">B</mi><mi id="S5.T1.6.6.6.2.m2.1.1.3" xref="S5.T1.6.6.6.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.2.m2.1b"><apply id="S5.T1.6.6.6.2.m2.1.1.cmml" xref="S5.T1.6.6.6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T1.6.6.6.2.m2.1.1.1.cmml" xref="S5.T1.6.6.6.2.m2.1.1">subscript</csymbol><ci id="S5.T1.6.6.6.2.m2.1.1.2.cmml" xref="S5.T1.6.6.6.2.m2.1.1.2">𝐵</ci><ci id="S5.T1.6.6.6.2.m2.1.1.3.cmml" xref="S5.T1.6.6.6.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.2.m2.1c">B_{k}</annotation></semantics></math>
</th>
<td id="S5.T1.6.6.6.3" class="ltx_td ltx_align_center">47.3</td>
<td id="S5.T1.6.6.6.4" class="ltx_td ltx_align_center">36.2</td>
</tr>
<tr id="S5.T1.8.8.8" class="ltx_tr">
<th id="S5.T1.8.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">+ Global <math id="S5.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="GCN_{s}" display="inline"><semantics id="S5.T1.7.7.7.1.m1.1a"><mrow id="S5.T1.7.7.7.1.m1.1.1" xref="S5.T1.7.7.7.1.m1.1.1.cmml"><mi id="S5.T1.7.7.7.1.m1.1.1.2" xref="S5.T1.7.7.7.1.m1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S5.T1.7.7.7.1.m1.1.1.1" xref="S5.T1.7.7.7.1.m1.1.1.1.cmml">​</mo><mi id="S5.T1.7.7.7.1.m1.1.1.3" xref="S5.T1.7.7.7.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.T1.7.7.7.1.m1.1.1.1a" xref="S5.T1.7.7.7.1.m1.1.1.1.cmml">​</mo><msub id="S5.T1.7.7.7.1.m1.1.1.4" xref="S5.T1.7.7.7.1.m1.1.1.4.cmml"><mi id="S5.T1.7.7.7.1.m1.1.1.4.2" xref="S5.T1.7.7.7.1.m1.1.1.4.2.cmml">N</mi><mi id="S5.T1.7.7.7.1.m1.1.1.4.3" xref="S5.T1.7.7.7.1.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.7.1.m1.1b"><apply id="S5.T1.7.7.7.1.m1.1.1.cmml" xref="S5.T1.7.7.7.1.m1.1.1"><times id="S5.T1.7.7.7.1.m1.1.1.1.cmml" xref="S5.T1.7.7.7.1.m1.1.1.1"></times><ci id="S5.T1.7.7.7.1.m1.1.1.2.cmml" xref="S5.T1.7.7.7.1.m1.1.1.2">𝐺</ci><ci id="S5.T1.7.7.7.1.m1.1.1.3.cmml" xref="S5.T1.7.7.7.1.m1.1.1.3">𝐶</ci><apply id="S5.T1.7.7.7.1.m1.1.1.4.cmml" xref="S5.T1.7.7.7.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.T1.7.7.7.1.m1.1.1.4.1.cmml" xref="S5.T1.7.7.7.1.m1.1.1.4">subscript</csymbol><ci id="S5.T1.7.7.7.1.m1.1.1.4.2.cmml" xref="S5.T1.7.7.7.1.m1.1.1.4.2">𝑁</ci><ci id="S5.T1.7.7.7.1.m1.1.1.4.3.cmml" xref="S5.T1.7.7.7.1.m1.1.1.4.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.7.1.m1.1c">GCN_{s}</annotation></semantics></math> with <math id="S5.T1.8.8.8.2.m2.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S5.T1.8.8.8.2.m2.1a"><msub id="S5.T1.8.8.8.2.m2.1.1" xref="S5.T1.8.8.8.2.m2.1.1.cmml"><mi id="S5.T1.8.8.8.2.m2.1.1.2" xref="S5.T1.8.8.8.2.m2.1.1.2.cmml">C</mi><mi id="S5.T1.8.8.8.2.m2.1.1.3" xref="S5.T1.8.8.8.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.8.2.m2.1b"><apply id="S5.T1.8.8.8.2.m2.1.1.cmml" xref="S5.T1.8.8.8.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T1.8.8.8.2.m2.1.1.1.cmml" xref="S5.T1.8.8.8.2.m2.1.1">subscript</csymbol><ci id="S5.T1.8.8.8.2.m2.1.1.2.cmml" xref="S5.T1.8.8.8.2.m2.1.1.2">𝐶</ci><ci id="S5.T1.8.8.8.2.m2.1.1.3.cmml" xref="S5.T1.8.8.8.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.8.2.m2.1c">C_{k}</annotation></semantics></math>
</th>
<td id="S5.T1.8.8.8.3" class="ltx_td ltx_align_center ltx_border_bb">46.2</td>
<td id="S5.T1.8.8.8.4" class="ltx_td ltx_align_center ltx_border_bb">36.0</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table II: </span>Ablation study on the sensitivity of spatial semantics in our model on Human3.6M under Protocol # 1.</figcaption>
<table id="S5.T2.5.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt">Method (T=27, CPN)</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">MPJPE(mm)</th>
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><math id="S5.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="S5.T2.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\Delta</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.3.3.3" class="ltx_tr">
<td id="S5.T2.3.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Ours w/o Local <math id="S5.T2.2.2.2.1.m1.1" class="ltx_Math" alttext="GCN_{s}" display="inline"><semantics id="S5.T2.2.2.2.1.m1.1a"><mrow id="S5.T2.2.2.2.1.m1.1.1" xref="S5.T2.2.2.2.1.m1.1.1.cmml"><mi id="S5.T2.2.2.2.1.m1.1.1.2" xref="S5.T2.2.2.2.1.m1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S5.T2.2.2.2.1.m1.1.1.1" xref="S5.T2.2.2.2.1.m1.1.1.1.cmml">​</mo><mi id="S5.T2.2.2.2.1.m1.1.1.3" xref="S5.T2.2.2.2.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.T2.2.2.2.1.m1.1.1.1a" xref="S5.T2.2.2.2.1.m1.1.1.1.cmml">​</mo><msub id="S5.T2.2.2.2.1.m1.1.1.4" xref="S5.T2.2.2.2.1.m1.1.1.4.cmml"><mi id="S5.T2.2.2.2.1.m1.1.1.4.2" xref="S5.T2.2.2.2.1.m1.1.1.4.2.cmml">N</mi><mi id="S5.T2.2.2.2.1.m1.1.1.4.3" xref="S5.T2.2.2.2.1.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.1.m1.1b"><apply id="S5.T2.2.2.2.1.m1.1.1.cmml" xref="S5.T2.2.2.2.1.m1.1.1"><times id="S5.T2.2.2.2.1.m1.1.1.1.cmml" xref="S5.T2.2.2.2.1.m1.1.1.1"></times><ci id="S5.T2.2.2.2.1.m1.1.1.2.cmml" xref="S5.T2.2.2.2.1.m1.1.1.2">𝐺</ci><ci id="S5.T2.2.2.2.1.m1.1.1.3.cmml" xref="S5.T2.2.2.2.1.m1.1.1.3">𝐶</ci><apply id="S5.T2.2.2.2.1.m1.1.1.4.cmml" xref="S5.T2.2.2.2.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.T2.2.2.2.1.m1.1.1.4.1.cmml" xref="S5.T2.2.2.2.1.m1.1.1.4">subscript</csymbol><ci id="S5.T2.2.2.2.1.m1.1.1.4.2.cmml" xref="S5.T2.2.2.2.1.m1.1.1.4.2">𝑁</ci><ci id="S5.T2.2.2.2.1.m1.1.1.4.3.cmml" xref="S5.T2.2.2.2.1.m1.1.1.4.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.1.m1.1c">GCN_{s}</annotation></semantics></math> with <math id="S5.T2.3.3.3.2.m2.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S5.T2.3.3.3.2.m2.1a"><msub id="S5.T2.3.3.3.2.m2.1.1" xref="S5.T2.3.3.3.2.m2.1.1.cmml"><mover accent="true" id="S5.T2.3.3.3.2.m2.1.1.2" xref="S5.T2.3.3.3.2.m2.1.1.2.cmml"><mi id="S5.T2.3.3.3.2.m2.1.1.2.2" xref="S5.T2.3.3.3.2.m2.1.1.2.2.cmml">A</mi><mo id="S5.T2.3.3.3.2.m2.1.1.2.1" xref="S5.T2.3.3.3.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S5.T2.3.3.3.2.m2.1.1.3" xref="S5.T2.3.3.3.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.2.m2.1b"><apply id="S5.T2.3.3.3.2.m2.1.1.cmml" xref="S5.T2.3.3.3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T2.3.3.3.2.m2.1.1.1.cmml" xref="S5.T2.3.3.3.2.m2.1.1">subscript</csymbol><apply id="S5.T2.3.3.3.2.m2.1.1.2.cmml" xref="S5.T2.3.3.3.2.m2.1.1.2"><ci id="S5.T2.3.3.3.2.m2.1.1.2.1.cmml" xref="S5.T2.3.3.3.2.m2.1.1.2.1">~</ci><ci id="S5.T2.3.3.3.2.m2.1.1.2.2.cmml" xref="S5.T2.3.3.3.2.m2.1.1.2.2">𝐴</ci></apply><ci id="S5.T2.3.3.3.2.m2.1.1.3.cmml" xref="S5.T2.3.3.3.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.2.m2.1c">\widetilde{A}_{c}</annotation></semantics></math>
</td>
<td id="S5.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.6</td>
<td id="S5.T2.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">1.4</td>
</tr>
<tr id="S5.T2.5.5.5" class="ltx_tr">
<td id="S5.T2.5.5.5.2" class="ltx_td ltx_align_left ltx_border_r">Ours w/o Local <math id="S5.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="GCN_{s}" display="inline"><semantics id="S5.T2.4.4.4.1.m1.1a"><mrow id="S5.T2.4.4.4.1.m1.1.1" xref="S5.T2.4.4.4.1.m1.1.1.cmml"><mi id="S5.T2.4.4.4.1.m1.1.1.2" xref="S5.T2.4.4.4.1.m1.1.1.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S5.T2.4.4.4.1.m1.1.1.1" xref="S5.T2.4.4.4.1.m1.1.1.1.cmml">​</mo><mi id="S5.T2.4.4.4.1.m1.1.1.3" xref="S5.T2.4.4.4.1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S5.T2.4.4.4.1.m1.1.1.1a" xref="S5.T2.4.4.4.1.m1.1.1.1.cmml">​</mo><msub id="S5.T2.4.4.4.1.m1.1.1.4" xref="S5.T2.4.4.4.1.m1.1.1.4.cmml"><mi id="S5.T2.4.4.4.1.m1.1.1.4.2" xref="S5.T2.4.4.4.1.m1.1.1.4.2.cmml">N</mi><mi id="S5.T2.4.4.4.1.m1.1.1.4.3" xref="S5.T2.4.4.4.1.m1.1.1.4.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.1.m1.1b"><apply id="S5.T2.4.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.4.1.m1.1.1"><times id="S5.T2.4.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.4.1.m1.1.1.1"></times><ci id="S5.T2.4.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.4.1.m1.1.1.2">𝐺</ci><ci id="S5.T2.4.4.4.1.m1.1.1.3.cmml" xref="S5.T2.4.4.4.1.m1.1.1.3">𝐶</ci><apply id="S5.T2.4.4.4.1.m1.1.1.4.cmml" xref="S5.T2.4.4.4.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.T2.4.4.4.1.m1.1.1.4.1.cmml" xref="S5.T2.4.4.4.1.m1.1.1.4">subscript</csymbol><ci id="S5.T2.4.4.4.1.m1.1.1.4.2.cmml" xref="S5.T2.4.4.4.1.m1.1.1.4.2">𝑁</ci><ci id="S5.T2.4.4.4.1.m1.1.1.4.3.cmml" xref="S5.T2.4.4.4.1.m1.1.1.4.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.1.m1.1c">GCN_{s}</annotation></semantics></math> with <math id="S5.T2.5.5.5.2.m2.1" class="ltx_Math" alttext="\widetilde{A}_{s}" display="inline"><semantics id="S5.T2.5.5.5.2.m2.1a"><msub id="S5.T2.5.5.5.2.m2.1.1" xref="S5.T2.5.5.5.2.m2.1.1.cmml"><mover accent="true" id="S5.T2.5.5.5.2.m2.1.1.2" xref="S5.T2.5.5.5.2.m2.1.1.2.cmml"><mi id="S5.T2.5.5.5.2.m2.1.1.2.2" xref="S5.T2.5.5.5.2.m2.1.1.2.2.cmml">A</mi><mo id="S5.T2.5.5.5.2.m2.1.1.2.1" xref="S5.T2.5.5.5.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S5.T2.5.5.5.2.m2.1.1.3" xref="S5.T2.5.5.5.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.2.m2.1b"><apply id="S5.T2.5.5.5.2.m2.1.1.cmml" xref="S5.T2.5.5.5.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T2.5.5.5.2.m2.1.1.1.cmml" xref="S5.T2.5.5.5.2.m2.1.1">subscript</csymbol><apply id="S5.T2.5.5.5.2.m2.1.1.2.cmml" xref="S5.T2.5.5.5.2.m2.1.1.2"><ci id="S5.T2.5.5.5.2.m2.1.1.2.1.cmml" xref="S5.T2.5.5.5.2.m2.1.1.2.1">~</ci><ci id="S5.T2.5.5.5.2.m2.1.1.2.2.cmml" xref="S5.T2.5.5.5.2.m2.1.1.2.2">𝐴</ci></apply><ci id="S5.T2.5.5.5.2.m2.1.1.3.cmml" xref="S5.T2.5.5.5.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.2.m2.1c">\widetilde{A}_{s}</annotation></semantics></math>
</td>
<td id="S5.T2.5.5.5.3" class="ltx_td ltx_align_center ltx_border_r">47.4</td>
<td id="S5.T2.5.5.5.4" class="ltx_td ltx_align_center">1.2</td>
</tr>
<tr id="S5.T2.5.5.6.1" class="ltx_tr">
<td id="S5.T2.5.5.6.1.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">Ours (GAST-Net)</td>
<td id="S5.T2.5.5.6.1.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">46.2</td>
<td id="S5.T2.5.5.6.1.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">-</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.4" class="ltx_p">We perform ablation studies to analyze the effect of spatial semantics in our networks architecture as shown in Table <a href="#S5.T1" title="Table I ‣ V-B1 Effects of Spatial Semantics ‣ V-B Ablation Studies ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. As the baseline, we build a plain GAST-Net comprised of TCNs and first-order SemGCNs to regress 2D keypoints to 3D poses. We then add different semantic GCNs one-by-one to conduct ablation studies. The semantics consist of:
(i) local kinematic relations <math id="S5.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S5.SS2.SSS1.p1.1.m1.1a"><msub id="S5.SS2.SSS1.p1.1.m1.1.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.cmml"><mover accent="true" id="S5.SS2.SSS1.p1.1.m1.1.1.2" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml"><mi id="S5.SS2.SSS1.p1.1.m1.1.1.2.2" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.2.cmml">A</mi><mo id="S5.SS2.SSS1.p1.1.m1.1.1.2.1" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.1.cmml">~</mo></mover><mi id="S5.SS2.SSS1.p1.1.m1.1.1.3" xref="S5.SS2.SSS1.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.1.m1.1b"><apply id="S5.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1">subscript</csymbol><apply id="S5.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.2"><ci id="S5.SS2.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.1">~</ci><ci id="S5.SS2.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.2.2">𝐴</ci></apply><ci id="S5.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS1.p1.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.1.m1.1c">\widetilde{A}_{c}</annotation></semantics></math>,
(ii) symmetric relations <math id="S5.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\widetilde{A}_{s}" display="inline"><semantics id="S5.SS2.SSS1.p1.2.m2.1a"><msub id="S5.SS2.SSS1.p1.2.m2.1.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.cmml"><mover accent="true" id="S5.SS2.SSS1.p1.2.m2.1.1.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml"><mi id="S5.SS2.SSS1.p1.2.m2.1.1.2.2" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.2.cmml">A</mi><mo id="S5.SS2.SSS1.p1.2.m2.1.1.2.1" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml">~</mo></mover><mi id="S5.SS2.SSS1.p1.2.m2.1.1.3" xref="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.2.m2.1b"><apply id="S5.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><apply id="S5.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2"><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.1">~</ci><ci id="S5.SS2.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.2.2">𝐴</ci></apply><ci id="S5.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS1.p1.2.m2.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.2.m2.1c">\widetilde{A}_{s}</annotation></semantics></math>,
(ii) global adaptive matrix <math id="S5.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.SS2.SSS1.p1.3.m3.1a"><msub id="S5.SS2.SSS1.p1.3.m3.1.1" xref="S5.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S5.SS2.SSS1.p1.3.m3.1.1.2" xref="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml">B</mi><mi id="S5.SS2.SSS1.p1.3.m3.1.1.3" xref="S5.SS2.SSS1.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.3.m3.1b"><apply id="S5.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.2">𝐵</ci><ci id="S5.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS1.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.3.m3.1c">B_{k}</annotation></semantics></math>, and
(iv) global learnable matrix <math id="S5.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S5.SS2.SSS1.p1.4.m4.1a"><msub id="S5.SS2.SSS1.p1.4.m4.1.1" xref="S5.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S5.SS2.SSS1.p1.4.m4.1.1.2" xref="S5.SS2.SSS1.p1.4.m4.1.1.2.cmml">C</mi><mi id="S5.SS2.SSS1.p1.4.m4.1.1.3" xref="S5.SS2.SSS1.p1.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS1.p1.4.m4.1b"><apply id="S5.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S5.SS2.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S5.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S5.SS2.SSS1.p1.4.m4.1.1.2">𝐶</ci><ci id="S5.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S5.SS2.SSS1.p1.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS1.p1.4.m4.1c">C_{k}</annotation></semantics></math>.
We see that as we consider additional local-to-global postural constraints, the performance improves steadily. The largest improvements come from local kinematic connections, symmetry, and the global adaptive matrix. These spatial constraints exactly express a hierarchical and symmetrical human structure and conveys global posture semantics, which better reconstructs valid 3D poses. These results support the significance of rich spatial semantics in 3D pose estimation.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS2.5.1.1" class="ltx_text">V-B</span>2 </span>Sensitivity Analysis of Spatial Semantics</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.4" class="ltx_p">Global graph matrices (<math id="S5.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.SS2.SSS2.p1.1.m1.1a"><msub id="S5.SS2.SSS2.p1.1.m1.1.1" xref="S5.SS2.SSS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.SSS2.p1.1.m1.1.1.2" xref="S5.SS2.SSS2.p1.1.m1.1.1.2.cmml">B</mi><mi id="S5.SS2.SSS2.p1.1.m1.1.1.3" xref="S5.SS2.SSS2.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.1.m1.1b"><apply id="S5.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.2">𝐵</ci><ci id="S5.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.SSS2.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.1.m1.1c">B_{k}</annotation></semantics></math> and <math id="S5.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S5.SS2.SSS2.p1.2.m2.1a"><msub id="S5.SS2.SSS2.p1.2.m2.1.1" xref="S5.SS2.SSS2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.SSS2.p1.2.m2.1.1.2" xref="S5.SS2.SSS2.p1.2.m2.1.1.2.cmml">C</mi><mi id="S5.SS2.SSS2.p1.2.m2.1.1.3" xref="S5.SS2.SSS2.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.2.m2.1b"><apply id="S5.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.2">𝐶</ci><ci id="S5.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.SSS2.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.2.m2.1c">C_{k}</annotation></semantics></math>) encompass both local and symmetric joint relations. We wish to explore the contributions of each of these configurations under the global analysis. To this end, we study the effect of removing local kinematic connections <math id="S5.SS2.SSS2.p1.3.m3.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S5.SS2.SSS2.p1.3.m3.1a"><msub id="S5.SS2.SSS2.p1.3.m3.1.1" xref="S5.SS2.SSS2.p1.3.m3.1.1.cmml"><mover accent="true" id="S5.SS2.SSS2.p1.3.m3.1.1.2" xref="S5.SS2.SSS2.p1.3.m3.1.1.2.cmml"><mi id="S5.SS2.SSS2.p1.3.m3.1.1.2.2" xref="S5.SS2.SSS2.p1.3.m3.1.1.2.2.cmml">A</mi><mo id="S5.SS2.SSS2.p1.3.m3.1.1.2.1" xref="S5.SS2.SSS2.p1.3.m3.1.1.2.1.cmml">~</mo></mover><mi id="S5.SS2.SSS2.p1.3.m3.1.1.3" xref="S5.SS2.SSS2.p1.3.m3.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.3.m3.1b"><apply id="S5.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1">subscript</csymbol><apply id="S5.SS2.SSS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.2"><ci id="S5.SS2.SSS2.p1.3.m3.1.1.2.1.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.2.1">~</ci><ci id="S5.SS2.SSS2.p1.3.m3.1.1.2.2.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.2.2">𝐴</ci></apply><ci id="S5.SS2.SSS2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.SSS2.p1.3.m3.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.3.m3.1c">\widetilde{A}_{c}</annotation></semantics></math> and symmetry <math id="S5.SS2.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\widetilde{A}_{s}" display="inline"><semantics id="S5.SS2.SSS2.p1.4.m4.1a"><msub id="S5.SS2.SSS2.p1.4.m4.1.1" xref="S5.SS2.SSS2.p1.4.m4.1.1.cmml"><mover accent="true" id="S5.SS2.SSS2.p1.4.m4.1.1.2" xref="S5.SS2.SSS2.p1.4.m4.1.1.2.cmml"><mi id="S5.SS2.SSS2.p1.4.m4.1.1.2.2" xref="S5.SS2.SSS2.p1.4.m4.1.1.2.2.cmml">A</mi><mo id="S5.SS2.SSS2.p1.4.m4.1.1.2.1" xref="S5.SS2.SSS2.p1.4.m4.1.1.2.1.cmml">~</mo></mover><mi id="S5.SS2.SSS2.p1.4.m4.1.1.3" xref="S5.SS2.SSS2.p1.4.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS2.p1.4.m4.1b"><apply id="S5.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS2.p1.4.m4.1.1.1.cmml" xref="S5.SS2.SSS2.p1.4.m4.1.1">subscript</csymbol><apply id="S5.SS2.SSS2.p1.4.m4.1.1.2.cmml" xref="S5.SS2.SSS2.p1.4.m4.1.1.2"><ci id="S5.SS2.SSS2.p1.4.m4.1.1.2.1.cmml" xref="S5.SS2.SSS2.p1.4.m4.1.1.2.1">~</ci><ci id="S5.SS2.SSS2.p1.4.m4.1.1.2.2.cmml" xref="S5.SS2.SSS2.p1.4.m4.1.1.2.2">𝐴</ci></apply><ci id="S5.SS2.SSS2.p1.4.m4.1.1.3.cmml" xref="S5.SS2.SSS2.p1.4.m4.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS2.p1.4.m4.1c">\widetilde{A}_{s}</annotation></semantics></math> separately on the Human3.6M as shown in Table <a href="#S5.T2" title="Table II ‣ V-B1 Effects of Spatial Semantics ‣ V-B Ablation Studies ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.
The study reveals that removing local connections and symmetry increase errors by 1.4mm and 1.2mm respectively. From this we conclude that explicitly embedding local connections and symmetrical prior knowledge is indispensable and complementary to global semantics in generating more accurate 3D poses.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Quantitative Results</span>
</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table III: </span>Quantitative comparisons of MPJPE in millimeters between the estimated pose and the ground-truth (GT) on the Human3.6M under Protocol #1 and Protocol #2. <math id="S5.T3.3.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.T3.3.m1.1b"><mi id="S5.T3.3.m1.1.1" xref="S5.T3.3.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.T3.3.m1.1c"><ci id="S5.T3.3.m1.1.1.cmml" xref="S5.T3.3.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.m1.1d">T</annotation></semantics></math> denotes the number of receptive fields, <math id="S5.T3.4.m2.1" class="ltx_Math" alttext="({\dagger})" display="inline"><semantics id="S5.T3.4.m2.1b"><mrow id="S5.T3.4.m2.1.2.2"><mo stretchy="false" id="S5.T3.4.m2.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1" xref="S5.T3.4.m2.1.1.cmml">†</mo><mo stretchy="false" id="S5.T3.4.m2.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.4.m2.1c"><ci id="S5.T3.4.m2.1.1.cmml" xref="S5.T3.4.m2.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.m2.1d">({\dagger})</annotation></semantics></math> indicates the use of pose refinement and spatio-temporal information. Best in bold, second best underlined.</figcaption>
<div id="S5.T3.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:420.6pt;height:194.6pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-179.7pt,82.9pt) scale(0.539245053251608,0.539245053251608) ;">
<table id="S5.T3.8.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.8.4.5.1" class="ltx_tr">
<th id="S5.T3.8.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt">Protocol #1</th>
<td id="S5.T3.8.4.5.1.2" class="ltx_td ltx_align_center ltx_border_tt">Dir.</td>
<td id="S5.T3.8.4.5.1.3" class="ltx_td ltx_align_center ltx_border_tt">Disc.</td>
<td id="S5.T3.8.4.5.1.4" class="ltx_td ltx_align_center ltx_border_tt">Eat</td>
<td id="S5.T3.8.4.5.1.5" class="ltx_td ltx_align_center ltx_border_tt">Greet</td>
<td id="S5.T3.8.4.5.1.6" class="ltx_td ltx_align_center ltx_border_tt">Phone</td>
<td id="S5.T3.8.4.5.1.7" class="ltx_td ltx_align_center ltx_border_tt">Photo</td>
<td id="S5.T3.8.4.5.1.8" class="ltx_td ltx_align_center ltx_border_tt">Pose</td>
<td id="S5.T3.8.4.5.1.9" class="ltx_td ltx_align_center ltx_border_tt">Purch.</td>
<td id="S5.T3.8.4.5.1.10" class="ltx_td ltx_align_center ltx_border_tt">Sit</td>
<td id="S5.T3.8.4.5.1.11" class="ltx_td ltx_align_center ltx_border_tt">SitD.</td>
<td id="S5.T3.8.4.5.1.12" class="ltx_td ltx_align_center ltx_border_tt">Smoke</td>
<td id="S5.T3.8.4.5.1.13" class="ltx_td ltx_align_center ltx_border_tt">Wait</td>
<td id="S5.T3.8.4.5.1.14" class="ltx_td ltx_align_center ltx_border_tt">WalkD.</td>
<td id="S5.T3.8.4.5.1.15" class="ltx_td ltx_align_center ltx_border_tt">Walk</td>
<td id="S5.T3.8.4.5.1.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">WalkT.</td>
<td id="S5.T3.8.4.5.1.17" class="ltx_td ltx_align_center ltx_border_tt">Avg</td>
</tr>
<tr id="S5.T3.8.4.6.2" class="ltx_tr">
<th id="S5.T3.8.4.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Hossain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S5.T3.8.4.6.2.2" class="ltx_td ltx_align_center ltx_border_t">48.4</td>
<td id="S5.T3.8.4.6.2.3" class="ltx_td ltx_align_center ltx_border_t">50.7</td>
<td id="S5.T3.8.4.6.2.4" class="ltx_td ltx_align_center ltx_border_t">57.2</td>
<td id="S5.T3.8.4.6.2.5" class="ltx_td ltx_align_center ltx_border_t">55.2</td>
<td id="S5.T3.8.4.6.2.6" class="ltx_td ltx_align_center ltx_border_t">63.1</td>
<td id="S5.T3.8.4.6.2.7" class="ltx_td ltx_align_center ltx_border_t">72.6</td>
<td id="S5.T3.8.4.6.2.8" class="ltx_td ltx_align_center ltx_border_t">53.0</td>
<td id="S5.T3.8.4.6.2.9" class="ltx_td ltx_align_center ltx_border_t">51.7</td>
<td id="S5.T3.8.4.6.2.10" class="ltx_td ltx_align_center ltx_border_t">66.1</td>
<td id="S5.T3.8.4.6.2.11" class="ltx_td ltx_align_center ltx_border_t">80.9</td>
<td id="S5.T3.8.4.6.2.12" class="ltx_td ltx_align_center ltx_border_t">59.0</td>
<td id="S5.T3.8.4.6.2.13" class="ltx_td ltx_align_center ltx_border_t">57.3</td>
<td id="S5.T3.8.4.6.2.14" class="ltx_td ltx_align_center ltx_border_t">62.4</td>
<td id="S5.T3.8.4.6.2.15" class="ltx_td ltx_align_center ltx_border_t">46.6</td>
<td id="S5.T3.8.4.6.2.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.6</td>
<td id="S5.T3.8.4.6.2.17" class="ltx_td ltx_align_center ltx_border_t">58.3</td>
</tr>
<tr id="S5.T3.5.1.1" class="ltx_tr">
<th id="S5.T3.5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Cai <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> (<math id="S5.T3.5.1.1.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S5.T3.5.1.1.1.m1.1a"><mo id="S5.T3.5.1.1.1.m1.1.1" xref="S5.T3.5.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.1.1.1.m1.1b"><ci id="S5.T3.5.1.1.1.m1.1.1.cmml" xref="S5.T3.5.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.1.1.1.m1.1c">{\dagger}</annotation></semantics></math>)</th>
<td id="S5.T3.5.1.1.2" class="ltx_td ltx_align_center">44.6</td>
<td id="S5.T3.5.1.1.3" class="ltx_td ltx_align_center">47.4</td>
<td id="S5.T3.5.1.1.4" class="ltx_td ltx_align_center">45.6</td>
<td id="S5.T3.5.1.1.5" class="ltx_td ltx_align_center">48.8</td>
<td id="S5.T3.5.1.1.6" class="ltx_td ltx_align_center">50.8</td>
<td id="S5.T3.5.1.1.7" class="ltx_td ltx_align_center">59.0</td>
<td id="S5.T3.5.1.1.8" class="ltx_td ltx_align_center">47.2</td>
<td id="S5.T3.5.1.1.9" class="ltx_td ltx_align_center">43.9</td>
<td id="S5.T3.5.1.1.10" class="ltx_td ltx_align_center">57.9</td>
<td id="S5.T3.5.1.1.11" class="ltx_td ltx_align_center">61.9</td>
<td id="S5.T3.5.1.1.12" class="ltx_td ltx_align_center">49.7</td>
<td id="S5.T3.5.1.1.13" class="ltx_td ltx_align_center">46.6</td>
<td id="S5.T3.5.1.1.14" class="ltx_td ltx_align_center">51.3</td>
<td id="S5.T3.5.1.1.15" class="ltx_td ltx_align_center">37.1</td>
<td id="S5.T3.5.1.1.16" class="ltx_td ltx_align_center ltx_border_r">39.4</td>
<td id="S5.T3.5.1.1.17" class="ltx_td ltx_align_center">48.8</td>
</tr>
<tr id="S5.T3.8.4.7.3" class="ltx_tr">
<th id="S5.T3.8.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Pavllo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S5.T3.8.4.7.3.2" class="ltx_td ltx_align_center">45.2</td>
<td id="S5.T3.8.4.7.3.3" class="ltx_td ltx_align_center">46.7</td>
<td id="S5.T3.8.4.7.3.4" class="ltx_td ltx_align_center">43.3</td>
<td id="S5.T3.8.4.7.3.5" class="ltx_td ltx_align_center">45.6</td>
<td id="S5.T3.8.4.7.3.6" class="ltx_td ltx_align_center">48.1</td>
<td id="S5.T3.8.4.7.3.7" class="ltx_td ltx_align_center">55.1</td>
<td id="S5.T3.8.4.7.3.8" class="ltx_td ltx_align_center">44.6</td>
<td id="S5.T3.8.4.7.3.9" class="ltx_td ltx_align_center">44.3</td>
<td id="S5.T3.8.4.7.3.10" class="ltx_td ltx_align_center">57.3</td>
<td id="S5.T3.8.4.7.3.11" class="ltx_td ltx_align_center">65.8</td>
<td id="S5.T3.8.4.7.3.12" class="ltx_td ltx_align_center">47.1</td>
<td id="S5.T3.8.4.7.3.13" class="ltx_td ltx_align_center">44.0</td>
<td id="S5.T3.8.4.7.3.14" class="ltx_td ltx_align_center">49.0</td>
<td id="S5.T3.8.4.7.3.15" class="ltx_td ltx_align_center">32.8</td>
<td id="S5.T3.8.4.7.3.16" class="ltx_td ltx_align_center ltx_border_r">33.9</td>
<td id="S5.T3.8.4.7.3.17" class="ltx_td ltx_align_center">46.8</td>
</tr>
<tr id="S5.T3.8.4.8.4" class="ltx_tr">
<th id="S5.T3.8.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Lin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</th>
<td id="S5.T3.8.4.8.4.2" class="ltx_td ltx_align_center">42.5</td>
<td id="S5.T3.8.4.8.4.3" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.8.4.3.1" class="ltx_ERROR undefined">\ul</span>44.8</td>
<td id="S5.T3.8.4.8.4.4" class="ltx_td ltx_align_center">42.6</td>
<td id="S5.T3.8.4.8.4.5" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.8.4.5.1" class="ltx_ERROR undefined">\ul</span>44.2</td>
<td id="S5.T3.8.4.8.4.6" class="ltx_td ltx_align_center">48.5</td>
<td id="S5.T3.8.4.8.4.7" class="ltx_td ltx_align_center">57.1</td>
<td id="S5.T3.8.4.8.4.8" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.8.4.8.1" class="ltx_ERROR undefined">\ul</span>42.6</td>
<td id="S5.T3.8.4.8.4.9" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.9.1" class="ltx_text ltx_font_bold">41.4</span></td>
<td id="S5.T3.8.4.8.4.10" class="ltx_td ltx_align_center">56.5</td>
<td id="S5.T3.8.4.8.4.11" class="ltx_td ltx_align_center">64.5</td>
<td id="S5.T3.8.4.8.4.12" class="ltx_td ltx_align_center">47.4</td>
<td id="S5.T3.8.4.8.4.13" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.8.4.13.1" class="ltx_ERROR undefined">\ul</span>43.0</td>
<td id="S5.T3.8.4.8.4.14" class="ltx_td ltx_align_center">48.1</td>
<td id="S5.T3.8.4.8.4.15" class="ltx_td ltx_align_center">33.0</td>
<td id="S5.T3.8.4.8.4.16" class="ltx_td ltx_align_center ltx_border_r">35.1</td>
<td id="S5.T3.8.4.8.4.17" class="ltx_td ltx_align_center">46.6</td>
</tr>
<tr id="S5.T3.8.4.9.5" class="ltx_tr">
<th id="S5.T3.8.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Liu <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</th>
<td id="S5.T3.8.4.9.5.2" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.2.1" class="ltx_ERROR undefined">\ul</span>41.8</td>
<td id="S5.T3.8.4.9.5.3" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.3.1" class="ltx_ERROR undefined">\ul</span>44.8</td>
<td id="S5.T3.8.4.9.5.4" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.4.1" class="ltx_ERROR undefined">\ul</span>41.1</td>
<td id="S5.T3.8.4.9.5.5" class="ltx_td ltx_align_center">44.9</td>
<td id="S5.T3.8.4.9.5.6" class="ltx_td ltx_align_center">47.4</td>
<td id="S5.T3.8.4.9.5.7" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.7.1" class="ltx_ERROR undefined">\ul</span>54.1</td>
<td id="S5.T3.8.4.9.5.8" class="ltx_td ltx_align_center">43.4</td>
<td id="S5.T3.8.4.9.5.9" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.9.1" class="ltx_ERROR undefined">\ul</span>42.2</td>
<td id="S5.T3.8.4.9.5.10" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.10.1" class="ltx_ERROR undefined">\ul</span>56.2</td>
<td id="S5.T3.8.4.9.5.11" class="ltx_td ltx_align_center">63.6</td>
<td id="S5.T3.8.4.9.5.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.12.1" class="ltx_text ltx_font_bold">45.3</span></td>
<td id="S5.T3.8.4.9.5.13" class="ltx_td ltx_align_center">43.5</td>
<td id="S5.T3.8.4.9.5.14" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.14.1" class="ltx_text ltx_font_bold">45.3</span></td>
<td id="S5.T3.8.4.9.5.15" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.9.5.15.1" class="ltx_ERROR undefined">\ul</span>31.3</td>
<td id="S5.T3.8.4.9.5.16" class="ltx_td ltx_align_center ltx_border_r">32.2</td>
<td id="S5.T3.8.4.9.5.17" class="ltx_td ltx_align_center">45.1</td>
</tr>
<tr id="S5.T3.6.2.2" class="ltx_tr">
<th id="S5.T3.6.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Wang <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> (<math id="S5.T3.6.2.2.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S5.T3.6.2.2.1.m1.1a"><mo id="S5.T3.6.2.2.1.m1.1.1" xref="S5.T3.6.2.2.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.2.2.1.m1.1b"><ci id="S5.T3.6.2.2.1.m1.1.1.cmml" xref="S5.T3.6.2.2.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.2.2.1.m1.1c">{\dagger}</annotation></semantics></math>)</th>
<td id="S5.T3.6.2.2.2" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.2.1" class="ltx_text ltx_font_bold">40.2</span></td>
<td id="S5.T3.6.2.2.3" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.3.1" class="ltx_text ltx_font_bold">42.5</span></td>
<td id="S5.T3.6.2.2.4" class="ltx_td ltx_align_center">42.6</td>
<td id="S5.T3.6.2.2.5" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.5.1" class="ltx_text ltx_font_bold">41.1</span></td>
<td id="S5.T3.6.2.2.6" class="ltx_td ltx_align_center">
<span id="S5.T3.6.2.2.6.1" class="ltx_ERROR undefined">\ul</span>46.7</td>
<td id="S5.T3.6.2.2.7" class="ltx_td ltx_align_center">56.7</td>
<td id="S5.T3.6.2.2.8" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.8.1" class="ltx_text ltx_font_bold">41.4</span></td>
<td id="S5.T3.6.2.2.9" class="ltx_td ltx_align_center">42.3</td>
<td id="S5.T3.6.2.2.10" class="ltx_td ltx_align_center">
<span id="S5.T3.6.2.2.10.1" class="ltx_ERROR undefined">\ul</span>56.2</td>
<td id="S5.T3.6.2.2.11" class="ltx_td ltx_align_center">
<span id="S5.T3.6.2.2.11.1" class="ltx_ERROR undefined">\ul</span>60.4</td>
<td id="S5.T3.6.2.2.12" class="ltx_td ltx_align_center">46.3</td>
<td id="S5.T3.6.2.2.13" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.13.1" class="ltx_text ltx_font_bold">42.2</span></td>
<td id="S5.T3.6.2.2.14" class="ltx_td ltx_align_center">
<span id="S5.T3.6.2.2.14.1" class="ltx_ERROR undefined">\ul</span>46.2</td>
<td id="S5.T3.6.2.2.15" class="ltx_td ltx_align_center">31.7</td>
<td id="S5.T3.6.2.2.16" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T3.6.2.2.16.1" class="ltx_ERROR undefined">\ul</span>31.0</td>
<td id="S5.T3.6.2.2.17" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.17.1" class="ltx_text ltx_font_bold">44.5</span></td>
</tr>
<tr id="S5.T3.8.4.10.6" class="ltx_tr">
<th id="S5.T3.8.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Ours (T=243 CPN causal)</th>
<td id="S5.T3.8.4.10.6.2" class="ltx_td ltx_align_center ltx_border_t">45.5</td>
<td id="S5.T3.8.4.10.6.3" class="ltx_td ltx_align_center ltx_border_t">48.4</td>
<td id="S5.T3.8.4.10.6.4" class="ltx_td ltx_align_center ltx_border_t">43.9</td>
<td id="S5.T3.8.4.10.6.5" class="ltx_td ltx_align_center ltx_border_t">48.3</td>
<td id="S5.T3.8.4.10.6.6" class="ltx_td ltx_align_center ltx_border_t">49.3</td>
<td id="S5.T3.8.4.10.6.7" class="ltx_td ltx_align_center ltx_border_t">57.6</td>
<td id="S5.T3.8.4.10.6.8" class="ltx_td ltx_align_center ltx_border_t">45.0</td>
<td id="S5.T3.8.4.10.6.9" class="ltx_td ltx_align_center ltx_border_t">45.8</td>
<td id="S5.T3.8.4.10.6.10" class="ltx_td ltx_align_center ltx_border_t">57.3</td>
<td id="S5.T3.8.4.10.6.11" class="ltx_td ltx_align_center ltx_border_t">61.4</td>
<td id="S5.T3.8.4.10.6.12" class="ltx_td ltx_align_center ltx_border_t">49.3</td>
<td id="S5.T3.8.4.10.6.13" class="ltx_td ltx_align_center ltx_border_t">45.3</td>
<td id="S5.T3.8.4.10.6.14" class="ltx_td ltx_align_center ltx_border_t">49.6</td>
<td id="S5.T3.8.4.10.6.15" class="ltx_td ltx_align_center ltx_border_t">33.7</td>
<td id="S5.T3.8.4.10.6.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">33.4</td>
<td id="S5.T3.8.4.10.6.17" class="ltx_td ltx_align_center ltx_border_t">47.7</td>
</tr>
<tr id="S5.T3.8.4.11.7" class="ltx_tr">
<th id="S5.T3.8.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Ours (T=243 CPN)</th>
<td id="S5.T3.8.4.11.7.2" class="ltx_td ltx_align_center">43.3</td>
<td id="S5.T3.8.4.11.7.3" class="ltx_td ltx_align_center">46.1</td>
<td id="S5.T3.8.4.11.7.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.4.1" class="ltx_text ltx_font_bold">40.9</span></td>
<td id="S5.T3.8.4.11.7.5" class="ltx_td ltx_align_center">44.6</td>
<td id="S5.T3.8.4.11.7.6" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.6.1" class="ltx_text ltx_font_bold">46.6</span></td>
<td id="S5.T3.8.4.11.7.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.7.1" class="ltx_text ltx_font_bold">54.0</span></td>
<td id="S5.T3.8.4.11.7.8" class="ltx_td ltx_align_center">44.1</td>
<td id="S5.T3.8.4.11.7.9" class="ltx_td ltx_align_center">42.9</td>
<td id="S5.T3.8.4.11.7.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.10.1" class="ltx_text ltx_font_bold">55.3</span></td>
<td id="S5.T3.8.4.11.7.11" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.11.1" class="ltx_text ltx_font_bold">57.9</span></td>
<td id="S5.T3.8.4.11.7.12" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.11.7.12.1" class="ltx_ERROR undefined">\ul</span>45.8</td>
<td id="S5.T3.8.4.11.7.13" class="ltx_td ltx_align_center">43.4</td>
<td id="S5.T3.8.4.11.7.14" class="ltx_td ltx_align_center">47.3</td>
<td id="S5.T3.8.4.11.7.15" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.15.1" class="ltx_text ltx_font_bold">30.4</span></td>
<td id="S5.T3.8.4.11.7.16" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.11.7.16.1" class="ltx_text ltx_font_bold">30.3</span></td>
<td id="S5.T3.8.4.11.7.17" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.11.7.17.1" class="ltx_ERROR undefined">\ul</span>44.9</td>
</tr>
<tr id="S5.T3.8.4.12.8" class="ltx_tr">
<th id="S5.T3.8.4.12.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Ours (T=243 GT)</th>
<td id="S5.T3.8.4.12.8.2" class="ltx_td ltx_align_center ltx_border_t">30.5</td>
<td id="S5.T3.8.4.12.8.3" class="ltx_td ltx_align_center ltx_border_t">33.1</td>
<td id="S5.T3.8.4.12.8.4" class="ltx_td ltx_align_center ltx_border_t">27.6</td>
<td id="S5.T3.8.4.12.8.5" class="ltx_td ltx_align_center ltx_border_t">31.0</td>
<td id="S5.T3.8.4.12.8.6" class="ltx_td ltx_align_center ltx_border_t">31.8</td>
<td id="S5.T3.8.4.12.8.7" class="ltx_td ltx_align_center ltx_border_t">37.0</td>
<td id="S5.T3.8.4.12.8.8" class="ltx_td ltx_align_center ltx_border_t">33.2</td>
<td id="S5.T3.8.4.12.8.9" class="ltx_td ltx_align_center ltx_border_t">30.0</td>
<td id="S5.T3.8.4.12.8.10" class="ltx_td ltx_align_center ltx_border_t">35.7</td>
<td id="S5.T3.8.4.12.8.11" class="ltx_td ltx_align_center ltx_border_t">37.7</td>
<td id="S5.T3.8.4.12.8.12" class="ltx_td ltx_align_center ltx_border_t">31.4</td>
<td id="S5.T3.8.4.12.8.13" class="ltx_td ltx_align_center ltx_border_t">29.8</td>
<td id="S5.T3.8.4.12.8.14" class="ltx_td ltx_align_center ltx_border_t">31.7</td>
<td id="S5.T3.8.4.12.8.15" class="ltx_td ltx_align_center ltx_border_t">24.0</td>
<td id="S5.T3.8.4.12.8.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25.7</td>
<td id="S5.T3.8.4.12.8.17" class="ltx_td ltx_align_center ltx_border_t">31.4</td>
</tr>
<tr id="S5.T3.8.4.13.9" class="ltx_tr">
<th id="S5.T3.8.4.13.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_t">Protocol #2</th>
<td id="S5.T3.8.4.13.9.2" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Dir.</td>
<td id="S5.T3.8.4.13.9.3" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Disc.</td>
<td id="S5.T3.8.4.13.9.4" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Eat</td>
<td id="S5.T3.8.4.13.9.5" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Greet</td>
<td id="S5.T3.8.4.13.9.6" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Phone</td>
<td id="S5.T3.8.4.13.9.7" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Photo</td>
<td id="S5.T3.8.4.13.9.8" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Pose</td>
<td id="S5.T3.8.4.13.9.9" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Purch.</td>
<td id="S5.T3.8.4.13.9.10" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Sit</td>
<td id="S5.T3.8.4.13.9.11" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">SitD.</td>
<td id="S5.T3.8.4.13.9.12" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Smoke</td>
<td id="S5.T3.8.4.13.9.13" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Wait</td>
<td id="S5.T3.8.4.13.9.14" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">WalkD.</td>
<td id="S5.T3.8.4.13.9.15" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Walk</td>
<td id="S5.T3.8.4.13.9.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">WalkT.</td>
<td id="S5.T3.8.4.13.9.17" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">Avg</td>
</tr>
<tr id="S5.T3.8.4.14.10" class="ltx_tr">
<th id="S5.T3.8.4.14.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Hossain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</th>
<td id="S5.T3.8.4.14.10.2" class="ltx_td ltx_align_center ltx_border_t">35.7</td>
<td id="S5.T3.8.4.14.10.3" class="ltx_td ltx_align_center ltx_border_t">39.3</td>
<td id="S5.T3.8.4.14.10.4" class="ltx_td ltx_align_center ltx_border_t">44.0</td>
<td id="S5.T3.8.4.14.10.5" class="ltx_td ltx_align_center ltx_border_t">43.0</td>
<td id="S5.T3.8.4.14.10.6" class="ltx_td ltx_align_center ltx_border_t">47.2</td>
<td id="S5.T3.8.4.14.10.7" class="ltx_td ltx_align_center ltx_border_t">54.0</td>
<td id="S5.T3.8.4.14.10.8" class="ltx_td ltx_align_center ltx_border_t">38.3</td>
<td id="S5.T3.8.4.14.10.9" class="ltx_td ltx_align_center ltx_border_t">37.5</td>
<td id="S5.T3.8.4.14.10.10" class="ltx_td ltx_align_center ltx_border_t">51.6</td>
<td id="S5.T3.8.4.14.10.11" class="ltx_td ltx_align_center ltx_border_t">61.3</td>
<td id="S5.T3.8.4.14.10.12" class="ltx_td ltx_align_center ltx_border_t">46.5</td>
<td id="S5.T3.8.4.14.10.13" class="ltx_td ltx_align_center ltx_border_t">41.4</td>
<td id="S5.T3.8.4.14.10.14" class="ltx_td ltx_align_center ltx_border_t">47.3</td>
<td id="S5.T3.8.4.14.10.15" class="ltx_td ltx_align_center ltx_border_t">34.2</td>
<td id="S5.T3.8.4.14.10.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">39.4</td>
<td id="S5.T3.8.4.14.10.17" class="ltx_td ltx_align_center ltx_border_t">44.1</td>
</tr>
<tr id="S5.T3.7.3.3" class="ltx_tr">
<th id="S5.T3.7.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Cai <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> (<math id="S5.T3.7.3.3.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S5.T3.7.3.3.1.m1.1a"><mo id="S5.T3.7.3.3.1.m1.1.1" xref="S5.T3.7.3.3.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T3.7.3.3.1.m1.1b"><ci id="S5.T3.7.3.3.1.m1.1.1.cmml" xref="S5.T3.7.3.3.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.3.3.1.m1.1c">{\dagger}</annotation></semantics></math>)</th>
<td id="S5.T3.7.3.3.2" class="ltx_td ltx_align_center">35.7</td>
<td id="S5.T3.7.3.3.3" class="ltx_td ltx_align_center">37.8</td>
<td id="S5.T3.7.3.3.4" class="ltx_td ltx_align_center">36.9</td>
<td id="S5.T3.7.3.3.5" class="ltx_td ltx_align_center">40.7</td>
<td id="S5.T3.7.3.3.6" class="ltx_td ltx_align_center">39.6</td>
<td id="S5.T3.7.3.3.7" class="ltx_td ltx_align_center">45.2</td>
<td id="S5.T3.7.3.3.8" class="ltx_td ltx_align_center">37.4</td>
<td id="S5.T3.7.3.3.9" class="ltx_td ltx_align_center">34.5</td>
<td id="S5.T3.7.3.3.10" class="ltx_td ltx_align_center">46.9</td>
<td id="S5.T3.7.3.3.11" class="ltx_td ltx_align_center">50.1</td>
<td id="S5.T3.7.3.3.12" class="ltx_td ltx_align_center">40.5</td>
<td id="S5.T3.7.3.3.13" class="ltx_td ltx_align_center">36.1</td>
<td id="S5.T3.7.3.3.14" class="ltx_td ltx_align_center">41.0</td>
<td id="S5.T3.7.3.3.15" class="ltx_td ltx_align_center">29.6</td>
<td id="S5.T3.7.3.3.16" class="ltx_td ltx_align_center ltx_border_r">33.2</td>
<td id="S5.T3.7.3.3.17" class="ltx_td ltx_align_center">39.0</td>
</tr>
<tr id="S5.T3.8.4.15.11" class="ltx_tr">
<th id="S5.T3.8.4.15.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Pavllo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S5.T3.8.4.15.11.2" class="ltx_td ltx_align_center">34.1</td>
<td id="S5.T3.8.4.15.11.3" class="ltx_td ltx_align_center">36.1</td>
<td id="S5.T3.8.4.15.11.4" class="ltx_td ltx_align_center">34.4</td>
<td id="S5.T3.8.4.15.11.5" class="ltx_td ltx_align_center">37.2</td>
<td id="S5.T3.8.4.15.11.6" class="ltx_td ltx_align_center">36.4</td>
<td id="S5.T3.8.4.15.11.7" class="ltx_td ltx_align_center">42.2</td>
<td id="S5.T3.8.4.15.11.8" class="ltx_td ltx_align_center">34.4</td>
<td id="S5.T3.8.4.15.11.9" class="ltx_td ltx_align_center">33.6</td>
<td id="S5.T3.8.4.15.11.10" class="ltx_td ltx_align_center">45.0</td>
<td id="S5.T3.8.4.15.11.11" class="ltx_td ltx_align_center">52.5</td>
<td id="S5.T3.8.4.15.11.12" class="ltx_td ltx_align_center">37.4</td>
<td id="S5.T3.8.4.15.11.13" class="ltx_td ltx_align_center">33.8</td>
<td id="S5.T3.8.4.15.11.14" class="ltx_td ltx_align_center">37.8</td>
<td id="S5.T3.8.4.15.11.15" class="ltx_td ltx_align_center">25.6</td>
<td id="S5.T3.8.4.15.11.16" class="ltx_td ltx_align_center ltx_border_r">27.3</td>
<td id="S5.T3.8.4.15.11.17" class="ltx_td ltx_align_center">36.5</td>
</tr>
<tr id="S5.T3.8.4.16.12" class="ltx_tr">
<th id="S5.T3.8.4.16.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Lin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</th>
<td id="S5.T3.8.4.16.12.2" class="ltx_td ltx_align_center">32.5</td>
<td id="S5.T3.8.4.16.12.3" class="ltx_td ltx_align_center">35.3</td>
<td id="S5.T3.8.4.16.12.4" class="ltx_td ltx_align_center">34.3</td>
<td id="S5.T3.8.4.16.12.5" class="ltx_td ltx_align_center">36.2</td>
<td id="S5.T3.8.4.16.12.6" class="ltx_td ltx_align_center">37.8</td>
<td id="S5.T3.8.4.16.12.7" class="ltx_td ltx_align_center">43.0</td>
<td id="S5.T3.8.4.16.12.8" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.16.12.8.1" class="ltx_ERROR undefined">\ul</span>33.0</td>
<td id="S5.T3.8.4.16.12.9" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.16.12.9.1" class="ltx_ERROR undefined">\ul</span>32.2</td>
<td id="S5.T3.8.4.16.12.10" class="ltx_td ltx_align_center">45.7</td>
<td id="S5.T3.8.4.16.12.11" class="ltx_td ltx_align_center">51.8</td>
<td id="S5.T3.8.4.16.12.12" class="ltx_td ltx_align_center">38.4</td>
<td id="S5.T3.8.4.16.12.13" class="ltx_td ltx_align_center">32.8</td>
<td id="S5.T3.8.4.16.12.14" class="ltx_td ltx_align_center">37.5</td>
<td id="S5.T3.8.4.16.12.15" class="ltx_td ltx_align_center">25.8</td>
<td id="S5.T3.8.4.16.12.16" class="ltx_td ltx_align_center ltx_border_r">28.9</td>
<td id="S5.T3.8.4.16.12.17" class="ltx_td ltx_align_center">36.8</td>
</tr>
<tr id="S5.T3.8.4.17.13" class="ltx_tr">
<th id="S5.T3.8.4.17.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Liu <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</th>
<td id="S5.T3.8.4.17.13.2" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.17.13.2.1" class="ltx_ERROR undefined">\ul</span>32.3</td>
<td id="S5.T3.8.4.17.13.3" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.17.13.3.1" class="ltx_ERROR undefined">\ul</span>35.2</td>
<td id="S5.T3.8.4.17.13.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.17.13.4.1" class="ltx_text ltx_font_bold">33.3</span></td>
<td id="S5.T3.8.4.17.13.5" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.17.13.5.1" class="ltx_ERROR undefined">\ul</span>35.8</td>
<td id="S5.T3.8.4.17.13.6" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.17.13.6.1" class="ltx_ERROR undefined">\ul</span>35.9</td>
<td id="S5.T3.8.4.17.13.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.17.13.7.1" class="ltx_text ltx_font_bold">41.5</span></td>
<td id="S5.T3.8.4.17.13.8" class="ltx_td ltx_align_center">33.2</td>
<td id="S5.T3.8.4.17.13.9" class="ltx_td ltx_align_center">32.7</td>
<td id="S5.T3.8.4.17.13.10" class="ltx_td ltx_align_center">44.6</td>
<td id="S5.T3.8.4.17.13.11" class="ltx_td ltx_align_center">50.9</td>
<td id="S5.T3.8.4.17.13.12" class="ltx_td ltx_align_center">37.0</td>
<td id="S5.T3.8.4.17.13.13" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.17.13.13.1" class="ltx_ERROR undefined">\ul</span>32.4</td>
<td id="S5.T3.8.4.17.13.14" class="ltx_td ltx_align_center">37.0</td>
<td id="S5.T3.8.4.17.13.15" class="ltx_td ltx_align_center">25.2</td>
<td id="S5.T3.8.4.17.13.16" class="ltx_td ltx_align_center ltx_border_r">27.2</td>
<td id="S5.T3.8.4.17.13.17" class="ltx_td ltx_align_center">35.6</td>
</tr>
<tr id="S5.T3.8.4.4" class="ltx_tr">
<th id="S5.T3.8.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Wang <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> (<math id="S5.T3.8.4.4.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S5.T3.8.4.4.1.m1.1a"><mo id="S5.T3.8.4.4.1.m1.1.1" xref="S5.T3.8.4.4.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T3.8.4.4.1.m1.1b"><ci id="S5.T3.8.4.4.1.m1.1.1.cmml" xref="S5.T3.8.4.4.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.4.4.1.m1.1c">{\dagger}</annotation></semantics></math>)</th>
<td id="S5.T3.8.4.4.2" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.2.1" class="ltx_text ltx_font_bold">31.8</span></td>
<td id="S5.T3.8.4.4.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.3.1" class="ltx_text ltx_font_bold">34.3</span></td>
<td id="S5.T3.8.4.4.4" class="ltx_td ltx_align_center">35.4</td>
<td id="S5.T3.8.4.4.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.5.1" class="ltx_text ltx_font_bold">33.5</span></td>
<td id="S5.T3.8.4.4.6" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.6.1" class="ltx_text ltx_font_bold">35.4</span></td>
<td id="S5.T3.8.4.4.7" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.4.7.1" class="ltx_ERROR undefined">\ul</span>41.7</td>
<td id="S5.T3.8.4.4.8" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.8.1" class="ltx_text ltx_font_bold">31.1</span></td>
<td id="S5.T3.8.4.4.9" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.9.1" class="ltx_text ltx_font_bold">31.6</span></td>
<td id="S5.T3.8.4.4.10" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.4.10.1" class="ltx_ERROR undefined">\ul</span>44.4</td>
<td id="S5.T3.8.4.4.11" class="ltx_td ltx_align_center">49.0</td>
<td id="S5.T3.8.4.4.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.12.1" class="ltx_text ltx_font_bold">36.4</span></td>
<td id="S5.T3.8.4.4.13" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.13.1" class="ltx_text ltx_font_bold">32.2</span></td>
<td id="S5.T3.8.4.4.14" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.14.1" class="ltx_text ltx_font_bold">35.0</span></td>
<td id="S5.T3.8.4.4.15" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.4.15.1" class="ltx_ERROR undefined">\ul</span>24.9</td>
<td id="S5.T3.8.4.4.16" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.4.16.1" class="ltx_text ltx_font_bold">23.0</span></td>
<td id="S5.T3.8.4.4.17" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.17.1" class="ltx_text ltx_font_bold">34.5</span></td>
</tr>
<tr id="S5.T3.8.4.18.14" class="ltx_tr">
<th id="S5.T3.8.4.18.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Ours (T=243 CPN causal)</th>
<td id="S5.T3.8.4.18.14.2" class="ltx_td ltx_align_center ltx_border_t">34.9</td>
<td id="S5.T3.8.4.18.14.3" class="ltx_td ltx_align_center ltx_border_t">37.5</td>
<td id="S5.T3.8.4.18.14.4" class="ltx_td ltx_align_center ltx_border_t">34.9</td>
<td id="S5.T3.8.4.18.14.5" class="ltx_td ltx_align_center ltx_border_t">38.3</td>
<td id="S5.T3.8.4.18.14.6" class="ltx_td ltx_align_center ltx_border_t">37.4</td>
<td id="S5.T3.8.4.18.14.7" class="ltx_td ltx_align_center ltx_border_t">44.0</td>
<td id="S5.T3.8.4.18.14.8" class="ltx_td ltx_align_center ltx_border_t">34.4</td>
<td id="S5.T3.8.4.18.14.9" class="ltx_td ltx_align_center ltx_border_t">34.6</td>
<td id="S5.T3.8.4.18.14.10" class="ltx_td ltx_align_center ltx_border_t">45.1</td>
<td id="S5.T3.8.4.18.14.11" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T3.8.4.18.14.11.1" class="ltx_ERROR undefined">\ul</span>48.0</td>
<td id="S5.T3.8.4.18.14.12" class="ltx_td ltx_align_center ltx_border_t">49.3</td>
<td id="S5.T3.8.4.18.14.13" class="ltx_td ltx_align_center ltx_border_t">34.8</td>
<td id="S5.T3.8.4.18.14.14" class="ltx_td ltx_align_center ltx_border_t">37.7</td>
<td id="S5.T3.8.4.18.14.15" class="ltx_td ltx_align_center ltx_border_t">26.2</td>
<td id="S5.T3.8.4.18.14.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.1</td>
<td id="S5.T3.8.4.18.14.17" class="ltx_td ltx_align_center ltx_border_t">36.9</td>
</tr>
<tr id="S5.T3.8.4.19.15" class="ltx_tr">
<th id="S5.T3.8.4.19.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Ours (T=243 CPN)</th>
<td id="S5.T3.8.4.19.15.2" class="ltx_td ltx_align_center">32.7</td>
<td id="S5.T3.8.4.19.15.3" class="ltx_td ltx_align_center">36.2</td>
<td id="S5.T3.8.4.19.15.4" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.19.15.4.1" class="ltx_ERROR undefined">\ul</span>33.4</td>
<td id="S5.T3.8.4.19.15.5" class="ltx_td ltx_align_center">36.5</td>
<td id="S5.T3.8.4.19.15.6" class="ltx_td ltx_align_center">36.0</td>
<td id="S5.T3.8.4.19.15.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.19.15.7.1" class="ltx_text ltx_font_bold">41.5</span></td>
<td id="S5.T3.8.4.19.15.8" class="ltx_td ltx_align_center">33.6</td>
<td id="S5.T3.8.4.19.15.9" class="ltx_td ltx_align_center">33.1</td>
<td id="S5.T3.8.4.19.15.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.19.15.10.1" class="ltx_text ltx_font_bold">44.1</span></td>
<td id="S5.T3.8.4.19.15.11" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.19.15.11.1" class="ltx_text ltx_font_bold">46.8</span></td>
<td id="S5.T3.8.4.19.15.12" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.19.15.12.1" class="ltx_ERROR undefined">\ul</span>36.7</td>
<td id="S5.T3.8.4.19.15.13" class="ltx_td ltx_align_center">33.1</td>
<td id="S5.T3.8.4.19.15.14" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.19.15.14.1" class="ltx_ERROR undefined">\ul</span>35.8</td>
<td id="S5.T3.8.4.19.15.15" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.19.15.15.1" class="ltx_text ltx_font_bold">24.2</span></td>
<td id="S5.T3.8.4.19.15.16" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T3.8.4.19.15.16.1" class="ltx_ERROR undefined">\ul</span>24.8</td>
<td id="S5.T3.8.4.19.15.17" class="ltx_td ltx_align_center">
<span id="S5.T3.8.4.19.15.17.1" class="ltx_ERROR undefined">\ul</span>35.2</td>
</tr>
<tr id="S5.T3.8.4.20.16" class="ltx_tr">
<th id="S5.T3.8.4.20.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Ours (T=243 GT)</th>
<td id="S5.T3.8.4.20.16.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">23.4</td>
<td id="S5.T3.8.4.20.16.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">26.8</td>
<td id="S5.T3.8.4.20.16.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">21.6</td>
<td id="S5.T3.8.4.20.16.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25.0</td>
<td id="S5.T3.8.4.20.16.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">24.5</td>
<td id="S5.T3.8.4.20.16.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">28.9</td>
<td id="S5.T3.8.4.20.16.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25.6</td>
<td id="S5.T3.8.4.20.16.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">23.4</td>
<td id="S5.T3.8.4.20.16.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">29.0</td>
<td id="S5.T3.8.4.20.16.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">30.5</td>
<td id="S5.T3.8.4.20.16.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">26.1</td>
<td id="S5.T3.8.4.20.16.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">23.3</td>
<td id="S5.T3.8.4.20.16.14" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25.8</td>
<td id="S5.T3.8.4.20.16.15" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">20.3</td>
<td id="S5.T3.8.4.20.16.16" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">21.7</td>
<td id="S5.T3.8.4.20.16.17" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25.1</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table IV: </span>Comparison on HumanEva-I under protocol #2. Best in bold, second best underlined. Note that the high error on S3’s “Walk” is due to corrupted mocap data.</figcaption>
<div id="S5.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:212.5pt;height:53.8pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-144.5pt,36.3pt) scale(0.423774342847688,0.423774342847688) ;">
<table id="S5.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.1.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T4.1.1.1.1.1.1" class="ltx_text">Protocol #2</span></th>
<td id="S5.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Walk</td>
<td id="S5.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Jog</td>
<td id="S5.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Box</td>
</tr>
<tr id="S5.T4.1.1.2.2" class="ltx_tr">
<td id="S5.T4.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S1</td>
<td id="S5.T4.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S2</td>
<td id="S5.T4.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">S3</td>
<td id="S5.T4.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S1</td>
<td id="S5.T4.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S2</td>
<td id="S5.T4.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">S3</td>
<td id="S5.T4.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S1</td>
<td id="S5.T4.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S2</td>
<td id="S5.T4.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">S3</td>
</tr>
<tr id="S5.T4.1.1.3.3" class="ltx_tr">
<th id="S5.T4.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Martinez <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</th>
<td id="S5.T4.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">19.7</td>
<td id="S5.T4.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">17.4</td>
<td id="S5.T4.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.8</td>
<td id="S5.T4.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">26.9</td>
<td id="S5.T4.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">18.2</td>
<td id="S5.T4.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">18.6</td>
<td id="S5.T4.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T4.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S5.T4.1.1.3.3.10" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T4.1.1.4.4" class="ltx_tr">
<th id="S5.T4.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Pavlakos <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</th>
<td id="S5.T4.1.1.4.4.2" class="ltx_td ltx_align_center">18.8</td>
<td id="S5.T4.1.1.4.4.3" class="ltx_td ltx_align_center">12.7</td>
<td id="S5.T4.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.1.1.4.4.4.1" class="ltx_text ltx_font_bold">29.2</span></td>
<td id="S5.T4.1.1.4.4.5" class="ltx_td ltx_align_center">23.5</td>
<td id="S5.T4.1.1.4.4.6" class="ltx_td ltx_align_center">15.4</td>
<td id="S5.T4.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">14.5</td>
<td id="S5.T4.1.1.4.4.8" class="ltx_td ltx_align_center">-</td>
<td id="S5.T4.1.1.4.4.9" class="ltx_td ltx_align_center">-</td>
<td id="S5.T4.1.1.4.4.10" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T4.1.1.5.5" class="ltx_tr">
<th id="S5.T4.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Lee <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</th>
<td id="S5.T4.1.1.5.5.2" class="ltx_td ltx_align_center">18.6</td>
<td id="S5.T4.1.1.5.5.3" class="ltx_td ltx_align_center">19.9</td>
<td id="S5.T4.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T4.1.1.5.5.4.1" class="ltx_ERROR undefined">\ul</span>30.5</td>
<td id="S5.T4.1.1.5.5.5" class="ltx_td ltx_align_center">25.7</td>
<td id="S5.T4.1.1.5.5.6" class="ltx_td ltx_align_center">16.8</td>
<td id="S5.T4.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">17.7</td>
<td id="S5.T4.1.1.5.5.8" class="ltx_td ltx_align_center">42.8</td>
<td id="S5.T4.1.1.5.5.9" class="ltx_td ltx_align_center">48.1</td>
<td id="S5.T4.1.1.5.5.10" class="ltx_td ltx_align_center">53.4</td>
</tr>
<tr id="S5.T4.1.1.6.6" class="ltx_tr">
<th id="S5.T4.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Pavllo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</th>
<td id="S5.T4.1.1.6.6.2" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.2.1" class="ltx_ERROR undefined">\ul</span>13.9</td>
<td id="S5.T4.1.1.6.6.3" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.3.1" class="ltx_ERROR undefined">\ul</span>10.2</td>
<td id="S5.T4.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">46.6</td>
<td id="S5.T4.1.1.6.6.5" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.5.1" class="ltx_ERROR undefined">\ul</span>20.9</td>
<td id="S5.T4.1.1.6.6.6" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.6.1" class="ltx_ERROR undefined">\ul</span>13.1</td>
<td id="S5.T4.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r">
<span id="S5.T4.1.1.6.6.7.1" class="ltx_ERROR undefined">\ul</span>13.8</td>
<td id="S5.T4.1.1.6.6.8" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.8.1" class="ltx_ERROR undefined">\ul</span>23.8</td>
<td id="S5.T4.1.1.6.6.9" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.9.1" class="ltx_ERROR undefined">\ul</span>33.7</td>
<td id="S5.T4.1.1.6.6.10" class="ltx_td ltx_align_center">
<span id="S5.T4.1.1.6.6.10.1" class="ltx_ERROR undefined">\ul</span>32.0</td>
</tr>
<tr id="S5.T4.1.1.7.7" class="ltx_tr">
<th id="S5.T4.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Ours (T=27 CPN)</th>
<td id="S5.T4.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.2.1" class="ltx_text ltx_font_bold">13.7</span></td>
<td id="S5.T4.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.3.1" class="ltx_text ltx_font_bold">9.2</span></td>
<td id="S5.T4.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">46.2</td>
<td id="S5.T4.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.5.1" class="ltx_text ltx_font_bold">20.1</span></td>
<td id="S5.T4.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.6.1" class="ltx_text ltx_font_bold">12.5</span></td>
<td id="S5.T4.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T4.1.1.7.7.7.1" class="ltx_text ltx_font_bold">12.7</span></td>
<td id="S5.T4.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.8.1" class="ltx_text ltx_font_bold">21.8</span></td>
<td id="S5.T4.1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.9.1" class="ltx_text ltx_font_bold">27.8</span></td>
<td id="S5.T4.1.1.7.7.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T4.1.1.7.7.10.1" class="ltx_text ltx_font_bold">27.0</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS1.5.1.1" class="ltx_text">V-C</span>1 </span>Comparison with State-of-the-Art</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p id="S5.SS3.SSS1.p1.1" class="ltx_p">With respect to the Human3.6M dataset, we train using CPNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> to detect 2D poses for fair comparison as this is the most commonly used detector in the compared works. Table <a href="#S5.T3" title="Table III ‣ V-C Quantitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> shows the performance of our 243 receptive field model compared to state-of-the-art (SOTA) results. Our method achieves competitive performance on human3.6M under both protocols. Note that Wang <em id="S5.SS3.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> not only exploited spatial and temporal information but also adopted pose refinement and motion loss to regular reconstructed 3D poses. In our work, we only model spatio-temporal information through a simple network and use a common MPJPE loss without using any bells and whistles. In addition, we also report the results when using ground truth 2D poses, which yield approximately 13.5mm improvements in MPJPE.</p>
</div>
<div id="S5.SS3.SSS1.p2" class="ltx_para">
<p id="S5.SS3.SSS1.p2.1" class="ltx_p">With respect to HumanEva-I dataset, which is comprised of videos with much smaller durations compared with those in Human3.6M, we choose to use fewer receptive fields—27—for evaluation. We compare our results with SOTA under Protocol #2. Table <a href="#S5.T4" title="Table IV ‣ V-C Quantitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> shows we achieved the best results in each action except the S3 of ”Walking” due to corrupted mocap data.</p>
</div>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS2.5.1.1" class="ltx_text">V-C</span>2 </span>Comparison with Temporal Convolutional Networks</h4>

<figure id="S5.F5" class="ltx_figure"><img src="/html/2003.14179/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="84" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S5.F5.3.1" class="ltx_text ltx_font_bold">Left</span>: Comparison with TCNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> in different receptive fields on Human3.6M under protocol #1 and #2. <span id="S5.F5.4.2" class="ltx_text ltx_font_bold">Right</span>: Comparison with the parameters of model.</figcaption>
</figure>
<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p id="S5.SS3.SSS2.p1.1" class="ltx_p">Fig. <a href="#S5.F5" title="Figure 5 ‣ V-C2 Comparison with Temporal Convolutional Networks ‣ V-C Quantitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> compares the number of parameters and the 3D pose estimation errors between TCNs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and our various receptive field models. Like <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, we use CPNs as 2D pose detector for fair comparison. As can be seen on the left plot of Fig. <a href="#S5.F5" title="Figure 5 ‣ V-C2 Comparison with Temporal Convolutional Networks ‣ V-C Quantitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we obtain smaller estimation errors for all receptive field combinations on Human3.6M under both protocols. Additionally, our model with 27 receptive fields is also slightly better than the TCNs with 243 receptive fields, which shows that the use of spatial information significantly contributes to reconstructing more accurate 3D poses. For the right side bar chart of Fig. <a href="#S5.F5" title="Figure 5 ‣ V-C2 Comparison with Temporal Convolutional Networks ‣ V-C Quantitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we see that our model uses 62.9%, 19.2%, 44.7%, and 58.2% fewer parameters compared to the TCNs’ 9, 27, 81, and 243 receptive field models respectively. This shows that interleaving of our spatial and temporal mechanisms results in a more efficient network for video pose estimation.</p>
</div>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">Qualitative Results</span>
</h3>

<figure id="S5.F6" class="ltx_figure"><img src="/html/2003.14179/assets/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="131" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="S5.F6.7.1" class="ltx_text ltx_font_bold">Left</span>: Examples of results from our model with/without local kinematic connections <math id="S5.F6.3.m1.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S5.F6.3.m1.1b"><msub id="S5.F6.3.m1.1.1" xref="S5.F6.3.m1.1.1.cmml"><mover accent="true" id="S5.F6.3.m1.1.1.2" xref="S5.F6.3.m1.1.1.2.cmml"><mi id="S5.F6.3.m1.1.1.2.2" xref="S5.F6.3.m1.1.1.2.2.cmml">A</mi><mo id="S5.F6.3.m1.1.1.2.1" xref="S5.F6.3.m1.1.1.2.1.cmml">~</mo></mover><mi id="S5.F6.3.m1.1.1.3" xref="S5.F6.3.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.3.m1.1c"><apply id="S5.F6.3.m1.1.1.cmml" xref="S5.F6.3.m1.1.1"><csymbol cd="ambiguous" id="S5.F6.3.m1.1.1.1.cmml" xref="S5.F6.3.m1.1.1">subscript</csymbol><apply id="S5.F6.3.m1.1.1.2.cmml" xref="S5.F6.3.m1.1.1.2"><ci id="S5.F6.3.m1.1.1.2.1.cmml" xref="S5.F6.3.m1.1.1.2.1">~</ci><ci id="S5.F6.3.m1.1.1.2.2.cmml" xref="S5.F6.3.m1.1.1.2.2">𝐴</ci></apply><ci id="S5.F6.3.m1.1.1.3.cmml" xref="S5.F6.3.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.3.m1.1d">\widetilde{A}_{c}</annotation></semantics></math>. <span id="S5.F6.8.2" class="ltx_text ltx_font_bold">Right</span>: Examples of results from our model with/without global adaptive matrix <math id="S5.F6.4.m2.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.F6.4.m2.1b"><msub id="S5.F6.4.m2.1.1" xref="S5.F6.4.m2.1.1.cmml"><mi id="S5.F6.4.m2.1.1.2" xref="S5.F6.4.m2.1.1.2.cmml">B</mi><mi id="S5.F6.4.m2.1.1.3" xref="S5.F6.4.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F6.4.m2.1c"><apply id="S5.F6.4.m2.1.1.cmml" xref="S5.F6.4.m2.1.1"><csymbol cd="ambiguous" id="S5.F6.4.m2.1.1.1.cmml" xref="S5.F6.4.m2.1.1">subscript</csymbol><ci id="S5.F6.4.m2.1.1.2.cmml" xref="S5.F6.4.m2.1.1.2">𝐵</ci><ci id="S5.F6.4.m2.1.1.3.cmml" xref="S5.F6.4.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.4.m2.1d">B_{k}</annotation></semantics></math>. Wrong estimations are labeled in red circles.</figcaption>
</figure>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2003.14179/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="175" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Visualization of global attention matrix <math id="S5.F7.2.m1.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.F7.2.m1.1b"><msub id="S5.F7.2.m1.1.1" xref="S5.F7.2.m1.1.1.cmml"><mi id="S5.F7.2.m1.1.1.2" xref="S5.F7.2.m1.1.1.2.cmml">B</mi><mi id="S5.F7.2.m1.1.1.3" xref="S5.F7.2.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.F7.2.m1.1c"><apply id="S5.F7.2.m1.1.1.cmml" xref="S5.F7.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F7.2.m1.1.1.1.cmml" xref="S5.F7.2.m1.1.1">subscript</csymbol><ci id="S5.F7.2.m1.1.1.2.cmml" xref="S5.F7.2.m1.1.1.2">𝐵</ci><ci id="S5.F7.2.m1.1.1.3.cmml" xref="S5.F7.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.2.m1.1d">B_{k}</annotation></semantics></math>. The right wrist is set as the visualized joint. Three colored layers represent three different attention layers advancing from top to bottom. Circle mass indicates the relationship strength between the current and the visualized joint.</figcaption>
</figure>
<section id="S5.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS4.SSS1.5.1.1" class="ltx_text">V-D</span>1 </span>Significance of Spatial Semantics</h4>

<div id="S5.SS4.SSS1.p1" class="ltx_para">
<p id="S5.SS4.SSS1.p1.2" class="ltx_p">These studies do 3D pose estimation on YouTube videos using our 27 receptive field mode. The left of Fig. <a href="#S5.F6" title="Figure 6 ‣ V-D Qualitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows pose reconstructions with/without local kinematic connections <math id="S5.SS4.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\widetilde{A}_{c}" display="inline"><semantics id="S5.SS4.SSS1.p1.1.m1.1a"><msub id="S5.SS4.SSS1.p1.1.m1.1.1" xref="S5.SS4.SSS1.p1.1.m1.1.1.cmml"><mover accent="true" id="S5.SS4.SSS1.p1.1.m1.1.1.2" xref="S5.SS4.SSS1.p1.1.m1.1.1.2.cmml"><mi id="S5.SS4.SSS1.p1.1.m1.1.1.2.2" xref="S5.SS4.SSS1.p1.1.m1.1.1.2.2.cmml">A</mi><mo id="S5.SS4.SSS1.p1.1.m1.1.1.2.1" xref="S5.SS4.SSS1.p1.1.m1.1.1.2.1.cmml">~</mo></mover><mi id="S5.SS4.SSS1.p1.1.m1.1.1.3" xref="S5.SS4.SSS1.p1.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p1.1.m1.1b"><apply id="S5.SS4.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1">subscript</csymbol><apply id="S5.SS4.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1.2"><ci id="S5.SS4.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1.2.1">~</ci><ci id="S5.SS4.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1.2.2">𝐴</ci></apply><ci id="S5.SS4.SSS1.p1.1.m1.1.1.3.cmml" xref="S5.SS4.SSS1.p1.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p1.1.m1.1c">\widetilde{A}_{c}</annotation></semantics></math> in Yoga videos, while the right shows pose reconstructions with/without the global adaptive matrix <math id="S5.SS4.SSS1.p1.2.m2.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.SS4.SSS1.p1.2.m2.1a"><msub id="S5.SS4.SSS1.p1.2.m2.1.1" xref="S5.SS4.SSS1.p1.2.m2.1.1.cmml"><mi id="S5.SS4.SSS1.p1.2.m2.1.1.2" xref="S5.SS4.SSS1.p1.2.m2.1.1.2.cmml">B</mi><mi id="S5.SS4.SSS1.p1.2.m2.1.1.3" xref="S5.SS4.SSS1.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS1.p1.2.m2.1b"><apply id="S5.SS4.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS4.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS1.p1.2.m2.1.1.1.cmml" xref="S5.SS4.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS4.SSS1.p1.2.m2.1.1.2.cmml" xref="S5.SS4.SSS1.p1.2.m2.1.1.2">𝐵</ci><ci id="S5.SS4.SSS1.p1.2.m2.1.1.3.cmml" xref="S5.SS4.SSS1.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS1.p1.2.m2.1c">B_{k}</annotation></semantics></math> in baseball videos. Pose errors are circled in red. Qualitative analysis for Yoga shows that when local kinematic connections are not considered there is considerable location ambiguity for distal joints. For the baseball videos, even when working with erroneous 2D input poses due to occlusions, the global posture semantics work effectively with temporal continuity to mitigate self-occlusion effects and yield accurate and smooth poses.</p>
</div>
</section>
<section id="S5.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS4.SSS2.6.1.1" class="ltx_text">V-D</span>2 </span>Visualization of Global Attention Matrix <math id="S5.SS4.SSS2.1.m1.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.SS4.SSS2.1.m1.1b"><msub id="S5.SS4.SSS2.1.m1.1.1" xref="S5.SS4.SSS2.1.m1.1.1.cmml"><mi id="S5.SS4.SSS2.1.m1.1.1.2" xref="S5.SS4.SSS2.1.m1.1.1.2.cmml">B</mi><mi id="S5.SS4.SSS2.1.m1.1.1.3" xref="S5.SS4.SSS2.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.1.m1.1c"><apply id="S5.SS4.SSS2.1.m1.1.1.cmml" xref="S5.SS4.SSS2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS2.1.m1.1.1.1.cmml" xref="S5.SS4.SSS2.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.SSS2.1.m1.1.1.2.cmml" xref="S5.SS4.SSS2.1.m1.1.1.2">𝐵</ci><ci id="S5.SS4.SSS2.1.m1.1.1.3.cmml" xref="S5.SS4.SSS2.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.1.m1.1d">B_{k}</annotation></semantics></math>
</h4>

<div id="S5.SS4.SSS2.p1" class="ltx_para">
<p id="S5.SS4.SSS2.p1.1" class="ltx_p">To further understand the construction of global semantics in occluded joints, we visualize our model’s global attention matrices <math id="S5.SS4.SSS2.p1.1.m1.1" class="ltx_Math" alttext="B_{k}" display="inline"><semantics id="S5.SS4.SSS2.p1.1.m1.1a"><msub id="S5.SS4.SSS2.p1.1.m1.1.1" xref="S5.SS4.SSS2.p1.1.m1.1.1.cmml"><mi id="S5.SS4.SSS2.p1.1.m1.1.1.2" xref="S5.SS4.SSS2.p1.1.m1.1.1.2.cmml">B</mi><mi id="S5.SS4.SSS2.p1.1.m1.1.1.3" xref="S5.SS4.SSS2.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.SSS2.p1.1.m1.1b"><apply id="S5.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS4.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.SSS2.p1.1.m1.1.1.1.cmml" xref="S5.SS4.SSS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.SSS2.p1.1.m1.1.1.2.cmml" xref="S5.SS4.SSS2.p1.1.m1.1.1.2">𝐵</ci><ci id="S5.SS4.SSS2.p1.1.m1.1.1.3.cmml" xref="S5.SS4.SSS2.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.SSS2.p1.1.m1.1c">B_{k}</annotation></semantics></math> on the baseball case. Fig. <a href="#S5.F7" title="Figure 7 ‣ V-D Qualitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> is the visualization of the sample represented by skeleton graphs, where the circle mass indicates the strength of the relationship between the current joint and the right wrist in matrices. Skeleton graphs of each layer contain the average result across the multi-head attention of Eqtn. <a href="#S3.E3" title="In III-C Global Attention Graph ‣ III Approach ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. From the relationship visualized by the three-layer skeleton graphs, we see that the global graph attention tends to establish strong connections with the spine, left hip and right hip—joints close to the root joint. We speculate that the position information of these joints is easier to predict and stabilizes the reconstruction of the valid 3D structure. Apart from the aforementioned relationships, the skeleton graph in the first layer focuses on self-connections. For the 2nd and 3rd layers, strong relationships are constructed with the joints along the left and right leg. We argue that higher layers convey higher-level posture semantics that contribute to modeling the non-local spatial configuration constraints.</p>
</div>
</section>
<section id="S5.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS4.SSS3.5.1.1" class="ltx_text">V-D</span>3 </span>Reconstruction of Special Case</h4>

<figure id="S5.F8" class="ltx_figure"><img src="/html/2003.14179/assets/x8.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="226" height="69" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="S5.F8.3.1" class="ltx_text ltx_font_bold">Left</span>: Examples of results from our model reconstructed valid 3D structure from a half body. <span id="S5.F8.4.2" class="ltx_text ltx_font_bold">Right</span>: Two failure cases caused by big 2D detection error and long-term heavy occlusion respectively.</figcaption>
</figure>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table V: </span>Test time of estimation speed</figcaption>
<div id="S5.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:208.1pt;height:42.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.5pt,5.8pt) scale(0.785005346691247,0.785005346691247) ;">
<table id="S5.T5.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T5.2.2.3.1" class="ltx_tr">
<th id="S5.T5.2.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt">GAST-Net</th>
<td id="S5.T5.2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Layer-by-layer inference</td>
<td id="S5.T5.2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Single-frame inference</td>
</tr>
<tr id="S5.T5.1.1.1" class="ltx_tr">
<th id="S5.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Receptive fields</th>
<td id="S5.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">27</td>
<td id="S5.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">81</td>
<td id="S5.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">243</td>
<td id="S5.T5.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">27</td>
<td id="S5.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">81</td>
<td id="S5.T5.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">243</td>
</tr>
<tr id="S5.T5.2.2.2" class="ltx_tr">
<th id="S5.T5.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Frames per second</th>
<td id="S5.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1270</td>
<td id="S5.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">1120</td>
<td id="S5.T5.2.2.2.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">960</td>
<td id="S5.T5.2.2.2.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">74</td>
<td id="S5.T5.2.2.2.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">56</td>
<td id="S5.T5.2.2.2.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">45</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.SS4.SSS3.p1" class="ltx_para">
<p id="S5.SS4.SSS3.p1.1" class="ltx_p">We also consider situations in which cameras only capture a person’s upper body (common across applications, <span id="S5.SS4.SSS3.p1.1.1" class="ltx_text ltx_font_italic">e.g. </span>human-robot interaction). We conducted experiments that reveal that GAST-Net yields reasonable 3D pose reconstructions as shown on the left of Fig. <a href="#S5.F8" title="Figure 8 ‣ V-D3 Reconstruction of Special Case ‣ V-D Qualitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Note that whilst GAST-Net is only trained on whole bodies, the model effectively reconstructs upper body test data it has not seen before. The right side of Fig <a href="#S5.F8" title="Figure 8 ‣ V-D3 Reconstruction of Special Case ‣ V-D Qualitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows two failure cases caused by large 2D detection errors (ice skating) as well as significant occlusions over long-term periods of time (wall climbing).</p>
</div>
</section>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.5.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.6.2" class="ltx_text ltx_font_italic">Testing the Speed of 3D Pose Estimation</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.2" class="ltx_p">We implemented our model with different inference modes and receptive fields to test the speed of 2D-to-3D video pose estimation. The speed time results are summarized in Table <a href="#S5.T5" title="Table V ‣ V-D3 Reconstruction of Special Case ‣ V-D Qualitative Results ‣ V Experiments ‣ A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. These tests used an Intel CORE CPU@2.20GHz(6 cores) laptop and an NVIDIA GTX 1060 GPU. We use native Python without parallel optimization for inference. Since layer-by-layer inference enables parallel processing on the input frames, the estimation speed is faster compared to single-frame inference. To intuitively understand the estimation speed of single-frame inference from RGB videos, we adopt YOLOv3 (160<math id="S5.SS5.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS5.p1.1.m1.1a"><mo id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><times id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">\times</annotation></semantics></math>160) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and SORT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> for human detection and tracking, HRNet (256<math id="S5.SS5.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS5.p1.2.m2.1a"><mo id="S5.SS5.p1.2.m2.1.1" xref="S5.SS5.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.2.m2.1b"><times id="S5.SS5.p1.2.m2.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.2.m2.1c">\times</annotation></semantics></math>192) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> for 2D pose estimation, and GAST-Net (27 receptive fields) for 2D-to-3D pose reconstruction. Experiments show that our top-down video pose estimation achieves 11 fps for a single person with the same test environment.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this work, we presented a real-time 3D pose estimation methodology that simultaneously and flexibly captures varying spatio-temporal sequences. The proposed graph attention blocks, effectively model the symmetrical hierarchy of 2D skeleton as well as global postural constraints, are synergistically combined with temporal dependencies to better mitigate depth ambiguity and resolve self-occlusion. Qualitative results show that our approach also generalizes to 3D pose estimation in the half upper body, which helps to close-range interactive applications (<em id="S6.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, human-robot interaction).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
L. Zhao, X. Peng, Y. Tian, M. Kapadia, and D. N. Metaxas, “Semantic graph
convolutional networks for 3d human pose regression,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2019, pp.
3425–3435.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Martinez, R. Hossain, J. Romero, and J. J. Little, “A simple yet effective
baseline for 3d human pose estimation,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE
International Conference on Computer Vision</em>, 2017, pp. 2640–2649.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
R. Dabral, A. Mundhada, U. Kusupati, S. Afaque, A. Sharma, and A. Jain,
“Learning 3d human pose from structure and motion,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the European Conference on Computer Vision (ECCV)</em>, 2018, pp. 668–683.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
B. Wandt and B. Rosenhahn, “Repnet: Weakly supervised training of an
adversarial reprojection network for 3d human pose estimation,” in
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2019, pp. 7782–7791.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
D. Drover, C.-H. Chen, A. Agrawal, A. Tyagi, and C. Phuoc Huynh, “Can 3d pose
be learned from 2d projections alone?” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European
Conference on Computer Vision (ECCV)</em>, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
M. Rayat Imtiaz Hossain and J. J. Little, “Exploiting temporal information for
3d human pose estimation,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference
on Computer Vision (ECCV)</em>, 2018, pp. 68–84.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
D. Pavllo, C. Feichtenhofer, D. Grangier, and M. Auli, “3d human pose
estimation in video with temporal convolutions and semi-supervised
training,” in <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition</em>, 2019, pp. 7753–7762.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Cai, L. Ge, J. Liu, J. Cai, T.-J. Cham, J. Yuan, and N. M. Thalmann,
“Exploiting spatial-temporal relationships for 3d pose estimation via graph
convolutional networks,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International
Conference on Computer Vision</em>, 2019, pp. 2272–2281.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Bai, J. Z. Kolter, and V. Koltun, “An empirical evaluation of generic
convolutional and recurrent networks for sequence modeling,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1803.01271</em>, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
L. Shi, Y. Zhang, J. Cheng, and H. Lu, “Two-stream adaptive graph
convolutional networks for skeleton-based action recognition,” in
<em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition</em>, 2019, pp. 12 026–12 035.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation learning on
large graphs,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
2017, pp. 1024–1034.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Wang, Y. Chen, Z. Guo, K. Qian, M. Lin, H. Li, and J. S. Ren, “Generalizing
monocular 3d human pose estimation in the wild,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
IEEE International Conference on Computer Vision Workshops</em>, 2019, pp. 0–0.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
K. Lee, I. Lee, and S. Lee, “Propagating lstm: 3d pose estimation based on
joint interdependency,” in <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on
Computer Vision (ECCV)</em>, 2018, pp. 119–135.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
J. Wang, S. Yan, Y. Xiong, and D. Lin, “Motion guided 3d pose estimation from
videos,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.13985</em>, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T. N. Kipf and M. Welling, “Semi-supervised classification with graph
convolutional networks,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1609.02907</em>, 2016.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and
Y. Bengio, “Graph attention networks,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1710.10903</em>, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
S. Yan, Y. Xiong, D. Lin, and xiaoou Tang, “Spatial temporal graph
convolutional networks for skeleton-based action recognition,” in
<em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">AAAI-18 AAAI Conference on Artificial Intelligence</em>, 2018, pp.
7444–7452.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Li, S. Chen, Y. Zhao, Y. Zhang, Y. Wang, and Q. Tian, “Dynamic multiscale
graph neural networks for 3d skeleton based human motion prediction,” in
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, June 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
C. Ionescu, D. Papava, V. Olaru, and C. Sminchisescu, “Human3.6m: Large scale
datasets and predictive methods for 3d human sensing in natural
environments,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, vol. 36, no. 7, pp. 1325–1339, 2013.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
L. Sigal, A. O. Balan, and M. J. Black, “Humaneva: Synchronized video and
motion capture dataset and baseline algorithm for evaluation of articulated
human motion,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International journal of computer vision</em>, vol. 87, no.
1-2, p. 4, 2010.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y. Chen, Z. Wang, Y. Peng, Z. Zhang, G. Yu, and J. Sun, “Cascaded pyramid
network for multi-person pose estimation,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE
conference on computer vision and pattern recognition</em>, 2018, pp. 7103–7112.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
J. Lin and G. H. Lee, “Trajectory space factorization for deep video-based 3d
human pose estimation,” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1908.08289</em>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
R. Liu, J. Shen, H. Wang, C. Chen, S.-c. Cheung, and V. Asari, “Attention
mechanism exploits temporal contexts: Real-time 3d human pose
reconstruction,” in <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition</em>, 2020, pp. 5064–5073.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
G. Pavlakos, X. Zhou, and K. Daniilidis, “Ordinal depth supervision for 3d
human pose estimation,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition</em>, 2018, pp. 7307–7316.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J. Redmon and A. Farhadi, “Yolov3: An incremental improvement,”
<em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1804.02767</em>, 2018.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
A. Bewley, Z. Ge, L. Ott, F. Ramos, and B. Upcroft, “Simple online and
realtime tracking,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">2016 IEEE International Conference on Image
Processing (ICIP)</em>, 2016, pp. 3464–3468.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
K. Sun, B. Xiao, D. Liu, and J. Wang, “Deep high-resolution
representation learning for human pose estimation,” in <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF
Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2019, pp.
5693–5703.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2003.14178" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2003.14179" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2003.14179">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2003.14179" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2003.14180" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 12:10:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
