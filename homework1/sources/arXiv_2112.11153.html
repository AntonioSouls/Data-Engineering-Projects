<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2112.11153] PONet: Robust 3D Human Pose Estimation via Learning Orientations Only</title><meta property="og:description" content="Conventional 3D human pose estimation
relies on first detecting 2D body keypoints
and then solving the 2D to 3D correspondence problem.
Despite the promising results,
this learning paradigm is highly dependent on the
qâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PONet: Robust 3D Human Pose Estimation via Learning Orientations Only">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="PONet: Robust 3D Human Pose Estimation via Learning Orientations Only">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2112.11153">

<!--Generated on Fri Mar  1 15:27:26 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
3D Human Pose,  keypoint,  Robust Pose
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">PONet: Robust 3D Human Pose Estimation via Learning Orientations Only</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jue Wang, Shaoli Huang<sup id="id2.1.id1" class="ltx_sup">*</sup>,Xinchao Wang, Dacheng Tao
</span><span class="ltx_author_notes"><sup id="id3.2.id1" class="ltx_sup">*</sup>Corresponding authors.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Conventional 3D human pose estimation
relies on first detecting 2D body keypoints
and then solving the 2D to 3D correspondence problem.
Despite the promising results,
this learning paradigm is highly dependent on the
quality of the 2D keypoint detector,
which is inevitably
fragile to occlusions and out-of-image absences.
In this paper,
we propose a novel Pose Orientation NetÂ (PONet)
that is able to
robustly estimate 3D pose by learning orientations only,
hence bypassing the error-prone keypoint detector
in the absence of image evidence.
For images with partially invisible limbs, PONet estimates the 3D orientation of these limbs by taking advantage of the local image evidence to recover the 3D pose.
Moreover, PONet is competent to infer full 3D poses even from images with completely invisible limbs, by exploiting the orientation correlation between visible limbs to complement the estimated poses,
further improving the robustness of 3D pose estimation.
We evaluate our method on multiple datasets, including Human3.6M, MPII, MPI-INF-3DHP, and 3DPW.
Our method achieves results on par with state-of-the-art techniques in ideal settings, yet significantly eliminates the dependency on keypoint detectors and the corresponding computation burden.
In highly challenging scenarios, such as truncation and erasing,
our method performs very robustly and yields
much superior results
as compared to state of the art,
demonstrating its potential for real-world applications.
Our code will be made publicly available.
Please see our video results
in the supplementary materials
for pose estimation in extreme cases.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
3D Human Pose, keypoint, Robust Pose

</div>
<span id="id1a" class="ltx_note ltx_note_frontmatter ltx_role_publicationid"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">publicationid: </span>pubid: 0000â€“0000/00$00.00Â Â©Â 2021 IEEE</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2112.11153/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="338" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example results on Human3.6M with vertical translation from <math id="S1.F1.3.m1.1" class="ltx_Math" alttext="-40\%" display="inline"><semantics id="S1.F1.3.m1.1b"><mrow id="S1.F1.3.m1.1.1" xref="S1.F1.3.m1.1.1.cmml"><mo id="S1.F1.3.m1.1.1b" xref="S1.F1.3.m1.1.1.cmml">âˆ’</mo><mrow id="S1.F1.3.m1.1.1.2" xref="S1.F1.3.m1.1.1.2.cmml"><mn id="S1.F1.3.m1.1.1.2.2" xref="S1.F1.3.m1.1.1.2.2.cmml">40</mn><mo id="S1.F1.3.m1.1.1.2.1" xref="S1.F1.3.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.3.m1.1c"><apply id="S1.F1.3.m1.1.1.cmml" xref="S1.F1.3.m1.1.1"><minus id="S1.F1.3.m1.1.1.1.cmml" xref="S1.F1.3.m1.1.1"></minus><apply id="S1.F1.3.m1.1.1.2.cmml" xref="S1.F1.3.m1.1.1.2"><csymbol cd="latexml" id="S1.F1.3.m1.1.1.2.1.cmml" xref="S1.F1.3.m1.1.1.2.1">percent</csymbol><cn type="integer" id="S1.F1.3.m1.1.1.2.2.cmml" xref="S1.F1.3.m1.1.1.2.2">40</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.3.m1.1d">-40\%</annotation></semantics></math> to <math id="S1.F1.4.m2.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S1.F1.4.m2.1b"><mrow id="S1.F1.4.m2.1.1" xref="S1.F1.4.m2.1.1.cmml"><mn id="S1.F1.4.m2.1.1.2" xref="S1.F1.4.m2.1.1.2.cmml">40</mn><mo id="S1.F1.4.m2.1.1.1" xref="S1.F1.4.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.4.m2.1c"><apply id="S1.F1.4.m2.1.1.cmml" xref="S1.F1.4.m2.1.1"><csymbol cd="latexml" id="S1.F1.4.m2.1.1.1.cmml" xref="S1.F1.4.m2.1.1.1">percent</csymbol><cn type="integer" id="S1.F1.4.m2.1.1.2.cmml" xref="S1.F1.4.m2.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.m2.1d">40\%</annotation></semantics></math>. PC denotes pose complementation. Our PONet is very robust to images with invisible limbs. More visual results on challenging scenarios can be found in our supplement.</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Human pose estimation aims at recovering the coordinates of a human body from one or multiple images, and therefore plays a vital role in an exceptionally broad spectrum of applications.
State-of-the-art 3D human pose estimation methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> rely on first detecting several 2D keypoints, like the body joints, from the image, followed by mapping the 2D keypoint locations back to the 3D world.
The advantage of building 3D pose estimation on 2D keypoint detection
lies in
that the former can inherit the good generalization capacity from the latter.
Despite its popularity,
this scheme still suffers from several flaws.
Firstly, methods built on 2D keypoint detection are usually sensitive to the 2D detection errors,
since the 2D-to-3D mapping is a highly
ill-posed and -conditioned problem.
Minor errors in the locations of the 2D keypoints
may lead to major drifts in the 3D results.
Secondly, 2D keypoint detection requires all the body joints to be visible in the image.
Such prerequisite is justifiable for monitored lab environments,
but unfortunately too strong for practical application scenarios,
where out-of-image absences of body joints and heavy occlusions
frequently occur and thus deteriorate the 3D estimation results.
</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Some recent endeavors have thus focused on
bypassing 2D keypoint detection through recovering human mesh.
For instance, KanazawaÂ <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> propose a method that directly estimates the parameters of SMPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
and then infer the 3D pose from the 3D body shape.
These methods provide richer 3D information about the body, like 3D human skin, while satisfying the anthropometric constrains.
Although this method is capable to handle keypoint-absent cases,
it would fail if a whole limbÂ <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We denote a limb to be the body region between two adjacent joints.</span></span></span> is visually absent.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we attempt to study
3D human pose estimation in challenging
scenarios, where image evidences are incomplete.
To this end, we first
categorize such evidence-incomplete images
into two levels of difficulties:
images with only <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">missing joints</em>,
<em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedoteach limb is at least partially visible,
and images with <em id="S1.p3.1.3" class="ltx_emph ltx_font_italic">missing limbs</em>,
<em id="S1.p3.1.4" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedotat least one limb is completely invisible.
The latter case is unarguably more demanding
than the former, since more visual cues
are absent. However, state-of-the-art methods
and even benchmarks have been focused on complete images or
the former case only, yet have largely overlooked
the latter, which, unfortunately,
better reflects in-the-wild data
in real-world applications.
</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We propose here a robust 3D pose estimation
termed as <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">Pose Orientation Net</em>Â (PONet),
which allows us to effortlessly
to handle both scenarios,
as demonstrated in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
At the heart of our approach is region-based 3D orientation learning and pose complementation.
Specifically, our method estimates limb confidence maps, 2D and 3D limb orientation maps directly from images using a three-branch multi-stage fully convolutional neural networkÂ (FCNN).
The limb confidence map represents the probability of each pixel
within the corresponding limb region,
while the 2D and 3D orientation maps represent
the limb orientations in the pixel space and 3D space, respectively.
The 3D pose estimation is produced by integrating the estimated 3D limb orientations with an embedded skeleton-shaped human model, which consists of free joints and fixed-length limbs.
This region-based orientation learning makes
our method robust to the cases where keypoints are missing.

The motivation behind such a design lies in that,
3D limb orientations enable 3D human pose recovery by utilizing the estimated directional vector oriented from a neighboring body part,
even if the body part of interest is visually incomplete.
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The proposed method also includes a pose complementation sub-network,
which aims to estimate a full 3D pose
when some limbs are missing.
The idea is to infer the 3D configuration of missing body parts from the visible parts, using the prediction confidence as an indicator.
Intuitively, the correlation between 3D limb orientations is stronger than that between keypoints, making it more dependable to infer a full pose
based on orientation relations between visible limbs.
We thereby infer the 3D orientations of invisible limbs from initial 3D orientation predictions of visible limbs,
by taking 3D orientation correlation and limb confidence into account.
The pose complementation sub-network further improves the robustness of 3D pose estimation, especially on images with inaccurate bounding boxes and large translation.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Unlike prior orientation-based methods that usually combine orientation
learning with 2D keypoint detection,
all the three maps adopted in our method are limb-region-based representation.
Such a design not only allows us to
handily carry out knowledge transfer
to images without 3D annotations
by using limb region estimation and 2D orientation learning, which can be trained with both 2D and 3D data, as a bridge,
but also enable differentiable post-processing and end-to-end training.
Besides, we take the average 3D orientation vector, weighted by the region confidence of each pixel,
as the final estimated 3D limb orientation. This pixel-wise voting scheme reduces the effect of noise and outliers in the estimated 3D orientation maps, making the 3D orientation estimation and pose estimation more robust and stable.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">We evaluate our method on several benchmarks, including Human3.6M, MPII, MPI-INF-3DHP, and 3DPW. Our proposed method achieves performance on par with state-of-the-art techniques in standard settings,
but shows much stronger generalization capacity to unseen in-the-wild images.
Moreover, unlike prior methods that usually rely on external keypoint detectorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> or complex human modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>,
our method stands on its own
and
does not require any other third-party pre-trained model.
Most importantly, our method significantly outperforms state-of-the-art techniques on
robustness testing including translation, occlusion, and various erasing,
demonstrating its potential for real-world applications.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Our main contributions are summarized as follows.</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose PONet for robust 3D human pose estimation, which is capable to infer the complete 3D pose even when the input image is incomplete. Our method significantly outperforms state-of-the-art techniques in challenging scenarios such as heavy object-occlusion, large translation and various erasing.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose a region-based orientation learning, which allows us to handily carry out knowledge transfer to in-the-wild images without 3D annotations. Our method yields very promising results on MPI-INF-3DHP and 3DPW without training on them, validating its gratifying generalization capacity.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose a differentiable voting scheme to extract orientations from predicted orientation maps, allowing us to end-to-end train the network and making the orientation estimation more robust and stable.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we briefly review monocular 3D human pose estimation approaches by dividing them into three categories that may overlap each other, <em id="S2.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedot2D keypoint detection based, human mesh recovery based and orientation-based approaches.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">2D keypoint detection based.</span>
2D human pose estimation has witnessed unprecedented progress in recent years and lots of 3D pose estimation methods are built on this technique.
Early efforts on 3D pose estimation used dictionary learning, with the assumption that a 3D pose can be represented by a sparse linear combination of a set of basis posesÂ 
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.
Recently, more and more researchers start to use deep neural networks for 3D pose regressionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
For instance,
MartinezÂ <em id="S2.p2.1.2" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> propose a light weighted fully connected network with residual connections and achieved impressing results.
LeeÂ <em id="S2.p2.1.3" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> propose a long short-term memory (LSTM) architecture to reconstruct 3D depth from the centroid to edge joints through learning the joint inter-dependencies.
LiÂ <em id="S2.p2.1.4" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> improves 2D-to-3D regression by synthesizing new 2D-3D pairs with evolution algorithm.
ChengÂ <em id="S2.p2.1.5" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> use explicit occlusion augmentation to improve the robustness to keypoint detection and 3D pose estimation in image sequences.
The major problem of keypoint-detection-based approaches is that 2D-to-3D lifting is ill-posed and ill-conditioned.
Minor errors in the locations of 2D keypoints can have large consequences in the 3D results.
In addition, these methods are prone to ambiguities in the 2D to 3D correspondence step.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Human mesh recovery based.</span>
Human mesh recovery is a highly related topic with 3D human pose estimation.
Several recent works deal with both tasks.
These methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> recover the 3D human body shape
based on the generative body model SMPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
BogoÂ <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> propose SMPLify, an optimization-based method to recover SMPL parameters from detected 2D joints that leverages multiple priors.
LassnerÂ <em id="S2.p3.1.3" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> take curated results from SMPLify to train 91 keypoint detectors, some of which correspond to the traditional body joints and others correspond to locations on the surface of the body.
KanazawaÂ <em id="S2.p3.1.4" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> directly infer SMPL parameters from images without relying on detected 2D keypoints, allowing shape and pose estimation on images with missing joints.
However, these methods would fail on images with missing limbs.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Orientation learning based</span>
There are a handful of approaches try to learn orientations for 3D pose estimation.
ZhouÂ <em id="S2.p4.1.2" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> propose a kinematic human model that adds different constrains to different joints, to simulate real human structure.
They use CNN to learn rotation angles for the adjustable joints.
CaoÂ <em id="S2.p4.1.3" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> propose <em id="S2.p4.1.4" class="ltx_emph ltx_font_italic">part affinity field</em>Â (PAF) to help linking the keypoints on a person in the multi-person 2D pose estimation problem.
XiangÂ <em id="S2.p4.1.5" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> use PAFs to fit a deformable mesh model to recover 3D shape and pose.
LuoÂ <em id="S2.p4.1.6" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> introduce OriNet that predicts 2D keypoint heatmaps and 3D PAFs for 3D pose estimation.
In LiuÂ <em id="S2.p4.1.7" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotâ€™s workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, 3D orientations are used as additional image evidence to improve the 2D-to-3D regression.
ShiÂ <em id="S2.p4.1.8" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> predict 3D pose by estimates 3D orientations and limb lengths from 2D keypoints.
Again, these approaches rely heavily on 2D keypoints. As a result, they are fragile to keypoint absences as well, let alone cases with limb absence.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Our approach.</span>
The proposed approach estimates 3D pose by only learning limb orientations from images without detecting 2D keypoints.
Our region-based orientation learning allows 3D pose estimation on images where the limbs are partially visible.
In addition, the proposed PONet can infer a full body pose from images with completely invisible limbs, by exploiting the orientation correlation between visible limbs.
Compared to traditional keypoint-detection-based and SMPL-based 3D pose estimation approaches, our method eliminates the dependency on 2D keypoint detectors, and is much more robust to images with visually absent joints or limbs.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2112.11153/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The inference pipeline of PONet. The system takes as input a color image, which can be incomplete.
First, the three-branch multi-stage FCNN simultaneously estimates limb confidence maps <math id="S2.F2.4.m1.1" class="ltx_Math" alttext="\hat{M}_{c}" display="inline"><semantics id="S2.F2.4.m1.1b"><msub id="S2.F2.4.m1.1.1" xref="S2.F2.4.m1.1.1.cmml"><mover accent="true" id="S2.F2.4.m1.1.1.2" xref="S2.F2.4.m1.1.1.2.cmml"><mi id="S2.F2.4.m1.1.1.2.2" xref="S2.F2.4.m1.1.1.2.2.cmml">M</mi><mo id="S2.F2.4.m1.1.1.2.1" xref="S2.F2.4.m1.1.1.2.1.cmml">^</mo></mover><mi id="S2.F2.4.m1.1.1.3" xref="S2.F2.4.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.4.m1.1c"><apply id="S2.F2.4.m1.1.1.cmml" xref="S2.F2.4.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.4.m1.1.1.1.cmml" xref="S2.F2.4.m1.1.1">subscript</csymbol><apply id="S2.F2.4.m1.1.1.2.cmml" xref="S2.F2.4.m1.1.1.2"><ci id="S2.F2.4.m1.1.1.2.1.cmml" xref="S2.F2.4.m1.1.1.2.1">^</ci><ci id="S2.F2.4.m1.1.1.2.2.cmml" xref="S2.F2.4.m1.1.1.2.2">ğ‘€</ci></apply><ci id="S2.F2.4.m1.1.1.3.cmml" xref="S2.F2.4.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.m1.1d">\hat{M}_{c}</annotation></semantics></math> and 2D/3D limb orientation maps <math id="S2.F2.5.m2.1" class="ltx_Math" alttext="\hat{M}_{2D}" display="inline"><semantics id="S2.F2.5.m2.1b"><msub id="S2.F2.5.m2.1.1" xref="S2.F2.5.m2.1.1.cmml"><mover accent="true" id="S2.F2.5.m2.1.1.2" xref="S2.F2.5.m2.1.1.2.cmml"><mi id="S2.F2.5.m2.1.1.2.2" xref="S2.F2.5.m2.1.1.2.2.cmml">M</mi><mo id="S2.F2.5.m2.1.1.2.1" xref="S2.F2.5.m2.1.1.2.1.cmml">^</mo></mover><mrow id="S2.F2.5.m2.1.1.3" xref="S2.F2.5.m2.1.1.3.cmml"><mn id="S2.F2.5.m2.1.1.3.2" xref="S2.F2.5.m2.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.F2.5.m2.1.1.3.1" xref="S2.F2.5.m2.1.1.3.1.cmml">â€‹</mo><mi id="S2.F2.5.m2.1.1.3.3" xref="S2.F2.5.m2.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F2.5.m2.1c"><apply id="S2.F2.5.m2.1.1.cmml" xref="S2.F2.5.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.5.m2.1.1.1.cmml" xref="S2.F2.5.m2.1.1">subscript</csymbol><apply id="S2.F2.5.m2.1.1.2.cmml" xref="S2.F2.5.m2.1.1.2"><ci id="S2.F2.5.m2.1.1.2.1.cmml" xref="S2.F2.5.m2.1.1.2.1">^</ci><ci id="S2.F2.5.m2.1.1.2.2.cmml" xref="S2.F2.5.m2.1.1.2.2">ğ‘€</ci></apply><apply id="S2.F2.5.m2.1.1.3.cmml" xref="S2.F2.5.m2.1.1.3"><times id="S2.F2.5.m2.1.1.3.1.cmml" xref="S2.F2.5.m2.1.1.3.1"></times><cn type="integer" id="S2.F2.5.m2.1.1.3.2.cmml" xref="S2.F2.5.m2.1.1.3.2">2</cn><ci id="S2.F2.5.m2.1.1.3.3.cmml" xref="S2.F2.5.m2.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.5.m2.1d">\hat{M}_{2D}</annotation></semantics></math> and <math id="S2.F2.6.m3.1" class="ltx_Math" alttext="\hat{M}_{3D}" display="inline"><semantics id="S2.F2.6.m3.1b"><msub id="S2.F2.6.m3.1.1" xref="S2.F2.6.m3.1.1.cmml"><mover accent="true" id="S2.F2.6.m3.1.1.2" xref="S2.F2.6.m3.1.1.2.cmml"><mi id="S2.F2.6.m3.1.1.2.2" xref="S2.F2.6.m3.1.1.2.2.cmml">M</mi><mo id="S2.F2.6.m3.1.1.2.1" xref="S2.F2.6.m3.1.1.2.1.cmml">^</mo></mover><mrow id="S2.F2.6.m3.1.1.3" xref="S2.F2.6.m3.1.1.3.cmml"><mn id="S2.F2.6.m3.1.1.3.2" xref="S2.F2.6.m3.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S2.F2.6.m3.1.1.3.1" xref="S2.F2.6.m3.1.1.3.1.cmml">â€‹</mo><mi id="S2.F2.6.m3.1.1.3.3" xref="S2.F2.6.m3.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F2.6.m3.1c"><apply id="S2.F2.6.m3.1.1.cmml" xref="S2.F2.6.m3.1.1"><csymbol cd="ambiguous" id="S2.F2.6.m3.1.1.1.cmml" xref="S2.F2.6.m3.1.1">subscript</csymbol><apply id="S2.F2.6.m3.1.1.2.cmml" xref="S2.F2.6.m3.1.1.2"><ci id="S2.F2.6.m3.1.1.2.1.cmml" xref="S2.F2.6.m3.1.1.2.1">^</ci><ci id="S2.F2.6.m3.1.1.2.2.cmml" xref="S2.F2.6.m3.1.1.2.2">ğ‘€</ci></apply><apply id="S2.F2.6.m3.1.1.3.cmml" xref="S2.F2.6.m3.1.1.3"><times id="S2.F2.6.m3.1.1.3.1.cmml" xref="S2.F2.6.m3.1.1.3.1"></times><cn type="integer" id="S2.F2.6.m3.1.1.3.2.cmml" xref="S2.F2.6.m3.1.1.3.2">3</cn><ci id="S2.F2.6.m3.1.1.3.3.cmml" xref="S2.F2.6.m3.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.6.m3.1d">\hat{M}_{3D}</annotation></semantics></math>.
Then we extract 3D limb orientations from the predicted maps using a differentiable voting scheme to produce an initial 3D pose estimation.
Finally, we use a pose complementationÂ (PC) sub-network, to infer a complete and reasonable final 3D pose estimation from initial estimation.
</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Method</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.3" class="ltx_p">The inference pipeline of the propose PONet is illustrated in Fig.Â <a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Our method takes as input a single color imageÂ (Fig.Â <a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>a), which can be incomplete and have visually absent joints or limbs.
Firstly, we use a three-branch multi-stage fully convolutional neural networkÂ (Fig.Â <a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>b) to simultaneously predict three sets of maps, <em id="S3.p1.3.1" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedotthe limb confidence maps <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\hat{M_{C}}" display="inline"><semantics id="S3.p1.1.m1.1a"><mover accent="true" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><msub id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml"><mi id="S3.p1.1.m1.1.1.2.2" xref="S3.p1.1.m1.1.1.2.2.cmml">M</mi><mi id="S3.p1.1.m1.1.1.2.3" xref="S3.p1.1.m1.1.1.2.3.cmml">C</mi></msub><mo id="S3.p1.1.m1.1.1.1" xref="S3.p1.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><ci id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1.1">^</ci><apply id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.2.1.cmml" xref="S3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.p1.1.m1.1.1.2.2.cmml" xref="S3.p1.1.m1.1.1.2.2">ğ‘€</ci><ci id="S3.p1.1.m1.1.1.2.3.cmml" xref="S3.p1.1.m1.1.1.2.3">ğ¶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\hat{M_{C}}</annotation></semantics></math>, 2D limb orientation maps <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="\hat{M}_{2D}" display="inline"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml"><mi id="S3.p1.2.m2.1.1.2.2" xref="S3.p1.2.m2.1.1.2.2.cmml">M</mi><mo id="S3.p1.2.m2.1.1.2.1" xref="S3.p1.2.m2.1.1.2.1.cmml">^</mo></mover><mrow id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml"><mn id="S3.p1.2.m2.1.1.3.2" xref="S3.p1.2.m2.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.p1.2.m2.1.1.3.1" xref="S3.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.p1.2.m2.1.1.3.3" xref="S3.p1.2.m2.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><apply id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2"><ci id="S3.p1.2.m2.1.1.2.1.cmml" xref="S3.p1.2.m2.1.1.2.1">^</ci><ci id="S3.p1.2.m2.1.1.2.2.cmml" xref="S3.p1.2.m2.1.1.2.2">ğ‘€</ci></apply><apply id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3"><times id="S3.p1.2.m2.1.1.3.1.cmml" xref="S3.p1.2.m2.1.1.3.1"></times><cn type="integer" id="S3.p1.2.m2.1.1.3.2.cmml" xref="S3.p1.2.m2.1.1.3.2">2</cn><ci id="S3.p1.2.m2.1.1.3.3.cmml" xref="S3.p1.2.m2.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\hat{M}_{2D}</annotation></semantics></math> and 3D orientation maps <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="\hat{M}_{3D}" display="inline"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml"><mi id="S3.p1.3.m3.1.1.2.2" xref="S3.p1.3.m3.1.1.2.2.cmml">M</mi><mo id="S3.p1.3.m3.1.1.2.1" xref="S3.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mrow id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml"><mn id="S3.p1.3.m3.1.1.3.2" xref="S3.p1.3.m3.1.1.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.p1.3.m3.1.1.3.1" xref="S3.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.p1.3.m3.1.1.3.3" xref="S3.p1.3.m3.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><apply id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2"><ci id="S3.p1.3.m3.1.1.2.1.cmml" xref="S3.p1.3.m3.1.1.2.1">^</ci><ci id="S3.p1.3.m3.1.1.2.2.cmml" xref="S3.p1.3.m3.1.1.2.2">ğ‘€</ci></apply><apply id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3"><times id="S3.p1.3.m3.1.1.3.1.cmml" xref="S3.p1.3.m3.1.1.3.1"></times><cn type="integer" id="S3.p1.3.m3.1.1.3.2.cmml" xref="S3.p1.3.m3.1.1.3.2">3</cn><ci id="S3.p1.3.m3.1.1.3.3.cmml" xref="S3.p1.3.m3.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\hat{M}_{3D}</annotation></semantics></math>.
Then we use a differentiable voting scheme to extract 3D limb orientations from the predicted maps.
An initial 3D pose estimationÂ (Fig.Â <a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>c) is produced by integrating the predicted 3D limb orientations into a skeleton-shaped human model with fixed limb lengths.
Since the input image may be incomplete, we introduce a pose complementation sub-networkÂ (Fig.Â <a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>e) to infer the 3D orientations of the missing limbs from that of the visible ones, so that the network can estimate a complete final 3D poseÂ (Fig.<a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>f) even if the input image is incomplete.
In the following sections, we explain these steps in detail.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Collaborative orientation learning</span>
</h3>

<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.4.1.1" class="ltx_text">III-A</span>1 </span>Limb orientation representation</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.2" class="ltx_p">FollowingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, we use orientation maps to represent the limb orientations.
Specifically, given an image of size <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="w\times h" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS1.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml">Ã—</mo><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><times id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.1"></times><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">ğ‘¤</ci><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">w\times h</annotation></semantics></math>, a 3D orientation map is a <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="w^{\prime}\times h^{\prime}" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><mrow id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><msup id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.2.cmml">w</mi><mo id="S3.SS1.SSS1.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.3.cmml">â€²</mo></msup><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS1.p1.2.m2.1.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml">Ã—</mo><msup id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.2.cmml">h</mi><mo id="S3.SS1.SSS1.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.3.cmml">â€²</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><times id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.1"></times><apply id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.2">ğ‘¤</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.3">â€²</ci></apply><apply id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.2">â„</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.3">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">w^{\prime}\times h^{\prime}</annotation></semantics></math> three-channel map, where each pixel within the limb region is a directional vector representing the 3D orientation of the limb in 3D space.
The pixels outside the limb region are set to zero vectors.
The 2D orientation maps are defined similarly as 3D orientation maps.
The limb confidence map is a 1-channel map, where each pixel is a value between 0 and 1, representing the probability of the pixel within the limb region.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.5" class="ltx_p">In human pose estimation, the exact human limb region is unavailable.
For simplicity, we take the rectangular region defined by the two end points of the limb and a fixed width <math id="S3.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><mi id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><ci id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">d</annotation></semantics></math> as the limb region.
When the 2D length of the limb is smaller than <math id="S3.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><mi id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><ci id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">d</annotation></semantics></math>, we take the square region centred at the mid-point of the limb as the limb region,
to avoid a too small region while keeping the 2D orientation information.
In this work, the 3D pose consists of <math id="S3.SS1.SSS1.p2.3.m3.1" class="ltx_Math" alttext="17" display="inline"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><mn id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml">17</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><cn type="integer" id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1">17</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">17</annotation></semantics></math> joints and thus <math id="S3.SS1.SSS1.p2.4.m4.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><mn id="S3.SS1.SSS1.p2.4.m4.1.1" xref="S3.SS1.SSS1.p2.4.m4.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.4.m4.1b"><cn type="integer" id="S3.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.4.m4.1c">16</annotation></semantics></math> limbs.
The FCNN predicts these three sets of maps simultaneously, that is <math id="S3.SS1.SSS1.p2.5.m5.1" class="ltx_Math" alttext="16\times(1+2+3)=96" display="inline"><semantics id="S3.SS1.SSS1.p2.5.m5.1a"><mrow id="S3.SS1.SSS1.p2.5.m5.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.cmml"><mrow id="S3.SS1.SSS1.p2.5.m5.1.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.cmml"><mn id="S3.SS1.SSS1.p2.5.m5.1.1.1.3" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS1.p2.5.m5.1.1.1.2" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.2.cmml">Ã—</mo><mrow id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.2" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.cmml"><mn id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.2" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.3" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.3.cmml">2</mn><mo id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.1a" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.4" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.4.cmml">3</mn></mrow><mo stretchy="false" id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.3" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.SSS1.p2.5.m5.1.1.2" xref="S3.SS1.SSS1.p2.5.m5.1.1.2.cmml">=</mo><mn id="S3.SS1.SSS1.p2.5.m5.1.1.3" xref="S3.SS1.SSS1.p2.5.m5.1.1.3.cmml">96</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.5.m5.1b"><apply id="S3.SS1.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1"><eq id="S3.SS1.SSS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.2"></eq><apply id="S3.SS1.SSS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1"><times id="S3.SS1.SSS1.p2.5.m5.1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.2"></times><cn type="integer" id="S3.SS1.SSS1.p2.5.m5.1.1.1.3.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.3">16</cn><apply id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1"><plus id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.1"></plus><cn type="integer" id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.2">1</cn><cn type="integer" id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.3">2</cn><cn type="integer" id="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.4.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.1.1.1.1.4">3</cn></apply></apply><cn type="integer" id="S3.SS1.SSS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.3">96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.5.m5.1c">16\times(1+2+3)=96</annotation></semantics></math> channels in total.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.4.1.1" class="ltx_text">III-A</span>2 </span>Weakly-supervised 3D orientation learning</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">Prior methods usually require specially designed lossesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, additional annotationsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> or adversarial trainingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> to achieve knowledge transfer to in-the-wild images.
By contrast, our PONet can handily generalize to in-the-wild images without extra bells and whistles but achieving better generalization capacity.
Specifically, we use a three-branch multi-stage FCNN to predict the limb confidence maps, 2D and 3D orientation maps, respectively.
Estimation of 2D orientation map is an auxiliary task, which is only used in the training phase to help learning orientation collaboratively and improve generalization.
During training, each mini-batch is randomly sampled from two datasets, an in-the-wild 2D pose dataset MPIIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and an indoor 3D pose dataset Human3.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, with equal probability.
Since both datasets have 2D annotations, we can fully-supervised train the limb confidence map prediction branch and 2D orientation map prediction branch.
For the 3D orientation branch, on average only a half of the training examples, <em id="S3.SS1.SSS2.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedotthose sampled from the 3D dataset, have 3D orientation map supervisions.
The other half of the training data are left unsupervised in this branch.
Our experiments demonstrate that, the proposed PONet can easily generalize to in-the-wild images using this simple weakly-supervised training strategy and achieve much better generalization capacity than state-of-the-art methods.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.7" class="ltx_p">In this paper, the confidence map estimation is taken to be a pixel-wise binary classification problem.
We use the <em id="S3.SS1.SSS2.p2.7.1" class="ltx_emph ltx_font_italic">Binary Cross Entropy</em>Â (BCE) loss for this task:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{CM}}^{t}=\text{BCE}(\hat{M}^{t}_{\text{C}},{M}^{t}_{\text{C}})," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msubsup id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.4.2.2" xref="S3.E1.m1.1.1.1.1.4.2.2.cmml">â„’</mi><mtext id="S3.E1.m1.1.1.1.1.4.2.3" xref="S3.E1.m1.1.1.1.1.4.2.3a.cmml">CM</mtext><mi id="S3.E1.m1.1.1.1.1.4.3" xref="S3.E1.m1.1.1.1.1.4.3.cmml">t</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><mtext id="S3.E1.m1.1.1.1.1.2.4" xref="S3.E1.m1.1.1.1.1.2.4a.cmml">BCE</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">(</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">M</mi><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3a.cmml">C</mtext><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.2.2.2.4" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">,</mo><msubsup id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml">M</mi><mtext id="S3.E1.m1.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3a.cmml">C</mtext><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.2.5" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"></eq><apply id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.1.4">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.4.2.1.cmml" xref="S3.E1.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.4.2.2.cmml" xref="S3.E1.m1.1.1.1.1.4.2.2">â„’</ci><ci id="S3.E1.m1.1.1.1.1.4.2.3a.cmml" xref="S3.E1.m1.1.1.1.1.4.2.3"><mtext mathsize="70%" id="S3.E1.m1.1.1.1.1.4.2.3.cmml" xref="S3.E1.m1.1.1.1.1.4.2.3">CM</mtext></ci></apply><ci id="S3.E1.m1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.1.1.1.1.4.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><times id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3"></times><ci id="S3.E1.m1.1.1.1.1.2.4a.cmml" xref="S3.E1.m1.1.1.1.1.2.4"><mtext id="S3.E1.m1.1.1.1.1.2.4.cmml" xref="S3.E1.m1.1.1.1.1.2.4">BCE</mtext></ci><interval closure="open" id="S3.E1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2"><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.2.2">ğ‘€</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">C</mtext></ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.2">ğ‘€</ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.2.3">ğ‘¡</ci></apply><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.3a.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3"><mtext mathsize="70%" id="S3.E1.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.3">C</mtext></ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{L}_{\text{CM}}^{t}=\text{BCE}(\hat{M}^{t}_{\text{C}},{M}^{t}_{\text{C}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p2.3" class="ltx_p">where <math id="S3.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\hat{M}^{t}_{\text{C}}" display="inline"><semantics id="S3.SS1.SSS2.p2.1.m1.1a"><msubsup id="S3.SS1.SSS2.p2.1.m1.1.1" xref="S3.SS1.SSS2.p2.1.m1.1.1.cmml"><mover accent="true" id="S3.SS1.SSS2.p2.1.m1.1.1.2.2" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.2.cmml"><mi id="S3.SS1.SSS2.p2.1.m1.1.1.2.2.2" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.2.2.cmml">M</mi><mo id="S3.SS1.SSS2.p2.1.m1.1.1.2.2.1" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS2.p2.1.m1.1.1.3" xref="S3.SS1.SSS2.p2.1.m1.1.1.3a.cmml">C</mtext><mi id="S3.SS1.SSS2.p2.1.m1.1.1.2.3" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.1.m1.1b"><apply id="S3.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.1.m1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p2.1.m1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.2"><ci id="S3.SS1.SSS2.p2.1.m1.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.2.1">^</ci><ci id="S3.SS1.SSS2.p2.1.m1.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.2.2">ğ‘€</ci></apply><ci id="S3.SS1.SSS2.p2.1.m1.1.1.2.3.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.SSS2.p2.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.3">C</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.1.m1.1c">\hat{M}^{t}_{\text{C}}</annotation></semantics></math> and <math id="S3.SS1.SSS2.p2.2.m2.1" class="ltx_Math" alttext="{M}^{t}_{\text{C}}" display="inline"><semantics id="S3.SS1.SSS2.p2.2.m2.1a"><msubsup id="S3.SS1.SSS2.p2.2.m2.1.1" xref="S3.SS1.SSS2.p2.2.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p2.2.m2.1.1.2.2" xref="S3.SS1.SSS2.p2.2.m2.1.1.2.2.cmml">M</mi><mtext id="S3.SS1.SSS2.p2.2.m2.1.1.3" xref="S3.SS1.SSS2.p2.2.m2.1.1.3a.cmml">C</mtext><mi id="S3.SS1.SSS2.p2.2.m2.1.1.2.3" xref="S3.SS1.SSS2.p2.2.m2.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.2.m2.1b"><apply id="S3.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1.2.2">ğ‘€</ci><ci id="S3.SS1.SSS2.p2.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.SSS2.p2.2.m2.1.1.3a.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1.3">C</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.2.m2.1c">{M}^{t}_{\text{C}}</annotation></semantics></math> represent the predicted and ground truth limb confidence maps at stage <math id="S3.SS1.SSS2.p2.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.SSS2.p2.3.m3.1a"><mi id="S3.SS1.SSS2.p2.3.m3.1.1" xref="S3.SS1.SSS2.p2.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.3.m3.1b"><ci id="S3.SS1.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.3.m3.1c">t</annotation></semantics></math>, respectively.
The 2D and 3D orientation map estimation is taken to be a regression problem and we use <em id="S3.SS1.SSS2.p2.3.1" class="ltx_emph ltx_font_italic">Mean Squared Error</em>Â (MSE) as the loss function:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{OM2D}}^{t}=\text{MSE}(\hat{M}^{t}_{\text{2D}},{M}^{t}_{\text{2D}})," display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msubsup id="S3.E2.m1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1.1.1.4.2.2" xref="S3.E2.m1.1.1.1.1.4.2.2.cmml">â„’</mi><mtext id="S3.E2.m1.1.1.1.1.4.2.3" xref="S3.E2.m1.1.1.1.1.4.2.3a.cmml">OM2D</mtext><mi id="S3.E2.m1.1.1.1.1.4.3" xref="S3.E2.m1.1.1.1.1.4.3.cmml">t</mi></msubsup><mo id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><mtext id="S3.E2.m1.1.1.1.1.2.4" xref="S3.E2.m1.1.1.1.1.2.4a.cmml">MSE</mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">(</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">M</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.E2.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3a.cmml">2D</mtext><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.E2.m1.1.1.1.1.2.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">,</mo><msubsup id="S3.E2.m1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.cmml">M</mi><mtext id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3a.cmml">2D</mtext><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.E2.m1.1.1.1.1.2.2.2.5" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"></eq><apply id="S3.E2.m1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.4.1.cmml" xref="S3.E2.m1.1.1.1.1.4">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.4.2.cmml" xref="S3.E2.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.4.2.1.cmml" xref="S3.E2.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.4.2.2.cmml" xref="S3.E2.m1.1.1.1.1.4.2.2">â„’</ci><ci id="S3.E2.m1.1.1.1.1.4.2.3a.cmml" xref="S3.E2.m1.1.1.1.1.4.2.3"><mtext mathsize="70%" id="S3.E2.m1.1.1.1.1.4.2.3.cmml" xref="S3.E2.m1.1.1.1.1.4.2.3">OM2D</mtext></ci></apply><ci id="S3.E2.m1.1.1.1.1.4.3.cmml" xref="S3.E2.m1.1.1.1.1.4.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><times id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3"></times><ci id="S3.E2.m1.1.1.1.1.2.4a.cmml" xref="S3.E2.m1.1.1.1.1.2.4"><mtext id="S3.E2.m1.1.1.1.1.2.4.cmml" xref="S3.E2.m1.1.1.1.1.2.4">MSE</mtext></ci><interval closure="open" id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2"><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.2.2">ğ‘€</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3">2D</mtext></ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2">ğ‘€</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3">ğ‘¡</ci></apply><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3"><mtext mathsize="70%" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3">2D</mtext></ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\mathcal{L}_{\text{OM2D}}^{t}=\text{MSE}(\hat{M}^{t}_{\text{2D}},{M}^{t}_{\text{2D}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{OM3D}}^{t}=\text{MSE}(\hat{M}^{t}_{\text{3D}},{M}^{t}_{\text{3D}})," display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msubsup id="S3.E3.m1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.4.2.2" xref="S3.E3.m1.1.1.1.1.4.2.2.cmml">â„’</mi><mtext id="S3.E3.m1.1.1.1.1.4.2.3" xref="S3.E3.m1.1.1.1.1.4.2.3a.cmml">OM3D</mtext><mi id="S3.E3.m1.1.1.1.1.4.3" xref="S3.E3.m1.1.1.1.1.4.3.cmml">t</mi></msubsup><mo id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mtext id="S3.E3.m1.1.1.1.1.2.4" xref="S3.E3.m1.1.1.1.1.2.4a.cmml">MSE</mtext><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">(</mo><msubsup id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">M</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3a.cmml">3D</mtext><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.E3.m1.1.1.1.1.2.2.2.4" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">,</mo><msubsup id="S3.E3.m1.1.1.1.1.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.cmml">M</mi><mtext id="S3.E3.m1.1.1.1.1.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3a.cmml">3D</mtext><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2.2.2.5" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"></eq><apply id="S3.E3.m1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.4.1.cmml" xref="S3.E3.m1.1.1.1.1.4">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.4.2.cmml" xref="S3.E3.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.4.2.1.cmml" xref="S3.E3.m1.1.1.1.1.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.4.2.2.cmml" xref="S3.E3.m1.1.1.1.1.4.2.2">â„’</ci><ci id="S3.E3.m1.1.1.1.1.4.2.3a.cmml" xref="S3.E3.m1.1.1.1.1.4.2.3"><mtext mathsize="70%" id="S3.E3.m1.1.1.1.1.4.2.3.cmml" xref="S3.E3.m1.1.1.1.1.4.2.3">OM3D</mtext></ci></apply><ci id="S3.E3.m1.1.1.1.1.4.3.cmml" xref="S3.E3.m1.1.1.1.1.4.3">ğ‘¡</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3"></times><ci id="S3.E3.m1.1.1.1.1.2.4a.cmml" xref="S3.E3.m1.1.1.1.1.2.4"><mtext id="S3.E3.m1.1.1.1.1.2.4.cmml" xref="S3.E3.m1.1.1.1.1.2.4">MSE</mtext></ci><interval closure="open" id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2"><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.2.2">ğ‘€</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">3D</mtext></ci></apply><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2">ğ‘€</ci><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.3">ğ‘¡</ci></apply><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.3a.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3"><mtext mathsize="70%" id="S3.E3.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3">3D</mtext></ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\mathcal{L}_{\text{OM3D}}^{t}=\text{MSE}(\hat{M}^{t}_{\text{3D}},{M}^{t}_{\text{3D}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p2.6" class="ltx_p">where <math id="S3.SS1.SSS2.p2.4.m1.1" class="ltx_Math" alttext="\hat{M}^{t}_{\text{2D/3D}}" display="inline"><semantics id="S3.SS1.SSS2.p2.4.m1.1a"><msubsup id="S3.SS1.SSS2.p2.4.m1.1.1" xref="S3.SS1.SSS2.p2.4.m1.1.1.cmml"><mover accent="true" id="S3.SS1.SSS2.p2.4.m1.1.1.2.2" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.2.cmml"><mi id="S3.SS1.SSS2.p2.4.m1.1.1.2.2.2" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.2.2.cmml">M</mi><mo id="S3.SS1.SSS2.p2.4.m1.1.1.2.2.1" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.2.1.cmml">^</mo></mover><mtext id="S3.SS1.SSS2.p2.4.m1.1.1.3" xref="S3.SS1.SSS2.p2.4.m1.1.1.3a.cmml">2D/3D</mtext><mi id="S3.SS1.SSS2.p2.4.m1.1.1.2.3" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.4.m1.1b"><apply id="S3.SS1.SSS2.p2.4.m1.1.1.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.4.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p2.4.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.4.m1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p2.4.m1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.2"><ci id="S3.SS1.SSS2.p2.4.m1.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.2.1">^</ci><ci id="S3.SS1.SSS2.p2.4.m1.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.2.2">ğ‘€</ci></apply><ci id="S3.SS1.SSS2.p2.4.m1.1.1.2.3.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.SSS2.p2.4.m1.1.1.3a.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.4.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p2.4.m1.1.1.3">2D/3D</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.4.m1.1c">\hat{M}^{t}_{\text{2D/3D}}</annotation></semantics></math> and <math id="S3.SS1.SSS2.p2.5.m2.1" class="ltx_Math" alttext="{M}^{t}_{\text{2D/3D}}" display="inline"><semantics id="S3.SS1.SSS2.p2.5.m2.1a"><msubsup id="S3.SS1.SSS2.p2.5.m2.1.1" xref="S3.SS1.SSS2.p2.5.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p2.5.m2.1.1.2.2" xref="S3.SS1.SSS2.p2.5.m2.1.1.2.2.cmml">M</mi><mtext id="S3.SS1.SSS2.p2.5.m2.1.1.3" xref="S3.SS1.SSS2.p2.5.m2.1.1.3a.cmml">2D/3D</mtext><mi id="S3.SS1.SSS2.p2.5.m2.1.1.2.3" xref="S3.SS1.SSS2.p2.5.m2.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.5.m2.1b"><apply id="S3.SS1.SSS2.p2.5.m2.1.1.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.5.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p2.5.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.5.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p2.5.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1.2.2">ğ‘€</ci><ci id="S3.SS1.SSS2.p2.5.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.SSS2.p2.5.m2.1.1.3a.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.5.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p2.5.m2.1.1.3">2D/3D</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.5.m2.1c">{M}^{t}_{\text{2D/3D}}</annotation></semantics></math> denote the predicted and ground truth 2D/3D orientation maps at stage <math id="S3.SS1.SSS2.p2.6.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.SSS2.p2.6.m3.1a"><mi id="S3.SS1.SSS2.p2.6.m3.1.1" xref="S3.SS1.SSS2.p2.6.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.6.m3.1b"><ci id="S3.SS1.SSS2.p2.6.m3.1.1.cmml" xref="S3.SS1.SSS2.p2.6.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.6.m3.1c">t</annotation></semantics></math>, respectively.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.4.1.1" class="ltx_text">III-A</span>3 </span>Differentiable voting scheme for orientation extraction</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">Prior orientation based methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> extract the directional vectors from orientation maps by computing the line integral over the corresponding orientation maps along the line segment connecting the detected part locations.
Many other candidate directional vectors that not on the line segment, which also contain important orientation information, however, are discarded.
Besides, this procedure depends on the detected 2D keypoint locations, making it non-differentiable and thus disables end-to-end training.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p id="S3.SS1.SSS3.p2.3" class="ltx_p">To address the above problems, we present a differentiable voting scheme to extract orientation vectors from the predicted orientation maps.
As described in SectionÂ <a href="#S3.SS1.SSS1" title="III-A1 Limb orientation representation â€£ III-A Collaborative orientation learning â€£ III Method â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>1</span></a>, our method predicts the limb confidence maps and 3D orientation maps at the same time.
For each limb <math id="S3.SS1.SSS3.p2.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS3.p2.1.m1.1a"><mi id="S3.SS1.SSS3.p2.1.m1.1.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.1.m1.1b"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.1.m1.1c">i</annotation></semantics></math> , we extract its 3D limb orientation by taking average of all the pixels in the pixel-wise product of the predicted limb confidence map <math id="S3.SS1.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\hat{M}_{\text{C}i}" display="inline"><semantics id="S3.SS1.SSS3.p2.2.m2.1a"><msub id="S3.SS1.SSS3.p2.2.m2.1.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.cmml"><mover accent="true" id="S3.SS1.SSS3.p2.2.m2.1.1.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.2.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.2.cmml">M</mi><mo id="S3.SS1.SSS3.p2.2.m2.1.1.2.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS1.SSS3.p2.2.m2.1.1.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.cmml"><mtext id="S3.SS1.SSS3.p2.2.m2.1.1.3.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.2a.cmml">C</mtext><mo lspace="0em" rspace="0em" id="S3.SS1.SSS3.p2.2.m2.1.1.3.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS3.p2.2.m2.1.1.3.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.2.m2.1b"><apply id="S3.SS1.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS3.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2"><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.1">^</ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.2">ğ‘€</ci></apply><apply id="S3.SS1.SSS3.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3"><times id="S3.SS1.SSS3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.1"></times><ci id="S3.SS1.SSS3.p2.2.m2.1.1.3.2a.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.2"><mtext mathsize="70%" id="S3.SS1.SSS3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.2">C</mtext></ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.2.m2.1c">\hat{M}_{\text{C}i}</annotation></semantics></math> and 3D orientation map <math id="S3.SS1.SSS3.p2.3.m3.1" class="ltx_Math" alttext="\hat{M}_{\text{3D}i}" display="inline"><semantics id="S3.SS1.SSS3.p2.3.m3.1a"><msub id="S3.SS1.SSS3.p2.3.m3.1.1" xref="S3.SS1.SSS3.p2.3.m3.1.1.cmml"><mover accent="true" id="S3.SS1.SSS3.p2.3.m3.1.1.2" xref="S3.SS1.SSS3.p2.3.m3.1.1.2.cmml"><mi id="S3.SS1.SSS3.p2.3.m3.1.1.2.2" xref="S3.SS1.SSS3.p2.3.m3.1.1.2.2.cmml">M</mi><mo id="S3.SS1.SSS3.p2.3.m3.1.1.2.1" xref="S3.SS1.SSS3.p2.3.m3.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS1.SSS3.p2.3.m3.1.1.3" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.cmml"><mtext id="S3.SS1.SSS3.p2.3.m3.1.1.3.2" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2a.cmml">3D</mtext><mo lspace="0em" rspace="0em" id="S3.SS1.SSS3.p2.3.m3.1.1.3.1" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.SSS3.p2.3.m3.1.1.3.3" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.3.m3.1b"><apply id="S3.SS1.SSS3.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1">subscript</csymbol><apply id="S3.SS1.SSS3.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.2"><ci id="S3.SS1.SSS3.p2.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.2.1">^</ci><ci id="S3.SS1.SSS3.p2.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.2.2">ğ‘€</ci></apply><apply id="S3.SS1.SSS3.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3"><times id="S3.SS1.SSS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.1"></times><ci id="S3.SS1.SSS3.p2.3.m3.1.1.3.2a.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2"><mtext mathsize="70%" id="S3.SS1.SSS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2">3D</mtext></ci><ci id="S3.SS1.SSS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.3.m3.1c">\hat{M}_{\text{3D}i}</annotation></semantics></math> of the last stage:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="v_{i}=\frac{1}{w^{\prime}h^{\prime}}\sum_{w^{\prime}}\sum_{h^{\prime}}\hat{M}_{\text{C}i}\odot\hat{M}_{\text{3D}i}," display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.2.2.cmml">v</mi><mi id="S3.E4.m1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><mfrac id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2.cmml"><mn id="S3.E4.m1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.cmml">1</mn><mrow id="S3.E4.m1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.cmml"><msup id="S3.E4.m1.1.1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.1.1.3.2.3.2.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.3.2.2.cmml">w</mi><mo id="S3.E4.m1.1.1.1.1.3.2.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.2.3.cmml">â€²</mo></msup><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.2.3.1" xref="S3.E4.m1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><msup id="S3.E4.m1.1.1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.1.1.3.2.3.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.3.3.2" xref="S3.E4.m1.1.1.1.1.3.2.3.3.2.cmml">h</mi><mo id="S3.E4.m1.1.1.1.1.3.2.3.3.3" xref="S3.E4.m1.1.1.1.1.3.2.3.3.3.cmml">â€²</mo></msup></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml"><munder id="S3.E4.m1.1.1.1.1.3.3.1" xref="S3.E4.m1.1.1.1.1.3.3.1.cmml"><mo movablelimits="false" rspace="0em" id="S3.E4.m1.1.1.1.1.3.3.1.2" xref="S3.E4.m1.1.1.1.1.3.3.1.2.cmml">âˆ‘</mo><msup id="S3.E4.m1.1.1.1.1.3.3.1.3" xref="S3.E4.m1.1.1.1.1.3.3.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.1.3.2" xref="S3.E4.m1.1.1.1.1.3.3.1.3.2.cmml">w</mi><mo id="S3.E4.m1.1.1.1.1.3.3.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.1.3.3.cmml">â€²</mo></msup></munder><mrow id="S3.E4.m1.1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.cmml"><munder id="S3.E4.m1.1.1.1.1.3.3.2.1" xref="S3.E4.m1.1.1.1.1.3.3.2.1.cmml"><mo movablelimits="false" id="S3.E4.m1.1.1.1.1.3.3.2.1.2" xref="S3.E4.m1.1.1.1.1.3.3.2.1.2.cmml">âˆ‘</mo><msup id="S3.E4.m1.1.1.1.1.3.3.2.1.3" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.2.1.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3.2.cmml">h</mi><mo id="S3.E4.m1.1.1.1.1.3.3.2.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3.3.cmml">â€²</mo></msup></munder><mrow id="S3.E4.m1.1.1.1.1.3.3.2.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.cmml"><msub id="S3.E4.m1.1.1.1.1.3.3.2.2.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.cmml"><mover accent="true" id="S3.E4.m1.1.1.1.1.3.3.2.2.2.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.2.cmml">M</mi><mo id="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.1" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.1.cmml">^</mo></mover><mrow id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.cmml"><mtext id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.2a.cmml">C</mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.1" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.3" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.3.cmml">i</mi></mrow></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E4.m1.1.1.1.1.3.3.2.2.1" xref="S3.E4.m1.1.1.1.1.3.3.2.2.1.cmml">âŠ™</mo><msub id="S3.E4.m1.1.1.1.1.3.3.2.2.3" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S3.E4.m1.1.1.1.1.3.3.2.2.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.cmml"><mi id="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.2.cmml">M</mi><mo id="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.1" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.1.cmml">^</mo></mover><mrow id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.cmml"><mtext id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.2" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.2a.cmml">3D</mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.1" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.3" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.3.cmml">i</mi></mrow></msub></mrow></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"></eq><apply id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.2.2">ğ‘£</ci><ci id="S3.E4.m1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><times id="S3.E4.m1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.1"></times><apply id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2"><divide id="S3.E4.m1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2"></divide><cn type="integer" id="S3.E4.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2">1</cn><apply id="S3.E4.m1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3"><times id="S3.E4.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.1"></times><apply id="S3.E4.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2.2">ğ‘¤</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2.3">â€²</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3.2">â„</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3.3">â€²</ci></apply></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3"><apply id="S3.E4.m1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="S3.E4.m1.1.1.1.1.3.3.1.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.2"></sum><apply id="S3.E4.m1.1.1.1.1.3.3.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.3.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.3.2">ğ‘¤</ci><ci id="S3.E4.m1.1.1.1.1.3.3.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.1.3.3">â€²</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2"><apply id="S3.E4.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.2.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1">subscript</csymbol><sum id="S3.E4.m1.1.1.1.1.3.3.2.1.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1.2"></sum><apply id="S3.E4.m1.1.1.1.1.3.3.2.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.2.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.3.2.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3.2">â„</ci><ci id="S3.E4.m1.1.1.1.1.3.3.2.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.1.3.3">â€²</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.3.3.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.1">direct-product</csymbol><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.2"><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.1">^</ci><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.2.2">ğ‘€</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3"><times id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.1"></times><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.2a.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.2"><mtext mathsize="70%" id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.2">C</mtext></ci><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.2.3.3">ğ‘–</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.3.2.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.2"><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.1">^</ci><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.2.2">ğ‘€</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3"><times id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.1"></times><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.2a.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.2"><mtext mathsize="70%" id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.2">3D</mtext></ci><ci id="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3.2.2.3.3.3">ğ‘–</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">v_{i}=\frac{1}{w^{\prime}h^{\prime}}\sum_{w^{\prime}}\sum_{h^{\prime}}\hat{M}_{\text{C}i}\odot\hat{M}_{\text{3D}i},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS3.p2.4" class="ltx_p">where <math id="S3.SS1.SSS3.p2.4.m1.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S3.SS1.SSS3.p2.4.m1.1a"><mo id="S3.SS1.SSS3.p2.4.m1.1.1" xref="S3.SS1.SSS3.p2.4.m1.1.1.cmml">âŠ™</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.4.m1.1b"><csymbol cd="latexml" id="S3.SS1.SSS3.p2.4.m1.1.1.cmml" xref="S3.SS1.SSS3.p2.4.m1.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.4.m1.1c">\odot</annotation></semantics></math> denotes pixel-wise product. Obviously, Eq.Â <a href="#S3.E4" title="In III-A3 Differentiable voting scheme for orientation extraction â€£ III-A Collaborative orientation learning â€£ III Method â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> is differentiable, which makes end-to-end training possible.
Besides, this confidence weighted voting scheme can leverage all the predicted orientation information, making our orientation estimation more accurate and stable.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS4.4.1.1" class="ltx_text">III-A</span>4 </span>Integration 3D orientations with human model</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p id="S3.SS1.SSS4.p1.5" class="ltx_p">Our method generates 3D pose estimation by integrating the estimated 3D orientations with a skeleton-shaped human model with fixed-length limbs.
This process works like twisting the limbs of the human model to fit the predicted 3D limb orientations.
Like many prior methods, we treat the pelvis as the root node and fix it to the origin.
For each child node <math id="S3.SS1.SSS4.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS4.p1.1.m1.1a"><mi id="S3.SS1.SSS4.p1.1.m1.1.1" xref="S3.SS1.SSS4.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.1.m1.1b"><ci id="S3.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS4.p1.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.1.m1.1c">i</annotation></semantics></math>, its location <math id="S3.SS1.SSS4.p1.2.m2.1" class="ltx_Math" alttext="Y_{i}" display="inline"><semantics id="S3.SS1.SSS4.p1.2.m2.1a"><msub id="S3.SS1.SSS4.p1.2.m2.1.1" xref="S3.SS1.SSS4.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS4.p1.2.m2.1.1.2" xref="S3.SS1.SSS4.p1.2.m2.1.1.2.cmml">Y</mi><mi id="S3.SS1.SSS4.p1.2.m2.1.1.3" xref="S3.SS1.SSS4.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.2.m2.1b"><apply id="S3.SS1.SSS4.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS4.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS4.p1.2.m2.1.1.2">ğ‘Œ</ci><ci id="S3.SS1.SSS4.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS4.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.2.m2.1c">Y_{i}</annotation></semantics></math> is determined by its parent nodeâ€™s location <math id="S3.SS1.SSS4.p1.3.m3.1" class="ltx_Math" alttext="X_{i}" display="inline"><semantics id="S3.SS1.SSS4.p1.3.m3.1a"><msub id="S3.SS1.SSS4.p1.3.m3.1.1" xref="S3.SS1.SSS4.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS4.p1.3.m3.1.1.2" xref="S3.SS1.SSS4.p1.3.m3.1.1.2.cmml">X</mi><mi id="S3.SS1.SSS4.p1.3.m3.1.1.3" xref="S3.SS1.SSS4.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.3.m3.1b"><apply id="S3.SS1.SSS4.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS4.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.2">ğ‘‹</ci><ci id="S3.SS1.SSS4.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS4.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.3.m3.1c">X_{i}</annotation></semantics></math>, the estimated 3D orientation <math id="S3.SS1.SSS4.p1.4.m4.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S3.SS1.SSS4.p1.4.m4.1a"><msub id="S3.SS1.SSS4.p1.4.m4.1.1" xref="S3.SS1.SSS4.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS4.p1.4.m4.1.1.2" xref="S3.SS1.SSS4.p1.4.m4.1.1.2.cmml">v</mi><mi id="S3.SS1.SSS4.p1.4.m4.1.1.3" xref="S3.SS1.SSS4.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.4.m4.1b"><apply id="S3.SS1.SSS4.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS4.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS4.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS4.p1.4.m4.1.1.2">ğ‘£</ci><ci id="S3.SS1.SSS4.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS4.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.4.m4.1c">v_{i}</annotation></semantics></math> and the 3D limb length <math id="S3.SS1.SSS4.p1.5.m5.1" class="ltx_Math" alttext="L_{i}" display="inline"><semantics id="S3.SS1.SSS4.p1.5.m5.1a"><msub id="S3.SS1.SSS4.p1.5.m5.1.1" xref="S3.SS1.SSS4.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS4.p1.5.m5.1.1.2" xref="S3.SS1.SSS4.p1.5.m5.1.1.2.cmml">L</mi><mi id="S3.SS1.SSS4.p1.5.m5.1.1.3" xref="S3.SS1.SSS4.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.5.m5.1b"><apply id="S3.SS1.SSS4.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS4.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.2">ğ¿</ci><ci id="S3.SS1.SSS4.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS4.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.5.m5.1c">L_{i}</annotation></semantics></math> as follows:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="Y_{i}=X_{i}+L_{i}v_{i}," display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msub id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.2.2.cmml">Y</mi><mi id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><msub id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2.2" xref="S3.E5.m1.1.1.1.1.3.2.2.cmml">X</mi><mi id="S3.E5.m1.1.1.1.1.3.2.3" xref="S3.E5.m1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.E5.m1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3.cmml"><msub id="S3.E5.m1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.2.2" xref="S3.E5.m1.1.1.1.1.3.3.2.2.cmml">L</mi><mi id="S3.E5.m1.1.1.1.1.3.3.2.3" xref="S3.E5.m1.1.1.1.1.3.3.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.1.1.3.3.1" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E5.m1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.3.2.cmml">v</mi><mi id="S3.E5.m1.1.1.1.1.3.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"></eq><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2">ğ‘Œ</ci><ci id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><plus id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.1"></plus><apply id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2.2">ğ‘‹</ci><ci id="S3.E5.m1.1.1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3"><times id="S3.E5.m1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.1"></times><apply id="S3.E5.m1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.2">ğ¿</ci><ci id="S3.E5.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2.3">ğ‘–</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.2">ğ‘£</ci><ci id="S3.E5.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3.3.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">Y_{i}=X_{i}+L_{i}v_{i},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS4.p1.6" class="ltx_p">where <math id="S3.SS1.SSS4.p1.6.m1.1" class="ltx_Math" alttext="X_{0}=0" display="inline"><semantics id="S3.SS1.SSS4.p1.6.m1.1a"><mrow id="S3.SS1.SSS4.p1.6.m1.1.1" xref="S3.SS1.SSS4.p1.6.m1.1.1.cmml"><msub id="S3.SS1.SSS4.p1.6.m1.1.1.2" xref="S3.SS1.SSS4.p1.6.m1.1.1.2.cmml"><mi id="S3.SS1.SSS4.p1.6.m1.1.1.2.2" xref="S3.SS1.SSS4.p1.6.m1.1.1.2.2.cmml">X</mi><mn id="S3.SS1.SSS4.p1.6.m1.1.1.2.3" xref="S3.SS1.SSS4.p1.6.m1.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS1.SSS4.p1.6.m1.1.1.1" xref="S3.SS1.SSS4.p1.6.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS4.p1.6.m1.1.1.3" xref="S3.SS1.SSS4.p1.6.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS4.p1.6.m1.1b"><apply id="S3.SS1.SSS4.p1.6.m1.1.1.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1"><eq id="S3.SS1.SSS4.p1.6.m1.1.1.1.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1.1"></eq><apply id="S3.SS1.SSS4.p1.6.m1.1.1.2.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS4.p1.6.m1.1.1.2.1.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS4.p1.6.m1.1.1.2.2.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1.2.2">ğ‘‹</ci><cn type="integer" id="S3.SS1.SSS4.p1.6.m1.1.1.2.3.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1.2.3">0</cn></apply><cn type="integer" id="S3.SS1.SSS4.p1.6.m1.1.1.3.cmml" xref="S3.SS1.SSS4.p1.6.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS4.p1.6.m1.1c">X_{0}=0</annotation></semantics></math>. The 3D pose is generated from root node to leaf nodes by recursively applying Eq.Â <a href="#S3.E5" title="In III-A4 Integration 3D orientations with human model â€£ III-A Collaborative orientation learning â€£ III Method â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> until all the leaf nodes are determined.</p>
</div>
</section>
<section id="S3.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS5.4.1.1" class="ltx_text">III-A</span>5 </span>End-to-end training with 3D pose loss</h4>

<div id="S3.SS1.SSS5.p1" class="ltx_para">
<p id="S3.SS1.SSS5.p1.1" class="ltx_p">In SectionÂ <a href="#S3.SS1.SSS2" title="III-A2 Weakly-supervised 3D orientation learning â€£ III-A Collaborative orientation learning â€£ III Method â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>2</span></a>, each limb orientation is <em id="S3.SS1.SSS5.p1.1.1" class="ltx_emph ltx_font_italic">separately</em> optimized.
Although limb orientation errors do not accumulate,
3D joint location errors could propagate along the skeleton tree and possibly accumulate into large errors for joints at the leaf node.</p>
</div>
<div id="S3.SS1.SSS5.p2" class="ltx_para">
<p id="S3.SS1.SSS5.p2.3" class="ltx_p">To this end, long-term objectives should be considered so that the 3D orientations are jointly optimized.
In our method, since all the steps are differentiable,
we can directly use the 3D pose loss as the long-term objective and train the model end-to-end.
This works like slightly adjusting the limb orientation so that the joint locations fit the ground truth better.
In experiment, we find that end-to-end training can speed up the convergence, and improve the inference accuracy as well.
Here we use L1 loss for 3D pose following many prior works:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{P3D}}=|\hat{S}-{S}|," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml">â„’</mi><mtext id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3a.cmml">P3D</mtext></msub><mo id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E6.m1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.1.1.1.2.2.cmml">S</mi><mo id="S3.E6.m1.1.1.1.1.1.1.1.2.1" xref="S3.E6.m1.1.1.1.1.1.1.1.2.1.cmml">^</mo></mover><mo id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"></eq><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2">â„’</ci><ci id="S3.E6.m1.1.1.1.1.3.3a.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3">P3D</mtext></ci></apply><apply id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1"><abs id="S3.E6.m1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.2"></abs><apply id="S3.E6.m1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1"><minus id="S3.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E6.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.2"><ci id="S3.E6.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.2.1">^</ci><ci id="S3.E6.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.2.2">ğ‘†</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.3">ğ‘†</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathcal{L}_{\text{P3D}}=|\hat{S}-{S}|,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS5.p2.2" class="ltx_p">where <math id="S3.SS1.SSS5.p2.1.m1.1" class="ltx_Math" alttext="\hat{S}" display="inline"><semantics id="S3.SS1.SSS5.p2.1.m1.1a"><mover accent="true" id="S3.SS1.SSS5.p2.1.m1.1.1" xref="S3.SS1.SSS5.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS5.p2.1.m1.1.1.2" xref="S3.SS1.SSS5.p2.1.m1.1.1.2.cmml">S</mi><mo id="S3.SS1.SSS5.p2.1.m1.1.1.1" xref="S3.SS1.SSS5.p2.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS5.p2.1.m1.1b"><apply id="S3.SS1.SSS5.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS5.p2.1.m1.1.1"><ci id="S3.SS1.SSS5.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS5.p2.1.m1.1.1.1">^</ci><ci id="S3.SS1.SSS5.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS5.p2.1.m1.1.1.2">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS5.p2.1.m1.1c">\hat{S}</annotation></semantics></math> and <math id="S3.SS1.SSS5.p2.2.m2.1" class="ltx_Math" alttext="{S}" display="inline"><semantics id="S3.SS1.SSS5.p2.2.m2.1a"><mi id="S3.SS1.SSS5.p2.2.m2.1.1" xref="S3.SS1.SSS5.p2.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS5.p2.2.m2.1b"><ci id="S3.SS1.SSS5.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS5.p2.2.m2.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS5.p2.2.m2.1c">{S}</annotation></semantics></math> represent the predicted and ground truth 3D pose at the last stage, respectively.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Human pose complementation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The orientation learning network can produce a complete pose estimation unless all limbs are at least partially visible in the image.
If a limb is completely visually absent, the estimated 3D orientation of the missing limb could be a zero vector or noisy values, resulting in an incomplete or wrong estimation.
To this end, we propose a pose complementationÂ (PC) networkÂ (see Fig.Â <a href="#S2.F2" title="Figure 2 â€£ II Related work â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>e) to infer the 3D orientations of the invisible limbs from visible ones.
To achieve this, there are two key problems to answer.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">(a) Which limbs should be complemented?</span>
Different testing images may have different missing limbs and different number of missing limbs.
How to let the network know which limbs need to be complemented?
Our solution is straightforward, <em id="S3.SS2.p2.1.2" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedotusing the predicted limb confidence score as an indicator.
Generally, the 3D orientation estimations of invisible limbs tend to have low confidence scores while visible ones have high ones.
In other words, limbs with lower confidence scores are probably invisible and the corresponding 3D orientations may need to be re-inferred.
So we explicitly provide the PC sub-network information about which limbs need complementation by feeding the limb confidence scores into it.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p"><span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">(b) How to complement?</span>
Fig.Â <a href="#S3.F3" title="Figure 3 â€£ III-B Human pose complementation â€£ III Method â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows an example of the proposed pose complementation, which is aimed to infer the configuration of missing limbs and provide an overall reasonable pose estimation, while keeping estimation of the visible parts consistent with the input image.
To achieve this,
we feed into the PC sub-network with three components, the predicted limb confidence score, the initial 3D limb orientation estimation and the upper triangular part of the 3D orientation correlation matrix masked by the confidence correlation matrix.
The dimension of the input is <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="16+16\times 3+16(16+1)/2=200" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mrow id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.3.cmml">16</mn><mo id="S3.SS2.p3.1.m1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.2.cmml">+</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.4" xref="S3.SS2.p3.1.m1.1.1.1.4.cmml"><mn id="S3.SS2.p3.1.m1.1.1.1.4.2" xref="S3.SS2.p3.1.m1.1.1.1.4.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.1.1.1.4.1" xref="S3.SS2.p3.1.m1.1.1.1.4.1.cmml">Ã—</mo><mn id="S3.SS2.p3.1.m1.1.1.1.4.3" xref="S3.SS2.p3.1.m1.1.1.1.4.3.cmml">3</mn></mrow><mo id="S3.SS2.p3.1.m1.1.1.1.2a" xref="S3.SS2.p3.1.m1.1.1.1.2.cmml">+</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.cmml"><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml">16</mn><mo lspace="0em" rspace="0em" id="S3.SS2.p3.1.m1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2.cmml">16</mn><mo id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.1.m1.1.1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.1.1.2.cmml">/</mo><mn id="S3.SS2.p3.1.m1.1.1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.1.1.3.cmml">2</mn></mrow></mrow><mo id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">=</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><eq id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2"></eq><apply id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"><plus id="S3.SS2.p3.1.m1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.2"></plus><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.3">16</cn><apply id="S3.SS2.p3.1.m1.1.1.1.4.cmml" xref="S3.SS2.p3.1.m1.1.1.1.4"><times id="S3.SS2.p3.1.m1.1.1.1.4.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.4.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.4.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.4.2">16</cn><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.4.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.4.3">3</cn></apply><apply id="S3.SS2.p3.1.m1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1"><divide id="S3.SS2.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.2"></divide><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.2"></times><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.3">16</cn><apply id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1"><plus id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.1"></plus><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.2">16</cn><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.1.1.1.1.3">1</cn></apply></apply><cn type="integer" id="S3.SS2.p3.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.1.1.3">2</cn></apply></apply><cn type="integer" id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">16+16\times 3+16(16+1)/2=200</annotation></semantics></math>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2112.11153/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="250" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An illustration of the proposed pose complementation.</figcaption>
</figure>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.2" class="ltx_p">The architecture of the PC sub-network is quite simple, which only consists of two linear layers of size 512 with residual connection.
In our experiment, we find that the network learns better pose complementation by predicting modification vectors <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\Delta v_{i}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mrow id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.1" xref="S3.SS2.p4.1.m1.1.1.1.cmml">â€‹</mo><msub id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.3.2" xref="S3.SS2.p4.1.m1.1.1.3.2.cmml">v</mi><mi id="S3.SS2.p4.1.m1.1.1.3.3" xref="S3.SS2.p4.1.m1.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><times id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1"></times><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">Î”</ci><apply id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.2">ğ‘£</ci><ci id="S3.SS2.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\Delta v_{i}</annotation></semantics></math> than directly predicting <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="v_{i}^{c}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><msubsup id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2.2" xref="S3.SS2.p4.2.m2.1.1.2.2.cmml">v</mi><mi id="S3.SS2.p4.2.m2.1.1.2.3" xref="S3.SS2.p4.2.m2.1.1.2.3.cmml">i</mi><mi id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">c</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2.2">ğ‘£</ci><ci id="S3.SS2.p4.2.m2.1.1.2.3.cmml" xref="S3.SS2.p4.2.m2.1.1.2.3">ğ‘–</ci></apply><ci id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">v_{i}^{c}</annotation></semantics></math>:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.2" class="ltx_Math" alttext="v_{i}^{c}=\frac{v_{i}+\Delta v_{i}}{||v_{i}+\Delta v_{i}||_{2}}." display="block"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2.1" xref="S3.E7.m1.2.2.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1" xref="S3.E7.m1.2.2.1.1.cmml"><msubsup id="S3.E7.m1.2.2.1.1.2" xref="S3.E7.m1.2.2.1.1.2.cmml"><mi id="S3.E7.m1.2.2.1.1.2.2.2" xref="S3.E7.m1.2.2.1.1.2.2.2.cmml">v</mi><mi id="S3.E7.m1.2.2.1.1.2.2.3" xref="S3.E7.m1.2.2.1.1.2.2.3.cmml">i</mi><mi id="S3.E7.m1.2.2.1.1.2.3" xref="S3.E7.m1.2.2.1.1.2.3.cmml">c</mi></msubsup><mo id="S3.E7.m1.2.2.1.1.1" xref="S3.E7.m1.2.2.1.1.1.cmml">=</mo><mfrac id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><mrow id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml"><msub id="S3.E7.m1.1.1.3.2" xref="S3.E7.m1.1.1.3.2.cmml"><mi id="S3.E7.m1.1.1.3.2.2" xref="S3.E7.m1.1.1.3.2.2.cmml">v</mi><mi id="S3.E7.m1.1.1.3.2.3" xref="S3.E7.m1.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.E7.m1.1.1.3.1" xref="S3.E7.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E7.m1.1.1.3.3" xref="S3.E7.m1.1.1.3.3.cmml"><mi mathvariant="normal" id="S3.E7.m1.1.1.3.3.2" xref="S3.E7.m1.1.1.3.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.3.3.1" xref="S3.E7.m1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E7.m1.1.1.3.3.3" xref="S3.E7.m1.1.1.3.3.3.cmml"><mi id="S3.E7.m1.1.1.3.3.3.2" xref="S3.E7.m1.1.1.3.3.3.2.cmml">v</mi><mi id="S3.E7.m1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow><msub id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E7.m1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2.2" xref="S3.E7.m1.1.1.1.1.1.1.2.2.cmml">v</mi><mi id="S3.E7.m1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E7.m1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E7.m1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.1.1.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><msub id="S3.E7.m1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.3.3.2" xref="S3.E7.m1.1.1.1.1.1.1.3.3.2.cmml">v</mi><mi id="S3.E7.m1.1.1.1.1.1.1.3.3.3" xref="S3.E7.m1.1.1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><mo stretchy="false" id="S3.E7.m1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E7.m1.1.1.1.3" xref="S3.E7.m1.1.1.1.3.cmml">2</mn></msub></mfrac></mrow><mo lspace="0em" id="S3.E7.m1.2.2.1.2" xref="S3.E7.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.1.1.cmml" xref="S3.E7.m1.2.2.1"><eq id="S3.E7.m1.2.2.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1"></eq><apply id="S3.E7.m1.2.2.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.2.1.cmml" xref="S3.E7.m1.2.2.1.1.2">superscript</csymbol><apply id="S3.E7.m1.2.2.1.1.2.2.cmml" xref="S3.E7.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.2.2.1.cmml" xref="S3.E7.m1.2.2.1.1.2">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.2.2.2.cmml" xref="S3.E7.m1.2.2.1.1.2.2.2">ğ‘£</ci><ci id="S3.E7.m1.2.2.1.1.2.2.3.cmml" xref="S3.E7.m1.2.2.1.1.2.2.3">ğ‘–</ci></apply><ci id="S3.E7.m1.2.2.1.1.2.3.cmml" xref="S3.E7.m1.2.2.1.1.2.3">ğ‘</ci></apply><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><divide id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1"></divide><apply id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3"><plus id="S3.E7.m1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.3.1"></plus><apply id="S3.E7.m1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.3.2.2">ğ‘£</ci><ci id="S3.E7.m1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.3.2.3">ğ‘–</ci></apply><apply id="S3.E7.m1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.3.3"><times id="S3.E7.m1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3.1"></times><ci id="S3.E7.m1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.2">Î”</ci><apply id="S3.E7.m1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.3.3.3.1.cmml" xref="S3.E7.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.3.3.3.2.cmml" xref="S3.E7.m1.1.1.3.3.3.2">ğ‘£</ci><ci id="S3.E7.m1.1.1.3.3.3.3.cmml" xref="S3.E7.m1.1.1.3.3.3.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1">subscript</csymbol><apply id="S3.E7.m1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1"><plus id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1"></plus><apply id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2">ğ‘£</ci><ci id="S3.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3"><times id="S3.E7.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.1"></times><ci id="S3.E7.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.2">Î”</ci><apply id="S3.E7.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.3.2">ğ‘£</ci><ci id="S3.E7.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3.3.3">ğ‘–</ci></apply></apply></apply></apply><cn type="integer" id="S3.E7.m1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">v_{i}^{c}=\frac{v_{i}+\Delta v_{i}}{||v_{i}+\Delta v_{i}||_{2}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">The complemented 3D orientations are then converted into 3D pose <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="\hat{S}^{c}" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><msup id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml"><mover accent="true" id="S3.SS2.p5.1.m1.1.1.2" xref="S3.SS2.p5.1.m1.1.1.2.cmml"><mi id="S3.SS2.p5.1.m1.1.1.2.2" xref="S3.SS2.p5.1.m1.1.1.2.2.cmml">S</mi><mo id="S3.SS2.p5.1.m1.1.1.2.1" xref="S3.SS2.p5.1.m1.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS2.p5.1.m1.1.1.3" xref="S3.SS2.p5.1.m1.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><apply id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.1.m1.1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">superscript</csymbol><apply id="S3.SS2.p5.1.m1.1.1.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2"><ci id="S3.SS2.p5.1.m1.1.1.2.1.cmml" xref="S3.SS2.p5.1.m1.1.1.2.1">^</ci><ci id="S3.SS2.p5.1.m1.1.1.2.2.cmml" xref="S3.SS2.p5.1.m1.1.1.2.2">ğ‘†</ci></apply><ci id="S3.SS2.p5.1.m1.1.1.3.cmml" xref="S3.SS2.p5.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">\hat{S}^{c}</annotation></semantics></math> and optimized with the L1 loss as well:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\text{CP3D}}=|\hat{S}^{c}-{S}|." display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><msub id="S3.E8.m1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.3.2.cmml">â„’</mi><mtext id="S3.E8.m1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.3.3a.cmml">CP3D</mtext></msub><mo id="S3.E8.m1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.cmml"><msup id="S3.E8.m1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.2.cmml"><mover accent="true" id="S3.E8.m1.1.1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.cmml">S</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.2.2.1" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.E8.m1.1.1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.1.1.2.3.cmml">c</mi></msup><mo id="S3.E8.m1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.3.cmml">S</mi></mrow><mo stretchy="false" id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mo lspace="0em" id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><eq id="S3.E8.m1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.2"></eq><apply id="S3.E8.m1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.3.2">â„’</ci><ci id="S3.E8.m1.1.1.1.1.3.3a.cmml" xref="S3.E8.m1.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.E8.m1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.3.3">CP3D</mtext></ci></apply><apply id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><abs id="S3.E8.m1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2"></abs><apply id="S3.E8.m1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1"><minus id="S3.E8.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E8.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E8.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2"><ci id="S3.E8.m1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.1">^</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.2.2">ğ‘†</ci></apply><ci id="S3.E8.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.E8.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.3">ğ‘†</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\mathcal{L}_{\text{CP3D}}=|\hat{S}^{c}-{S}|.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p">In all, for a <math id="S3.SS2.p6.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">T</annotation></semantics></math> stages network, our overall objective is the combination of the five objectives:</p>
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.1" class="ltx_Math" alttext="\small\mathcal{L}=\sum_{t=1}^{T}(\lambda_{1}\mathcal{L}_{\text{CM}}^{t}+\lambda_{2}\mathcal{L}_{\text{OM2D}}^{t}+\mathbbm{1}\lambda_{3}\mathcal{L}_{\text{OM3D}}^{t})+\mathbbm{1}(\mathcal{L}_{\text{P3D}}+\mathcal{L}_{\text{CP3D}})," display="block"><semantics id="S3.E9.m1.1a"><mrow id="S3.E9.m1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><mrow id="S3.E9.m1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E9.m1.1.1.1.1.4" xref="S3.E9.m1.1.1.1.1.4.cmml">â„’</mi><mo mathsize="90%" rspace="0.111em" id="S3.E9.m1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E9.m1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.cmml"><mrow id="S3.E9.m1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.cmml"><munderover id="S3.E9.m1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.2.cmml"><mo maxsize="90%" minsize="90%" movablelimits="false" rspace="0em" stretchy="true" id="S3.E9.m1.1.1.1.1.1.1.2.2.2" xref="S3.E9.m1.1.1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.2.2.3" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.cmml"><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.2.2.3.2" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.2.cmml">t</mi><mo mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.2.2.3.1" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.2.2.3.3" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.2.3" xref="S3.E9.m1.1.1.1.1.1.1.2.3.cmml">T</mi></munderover><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.cmml"><msub id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">Î»</mi><mn mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.1.cmml">â€‹</mo><msubsup id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.2.cmml">â„’</mi><mtext mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.3a.cmml">CM</mtext><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">t</mi></msubsup></mrow><mo mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">Î»</mi><mn mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><msubsup id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.2.cmml">â„’</mi><mtext mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.3a.cmml">OM2D</mtext><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></msubsup></mrow><mo mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.cmml"><mn mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.2.cmml">ğŸ™</mn><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.1" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.1.cmml">â€‹</mo><msub id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.cmml"><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.2.cmml">Î»</mi><mn mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.1a" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.1.cmml">â€‹</mo><msubsup id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.2" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.2.cmml">â„’</mi><mtext mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.3a.cmml">OM3D</mtext><mi mathsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.3.cmml">t</mi></msubsup></mrow></mrow><mo maxsize="90%" minsize="90%" id="S3.E9.m1.1.1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo mathsize="90%" id="S3.E9.m1.1.1.1.1.2.3" xref="S3.E9.m1.1.1.1.1.2.3.cmml">+</mo><mrow id="S3.E9.m1.1.1.1.1.2.2" xref="S3.E9.m1.1.1.1.1.2.2.cmml"><mn mathsize="90%" id="S3.E9.m1.1.1.1.1.2.2.3" xref="S3.E9.m1.1.1.1.1.2.2.3.cmml">ğŸ™</mn><mo lspace="0em" rspace="0em" id="S3.E9.m1.1.1.1.1.2.2.2" xref="S3.E9.m1.1.1.1.1.2.2.2.cmml">â€‹</mo><mrow id="S3.E9.m1.1.1.1.1.2.2.1.1" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.cmml"><mo maxsize="90%" minsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.2" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.cmml">(</mo><mrow id="S3.E9.m1.1.1.1.1.2.2.1.1.1" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.cmml"><msub id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.2" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.2.cmml">â„’</mi><mtext mathsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.3" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.3a.cmml">P3D</mtext></msub><mo mathsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.1" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.1.cmml">+</mo><msub id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.2" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.2.cmml">â„’</mi><mtext mathsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.3a.cmml">CP3D</mtext></msub></mrow><mo maxsize="90%" minsize="90%" id="S3.E9.m1.1.1.1.1.2.2.1.1.3" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo mathsize="90%" id="S3.E9.m1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.1b"><apply id="S3.E9.m1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1"><eq id="S3.E9.m1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.3"></eq><ci id="S3.E9.m1.1.1.1.1.4.cmml" xref="S3.E9.m1.1.1.1.1.4">â„’</ci><apply id="S3.E9.m1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2"><plus id="S3.E9.m1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.3"></plus><apply id="S3.E9.m1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1"><apply id="S3.E9.m1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E9.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.2"></sum><apply id="S3.E9.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3"><eq id="S3.E9.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E9.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E9.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.3">ğ‘‡</ci></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1"><plus id="S3.E9.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.1"></times><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.2">ğœ†</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.2.3">1</cn></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.3a.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.3"><mtext mathsize="63%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.2.3">CM</mtext></ci></apply><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.2.3.3">ğ‘¡</ci></apply></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.1"></times><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.2">ğœ†</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.2.3">2</cn></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.3a.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.3"><mtext mathsize="63%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.2.3">OM2D</mtext></ci></apply><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4"><times id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.1"></times><cn type="integer" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.2">1</cn><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.2">ğœ†</ci><cn type="integer" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.3.3">3</cn></apply><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.3a.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.3"><mtext mathsize="63%" id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.2.3">OM3D</mtext></ci></apply><ci id="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1.1.1.4.4.3">ğ‘¡</ci></apply></apply></apply></apply><apply id="S3.E9.m1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2"><times id="S3.E9.m1.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.2"></times><cn type="integer" id="S3.E9.m1.1.1.1.1.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.3">1</cn><apply id="S3.E9.m1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1"><plus id="S3.E9.m1.1.1.1.1.2.2.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.1"></plus><apply id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.3a.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.3"><mtext mathsize="63%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.2.3">P3D</mtext></ci></apply><apply id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.2">â„’</ci><ci id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.3a.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.3"><mtext mathsize="63%" id="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.2.2.1.1.1.3.3">CP3D</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.1c">\small\mathcal{L}=\sum_{t=1}^{T}(\lambda_{1}\mathcal{L}_{\text{CM}}^{t}+\lambda_{2}\mathcal{L}_{\text{OM2D}}^{t}+\mathbbm{1}\lambda_{3}\mathcal{L}_{\text{OM3D}}^{t})+\mathbbm{1}(\mathcal{L}_{\text{P3D}}+\mathcal{L}_{\text{CP3D}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p6.8" class="ltx_p">where <math id="S3.SS2.p6.2.m1.1" class="ltx_Math" alttext="\lambda_{1}" display="inline"><semantics id="S3.SS2.p6.2.m1.1a"><msub id="S3.SS2.p6.2.m1.1.1" xref="S3.SS2.p6.2.m1.1.1.cmml"><mi id="S3.SS2.p6.2.m1.1.1.2" xref="S3.SS2.p6.2.m1.1.1.2.cmml">Î»</mi><mn id="S3.SS2.p6.2.m1.1.1.3" xref="S3.SS2.p6.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m1.1b"><apply id="S3.SS2.p6.2.m1.1.1.cmml" xref="S3.SS2.p6.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.2.m1.1.1.1.cmml" xref="S3.SS2.p6.2.m1.1.1">subscript</csymbol><ci id="S3.SS2.p6.2.m1.1.1.2.cmml" xref="S3.SS2.p6.2.m1.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS2.p6.2.m1.1.1.3.cmml" xref="S3.SS2.p6.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m1.1c">\lambda_{1}</annotation></semantics></math>, <math id="S3.SS2.p6.3.m2.1" class="ltx_Math" alttext="\lambda_{2}" display="inline"><semantics id="S3.SS2.p6.3.m2.1a"><msub id="S3.SS2.p6.3.m2.1.1" xref="S3.SS2.p6.3.m2.1.1.cmml"><mi id="S3.SS2.p6.3.m2.1.1.2" xref="S3.SS2.p6.3.m2.1.1.2.cmml">Î»</mi><mn id="S3.SS2.p6.3.m2.1.1.3" xref="S3.SS2.p6.3.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m2.1b"><apply id="S3.SS2.p6.3.m2.1.1.cmml" xref="S3.SS2.p6.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.3.m2.1.1.1.cmml" xref="S3.SS2.p6.3.m2.1.1">subscript</csymbol><ci id="S3.SS2.p6.3.m2.1.1.2.cmml" xref="S3.SS2.p6.3.m2.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS2.p6.3.m2.1.1.3.cmml" xref="S3.SS2.p6.3.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m2.1c">\lambda_{2}</annotation></semantics></math> and <math id="S3.SS2.p6.4.m3.1" class="ltx_Math" alttext="\lambda_{3}" display="inline"><semantics id="S3.SS2.p6.4.m3.1a"><msub id="S3.SS2.p6.4.m3.1.1" xref="S3.SS2.p6.4.m3.1.1.cmml"><mi id="S3.SS2.p6.4.m3.1.1.2" xref="S3.SS2.p6.4.m3.1.1.2.cmml">Î»</mi><mn id="S3.SS2.p6.4.m3.1.1.3" xref="S3.SS2.p6.4.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m3.1b"><apply id="S3.SS2.p6.4.m3.1.1.cmml" xref="S3.SS2.p6.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m3.1.1.1.cmml" xref="S3.SS2.p6.4.m3.1.1">subscript</csymbol><ci id="S3.SS2.p6.4.m3.1.1.2.cmml" xref="S3.SS2.p6.4.m3.1.1.2">ğœ†</ci><cn type="integer" id="S3.SS2.p6.4.m3.1.1.3.cmml" xref="S3.SS2.p6.4.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m3.1c">\lambda_{3}</annotation></semantics></math> control the relative importance of each objective, <math id="S3.SS2.p6.5.m4.1" class="ltx_Math" alttext="\mathbbm{1}" display="inline"><semantics id="S3.SS2.p6.5.m4.1a"><mn id="S3.SS2.p6.5.m4.1.1" xref="S3.SS2.p6.5.m4.1.1.cmml">ğŸ™</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m4.1b"><cn type="integer" id="S3.SS2.p6.5.m4.1.1.cmml" xref="S3.SS2.p6.5.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m4.1c">\mathbbm{1}</annotation></semantics></math> is an indicator function that is 1 if ground truth 3D is available for an image and 0 otherwise. We set <math id="S3.SS2.p6.6.m5.1" class="ltx_Math" alttext="\lambda_{1}=0.1" display="inline"><semantics id="S3.SS2.p6.6.m5.1a"><mrow id="S3.SS2.p6.6.m5.1.1" xref="S3.SS2.p6.6.m5.1.1.cmml"><msub id="S3.SS2.p6.6.m5.1.1.2" xref="S3.SS2.p6.6.m5.1.1.2.cmml"><mi id="S3.SS2.p6.6.m5.1.1.2.2" xref="S3.SS2.p6.6.m5.1.1.2.2.cmml">Î»</mi><mn id="S3.SS2.p6.6.m5.1.1.2.3" xref="S3.SS2.p6.6.m5.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.p6.6.m5.1.1.1" xref="S3.SS2.p6.6.m5.1.1.1.cmml">=</mo><mn id="S3.SS2.p6.6.m5.1.1.3" xref="S3.SS2.p6.6.m5.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.6.m5.1b"><apply id="S3.SS2.p6.6.m5.1.1.cmml" xref="S3.SS2.p6.6.m5.1.1"><eq id="S3.SS2.p6.6.m5.1.1.1.cmml" xref="S3.SS2.p6.6.m5.1.1.1"></eq><apply id="S3.SS2.p6.6.m5.1.1.2.cmml" xref="S3.SS2.p6.6.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.6.m5.1.1.2.1.cmml" xref="S3.SS2.p6.6.m5.1.1.2">subscript</csymbol><ci id="S3.SS2.p6.6.m5.1.1.2.2.cmml" xref="S3.SS2.p6.6.m5.1.1.2.2">ğœ†</ci><cn type="integer" id="S3.SS2.p6.6.m5.1.1.2.3.cmml" xref="S3.SS2.p6.6.m5.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS2.p6.6.m5.1.1.3.cmml" xref="S3.SS2.p6.6.m5.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.6.m5.1c">\lambda_{1}=0.1</annotation></semantics></math>, <math id="S3.SS2.p6.7.m6.1" class="ltx_Math" alttext="\lambda_{2}=1" display="inline"><semantics id="S3.SS2.p6.7.m6.1a"><mrow id="S3.SS2.p6.7.m6.1.1" xref="S3.SS2.p6.7.m6.1.1.cmml"><msub id="S3.SS2.p6.7.m6.1.1.2" xref="S3.SS2.p6.7.m6.1.1.2.cmml"><mi id="S3.SS2.p6.7.m6.1.1.2.2" xref="S3.SS2.p6.7.m6.1.1.2.2.cmml">Î»</mi><mn id="S3.SS2.p6.7.m6.1.1.2.3" xref="S3.SS2.p6.7.m6.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS2.p6.7.m6.1.1.1" xref="S3.SS2.p6.7.m6.1.1.1.cmml">=</mo><mn id="S3.SS2.p6.7.m6.1.1.3" xref="S3.SS2.p6.7.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.7.m6.1b"><apply id="S3.SS2.p6.7.m6.1.1.cmml" xref="S3.SS2.p6.7.m6.1.1"><eq id="S3.SS2.p6.7.m6.1.1.1.cmml" xref="S3.SS2.p6.7.m6.1.1.1"></eq><apply id="S3.SS2.p6.7.m6.1.1.2.cmml" xref="S3.SS2.p6.7.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.7.m6.1.1.2.1.cmml" xref="S3.SS2.p6.7.m6.1.1.2">subscript</csymbol><ci id="S3.SS2.p6.7.m6.1.1.2.2.cmml" xref="S3.SS2.p6.7.m6.1.1.2.2">ğœ†</ci><cn type="integer" id="S3.SS2.p6.7.m6.1.1.2.3.cmml" xref="S3.SS2.p6.7.m6.1.1.2.3">2</cn></apply><cn type="integer" id="S3.SS2.p6.7.m6.1.1.3.cmml" xref="S3.SS2.p6.7.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.7.m6.1c">\lambda_{2}=1</annotation></semantics></math> and <math id="S3.SS2.p6.8.m7.1" class="ltx_Math" alttext="\lambda_{3}=1" display="inline"><semantics id="S3.SS2.p6.8.m7.1a"><mrow id="S3.SS2.p6.8.m7.1.1" xref="S3.SS2.p6.8.m7.1.1.cmml"><msub id="S3.SS2.p6.8.m7.1.1.2" xref="S3.SS2.p6.8.m7.1.1.2.cmml"><mi id="S3.SS2.p6.8.m7.1.1.2.2" xref="S3.SS2.p6.8.m7.1.1.2.2.cmml">Î»</mi><mn id="S3.SS2.p6.8.m7.1.1.2.3" xref="S3.SS2.p6.8.m7.1.1.2.3.cmml">3</mn></msub><mo id="S3.SS2.p6.8.m7.1.1.1" xref="S3.SS2.p6.8.m7.1.1.1.cmml">=</mo><mn id="S3.SS2.p6.8.m7.1.1.3" xref="S3.SS2.p6.8.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.8.m7.1b"><apply id="S3.SS2.p6.8.m7.1.1.cmml" xref="S3.SS2.p6.8.m7.1.1"><eq id="S3.SS2.p6.8.m7.1.1.1.cmml" xref="S3.SS2.p6.8.m7.1.1.1"></eq><apply id="S3.SS2.p6.8.m7.1.1.2.cmml" xref="S3.SS2.p6.8.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p6.8.m7.1.1.2.1.cmml" xref="S3.SS2.p6.8.m7.1.1.2">subscript</csymbol><ci id="S3.SS2.p6.8.m7.1.1.2.2.cmml" xref="S3.SS2.p6.8.m7.1.1.2.2">ğœ†</ci><cn type="integer" id="S3.SS2.p6.8.m7.1.1.2.3.cmml" xref="S3.SS2.p6.8.m7.1.1.2.3">3</cn></apply><cn type="integer" id="S3.SS2.p6.8.m7.1.1.3.cmml" xref="S3.SS2.p6.8.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.8.m7.1c">\lambda_{3}=1</annotation></semantics></math> in our experiment.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We provide here details on our experiments, including datasets and implementation details,
results under regular settings, results on images with missing joints/limbs, cross-dataset evaluations to test the generalization capacity and qualitative results.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Datasets</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p"><span id="S4.SS1.p1.2.1" class="ltx_text ltx_font_bold">Human3.6M</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> is a large-scale indoor 3D human pose dataset
that comprises 3.6 million images and the corresponding 2D pose and 3D pose annotations.
It features <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">7</annotation></semantics></math> subjects performing <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn type="integer" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">15</annotation></semantics></math> everyday activities.
Following the standard protocols, we use S1, S5, S6, S7, S8 for training, and S9, S11 for testing. We report results in two metrics, <em id="S4.SS1.p1.2.2" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedot<em id="S4.SS1.p1.2.3" class="ltx_emph ltx_font_italic">Mean Per Joint Position ErrorÂ (MPJPE)</em> and <em id="S4.SS1.p1.2.4" class="ltx_emph ltx_font_italic">MPJPE after Procrustes AlignmentÂ (PA-MPJPE)</em>. The original videos are down-sampled from 50fps to 10fps to reduce redundancy.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">MPI-INF-3DHP</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> test set consists of 2929 indoor and outdoor images from six subjects performing seven actions. We only use the test set of this dataset to evaluate our methodâ€™s generalization quantitatively.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">MPII</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is a widely used benchmark for 2D human pose estimation. It contains 5K in-the-wild images covering a wide range of activities.
It is annotated with 2D keypoints but no 3D ground truth.
We use it for weakly supervised training to achieve better generalization.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">3DPW</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> is a recently proposed 3D poses dataset in the wild.
It contains 60 video sequences and 3D annotations captured via IMUs.
For a fair comparison, the evaluation is performed following the same protocol asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Implementation details</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.7" class="ltx_p">Our method is implemented with PyTorchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.
We train our model in two steps from scratch.
First, we train the whole network in regular settings.
Augmentations of random scalingÂ (<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="1\pm 0.25" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">1</mn><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">Â±</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1">plus-or-minus</csymbol><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">1</cn><cn type="float" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1\pm 0.25</annotation></semantics></math>), random translationÂ (<math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\pm 0.2" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mo id="S4.SS2.p1.2.m2.1.1a" xref="S4.SS2.p1.2.m2.1.1.cmml">Â±</mo><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">plus-or-minus</csymbol><cn type="float" id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\pm 0.2</annotation></semantics></math>), random rotationÂ (<math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="\pm 30^{\circ}" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mo id="S4.SS2.p1.3.m3.1.1a" xref="S4.SS2.p1.3.m3.1.1.cmml">Â±</mo><msup id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2.2" xref="S4.SS2.p1.3.m3.1.1.2.2.cmml">30</mn><mo id="S4.SS2.p1.3.m3.1.1.2.3" xref="S4.SS2.p1.3.m3.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">plus-or-minus</csymbol><apply id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.2.1.cmml" xref="S4.SS2.p1.3.m3.1.1.2">superscript</csymbol><cn type="integer" id="S4.SS2.p1.3.m3.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2.2">30</cn><compose id="S4.SS2.p1.3.m3.1.1.2.3.cmml" xref="S4.SS2.p1.3.m3.1.1.2.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">\pm 30^{\circ}</annotation></semantics></math>), random horizontal flippingÂ (<math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="p=0.5" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">p</mi><mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><eq id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></eq><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">ğ‘</ci><cn type="float" id="S4.SS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">p=0.5</annotation></semantics></math>) and random color jitterÂ (<math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="1\pm 0.2" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mn id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">1</mn><mo id="S4.SS2.p1.5.m5.1.1.1" xref="S4.SS2.p1.5.m5.1.1.1.cmml">Â±</mo><mn id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1">plus-or-minus</csymbol><cn type="integer" id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">1</cn><cn type="float" id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">1\pm 0.2</annotation></semantics></math>), are used for both MPII and Human3.6M.
The network is trained for 100 epochs with a batch size of 12.
The learning rate is initially set to <math id="S4.SS2.p1.6.m6.1" class="ltx_Math" alttext="2\times 10^{-4}" display="inline"><semantics id="S4.SS2.p1.6.m6.1a"><mrow id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mn id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.6.m6.1.1.1" xref="S4.SS2.p1.6.m6.1.1.1.cmml">Ã—</mo><msup id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3.cmml"><mn id="S4.SS2.p1.6.m6.1.1.3.2" xref="S4.SS2.p1.6.m6.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p1.6.m6.1.1.3.3" xref="S4.SS2.p1.6.m6.1.1.3.3.cmml"><mo id="S4.SS2.p1.6.m6.1.1.3.3a" xref="S4.SS2.p1.6.m6.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.6.m6.1.1.3.3.2" xref="S4.SS2.p1.6.m6.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><times id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1.1"></times><cn type="integer" id="S4.SS2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.p1.6.m6.1.1.2">2</cn><apply id="S4.SS2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m6.1.1.3.1.cmml" xref="S4.SS2.p1.6.m6.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS2.p1.6.m6.1.1.3.2.cmml" xref="S4.SS2.p1.6.m6.1.1.3.2">10</cn><apply id="S4.SS2.p1.6.m6.1.1.3.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3.3"><minus id="S4.SS2.p1.6.m6.1.1.3.3.1.cmml" xref="S4.SS2.p1.6.m6.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p1.6.m6.1.1.3.3.2.cmml" xref="S4.SS2.p1.6.m6.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">2\times 10^{-4}</annotation></semantics></math> and decays at 60th epoch by a factor of <math id="S4.SS2.p1.7.m7.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SS2.p1.7.m7.1a"><mn id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><cn type="float" id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">0.1</annotation></semantics></math>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.4" class="ltx_p">In the first training step, the images are almost always complete, because the translation augmentation is limited at a very small range.
To this end, we need to create incomplete images to train the PC sub-network.
In our experiments, we use random translation up to <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\pm 50\%" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mo id="S4.SS2.p2.1.m1.1.1a" xref="S4.SS2.p2.1.m1.1.1.cmml">Â±</mo><mrow id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2.2" xref="S4.SS2.p2.1.m1.1.1.2.2.cmml">50</mn><mo id="S4.SS2.p2.1.m1.1.1.2.1" xref="S4.SS2.p2.1.m1.1.1.2.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">plus-or-minus</csymbol><apply id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2"><csymbol cd="latexml" id="S4.SS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.p2.1.m1.1.1.2.1">percent</csymbol><cn type="integer" id="S4.SS2.p2.1.m1.1.1.2.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\pm 50\%</annotation></semantics></math> of the image size and randomly render objects on the 3D training images, to simulate joint and limb absence caused by truncation and occlusion.
Then we fine-tune network on these synthetic incomplete images for <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mn id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><cn type="integer" id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">50</annotation></semantics></math> epochs with the same batch size.
The learning rate is initially set to <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mrow id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml"><mn id="S4.SS2.p2.3.m3.1.1.2" xref="S4.SS2.p2.3.m3.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p2.3.m3.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.cmml">Ã—</mo><msup id="S4.SS2.p2.3.m3.1.1.3" xref="S4.SS2.p2.3.m3.1.1.3.cmml"><mn id="S4.SS2.p2.3.m3.1.1.3.2" xref="S4.SS2.p2.3.m3.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p2.3.m3.1.1.3.3" xref="S4.SS2.p2.3.m3.1.1.3.3.cmml"><mo id="S4.SS2.p2.3.m3.1.1.3.3a" xref="S4.SS2.p2.3.m3.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p2.3.m3.1.1.3.3.2" xref="S4.SS2.p2.3.m3.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><apply id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1"><times id="S4.SS2.p2.3.m3.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1"></times><cn type="integer" id="S4.SS2.p2.3.m3.1.1.2.cmml" xref="S4.SS2.p2.3.m3.1.1.2">1</cn><apply id="S4.SS2.p2.3.m3.1.1.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.1.1.3.1.cmml" xref="S4.SS2.p2.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS2.p2.3.m3.1.1.3.2.cmml" xref="S4.SS2.p2.3.m3.1.1.3.2">10</cn><apply id="S4.SS2.p2.3.m3.1.1.3.3.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3"><minus id="S4.SS2.p2.3.m3.1.1.3.3.1.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p2.3.m3.1.1.3.3.2.cmml" xref="S4.SS2.p2.3.m3.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">1\times 10^{-4}</annotation></semantics></math> and decays at the 30th epoch by a factor of <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mn id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><cn type="float" id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">0.1</annotation></semantics></math>.
We use the RMSProp as the optimizer for all the steps.
In both training steps, the PC sub-network is detached from the FCNN.
In other words, the gradient in the PC sub-network does not backpropagate to the FCNN, to avoid the deterioration of orientation learning.
It takes about 35 hours on two Tesla V100 GPUs with 16 GB memory on each to train a 4-stage model.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Rules to generate incomplete images</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In SectionÂ <a href="#S4.SS4" title="IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-D</span></span></a> of the main manuscript, we provided quantitative results on various incomplete images.
Here we explain the rules to generate these incomplete images.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.5" class="ltx_p"><span id="S4.SS3.p2.5.1" class="ltx_text ltx_font_bold">Translation</span>. For an image of the size <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="a\times a" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mi id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">Ã—</mo><mi id="S4.SS3.p2.1.m1.1.1.3" xref="S4.SS3.p2.1.m1.1.1.3.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><times id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1"></times><ci id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">ğ‘</ci><ci id="S4.SS3.p2.1.m1.1.1.3.cmml" xref="S4.SS3.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">a\times a</annotation></semantics></math>, we randomly translate the image center by <math id="S4.SS3.p2.2.m2.2" class="ltx_Math" alttext="(x,y)\times a" display="inline"><semantics id="S4.SS3.p2.2.m2.2a"><mrow id="S4.SS3.p2.2.m2.2.3" xref="S4.SS3.p2.2.m2.2.3.cmml"><mrow id="S4.SS3.p2.2.m2.2.3.2.2" xref="S4.SS3.p2.2.m2.2.3.2.1.cmml"><mo stretchy="false" id="S4.SS3.p2.2.m2.2.3.2.2.1" xref="S4.SS3.p2.2.m2.2.3.2.1.cmml">(</mo><mi id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">x</mi><mo id="S4.SS3.p2.2.m2.2.3.2.2.2" xref="S4.SS3.p2.2.m2.2.3.2.1.cmml">,</mo><mi id="S4.SS3.p2.2.m2.2.2" xref="S4.SS3.p2.2.m2.2.2.cmml">y</mi><mo rspace="0.055em" stretchy="false" id="S4.SS3.p2.2.m2.2.3.2.2.3" xref="S4.SS3.p2.2.m2.2.3.2.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.SS3.p2.2.m2.2.3.1" xref="S4.SS3.p2.2.m2.2.3.1.cmml">Ã—</mo><mi id="S4.SS3.p2.2.m2.2.3.3" xref="S4.SS3.p2.2.m2.2.3.3.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.2b"><apply id="S4.SS3.p2.2.m2.2.3.cmml" xref="S4.SS3.p2.2.m2.2.3"><times id="S4.SS3.p2.2.m2.2.3.1.cmml" xref="S4.SS3.p2.2.m2.2.3.1"></times><interval closure="open" id="S4.SS3.p2.2.m2.2.3.2.1.cmml" xref="S4.SS3.p2.2.m2.2.3.2.2"><ci id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">ğ‘¥</ci><ci id="S4.SS3.p2.2.m2.2.2.cmml" xref="S4.SS3.p2.2.m2.2.2">ğ‘¦</ci></interval><ci id="S4.SS3.p2.2.m2.2.3.3.cmml" xref="S4.SS3.p2.2.m2.2.3.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.2c">(x,y)\times a</annotation></semantics></math>, where <math id="S4.SS3.p2.3.m3.2" class="ltx_Math" alttext="x,y" display="inline"><semantics id="S4.SS3.p2.3.m3.2a"><mrow id="S4.SS3.p2.3.m3.2.3.2" xref="S4.SS3.p2.3.m3.2.3.1.cmml"><mi id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml">x</mi><mo id="S4.SS3.p2.3.m3.2.3.2.1" xref="S4.SS3.p2.3.m3.2.3.1.cmml">,</mo><mi id="S4.SS3.p2.3.m3.2.2" xref="S4.SS3.p2.3.m3.2.2.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.2b"><list id="S4.SS3.p2.3.m3.2.3.1.cmml" xref="S4.SS3.p2.3.m3.2.3.2"><ci id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1">ğ‘¥</ci><ci id="S4.SS3.p2.3.m3.2.2.cmml" xref="S4.SS3.p2.3.m3.2.2">ğ‘¦</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.2c">x,y</annotation></semantics></math> are random numbers drawn from uniform distribution between <math id="S4.SS3.p2.4.m4.2" class="ltx_Math" alttext="[-\tau,\tau]" display="inline"><semantics id="S4.SS3.p2.4.m4.2a"><mrow id="S4.SS3.p2.4.m4.2.2.1" xref="S4.SS3.p2.4.m4.2.2.2.cmml"><mo stretchy="false" id="S4.SS3.p2.4.m4.2.2.1.2" xref="S4.SS3.p2.4.m4.2.2.2.cmml">[</mo><mrow id="S4.SS3.p2.4.m4.2.2.1.1" xref="S4.SS3.p2.4.m4.2.2.1.1.cmml"><mo id="S4.SS3.p2.4.m4.2.2.1.1a" xref="S4.SS3.p2.4.m4.2.2.1.1.cmml">âˆ’</mo><mi id="S4.SS3.p2.4.m4.2.2.1.1.2" xref="S4.SS3.p2.4.m4.2.2.1.1.2.cmml">Ï„</mi></mrow><mo id="S4.SS3.p2.4.m4.2.2.1.3" xref="S4.SS3.p2.4.m4.2.2.2.cmml">,</mo><mi id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">Ï„</mi><mo stretchy="false" id="S4.SS3.p2.4.m4.2.2.1.4" xref="S4.SS3.p2.4.m4.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.2b"><interval closure="closed" id="S4.SS3.p2.4.m4.2.2.2.cmml" xref="S4.SS3.p2.4.m4.2.2.1"><apply id="S4.SS3.p2.4.m4.2.2.1.1.cmml" xref="S4.SS3.p2.4.m4.2.2.1.1"><minus id="S4.SS3.p2.4.m4.2.2.1.1.1.cmml" xref="S4.SS3.p2.4.m4.2.2.1.1"></minus><ci id="S4.SS3.p2.4.m4.2.2.1.1.2.cmml" xref="S4.SS3.p2.4.m4.2.2.1.1.2">ğœ</ci></apply><ci id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">ğœ</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.2c">[-\tau,\tau]</annotation></semantics></math>. We set <math id="S4.SS3.p2.5.m5.2" class="ltx_Math" alttext="\tau=0.25,0.4" display="inline"><semantics id="S4.SS3.p2.5.m5.2a"><mrow id="S4.SS3.p2.5.m5.2.3" xref="S4.SS3.p2.5.m5.2.3.cmml"><mi id="S4.SS3.p2.5.m5.2.3.2" xref="S4.SS3.p2.5.m5.2.3.2.cmml">Ï„</mi><mo id="S4.SS3.p2.5.m5.2.3.1" xref="S4.SS3.p2.5.m5.2.3.1.cmml">=</mo><mrow id="S4.SS3.p2.5.m5.2.3.3.2" xref="S4.SS3.p2.5.m5.2.3.3.1.cmml"><mn id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">0.25</mn><mo id="S4.SS3.p2.5.m5.2.3.3.2.1" xref="S4.SS3.p2.5.m5.2.3.3.1.cmml">,</mo><mn id="S4.SS3.p2.5.m5.2.2" xref="S4.SS3.p2.5.m5.2.2.cmml">0.4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.2b"><apply id="S4.SS3.p2.5.m5.2.3.cmml" xref="S4.SS3.p2.5.m5.2.3"><eq id="S4.SS3.p2.5.m5.2.3.1.cmml" xref="S4.SS3.p2.5.m5.2.3.1"></eq><ci id="S4.SS3.p2.5.m5.2.3.2.cmml" xref="S4.SS3.p2.5.m5.2.3.2">ğœ</ci><list id="S4.SS3.p2.5.m5.2.3.3.1.cmml" xref="S4.SS3.p2.5.m5.2.3.3.2"><cn type="float" id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">0.25</cn><cn type="float" id="S4.SS3.p2.5.m5.2.2.cmml" xref="S4.SS3.p2.5.m5.2.2">0.4</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.2c">\tau=0.25,0.4</annotation></semantics></math> respectively in our experiments.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_bold">Synthetic occlusions</span>. For each image, we add a random number of VOC objects at random locations with random sizes. We directly use the code provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> to generate occlusions.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.2" class="ltx_p"><span id="S4.SS3.p4.2.1" class="ltx_text ltx_font_bold">Rectangular erasing</span>. Given an image of size <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="a\times a" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mrow id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mi id="S4.SS3.p4.1.m1.1.1.2" xref="S4.SS3.p4.1.m1.1.1.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1.cmml">Ã—</mo><mi id="S4.SS3.p4.1.m1.1.1.3" xref="S4.SS3.p4.1.m1.1.1.3.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><times id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1.1"></times><ci id="S4.SS3.p4.1.m1.1.1.2.cmml" xref="S4.SS3.p4.1.m1.1.1.2">ğ‘</ci><ci id="S4.SS3.p4.1.m1.1.1.3.cmml" xref="S4.SS3.p4.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">a\times a</annotation></semantics></math>, we first select two arbitrary points within the image as the two mid-points of the widths of the rectangle, and then draw a value between <math id="S4.SS3.p4.2.m2.2" class="ltx_Math" alttext="[0,a]" display="inline"><semantics id="S4.SS3.p4.2.m2.2a"><mrow id="S4.SS3.p4.2.m2.2.3.2" xref="S4.SS3.p4.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS3.p4.2.m2.2.3.2.1" xref="S4.SS3.p4.2.m2.2.3.1.cmml">[</mo><mn id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml">0</mn><mo id="S4.SS3.p4.2.m2.2.3.2.2" xref="S4.SS3.p4.2.m2.2.3.1.cmml">,</mo><mi id="S4.SS3.p4.2.m2.2.2" xref="S4.SS3.p4.2.m2.2.2.cmml">a</mi><mo stretchy="false" id="S4.SS3.p4.2.m2.2.3.2.3" xref="S4.SS3.p4.2.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.2b"><interval closure="closed" id="S4.SS3.p4.2.m2.2.3.1.cmml" xref="S4.SS3.p4.2.m2.2.3.2"><cn type="integer" id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1">0</cn><ci id="S4.SS3.p4.2.m2.2.2.cmml" xref="S4.SS3.p4.2.m2.2.2">ğ‘</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.2c">[0,a]</annotation></semantics></math> at random as the width of the rectangle.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.2" class="ltx_p"><span id="S4.SS3.p5.2.1" class="ltx_text ltx_font_bold">Circle erasing</span>. Given an image of size <math id="S4.SS3.p5.1.m1.1" class="ltx_Math" alttext="a\times a" display="inline"><semantics id="S4.SS3.p5.1.m1.1a"><mrow id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml"><mi id="S4.SS3.p5.1.m1.1.1.2" xref="S4.SS3.p5.1.m1.1.1.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p5.1.m1.1.1.1" xref="S4.SS3.p5.1.m1.1.1.1.cmml">Ã—</mo><mi id="S4.SS3.p5.1.m1.1.1.3" xref="S4.SS3.p5.1.m1.1.1.3.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><apply id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1"><times id="S4.SS3.p5.1.m1.1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1.1"></times><ci id="S4.SS3.p5.1.m1.1.1.2.cmml" xref="S4.SS3.p5.1.m1.1.1.2">ğ‘</ci><ci id="S4.SS3.p5.1.m1.1.1.3.cmml" xref="S4.SS3.p5.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">a\times a</annotation></semantics></math>, we first select an arbitrary point within the image as the center of the circle, and then draw a value between <math id="S4.SS3.p5.2.m2.2" class="ltx_Math" alttext="[a/5,2a/5]" display="inline"><semantics id="S4.SS3.p5.2.m2.2a"><mrow id="S4.SS3.p5.2.m2.2.2.2" xref="S4.SS3.p5.2.m2.2.2.3.cmml"><mo stretchy="false" id="S4.SS3.p5.2.m2.2.2.2.3" xref="S4.SS3.p5.2.m2.2.2.3.cmml">[</mo><mrow id="S4.SS3.p5.2.m2.1.1.1.1" xref="S4.SS3.p5.2.m2.1.1.1.1.cmml"><mi id="S4.SS3.p5.2.m2.1.1.1.1.2" xref="S4.SS3.p5.2.m2.1.1.1.1.2.cmml">a</mi><mo id="S4.SS3.p5.2.m2.1.1.1.1.1" xref="S4.SS3.p5.2.m2.1.1.1.1.1.cmml">/</mo><mn id="S4.SS3.p5.2.m2.1.1.1.1.3" xref="S4.SS3.p5.2.m2.1.1.1.1.3.cmml">5</mn></mrow><mo id="S4.SS3.p5.2.m2.2.2.2.4" xref="S4.SS3.p5.2.m2.2.2.3.cmml">,</mo><mrow id="S4.SS3.p5.2.m2.2.2.2.2" xref="S4.SS3.p5.2.m2.2.2.2.2.cmml"><mrow id="S4.SS3.p5.2.m2.2.2.2.2.2" xref="S4.SS3.p5.2.m2.2.2.2.2.2.cmml"><mn id="S4.SS3.p5.2.m2.2.2.2.2.2.2" xref="S4.SS3.p5.2.m2.2.2.2.2.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p5.2.m2.2.2.2.2.2.1" xref="S4.SS3.p5.2.m2.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S4.SS3.p5.2.m2.2.2.2.2.2.3" xref="S4.SS3.p5.2.m2.2.2.2.2.2.3.cmml">a</mi></mrow><mo id="S4.SS3.p5.2.m2.2.2.2.2.1" xref="S4.SS3.p5.2.m2.2.2.2.2.1.cmml">/</mo><mn id="S4.SS3.p5.2.m2.2.2.2.2.3" xref="S4.SS3.p5.2.m2.2.2.2.2.3.cmml">5</mn></mrow><mo stretchy="false" id="S4.SS3.p5.2.m2.2.2.2.5" xref="S4.SS3.p5.2.m2.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.2.m2.2b"><interval closure="closed" id="S4.SS3.p5.2.m2.2.2.3.cmml" xref="S4.SS3.p5.2.m2.2.2.2"><apply id="S4.SS3.p5.2.m2.1.1.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1.1.1"><divide id="S4.SS3.p5.2.m2.1.1.1.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1.1.1.1"></divide><ci id="S4.SS3.p5.2.m2.1.1.1.1.2.cmml" xref="S4.SS3.p5.2.m2.1.1.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS3.p5.2.m2.1.1.1.1.3.cmml" xref="S4.SS3.p5.2.m2.1.1.1.1.3">5</cn></apply><apply id="S4.SS3.p5.2.m2.2.2.2.2.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2"><divide id="S4.SS3.p5.2.m2.2.2.2.2.1.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2.1"></divide><apply id="S4.SS3.p5.2.m2.2.2.2.2.2.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2.2"><times id="S4.SS3.p5.2.m2.2.2.2.2.2.1.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2.2.1"></times><cn type="integer" id="S4.SS3.p5.2.m2.2.2.2.2.2.2.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2.2.2">2</cn><ci id="S4.SS3.p5.2.m2.2.2.2.2.2.3.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2.2.3">ğ‘</ci></apply><cn type="integer" id="S4.SS3.p5.2.m2.2.2.2.2.3.cmml" xref="S4.SS3.p5.2.m2.2.2.2.2.3">5</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.2.m2.2c">[a/5,2a/5]</annotation></semantics></math> at random as its radius.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.2" class="ltx_p"><span id="S4.SS3.p6.2.1" class="ltx_text ltx_font_bold">Edge erasing</span>. Given an image of size <math id="S4.SS3.p6.1.m1.1" class="ltx_Math" alttext="a\times a" display="inline"><semantics id="S4.SS3.p6.1.m1.1a"><mrow id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml"><mi id="S4.SS3.p6.1.m1.1.1.2" xref="S4.SS3.p6.1.m1.1.1.2.cmml">a</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p6.1.m1.1.1.1" xref="S4.SS3.p6.1.m1.1.1.1.cmml">Ã—</mo><mi id="S4.SS3.p6.1.m1.1.1.3" xref="S4.SS3.p6.1.m1.1.1.3.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><apply id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1"><times id="S4.SS3.p6.1.m1.1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1.1"></times><ci id="S4.SS3.p6.1.m1.1.1.2.cmml" xref="S4.SS3.p6.1.m1.1.1.2">ğ‘</ci><ci id="S4.SS3.p6.1.m1.1.1.3.cmml" xref="S4.SS3.p6.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">a\times a</annotation></semantics></math>, we first select an arbitrary edge from left, right, top, bottom, and then draw a value between <math id="S4.SS3.p6.2.m2.2" class="ltx_Math" alttext="[0,a/2]" display="inline"><semantics id="S4.SS3.p6.2.m2.2a"><mrow id="S4.SS3.p6.2.m2.2.2.1" xref="S4.SS3.p6.2.m2.2.2.2.cmml"><mo stretchy="false" id="S4.SS3.p6.2.m2.2.2.1.2" xref="S4.SS3.p6.2.m2.2.2.2.cmml">[</mo><mn id="S4.SS3.p6.2.m2.1.1" xref="S4.SS3.p6.2.m2.1.1.cmml">0</mn><mo id="S4.SS3.p6.2.m2.2.2.1.3" xref="S4.SS3.p6.2.m2.2.2.2.cmml">,</mo><mrow id="S4.SS3.p6.2.m2.2.2.1.1" xref="S4.SS3.p6.2.m2.2.2.1.1.cmml"><mi id="S4.SS3.p6.2.m2.2.2.1.1.2" xref="S4.SS3.p6.2.m2.2.2.1.1.2.cmml">a</mi><mo id="S4.SS3.p6.2.m2.2.2.1.1.1" xref="S4.SS3.p6.2.m2.2.2.1.1.1.cmml">/</mo><mn id="S4.SS3.p6.2.m2.2.2.1.1.3" xref="S4.SS3.p6.2.m2.2.2.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.SS3.p6.2.m2.2.2.1.4" xref="S4.SS3.p6.2.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.2.m2.2b"><interval closure="closed" id="S4.SS3.p6.2.m2.2.2.2.cmml" xref="S4.SS3.p6.2.m2.2.2.1"><cn type="integer" id="S4.SS3.p6.2.m2.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1">0</cn><apply id="S4.SS3.p6.2.m2.2.2.1.1.cmml" xref="S4.SS3.p6.2.m2.2.2.1.1"><divide id="S4.SS3.p6.2.m2.2.2.1.1.1.cmml" xref="S4.SS3.p6.2.m2.2.2.1.1.1"></divide><ci id="S4.SS3.p6.2.m2.2.2.1.1.2.cmml" xref="S4.SS3.p6.2.m2.2.2.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS3.p6.2.m2.2.2.1.1.3.cmml" xref="S4.SS3.p6.2.m2.2.2.1.1.3">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.2.m2.2c">[0,a/2]</annotation></semantics></math> at random as the width of edge to erase.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.4.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.5.2" class="ltx_text ltx_font_italic">Quantitative results</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this section, we first report results on Human3.6M and compare with state-of-the-art methods in regular settings.
Then we evaluate our method on incomplete images to test the robustness of 3D pose estimation.
Some recent works estimate 3D pose by recovering 3D human mesh based on SMPL modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.
We compare with these model-based methods on Human3.6M and 3DPW.
Finally, we quantitatively evaluate our method on MPI-INF-3DHP without training on it, to evaluate the generalization of our PONet.</p>
</div>
<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS1.4.1.1" class="ltx_text">IV-D</span>1 </span>Results on Human3.6M in regular settings</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">We first compare the proposed method with state-of-the-art 3D pose estimation methods in regular settings, <em id="S4.SS4.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">i.e</em>let@tokeneonedot, all testing images are precisely cropped using ground truth bounding boxes so that the subjects always appear right in the center of testing images with all the joints within the images.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:142.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-23.1pt,9.5pt) scale(0.882267573062548,0.882267573062548) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Method (Authors)</span></th>
<th id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">MPJPE</span></th>
<th id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">PA-MPJPE</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.2.1" class="ltx_tr">
<td id="S4.T1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">MartinezÂ <em id="S4.T1.1.1.2.1.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</td>
<td id="S4.T1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">62.9</td>
<td id="S4.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">45.5</td>
</tr>
<tr id="S4.T1.1.1.3.2" class="ltx_tr">
<td id="S4.T1.1.1.3.2.1" class="ltx_td ltx_align_left">PavlakosÂ <em id="S4.T1.1.1.3.2.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="S4.T1.1.1.3.2.2" class="ltx_td ltx_align_center">56.2</td>
<td id="S4.T1.1.1.3.2.3" class="ltx_td ltx_align_center">41.8</td>
</tr>
<tr id="S4.T1.1.1.4.3" class="ltx_tr">
<td id="S4.T1.1.1.4.3.1" class="ltx_td ltx_align_left">YangÂ <em id="S4.T1.1.1.4.3.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>
</td>
<td id="S4.T1.1.1.4.3.2" class="ltx_td ltx_align_center">58.6</td>
<td id="S4.T1.1.1.4.3.3" class="ltx_td ltx_align_center">37.7</td>
</tr>
<tr id="S4.T1.1.1.5.4" class="ltx_tr">
<td id="S4.T1.1.1.5.4.1" class="ltx_td ltx_align_left">WangÂ <em id="S4.T1.1.1.5.4.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="S4.T1.1.1.5.4.2" class="ltx_td ltx_align_center">52.6</td>
<td id="S4.T1.1.1.5.4.3" class="ltx_td ltx_align_center">40.7</td>
</tr>
<tr id="S4.T1.1.1.6.5" class="ltx_tr">
<td id="S4.T1.1.1.6.5.1" class="ltx_td ltx_align_left">CaiÂ <em id="S4.T1.1.1.6.5.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S4.T1.1.1.6.5.2" class="ltx_td ltx_align_center">50.6</td>
<td id="S4.T1.1.1.6.5.3" class="ltx_td ltx_align_center">40.2</td>
</tr>
<tr id="S4.T1.1.1.7.6" class="ltx_tr">
<td id="S4.T1.1.1.7.6.1" class="ltx_td ltx_align_left">LiÂ <em id="S4.T1.1.1.7.6.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T1.1.1.7.6.2" class="ltx_td ltx_align_center">50.9</td>
<td id="S4.T1.1.1.7.6.3" class="ltx_td ltx_align_center">38.0</td>
</tr>
<tr id="S4.T1.1.1.8.7" class="ltx_tr">
<td id="S4.T1.1.1.8.7.1" class="ltx_td ltx_align_left">XuÂ <em id="S4.T1.1.1.8.7.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="S4.T1.1.1.8.7.2" class="ltx_td ltx_align_center">49.2</td>
<td id="S4.T1.1.1.8.7.3" class="ltx_td ltx_align_center">38.9</td>
</tr>
<tr id="S4.T1.1.1.9.8" class="ltx_tr">
<td id="S4.T1.1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Ours</td>
<td id="S4.T1.1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">56.1</td>
<td id="S4.T1.1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">39.8</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Quantitative results on Human3.6M in regular settings.</figcaption>
</figure>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<p id="S4.SS4.SSS1.p2.1" class="ltx_p">The results on Human3.6M in terms of MPJPE and PA-MPJPE are shown in Tab.Â <a href="#S4.T1" title="TABLE I â€£ IV-D1 Results on Human3.6M in regular settings â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.
All methods in this table, except for ours, regress the 3D joint locations so that they can fit the data by distorting the body.
By contrast, our method uses a skeleton-shaped human model with fixed-length limbs so that our pose estimation will always satisfy anthropometric constraints, at the cost of some fitting accuracy.
Even so, our results are on par with these methods.
</p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS2.4.1.1" class="ltx_text">IV-D</span>2 </span>Results on images with noisy bounding boxes </h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.2" class="ltx_p">We carry out experiments on Human3.6M by adding Gaussian noises to the centersÂ <math id="S4.SS4.SSS2.p1.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.SS4.SSS2.p1.1.m1.1a"><mi id="S4.SS4.SSS2.p1.1.m1.1.1" xref="S4.SS4.SSS2.p1.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.1.m1.1b"><ci id="S4.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS2.p1.1.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.1.m1.1c">C</annotation></semantics></math> and/or the sizesÂ <math id="S4.SS4.SSS2.p1.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS4.SSS2.p1.2.m2.1a"><mi id="S4.SS4.SSS2.p1.2.m2.1.1" xref="S4.SS4.SSS2.p1.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.2.m2.1b"><ci id="S4.SS4.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS2.p1.2.m2.1.1">ğ‘†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.2.m2.1c">S</annotation></semantics></math> of ground truth bounding boxes,</p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.5" class="ltx_Math" alttext="\begin{array}[]{lc}C\leftarrow C+S\times\mathcal{N}((0,0),(\sigma^{2}_{c},\sigma^{2}_{c})),\\
S\leftarrow S+S\times\mathcal{N}(0,\sigma^{2}_{s}),\end{array}" display="block"><semantics id="S4.Ex1.m1.5a"><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S4.Ex1.m1.5.5" xref="S4.Ex1.m1.5.5.cmml"><mtr id="S4.Ex1.m1.5.5a" xref="S4.Ex1.m1.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.Ex1.m1.5.5b" xref="S4.Ex1.m1.5.5.cmml"><mrow id="S4.Ex1.m1.3.3.3.3.3.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.cmml"><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1" xref="S4.Ex1.m1.3.3.3.3.3.3.1.cmml"><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.4" xref="S4.Ex1.m1.3.3.3.3.3.3.1.4.cmml">C</mi><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.3.cmml">â†</mo><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.cmml"><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.2.4" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.4.cmml">C</mi><mo id="S4.Ex1.m1.3.3.3.3.3.3.1.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.3.cmml">+</mo><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.cmml"><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.cmml"><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.2.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.1" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.1.cmml">Ã—</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.3.cmml">ğ’©</mi></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.3.cmml">â€‹</mo><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.3.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.3.cmml">(</mo><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.2.1" xref="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.1.cmml">(</mo><mn id="S4.Ex1.m1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml">0</mn><mo id="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.1.cmml">,</mo><mn id="S4.Ex1.m1.2.2.2.2.2.2" xref="S4.Ex1.m1.2.2.2.2.2.2.cmml">0</mn><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.4" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.3.cmml">,</mo><mrow id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.3.cmml">(</mo><msubsup id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.cmml"><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.2.cmml">Ïƒ</mi><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.3.cmml">c</mi><mn id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.3.cmml">2</mn></msubsup><mo id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.4" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.3.cmml">,</mo><msubsup id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.cmml"><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.2.cmml">Ïƒ</mi><mi id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.3.cmml">c</mi><mn id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.3" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.3.cmml">2</mn></msubsup><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.5" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.3.cmml">)</mo></mrow><mo stretchy="false" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.5" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.Ex1.m1.3.3.3.3.3.3.2" xref="S4.Ex1.m1.3.3.3.3.3.3.1.cmml">,</mo></mrow></mtd><mtd id="S4.Ex1.m1.5.5c" xref="S4.Ex1.m1.5.5.cmml"></mtd></mtr><mtr id="S4.Ex1.m1.5.5d" xref="S4.Ex1.m1.5.5.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.Ex1.m1.5.5e" xref="S4.Ex1.m1.5.5.cmml"><mrow id="S4.Ex1.m1.5.5.5.2.2.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.cmml"><mrow id="S4.Ex1.m1.5.5.5.2.2.2.1" xref="S4.Ex1.m1.5.5.5.2.2.2.1.cmml"><mi id="S4.Ex1.m1.5.5.5.2.2.2.1.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.3.cmml">S</mi><mo stretchy="false" id="S4.Ex1.m1.5.5.5.2.2.2.1.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.2.cmml">â†</mo><mrow id="S4.Ex1.m1.5.5.5.2.2.2.1.1" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.cmml"><mi id="S4.Ex1.m1.5.5.5.2.2.2.1.1.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.3.cmml">S</mi><mo id="S4.Ex1.m1.5.5.5.2.2.2.1.1.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.2.cmml">+</mo><mrow id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.cmml"><mrow id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.cmml"><mi id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.2.cmml">S</mi><mo lspace="0.222em" rspace="0.222em" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.1" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.1.cmml">Ã—</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.3.cmml">ğ’©</mi></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.2.cmml">(</mo><mn id="S4.Ex1.m1.4.4.4.1.1.1" xref="S4.Ex1.m1.4.4.4.1.1.1.cmml">0</mn><mo id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.2.cmml">,</mo><msubsup id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.cmml"><mi id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.2.cmml">Ïƒ</mi><mi id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.3.cmml">s</mi><mn id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.3" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.3.cmml">2</mn></msubsup><mo stretchy="false" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.4" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.Ex1.m1.5.5.5.2.2.2.2" xref="S4.Ex1.m1.5.5.5.2.2.2.1.cmml">,</mo></mrow></mtd><mtd id="S4.Ex1.m1.5.5f" xref="S4.Ex1.m1.5.5.cmml"></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.5b"><matrix id="S4.Ex1.m1.5.5.cmml" xref="S4.Ex1.m1.5.5"><matrixrow id="S4.Ex1.m1.5.5a.cmml" xref="S4.Ex1.m1.5.5"><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3"><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.3">â†</ci><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.4.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.4">ğ¶</ci><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2"><plus id="S4.Ex1.m1.3.3.3.3.3.3.1.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.3"></plus><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.4.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.4">ğ¶</ci><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2"><times id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.3"></times><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4"><times id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.1"></times><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.2">ğ‘†</ci><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.4.3">ğ’©</ci></apply><interval closure="open" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2"><interval closure="open" id="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.1.1.1.1.1.2"><cn type="integer" id="S4.Ex1.m1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1">0</cn><cn type="integer" id="S4.Ex1.m1.2.2.2.2.2.2.cmml" xref="S4.Ex1.m1.2.2.2.2.2.2">0</cn></interval><interval closure="open" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2"><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1">subscript</csymbol><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1">superscript</csymbol><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.2">ğœ</ci><cn type="integer" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.2.3">2</cn></apply><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.1.1.3">ğ‘</ci></apply><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2">subscript</csymbol><apply id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.1.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2">superscript</csymbol><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.2.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.2">ğœ</ci><cn type="integer" id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.2.3">2</cn></apply><ci id="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.3.cmml" xref="S4.Ex1.m1.3.3.3.3.3.3.1.2.2.2.2.2.2.2.3">ğ‘</ci></apply></interval></interval></apply></apply></apply><cerror id="S4.Ex1.m1.5.5b.cmml" xref="S4.Ex1.m1.5.5"><csymbol cd="ambiguous" id="S4.Ex1.m1.5.5c.cmml" xref="S4.Ex1.m1.5.5">missing-subexpression</csymbol></cerror></matrixrow><matrixrow id="S4.Ex1.m1.5.5d.cmml" xref="S4.Ex1.m1.5.5"><apply id="S4.Ex1.m1.5.5.5.2.2.2.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2"><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.2">â†</ci><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.3.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.3">ğ‘†</ci><apply id="S4.Ex1.m1.5.5.5.2.2.2.1.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1"><plus id="S4.Ex1.m1.5.5.5.2.2.2.1.1.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.2"></plus><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.1.3.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.3">ğ‘†</ci><apply id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1"><times id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.2"></times><apply id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3"><times id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.1"></times><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.2">ğ‘†</ci><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.3.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.3.3">ğ’©</ci></apply><interval closure="open" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1"><cn type="integer" id="S4.Ex1.m1.4.4.4.1.1.1.cmml" xref="S4.Ex1.m1.4.4.4.1.1.1">0</cn><apply id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1">subscript</csymbol><apply id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.2">ğœ</ci><cn type="integer" id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.2.3">2</cn></apply><ci id="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.5.5.5.2.2.2.1.1.1.1.1.1.3">ğ‘ </ci></apply></interval></apply></apply></apply><cerror id="S4.Ex1.m1.5.5e.cmml" xref="S4.Ex1.m1.5.5"><csymbol cd="ambiguous" id="S4.Ex1.m1.5.5f.cmml" xref="S4.Ex1.m1.5.5">missing-subexpression</csymbol></cerror></matrixrow></matrix></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.5c">\begin{array}[]{lc}C\leftarrow C+S\times\mathcal{N}((0,0),(\sigma^{2}_{c},\sigma^{2}_{c})),\\
S\leftarrow S+S\times\mathcal{N}(0,\sigma^{2}_{s}),\end{array}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS4.SSS2.p1.4" class="ltx_p">where <math id="S4.SS4.SSS2.p1.3.m1.1" class="ltx_Math" alttext="\sigma_{c}" display="inline"><semantics id="S4.SS4.SSS2.p1.3.m1.1a"><msub id="S4.SS4.SSS2.p1.3.m1.1.1" xref="S4.SS4.SSS2.p1.3.m1.1.1.cmml"><mi id="S4.SS4.SSS2.p1.3.m1.1.1.2" xref="S4.SS4.SSS2.p1.3.m1.1.1.2.cmml">Ïƒ</mi><mi id="S4.SS4.SSS2.p1.3.m1.1.1.3" xref="S4.SS4.SSS2.p1.3.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.3.m1.1b"><apply id="S4.SS4.SSS2.p1.3.m1.1.1.cmml" xref="S4.SS4.SSS2.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.3.m1.1.1.1.cmml" xref="S4.SS4.SSS2.p1.3.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.3.m1.1.1.2.cmml" xref="S4.SS4.SSS2.p1.3.m1.1.1.2">ğœ</ci><ci id="S4.SS4.SSS2.p1.3.m1.1.1.3.cmml" xref="S4.SS4.SSS2.p1.3.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.3.m1.1c">\sigma_{c}</annotation></semantics></math> and <math id="S4.SS4.SSS2.p1.4.m2.1" class="ltx_Math" alttext="\sigma_{s}" display="inline"><semantics id="S4.SS4.SSS2.p1.4.m2.1a"><msub id="S4.SS4.SSS2.p1.4.m2.1.1" xref="S4.SS4.SSS2.p1.4.m2.1.1.cmml"><mi id="S4.SS4.SSS2.p1.4.m2.1.1.2" xref="S4.SS4.SSS2.p1.4.m2.1.1.2.cmml">Ïƒ</mi><mi id="S4.SS4.SSS2.p1.4.m2.1.1.3" xref="S4.SS4.SSS2.p1.4.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p1.4.m2.1b"><apply id="S4.SS4.SSS2.p1.4.m2.1.1.cmml" xref="S4.SS4.SSS2.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p1.4.m2.1.1.1.cmml" xref="S4.SS4.SSS2.p1.4.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS2.p1.4.m2.1.1.2.cmml" xref="S4.SS4.SSS2.p1.4.m2.1.1.2">ğœ</ci><ci id="S4.SS4.SSS2.p1.4.m2.1.1.3.cmml" xref="S4.SS4.SSS2.p1.4.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p1.4.m2.1c">\sigma_{s}</annotation></semantics></math> control the level of noise relative to the GT size of bounding box.
The results are shown in Tab.Â <a href="#S4.T2" title="TABLE II â€£ IV-D2 Results on images with noisy bounding boxes â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> and Fig.Â <a href="#S4.F4" title="Figure 4 â€£ IV-D2 Results on images with noisy bounding boxes â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.21" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:444.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(16.3pt,-33.4pt) scale(1.17671533270465,1.17671533270465) ;">
<table id="S4.T2.21.21" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><math id="S4.T2.1.1.1.1.m1.2" class="ltx_Math" alttext="(\sigma_{c},\sigma_{s})" display="inline"><semantics id="S4.T2.1.1.1.1.m1.2a"><mrow id="S4.T2.1.1.1.1.m1.2.2.2" xref="S4.T2.1.1.1.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.T2.1.1.1.1.m1.2.2.2.3" xref="S4.T2.1.1.1.1.m1.2.2.3.cmml">(</mo><msub id="S4.T2.1.1.1.1.m1.1.1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.1.1.cmml"><mi id="S4.T2.1.1.1.1.m1.1.1.1.1.2" xref="S4.T2.1.1.1.1.m1.1.1.1.1.2.cmml">Ïƒ</mi><mi id="S4.T2.1.1.1.1.m1.1.1.1.1.3" xref="S4.T2.1.1.1.1.m1.1.1.1.1.3.cmml">c</mi></msub><mo id="S4.T2.1.1.1.1.m1.2.2.2.4" xref="S4.T2.1.1.1.1.m1.2.2.3.cmml">,</mo><msub id="S4.T2.1.1.1.1.m1.2.2.2.2" xref="S4.T2.1.1.1.1.m1.2.2.2.2.cmml"><mi id="S4.T2.1.1.1.1.m1.2.2.2.2.2" xref="S4.T2.1.1.1.1.m1.2.2.2.2.2.cmml">Ïƒ</mi><mi id="S4.T2.1.1.1.1.m1.2.2.2.2.3" xref="S4.T2.1.1.1.1.m1.2.2.2.2.3.cmml">s</mi></msub><mo stretchy="false" id="S4.T2.1.1.1.1.m1.2.2.2.5" xref="S4.T2.1.1.1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.2b"><interval closure="open" id="S4.T2.1.1.1.1.m1.2.2.3.cmml" xref="S4.T2.1.1.1.1.m1.2.2.2"><apply id="S4.T2.1.1.1.1.m1.1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.T2.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.T2.1.1.1.1.m1.1.1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1.1.2">ğœ</ci><ci id="S4.T2.1.1.1.1.m1.1.1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1.1.3">ğ‘</ci></apply><apply id="S4.T2.1.1.1.1.m1.2.2.2.2.cmml" xref="S4.T2.1.1.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.T2.1.1.1.1.m1.2.2.2.2.1.cmml" xref="S4.T2.1.1.1.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.T2.1.1.1.1.m1.2.2.2.2.2.cmml" xref="S4.T2.1.1.1.1.m1.2.2.2.2.2">ğœ</ci><ci id="S4.T2.1.1.1.1.m1.2.2.2.2.3.cmml" xref="S4.T2.1.1.1.1.m1.2.2.2.2.3">ğ‘ </ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.2c">(\sigma_{c},\sigma_{s})</annotation></semantics></math></th>
<td id="S4.T2.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt">PCK</td>
<td id="S4.T2.1.1.1.3" class="ltx_td ltx_align_right ltx_border_tt">AUC</td>
<td id="S4.T2.1.1.1.4" class="ltx_td ltx_align_right ltx_border_tt">MPJPE</td>
</tr>
<tr id="S4.T2.2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="S4.T2.2.2.2.1.m1.2" class="ltx_Math" alttext="(0,0)" display="inline"><semantics id="S4.T2.2.2.2.1.m1.2a"><mrow id="S4.T2.2.2.2.1.m1.2.3.2" xref="S4.T2.2.2.2.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.2.2.2.1.m1.2.3.2.1" xref="S4.T2.2.2.2.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.2.2.2.1.m1.1.1" xref="S4.T2.2.2.2.1.m1.1.1.cmml">0</mn><mo id="S4.T2.2.2.2.1.m1.2.3.2.2" xref="S4.T2.2.2.2.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.2.2.2.1.m1.2.2" xref="S4.T2.2.2.2.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.2.2.2.1.m1.2.3.2.3" xref="S4.T2.2.2.2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.1.m1.2b"><interval closure="open" id="S4.T2.2.2.2.1.m1.2.3.1.cmml" xref="S4.T2.2.2.2.1.m1.2.3.2"><cn type="integer" id="S4.T2.2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.2.1.m1.1.1">0</cn><cn type="integer" id="S4.T2.2.2.2.1.m1.2.2.cmml" xref="S4.T2.2.2.2.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.1.m1.2c">(0,0)</annotation></semantics></math></th>
<td id="S4.T2.2.2.2.2" class="ltx_td ltx_align_right ltx_border_t">96.4</td>
<td id="S4.T2.2.2.2.3" class="ltx_td ltx_align_right ltx_border_t">66.2</td>
<td id="S4.T2.2.2.2.4" class="ltx_td ltx_align_right ltx_border_t">56.1</td>
</tr>
<tr id="S4.T2.3.3.3" class="ltx_tr">
<th id="S4.T2.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.3.3.3.1.m1.2" class="ltx_Math" alttext="(0.1,0)" display="inline"><semantics id="S4.T2.3.3.3.1.m1.2a"><mrow id="S4.T2.3.3.3.1.m1.2.3.2" xref="S4.T2.3.3.3.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.3.3.3.1.m1.2.3.2.1" xref="S4.T2.3.3.3.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.3.3.3.1.m1.1.1" xref="S4.T2.3.3.3.1.m1.1.1.cmml">0.1</mn><mo id="S4.T2.3.3.3.1.m1.2.3.2.2" xref="S4.T2.3.3.3.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.3.3.3.1.m1.2.2" xref="S4.T2.3.3.3.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.3.3.3.1.m1.2.3.2.3" xref="S4.T2.3.3.3.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.1.m1.2b"><interval closure="open" id="S4.T2.3.3.3.1.m1.2.3.1.cmml" xref="S4.T2.3.3.3.1.m1.2.3.2"><cn type="float" id="S4.T2.3.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.3.1.m1.1.1">0.1</cn><cn type="integer" id="S4.T2.3.3.3.1.m1.2.2.cmml" xref="S4.T2.3.3.3.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.1.m1.2c">(0.1,0)</annotation></semantics></math></th>
<td id="S4.T2.3.3.3.2" class="ltx_td ltx_align_right">96.3</td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_right">65.9</td>
<td id="S4.T2.3.3.3.4" class="ltx_td ltx_align_right">56.6</td>
</tr>
<tr id="S4.T2.4.4.4" class="ltx_tr">
<th id="S4.T2.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.4.4.4.1.m1.2" class="ltx_Math" alttext="(0.15,0)" display="inline"><semantics id="S4.T2.4.4.4.1.m1.2a"><mrow id="S4.T2.4.4.4.1.m1.2.3.2" xref="S4.T2.4.4.4.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.4.4.4.1.m1.2.3.2.1" xref="S4.T2.4.4.4.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.4.4.4.1.m1.1.1" xref="S4.T2.4.4.4.1.m1.1.1.cmml">0.15</mn><mo id="S4.T2.4.4.4.1.m1.2.3.2.2" xref="S4.T2.4.4.4.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.4.4.4.1.m1.2.2" xref="S4.T2.4.4.4.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.4.4.4.1.m1.2.3.2.3" xref="S4.T2.4.4.4.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.1.m1.2b"><interval closure="open" id="S4.T2.4.4.4.1.m1.2.3.1.cmml" xref="S4.T2.4.4.4.1.m1.2.3.2"><cn type="float" id="S4.T2.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.1.m1.1.1">0.15</cn><cn type="integer" id="S4.T2.4.4.4.1.m1.2.2.cmml" xref="S4.T2.4.4.4.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.1.m1.2c">(0.15,0)</annotation></semantics></math></th>
<td id="S4.T2.4.4.4.2" class="ltx_td ltx_align_right">95.8</td>
<td id="S4.T2.4.4.4.3" class="ltx_td ltx_align_right">65.3</td>
<td id="S4.T2.4.4.4.4" class="ltx_td ltx_align_right">58.3</td>
</tr>
<tr id="S4.T2.5.5.5" class="ltx_tr">
<th id="S4.T2.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.5.5.5.1.m1.2" class="ltx_Math" alttext="(0.2,0)" display="inline"><semantics id="S4.T2.5.5.5.1.m1.2a"><mrow id="S4.T2.5.5.5.1.m1.2.3.2" xref="S4.T2.5.5.5.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.5.5.5.1.m1.2.3.2.1" xref="S4.T2.5.5.5.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.5.5.5.1.m1.1.1" xref="S4.T2.5.5.5.1.m1.1.1.cmml">0.2</mn><mo id="S4.T2.5.5.5.1.m1.2.3.2.2" xref="S4.T2.5.5.5.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.5.5.5.1.m1.2.2" xref="S4.T2.5.5.5.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.5.5.5.1.m1.2.3.2.3" xref="S4.T2.5.5.5.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.1.m1.2b"><interval closure="open" id="S4.T2.5.5.5.1.m1.2.3.1.cmml" xref="S4.T2.5.5.5.1.m1.2.3.2"><cn type="float" id="S4.T2.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1">0.2</cn><cn type="integer" id="S4.T2.5.5.5.1.m1.2.2.cmml" xref="S4.T2.5.5.5.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.1.m1.2c">(0.2,0)</annotation></semantics></math></th>
<td id="S4.T2.5.5.5.2" class="ltx_td ltx_align_right">94.0</td>
<td id="S4.T2.5.5.5.3" class="ltx_td ltx_align_right">63.6</td>
<td id="S4.T2.5.5.5.4" class="ltx_td ltx_align_right">63.3</td>
</tr>
<tr id="S4.T2.6.6.6" class="ltx_tr">
<th id="S4.T2.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.6.6.6.1.m1.2" class="ltx_Math" alttext="(0.25,0)" display="inline"><semantics id="S4.T2.6.6.6.1.m1.2a"><mrow id="S4.T2.6.6.6.1.m1.2.3.2" xref="S4.T2.6.6.6.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.6.6.6.1.m1.2.3.2.1" xref="S4.T2.6.6.6.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.6.6.6.1.m1.1.1" xref="S4.T2.6.6.6.1.m1.1.1.cmml">0.25</mn><mo id="S4.T2.6.6.6.1.m1.2.3.2.2" xref="S4.T2.6.6.6.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.6.6.6.1.m1.2.2" xref="S4.T2.6.6.6.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.6.6.6.1.m1.2.3.2.3" xref="S4.T2.6.6.6.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.1.m1.2b"><interval closure="open" id="S4.T2.6.6.6.1.m1.2.3.1.cmml" xref="S4.T2.6.6.6.1.m1.2.3.2"><cn type="float" id="S4.T2.6.6.6.1.m1.1.1.cmml" xref="S4.T2.6.6.6.1.m1.1.1">0.25</cn><cn type="integer" id="S4.T2.6.6.6.1.m1.2.2.cmml" xref="S4.T2.6.6.6.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.1.m1.2c">(0.25,0)</annotation></semantics></math></th>
<td id="S4.T2.6.6.6.2" class="ltx_td ltx_align_right">90.9</td>
<td id="S4.T2.6.6.6.3" class="ltx_td ltx_align_right">60.6</td>
<td id="S4.T2.6.6.6.4" class="ltx_td ltx_align_right">71.4</td>
</tr>
<tr id="S4.T2.7.7.7" class="ltx_tr">
<th id="S4.T2.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.7.7.7.1.m1.2" class="ltx_Math" alttext="(0.3,0)" display="inline"><semantics id="S4.T2.7.7.7.1.m1.2a"><mrow id="S4.T2.7.7.7.1.m1.2.3.2" xref="S4.T2.7.7.7.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.7.7.7.1.m1.2.3.2.1" xref="S4.T2.7.7.7.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.7.7.7.1.m1.1.1" xref="S4.T2.7.7.7.1.m1.1.1.cmml">0.3</mn><mo id="S4.T2.7.7.7.1.m1.2.3.2.2" xref="S4.T2.7.7.7.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.7.7.7.1.m1.2.2" xref="S4.T2.7.7.7.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.7.7.7.1.m1.2.3.2.3" xref="S4.T2.7.7.7.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.1.m1.2b"><interval closure="open" id="S4.T2.7.7.7.1.m1.2.3.1.cmml" xref="S4.T2.7.7.7.1.m1.2.3.2"><cn type="float" id="S4.T2.7.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.7.1.m1.1.1">0.3</cn><cn type="integer" id="S4.T2.7.7.7.1.m1.2.2.cmml" xref="S4.T2.7.7.7.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.1.m1.2c">(0.3,0)</annotation></semantics></math></th>
<td id="S4.T2.7.7.7.2" class="ltx_td ltx_align_right">87.4</td>
<td id="S4.T2.7.7.7.3" class="ltx_td ltx_align_right">57.5</td>
<td id="S4.T2.7.7.7.4" class="ltx_td ltx_align_right">81.9</td>
</tr>
<tr id="S4.T2.8.8.8" class="ltx_tr">
<th id="S4.T2.8.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.8.8.8.1.m1.2" class="ltx_Math" alttext="(0.35,0)" display="inline"><semantics id="S4.T2.8.8.8.1.m1.2a"><mrow id="S4.T2.8.8.8.1.m1.2.3.2" xref="S4.T2.8.8.8.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.8.8.8.1.m1.2.3.2.1" xref="S4.T2.8.8.8.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.8.8.8.1.m1.1.1" xref="S4.T2.8.8.8.1.m1.1.1.cmml">0.35</mn><mo id="S4.T2.8.8.8.1.m1.2.3.2.2" xref="S4.T2.8.8.8.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.8.8.8.1.m1.2.2" xref="S4.T2.8.8.8.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.8.8.8.1.m1.2.3.2.3" xref="S4.T2.8.8.8.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.1.m1.2b"><interval closure="open" id="S4.T2.8.8.8.1.m1.2.3.1.cmml" xref="S4.T2.8.8.8.1.m1.2.3.2"><cn type="float" id="S4.T2.8.8.8.1.m1.1.1.cmml" xref="S4.T2.8.8.8.1.m1.1.1">0.35</cn><cn type="integer" id="S4.T2.8.8.8.1.m1.2.2.cmml" xref="S4.T2.8.8.8.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.1.m1.2c">(0.35,0)</annotation></semantics></math></th>
<td id="S4.T2.8.8.8.2" class="ltx_td ltx_align_right">83.4</td>
<td id="S4.T2.8.8.8.3" class="ltx_td ltx_align_right">54.2</td>
<td id="S4.T2.8.8.8.4" class="ltx_td ltx_align_right">93.7</td>
</tr>
<tr id="S4.T2.9.9.9" class="ltx_tr">
<th id="S4.T2.9.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.9.9.9.1.m1.2" class="ltx_Math" alttext="(0.4,0)" display="inline"><semantics id="S4.T2.9.9.9.1.m1.2a"><mrow id="S4.T2.9.9.9.1.m1.2.3.2" xref="S4.T2.9.9.9.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.9.9.9.1.m1.2.3.2.1" xref="S4.T2.9.9.9.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.9.9.9.1.m1.1.1" xref="S4.T2.9.9.9.1.m1.1.1.cmml">0.4</mn><mo id="S4.T2.9.9.9.1.m1.2.3.2.2" xref="S4.T2.9.9.9.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.9.9.9.1.m1.2.2" xref="S4.T2.9.9.9.1.m1.2.2.cmml">0</mn><mo stretchy="false" id="S4.T2.9.9.9.1.m1.2.3.2.3" xref="S4.T2.9.9.9.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.1.m1.2b"><interval closure="open" id="S4.T2.9.9.9.1.m1.2.3.1.cmml" xref="S4.T2.9.9.9.1.m1.2.3.2"><cn type="float" id="S4.T2.9.9.9.1.m1.1.1.cmml" xref="S4.T2.9.9.9.1.m1.1.1">0.4</cn><cn type="integer" id="S4.T2.9.9.9.1.m1.2.2.cmml" xref="S4.T2.9.9.9.1.m1.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.1.m1.2c">(0.4,0)</annotation></semantics></math></th>
<td id="S4.T2.9.9.9.2" class="ltx_td ltx_align_right">80.5</td>
<td id="S4.T2.9.9.9.3" class="ltx_td ltx_align_right">51.7</td>
<td id="S4.T2.9.9.9.4" class="ltx_td ltx_align_right">102.4</td>
</tr>
<tr id="S4.T2.10.10.10" class="ltx_tr">
<th id="S4.T2.10.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="S4.T2.10.10.10.1.m1.2" class="ltx_Math" alttext="(0,0.1)" display="inline"><semantics id="S4.T2.10.10.10.1.m1.2a"><mrow id="S4.T2.10.10.10.1.m1.2.3.2" xref="S4.T2.10.10.10.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.10.10.10.1.m1.2.3.2.1" xref="S4.T2.10.10.10.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.10.10.10.1.m1.1.1" xref="S4.T2.10.10.10.1.m1.1.1.cmml">0</mn><mo id="S4.T2.10.10.10.1.m1.2.3.2.2" xref="S4.T2.10.10.10.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.10.10.10.1.m1.2.2" xref="S4.T2.10.10.10.1.m1.2.2.cmml">0.1</mn><mo stretchy="false" id="S4.T2.10.10.10.1.m1.2.3.2.3" xref="S4.T2.10.10.10.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.10.1.m1.2b"><interval closure="open" id="S4.T2.10.10.10.1.m1.2.3.1.cmml" xref="S4.T2.10.10.10.1.m1.2.3.2"><cn type="integer" id="S4.T2.10.10.10.1.m1.1.1.cmml" xref="S4.T2.10.10.10.1.m1.1.1">0</cn><cn type="float" id="S4.T2.10.10.10.1.m1.2.2.cmml" xref="S4.T2.10.10.10.1.m1.2.2">0.1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.10.1.m1.2c">(0,0.1)</annotation></semantics></math></th>
<td id="S4.T2.10.10.10.2" class="ltx_td ltx_align_right ltx_border_t">96.4</td>
<td id="S4.T2.10.10.10.3" class="ltx_td ltx_align_right ltx_border_t">66.2</td>
<td id="S4.T2.10.10.10.4" class="ltx_td ltx_align_right ltx_border_t">56.3</td>
</tr>
<tr id="S4.T2.11.11.11" class="ltx_tr">
<th id="S4.T2.11.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.11.11.11.1.m1.2" class="ltx_Math" alttext="(0,0.15)" display="inline"><semantics id="S4.T2.11.11.11.1.m1.2a"><mrow id="S4.T2.11.11.11.1.m1.2.3.2" xref="S4.T2.11.11.11.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.11.11.11.1.m1.2.3.2.1" xref="S4.T2.11.11.11.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.11.11.11.1.m1.1.1" xref="S4.T2.11.11.11.1.m1.1.1.cmml">0</mn><mo id="S4.T2.11.11.11.1.m1.2.3.2.2" xref="S4.T2.11.11.11.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.11.11.11.1.m1.2.2" xref="S4.T2.11.11.11.1.m1.2.2.cmml">0.15</mn><mo stretchy="false" id="S4.T2.11.11.11.1.m1.2.3.2.3" xref="S4.T2.11.11.11.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.1.m1.2b"><interval closure="open" id="S4.T2.11.11.11.1.m1.2.3.1.cmml" xref="S4.T2.11.11.11.1.m1.2.3.2"><cn type="integer" id="S4.T2.11.11.11.1.m1.1.1.cmml" xref="S4.T2.11.11.11.1.m1.1.1">0</cn><cn type="float" id="S4.T2.11.11.11.1.m1.2.2.cmml" xref="S4.T2.11.11.11.1.m1.2.2">0.15</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.1.m1.2c">(0,0.15)</annotation></semantics></math></th>
<td id="S4.T2.11.11.11.2" class="ltx_td ltx_align_right">96.4</td>
<td id="S4.T2.11.11.11.3" class="ltx_td ltx_align_right">66.0</td>
<td id="S4.T2.11.11.11.4" class="ltx_td ltx_align_right">56.5</td>
</tr>
<tr id="S4.T2.12.12.12" class="ltx_tr">
<th id="S4.T2.12.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.12.12.12.1.m1.2" class="ltx_Math" alttext="(0,0.2)" display="inline"><semantics id="S4.T2.12.12.12.1.m1.2a"><mrow id="S4.T2.12.12.12.1.m1.2.3.2" xref="S4.T2.12.12.12.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.12.12.12.1.m1.2.3.2.1" xref="S4.T2.12.12.12.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.12.12.12.1.m1.1.1" xref="S4.T2.12.12.12.1.m1.1.1.cmml">0</mn><mo id="S4.T2.12.12.12.1.m1.2.3.2.2" xref="S4.T2.12.12.12.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.12.12.12.1.m1.2.2" xref="S4.T2.12.12.12.1.m1.2.2.cmml">0.2</mn><mo stretchy="false" id="S4.T2.12.12.12.1.m1.2.3.2.3" xref="S4.T2.12.12.12.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.1.m1.2b"><interval closure="open" id="S4.T2.12.12.12.1.m1.2.3.1.cmml" xref="S4.T2.12.12.12.1.m1.2.3.2"><cn type="integer" id="S4.T2.12.12.12.1.m1.1.1.cmml" xref="S4.T2.12.12.12.1.m1.1.1">0</cn><cn type="float" id="S4.T2.12.12.12.1.m1.2.2.cmml" xref="S4.T2.12.12.12.1.m1.2.2">0.2</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.1.m1.2c">(0,0.2)</annotation></semantics></math></th>
<td id="S4.T2.12.12.12.2" class="ltx_td ltx_align_right">96.1</td>
<td id="S4.T2.12.12.12.3" class="ltx_td ltx_align_right">65.7</td>
<td id="S4.T2.12.12.12.4" class="ltx_td ltx_align_right">57.3</td>
</tr>
<tr id="S4.T2.13.13.13" class="ltx_tr">
<th id="S4.T2.13.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.13.13.13.1.m1.2" class="ltx_Math" alttext="(0,0.25)" display="inline"><semantics id="S4.T2.13.13.13.1.m1.2a"><mrow id="S4.T2.13.13.13.1.m1.2.3.2" xref="S4.T2.13.13.13.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.13.13.13.1.m1.2.3.2.1" xref="S4.T2.13.13.13.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.13.13.13.1.m1.1.1" xref="S4.T2.13.13.13.1.m1.1.1.cmml">0</mn><mo id="S4.T2.13.13.13.1.m1.2.3.2.2" xref="S4.T2.13.13.13.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.13.13.13.1.m1.2.2" xref="S4.T2.13.13.13.1.m1.2.2.cmml">0.25</mn><mo stretchy="false" id="S4.T2.13.13.13.1.m1.2.3.2.3" xref="S4.T2.13.13.13.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.13.1.m1.2b"><interval closure="open" id="S4.T2.13.13.13.1.m1.2.3.1.cmml" xref="S4.T2.13.13.13.1.m1.2.3.2"><cn type="integer" id="S4.T2.13.13.13.1.m1.1.1.cmml" xref="S4.T2.13.13.13.1.m1.1.1">0</cn><cn type="float" id="S4.T2.13.13.13.1.m1.2.2.cmml" xref="S4.T2.13.13.13.1.m1.2.2">0.25</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.13.1.m1.2c">(0,0.25)</annotation></semantics></math></th>
<td id="S4.T2.13.13.13.2" class="ltx_td ltx_align_right">95.9</td>
<td id="S4.T2.13.13.13.3" class="ltx_td ltx_align_right">65.5</td>
<td id="S4.T2.13.13.13.4" class="ltx_td ltx_align_right">58.9</td>
</tr>
<tr id="S4.T2.14.14.14" class="ltx_tr">
<th id="S4.T2.14.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.14.14.14.1.m1.2" class="ltx_Math" alttext="(0,0.3)" display="inline"><semantics id="S4.T2.14.14.14.1.m1.2a"><mrow id="S4.T2.14.14.14.1.m1.2.3.2" xref="S4.T2.14.14.14.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.14.14.14.1.m1.2.3.2.1" xref="S4.T2.14.14.14.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.14.14.14.1.m1.1.1" xref="S4.T2.14.14.14.1.m1.1.1.cmml">0</mn><mo id="S4.T2.14.14.14.1.m1.2.3.2.2" xref="S4.T2.14.14.14.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.14.14.14.1.m1.2.2" xref="S4.T2.14.14.14.1.m1.2.2.cmml">0.3</mn><mo stretchy="false" id="S4.T2.14.14.14.1.m1.2.3.2.3" xref="S4.T2.14.14.14.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.14.1.m1.2b"><interval closure="open" id="S4.T2.14.14.14.1.m1.2.3.1.cmml" xref="S4.T2.14.14.14.1.m1.2.3.2"><cn type="integer" id="S4.T2.14.14.14.1.m1.1.1.cmml" xref="S4.T2.14.14.14.1.m1.1.1">0</cn><cn type="float" id="S4.T2.14.14.14.1.m1.2.2.cmml" xref="S4.T2.14.14.14.1.m1.2.2">0.3</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.14.1.m1.2c">(0,0.3)</annotation></semantics></math></th>
<td id="S4.T2.14.14.14.2" class="ltx_td ltx_align_right">95.6</td>
<td id="S4.T2.14.14.14.3" class="ltx_td ltx_align_right">65.0</td>
<td id="S4.T2.14.14.14.4" class="ltx_td ltx_align_right">59.2</td>
</tr>
<tr id="S4.T2.15.15.15" class="ltx_tr">
<th id="S4.T2.15.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.15.15.15.1.m1.2" class="ltx_Math" alttext="(0,0.35)" display="inline"><semantics id="S4.T2.15.15.15.1.m1.2a"><mrow id="S4.T2.15.15.15.1.m1.2.3.2" xref="S4.T2.15.15.15.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.15.15.15.1.m1.2.3.2.1" xref="S4.T2.15.15.15.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.15.15.15.1.m1.1.1" xref="S4.T2.15.15.15.1.m1.1.1.cmml">0</mn><mo id="S4.T2.15.15.15.1.m1.2.3.2.2" xref="S4.T2.15.15.15.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.15.15.15.1.m1.2.2" xref="S4.T2.15.15.15.1.m1.2.2.cmml">0.35</mn><mo stretchy="false" id="S4.T2.15.15.15.1.m1.2.3.2.3" xref="S4.T2.15.15.15.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.15.1.m1.2b"><interval closure="open" id="S4.T2.15.15.15.1.m1.2.3.1.cmml" xref="S4.T2.15.15.15.1.m1.2.3.2"><cn type="integer" id="S4.T2.15.15.15.1.m1.1.1.cmml" xref="S4.T2.15.15.15.1.m1.1.1">0</cn><cn type="float" id="S4.T2.15.15.15.1.m1.2.2.cmml" xref="S4.T2.15.15.15.1.m1.2.2">0.35</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.15.1.m1.2c">(0,0.35)</annotation></semantics></math></th>
<td id="S4.T2.15.15.15.2" class="ltx_td ltx_align_right">95.2</td>
<td id="S4.T2.15.15.15.3" class="ltx_td ltx_align_right">64.4</td>
<td id="S4.T2.15.15.15.4" class="ltx_td ltx_align_right">60.8</td>
</tr>
<tr id="S4.T2.16.16.16" class="ltx_tr">
<th id="S4.T2.16.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.16.16.16.1.m1.2" class="ltx_Math" alttext="(0,0.4)" display="inline"><semantics id="S4.T2.16.16.16.1.m1.2a"><mrow id="S4.T2.16.16.16.1.m1.2.3.2" xref="S4.T2.16.16.16.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.16.16.16.1.m1.2.3.2.1" xref="S4.T2.16.16.16.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.16.16.16.1.m1.1.1" xref="S4.T2.16.16.16.1.m1.1.1.cmml">0</mn><mo id="S4.T2.16.16.16.1.m1.2.3.2.2" xref="S4.T2.16.16.16.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.16.16.16.1.m1.2.2" xref="S4.T2.16.16.16.1.m1.2.2.cmml">0.4</mn><mo stretchy="false" id="S4.T2.16.16.16.1.m1.2.3.2.3" xref="S4.T2.16.16.16.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.16.1.m1.2b"><interval closure="open" id="S4.T2.16.16.16.1.m1.2.3.1.cmml" xref="S4.T2.16.16.16.1.m1.2.3.2"><cn type="integer" id="S4.T2.16.16.16.1.m1.1.1.cmml" xref="S4.T2.16.16.16.1.m1.1.1">0</cn><cn type="float" id="S4.T2.16.16.16.1.m1.2.2.cmml" xref="S4.T2.16.16.16.1.m1.2.2">0.4</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.16.1.m1.2c">(0,0.4)</annotation></semantics></math></th>
<td id="S4.T2.16.16.16.2" class="ltx_td ltx_align_right">94.7</td>
<td id="S4.T2.16.16.16.3" class="ltx_td ltx_align_right">63.9</td>
<td id="S4.T2.16.16.16.4" class="ltx_td ltx_align_right">62.4</td>
</tr>
<tr id="S4.T2.17.17.17" class="ltx_tr">
<th id="S4.T2.17.17.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="S4.T2.17.17.17.1.m1.2" class="ltx_Math" alttext="(0.1,0.1)" display="inline"><semantics id="S4.T2.17.17.17.1.m1.2a"><mrow id="S4.T2.17.17.17.1.m1.2.3.2" xref="S4.T2.17.17.17.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.17.17.17.1.m1.2.3.2.1" xref="S4.T2.17.17.17.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.17.17.17.1.m1.1.1" xref="S4.T2.17.17.17.1.m1.1.1.cmml">0.1</mn><mo id="S4.T2.17.17.17.1.m1.2.3.2.2" xref="S4.T2.17.17.17.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.17.17.17.1.m1.2.2" xref="S4.T2.17.17.17.1.m1.2.2.cmml">0.1</mn><mo stretchy="false" id="S4.T2.17.17.17.1.m1.2.3.2.3" xref="S4.T2.17.17.17.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.17.1.m1.2b"><interval closure="open" id="S4.T2.17.17.17.1.m1.2.3.1.cmml" xref="S4.T2.17.17.17.1.m1.2.3.2"><cn type="float" id="S4.T2.17.17.17.1.m1.1.1.cmml" xref="S4.T2.17.17.17.1.m1.1.1">0.1</cn><cn type="float" id="S4.T2.17.17.17.1.m1.2.2.cmml" xref="S4.T2.17.17.17.1.m1.2.2">0.1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.17.1.m1.2c">(0.1,0.1)</annotation></semantics></math></th>
<td id="S4.T2.17.17.17.2" class="ltx_td ltx_align_right ltx_border_t">96.3</td>
<td id="S4.T2.17.17.17.3" class="ltx_td ltx_align_right ltx_border_t">65.9</td>
<td id="S4.T2.17.17.17.4" class="ltx_td ltx_align_right ltx_border_t">56.8</td>
</tr>
<tr id="S4.T2.18.18.18" class="ltx_tr">
<th id="S4.T2.18.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.18.18.18.1.m1.2" class="ltx_Math" alttext="(0.15,0.15)" display="inline"><semantics id="S4.T2.18.18.18.1.m1.2a"><mrow id="S4.T2.18.18.18.1.m1.2.3.2" xref="S4.T2.18.18.18.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.18.18.18.1.m1.2.3.2.1" xref="S4.T2.18.18.18.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.18.18.18.1.m1.1.1" xref="S4.T2.18.18.18.1.m1.1.1.cmml">0.15</mn><mo id="S4.T2.18.18.18.1.m1.2.3.2.2" xref="S4.T2.18.18.18.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.18.18.18.1.m1.2.2" xref="S4.T2.18.18.18.1.m1.2.2.cmml">0.15</mn><mo stretchy="false" id="S4.T2.18.18.18.1.m1.2.3.2.3" xref="S4.T2.18.18.18.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.18.1.m1.2b"><interval closure="open" id="S4.T2.18.18.18.1.m1.2.3.1.cmml" xref="S4.T2.18.18.18.1.m1.2.3.2"><cn type="float" id="S4.T2.18.18.18.1.m1.1.1.cmml" xref="S4.T2.18.18.18.1.m1.1.1">0.15</cn><cn type="float" id="S4.T2.18.18.18.1.m1.2.2.cmml" xref="S4.T2.18.18.18.1.m1.2.2">0.15</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.18.1.m1.2c">(0.15,0.15)</annotation></semantics></math></th>
<td id="S4.T2.18.18.18.2" class="ltx_td ltx_align_right">95.2</td>
<td id="S4.T2.18.18.18.3" class="ltx_td ltx_align_right">64.6</td>
<td id="S4.T2.18.18.18.4" class="ltx_td ltx_align_right">59.2</td>
</tr>
<tr id="S4.T2.19.19.19" class="ltx_tr">
<th id="S4.T2.19.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.19.19.19.1.m1.2" class="ltx_Math" alttext="(0.2,0.2)" display="inline"><semantics id="S4.T2.19.19.19.1.m1.2a"><mrow id="S4.T2.19.19.19.1.m1.2.3.2" xref="S4.T2.19.19.19.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.19.19.19.1.m1.2.3.2.1" xref="S4.T2.19.19.19.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.19.19.19.1.m1.1.1" xref="S4.T2.19.19.19.1.m1.1.1.cmml">0.2</mn><mo id="S4.T2.19.19.19.1.m1.2.3.2.2" xref="S4.T2.19.19.19.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.19.19.19.1.m1.2.2" xref="S4.T2.19.19.19.1.m1.2.2.cmml">0.2</mn><mo stretchy="false" id="S4.T2.19.19.19.1.m1.2.3.2.3" xref="S4.T2.19.19.19.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.19.1.m1.2b"><interval closure="open" id="S4.T2.19.19.19.1.m1.2.3.1.cmml" xref="S4.T2.19.19.19.1.m1.2.3.2"><cn type="float" id="S4.T2.19.19.19.1.m1.1.1.cmml" xref="S4.T2.19.19.19.1.m1.1.1">0.2</cn><cn type="float" id="S4.T2.19.19.19.1.m1.2.2.cmml" xref="S4.T2.19.19.19.1.m1.2.2">0.2</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.19.1.m1.2c">(0.2,0.2)</annotation></semantics></math></th>
<td id="S4.T2.19.19.19.2" class="ltx_td ltx_align_right">91.9</td>
<td id="S4.T2.19.19.19.3" class="ltx_td ltx_align_right">61.7</td>
<td id="S4.T2.19.19.19.4" class="ltx_td ltx_align_right">69.8</td>
</tr>
<tr id="S4.T2.20.20.20" class="ltx_tr">
<th id="S4.T2.20.20.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="S4.T2.20.20.20.1.m1.2" class="ltx_Math" alttext="(0.3,0.3)" display="inline"><semantics id="S4.T2.20.20.20.1.m1.2a"><mrow id="S4.T2.20.20.20.1.m1.2.3.2" xref="S4.T2.20.20.20.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.20.20.20.1.m1.2.3.2.1" xref="S4.T2.20.20.20.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.20.20.20.1.m1.1.1" xref="S4.T2.20.20.20.1.m1.1.1.cmml">0.3</mn><mo id="S4.T2.20.20.20.1.m1.2.3.2.2" xref="S4.T2.20.20.20.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.20.20.20.1.m1.2.2" xref="S4.T2.20.20.20.1.m1.2.2.cmml">0.3</mn><mo stretchy="false" id="S4.T2.20.20.20.1.m1.2.3.2.3" xref="S4.T2.20.20.20.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.20.1.m1.2b"><interval closure="open" id="S4.T2.20.20.20.1.m1.2.3.1.cmml" xref="S4.T2.20.20.20.1.m1.2.3.2"><cn type="float" id="S4.T2.20.20.20.1.m1.1.1.cmml" xref="S4.T2.20.20.20.1.m1.1.1">0.3</cn><cn type="float" id="S4.T2.20.20.20.1.m1.2.2.cmml" xref="S4.T2.20.20.20.1.m1.2.2">0.3</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.20.1.m1.2c">(0.3,0.3)</annotation></semantics></math></th>
<td id="S4.T2.20.20.20.2" class="ltx_td ltx_align_right">81.4</td>
<td id="S4.T2.20.20.20.3" class="ltx_td ltx_align_right">53.0</td>
<td id="S4.T2.20.20.20.4" class="ltx_td ltx_align_right">106.3</td>
</tr>
<tr id="S4.T2.21.21.21" class="ltx_tr">
<th id="S4.T2.21.21.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><math id="S4.T2.21.21.21.1.m1.2" class="ltx_Math" alttext="(0.4,0.4)" display="inline"><semantics id="S4.T2.21.21.21.1.m1.2a"><mrow id="S4.T2.21.21.21.1.m1.2.3.2" xref="S4.T2.21.21.21.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.T2.21.21.21.1.m1.2.3.2.1" xref="S4.T2.21.21.21.1.m1.2.3.1.cmml">(</mo><mn id="S4.T2.21.21.21.1.m1.1.1" xref="S4.T2.21.21.21.1.m1.1.1.cmml">0.4</mn><mo id="S4.T2.21.21.21.1.m1.2.3.2.2" xref="S4.T2.21.21.21.1.m1.2.3.1.cmml">,</mo><mn id="S4.T2.21.21.21.1.m1.2.2" xref="S4.T2.21.21.21.1.m1.2.2.cmml">0.4</mn><mo stretchy="false" id="S4.T2.21.21.21.1.m1.2.3.2.3" xref="S4.T2.21.21.21.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.21.1.m1.2b"><interval closure="open" id="S4.T2.21.21.21.1.m1.2.3.1.cmml" xref="S4.T2.21.21.21.1.m1.2.3.2"><cn type="float" id="S4.T2.21.21.21.1.m1.1.1.cmml" xref="S4.T2.21.21.21.1.m1.1.1">0.4</cn><cn type="float" id="S4.T2.21.21.21.1.m1.2.2.cmml" xref="S4.T2.21.21.21.1.m1.2.2">0.4</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.21.1.m1.2c">(0.4,0.4)</annotation></semantics></math></th>
<td id="S4.T2.21.21.21.2" class="ltx_td ltx_align_right ltx_border_bb">72.8</td>
<td id="S4.T2.21.21.21.3" class="ltx_td ltx_align_right ltx_border_bb">46.4</td>
<td id="S4.T2.21.21.21.4" class="ltx_td ltx_align_right ltx_border_bb">138.2</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Performance of our method on Human3.6M with different levels of Gaussian noises in the bounding boxes.</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2112.11153/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Results on Human3.6M with Gaussian noises <math id="S4.F4.2.m1.2" class="ltx_Math" alttext="\mathcal{N}(0,\sigma^{2})" display="inline"><semantics id="S4.F4.2.m1.2b"><mrow id="S4.F4.2.m1.2.2" xref="S4.F4.2.m1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F4.2.m1.2.2.3" xref="S4.F4.2.m1.2.2.3.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S4.F4.2.m1.2.2.2" xref="S4.F4.2.m1.2.2.2.cmml">â€‹</mo><mrow id="S4.F4.2.m1.2.2.1.1" xref="S4.F4.2.m1.2.2.1.2.cmml"><mo stretchy="false" id="S4.F4.2.m1.2.2.1.1.2" xref="S4.F4.2.m1.2.2.1.2.cmml">(</mo><mn id="S4.F4.2.m1.1.1" xref="S4.F4.2.m1.1.1.cmml">0</mn><mo id="S4.F4.2.m1.2.2.1.1.3" xref="S4.F4.2.m1.2.2.1.2.cmml">,</mo><msup id="S4.F4.2.m1.2.2.1.1.1" xref="S4.F4.2.m1.2.2.1.1.1.cmml"><mi id="S4.F4.2.m1.2.2.1.1.1.2" xref="S4.F4.2.m1.2.2.1.1.1.2.cmml">Ïƒ</mi><mn id="S4.F4.2.m1.2.2.1.1.1.3" xref="S4.F4.2.m1.2.2.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S4.F4.2.m1.2.2.1.1.4" xref="S4.F4.2.m1.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.2.m1.2c"><apply id="S4.F4.2.m1.2.2.cmml" xref="S4.F4.2.m1.2.2"><times id="S4.F4.2.m1.2.2.2.cmml" xref="S4.F4.2.m1.2.2.2"></times><ci id="S4.F4.2.m1.2.2.3.cmml" xref="S4.F4.2.m1.2.2.3">ğ’©</ci><interval closure="open" id="S4.F4.2.m1.2.2.1.2.cmml" xref="S4.F4.2.m1.2.2.1.1"><cn type="integer" id="S4.F4.2.m1.1.1.cmml" xref="S4.F4.2.m1.1.1">0</cn><apply id="S4.F4.2.m1.2.2.1.1.1.cmml" xref="S4.F4.2.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.F4.2.m1.2.2.1.1.1.1.cmml" xref="S4.F4.2.m1.2.2.1.1.1">superscript</csymbol><ci id="S4.F4.2.m1.2.2.1.1.1.2.cmml" xref="S4.F4.2.m1.2.2.1.1.1.2">ğœ</ci><cn type="integer" id="S4.F4.2.m1.2.2.1.1.1.3.cmml" xref="S4.F4.2.m1.2.2.1.1.1.3">2</cn></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.2.m1.2d">\mathcal{N}(0,\sigma^{2})</annotation></semantics></math> added to the centers or/and sizes of GT bounding boxes.</figcaption>
</figure>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.9" class="ltx_p">We can see that: (a) When <math id="S4.SS4.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\sigma_{c}&lt;0.1" display="inline"><semantics id="S4.SS4.SSS2.p2.1.m1.1a"><mrow id="S4.SS4.SSS2.p2.1.m1.1.1" xref="S4.SS4.SSS2.p2.1.m1.1.1.cmml"><msub id="S4.SS4.SSS2.p2.1.m1.1.1.2" xref="S4.SS4.SSS2.p2.1.m1.1.1.2.cmml"><mi id="S4.SS4.SSS2.p2.1.m1.1.1.2.2" xref="S4.SS4.SSS2.p2.1.m1.1.1.2.2.cmml">Ïƒ</mi><mi id="S4.SS4.SSS2.p2.1.m1.1.1.2.3" xref="S4.SS4.SSS2.p2.1.m1.1.1.2.3.cmml">c</mi></msub><mo id="S4.SS4.SSS2.p2.1.m1.1.1.1" xref="S4.SS4.SSS2.p2.1.m1.1.1.1.cmml">&lt;</mo><mn id="S4.SS4.SSS2.p2.1.m1.1.1.3" xref="S4.SS4.SSS2.p2.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.1.m1.1b"><apply id="S4.SS4.SSS2.p2.1.m1.1.1.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1"><lt id="S4.SS4.SSS2.p2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.1"></lt><apply id="S4.SS4.SSS2.p2.1.m1.1.1.2.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS4.SSS2.p2.1.m1.1.1.2.2.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.2.2">ğœ</ci><ci id="S4.SS4.SSS2.p2.1.m1.1.1.2.3.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.2.3">ğ‘</ci></apply><cn type="float" id="S4.SS4.SSS2.p2.1.m1.1.1.3.cmml" xref="S4.SS4.SSS2.p2.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.1.m1.1c">\sigma_{c}&lt;0.1</annotation></semantics></math> and <math id="S4.SS4.SSS2.p2.2.m2.1" class="ltx_Math" alttext="\sigma_{s}&lt;0.1" display="inline"><semantics id="S4.SS4.SSS2.p2.2.m2.1a"><mrow id="S4.SS4.SSS2.p2.2.m2.1.1" xref="S4.SS4.SSS2.p2.2.m2.1.1.cmml"><msub id="S4.SS4.SSS2.p2.2.m2.1.1.2" xref="S4.SS4.SSS2.p2.2.m2.1.1.2.cmml"><mi id="S4.SS4.SSS2.p2.2.m2.1.1.2.2" xref="S4.SS4.SSS2.p2.2.m2.1.1.2.2.cmml">Ïƒ</mi><mi id="S4.SS4.SSS2.p2.2.m2.1.1.2.3" xref="S4.SS4.SSS2.p2.2.m2.1.1.2.3.cmml">s</mi></msub><mo id="S4.SS4.SSS2.p2.2.m2.1.1.1" xref="S4.SS4.SSS2.p2.2.m2.1.1.1.cmml">&lt;</mo><mn id="S4.SS4.SSS2.p2.2.m2.1.1.3" xref="S4.SS4.SSS2.p2.2.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.2.m2.1b"><apply id="S4.SS4.SSS2.p2.2.m2.1.1.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1"><lt id="S4.SS4.SSS2.p2.2.m2.1.1.1.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.1"></lt><apply id="S4.SS4.SSS2.p2.2.m2.1.1.2.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.2.m2.1.1.2.1.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS4.SSS2.p2.2.m2.1.1.2.2.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.2.2">ğœ</ci><ci id="S4.SS4.SSS2.p2.2.m2.1.1.2.3.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.2.3">ğ‘ </ci></apply><cn type="float" id="S4.SS4.SSS2.p2.2.m2.1.1.3.cmml" xref="S4.SS4.SSS2.p2.2.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.2.m2.1c">\sigma_{s}&lt;0.1</annotation></semantics></math>,
the PCK and AUC of our approach drop less than <math id="S4.SS4.SSS2.p2.3.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.SS4.SSS2.p2.3.m3.1a"><mrow id="S4.SS4.SSS2.p2.3.m3.1.1" xref="S4.SS4.SSS2.p2.3.m3.1.1.cmml"><mn id="S4.SS4.SSS2.p2.3.m3.1.1.2" xref="S4.SS4.SSS2.p2.3.m3.1.1.2.cmml">1</mn><mo id="S4.SS4.SSS2.p2.3.m3.1.1.1" xref="S4.SS4.SSS2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.3.m3.1b"><apply id="S4.SS4.SSS2.p2.3.m3.1.1.cmml" xref="S4.SS4.SSS2.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.SSS2.p2.3.m3.1.1.1.cmml" xref="S4.SS4.SSS2.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.SSS2.p2.3.m3.1.1.2.cmml" xref="S4.SS4.SSS2.p2.3.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.3.m3.1c">1\%</annotation></semantics></math>, while MPJPE drops about <math id="S4.SS4.SSS2.p2.4.m4.1" class="ltx_Math" alttext="1.2\%" display="inline"><semantics id="S4.SS4.SSS2.p2.4.m4.1a"><mrow id="S4.SS4.SSS2.p2.4.m4.1.1" xref="S4.SS4.SSS2.p2.4.m4.1.1.cmml"><mn id="S4.SS4.SSS2.p2.4.m4.1.1.2" xref="S4.SS4.SSS2.p2.4.m4.1.1.2.cmml">1.2</mn><mo id="S4.SS4.SSS2.p2.4.m4.1.1.1" xref="S4.SS4.SSS2.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.4.m4.1b"><apply id="S4.SS4.SSS2.p2.4.m4.1.1.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS4.SSS2.p2.4.m4.1.1.1.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.SSS2.p2.4.m4.1.1.2.cmml" xref="S4.SS4.SSS2.p2.4.m4.1.1.2">1.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.4.m4.1c">1.2\%</annotation></semantics></math>, proving that our performance is very stable on images with small noiseÂ (25.6 pixels) added to the bounding boxes.
(b) When <math id="S4.SS4.SSS2.p2.5.m5.1" class="ltx_Math" alttext="\sigma_{c}=0.2" display="inline"><semantics id="S4.SS4.SSS2.p2.5.m5.1a"><mrow id="S4.SS4.SSS2.p2.5.m5.1.1" xref="S4.SS4.SSS2.p2.5.m5.1.1.cmml"><msub id="S4.SS4.SSS2.p2.5.m5.1.1.2" xref="S4.SS4.SSS2.p2.5.m5.1.1.2.cmml"><mi id="S4.SS4.SSS2.p2.5.m5.1.1.2.2" xref="S4.SS4.SSS2.p2.5.m5.1.1.2.2.cmml">Ïƒ</mi><mi id="S4.SS4.SSS2.p2.5.m5.1.1.2.3" xref="S4.SS4.SSS2.p2.5.m5.1.1.2.3.cmml">c</mi></msub><mo id="S4.SS4.SSS2.p2.5.m5.1.1.1" xref="S4.SS4.SSS2.p2.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS4.SSS2.p2.5.m5.1.1.3" xref="S4.SS4.SSS2.p2.5.m5.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.5.m5.1b"><apply id="S4.SS4.SSS2.p2.5.m5.1.1.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1"><eq id="S4.SS4.SSS2.p2.5.m5.1.1.1.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1.1"></eq><apply id="S4.SS4.SSS2.p2.5.m5.1.1.2.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.5.m5.1.1.2.1.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS4.SSS2.p2.5.m5.1.1.2.2.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1.2.2">ğœ</ci><ci id="S4.SS4.SSS2.p2.5.m5.1.1.2.3.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1.2.3">ğ‘</ci></apply><cn type="float" id="S4.SS4.SSS2.p2.5.m5.1.1.3.cmml" xref="S4.SS4.SSS2.p2.5.m5.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.5.m5.1c">\sigma_{c}=0.2</annotation></semantics></math> and <math id="S4.SS4.SSS2.p2.6.m6.1" class="ltx_Math" alttext="\sigma_{s}=0.2" display="inline"><semantics id="S4.SS4.SSS2.p2.6.m6.1a"><mrow id="S4.SS4.SSS2.p2.6.m6.1.1" xref="S4.SS4.SSS2.p2.6.m6.1.1.cmml"><msub id="S4.SS4.SSS2.p2.6.m6.1.1.2" xref="S4.SS4.SSS2.p2.6.m6.1.1.2.cmml"><mi id="S4.SS4.SSS2.p2.6.m6.1.1.2.2" xref="S4.SS4.SSS2.p2.6.m6.1.1.2.2.cmml">Ïƒ</mi><mi id="S4.SS4.SSS2.p2.6.m6.1.1.2.3" xref="S4.SS4.SSS2.p2.6.m6.1.1.2.3.cmml">s</mi></msub><mo id="S4.SS4.SSS2.p2.6.m6.1.1.1" xref="S4.SS4.SSS2.p2.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS4.SSS2.p2.6.m6.1.1.3" xref="S4.SS4.SSS2.p2.6.m6.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.6.m6.1b"><apply id="S4.SS4.SSS2.p2.6.m6.1.1.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1"><eq id="S4.SS4.SSS2.p2.6.m6.1.1.1.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.1"></eq><apply id="S4.SS4.SSS2.p2.6.m6.1.1.2.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS4.SSS2.p2.6.m6.1.1.2.1.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS4.SSS2.p2.6.m6.1.1.2.2.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.2.2">ğœ</ci><ci id="S4.SS4.SSS2.p2.6.m6.1.1.2.3.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.2.3">ğ‘ </ci></apply><cn type="float" id="S4.SS4.SSS2.p2.6.m6.1.1.3.cmml" xref="S4.SS4.SSS2.p2.6.m6.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.6.m6.1c">\sigma_{s}=0.2</annotation></semantics></math>, the PCK only decreases <math id="S4.SS4.SSS2.p2.7.m7.1" class="ltx_Math" alttext="4.7\%" display="inline"><semantics id="S4.SS4.SSS2.p2.7.m7.1a"><mrow id="S4.SS4.SSS2.p2.7.m7.1.1" xref="S4.SS4.SSS2.p2.7.m7.1.1.cmml"><mn id="S4.SS4.SSS2.p2.7.m7.1.1.2" xref="S4.SS4.SSS2.p2.7.m7.1.1.2.cmml">4.7</mn><mo id="S4.SS4.SSS2.p2.7.m7.1.1.1" xref="S4.SS4.SSS2.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.7.m7.1b"><apply id="S4.SS4.SSS2.p2.7.m7.1.1.cmml" xref="S4.SS4.SSS2.p2.7.m7.1.1"><csymbol cd="latexml" id="S4.SS4.SSS2.p2.7.m7.1.1.1.cmml" xref="S4.SS4.SSS2.p2.7.m7.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.SSS2.p2.7.m7.1.1.2.cmml" xref="S4.SS4.SSS2.p2.7.m7.1.1.2">4.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.7.m7.1c">4.7\%</annotation></semantics></math> and AUC decreases <math id="S4.SS4.SSS2.p2.8.m8.1" class="ltx_Math" alttext="6.8\%" display="inline"><semantics id="S4.SS4.SSS2.p2.8.m8.1a"><mrow id="S4.SS4.SSS2.p2.8.m8.1.1" xref="S4.SS4.SSS2.p2.8.m8.1.1.cmml"><mn id="S4.SS4.SSS2.p2.8.m8.1.1.2" xref="S4.SS4.SSS2.p2.8.m8.1.1.2.cmml">6.8</mn><mo id="S4.SS4.SSS2.p2.8.m8.1.1.1" xref="S4.SS4.SSS2.p2.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.8.m8.1b"><apply id="S4.SS4.SSS2.p2.8.m8.1.1.cmml" xref="S4.SS4.SSS2.p2.8.m8.1.1"><csymbol cd="latexml" id="S4.SS4.SSS2.p2.8.m8.1.1.1.cmml" xref="S4.SS4.SSS2.p2.8.m8.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.SSS2.p2.8.m8.1.1.2.cmml" xref="S4.SS4.SSS2.p2.8.m8.1.1.2">6.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.8.m8.1c">6.8\%</annotation></semantics></math>, which shows that our PONet can work rather well even when both the size and the center of bounding boxes have an average error of <math id="S4.SS4.SSS2.p2.9.m9.1" class="ltx_Math" alttext="51.2" display="inline"><semantics id="S4.SS4.SSS2.p2.9.m9.1a"><mn id="S4.SS4.SSS2.p2.9.m9.1.1" xref="S4.SS4.SSS2.p2.9.m9.1.1.cmml">51.2</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS2.p2.9.m9.1b"><cn type="float" id="S4.SS4.SSS2.p2.9.m9.1.1.cmml" xref="S4.SS4.SSS2.p2.9.m9.1.1">51.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS2.p2.9.m9.1c">51.2</annotation></semantics></math> pixels.
The experiments demonstrate that our method does not rely on accurate bound boxes.
This implies that in practical applications, we can use a person detector to obtain a rough bounding box to crop the image, without losing much accuracy in the performance of 3D human pose estimation.</p>
</div>
</section>
<section id="S4.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS3.4.1.1" class="ltx_text">IV-D</span>3 </span>Results on Human3.6M on incomplete images</h4>

<div id="S4.SS4.SSS3.p1" class="ltx_para">
<p id="S4.SS4.SSS3.p1.1" class="ltx_p">Human3.6M is captured in monitored laboratory environment with precise bounding boxes and little noise.
In practical applications, occlusion and truncation frequently occur in testing images.
To find out the performance of 3D pose estimation in these challenging cases, itâ€™s not enough to only evaluate in ideal settings.
To this end, we introduce three kinds of synthetic disturbance, including random object occlusion, random translation and random erasing to the testing images and evaluate the robustness of the proposed method on these images and compare it with several state-of-the-art keypoint-detection-based methods.
To reduce the impact of random number generator, we independently repeat each experiment for 5 times, and report the average results in Tab.Â <a href="#S4.T3" title="TABLE III â€£ IV-D3 Results on Human3.6M on incomplete images â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:139.9pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-7.9pt,2.5pt) scale(0.964684683706044,0.964684683706044) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">MethodÂ (Authors)</span></td>
<td id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S4.T3.1.1.1.1.2.1" class="ltx_text ltx_font_bold">None</span></td>
<td id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" rowspan="2"><span id="S4.T3.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Occl.</span></td>
<td id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="2"><span id="S4.T3.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Translation</span></td>
<td id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;" colspan="3"><span id="S4.T3.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Erasing</span></td>
</tr>
<tr id="S4.T3.1.1.2.2" class="ltx_tr">
<td id="S4.T3.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">25%</td>
<td id="S4.T3.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">40%</td>
<td id="S4.T3.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Rect.</td>
<td id="S4.T3.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Circle</td>
<td id="S4.T3.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Edge</td>
</tr>
<tr id="S4.T3.1.1.3.3" class="ltx_tr">
<td id="S4.T3.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">MartinezÂ <em id="S4.T3.1.1.3.3.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>
</td>
<td id="S4.T3.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">62.9</td>
<td id="S4.T3.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">88.8</td>
<td id="S4.T3.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">121.2</td>
<td id="S4.T3.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">261.7</td>
<td id="S4.T3.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">112.7</td>
<td id="S4.T3.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">87.6</td>
<td id="S4.T3.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">115.5</td>
</tr>
<tr id="S4.T3.1.1.4.4" class="ltx_tr">
<td id="S4.T3.1.1.4.4.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">ZhouÂ <em id="S4.T3.1.1.4.4.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T3.1.1.4.4.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">64.9</td>
<td id="S4.T3.1.1.4.4.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">90.0</td>
<td id="S4.T3.1.1.4.4.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">183.9</td>
<td id="S4.T3.1.1.4.4.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">303.2</td>
<td id="S4.T3.1.1.4.4.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">109.6</td>
<td id="S4.T3.1.1.4.4.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">81.6</td>
<td id="S4.T3.1.1.4.4.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">117.5</td>
</tr>
<tr id="S4.T3.1.1.5.5" class="ltx_tr">
<td id="S4.T3.1.1.5.5.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">WangÂ <em id="S4.T3.1.1.5.5.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="S4.T3.1.1.5.5.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">52.6</td>
<td id="S4.T3.1.1.5.5.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">88.6</td>
<td id="S4.T3.1.1.5.5.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">115.3</td>
<td id="S4.T3.1.1.5.5.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">277.9</td>
<td id="S4.T3.1.1.5.5.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">108.1</td>
<td id="S4.T3.1.1.5.5.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">81.1</td>
<td id="S4.T3.1.1.5.5.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">109.3</td>
</tr>
<tr id="S4.T3.1.1.6.6" class="ltx_tr">
<td id="S4.T3.1.1.6.6.1" class="ltx_td ltx_align_left" style="padding-left:2.0pt;padding-right:2.0pt;">LiÂ <em id="S4.T3.1.1.6.6.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T3.1.1.6.6.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.6.6.2.1" class="ltx_text ltx_font_bold">50.9</span></td>
<td id="S4.T3.1.1.6.6.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">96.7</td>
<td id="S4.T3.1.1.6.6.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">107.6</td>
<td id="S4.T3.1.1.6.6.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">248.6</td>
<td id="S4.T3.1.1.6.6.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">148.3</td>
<td id="S4.T3.1.1.6.6.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">108.5</td>
<td id="S4.T3.1.1.6.6.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">114.9</td>
</tr>
<tr id="S4.T3.1.1.7.7" class="ltx_tr">
<td id="S4.T3.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Ours before PC</td>
<td id="S4.T3.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">56.2</td>
<td id="S4.T3.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">66.5</td>
<td id="S4.T3.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">60.5</td>
<td id="S4.T3.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">82.0</td>
<td id="S4.T3.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">67.5</td>
<td id="S4.T3.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">60.2</td>
<td id="S4.T3.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">71.4</td>
</tr>
<tr id="S4.T3.1.1.8.8" class="ltx_tr">
<td id="S4.T3.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">Ours after PC</td>
<td id="S4.T3.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;">56.1</td>
<td id="S4.T3.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.8.8.3.1" class="ltx_text ltx_font_bold">65.6</span></td>
<td id="S4.T3.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.8.8.4.1" class="ltx_text ltx_font_bold">60.3</span></td>
<td id="S4.T3.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.8.8.5.1" class="ltx_text ltx_font_bold">68.3</span></td>
<td id="S4.T3.1.1.8.8.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.8.8.6.1" class="ltx_text ltx_font_bold">66.2</span></td>
<td id="S4.T3.1.1.8.8.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.8.8.7.1" class="ltx_text ltx_font_bold">59.8</span></td>
<td id="S4.T3.1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S4.T3.1.1.8.8.8.1" class="ltx_text ltx_font_bold">68.9</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Comparison with state-of-the-art keypoint-detection-based methods on images from Human3.6M with missing joints or limbs in terms of MPJPE. PC denotes pose complementation.
</figcaption>
</figure>
<div id="S4.SS4.SSS3.p2" class="ltx_para">
<p id="S4.SS4.SSS3.p2.5" class="ltx_p">All the methods across Tab.Â <a href="#S4.T3" title="TABLE III â€£ IV-D3 Results on Human3.6M on incomplete images â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> show to have certain robustness to synthetic object occlusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, but our method proves to be more robust in this testing case.
In terms of translation, our method turn out to have much better robustness than the other ones.
While other methods already more than double their errors under <math id="S4.SS4.SSS3.p2.1.m1.1" class="ltx_Math" alttext="25\%" display="inline"><semantics id="S4.SS4.SSS3.p2.1.m1.1a"><mrow id="S4.SS4.SSS3.p2.1.m1.1.1" xref="S4.SS4.SSS3.p2.1.m1.1.1.cmml"><mn id="S4.SS4.SSS3.p2.1.m1.1.1.2" xref="S4.SS4.SSS3.p2.1.m1.1.1.2.cmml">25</mn><mo id="S4.SS4.SSS3.p2.1.m1.1.1.1" xref="S4.SS4.SSS3.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p2.1.m1.1b"><apply id="S4.SS4.SSS3.p2.1.m1.1.1.cmml" xref="S4.SS4.SSS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.SSS3.p2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS3.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.SSS3.p2.1.m1.1.1.2.cmml" xref="S4.SS4.SSS3.p2.1.m1.1.1.2">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p2.1.m1.1c">25\%</annotation></semantics></math> translation, our MPJPE only increases <math id="S4.SS4.SSS3.p2.2.m2.1" class="ltx_Math" alttext="7.5\%" display="inline"><semantics id="S4.SS4.SSS3.p2.2.m2.1a"><mrow id="S4.SS4.SSS3.p2.2.m2.1.1" xref="S4.SS4.SSS3.p2.2.m2.1.1.cmml"><mn id="S4.SS4.SSS3.p2.2.m2.1.1.2" xref="S4.SS4.SSS3.p2.2.m2.1.1.2.cmml">7.5</mn><mo id="S4.SS4.SSS3.p2.2.m2.1.1.1" xref="S4.SS4.SSS3.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p2.2.m2.1b"><apply id="S4.SS4.SSS3.p2.2.m2.1.1.cmml" xref="S4.SS4.SSS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.SSS3.p2.2.m2.1.1.1.cmml" xref="S4.SS4.SSS3.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.SSS3.p2.2.m2.1.1.2.cmml" xref="S4.SS4.SSS3.p2.2.m2.1.1.2">7.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p2.2.m2.1c">7.5\%</annotation></semantics></math>.
Under <math id="S4.SS4.SSS3.p2.3.m3.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S4.SS4.SSS3.p2.3.m3.1a"><mrow id="S4.SS4.SSS3.p2.3.m3.1.1" xref="S4.SS4.SSS3.p2.3.m3.1.1.cmml"><mn id="S4.SS4.SSS3.p2.3.m3.1.1.2" xref="S4.SS4.SSS3.p2.3.m3.1.1.2.cmml">40</mn><mo id="S4.SS4.SSS3.p2.3.m3.1.1.1" xref="S4.SS4.SSS3.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p2.3.m3.1b"><apply id="S4.SS4.SSS3.p2.3.m3.1.1.cmml" xref="S4.SS4.SSS3.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.SSS3.p2.3.m3.1.1.1.cmml" xref="S4.SS4.SSS3.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.SSS3.p2.3.m3.1.1.2.cmml" xref="S4.SS4.SSS3.p2.3.m3.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p2.3.m3.1c">40\%</annotation></semantics></math> translation, the other methodsâ€™ MPJPEs sharply increase to more than <math id="S4.SS4.SSS3.p2.4.m4.1" class="ltx_Math" alttext="240" display="inline"><semantics id="S4.SS4.SSS3.p2.4.m4.1a"><mn id="S4.SS4.SSS3.p2.4.m4.1.1" xref="S4.SS4.SSS3.p2.4.m4.1.1.cmml">240</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p2.4.m4.1b"><cn type="integer" id="S4.SS4.SSS3.p2.4.m4.1.1.cmml" xref="S4.SS4.SSS3.p2.4.m4.1.1">240</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p2.4.m4.1c">240</annotation></semantics></math>mm.
By contrast, our result after pose complementation remains smaller than <math id="S4.SS4.SSS3.p2.5.m5.1" class="ltx_Math" alttext="69" display="inline"><semantics id="S4.SS4.SSS3.p2.5.m5.1a"><mn id="S4.SS4.SSS3.p2.5.m5.1.1" xref="S4.SS4.SSS3.p2.5.m5.1.1.cmml">69</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS3.p2.5.m5.1b"><cn type="integer" id="S4.SS4.SSS3.p2.5.m5.1.1.cmml" xref="S4.SS4.SSS3.p2.5.m5.1.1">69</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS3.p2.5.m5.1c">69</annotation></semantics></math>mm,
demonstrating the outstanding robustness of our PONet on truncated images.
We also randomly erasing a rectangle, circle or a certain edge on the input image to simulate keypoint and limb absent cases. Again our method outperforms the other ones, although we did not use data augmentation of erasing in training.
In summary, although our method does not achieve the best score in ideal settings, it performs much better on incomplete images including occlusion, translation and erasing.</p>
</div>
<div id="S4.SS4.SSS3.p3" class="ltx_para">
<p id="S4.SS4.SSS3.p3.1" class="ltx_p">There are four reasons why our method performs significantly better on images with missing joints or limbs.
Firstly, our method does not detect the only intermittently visible body keypoints, but learn to estimate the limb orientation using a region-based representation.
This pure orientation-based design allows us to estimate the 3D pose even when some limbs are partially invisible.
Secondly, through pose complementation, our method can output a full-body pose estimation even if some limbs are completely out-of-image.
Thirdly, we embed a fixed-length skeleton-shaped human model into the network so that the pose estimation will always satisfy anthropometric constrains such as limb ratios.
Lastly, the 3D limb orientations are voted by all the pixels in the estimated orientation maps weighted with the corresponding confidence. This voting scheme can suppress the noise and outliers in the estimated 3D orientation maps, making the 3D orientation estimation and thus 3D pose estimation more robust and stable.</p>
</div>
</section>
<section id="S4.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS4.4.1.1" class="ltx_text">IV-D</span>4 </span>Comparison with SMPL-based methods</h4>

<div id="S4.SS4.SSS4.p1" class="ltx_para">
<p id="S4.SS4.SSS4.p1.1" class="ltx_p">We compare with these SMPL-based methods because they also introduce anthropometric constraints to the estimated 3D poses.
First, we compare our method with them on Human3.6M in regular settings.
The second column of Tab.Â <a href="#S4.T4" title="TABLE IV â€£ IV-D4 Comparison with SMPL-based methods â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> shows the PA-MPJPE of our method and some recent ones
Our method outperforms all the other approaches.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:159.2pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-5.2pt,1.9pt) scale(0.976512575944806,0.976512575944806) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">MethodÂ (Authors)</span></th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T4.1.1.1.1.2.1" class="ltx_text ltx_font_bold">H3.6M</span></th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.1.1.1.1.3.1" class="ltx_text ltx_font_bold">H3.6M</span></th>
<th id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S4.T4.1.1.1.1.4.1" class="ltx_text ltx_font_bold">3DPW</span></th>
</tr>
<tr id="S4.T4.1.1.2.2" class="ltx_tr">
<th id="S4.T4.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T4.1.1.2.2.1.1" class="ltx_text ltx_font_bold">(Occlusion)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.3.1" class="ltx_tr">
<td id="S4.T4.1.1.3.1.1" class="ltx_td ltx_align_left ltx_border_t">BogoÂ <em id="S4.T4.1.1.3.1.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S4.T4.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t">82.3</td>
<td id="S4.T4.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">159.4</td>
<td id="S4.T4.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">114.0</td>
</tr>
<tr id="S4.T4.1.1.4.2" class="ltx_tr">
<td id="S4.T4.1.1.4.2.1" class="ltx_td ltx_align_left">PavlakosÂ <em id="S4.T4.1.1.4.2.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</td>
<td id="S4.T4.1.1.4.2.2" class="ltx_td ltx_align_center">-</td>
<td id="S4.T4.1.1.4.2.3" class="ltx_td ltx_align_center">145.6</td>
<td id="S4.T4.1.1.4.2.4" class="ltx_td ltx_align_center">151.3</td>
</tr>
<tr id="S4.T4.1.1.5.3" class="ltx_tr">
<td id="S4.T4.1.1.5.3.1" class="ltx_td ltx_align_left">KanazawaÂ <em id="S4.T4.1.1.5.3.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</td>
<td id="S4.T4.1.1.5.3.2" class="ltx_td ltx_align_center">56.8</td>
<td id="S4.T4.1.1.5.3.3" class="ltx_td ltx_align_center">82.2</td>
<td id="S4.T4.1.1.5.3.4" class="ltx_td ltx_align_center">103.8</td>
</tr>
<tr id="S4.T4.1.1.6.4" class="ltx_tr">
<td id="S4.T4.1.1.6.4.1" class="ltx_td ltx_align_left">KolotourosÂ <em id="S4.T4.1.1.6.4.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S4.T4.1.1.6.4.2" class="ltx_td ltx_align_center">50.1</td>
<td id="S4.T4.1.1.6.4.3" class="ltx_td ltx_align_center">74.4</td>
<td id="S4.T4.1.1.6.4.4" class="ltx_td ltx_align_center">104.8</td>
</tr>
<tr id="S4.T4.1.1.7.5" class="ltx_tr">
<td id="S4.T4.1.1.7.5.1" class="ltx_td ltx_align_left">KolotourosÂ <em id="S4.T4.1.1.7.5.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S4.T4.1.1.7.5.2" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.7.5.2.1" class="ltx_text ltx_framed ltx_framed_underline">41.1</span></td>
<td id="S4.T4.1.1.7.5.3" class="ltx_td ltx_align_center">64.9</td>
<td id="S4.T4.1.1.7.5.4" class="ltx_td ltx_align_center">95.4</td>
</tr>
<tr id="S4.T4.1.1.8.6" class="ltx_tr">
<td id="S4.T4.1.1.8.6.1" class="ltx_td ltx_align_left">ZhangÂ <em id="S4.T4.1.1.8.6.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</td>
<td id="S4.T4.1.1.8.6.2" class="ltx_td ltx_align_center">41.7</td>
<td id="S4.T4.1.1.8.6.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.8.6.3.1" class="ltx_text ltx_framed ltx_framed_underline">56.4</span></td>
<td id="S4.T4.1.1.8.6.4" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.8.6.4.1" class="ltx_text ltx_font_bold">72.2</span></td>
</tr>
<tr id="S4.T4.1.1.9.7" class="ltx_tr">
<td id="S4.T4.1.1.9.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Ours</td>
<td id="S4.T4.1.1.9.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T4.1.1.9.7.2.1" class="ltx_text ltx_font_bold">39.8</span></td>
<td id="S4.T4.1.1.9.7.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T4.1.1.9.7.3.1" class="ltx_text ltx_font_bold">47.6</span></td>
<td id="S4.T4.1.1.9.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T4.1.1.9.7.4.1" class="ltx_text ltx_framed ltx_framed_underline">76.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Comparison with state-of-the-art SMPL-based methods on Human3.6M and 3DPW in terms of PA-MPJPE. The best results are marked in bold and second best ones are underlined. No data from 3DPW are used to train our model.</figcaption>
</figure>
<div id="S4.SS4.SSS4.p2" class="ltx_para">
<p id="S4.SS4.SSS4.p2.1" class="ltx_p">We also compare our method on datasets with occlusion.
The third column of Tab.Â <a href="#S4.T4" title="TABLE IV â€£ IV-D4 Comparison with SMPL-based methods â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> reports results on Human3.6M with synthetic occlusions.
Our method, again, outperforms all the other methods including a very recent workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> that specially designed for pose estimation on object-occluded images.
We show the performance on 3DPW in the last column of Tab.Â <a href="#S4.T4" title="TABLE IV â€£ IV-D4 Comparison with SMPL-based methods â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.
Our method achieves the second best performance on this dataset without training on it.</p>
</div>
<div id="S4.SS4.SSS4.p3" class="ltx_para">
<p id="S4.SS4.SSS4.p3.1" class="ltx_p">In summary, our PONet performs better in both the original and occluded datasets, demonstrating the superiority of the proposed method over the others in terms of the accuracy of 3D joint location prediction and robustness.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:250.9pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.8pt,1.0pt) scale(0.991774971168338,0.991774971168338) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">MethodÂ (Authors)</span></td>
<td id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.1.1.1.1.2.1" class="ltx_text ltx_font_bold">CE?</span></td>
<td id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.1.1.1.1.3.1" class="ltx_text ltx_font_bold">PCK</span></td>
<td id="S4.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.1.1.1.1.4.1" class="ltx_text ltx_font_bold">AUC</span></td>
<td id="S4.T5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.1.1.1.1.5.1" class="ltx_text ltx_font_bold">MPJPE</span></td>
</tr>
<tr id="S4.T5.1.1.2.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t">MehtaÂ <em id="S4.T5.1.1.2.2.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T5.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">N</td>
<td id="S4.T5.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">75.7</td>
<td id="S4.T5.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">39.3</td>
<td id="S4.T5.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">117.6</td>
</tr>
<tr id="S4.T5.1.1.3.3" class="ltx_tr">
<td id="S4.T5.1.1.3.3.1" class="ltx_td ltx_align_left">MehtaÂ <em id="S4.T5.1.1.3.3.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S4.T5.1.1.3.3.2" class="ltx_td ltx_align_center">N</td>
<td id="S4.T5.1.1.3.3.3" class="ltx_td ltx_align_center">76.6</td>
<td id="S4.T5.1.1.3.3.4" class="ltx_td ltx_align_center">40.4</td>
<td id="S4.T5.1.1.3.3.5" class="ltx_td ltx_align_center">124.7</td>
</tr>
<tr id="S4.T5.1.1.4.4" class="ltx_tr">
<td id="S4.T5.1.1.4.4.1" class="ltx_td ltx_align_left">HabibieÂ <em id="S4.T5.1.1.4.4.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S4.T5.1.1.4.4.2" class="ltx_td ltx_align_center">N</td>
<td id="S4.T5.1.1.4.4.3" class="ltx_td ltx_align_center">81.5</td>
<td id="S4.T5.1.1.4.4.4" class="ltx_td ltx_align_center">44.5</td>
<td id="S4.T5.1.1.4.4.5" class="ltx_td ltx_align_center">90.7</td>
</tr>
<tr id="S4.T5.1.1.5.5" class="ltx_tr">
<td id="S4.T5.1.1.5.5.1" class="ltx_td ltx_align_left">LuoÂ <em id="S4.T5.1.1.5.5.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T5.1.1.5.5.2" class="ltx_td ltx_align_center">N</td>
<td id="S4.T5.1.1.5.5.3" class="ltx_td ltx_align_center">81.8</td>
<td id="S4.T5.1.1.5.5.4" class="ltx_td ltx_align_center">45.2</td>
<td id="S4.T5.1.1.5.5.5" class="ltx_td ltx_align_center">89.4</td>
</tr>
<tr id="S4.T5.1.1.6.6" class="ltx_tr">
<td id="S4.T5.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_t">LuoÂ <em id="S4.T5.1.1.6.6.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T5.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t">Y</td>
<td id="S4.T5.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t">64.6</td>
<td id="S4.T5.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_t">32.1</td>
<td id="S4.T5.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t">â€“</td>
</tr>
<tr id="S4.T5.1.1.7.7" class="ltx_tr">
<td id="S4.T5.1.1.7.7.1" class="ltx_td ltx_align_left">YangÂ <em id="S4.T5.1.1.7.7.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>
</td>
<td id="S4.T5.1.1.7.7.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.7.7.3" class="ltx_td ltx_align_center">69.0</td>
<td id="S4.T5.1.1.7.7.4" class="ltx_td ltx_align_center">32.0</td>
<td id="S4.T5.1.1.7.7.5" class="ltx_td ltx_align_center">â€“</td>
</tr>
<tr id="S4.T5.1.1.8.8" class="ltx_tr">
<td id="S4.T5.1.1.8.8.1" class="ltx_td ltx_align_left">ZhouÂ <em id="S4.T5.1.1.8.8.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T5.1.1.8.8.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.8.8.3" class="ltx_td ltx_align_center">69.2</td>
<td id="S4.T5.1.1.8.8.4" class="ltx_td ltx_align_center">32.5</td>
<td id="S4.T5.1.1.8.8.5" class="ltx_td ltx_align_center">137.1</td>
</tr>
<tr id="S4.T5.1.1.9.9" class="ltx_tr">
<td id="S4.T5.1.1.9.9.1" class="ltx_td ltx_align_left">HabibieÂ <em id="S4.T5.1.1.9.9.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S4.T5.1.1.9.9.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.9.9.3" class="ltx_td ltx_align_center">69.6</td>
<td id="S4.T5.1.1.9.9.4" class="ltx_td ltx_align_center">35.5</td>
<td id="S4.T5.1.1.9.9.5" class="ltx_td ltx_align_center">127.0</td>
</tr>
<tr id="S4.T5.1.1.10.10" class="ltx_tr">
<td id="S4.T5.1.1.10.10.1" class="ltx_td ltx_align_left">PavlakosÂ <em id="S4.T5.1.1.10.10.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="S4.T5.1.1.10.10.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.10.10.3" class="ltx_td ltx_align_center">71.9</td>
<td id="S4.T5.1.1.10.10.4" class="ltx_td ltx_align_center">35.3</td>
<td id="S4.T5.1.1.10.10.5" class="ltx_td ltx_align_center">â€“</td>
</tr>
<tr id="S4.T5.1.1.11.11" class="ltx_tr">
<td id="S4.T5.1.1.11.11.1" class="ltx_td ltx_align_left">WangÂ <em id="S4.T5.1.1.11.11.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="S4.T5.1.1.11.11.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.11.11.3" class="ltx_td ltx_align_center">71.9</td>
<td id="S4.T5.1.1.11.11.4" class="ltx_td ltx_align_center">35.8</td>
<td id="S4.T5.1.1.11.11.5" class="ltx_td ltx_align_center">â€“</td>
</tr>
<tr id="S4.T5.1.1.12.12" class="ltx_tr">
<td id="S4.T5.1.1.12.12.1" class="ltx_td ltx_align_left">KanazawaÂ <em id="S4.T5.1.1.12.12.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</td>
<td id="S4.T5.1.1.12.12.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.12.12.3" class="ltx_td ltx_align_center">72.9</td>
<td id="S4.T5.1.1.12.12.4" class="ltx_td ltx_align_center">36.5</td>
<td id="S4.T5.1.1.12.12.5" class="ltx_td ltx_align_center">124.2</td>
</tr>
<tr id="S4.T5.1.1.13.13" class="ltx_tr">
<td id="S4.T5.1.1.13.13.1" class="ltx_td ltx_align_left">LiÂ <em id="S4.T5.1.1.13.13.1.1" class="ltx_emph ltx_font_italic">et al</em>let@tokeneonedotÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T5.1.1.13.13.2" class="ltx_td ltx_align_center">Y</td>
<td id="S4.T5.1.1.13.13.3" class="ltx_td ltx_align_center">81.2</td>
<td id="S4.T5.1.1.13.13.4" class="ltx_td ltx_align_center">46.1</td>
<td id="S4.T5.1.1.13.13.5" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.13.13.5.1" class="ltx_text ltx_font_bold">99.7</span></td>
</tr>
<tr id="S4.T5.1.1.14.14" class="ltx_tr">
<td id="S4.T5.1.1.14.14.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Ours</td>
<td id="S4.T5.1.1.14.14.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Y</td>
<td id="S4.T5.1.1.14.14.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.1.1.14.14.3.1" class="ltx_text ltx_font_bold">76.1</span></td>
<td id="S4.T5.1.1.14.14.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T5.1.1.14.14.4.1" class="ltx_text ltx_font_bold">40.6</span></td>
<td id="S4.T5.1.1.14.14.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">115.0</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Results on MPI-INF-3DHP dataset.
For PCK and AUC, higher is better; For MPJPE, lower is better. MPJPE is evaluated without Procrustes alignment.
CE denotes cross-dataset evaluation without training on this dataset.</figcaption>
</figure>
</section>
<section id="S4.SS4.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS5.4.1.1" class="ltx_text">IV-D</span>5 </span>Evaluation of cross-dataset generalization</h4>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2112.11153/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="170" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative results on MPIIÂ (first two rows) and 3DPWÂ (last row) and comparison with <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. PC denotes <em id="S4.F5.2.1" class="ltx_emph ltx_font_italic">pose complementation</em>. Our method is robust to joint absenceÂ (first row), limb absenceÂ (second row) and occlusionÂ (last row).</figcaption>
</figure>
<div id="S4.SS4.SSS5.p1" class="ltx_para">
<p id="S4.SS4.SSS5.p1.1" class="ltx_p">To quantitatively show the generalization on unseen images, we compare with other methods on MPI-INF-3DHP without using any data from this dataset for training.
In addition to MPJPE, we report Percentage of Correct KeypointsÂ (PCK) thresholded at 150mm and Area Under the CurveÂ (AUC) over a range of PCK thresholds.</p>
</div>
<div id="S4.SS4.SSS5.p2" class="ltx_para">
<p id="S4.SS4.SSS5.p2.1" class="ltx_p">The results are shown in Tab.Â <a href="#S4.T5" title="TABLE V â€£ IV-D4 Comparison with SMPL-based methods â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. Our method outperforms state-of-the-art methods by a large margin without training on this dataset, demonstrating our methodâ€™s excellent generalization to unseen images.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.4.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.5.2" class="ltx_text ltx_font_italic">Qualitative results</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">In this section, we qualitatively compare our method with state-of-the-art methods on MPII and 3DPW.
In Fig.Â <a href="#S4.F5" title="Figure 5 â€£ IV-D5 Evaluation of cross-dataset generalization â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we show six examples with invisible parts and compare with two approaches that based on 2D keypoint detection, SimpleBaselineÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> and a very recent work EvoSkeletonÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
SimpleBaseline uses <em id="S4.SS5.p1.1.1" class="ltx_emph ltx_font_italic">StackedHourglass</em>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> to detect 2D poses, while EveSkeleton uses a better 2D pose estimator <em id="S4.SS5.p1.1.2" class="ltx_emph ltx_font_italic">HRNet</em>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and achieved state-of-the-art results on Human3.6M in regular settings.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">The first row of Fig.Â <a href="#S4.F5" title="Figure 5 â€£ IV-D5 Evaluation of cross-dataset generalization â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows two cases from MPII with only a single out-of-image joint. Neither of SimpleBaseline and EvoSkeleton can correctly predict the 3D location of the missing joint, while our method provides visually appealing results even without pose complementation.
The second row of Fig.Â <a href="#S4.F5" title="Figure 5 â€£ IV-D5 Evaluation of cross-dataset generalization â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows two cases with invisible limbs.
The performance of the two keypoint-detection-based methods drops drastically, compared to single joint absent cases.
By contrast, our method can correctly estimate the configuration of the visible parts, and provide a reasonable full-body pose estimation after pose complementation.
The third row of Fig.Â <a href="#S4.F5" title="Figure 5 â€£ IV-D5 Evaluation of cross-dataset generalization â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows two occluded images.
Again, our method performs better in these cases as well.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS6.4.1.1" class="ltx_text">IV-F</span> </span><span id="S4.SS6.5.2" class="ltx_text ltx_font_italic">Failure cases</span>
</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">In Fig.Â <a href="#S4.F6" title="Figure 6 â€£ IV-F Failure cases â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we provide 4 typical failure cases.
The first two rows of Fig.Â <a href="#S4.F6" title="Figure 6 â€£ IV-F Failure cases â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> show
two failure cases in limb region estimation in multi-person scenarios.
The third row of Fig.Â <a href="#S4.F6" title="Figure 6 â€£ IV-F Failure cases â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> is a false positive case on clothes.
The last row of Fig.Â <a href="#S4.F6" title="Figure 6 â€£ IV-F Failure cases â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows an example
that the right half of the body is truncated so
that the network gets confused about the left and right side of the body.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2112.11153/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Failure Cases.</figcaption>
</figure>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS7.4.1.1" class="ltx_text">IV-G</span> </span><span id="S4.SS7.5.2" class="ltx_text ltx_font_italic">Ablation study</span>
</h3>

<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.5" class="ltx_p">To analyze the effectiveness of each component in our method, we conduct ablation study on Human3.6M in both regular setting and translation up to <math id="S4.SS7.p1.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S4.SS7.p1.1.m1.1a"><mrow id="S4.SS7.p1.1.m1.1.1" xref="S4.SS7.p1.1.m1.1.1.cmml"><mn id="S4.SS7.p1.1.m1.1.1.2" xref="S4.SS7.p1.1.m1.1.1.2.cmml">40</mn><mo id="S4.SS7.p1.1.m1.1.1.1" xref="S4.SS7.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p1.1.m1.1b"><apply id="S4.SS7.p1.1.m1.1.1.cmml" xref="S4.SS7.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS7.p1.1.m1.1.1.1.cmml" xref="S4.SS7.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS7.p1.1.m1.1.1.2.cmml" xref="S4.SS7.p1.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p1.1.m1.1c">40\%</annotation></semantics></math> of the image size.
In Tab.Â <a href="#S4.T6" title="TABLE VI â€£ IV-G Ablation study â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>, <em id="S4.SS7.p1.5.1" class="ltx_emph ltx_font_italic">Baseline</em> refers to model trained with <math id="S4.SS7.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{CM}" display="inline"><semantics id="S4.SS7.p1.2.m2.1a"><msub id="S4.SS7.p1.2.m2.1.1" xref="S4.SS7.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS7.p1.2.m2.1.1.2" xref="S4.SS7.p1.2.m2.1.1.2.cmml">â„’</mi><mrow id="S4.SS7.p1.2.m2.1.1.3" xref="S4.SS7.p1.2.m2.1.1.3.cmml"><mi id="S4.SS7.p1.2.m2.1.1.3.2" xref="S4.SS7.p1.2.m2.1.1.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.SS7.p1.2.m2.1.1.3.1" xref="S4.SS7.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS7.p1.2.m2.1.1.3.3" xref="S4.SS7.p1.2.m2.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.p1.2.m2.1b"><apply id="S4.SS7.p1.2.m2.1.1.cmml" xref="S4.SS7.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS7.p1.2.m2.1.1.1.cmml" xref="S4.SS7.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS7.p1.2.m2.1.1.2.cmml" xref="S4.SS7.p1.2.m2.1.1.2">â„’</ci><apply id="S4.SS7.p1.2.m2.1.1.3.cmml" xref="S4.SS7.p1.2.m2.1.1.3"><times id="S4.SS7.p1.2.m2.1.1.3.1.cmml" xref="S4.SS7.p1.2.m2.1.1.3.1"></times><ci id="S4.SS7.p1.2.m2.1.1.3.2.cmml" xref="S4.SS7.p1.2.m2.1.1.3.2">ğ¶</ci><ci id="S4.SS7.p1.2.m2.1.1.3.3.cmml" xref="S4.SS7.p1.2.m2.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p1.2.m2.1c">\mathcal{L}_{CM}</annotation></semantics></math>, <math id="S4.SS7.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{OM2D}" display="inline"><semantics id="S4.SS7.p1.3.m3.1a"><msub id="S4.SS7.p1.3.m3.1.1" xref="S4.SS7.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS7.p1.3.m3.1.1.2" xref="S4.SS7.p1.3.m3.1.1.2.cmml">â„’</mi><mrow id="S4.SS7.p1.3.m3.1.1.3" xref="S4.SS7.p1.3.m3.1.1.3.cmml"><mi id="S4.SS7.p1.3.m3.1.1.3.2" xref="S4.SS7.p1.3.m3.1.1.3.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS7.p1.3.m3.1.1.3.1" xref="S4.SS7.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS7.p1.3.m3.1.1.3.3" xref="S4.SS7.p1.3.m3.1.1.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.SS7.p1.3.m3.1.1.3.1a" xref="S4.SS7.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mn id="S4.SS7.p1.3.m3.1.1.3.4" xref="S4.SS7.p1.3.m3.1.1.3.4.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS7.p1.3.m3.1.1.3.1b" xref="S4.SS7.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS7.p1.3.m3.1.1.3.5" xref="S4.SS7.p1.3.m3.1.1.3.5.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.p1.3.m3.1b"><apply id="S4.SS7.p1.3.m3.1.1.cmml" xref="S4.SS7.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS7.p1.3.m3.1.1.1.cmml" xref="S4.SS7.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS7.p1.3.m3.1.1.2.cmml" xref="S4.SS7.p1.3.m3.1.1.2">â„’</ci><apply id="S4.SS7.p1.3.m3.1.1.3.cmml" xref="S4.SS7.p1.3.m3.1.1.3"><times id="S4.SS7.p1.3.m3.1.1.3.1.cmml" xref="S4.SS7.p1.3.m3.1.1.3.1"></times><ci id="S4.SS7.p1.3.m3.1.1.3.2.cmml" xref="S4.SS7.p1.3.m3.1.1.3.2">ğ‘‚</ci><ci id="S4.SS7.p1.3.m3.1.1.3.3.cmml" xref="S4.SS7.p1.3.m3.1.1.3.3">ğ‘€</ci><cn type="integer" id="S4.SS7.p1.3.m3.1.1.3.4.cmml" xref="S4.SS7.p1.3.m3.1.1.3.4">2</cn><ci id="S4.SS7.p1.3.m3.1.1.3.5.cmml" xref="S4.SS7.p1.3.m3.1.1.3.5">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p1.3.m3.1c">\mathcal{L}_{OM2D}</annotation></semantics></math> and <math id="S4.SS7.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{L}_{OM3D}" display="inline"><semantics id="S4.SS7.p1.4.m4.1a"><msub id="S4.SS7.p1.4.m4.1.1" xref="S4.SS7.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS7.p1.4.m4.1.1.2" xref="S4.SS7.p1.4.m4.1.1.2.cmml">â„’</mi><mrow id="S4.SS7.p1.4.m4.1.1.3" xref="S4.SS7.p1.4.m4.1.1.3.cmml"><mi id="S4.SS7.p1.4.m4.1.1.3.2" xref="S4.SS7.p1.4.m4.1.1.3.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S4.SS7.p1.4.m4.1.1.3.1" xref="S4.SS7.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS7.p1.4.m4.1.1.3.3" xref="S4.SS7.p1.4.m4.1.1.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.SS7.p1.4.m4.1.1.3.1a" xref="S4.SS7.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mn id="S4.SS7.p1.4.m4.1.1.3.4" xref="S4.SS7.p1.4.m4.1.1.3.4.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.SS7.p1.4.m4.1.1.3.1b" xref="S4.SS7.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS7.p1.4.m4.1.1.3.5" xref="S4.SS7.p1.4.m4.1.1.3.5.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.p1.4.m4.1b"><apply id="S4.SS7.p1.4.m4.1.1.cmml" xref="S4.SS7.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS7.p1.4.m4.1.1.1.cmml" xref="S4.SS7.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS7.p1.4.m4.1.1.2.cmml" xref="S4.SS7.p1.4.m4.1.1.2">â„’</ci><apply id="S4.SS7.p1.4.m4.1.1.3.cmml" xref="S4.SS7.p1.4.m4.1.1.3"><times id="S4.SS7.p1.4.m4.1.1.3.1.cmml" xref="S4.SS7.p1.4.m4.1.1.3.1"></times><ci id="S4.SS7.p1.4.m4.1.1.3.2.cmml" xref="S4.SS7.p1.4.m4.1.1.3.2">ğ‘‚</ci><ci id="S4.SS7.p1.4.m4.1.1.3.3.cmml" xref="S4.SS7.p1.4.m4.1.1.3.3">ğ‘€</ci><cn type="integer" id="S4.SS7.p1.4.m4.1.1.3.4.cmml" xref="S4.SS7.p1.4.m4.1.1.3.4">3</cn><ci id="S4.SS7.p1.4.m4.1.1.3.5.cmml" xref="S4.SS7.p1.4.m4.1.1.3.5">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p1.4.m4.1c">\mathcal{L}_{OM3D}</annotation></semantics></math>.
<em id="S4.SS7.p1.5.2" class="ltx_emph ltx_font_italic">Aug.</em> refers to using the data augmentation of synthetic occlusion and <math id="S4.SS7.p1.5.m5.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S4.SS7.p1.5.m5.1a"><mrow id="S4.SS7.p1.5.m5.1.1" xref="S4.SS7.p1.5.m5.1.1.cmml"><mn id="S4.SS7.p1.5.m5.1.1.2" xref="S4.SS7.p1.5.m5.1.1.2.cmml">40</mn><mo id="S4.SS7.p1.5.m5.1.1.1" xref="S4.SS7.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p1.5.m5.1b"><apply id="S4.SS7.p1.5.m5.1.1.cmml" xref="S4.SS7.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS7.p1.5.m5.1.1.1.cmml" xref="S4.SS7.p1.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S4.SS7.p1.5.m5.1.1.2.cmml" xref="S4.SS7.p1.5.m5.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p1.5.m5.1c">40\%</annotation></semantics></math> random translation.
<em id="S4.SS7.p1.5.3" class="ltx_emph ltx_font_italic">PC</em> refers to pose complementation.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<div id="S4.T6.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:150.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(87.3pt,-30.3pt) scale(1.67443280077542,1.67443280077542) ;">
<table id="S4.T6.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.3.3.4.1" class="ltx_tr">
<th id="S4.T6.3.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T6.3.3.4.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<th id="S4.T6.3.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.3.3.4.1.2.1" class="ltx_text ltx_font_bold">Regular</span></th>
<th id="S4.T6.3.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.3.3.4.1.3.1" class="ltx_text ltx_font_bold">Translation</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.3.3.5.1" class="ltx_tr">
<th id="S4.T6.3.3.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Baseline</th>
<td id="S4.T6.3.3.5.1.2" class="ltx_td ltx_align_center ltx_border_t">59.8</td>
<td id="S4.T6.3.3.5.1.3" class="ltx_td ltx_align_center ltx_border_t">92.2</td>
</tr>
<tr id="S4.T6.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Baseline + <math id="S4.T6.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{P3D}" display="inline"><semantics id="S4.T6.1.1.1.1.m1.1a"><msub id="S4.T6.1.1.1.1.m1.1.1" xref="S4.T6.1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T6.1.1.1.1.m1.1.1.2" xref="S4.T6.1.1.1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T6.1.1.1.1.m1.1.1.3" xref="S4.T6.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.T6.1.1.1.1.m1.1.1.3.2" xref="S4.T6.1.1.1.1.m1.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.T6.1.1.1.1.m1.1.1.3.1" xref="S4.T6.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S4.T6.1.1.1.1.m1.1.1.3.3" xref="S4.T6.1.1.1.1.m1.1.1.3.3.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.T6.1.1.1.1.m1.1.1.3.1a" xref="S4.T6.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.1.1.1.1.m1.1.1.3.4" xref="S4.T6.1.1.1.1.m1.1.1.3.4.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.1.m1.1b"><apply id="S4.T6.1.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.1.1.1.1.m1.1.1.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T6.1.1.1.1.m1.1.1.2.cmml" xref="S4.T6.1.1.1.1.m1.1.1.2">â„’</ci><apply id="S4.T6.1.1.1.1.m1.1.1.3.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3"><times id="S4.T6.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.1"></times><ci id="S4.T6.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.2">ğ‘ƒ</ci><cn type="integer" id="S4.T6.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.3">3</cn><ci id="S4.T6.1.1.1.1.m1.1.1.3.4.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.4">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.1.m1.1c">\mathcal{L}_{P3D}</annotation></semantics></math>
</th>
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_center">58.4</td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center">87.7</td>
</tr>
<tr id="S4.T6.2.2.2" class="ltx_tr">
<th id="S4.T6.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Baseline + <math id="S4.T6.2.2.2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{P3D}" display="inline"><semantics id="S4.T6.2.2.2.1.m1.1a"><msub id="S4.T6.2.2.2.1.m1.1.1" xref="S4.T6.2.2.2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T6.2.2.2.1.m1.1.1.2" xref="S4.T6.2.2.2.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T6.2.2.2.1.m1.1.1.3" xref="S4.T6.2.2.2.1.m1.1.1.3.cmml"><mi id="S4.T6.2.2.2.1.m1.1.1.3.2" xref="S4.T6.2.2.2.1.m1.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.T6.2.2.2.1.m1.1.1.3.1" xref="S4.T6.2.2.2.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S4.T6.2.2.2.1.m1.1.1.3.3" xref="S4.T6.2.2.2.1.m1.1.1.3.3.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.T6.2.2.2.1.m1.1.1.3.1a" xref="S4.T6.2.2.2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.2.2.2.1.m1.1.1.3.4" xref="S4.T6.2.2.2.1.m1.1.1.3.4.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.1.m1.1b"><apply id="S4.T6.2.2.2.1.m1.1.1.cmml" xref="S4.T6.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.2.2.2.1.m1.1.1.1.cmml" xref="S4.T6.2.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T6.2.2.2.1.m1.1.1.2.cmml" xref="S4.T6.2.2.2.1.m1.1.1.2">â„’</ci><apply id="S4.T6.2.2.2.1.m1.1.1.3.cmml" xref="S4.T6.2.2.2.1.m1.1.1.3"><times id="S4.T6.2.2.2.1.m1.1.1.3.1.cmml" xref="S4.T6.2.2.2.1.m1.1.1.3.1"></times><ci id="S4.T6.2.2.2.1.m1.1.1.3.2.cmml" xref="S4.T6.2.2.2.1.m1.1.1.3.2">ğ‘ƒ</ci><cn type="integer" id="S4.T6.2.2.2.1.m1.1.1.3.3.cmml" xref="S4.T6.2.2.2.1.m1.1.1.3.3">3</cn><ci id="S4.T6.2.2.2.1.m1.1.1.3.4.cmml" xref="S4.T6.2.2.2.1.m1.1.1.3.4">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.1.m1.1c">\mathcal{L}_{P3D}</annotation></semantics></math> + Aug.</th>
<td id="S4.T6.2.2.2.2" class="ltx_td ltx_align_center">56.2</td>
<td id="S4.T6.2.2.2.3" class="ltx_td ltx_align_center">82.0</td>
</tr>
<tr id="S4.T6.3.3.3" class="ltx_tr">
<th id="S4.T6.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Baseline + <math id="S4.T6.3.3.3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{P3D}" display="inline"><semantics id="S4.T6.3.3.3.1.m1.1a"><msub id="S4.T6.3.3.3.1.m1.1.1" xref="S4.T6.3.3.3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T6.3.3.3.1.m1.1.1.2" xref="S4.T6.3.3.3.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T6.3.3.3.1.m1.1.1.3" xref="S4.T6.3.3.3.1.m1.1.1.3.cmml"><mi id="S4.T6.3.3.3.1.m1.1.1.3.2" xref="S4.T6.3.3.3.1.m1.1.1.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.T6.3.3.3.1.m1.1.1.3.1" xref="S4.T6.3.3.3.1.m1.1.1.3.1.cmml">â€‹</mo><mn id="S4.T6.3.3.3.1.m1.1.1.3.3" xref="S4.T6.3.3.3.1.m1.1.1.3.3.cmml">3</mn><mo lspace="0em" rspace="0em" id="S4.T6.3.3.3.1.m1.1.1.3.1a" xref="S4.T6.3.3.3.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.3.3.3.1.m1.1.1.3.4" xref="S4.T6.3.3.3.1.m1.1.1.3.4.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.1.m1.1b"><apply id="S4.T6.3.3.3.1.m1.1.1.cmml" xref="S4.T6.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.3.3.3.1.m1.1.1.1.cmml" xref="S4.T6.3.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T6.3.3.3.1.m1.1.1.2.cmml" xref="S4.T6.3.3.3.1.m1.1.1.2">â„’</ci><apply id="S4.T6.3.3.3.1.m1.1.1.3.cmml" xref="S4.T6.3.3.3.1.m1.1.1.3"><times id="S4.T6.3.3.3.1.m1.1.1.3.1.cmml" xref="S4.T6.3.3.3.1.m1.1.1.3.1"></times><ci id="S4.T6.3.3.3.1.m1.1.1.3.2.cmml" xref="S4.T6.3.3.3.1.m1.1.1.3.2">ğ‘ƒ</ci><cn type="integer" id="S4.T6.3.3.3.1.m1.1.1.3.3.cmml" xref="S4.T6.3.3.3.1.m1.1.1.3.3">3</cn><ci id="S4.T6.3.3.3.1.m1.1.1.3.4.cmml" xref="S4.T6.3.3.3.1.m1.1.1.3.4">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.1.m1.1c">\mathcal{L}_{P3D}</annotation></semantics></math> + Aug. + PC</th>
<td id="S4.T6.3.3.3.2" class="ltx_td ltx_align_center ltx_border_bb">56.1</td>
<td id="S4.T6.3.3.3.3" class="ltx_td ltx_align_center ltx_border_bb">68.3</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Ablation study on Human3.6M in terms of MPJPE.</figcaption>
</figure>
<div id="S4.SS7.p2" class="ltx_para">
<p id="S4.SS7.p2.2" class="ltx_p">From Tab.Â <a href="#S4.T6" title="TABLE VI â€£ IV-G Ablation study â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> we can see that, the baseline yields MPJPE of 92.2 on images with <math id="S4.SS7.p2.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S4.SS7.p2.1.m1.1a"><mrow id="S4.SS7.p2.1.m1.1.1" xref="S4.SS7.p2.1.m1.1.1.cmml"><mn id="S4.SS7.p2.1.m1.1.1.2" xref="S4.SS7.p2.1.m1.1.1.2.cmml">40</mn><mo id="S4.SS7.p2.1.m1.1.1.1" xref="S4.SS7.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.1.m1.1b"><apply id="S4.SS7.p2.1.m1.1.1.cmml" xref="S4.SS7.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS7.p2.1.m1.1.1.1.cmml" xref="S4.SS7.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS7.p2.1.m1.1.1.2.cmml" xref="S4.SS7.p2.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.1.m1.1c">40\%</annotation></semantics></math> translation, outperforms all the other methods in Tab.Â <a href="#S4.T3" title="TABLE III â€£ IV-D3 Results on Human3.6M on incomplete images â€£ IV-D Quantitative results â€£ IV Experiments â€£ PONet: Robust 3D Human Pose Estimation via Learning Orientations Only" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, proving the superiority of our orientation-based method over keypoint-detection-based ones in improving the robustness.
End-to-end training can improve the performance on both complete and incomplete images, demonstrating the importance of our differentiable orientation extraction.
Data augmentation of occlusion and large translation can further improve the performance.
At last, the performance gain brought by pose complementation in regular setting is limited, but it can improve the performance on translation of <math id="S4.SS7.p2.2.m2.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S4.SS7.p2.2.m2.1a"><mrow id="S4.SS7.p2.2.m2.1.1" xref="S4.SS7.p2.2.m2.1.1.cmml"><mn id="S4.SS7.p2.2.m2.1.1.2" xref="S4.SS7.p2.2.m2.1.1.2.cmml">40</mn><mo id="S4.SS7.p2.2.m2.1.1.1" xref="S4.SS7.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.2.m2.1b"><apply id="S4.SS7.p2.2.m2.1.1.cmml" xref="S4.SS7.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS7.p2.2.m2.1.1.1.cmml" xref="S4.SS7.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS7.p2.2.m2.1.1.2.cmml" xref="S4.SS7.p2.2.m2.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.2.m2.1c">40\%</annotation></semantics></math> by a large margin.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we propose PONet, a robust and effectual 3D human pose estimation
network based on learning orientation only.
Our method bypasses 2D keypoint detection, which is prone to errors in the absence of body parts, by learning three sets of maps that encode the limb confidence, 2D and 3D orientations of each limb.
This design allows us to predict the 3D limb orientations on images with absent joints.
In the more challenging scenarios where limbs are completely occluded or out-of-image,
PONet can provide a complete 3D pose estimation by inferring the 3D orientations of the invisible limbs from the visible ones using pose complementation.
We evaluate our method on multiple datasets including Human3.6M, MPII, MPI-INF-3DHP and 3DPW.
Extensive experiments demonstrate the gratifying robustness of the proposed method.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">2d human pose estimation: New benchmark and state of the art
analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Anurag Arnab, Carl Doersch, and Andrew Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Exploiting temporal context for 3d human pose estimation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter Gehler, Javier Romero,
and MichaelÂ J Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Keep it smpl: Automatic estimation of 3d human pose and shape from a
single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 561â€“578.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Yujun Cai, Liuhao Ge, Jun Liu, Jianfei Cai, Tat-Jen Cham, Junsong Yuan, and
NadiaÂ Magnenat Thalmann.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Exploiting spatial-temporal relationships for 3d pose estimation via
graph convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, October 2019.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Realtime multi-person 2d pose estimation using part affinity fields.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, July 2017.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Ching-Hang Chen and Deva Ramanan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">3d human pose estimation = 2d pose estimation + matching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, July 2017.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Y. Cheng, B. Yang, Bo Wang, and R. Tan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">3d human pose estimation using spatio-temporal networks with explicit
occlusion training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Yu Cheng, Bo Yang, Bo Wang, Wending Yan, and RobbyÂ T. Tan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Occlusion-aware networks for 3d human pose estimation in video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">,
October 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Rishabh Dabral, Anurag Mundhada, Uday Kusupati, Safeer Afaque, Abhishek Sharma,
and Arjun Jain.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Learning 3d human pose from structure and motion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The European Conference on Computer Vision (ECCV)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, September
2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Haoshu Fang, Yuanlu Xu, Wenguan Wang, Xiaobai Liu, and Song-Chun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Learning pose grammar to encode human body configuration for 3d pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Ikhsanul Habibie, Weipeng Xu, Dushyant Mehta, Gerard Pons-Moll, and Christian
Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">In the wild human pose estimation using explicit 2d features and
intermediate 3d representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Catalin Ionescu, Dragos Papava, Vlad Olaru, and Cristian Sminchisescu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Human3. 6m: Large scale datasets and predictive methods for 3d human
sensing in natural environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">,
2014.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Angjoo Kanazawa, MichaelÂ J. Black, DavidÂ W. Jacobs, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">End-to-end recovery of human shape and pose.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, June 2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Angjoo Kanazawa, JasonÂ Y. Zhang, Panna Felsen, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Learning 3d human dynamics from video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Muhammed Kocabas, Salih Karagoz, and Emre Akbas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Self-supervised learning of 3d human pose using multi-view geometry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Nikos Kolotouros, Georgios Pavlakos, MichaelÂ J. Black, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Learning to reconstruct 3d human pose and shape via model-fitting in
the loop.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, October 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Nikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Convolutional mesh regression for single-image human shape
reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Christoph Lassner, Javier Romero, Martin Kiefel, Federica Bogo, MichaelÂ J
Black, and PeterÂ V Gehler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Unite the people: Closing the loop between 3d and 2d human
representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 6050â€“6059, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Kyoungoh Lee, Inwoong Lee, and Sanghoon Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Propagating lstm: 3d pose estimation based on joint interdependency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The European Conference on Computer Vision (ECCV)</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, September
2018.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Shichao Li, Lei Ke, Kevin Pratama, Yu-Wing Tai, Chi-Keung Tang, and Kwang-Ting
Cheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Cascaded deep monocular 3d human pose estimation with evolutionary
training data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Ding Liu, Zixu Zhao, Xinchao Wang, Yuxiao Hu, Lei Zhang, and Thomas Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Improving 3d human pose estimation via 3d part affinity fields.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE Winter Conference on Applications of Computer
Vision (WACV)</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 1004â€“1013. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Ponsmoll, and MichaelÂ J
Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Smpl: a skinned multi-person linear model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 34(6):248, 2015.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Chenxu Luo, Xiao Chu, and Alan Yuille.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Orinet: A fully convolutional network for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">BMVC</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Julieta Martinez, Rayat Hossain, Javier Romero, and JamesÂ J Little.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">A simple yet effective baseline for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksandr Sotnychenko,
Weipeng Xu, and Christian Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Monocular 3d human pose estimation in the wild using improved cnn
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">3D Vision (3DV), 2017 International Conference on</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages
506â€“516. IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Dushyant Mehta, Srinath Sridhar, Oleksandr Sotnychenko, Helge Rhodin, Mohammad
Shafiei, Hans-Peter Seidel, Weipeng Xu, Dan Casas, and Christian Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Vnect: Real-time 3d human pose estimation with a single rgb camera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics (TOG)</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, 36(4):1â€“14, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Francesc Moreno-Noguer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">3d human pose estimation from a single image via distance matrix
regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Alejandro Newell, Kaiyu Yang, and Jia Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Stacked hourglass networks for human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
BruceÂ Xiaohan Nie, Ping Wei, and Song-Chun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Monocular 3d human pose estimation by predicting depth on joints.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
Chintala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Pytorch: An imperative style, high-performance deep learning library.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchÃ©-Buc, E. Fox, and R. Garnett, editors, </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural
Information Processing Systems 32</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 8024â€“8035. Curran Associates,
Inc., 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A.Â A.
Osman, Dimitrios Tzionas, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Expressive body capture: 3d hands, face, and body from a single
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Ordinal depth supervision for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Learning to estimate 3d human pose and shape from a single color
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 459â€“468, 2018.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Haibo Qiu, Chunyu Wang, Jingdong Wang, Naiyan Wang, and Wenjun Zeng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Cross view fusion for 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">,
October 2019.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
IstvÃ¡n SÃ¡rÃ¡ndi, Timm Linder, KaiÂ O Arras, and Bastian Leibe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">How robust is 3d human pose estimation to occlusion?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1808.09316</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Mingyi Shi, Kfir Aberman, Andreas Aristidou, Taku Komura, Dani Lischinski,
Daniel Cohen-Or, and Baoquan Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Motionet: 3d human motion reconstruction from monocular video with
skeleton consistency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 40(1), Sept. 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Deep high-resolution representation learning for human pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Xiao Sun, Jiaxiang Shang, Shuang Liang, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Compositional human pose regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">,
Oct 2017.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Denis Tome, Chris Russell, and Lourdes Agapito.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Lifting from the deep: Convolutional 3d pose estimation from a single
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, July 2017.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Hsiao-Yu Tung, Hsiao-Wei Tung, Ersin Yumer, and Katerina Fragkiadaki.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Self-supervised learning of motion capture.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, pages
5236â€“5246, 2017.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Gul Varol, Duygu Ceylan, Bryan Russell, Jimei Yang, Ersin Yumer, Ivan Laptev,
and Cordelia Schmid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Bodynet: Volumetric inference of 3d human body shapes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The European Conference on Computer Vision (ECCV)</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, September
2018.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Timo von Marcard, Roberto Henschel, Michael Black, Bodo Rosenhahn, and Gerard
Pons-Moll.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Recovering accurate 3d human pose in the wild using imus and a moving
camera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, sep 2018.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Chunyu Wang, Yizhou Wang, Zhouchen Lin, AlanÂ L. Yuille, and Wen Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Robust estimation of 3d human poses from a single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, June 2014.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Jue Wang, Shaoli Huang, Xinchao Wang, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Not all parts are created equal: 3d pose estimation by modeling
bi-directional dependencies of body parts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE International Conference on Computer Vision (ICCV)</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">,
October 2019.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Donglai Xiang, Hanbyul Joo, and Yaser Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Monocular total capture: Posing face, body, and hands in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, June 2019.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Jingwei Xu, Zhenbo Yu, Bingbing Ni, Jiancheng Yang, Xiaokang Yang, and Wenjun
Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Deep kinematics analysis for monocular 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Wei Yang, Wanli Ouyang, Xiaolong Wang, Jimmy Ren, Hongsheng Li, and Xiaogang
Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">3d human pose estimation in the wild by adversarial learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Tianshu Zhang, Buzhen Huang, and Yangang Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Object-occluded human shape and pose estimation from a single color
image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib48.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Xingyi Zhou, Qixing Huang, Xiao Sun, Xiangyang Xue, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Towards 3d human pose estimation in the wild: a weakly-supervised
approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib49.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Xiaowei Zhou, Spyridon Leonardos, Xiaoyan Hu, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">3d shape estimation from 2d landmarks: A convex relaxation approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, June 2015.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Xingyi Zhou, Xiao Sun, Wei Zhang, Shuang Liang, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Deep kinematic pose regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, pages 186â€“201.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Xiaowei Zhou, Menglong Zhu, Spyridon Leonardos, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Sparse representation for 3d shape estimation: A convex relaxation
approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib52.4.2" class="ltx_text" style="font-size:90%;">,
39(8):1648â€“1661, 2017.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Xiaowei Zhou, Menglong Zhu, Spyridon Leonardos, KonstantinosÂ G Derpanis, and
Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Sparseness meets deepness: 3d human pose estimation from monocular
video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib53.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib53.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Xiaowei Zhou, Menglong Zhu, Georgios Pavlakos, Spyridon Leonardos,
KonstantinosÂ G Derpanis, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Monocap: Monocular human motion capture using a cnn coupled with a
geometric prior.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib54.4.2" class="ltx_text" style="font-size:90%;">,
41(4):901â€“914, 2018.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold">If you will not include a photo:</span></p>
</div>
<figure id="id1" class="ltx_float biography">
<table id="id1.1" class="ltx_tabular">
<tr id="id1.1.1" class="ltx_tr">
<td id="id1.1.1.1" class="ltx_td">
<span id="id1.1.1.1.1" class="ltx_inline-block">
<span id="id1.1.1.1.1.1" class="ltx_p"><span id="id1.1.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_bold">John Doe</span><span id="id1.1.1.1.1.1.2" class="ltx_text ltx_font_bold"> 
Use </span><math id="id1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\backslash" display="inline"><semantics id="id1.1.1.1.1.1.m1.1a"><mo id="id1.1.1.1.1.1.m1.1.1" xref="id1.1.1.1.1.1.m1.1.1.cmml">\</mo><annotation-xml encoding="MathML-Content" id="id1.1.1.1.1.1.m1.1b"><ci id="id1.1.1.1.1.1.m1.1.1.cmml" xref="id1.1.1.1.1.1.m1.1.1">\</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.1.1.1.m1.1c">\backslash</annotation></semantics></math><span id="id1.1.1.1.1.1.3" class="ltx_text ltx_font_typewriter">begin{IEEEbiographynophoto}</span><span id="id1.1.1.1.1.1.4" class="ltx_text ltx_font_bold"> and the author name as the argument followed by the biography text.</span></span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2112.11152" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2112.11153" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2112.11153">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2112.11153" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2112.11154" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 15:27:26 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
