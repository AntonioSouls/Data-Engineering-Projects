<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data</title>
<!--Generated on Wed Sep 25 17:11:45 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03705v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S1" title="In Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S2" title="In Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S2.SS1" title="In 2 Background ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Traditional Machine Learning Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S2.SS2" title="In 2 Background ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Deep Neural Networks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S2.SS3" title="In 2 Background ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Ensemble Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S3" title="In Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Problem Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4" title="In Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS1" title="In 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS2" title="In 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Data Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS3" title="In 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Training Procedure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS4" title="In 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Hyperparameter Optimization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS5" title="In 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S5" title="In Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S6" title="In Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">A. Yarkƒ±n Yƒ±ldƒ±z and Asli Kalayci
</span><span class="ltx_author_notes">A. Yarkƒ±n Yƒ±ldƒ±z is with Department of Electrical and Computer Engineering, Northeastern
University, Boston, MA 02115 USA (e-mail: yildiz.ay@northeastern.edu).Asli Kalayci is with School of Business, Worcester Polytechnic Institute, Worcester, MA 01609 USA (e-mail: akalayci@wpi.edu).</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Medical diagnosis is a crucial task in the medical field, in terms of providing accurate classification and respective treatments. Having near-precise decisions based on correct diagnosis can affect a patient‚Äôs life itself, and may extremely result in a catastrophe if not classified correctly. Several traditional machine learning (ML), such as support vector machines (SVMs) and logistic regression, and state-of-the-art tabular deep learning (DL) methods, including TabNet and TabTransformer, have been proposed and used over tabular medical datasets. Additionally, due to the superior performances, lower computational costs, and easier optimization over different tasks, ensemble methods have been used in the field more recently. They offer a powerful alternative in terms of providing successful medical decision-making processes in several diagnosis tasks. In this study, we investigated the benefits of ensemble methods, especially the Gradient Boosting Decision Tree (GBDT) algorithms in medical classification tasks over tabular data, focusing on XGBoost, CatBoost, and LightGBM. The experiments demonstrate that GBDT methods outperform traditional ML and deep neural network architectures and have the highest average rank over several benchmark tabular medical diagnosis datasets. Furthermore, they require much less computational power compared to DL models, creating the optimal methodology in terms of high performance and lower complexity.</p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">{IEEEkeywords}</span>
<p class="ltx_p" id="p1.2">Decision Trees, Ensemble Methods, Gradient Boosting, Medical Diagnosis, Tabular Data</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<span class="ltx_ERROR undefined" id="S1.p1.1">\IEEEPARstart</span>
<p class="ltx_p" id="S1.p1.2">Tabular data, a prevalent data type in real world applications, consists of rows representing samples and columns representing features of each sample. This form of data is widely utilized across various fields, including manufacturing, finance and healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib1" title="">1</a>]</cite>. Given its extensive use in applications dependent on relational databases, tabular data modeling is considered crucial in the machine learning (ML) domain. Various traditional ML models have been employed for tabular data classification, including k-nearest neighbors (KNN), logistic regression, and support vector machines (SVMs). Although having a wide range of implementations and high performances in the past, the success of these models has diminished and initiated advancements in other types of ML architectures, such as deep networks and ensemble models.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Following the increasing availability of large amounts of datasets and advancements in computing resources and deep learning (DL) architectures, such as convolutional models and recurrent mechanisms, have increased their success in the field. With the growing demand for research in large language models (LLMs), attention-based methods have emerged as the state-of-the-art in many downstream tasks, including image, audio, and textual data analysis. Despite these advances, there has been an ongoing debate about whether deep architectures provide satisfying results for tabular data. Following the recent comparisons <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib2" title="">2</a>]</cite>, deep architectures have deployed superior performance over traditional ML algorithms, over specific tabular data including credit lines, income information, and cartography. Despite increasing the baseline performances compared to other traditional ML methods, DL architectures still possess some challenges in tabular data classification, due to the heterogeneous environment in this type of data. Originally, textual type of data contains a homogeneous environment that helps DL models to have a better generalization. These architectures can encode pretty meaningful representations in the domain of the data. However, tabular data include a large amount of sparse categorical features that impose challenges in learning a representation among these features even having a good encoding before training. Additionally, the numerical features are usually dense and the correlation between the features is much weaker compared to textual data. Therefore, deep neural networks can encounter some challenges when handling tasks involving tabular data.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Due to these issues mentioned above, there is a need for models that require little to no correlational information between features in order to provide good performances. In this context, ensemble models have started to surpass the deep and traditional ML architectures due to their robustness in sparse environments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib3" title="">3</a>]</cite>. For tasks requiring tabular data, ensemble models offer good accuracy while maintaining computational convenience, whereas deep neural networks struggle due to their complex architectures. More recently, gradient boosting decision trees (GBDTs) have started to show superiority and become state-of-the-art in many downstream tasks, including those requiring tabular data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib4" title="">4</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Following the recent application fields, one of the most important environments that utilize tabular data is the medical field, especially several diagnosis tasks using patient records. Here, each patient record can be treated as row entries, and columns have the corresponding attributes of the patients. Possibility of having sparsity and less correlation between each record, robust GBDT methods have gained high popularity in the field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib5" title="">5</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib6" title="">6</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Motivated by these advancements, in this work, we highlight the superiority of the ensemble models, especially the GBDTs, over other traditional ML methods and DL architectures, in medical diagnosis tasks, specifically over tabular data. We compared 5 traditional ML methods and 5 DL models with 4 ensemble models, 3 of them being GBDT models, over 7 different medical datasets. We experimentally showed that GBDTs outperform all of the other methods and have the highest ranks over the medical diagnosis datasets on average.  Unlike previous works that provide individual applications focusing on a limited number of disease types <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib7" title="">7</a>]</cite> or certain types of tabular datasets outside the medical field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib2" title="">2</a>]</cite> by utilizing certain types of ML algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib8" title="">8</a>]</cite> or a limited number of comparisons regarding DL and ML methodologies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib9" title="">9</a>]</cite>, our contribution is to provide deep insights into the superiority of the GBDT models over state-of-the-art tabular DL and traditional ML models, focused on a diverse set of tabular medical diagnosis tasks consisting of different dataset dimensions and size settings. Having evaluated the relative performance of the methods across different clinical settings, we also provide insight into which model is more suitable in such medical cases. Additionally, we provide an analysis of training time consumption between the models, which has crucial implications in the medical field in terms of providing fast and accurate well-informed clinical decisions.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Traditional Machine Learning Models</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Various studies have explored the application of ML algorithms in medical diagnosis over tabular data. For example, KNN algorithms are used in many applications due to their simplicity, especially in medical data classification, where the data consist of many samples of medical health <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib10" title="">10</a>]</cite>, when detecting breast cancer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib7" title="">7</a>]</cite>, and providing diagnosis on diabetes by using a fine-tuned KNN classifier <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib11" title="">11</a>]</cite>. Another example can be logistic regression, that has been widely used in both continuous and categorical data classifications, including the medical diagnosis field <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib12" title="">12</a>]</cite>, specifically in COVID-19 diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib13" title="">13</a>]</cite>, and on many other major chronic disease diagnoses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib14" title="">14</a>]</cite>. On the other hand, SVMs are relatively famous for performing medical diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib15" title="">15</a>]</cite>, especially when combined with other different ML methods, including several deep neural networks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib16" title="">16</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib17" title="">17</a>]</cite>. Moreover, decision trees are one of the most widely used classifiers over tabular data in general <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib18" title="">18</a>]</cite>, and for medical diagnosis specifically, such as coronary artery disease classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib19" title="">19</a>]</cite>, chronic kidney disease diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib8" title="">8</a>]</cite>. Their performance can be increased when combined with other deep neural network models, such as training the decision trees using convolutional neural networks (CNN) for COVID-19 diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib20" title="">20</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Deep Neural Networks</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Recently, several DL models that are designed for tabular learning have started to form the state-of-the-art for tabular data classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib21" title="">21</a>]</cite>. There is a tremendous success of attention-based architectures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib22" title="">22</a>]</cite>, such as transformers that are applied on several different areas, including medical image analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib23" title="">23</a>]</cite>, and as the LLMs have started to occupy the research industry, they have been widely applied to textual data analysis, including the self-attention methods used in time-series analysis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib24" title="">24</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib25" title="">25</a>]</cite>. In general, they utilize neural network architectures that leverage DL to reflect the complicated relationships between words in the text-based training data set <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib26" title="">26</a>]</cite>. The generative AI-powered application, ChatGPT for instance, is a widely used LLM chatbot that produces text in response to text input <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib26" title="">26</a>]</cite>. In particular, the LLM algorithm analyzes the data and the context of the words related to each other and creates a text based on a prompt. While DL techniques have advanced, along with enhanced computational resources and big datasets for training, LLM applications have the potential to augment the work across various sectors, including healthcare, which has begun to emerge. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib27" title="">27</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Moreover, LLM models have shown impressive ability in the field of medicine. They demonstrated the ability to provide meaningful suggestions for further treatments based on the provided information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib28" title="">28</a>]</cite>. By combining healthcare data and LLMs, medical diagnosis and treatment can achieve improved precision and efficiency. For example, the diagnostic accuracy of algorithms to identify pathology in medical imaging is studied by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib29" title="">29</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">The development of DL algorithms is driven by the availability of medical datasets, which are often challenging to access due to their size and diversity. In other words, the proper acquisition of these datasets is integral for interpreting model performance and accuracy within real-world clinical data. Furthermore, LLM processing employs ethical concerns together with security and privacy due to the inclusion of personal health records during model training <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib30" title="">30</a>]</cite>. These concerns and challenges are broadly justified in the literature in terms of its acceptability <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib31" title="">31</a>]</cite>, downstream accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib32" title="">32</a>]</cite>, medical ethics <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib33" title="">33</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib34" title="">34</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib35" title="">35</a>]</cite>. Hence, due to the limitations mentioned above, few experimental studies of DL applications in medicine have been conducted, thus, there is a great demand for explanatory research to validate the the diverse models using medical data. On a larger scale, employing diverse deep neural network architectures can serve as a guiding tool for handling more complex data.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Following these advances of deep architectures in textual type of data, attention-based methods have started to be developed for techniques applied to tabular data as well. Self-attention-based transformer architectures are used for supervised and semi-supervised learning, named TabTransformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib36" title="">36</a>]</cite>, specifically designed for tabular data. Moreover, a sequential attention architecture is developed for choosing which features to benefit from at each decision step, called TabNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib9" title="">9</a>]</cite>. Furthermore, a feature selection method is utilized for the problems in neural network estimation by using a procedure based on probabilistic relaxation, namely stochastic gates (STG) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib37" title="">37</a>]</cite>, and a novel self and semi-supervised learning framework adapted to tabular data classification, named value imputation and mask estimation (VIME) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib38" title="">38</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Ensemble Models</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Ensemble learning aims to improve model performance by integrating data from various sources, such as healthcare, and medical data with distinct attributes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib39" title="">39</a>]</cite>. One popular approach is Random Forest, which is based on the decision tree methodology and consists of a combination of parallel tree predictors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib40" title="">40</a>]</cite>. This method employs feature bagging, where each tree in the ensemble is built from a sample drawn with replacement from the training set, which is also called a bootstrap sample. Random Forest is widely used for tabular data classification across diverse healthcare domains <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib41" title="">41</a>]</cite>, including medical diagnosis in detecting Alzheimer‚Äôs disease <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib42" title="">42</a>]</cite>, COVID-19 prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib43" title="">43</a>]</cite>, and heart disease monitoring <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib44" title="">44</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">More recently, gradient-boosting methods have started to become the state-of-the-art in many fields, particularly GBDTs. Unlike other ensemble learning methods, many weak learners are combined to create a single strong learner, with each weak learner representing an individual decision tree. Each tree tries to minimize the error on the previous tree, where all of the trees are connected sequentially. Therefore, the model improves at each step iteratively, resulting in a stronger learner by the end. Some of their application fields include GPS signal reception classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib45" title="">45</a>]</cite> and credit risk assessments <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib46" title="">46</a>]</cite>, and also occupy various applications in the medical field including heart disease detection <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib47" title="">47</a>]</cite>, and parkinson‚Äôs disease progression prediction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib48" title="">48</a>]</cite>. GBDT comprises three main algorithms that have been occupying the field in recent years, which are XGBoost <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib49" title="">49</a>]</cite>, LightGBM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib50" title="">50</a>]</cite>, and CatBoost <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib51" title="">51</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">XGBoost is a flexible and portable optimized distributed GBDT framework that provides parallel tree boosting in a wide range of applications. It uses a special regularization that maintains an increased efficiency compared to the other GBDT methods. It has been one of the state-of-the-art GBDT methods, and it has diverse application fields including the medical field in breast cancer classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib52" title="">52</a>]</cite>,</p>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">LightGBM is another prevalent GBDT model that deploys a leaf-wise growth for tree construction, unlike XGBoost‚Äôs row-by-row approach. Another difference is that it implements a decision tree algorithm that is a highly optimized histogram-based algorithm, that yields increased efficiency and reduced memory consumption. Besides, LightGBM inherits many of XGBoost‚Äôs advantages such as optimization, regularization capabilities, and support for parallel training.</p>
</div>
<div class="ltx_para" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.1">CatBoost is the other valuable GBDT methodology designed specifically for handling categorical features. It offers advantages such as fast GPU and multi-GPU supports for training, including a range of visualization tools, and use of ordered boosting to overcome overfitting. It is one of the most used ML frameworks in practice, together with XGBoost and LightGBM.</p>
</div>
<div class="ltx_para" id="S2.SS3.p6">
<p class="ltx_p" id="S2.SS3.p6.1">Although the implementations of these algorithms can vary in detail in many applications, their performances usually do not differ that much <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib51" title="">51</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Problem Formulation</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In general, tabular data consist of multiple attributes that offer information regarding the specific task. Each attribute resides in a separate column in the dataset, and each row corresponds to the different samples. In our task, each sample corresponds to a single patient, and each attribute includes various pieces of information regarding the patient‚Äôs records relevant to the task at hand.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Formally, for each of the task, we have the feature matrix, that consists of:</p>
</div>
<div class="ltx_para" id="S3.p3">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\boldsymbol{X}=\{\boldsymbol{x}_{i}\}_{i=1}^{n}=\{\boldsymbol{x}_%
{1},\boldsymbol{x}_{2},\dots,\boldsymbol{x}_{n}\}" class="ltx_Math" display="inline" id="S3.E1.m1.5"><semantics id="S3.E1.m1.5a"><mrow id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml"><mi id="S3.E1.m1.5.5.6" xref="S3.E1.m1.5.5.6.cmml">ùëø</mi><mo id="S3.E1.m1.5.5.7" xref="S3.E1.m1.5.5.7.cmml">=</mo><msubsup id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.2.cmml"><mo id="S3.E1.m1.2.2.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.2.cmml">{</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml">ùíô</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.3.2" xref="S3.E1.m1.2.2.1.1.3.2.cmml">i</mi><mo id="S3.E1.m1.2.2.1.1.3.1" xref="S3.E1.m1.2.2.1.1.3.1.cmml">=</mo><mn id="S3.E1.m1.2.2.1.1.3.3" xref="S3.E1.m1.2.2.1.1.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml">n</mi></msubsup><mo id="S3.E1.m1.5.5.8" xref="S3.E1.m1.5.5.8.cmml">=</mo><mrow id="S3.E1.m1.5.5.4.3" xref="S3.E1.m1.5.5.4.4.cmml"><mo id="S3.E1.m1.5.5.4.3.4" stretchy="false" xref="S3.E1.m1.5.5.4.4.cmml">{</mo><msub id="S3.E1.m1.3.3.2.1.1" xref="S3.E1.m1.3.3.2.1.1.cmml"><mi id="S3.E1.m1.3.3.2.1.1.2" xref="S3.E1.m1.3.3.2.1.1.2.cmml">ùíô</mi><mn id="S3.E1.m1.3.3.2.1.1.3" xref="S3.E1.m1.3.3.2.1.1.3.cmml">1</mn></msub><mo id="S3.E1.m1.5.5.4.3.5" xref="S3.E1.m1.5.5.4.4.cmml">,</mo><msub id="S3.E1.m1.4.4.3.2.2" xref="S3.E1.m1.4.4.3.2.2.cmml"><mi id="S3.E1.m1.4.4.3.2.2.2" xref="S3.E1.m1.4.4.3.2.2.2.cmml">ùíô</mi><mn id="S3.E1.m1.4.4.3.2.2.3" xref="S3.E1.m1.4.4.3.2.2.3.cmml">2</mn></msub><mo id="S3.E1.m1.5.5.4.3.6" xref="S3.E1.m1.5.5.4.4.cmml">,</mo><mi id="S3.E1.m1.1.1" mathvariant="normal" xref="S3.E1.m1.1.1.cmml">‚Ä¶</mi><mo id="S3.E1.m1.5.5.4.3.7" xref="S3.E1.m1.5.5.4.4.cmml">,</mo><msub id="S3.E1.m1.5.5.4.3.3" xref="S3.E1.m1.5.5.4.3.3.cmml"><mi id="S3.E1.m1.5.5.4.3.3.2" xref="S3.E1.m1.5.5.4.3.3.2.cmml">ùíô</mi><mi id="S3.E1.m1.5.5.4.3.3.3" xref="S3.E1.m1.5.5.4.3.3.3.cmml">n</mi></msub><mo id="S3.E1.m1.5.5.4.3.8" stretchy="false" xref="S3.E1.m1.5.5.4.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.5b"><apply id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5"><and id="S3.E1.m1.5.5a.cmml" xref="S3.E1.m1.5.5"></and><apply id="S3.E1.m1.5.5b.cmml" xref="S3.E1.m1.5.5"><eq id="S3.E1.m1.5.5.7.cmml" xref="S3.E1.m1.5.5.7"></eq><ci id="S3.E1.m1.5.5.6.cmml" xref="S3.E1.m1.5.5.6">ùëø</ci><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1">subscript</csymbol><set id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1"><apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2">ùíô</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3">ùëñ</ci></apply></set><apply id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3"><eq id="S3.E1.m1.2.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.3.1"></eq><ci id="S3.E1.m1.2.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2">ùëñ</ci><cn id="S3.E1.m1.2.2.1.1.3.3.cmml" type="integer" xref="S3.E1.m1.2.2.1.1.3.3">1</cn></apply></apply><ci id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3">ùëõ</ci></apply></apply><apply id="S3.E1.m1.5.5c.cmml" xref="S3.E1.m1.5.5"><eq id="S3.E1.m1.5.5.8.cmml" xref="S3.E1.m1.5.5.8"></eq><share href="https://arxiv.org/html/2410.03705v1#S3.E1.m1.2.2.1.cmml" id="S3.E1.m1.5.5d.cmml" xref="S3.E1.m1.5.5"></share><set id="S3.E1.m1.5.5.4.4.cmml" xref="S3.E1.m1.5.5.4.3"><apply id="S3.E1.m1.3.3.2.1.1.cmml" xref="S3.E1.m1.3.3.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.1.1.1.cmml" xref="S3.E1.m1.3.3.2.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.2.1.1.2.cmml" xref="S3.E1.m1.3.3.2.1.1.2">ùíô</ci><cn id="S3.E1.m1.3.3.2.1.1.3.cmml" type="integer" xref="S3.E1.m1.3.3.2.1.1.3">1</cn></apply><apply id="S3.E1.m1.4.4.3.2.2.cmml" xref="S3.E1.m1.4.4.3.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.2.2.1.cmml" xref="S3.E1.m1.4.4.3.2.2">subscript</csymbol><ci id="S3.E1.m1.4.4.3.2.2.2.cmml" xref="S3.E1.m1.4.4.3.2.2.2">ùíô</ci><cn id="S3.E1.m1.4.4.3.2.2.3.cmml" type="integer" xref="S3.E1.m1.4.4.3.2.2.3">2</cn></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">‚Ä¶</ci><apply id="S3.E1.m1.5.5.4.3.3.cmml" xref="S3.E1.m1.5.5.4.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.4.3.3.1.cmml" xref="S3.E1.m1.5.5.4.3.3">subscript</csymbol><ci id="S3.E1.m1.5.5.4.3.3.2.cmml" xref="S3.E1.m1.5.5.4.3.3.2">ùíô</ci><ci id="S3.E1.m1.5.5.4.3.3.3.cmml" xref="S3.E1.m1.5.5.4.3.3.3">ùëõ</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.5c">\displaystyle\boldsymbol{X}=\{\boldsymbol{x}_{i}\}_{i=1}^{n}=\{\boldsymbol{x}_%
{1},\boldsymbol{x}_{2},\dots,\boldsymbol{x}_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.5d">bold_italic_X = { bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT = { bold_italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ‚Ä¶ , bold_italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.2">where each <math alttext="\boldsymbol{x}_{i}" class="ltx_Math" display="inline" id="S3.p4.1.m1.1"><semantics id="S3.p4.1.m1.1a"><msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mi id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">ùíô</mi><mi id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">ùíô</ci><ci id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\boldsymbol{x}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p4.1.m1.1d">bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes the feature vector for the <math alttext="i" class="ltx_Math" display="inline" id="S3.p4.2.m2.1"><semantics id="S3.p4.2.m2.1a"><mi id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><ci id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.p4.2.m2.1d">italic_i</annotation></semantics></math>-th patient. Additionally, we have the class labels, that consists of:</p>
</div>
<div class="ltx_para" id="S3.p5">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx2">
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\boldsymbol{y}=\{y_{1},y_{2},\dots,y_{n}\}" class="ltx_Math" display="inline" id="S3.E2.m1.4"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4" xref="S3.E2.m1.4.4.cmml"><mi id="S3.E2.m1.4.4.5" xref="S3.E2.m1.4.4.5.cmml">ùíö</mi><mo id="S3.E2.m1.4.4.4" xref="S3.E2.m1.4.4.4.cmml">=</mo><mrow id="S3.E2.m1.4.4.3.3" xref="S3.E2.m1.4.4.3.4.cmml"><mo id="S3.E2.m1.4.4.3.3.4" stretchy="false" xref="S3.E2.m1.4.4.3.4.cmml">{</mo><msub id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml">y</mi><mn id="S3.E2.m1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.E2.m1.4.4.3.3.5" xref="S3.E2.m1.4.4.3.4.cmml">,</mo><msub id="S3.E2.m1.3.3.2.2.2" xref="S3.E2.m1.3.3.2.2.2.cmml"><mi id="S3.E2.m1.3.3.2.2.2.2" xref="S3.E2.m1.3.3.2.2.2.2.cmml">y</mi><mn id="S3.E2.m1.3.3.2.2.2.3" xref="S3.E2.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.E2.m1.4.4.3.3.6" xref="S3.E2.m1.4.4.3.4.cmml">,</mo><mi id="S3.E2.m1.1.1" mathvariant="normal" xref="S3.E2.m1.1.1.cmml">‚Ä¶</mi><mo id="S3.E2.m1.4.4.3.3.7" xref="S3.E2.m1.4.4.3.4.cmml">,</mo><msub id="S3.E2.m1.4.4.3.3.3" xref="S3.E2.m1.4.4.3.3.3.cmml"><mi id="S3.E2.m1.4.4.3.3.3.2" xref="S3.E2.m1.4.4.3.3.3.2.cmml">y</mi><mi id="S3.E2.m1.4.4.3.3.3.3" xref="S3.E2.m1.4.4.3.3.3.3.cmml">n</mi></msub><mo id="S3.E2.m1.4.4.3.3.8" stretchy="false" xref="S3.E2.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.cmml" xref="S3.E2.m1.4.4"><eq id="S3.E2.m1.4.4.4.cmml" xref="S3.E2.m1.4.4.4"></eq><ci id="S3.E2.m1.4.4.5.cmml" xref="S3.E2.m1.4.4.5">ùíö</ci><set id="S3.E2.m1.4.4.3.4.cmml" xref="S3.E2.m1.4.4.3.3"><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.2">ùë¶</ci><cn id="S3.E2.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.E2.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.E2.m1.3.3.2.2.2.cmml" xref="S3.E2.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.2.2.2.1.cmml" xref="S3.E2.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.E2.m1.3.3.2.2.2.2.cmml" xref="S3.E2.m1.3.3.2.2.2.2">ùë¶</ci><cn id="S3.E2.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.E2.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">‚Ä¶</ci><apply id="S3.E2.m1.4.4.3.3.3.cmml" xref="S3.E2.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.3.3.3.1.cmml" xref="S3.E2.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.E2.m1.4.4.3.3.3.2.cmml" xref="S3.E2.m1.4.4.3.3.3.2">ùë¶</ci><ci id="S3.E2.m1.4.4.3.3.3.3.cmml" xref="S3.E2.m1.4.4.3.3.3.3">ùëõ</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\displaystyle\boldsymbol{y}=\{y_{1},y_{2},\dots,y_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.4d">bold_italic_y = { italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ‚Ä¶ , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p" id="S3.p6.5">where each <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.p6.1.m1.1"><semantics id="S3.p6.1.m1.1a"><msub id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml"><mi id="S3.p6.1.m1.1.1.2" xref="S3.p6.1.m1.1.1.2.cmml">y</mi><mi id="S3.p6.1.m1.1.1.3" xref="S3.p6.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><apply id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p6.1.m1.1.1.1.cmml" xref="S3.p6.1.m1.1.1">subscript</csymbol><ci id="S3.p6.1.m1.1.1.2.cmml" xref="S3.p6.1.m1.1.1.2">ùë¶</ci><ci id="S3.p6.1.m1.1.1.3.cmml" xref="S3.p6.1.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p6.1.m1.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> indicates the diagnosis class for the <math alttext="i" class="ltx_Math" display="inline" id="S3.p6.2.m2.1"><semantics id="S3.p6.2.m2.1a"><mi id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><ci id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.p6.2.m2.1d">italic_i</annotation></semantics></math>-th patient. The goal is to learn a mapping function <math alttext="f:\boldsymbol{X}\rightarrow\boldsymbol{y}" class="ltx_Math" display="inline" id="S3.p6.3.m3.1"><semantics id="S3.p6.3.m3.1a"><mrow id="S3.p6.3.m3.1.1" xref="S3.p6.3.m3.1.1.cmml"><mi id="S3.p6.3.m3.1.1.2" xref="S3.p6.3.m3.1.1.2.cmml">f</mi><mo id="S3.p6.3.m3.1.1.1" lspace="0.278em" rspace="0.278em" xref="S3.p6.3.m3.1.1.1.cmml">:</mo><mrow id="S3.p6.3.m3.1.1.3" xref="S3.p6.3.m3.1.1.3.cmml"><mi id="S3.p6.3.m3.1.1.3.2" xref="S3.p6.3.m3.1.1.3.2.cmml">ùëø</mi><mo id="S3.p6.3.m3.1.1.3.1" stretchy="false" xref="S3.p6.3.m3.1.1.3.1.cmml">‚Üí</mo><mi id="S3.p6.3.m3.1.1.3.3" xref="S3.p6.3.m3.1.1.3.3.cmml">ùíö</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.3.m3.1b"><apply id="S3.p6.3.m3.1.1.cmml" xref="S3.p6.3.m3.1.1"><ci id="S3.p6.3.m3.1.1.1.cmml" xref="S3.p6.3.m3.1.1.1">:</ci><ci id="S3.p6.3.m3.1.1.2.cmml" xref="S3.p6.3.m3.1.1.2">ùëì</ci><apply id="S3.p6.3.m3.1.1.3.cmml" xref="S3.p6.3.m3.1.1.3"><ci id="S3.p6.3.m3.1.1.3.1.cmml" xref="S3.p6.3.m3.1.1.3.1">‚Üí</ci><ci id="S3.p6.3.m3.1.1.3.2.cmml" xref="S3.p6.3.m3.1.1.3.2">ùëø</ci><ci id="S3.p6.3.m3.1.1.3.3.cmml" xref="S3.p6.3.m3.1.1.3.3">ùíö</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m3.1c">f:\boldsymbol{X}\rightarrow\boldsymbol{y}</annotation><annotation encoding="application/x-llamapun" id="S3.p6.3.m3.1d">italic_f : bold_italic_X ‚Üí bold_italic_y</annotation></semantics></math> that can accurately predict the diagnosis class <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.p6.4.m4.1"><semantics id="S3.p6.4.m4.1a"><msub id="S3.p6.4.m4.1.1" xref="S3.p6.4.m4.1.1.cmml"><mi id="S3.p6.4.m4.1.1.2" xref="S3.p6.4.m4.1.1.2.cmml">y</mi><mi id="S3.p6.4.m4.1.1.3" xref="S3.p6.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.4.m4.1b"><apply id="S3.p6.4.m4.1.1.cmml" xref="S3.p6.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p6.4.m4.1.1.1.cmml" xref="S3.p6.4.m4.1.1">subscript</csymbol><ci id="S3.p6.4.m4.1.1.2.cmml" xref="S3.p6.4.m4.1.1.2">ùë¶</ci><ci id="S3.p6.4.m4.1.1.3.cmml" xref="S3.p6.4.m4.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.4.m4.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p6.4.m4.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> for a given feature vector <math alttext="\boldsymbol{x}_{i}" class="ltx_Math" display="inline" id="S3.p6.5.m5.1"><semantics id="S3.p6.5.m5.1a"><msub id="S3.p6.5.m5.1.1" xref="S3.p6.5.m5.1.1.cmml"><mi id="S3.p6.5.m5.1.1.2" xref="S3.p6.5.m5.1.1.2.cmml">ùíô</mi><mi id="S3.p6.5.m5.1.1.3" xref="S3.p6.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p6.5.m5.1b"><apply id="S3.p6.5.m5.1.1.cmml" xref="S3.p6.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p6.5.m5.1.1.1.cmml" xref="S3.p6.5.m5.1.1">subscript</csymbol><ci id="S3.p6.5.m5.1.1.2.cmml" xref="S3.p6.5.m5.1.1.2">ùíô</ci><ci id="S3.p6.5.m5.1.1.3.cmml" xref="S3.p6.5.m5.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.5.m5.1c">\boldsymbol{x}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p6.5.m5.1d">bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> for a specific patient.</p>
</div>
<div class="ltx_para" id="S3.p7">
<p class="ltx_p" id="S3.p7.1">Several techniques can be used in order to overcome possible challenges, including imbalanced datasets and generalization to unseen data, that will be mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4" title="4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">Dataset information. The number of features includes the target labels as well.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.4" style="width:433.6pt;height:118.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.2pt,13.3pt) scale(0.81507398651888,0.81507398651888) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.1.1">Datasets</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.2.1">Source</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.3.1">Samples</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.4.1">Features</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.5.1">Classes</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S3.T1.4.1.1.1.6.1">Task</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.4.1.2.1.1">CD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib53" title="">53</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.1.2">OpenML</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.1.3">70k</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.1.4">12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.1.5">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.1.2.1.6">Binary</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.3.2">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.3.2.1">Heart Failure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib54" title="">54</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.2.2">Kaggle</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.2.3">299</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.2.4">13</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.2.5">2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.3.2.6">Binary</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.4.3">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.4.3.1">Parkinsons <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib55" title="">55</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.3.2">Kaggle</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.3.3">195</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.3.4">23</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.3.5">2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.4.3.6">Binary</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.5.4">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.5.4.1">EEG Eye State <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib56" title="">56</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.4.2">OpenML</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.4.3">15k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.4.4">15</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.4.5">2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.5.4.6">Binary</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.6.5">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.6.5.1">Eye Movements <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib57" title="">57</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.5.2">OpenML</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.5.3">11k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.5.4">28</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.5.5">3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.6.5.6">Multi-Class</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.7.6">
<td class="ltx_td ltx_align_left" id="S3.T1.4.1.7.6.1">Arcene <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib58" title="">58</a>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.6.2">OpenML</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.6.3">200</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.6.4">10k</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.6.5">2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.1.7.6.6">Binary</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.4.1.8.7.1">Prostate <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib59" title="">59</a>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.8.7.2">OpenML</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.8.7.3">102</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.8.7.4">12.6k</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.8.7.5">2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.1.8.7.6">Binary</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We evaluated the performance of GBDT models over 7 medical diagnosis datasets. Dataset information that includes the number of samples, features, classes, and the type of the task is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S3.T1" title="Table 1 ‚Ä£ 3 Problem Formulation ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1</span></a>. Cardiovascular Disease Dataset (CD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib53" title="">53</a>]</cite> contains heart disease data that consist of 70000 patient records with 11 independent features, including a binary label. The aim is to build a predictive algorithm that detects the presence of an early-stage heart disease. Heart Failure <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib54" title="">54</a>]</cite> is another heart-related dataset that contains 299 medical records of different patients who had heart failure, where each of the patients has 13 clinical features. The aim is to predict the death event for the given patient records, i.e., whether there will occur heart failure with respect to the given patient features. Parkinson‚Äôs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib55" title="">55</a>]</cite> dataset comprises several biomedical voice measurements from a total of 31 patients, where 23 of them have Parkinson‚Äôs disease. There is a total of 195 different samples from these patients, where each of them includes 22 features. These features include continuous measurements. It is used to predict the status of a given patient data, which corresponds to being healthy or having Parkinson‚Äôs disease. EEG Eye State <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib56" title="">56</a>]</cite> dataset consists of 14 features for each patient that hold values regarding the EEG measurements. These features include continuous measurements. There are nearly 15000 samples and each of them has a label indicating the eye-closed or eye-open states. It is aimed to predict the state of a patient sample using these EEG measurement features. Eye Movements <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib57" title="">57</a>]</cite> contains 27 features in which 22 of them comprises features that are commonly used in psychological studies on eye movements. The rest of the features include extra information about the samples, that each of the samples is an assignment. These assignments consist of a question, that is followed up by several answer sentences. The task is to predict the multi-class relevance label of an answer for each assignment, in which the labels are irrelevant, relevant, and the correct answer. Arcene <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib58" title="">58</a>]</cite> dataset includes several features that indicate the abundance of proteins in human sera, having a given mass value. There are 200 patient samples and nearly 10000 features in total. These features are continuous. The task is to predict patients who have cancer and patients that are healthy, according to the given features. Lastly, Prostate <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib59" title="">59</a>]</cite> dataset includes continuous features that give information regarding prostate cancer. There are 102 patient samples and nearly 12600 total features. The aim is to predict whether a given patient has prostate cancer or not.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.2.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.3.2" style="font-size:90%;">Optimal Parameters for MLP</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.4" style="width:433.6pt;height:75.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.7pt,-1.7pt) scale(1.04665212948369,1.04665212948369) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T2.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.1.1">Parameters</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.2.1">CD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.3.1">Heart F.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.4.1">Parkin.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.5.1">EEG Eye</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.6.1">Eye Mov.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.7.1">Arcene</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T2.4.1.1.1.8.1">Prostate</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.4.1.2.2.1">hidden_dim</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.2">64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.3">98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.4">100</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.5">83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.6">65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.7">80</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.1.2.2.8">85</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T2.4.1.3.3.1">n_layers</th>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.2">2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.3">5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.4">5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.5">5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.6">4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.7">3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.4.1.3.3.8">3</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T2.4.1.4.4.1">learning_rate</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.2">0.00099</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.3">0.00050</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.4">0.00058</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.5">0.00082</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.6">0.00073</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.7">0.00084</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.4.1.4.4.8">0.00092</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T3.2.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S4.T3.3.2" style="font-size:90%;">Optimal Parameters for STG</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.4" style="width:433.6pt;height:58.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.3pt,7.1pt) scale(0.802668077125813,0.802668077125813) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.1.1">Parameters</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.2.1">CD</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.3.1">Heart F.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.4.1">Parkin.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.5.1">EEG Eye</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.6.1">Eye Mov.</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.7.1">Arcene</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.4.1.1.1.8.1">Prostate</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.4.1.2.1.1">learning_rate</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.2">0.00364</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.3">0.04298</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.4">0.09809</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.5">0.04842</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.6">0.02477</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.7">0.04868</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.4.1.2.1.8">0.00984</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.4.1.3.2.1">lam</th>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.2">0.02405</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.3">0.48410</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.4">0.45500</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.5">0.00244</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.6">0.03157</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.7">0.00112</td>
<td class="ltx_td ltx_align_center" id="S4.T3.4.1.3.2.8">0.00645</td>
</tr>
<tr class="ltx_tr" id="S4.T3.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T3.4.1.4.3.1">hidden_dims</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.2">[500, 500, 10]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.3">[500, 50, 10]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.4">[500, 50, 10]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.5">[500, 50, 10]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.6">[500, 200, 20]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.7">[500, 400, 20]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.4.1.4.3.8">[500, 50, 10]</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T4.2.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S4.T4.3.2" style="font-size:90%;">Optimal Parameters for TabNet</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.4" style="width:433.6pt;height:165.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(5.0pt,-1.9pt) scale(1.02362582516192,1.02362582516192) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.1.1">Parameters</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.2.1">CD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.3.1">Heart F.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.4.1">Parkin.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.5.1">EEG Eye</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.6.1">Eye Mov.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.7.1">Arcene</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T4.4.1.1.1.8.1">Prostate</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.4.1.2.2.1">n_d</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.2">55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.3">14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.4">32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.5">9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.6">50</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.7">38</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.4.1.2.2.8">8</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.1.3.3.1">n_steps</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.2">4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.3">10</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.4">5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.5">8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.6">4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.7">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.3.3.8">10</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.1.4.4.1">gamma</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.2">1.27</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.3">1.38</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.4">1.11</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.5">1.14</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.6">1.01</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.7">1.60</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.4.4.8">1.98</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.1.5.5.1">cat_emb_dim</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.2">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.3">1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.4">2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.5">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.6">1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.7">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.5.5.8">2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.1.6.6.1">n_independent</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.2">2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.3">4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.4">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.5">2</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.6">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.7">4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.6.6.8">2</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.1.7.7.1">n_shared</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.2">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.3">4</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.4">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.5">5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.6">3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.7">1</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.7.7.8">5</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.4.1.8.8.1">momentum</th>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.2">0.016</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.3">0.095</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.4">0.23</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.5">0.0041</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.6">0.16</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.7">0.34</td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.1.8.8.8">0.40</td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T4.4.1.9.9.1">mask_type</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.2">entmax</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.3">entmax</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.4">entmax</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.5">sparsemax</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.6">entmax</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.7">entmax</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.4.1.9.9.8">entmax</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T5.2.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="S4.T5.3.2" style="font-size:90%;">Optimal Parameters for TabTransformer</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.4" style="width:433.6pt;height:138.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(20.0pt,-6.4pt) scale(1.10168307803469,1.10168307803469) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T5.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.1.1">Parameters</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.2.1">CD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.3.1">Heart F.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.4.1">Parkin.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.5.1">EEG Eye</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.6.1">Eye Mov.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.7.1">Arcene</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T5.4.1.1.1.8.1">Prostate</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.4.1.2.2.1">dim</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.2">128</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.3">64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.4">32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.5">64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.6">64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.7">256</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.4.1.2.2.8">64</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.4.1.3.3.1">depth</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.2">12</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.3">2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.4">12</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.5">6</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.6">12</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.7">1</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.3.3.8">2</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.4.1.4.4.1">heads</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.2">4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.3">2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.4">4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.5">4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.6">8</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.7">2</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.4.4.8">4</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.4.1.5.5.1">weight_decay</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.2">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.3">-6</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.4">-4</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.5">-6</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.6">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.7">-5</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.5.5.8">-6</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.4.1.6.6.1">learning_rate</th>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.2">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.3">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.4">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.5">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.6">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.7">-3</td>
<td class="ltx_td ltx_align_center" id="S4.T5.4.1.6.6.8">-3</td>
</tr>
<tr class="ltx_tr" id="S4.T5.4.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T5.4.1.7.7.1">dropout</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.2">0.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.3">0.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.4">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.5">0.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.6">0.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.7">0.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.4.1.7.7.8">0.2</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T6.2.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="S4.T6.3.2" style="font-size:90%;">Optimal Parameters for VIME</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T6.4" style="width:433.6pt;height:98.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(19.1pt,-4.3pt) scale(1.09634421272852,1.09634421272852) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.1.1">Parameters</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.2.1">CD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.3.1">Heart F.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.4.1">Parkin.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.5.1">EEG Eye</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.6.1">Eye Mov.</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.7.1">Arcene</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T6.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T6.4.1.1.1.8.1">Prostate</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.4.1.2.2.1">p_m</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.2">0.7197</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.3">0.6619</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.4">0.8315</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.5">0.5839</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.6">0.6613</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.7">0.2758</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.4.1.2.2.8">0.7594</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.1.3.3.1">alpha</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.2">6.0055</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.3">0.3545</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.4">4.1976</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.5">4.7264</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.6">2.4494</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.7">8.6216</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.3.3.8">7.0457</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.4.1.4.4.1">K</th>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.2">20</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.3">3</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.4">2</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.5">20</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.6">2</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.7">5</td>
<td class="ltx_td ltx_align_center" id="S4.T6.4.1.4.4.8">10</td>
</tr>
<tr class="ltx_tr" id="S4.T6.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T6.4.1.5.5.1">beta</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.2">0.2070</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.3">0.3099</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.4">0.3812</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.5">0.1080</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.6">0.4152</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.7">2.4450</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.4.1.5.5.8">4.9083</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Data Preprocessing</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Data is preprocessed in the same way for each of the models by applying ordinal encoding to the categorical values, and zero mean, unit variance normalization for numerical features. Furthermore, the categorical features are explicitly specified for the deep neural networks requiring further information on these features, for TabNet and TabTransformer, since their functionality depends on learning appropriate embedding of such features.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training Procedure</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We compared 5 traditional ML methods, which are SVM, Logistic Regression, KNN, Decision Tree, and Linear Discriminant Analysis (LDA), and 5 DL models, which are Multilayer Perceptron (MLP), STG, TabNet, TabTransformer, and VIME, with 4 ensemble models including Random Forest, 3 of them being GBDT models that are XGBoost, LightGBM, and CatBoost, over the different medical datasets in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S3.T1" title="Table 1 ‚Ä£ 3 Problem Formulation ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">We selected ROC AUC score as our comparison metric. ROC AUC score is the area under the ROC curve that summarizes the the classifier performance with different decision thresholds, and it is a plot of true positive rate (TPR) against the false positive rate (FPR). It is a commonly used metric in comparing multiple models due to its drift tolerance in class balances and reliability in imbalanced data. Hence, we utilized ROC AUC score for both the optimization of the hyperparameters, which is explained below at section <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS4" title="4.4 Hyperparameter Optimization ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">4.4</span></a>, and the comparison of different models for each dataset.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">In order to evaluate the best-performing model for each respective dataset, we employed 8-fold stratified cross-validation. We performed the cross-validation by splitting the whole data into 8 parts, taking 7 folds as training and 1 fold as validation, and taking the average and standard deviation of the ROC AUC scores after repeating this process 8 times. Shuffling is set to True by keeping the same seed for every dataset and model for fair comparison and reproducibility. This technique mitigates the unbalanced data factor that may create a bias in the classification performance. Using each part of the data ensures better generalization rather than selecting a specific part of the data.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Hyperparameter Optimization</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Each of the models is optimized over each of the respective datasets in terms of selecting the best combination of hyperparameters. For every model, best-resulting hyperparameter settings are taken with respect to the datasets by evaluating the average ROC AUC score of the 8-folds for each different hyperparameter combination. The hyperparameter combination that reaches the highest average ROC AUC score of the cross-validation is considered as the optimal setting.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">Traditional ML algorithms and ensemble models are easier to optimize compared to deep neural networks due to their less complex architectures.  For the deep learning models, each hyperparameter combination setup is trained for 1000 epochs with an early stopping criterion with 100 epochs patience. On average, 36 different combinations are evaluated for each model, in which the best combination is taken as the best performance of the specific model for comparison. Optimized hyperparameters for the DL architectures with respect to the datasets are shown in Table‚Äôs <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.T2" title="Table 2 ‚Ä£ 4.1 Datasets ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">2</span></a> - <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.T6" title="Table 6 ‚Ä£ 4.1 Datasets ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Results</h3>
<figure class="ltx_table" id="S4.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T7.2.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="S4.T7.3.2" style="font-size:90%;">ROC AUC scores for the traditional ML models, state-of-the-art tabular DL methods, and GBDT models on different datasets. Higher is better. The best is bolded, and the second best is underlined.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T7.4" style="width:433.6pt;height:142.8pt;vertical-align:-0.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-194.5pt,63.8pt) scale(0.527063008427323,0.527063008427323) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T7.4.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.1.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.2.1">CD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.3.1">Heart Failure</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.4.1">Parkinsons</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.5.1">EEG Eye State</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.6.1">Eye Movements</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.7.1">Arcene</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S4.T7.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.8.1">Prostate</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.4.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.1.1.9.1">Avg. Rank</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.4.1.2.2.1">SVM</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.2">78.715 ¬± 0.005</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.3">86.389 ¬± 0.048</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.4">88.791 ¬± 0.068</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.5">70.752 ¬± 0.013</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.6">78.405 ¬± 0.007</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.7">87.094 ¬± 0.043</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.4.1.2.2.8">91.419 ¬± 0.096</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.2.2.9">9.857</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.3.3.1">Logistic Reg.</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.2">78.435 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.3">87.571 ¬± 0.051</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.4">90.875 ¬± 0.041</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.5">61.125 ¬± 0.014</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.6">71.180 ¬± 0.009</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.7"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.3.3.7.1">95.211 ¬± 0.031</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.3.3.8">95.089 ¬± 0.065</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.3.3.9">8.143</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.4.4.1">KNN</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.2">69.611 ¬± 0.006</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.3">77.529 ¬± 0.067</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.4">96.857 ¬± 0.023</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.5">91.185 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.6">72.448 ¬± 0.009</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.7">90.869 ¬± 0.065</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.4.4.8">87.822 ¬± 0.112</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.4.4.9">9.857</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.5.5.1">Random Forest</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.2">77.464 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.3">91.233 ¬± 0.038</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.4">96.068 ¬± 0.033</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.5"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.5.5.5.1">98.404 ¬± 0.002</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.6">87.234 ¬± 0.007</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.7">91.153 ¬± 0.034</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.5.5.8">93.155 ¬± 0.078</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.5.5.9">6.000</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.6.6.1">Decision Tree</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.2">63.325 ¬± 0.006</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.3">71.646 ¬± 0.051</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.4">81.287 ¬± 0.060</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.5">83.781 ¬± 0.008</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.6">70.951 ¬± 0.009</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.7">72.037 ¬± 0.116</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.6.6.8">80.357 ¬± 0.106</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.6.6.9">12.714</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.7.7.1">LDA</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.2">70.363 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.3">87.896 ¬± 0.053</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.4">88.609 ¬± 0.060</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.5">67.130 ¬± 0.014</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.6">71.273 ¬± 0.010</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.7">69.927 ¬± 0.124</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.7.7.8">93.849 ¬± 0.060</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.7.7.9">10.571</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.4.1.8.8.1">MLP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib60" title="">60</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.2">80.090 ¬± 0.005</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.3">87.288 ¬± 0.056</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.4">97.186 ¬± 0.022</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.5">95.513 ¬± 0.006</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.6">73.397 ¬± 0.015</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.7">93.669 ¬± 0.042</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.4.1.8.8.8">89.881 ¬± 0.108</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.8.8.9">6.429</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.9.9.1">STG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib37" title="">37</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.2">79.667 ¬± 0.004</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.3">86.241 ¬± 0.058</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.4">95.352 ¬± 0.038</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.5">84.854 ¬± 0.011</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.6">80.780 ¬± 0.006</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.7">90.584 ¬± 0.062</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.9.9.8">94.048 ¬± 0.094</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.9.9.9">7.857</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.10.10.1">TabNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib9" title="">9</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.2">77.757 ¬± 0.004</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.3"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.10.10.3.1">93.319 ¬± 0.037</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.4"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.10.10.4.1">99.446 ¬± 0.012</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.5">62.441 ¬± 0.040</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.6">87.673 ¬± 0.008</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.7">87.662 ¬± 0.098</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.10.10.8">66.865 ¬± 0.205</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.10.10.9">7.429</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.11.11.1">TabTransformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib36" title="">36</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.2">71.327 ¬± 0.123</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.3">87.642 ¬± 0.069</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.4">96.625 ¬± 0.027</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.5">79.646 ¬± 0.039</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.6">70.534 ¬± 0.010</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.11.11.7.1">94.724 ¬± 0.051</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.11.11.8">92.956 ¬± 0.107</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.11.11.9">8.571</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.12.12.1">VIME <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib38" title="">38</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.2">78.882 ¬± 0.004</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.3">85.758 ¬± 0.047</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.4">98.532 ¬± 0.016</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.5">92.473 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.6">81.918 ¬± 0.008</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.7">91.721 ¬± 0.070</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.12.12.8">52.679 ¬± 0.164</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.12.12.9">7.429</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.4.1.13.13.1">XGBoost <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib49" title="">49</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.2">79.745 ¬± 0.004</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.3">90.478 ¬± 0.025</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.4">97.265 ¬± 0.023</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.13.13.5.1">98.331 ¬± 0.002</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.6"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.13.13.6.1">89.675 ¬± 0.008</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.7">89.123 ¬± 0.047</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T7.4.1.13.13.8">94.940 ¬± 0.055</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.4.1.13.13.9">4.429</td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.4.1.14.14.1">LightGBM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib50" title="">50</a>]</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.14.14.2.1">80.296 ¬± 0.004</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.14.14.3.1">91.490 ¬± 0.027</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.14.14.4.1">98.623 ¬± 0.015</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.5">97.008 ¬± 0.004</td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.14.14.6.1">89.059 ¬± 0.007</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.7">91.883 ¬± 0.043</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T7.4.1.14.14.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.14.14.8.1">95.486 ¬± 0.052</span></td>
<td class="ltx_td ltx_align_center" id="S4.T7.4.1.14.14.9"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.14.14.9.1">2.571</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.4.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T7.4.1.15.15.1">CatBoost <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib51" title="">51</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.2"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.15.15.2.1">80.378 ¬± 0.004</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.3">91.056 ¬± 0.034</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.4">97.740 ¬± 0.014</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.5">97.739 ¬± 0.003</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.6">88.954 ¬± 0.006</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.7">91.396 ¬± 0.040</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T7.4.1.15.15.8"><span class="ltx_text ltx_font_bold" id="S4.T7.4.1.15.15.8.1">96.379 ¬± 0.053</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.4.1.15.15.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T7.4.1.15.15.9.1">3.143</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="S4.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T8.2.1.1" style="font-size:90%;">Table 8</span>: </span><span class="ltx_text" id="S4.T8.3.2" style="font-size:90%;">Different metric scores for highest ranked (LightGBM) model on different datasets.</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T8.4" style="width:433.6pt;height:78.2pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-85.4pt,15.3pt) scale(0.717533087948638,0.717533087948638) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T8.4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T8.4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T8.4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.1.1">Metrics</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.2.1">CD</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.3.1">Heart Failure</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.4.1">Parkinsons</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.5.1">EEG Eye State</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.6.1">Eye Movements</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.7.1">Arcene</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.4.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T8.4.1.1.1.8.1">Prostate</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T8.4.1.2.1.1">Accuracy</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.2">73.636 ¬± 0.005</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.3">85.615 ¬± 0.045</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.4">95.375 ¬± 0.033</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.5">90.427 ¬± 0.012</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.6">71.726 ¬± 0.012</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.7">81.500 ¬± 0.044</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T8.4.1.2.1.8">91.186 ¬± 0.046</td>
</tr>
<tr class="ltx_tr" id="S4.T8.4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.4.1.3.2.1">F1 Score</th>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.2">73.598 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.3">85.296 ¬± 0.045</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.4">95.284 ¬± 0.034</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.5">90.407 ¬± 0.007</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.6">71.766 ¬± 0.012</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.7">81.428 ¬± 0.045</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.3.2.8">91.113 ¬± 0.046</td>
</tr>
<tr class="ltx_tr" id="S4.T8.4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.4.1.4.3.1">ROC AUC</th>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.2">80.296 ¬± 0.004</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.3">91.490 ¬± 0.027</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.4">98.623 ¬± 0.015</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.5">97.008 ¬± 0.004</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.6">89.059 ¬± 0.007</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.7">91.883 ¬± 0.043</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.4.3.8">95.486 ¬± 0.052</td>
</tr>
<tr class="ltx_tr" id="S4.T8.4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T8.4.1.5.4.1">Precision</th>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.2">75.538 ¬± 0.005</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.3">82.814 ¬± 0.119</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.4">96.118 ¬± 0.035</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.5">90.883 ¬± 0.009</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.6">71.848 ¬± 0.012</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.7">84.305 ¬± 0.062</td>
<td class="ltx_td ltx_align_center" id="S4.T8.4.1.5.4.8">91.443 ¬± 0.092</td>
</tr>
<tr class="ltx_tr" id="S4.T8.4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T8.4.1.6.5.1">Recall</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.2">69.865 ¬± 0.007</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.3">72.917 ¬± 0.130</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.4">97.953 ¬± 0.026</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.5">87.446 ¬± 0.010</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.6">71.726 ¬± 0.012</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.7">83.036 ¬± 0.050</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T8.4.1.6.5.8">91.667 ¬± 0.083</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">Overall results are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.T7" title="Table 7 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">7</span></a>. Best models are selected by comparing the average ROC AUC scores of the 8-folds over each respective dataset. For the multi-class problem in the Eye Movements dataset, ‚Äôone-vs-one‚Äô configuration of the ROC AUC scores are reported. Each result also includes the standard deviation between the different fold results. According to the performances, each model is ranked with respect to the results on each of the datasets, and their average ranks are reported at the end of the table. It can be inferred that GBDT consistently outperforms both the traditional ML methods and the state-of-the-art tabular DL models regardless of the dataset sample size. They perform well in both small sized (e.g. Prostate) and large sized (e.g. CD) datasets. Top-3 ranks consist of the three proposed GBDT models, which demonstrate the overall superior performance of the GBDT over the other traditional ML and tabular DL methods in medical diagnosis tasks.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">Furthermore, the average ROC AUC scores and average training times of the models are compared. Some examples are visualized over a common plot at Fig.‚Äôs <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F1" title="Figure 1 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F2" title="Figure 2 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">2</span></a>. Although most tabular DL models perform well on some of the datasets, their average training times are much higher than the training times of GBDT and traditional ML models due to their complex architectures. Having superior performance over the other models, GBDT possesses the optimal structure in terms of performance and time consumption.</p>
</div>
<div class="ltx_para" id="S4.SS5.p3">
<p class="ltx_p" id="S4.SS5.p3.1">Consequently, different metric scores for the highest ranked GBDT model in average, which is LightGBM, are shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.T8" title="Table 8 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">8</span></a>. Metrics are Accuracy, F1 Score, ROC AUC Score (same as in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.T7" title="Table 7 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">7</span></a>), Precision, and Recall. Again, the average and standard deviation of the fold scores are reported. Respective formulas for the metrics are represented at Eq‚Äôs (<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.E3" title="In 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">3</span></a>) - (<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.E6" title="In 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">6</span></a>) except ROC AUC, which is defined in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.SS4" title="4.4 Hyperparameter Optimization ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">4.4</span></a>. <span class="ltx_text ltx_font_italic" id="S4.SS5.p3.1.1">TP</span>, <span class="ltx_text ltx_font_italic" id="S4.SS5.p3.1.2">FP</span>, <span class="ltx_text ltx_font_italic" id="S4.SS5.p3.1.3">TN</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS5.p3.1.4">FN</span> are defined as true positives, false positives, true negatives, and false negatives respectively. Regarding the multi-class problem in the Eye Movements dataset, weighted averages of the label scores are reported for F1 Score, Recall, and Precision metrics.</p>
</div>
<figure class="ltx_figure" id="S4.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S4.F1.sf1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F1.sf1.3.2" style="font-size:90%;">CD dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S4.F1.sf2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F1.sf2.3.2" style="font-size:90%;">EEG Eye State dataset</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S4.F1.3.2" style="font-size:90%;">ROC AUC score vs avg. training time comparisons for (a) CD and (b) EEG Eye State datasets</span></figcaption>
</figure>
<div class="ltx_para" id="S4.SS5.p4">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx3">
<tbody id="S4.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{{Accuracy}}=\frac{TP+FP}{TP+FP+TN+FN}" class="ltx_Math" display="inline" id="S4.E3.m1.1"><semantics id="S4.E3.m1.1a"><mrow id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S4.E3.m1.1.1.2" xref="S4.E3.m1.1.1.2a.cmml">Accuracy</mtext><mo id="S4.E3.m1.1.1.1" xref="S4.E3.m1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E3.m1.1.1.3" xref="S4.E3.m1.1.1.3.cmml"><mfrac id="S4.E3.m1.1.1.3a" xref="S4.E3.m1.1.1.3.cmml"><mrow id="S4.E3.m1.1.1.3.2" xref="S4.E3.m1.1.1.3.2.cmml"><mrow id="S4.E3.m1.1.1.3.2.2" xref="S4.E3.m1.1.1.3.2.2.cmml"><mi id="S4.E3.m1.1.1.3.2.2.2" xref="S4.E3.m1.1.1.3.2.2.2.cmml">T</mi><mo id="S4.E3.m1.1.1.3.2.2.1" xref="S4.E3.m1.1.1.3.2.2.1.cmml">‚Å¢</mo><mi id="S4.E3.m1.1.1.3.2.2.3" xref="S4.E3.m1.1.1.3.2.2.3.cmml">P</mi></mrow><mo id="S4.E3.m1.1.1.3.2.1" xref="S4.E3.m1.1.1.3.2.1.cmml">+</mo><mrow id="S4.E3.m1.1.1.3.2.3" xref="S4.E3.m1.1.1.3.2.3.cmml"><mi id="S4.E3.m1.1.1.3.2.3.2" xref="S4.E3.m1.1.1.3.2.3.2.cmml">F</mi><mo id="S4.E3.m1.1.1.3.2.3.1" xref="S4.E3.m1.1.1.3.2.3.1.cmml">‚Å¢</mo><mi id="S4.E3.m1.1.1.3.2.3.3" xref="S4.E3.m1.1.1.3.2.3.3.cmml">P</mi></mrow></mrow><mrow id="S4.E3.m1.1.1.3.3" xref="S4.E3.m1.1.1.3.3.cmml"><mrow id="S4.E3.m1.1.1.3.3.2" xref="S4.E3.m1.1.1.3.3.2.cmml"><mi id="S4.E3.m1.1.1.3.3.2.2" xref="S4.E3.m1.1.1.3.3.2.2.cmml">T</mi><mo id="S4.E3.m1.1.1.3.3.2.1" xref="S4.E3.m1.1.1.3.3.2.1.cmml">‚Å¢</mo><mi id="S4.E3.m1.1.1.3.3.2.3" xref="S4.E3.m1.1.1.3.3.2.3.cmml">P</mi></mrow><mo id="S4.E3.m1.1.1.3.3.1" xref="S4.E3.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E3.m1.1.1.3.3.3" xref="S4.E3.m1.1.1.3.3.3.cmml"><mi id="S4.E3.m1.1.1.3.3.3.2" xref="S4.E3.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E3.m1.1.1.3.3.3.1" xref="S4.E3.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S4.E3.m1.1.1.3.3.3.3" xref="S4.E3.m1.1.1.3.3.3.3.cmml">P</mi></mrow><mo id="S4.E3.m1.1.1.3.3.1a" xref="S4.E3.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E3.m1.1.1.3.3.4" xref="S4.E3.m1.1.1.3.3.4.cmml"><mi id="S4.E3.m1.1.1.3.3.4.2" xref="S4.E3.m1.1.1.3.3.4.2.cmml">T</mi><mo id="S4.E3.m1.1.1.3.3.4.1" xref="S4.E3.m1.1.1.3.3.4.1.cmml">‚Å¢</mo><mi id="S4.E3.m1.1.1.3.3.4.3" xref="S4.E3.m1.1.1.3.3.4.3.cmml">N</mi></mrow><mo id="S4.E3.m1.1.1.3.3.1b" xref="S4.E3.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E3.m1.1.1.3.3.5" xref="S4.E3.m1.1.1.3.3.5.cmml"><mi id="S4.E3.m1.1.1.3.3.5.2" xref="S4.E3.m1.1.1.3.3.5.2.cmml">F</mi><mo id="S4.E3.m1.1.1.3.3.5.1" xref="S4.E3.m1.1.1.3.3.5.1.cmml">‚Å¢</mo><mi id="S4.E3.m1.1.1.3.3.5.3" xref="S4.E3.m1.1.1.3.3.5.3.cmml">N</mi></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.1b"><apply id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1"><eq id="S4.E3.m1.1.1.1.cmml" xref="S4.E3.m1.1.1.1"></eq><ci id="S4.E3.m1.1.1.2a.cmml" xref="S4.E3.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S4.E3.m1.1.1.2.cmml" xref="S4.E3.m1.1.1.2">Accuracy</mtext></ci><apply id="S4.E3.m1.1.1.3.cmml" xref="S4.E3.m1.1.1.3"><divide id="S4.E3.m1.1.1.3.1.cmml" xref="S4.E3.m1.1.1.3"></divide><apply id="S4.E3.m1.1.1.3.2.cmml" xref="S4.E3.m1.1.1.3.2"><plus id="S4.E3.m1.1.1.3.2.1.cmml" xref="S4.E3.m1.1.1.3.2.1"></plus><apply id="S4.E3.m1.1.1.3.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2"><times id="S4.E3.m1.1.1.3.2.2.1.cmml" xref="S4.E3.m1.1.1.3.2.2.1"></times><ci id="S4.E3.m1.1.1.3.2.2.2.cmml" xref="S4.E3.m1.1.1.3.2.2.2">ùëá</ci><ci id="S4.E3.m1.1.1.3.2.2.3.cmml" xref="S4.E3.m1.1.1.3.2.2.3">ùëÉ</ci></apply><apply id="S4.E3.m1.1.1.3.2.3.cmml" xref="S4.E3.m1.1.1.3.2.3"><times id="S4.E3.m1.1.1.3.2.3.1.cmml" xref="S4.E3.m1.1.1.3.2.3.1"></times><ci id="S4.E3.m1.1.1.3.2.3.2.cmml" xref="S4.E3.m1.1.1.3.2.3.2">ùêπ</ci><ci id="S4.E3.m1.1.1.3.2.3.3.cmml" xref="S4.E3.m1.1.1.3.2.3.3">ùëÉ</ci></apply></apply><apply id="S4.E3.m1.1.1.3.3.cmml" xref="S4.E3.m1.1.1.3.3"><plus id="S4.E3.m1.1.1.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.1"></plus><apply id="S4.E3.m1.1.1.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.2"><times id="S4.E3.m1.1.1.3.3.2.1.cmml" xref="S4.E3.m1.1.1.3.3.2.1"></times><ci id="S4.E3.m1.1.1.3.3.2.2.cmml" xref="S4.E3.m1.1.1.3.3.2.2">ùëá</ci><ci id="S4.E3.m1.1.1.3.3.2.3.cmml" xref="S4.E3.m1.1.1.3.3.2.3">ùëÉ</ci></apply><apply id="S4.E3.m1.1.1.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3"><times id="S4.E3.m1.1.1.3.3.3.1.cmml" xref="S4.E3.m1.1.1.3.3.3.1"></times><ci id="S4.E3.m1.1.1.3.3.3.2.cmml" xref="S4.E3.m1.1.1.3.3.3.2">ùêπ</ci><ci id="S4.E3.m1.1.1.3.3.3.3.cmml" xref="S4.E3.m1.1.1.3.3.3.3">ùëÉ</ci></apply><apply id="S4.E3.m1.1.1.3.3.4.cmml" xref="S4.E3.m1.1.1.3.3.4"><times id="S4.E3.m1.1.1.3.3.4.1.cmml" xref="S4.E3.m1.1.1.3.3.4.1"></times><ci id="S4.E3.m1.1.1.3.3.4.2.cmml" xref="S4.E3.m1.1.1.3.3.4.2">ùëá</ci><ci id="S4.E3.m1.1.1.3.3.4.3.cmml" xref="S4.E3.m1.1.1.3.3.4.3">ùëÅ</ci></apply><apply id="S4.E3.m1.1.1.3.3.5.cmml" xref="S4.E3.m1.1.1.3.3.5"><times id="S4.E3.m1.1.1.3.3.5.1.cmml" xref="S4.E3.m1.1.1.3.3.5.1"></times><ci id="S4.E3.m1.1.1.3.3.5.2.cmml" xref="S4.E3.m1.1.1.3.3.5.2">ùêπ</ci><ci id="S4.E3.m1.1.1.3.3.5.3.cmml" xref="S4.E3.m1.1.1.3.3.5.3">ùëÅ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.1c">\displaystyle\text{{Accuracy}}=\frac{TP+FP}{TP+FP+TN+FN}</annotation><annotation encoding="application/x-llamapun" id="S4.E3.m1.1d">Accuracy = divide start_ARG italic_T italic_P + italic_F italic_P end_ARG start_ARG italic_T italic_P + italic_F italic_P + italic_T italic_N + italic_F italic_N end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS5.p5">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx4">
<tbody id="S4.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{{F1 Score}}=\frac{2\times TP}{2\times TP+FP+FN}" class="ltx_Math" display="inline" id="S4.E4.m1.1"><semantics id="S4.E4.m1.1a"><mrow id="S4.E4.m1.1.1" xref="S4.E4.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S4.E4.m1.1.1.2" xref="S4.E4.m1.1.1.2a.cmml">F1 Score</mtext><mo id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E4.m1.1.1.3" xref="S4.E4.m1.1.1.3.cmml"><mfrac id="S4.E4.m1.1.1.3a" xref="S4.E4.m1.1.1.3.cmml"><mrow id="S4.E4.m1.1.1.3.2" xref="S4.E4.m1.1.1.3.2.cmml"><mrow id="S4.E4.m1.1.1.3.2.2" xref="S4.E4.m1.1.1.3.2.2.cmml"><mn id="S4.E4.m1.1.1.3.2.2.2" xref="S4.E4.m1.1.1.3.2.2.2.cmml">2</mn><mo id="S4.E4.m1.1.1.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S4.E4.m1.1.1.3.2.2.1.cmml">√ó</mo><mi id="S4.E4.m1.1.1.3.2.2.3" xref="S4.E4.m1.1.1.3.2.2.3.cmml">T</mi></mrow><mo id="S4.E4.m1.1.1.3.2.1" xref="S4.E4.m1.1.1.3.2.1.cmml">‚Å¢</mo><mi id="S4.E4.m1.1.1.3.2.3" xref="S4.E4.m1.1.1.3.2.3.cmml">P</mi></mrow><mrow id="S4.E4.m1.1.1.3.3" xref="S4.E4.m1.1.1.3.3.cmml"><mrow id="S4.E4.m1.1.1.3.3.2" xref="S4.E4.m1.1.1.3.3.2.cmml"><mrow id="S4.E4.m1.1.1.3.3.2.2" xref="S4.E4.m1.1.1.3.3.2.2.cmml"><mn id="S4.E4.m1.1.1.3.3.2.2.2" xref="S4.E4.m1.1.1.3.3.2.2.2.cmml">2</mn><mo id="S4.E4.m1.1.1.3.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="S4.E4.m1.1.1.3.3.2.2.1.cmml">√ó</mo><mi id="S4.E4.m1.1.1.3.3.2.2.3" xref="S4.E4.m1.1.1.3.3.2.2.3.cmml">T</mi></mrow><mo id="S4.E4.m1.1.1.3.3.2.1" xref="S4.E4.m1.1.1.3.3.2.1.cmml">‚Å¢</mo><mi id="S4.E4.m1.1.1.3.3.2.3" xref="S4.E4.m1.1.1.3.3.2.3.cmml">P</mi></mrow><mo id="S4.E4.m1.1.1.3.3.1" xref="S4.E4.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E4.m1.1.1.3.3.3" xref="S4.E4.m1.1.1.3.3.3.cmml"><mi id="S4.E4.m1.1.1.3.3.3.2" xref="S4.E4.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E4.m1.1.1.3.3.3.1" xref="S4.E4.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S4.E4.m1.1.1.3.3.3.3" xref="S4.E4.m1.1.1.3.3.3.3.cmml">P</mi></mrow><mo id="S4.E4.m1.1.1.3.3.1a" xref="S4.E4.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E4.m1.1.1.3.3.4" xref="S4.E4.m1.1.1.3.3.4.cmml"><mi id="S4.E4.m1.1.1.3.3.4.2" xref="S4.E4.m1.1.1.3.3.4.2.cmml">F</mi><mo id="S4.E4.m1.1.1.3.3.4.1" xref="S4.E4.m1.1.1.3.3.4.1.cmml">‚Å¢</mo><mi id="S4.E4.m1.1.1.3.3.4.3" xref="S4.E4.m1.1.1.3.3.4.3.cmml">N</mi></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.1b"><apply id="S4.E4.m1.1.1.cmml" xref="S4.E4.m1.1.1"><eq id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"></eq><ci id="S4.E4.m1.1.1.2a.cmml" xref="S4.E4.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S4.E4.m1.1.1.2.cmml" xref="S4.E4.m1.1.1.2">F1 Score</mtext></ci><apply id="S4.E4.m1.1.1.3.cmml" xref="S4.E4.m1.1.1.3"><divide id="S4.E4.m1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.3"></divide><apply id="S4.E4.m1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.3.2"><times id="S4.E4.m1.1.1.3.2.1.cmml" xref="S4.E4.m1.1.1.3.2.1"></times><apply id="S4.E4.m1.1.1.3.2.2.cmml" xref="S4.E4.m1.1.1.3.2.2"><times id="S4.E4.m1.1.1.3.2.2.1.cmml" xref="S4.E4.m1.1.1.3.2.2.1"></times><cn id="S4.E4.m1.1.1.3.2.2.2.cmml" type="integer" xref="S4.E4.m1.1.1.3.2.2.2">2</cn><ci id="S4.E4.m1.1.1.3.2.2.3.cmml" xref="S4.E4.m1.1.1.3.2.2.3">ùëá</ci></apply><ci id="S4.E4.m1.1.1.3.2.3.cmml" xref="S4.E4.m1.1.1.3.2.3">ùëÉ</ci></apply><apply id="S4.E4.m1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.3.3"><plus id="S4.E4.m1.1.1.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.1"></plus><apply id="S4.E4.m1.1.1.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.2"><times id="S4.E4.m1.1.1.3.3.2.1.cmml" xref="S4.E4.m1.1.1.3.3.2.1"></times><apply id="S4.E4.m1.1.1.3.3.2.2.cmml" xref="S4.E4.m1.1.1.3.3.2.2"><times id="S4.E4.m1.1.1.3.3.2.2.1.cmml" xref="S4.E4.m1.1.1.3.3.2.2.1"></times><cn id="S4.E4.m1.1.1.3.3.2.2.2.cmml" type="integer" xref="S4.E4.m1.1.1.3.3.2.2.2">2</cn><ci id="S4.E4.m1.1.1.3.3.2.2.3.cmml" xref="S4.E4.m1.1.1.3.3.2.2.3">ùëá</ci></apply><ci id="S4.E4.m1.1.1.3.3.2.3.cmml" xref="S4.E4.m1.1.1.3.3.2.3">ùëÉ</ci></apply><apply id="S4.E4.m1.1.1.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.3"><times id="S4.E4.m1.1.1.3.3.3.1.cmml" xref="S4.E4.m1.1.1.3.3.3.1"></times><ci id="S4.E4.m1.1.1.3.3.3.2.cmml" xref="S4.E4.m1.1.1.3.3.3.2">ùêπ</ci><ci id="S4.E4.m1.1.1.3.3.3.3.cmml" xref="S4.E4.m1.1.1.3.3.3.3">ùëÉ</ci></apply><apply id="S4.E4.m1.1.1.3.3.4.cmml" xref="S4.E4.m1.1.1.3.3.4"><times id="S4.E4.m1.1.1.3.3.4.1.cmml" xref="S4.E4.m1.1.1.3.3.4.1"></times><ci id="S4.E4.m1.1.1.3.3.4.2.cmml" xref="S4.E4.m1.1.1.3.3.4.2">ùêπ</ci><ci id="S4.E4.m1.1.1.3.3.4.3.cmml" xref="S4.E4.m1.1.1.3.3.4.3">ùëÅ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.1c">\displaystyle\text{{F1 Score}}=\frac{2\times TP}{2\times TP+FP+FN}</annotation><annotation encoding="application/x-llamapun" id="S4.E4.m1.1d">F1 Score = divide start_ARG 2 √ó italic_T italic_P end_ARG start_ARG 2 √ó italic_T italic_P + italic_F italic_P + italic_F italic_N end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS5.p6">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx5">
<tbody id="S4.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{{Recall}}=\frac{TP}{TP+FN}" class="ltx_Math" display="inline" id="S4.E5.m1.1"><semantics id="S4.E5.m1.1a"><mrow id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.1.1.2" xref="S4.E5.m1.1.1.2a.cmml">Recall</mtext><mo id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E5.m1.1.1.3" xref="S4.E5.m1.1.1.3.cmml"><mfrac id="S4.E5.m1.1.1.3a" xref="S4.E5.m1.1.1.3.cmml"><mrow id="S4.E5.m1.1.1.3.2" xref="S4.E5.m1.1.1.3.2.cmml"><mi id="S4.E5.m1.1.1.3.2.2" xref="S4.E5.m1.1.1.3.2.2.cmml">T</mi><mo id="S4.E5.m1.1.1.3.2.1" xref="S4.E5.m1.1.1.3.2.1.cmml">‚Å¢</mo><mi id="S4.E5.m1.1.1.3.2.3" xref="S4.E5.m1.1.1.3.2.3.cmml">P</mi></mrow><mrow id="S4.E5.m1.1.1.3.3" xref="S4.E5.m1.1.1.3.3.cmml"><mrow id="S4.E5.m1.1.1.3.3.2" xref="S4.E5.m1.1.1.3.3.2.cmml"><mi id="S4.E5.m1.1.1.3.3.2.2" xref="S4.E5.m1.1.1.3.3.2.2.cmml">T</mi><mo id="S4.E5.m1.1.1.3.3.2.1" xref="S4.E5.m1.1.1.3.3.2.1.cmml">‚Å¢</mo><mi id="S4.E5.m1.1.1.3.3.2.3" xref="S4.E5.m1.1.1.3.3.2.3.cmml">P</mi></mrow><mo id="S4.E5.m1.1.1.3.3.1" xref="S4.E5.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E5.m1.1.1.3.3.3" xref="S4.E5.m1.1.1.3.3.3.cmml"><mi id="S4.E5.m1.1.1.3.3.3.2" xref="S4.E5.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E5.m1.1.1.3.3.3.1" xref="S4.E5.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S4.E5.m1.1.1.3.3.3.3" xref="S4.E5.m1.1.1.3.3.3.3.cmml">N</mi></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><apply id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.1.1"><eq id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"></eq><ci id="S4.E5.m1.1.1.2a.cmml" xref="S4.E5.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S4.E5.m1.1.1.2.cmml" xref="S4.E5.m1.1.1.2">Recall</mtext></ci><apply id="S4.E5.m1.1.1.3.cmml" xref="S4.E5.m1.1.1.3"><divide id="S4.E5.m1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.3"></divide><apply id="S4.E5.m1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.3.2"><times id="S4.E5.m1.1.1.3.2.1.cmml" xref="S4.E5.m1.1.1.3.2.1"></times><ci id="S4.E5.m1.1.1.3.2.2.cmml" xref="S4.E5.m1.1.1.3.2.2">ùëá</ci><ci id="S4.E5.m1.1.1.3.2.3.cmml" xref="S4.E5.m1.1.1.3.2.3">ùëÉ</ci></apply><apply id="S4.E5.m1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.3.3"><plus id="S4.E5.m1.1.1.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3.1"></plus><apply id="S4.E5.m1.1.1.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.2"><times id="S4.E5.m1.1.1.3.3.2.1.cmml" xref="S4.E5.m1.1.1.3.3.2.1"></times><ci id="S4.E5.m1.1.1.3.3.2.2.cmml" xref="S4.E5.m1.1.1.3.3.2.2">ùëá</ci><ci id="S4.E5.m1.1.1.3.3.2.3.cmml" xref="S4.E5.m1.1.1.3.3.2.3">ùëÉ</ci></apply><apply id="S4.E5.m1.1.1.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3"><times id="S4.E5.m1.1.1.3.3.3.1.cmml" xref="S4.E5.m1.1.1.3.3.3.1"></times><ci id="S4.E5.m1.1.1.3.3.3.2.cmml" xref="S4.E5.m1.1.1.3.3.3.2">ùêπ</ci><ci id="S4.E5.m1.1.1.3.3.3.3.cmml" xref="S4.E5.m1.1.1.3.3.3.3">ùëÅ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">\displaystyle\text{{Recall}}=\frac{TP}{TP+FN}</annotation><annotation encoding="application/x-llamapun" id="S4.E5.m1.1d">Recall = divide start_ARG italic_T italic_P end_ARG start_ARG italic_T italic_P + italic_F italic_N end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS5.p7">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx6">
<tbody id="S4.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\text{{Precision}}=\frac{TP}{TP+FP}" class="ltx_Math" display="inline" id="S4.E6.m1.1"><semantics id="S4.E6.m1.1a"><mrow id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S4.E6.m1.1.1.2" xref="S4.E6.m1.1.1.2a.cmml">Precision</mtext><mo id="S4.E6.m1.1.1.1" xref="S4.E6.m1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E6.m1.1.1.3" xref="S4.E6.m1.1.1.3.cmml"><mfrac id="S4.E6.m1.1.1.3a" xref="S4.E6.m1.1.1.3.cmml"><mrow id="S4.E6.m1.1.1.3.2" xref="S4.E6.m1.1.1.3.2.cmml"><mi id="S4.E6.m1.1.1.3.2.2" xref="S4.E6.m1.1.1.3.2.2.cmml">T</mi><mo id="S4.E6.m1.1.1.3.2.1" xref="S4.E6.m1.1.1.3.2.1.cmml">‚Å¢</mo><mi id="S4.E6.m1.1.1.3.2.3" xref="S4.E6.m1.1.1.3.2.3.cmml">P</mi></mrow><mrow id="S4.E6.m1.1.1.3.3" xref="S4.E6.m1.1.1.3.3.cmml"><mrow id="S4.E6.m1.1.1.3.3.2" xref="S4.E6.m1.1.1.3.3.2.cmml"><mi id="S4.E6.m1.1.1.3.3.2.2" xref="S4.E6.m1.1.1.3.3.2.2.cmml">T</mi><mo id="S4.E6.m1.1.1.3.3.2.1" xref="S4.E6.m1.1.1.3.3.2.1.cmml">‚Å¢</mo><mi id="S4.E6.m1.1.1.3.3.2.3" xref="S4.E6.m1.1.1.3.3.2.3.cmml">P</mi></mrow><mo id="S4.E6.m1.1.1.3.3.1" xref="S4.E6.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.E6.m1.1.1.3.3.3" xref="S4.E6.m1.1.1.3.3.3.cmml"><mi id="S4.E6.m1.1.1.3.3.3.2" xref="S4.E6.m1.1.1.3.3.3.2.cmml">F</mi><mo id="S4.E6.m1.1.1.3.3.3.1" xref="S4.E6.m1.1.1.3.3.3.1.cmml">‚Å¢</mo><mi id="S4.E6.m1.1.1.3.3.3.3" xref="S4.E6.m1.1.1.3.3.3.3.cmml">P</mi></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.1b"><apply id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1"><eq id="S4.E6.m1.1.1.1.cmml" xref="S4.E6.m1.1.1.1"></eq><ci id="S4.E6.m1.1.1.2a.cmml" xref="S4.E6.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S4.E6.m1.1.1.2.cmml" xref="S4.E6.m1.1.1.2">Precision</mtext></ci><apply id="S4.E6.m1.1.1.3.cmml" xref="S4.E6.m1.1.1.3"><divide id="S4.E6.m1.1.1.3.1.cmml" xref="S4.E6.m1.1.1.3"></divide><apply id="S4.E6.m1.1.1.3.2.cmml" xref="S4.E6.m1.1.1.3.2"><times id="S4.E6.m1.1.1.3.2.1.cmml" xref="S4.E6.m1.1.1.3.2.1"></times><ci id="S4.E6.m1.1.1.3.2.2.cmml" xref="S4.E6.m1.1.1.3.2.2">ùëá</ci><ci id="S4.E6.m1.1.1.3.2.3.cmml" xref="S4.E6.m1.1.1.3.2.3">ùëÉ</ci></apply><apply id="S4.E6.m1.1.1.3.3.cmml" xref="S4.E6.m1.1.1.3.3"><plus id="S4.E6.m1.1.1.3.3.1.cmml" xref="S4.E6.m1.1.1.3.3.1"></plus><apply id="S4.E6.m1.1.1.3.3.2.cmml" xref="S4.E6.m1.1.1.3.3.2"><times id="S4.E6.m1.1.1.3.3.2.1.cmml" xref="S4.E6.m1.1.1.3.3.2.1"></times><ci id="S4.E6.m1.1.1.3.3.2.2.cmml" xref="S4.E6.m1.1.1.3.3.2.2">ùëá</ci><ci id="S4.E6.m1.1.1.3.3.2.3.cmml" xref="S4.E6.m1.1.1.3.3.2.3">ùëÉ</ci></apply><apply id="S4.E6.m1.1.1.3.3.3.cmml" xref="S4.E6.m1.1.1.3.3.3"><times id="S4.E6.m1.1.1.3.3.3.1.cmml" xref="S4.E6.m1.1.1.3.3.3.1"></times><ci id="S4.E6.m1.1.1.3.3.3.2.cmml" xref="S4.E6.m1.1.1.3.3.3.2">ùêπ</ci><ci id="S4.E6.m1.1.1.3.3.3.3.cmml" xref="S4.E6.m1.1.1.3.3.3.3">ùëÉ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.1c">\displaystyle\text{{Precision}}=\frac{TP}{TP+FP}</annotation><annotation encoding="application/x-llamapun" id="S4.E6.m1.1d">Precision = divide start_ARG italic_T italic_P end_ARG start_ARG italic_T italic_P + italic_F italic_P end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS5.p8">
<p class="ltx_p" id="S4.SS5.p8.1">Overall, LightGBM provides high performance in medical diagnosis over all of the datasets, yet has a pretty good computational performance by having a relatively less average training time compared to others.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S4.F2.sf1.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S4.F2.sf1.3.2" style="font-size:90%;">Eye Movements dataset</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S4.F2.sf2.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S4.F2.sf2.3.2" style="font-size:90%;">Prostate dataset</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S4.F2.3.2" style="font-size:90%;">ROC AUC score vs avg. training time comparisons for (a) Eye Movements and (b) Prostate datasets</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Observing Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.T7" title="Table 7 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">7</span></a>, traditional ML models such as SVM, Logistic Regression, and KNN‚Äôs generally show varying performance on different tasks, such as KNN excelling on Parkinson‚Äôs but struggling on others. The reason behind is that SVM and logistic regression are linear models that usually rely on low-dimensional datasets to perform well. Since medical diagnosis datasets usually consist of diverse patient symptoms, such linear models may struggle in performance. On the other hand, being a distance-based method, KNN can perform inconsistently and be sensitive to noisy and high-dimensioned data, which is usually the case for datasets in the medical field. Unlike other ML models, Random Forest provides accurate performances over both small and large sample-sized datasets, such as EEG Eye State and Heart Failure, since it is an ensemble method that becomes effective in reducing overfitting and capturing non-linear relations, being a preferable algorithm for medical datasets with complex patterns. Furthermore, GBDT models, in which we evaluated LightGBM, CatBoost, and XGBoost, tend to perform better on tabular data. These models effectively capture complex interactions between the features that become advantageous for handling imbalanced datasets. In medical settings where the data includes noisy features, GBDT possesses robust mechanisms to overcome these difficulties more easily than other ML methodologies.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In the case of deep neural networks, they tend to have a large number of parameters and complexity compared to other ML-based methods. When the task provides small sample sizes, they can easily overfit the training data and struggle in generalization over the test set, since they tend to capture the noise rather than the correct pattern in the data. Considering MLP and STG, they are mainly designed for tasks including unstructured data, such as images, audio, or text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib37" title="">37</a>]</cite>. In contrast to the unstructured types, tabular medical data has fewer correlations between the features, which may potentially include unrelated and redundant features. Therefore, in such tabular tasks, these models tend to have difficulty in performance. Unlike these models; TabNet and VIME have specialized structures for tabular data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib9" title="">9</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#bib.bib38" title="">38</a>]</cite>. However, they may still struggle and may not effectively capture the temporal dependencies in several cases, such as in EEG Eye State and Parkinsons, when the features of the tabular data consist of continuous measurements over time rather than having individual entries.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Observing Fig.‚Äôs <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F1" title="Figure 1 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F2" title="Figure 2 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">2</span></a>, DL models tend to have higher average training times compared to other ML models due to the complex structures that consist of large number of parameters that needs to be optimized. Specifically, in Fig.‚Äôs <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F1.sf1" title="In Figure 1 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1(a)</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F2.sf1" title="In Figure 2 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">2(a)</span></a>, DL models have higher average training times than traditional ML and GBDT models. In Fig.‚Äôs <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F1.sf2" title="In Figure 1 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1(b)</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F2.sf2" title="In Figure 2 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">2(b)</span></a>, the above trend continues except CatBoost having increased training time in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F1.sf2" title="In Figure 1 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">1(b)</span></a> and higher training time than DL models in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.03705v1#S4.F2.sf2" title="In Figure 2 ‚Ä£ 4.5 Results ‚Ä£ 4 Experiments ‚Ä£ Gradient Boosting Decision Trees on Medical Diagnosis over Tabular Data"><span class="ltx_text ltx_ref_tag">2(b)</span></a>. The reason behind is that since CatBoost relies on building an ensemble of trees sequentially, due to the existence of high dimensions and intricate patterns in medical datasets, such ensemble models might require deeper and larger number of trees to capture the dependencies in the data, leading to longer training times. Having a relatively higher number of dimensions in the Prostate dataset, CatBoost required a higher average training time than normal, which caused some of the DL models, such as TabNet and VIME, have shorter average training times. In general, GBDT methods employ high overall performance in all of the datasets, yet have a good computational performance by having relatively less average training times.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we investigated the overall superiority of ensemble models, especially GBDTs, over other state-of-the-art tabular DL models and traditional ML methods in medical diagnosis, for several benchmark tabular medical datasets. In our analysis, we explored the trade-offs between performance, computational cost, and ease of optimization between the models. Overall, GBDT models exhibited superior performance compared to traditional ML and other deep architectures. Additionally, GBDTs are computationally convenient due to the less complex architectures compared to the deep neural networks that are considerably complex. Due to the less complex structure, GBDTs were much easier to optimize in comparison. Consequently, GBDT models can be safely used in various medical tasks for providing fast and accurate results in any type of diagnosis. In practice, our findings can facilitate clinical decisions. These insights can help data scientists and medical professionals to optimize model selection based on performance and time efficiency. Within this approach, patient care and delivery of healthcare can be improved since our study provides a comprehensive evaluation across a range of ML and DL models as a representative of real-world clinical challenges.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Despite the significant progress of gradient boosting methods over tabular data, further research can be conducted on benchmarking the advantages of GBDTs across alternative settings in healthcare. These alternative settings have the potential to provide further opportunities for analyzing, utilizing, and implementing the GBDT approach. Moreover, they pretty much compose the field of tabular data analysis due to the suffering of deep architectures, that can be extended to any type of task utilized from using tabular data. Due to the significance of tabular data both to the industry and academia, our findings can provide remarkable assistance in the field.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">References</h2>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
R.¬†Shwartz-Ziv and A.¬†Armon, ‚ÄúTabular data: Deep learning is not all you need,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Information Fusion</em>, vol.¬†81, pp. 84‚Äì90, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
V.¬†Borisov, T.¬†Leemann, K.¬†Se√üler, J.¬†Haug, M.¬†Pawelczyk, and G.¬†Kasneci, ‚ÄúDeep neural networks and tabular data: A survey,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE Transactions on Neural Networks and Learning Systems</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A.¬†Mohammed and R.¬†Kora, ‚ÄúA comprehensive review on ensemble deep learning: Opportunities and challenges,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Journal of King Saud University-Computer and Information Sciences</em>, vol.¬†35, no.¬†2, pp. 757‚Äì774, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M.¬†Schmitt, ‚ÄúDeep learning vs. gradient boosting: Benchmarking state-of-the-art machine learning algorithms for credit scoring,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2205.10535</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
X.¬†Yuan, X.¬†Wang, J.¬†Han, J.¬†Liu, H.¬†Chen, K.¬†Zhang, and Q.¬†Ye, ‚ÄúA high accuracy integrated bagging-fuzzy-gbdt prediction algorithm for heart disease diagnosis,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">2019 IEEE/CIC International Conference on Communications in China (ICCC)</em>.¬†¬†¬†IEEE, 2019, pp. 467‚Äì471.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
P.¬†S. Kumar, A.¬†Kumari, S.¬†Mohapatra, B.¬†Naik, J.¬†Nayak, and M.¬†Mishra, ‚ÄúCatboost ensemble approach for diabetes risk prediction at early stages,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">2021 1st Odisha International Conference on Electrical Power Engineering, Communication and Computing Technology (ODICON)</em>.¬†¬†¬†IEEE, 2021, pp. 1‚Äì6.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
R.¬†MurtiRawat, S.¬†Panchal, V.¬†K. Singh, and Y.¬†Panchal, ‚ÄúBreast cancer detection using k-nearest neighbors, logistic regression and ensemble learning,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">2020 international conference on electronics and sustainable communication systems (ICESC)</em>.¬†¬†¬†IEEE, 2020, pp. 534‚Äì540.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H.¬†Ilyas, S.¬†Ali, M.¬†Ponum, O.¬†Hasan, M.¬†T. Mahmood, M.¬†Iftikhar, and M.¬†H. Malik, ‚ÄúChronic kidney disease diagnosis using decision tree algorithms,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">BMC nephrology</em>, vol.¬†22, no.¬†1, p. 273, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S.¬†√ñ. Arik and T.¬†Pfister, ‚ÄúTabnet: Attentive interpretable tabular learning,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, vol.¬†35, no.¬†8, 2021, pp. 6679‚Äì6687.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
W.¬†Xing and Y.¬†Bei, ‚ÄúMedical health big data classification based on knn classification algorithm,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Ieee Access</em>, vol.¬†8, pp. 28‚Äâ808‚Äì28‚Äâ819, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H.¬†Salem, M.¬†Y. Shams, O.¬†M. Elzeki, M.¬†Abd¬†Elfattah, J.¬†F.¬†Al-Amri, and S.¬†Elnazer, ‚ÄúFine-tuning fuzzy knn classifier based on uncertainty membership for the medical diagnosis of diabetes,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Applied Sciences</em>, vol.¬†12, no.¬†3, p. 950, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
E.¬†Y. Boateng, D.¬†A. Abaye <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">et¬†al.</em>, ‚ÄúA review of the logistic regression model with emphasis on medical research,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib12.2.2">Journal of data analysis and information processing</em>, vol.¬†7, no.¬†04, p. 190, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
P.¬†Podder, S.¬†Bharati, M.¬†R.¬†H. Mondal, and U.¬†Kose, ‚ÄúApplication of machine learning for the diagnosis of covid-19,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Data science for COVID-19</em>.¬†¬†¬†Elsevier, 2021, pp. 175‚Äì194.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
S.¬†Nusinovici, Y.¬†C. Tham, M.¬†Y.¬†C. Yan, D.¬†S.¬†W. Ting, J.¬†Li, C.¬†Sabanayagam, T.¬†Y. Wong, and C.-Y. Cheng, ‚ÄúLogistic regression was as good as machine learning for predicting major chronic diseases,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Journal of clinical epidemiology</em>, vol. 122, pp. 56‚Äì69, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
P.¬†Dinesh, A.¬†Vickram, and P.¬†Kalyanasundaram, ‚ÄúMedical image prediction for diagnosis of breast cancer disease comparing the machine learning algorithms: Svm, knn, logistic regression, random forest and decision tree to measure accuracy,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">AIP Conference Proceedings</em>, vol. 2853, no.¬†1.¬†¬†¬†AIP Publishing, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
W.¬†Wu, D.¬†Li, J.¬†Du, X.¬†Gao, W.¬†Gu, F.¬†Zhao, X.¬†Feng, H.¬†Yan <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">et¬†al.</em>, ‚ÄúAn intelligent diagnosis method of brain mri tumor segmentation using deep convolutional neural network and svm algorithm,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib16.2.2">Computational and mathematical methods in medicine</em>, vol. 2020, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
G.¬†Latif, G.¬†Ben¬†Brahim, D.¬†A. Iskandar, A.¬†Bashar, and J.¬†Alghazo, ‚ÄúGlioma tumors‚Äô classification using deep-neural-network-based features with svm classifier,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Diagnostics</em>, vol.¬†12, no.¬†4, p. 1018, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Priyanka and D.¬†Kumar, ‚ÄúDecision tree classifier: a detailed survey,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">International Journal of Information and Decision Sciences</em>, vol.¬†12, no.¬†3, pp. 246‚Äì269, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
M.¬†M. Ghiasi, S.¬†Zendehboudi, and A.¬†A. Mohsenipour, ‚ÄúDecision tree-based diagnosis of coronary artery disease: Cart model,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Computer methods and programs in biomedicine</em>, vol. 192, p. 105400, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
S.¬†H. Yoo, H.¬†Geng, T.¬†L. Chiu, S.¬†K. Yu, D.¬†C. Cho, J.¬†Heo, M.¬†S. Choi, I.¬†H. Choi, C.¬†Cung¬†Van, N.¬†V. Nhung <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">et¬†al.</em>, ‚ÄúDeep learning-based decision-tree classifier for covid-19 diagnosis from chest x-ray imaging,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib20.2.2">Frontiers in medicine</em>, vol.¬†7, p. 427, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Y.¬†Gorishniy, I.¬†Rubachev, V.¬†Khrulkov, and A.¬†Babenko, ‚ÄúRevisiting deep learning models for tabular data,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Advances in Neural Information Processing Systems</em>, vol.¬†34, pp. 18‚Äâ932‚Äì18‚Äâ943, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
A.¬†Vaswani, N.¬†Shazeer, N.¬†Parmar, J.¬†Uszkoreit, L.¬†Jones, A.¬†N. Gomez, ≈Å.¬†Kaiser, and I.¬†Polosukhin, ‚ÄúAttention is all you need,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Advances in neural information processing systems</em>, vol.¬†30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
K.¬†He, C.¬†Gan, Z.¬†Li, I.¬†Rekik, Z.¬†Yin, W.¬†Ji, Y.¬†Gao, Q.¬†Wang, J.¬†Zhang, and D.¬†Shen, ‚ÄúTransformers in medical image analysis,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Intelligent Medicine</em>, vol.¬†3, no.¬†1, pp. 59‚Äì78, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A.¬†Y. Yƒ±ldƒ±z, E.¬†Ko√ß, and A.¬†Ko√ß, ‚ÄúMultivariate time series imputation with transformers,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">IEEE Signal Processing Letters</em>, vol.¬†29, pp. 2517‚Äì2521, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
T.¬†Brown, B.¬†Mann, N.¬†Ryder, M.¬†Subbiah, J.¬†D. Kaplan, P.¬†Dhariwal, A.¬†Neelakantan, P.¬†Shyam, G.¬†Sastry, A.¬†Askell <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">et¬†al.</em>, ‚ÄúLanguage models are few-shot learners,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib25.2.2">Advances in neural information processing systems</em>, vol.¬†33, pp. 1877‚Äì1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
A.¬†J. Thirunavukarasu, D.¬†S.¬†J. Ting, K.¬†Elangovan, L.¬†Gutierrez, T.¬†F. Tan, and D.¬†S.¬†W. Ting, ‚ÄúLarge language models in medicine,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Nature medicine</em>, vol.¬†29, no.¬†8, pp. 1930‚Äì1940, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
S.¬†S. Biswas, ‚ÄúRole of chat gpt in public health,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Annals of biomedical engineering</em>, vol.¬†51, no.¬†5, pp. 868‚Äì869, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
M.¬†Cascella, J.¬†Montomoli, V.¬†Bellini, and E.¬†Bignami, ‚ÄúEvaluating the feasibility of chatgpt in healthcare: an analysis of multiple clinical and research scenarios,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Journal of medical systems</em>, vol.¬†47, no.¬†1, p.¬†33, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
R.¬†Aggarwal, V.¬†Sounderajah, G.¬†Martin, D.¬†S. Ting, A.¬†Karthikesalingam, D.¬†King, H.¬†Ashrafian, and A.¬†Darzi, ‚ÄúDiagnostic accuracy of deep learning in medical imaging: a systematic review and meta-analysis,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">NPJ digital medicine</em>, vol.¬†4, no.¬†1, p.¬†65, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
A.¬†Kalayci and B.¬†Tulu, ‚ÄúExploring usability challenges at the intersection of digital health interventions and health it: Review of reviews,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">AMCIS 2024 Proceedings</em>, vol.¬†26.¬†¬†¬†Association Information Systems, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J.¬†K. Kim, M.¬†Chua, M.¬†Rickard, and A.¬†Lorenzo, ‚ÄúChatgpt and large language model (llm) chatbots: The current state of acceptability and a proposal for guidelines on utilization in academic medicine,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Journal of Pediatric Urology</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
B.¬†Sayin, P.¬†Minervini, J.¬†Staiano, and A.¬†Passerini, ‚ÄúCan llms correct physicians, yet? investigating effective interaction methods in the medical domain,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2403.20288</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
L.¬†Goetz, M.¬†Trengove, A.¬†Trotsyuk, and C.¬†A. Federico, ‚ÄúUnreliable llm bioethics assistants: Ethical and pedagogical risks,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">The American Journal of Bioethics</em>, vol.¬†23, no.¬†10, pp. 89‚Äì91, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
J.¬†Haltaufderheide and R.¬†Ranisch, ‚ÄúThe ethics of chatgpt in medicine and healthcare: A systematic review on large language models (llms),‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2403.14473</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J.¬†C.¬†L. Ong, S.¬†Y.-H. Chang, W.¬†William, A.¬†J. Butte, N.¬†H. Shah, L.¬†S.¬†T. Chew, N.¬†Liu, F.¬†Doshi-Velez, W.¬†Lu, J.¬†Savulescu <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">et¬†al.</em>, ‚ÄúEthical and regulatory challenges of large language models in medicine,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib35.2.2">The Lancet Digital Health</em>, vol.¬†6, no.¬†6, pp. e428‚Äìe432, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
X.¬†Huang, A.¬†Khetan, M.¬†Cvitkovic, and Z.¬†Karnin, ‚ÄúTabtransformer: Tabular data modeling using contextual embeddings,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2012.06678</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Y.¬†Yamada, O.¬†Lindenbaum, S.¬†Negahban, and Y.¬†Kluger, ‚ÄúFeature selection using stochastic gates,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">International conference on machine learning</em>.¬†¬†¬†PMLR, 2020, pp. 10‚Äâ648‚Äì10‚Äâ659.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
J.¬†Yoon, Y.¬†Zhang, J.¬†Jordon, and M.¬†Van¬†der Schaar, ‚ÄúVime: Extending the success of self-and semi-supervised learning to tabular domain,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Advances in Neural Information Processing Systems</em>, vol.¬†33, pp. 11‚Äâ033‚Äì11‚Äâ043, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A.¬†K. Rider and N.¬†V. Chawla, ‚ÄúAn ensemble topic model for sharing healthcare data and predicting disease risk,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the international conference on bioinformatics, computational biology and biomedical informatics</em>, 2013, pp. 333‚Äì340.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
L.¬†Breiman, ‚ÄúRandom forests,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Machine learning</em>, vol.¬†45, pp. 5‚Äì32, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
M.¬†Aria, C.¬†Cuccurullo, and A.¬†Gnasso, ‚ÄúA comparison among interpretative proposals for random forests,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Machine Learning with Applications</em>, vol.¬†6, p. 100094, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
X.-a. Bi, X.¬†Hu, H.¬†Wu, and Y.¬†Wang, ‚ÄúMultimodal data analysis of alzheimer‚Äôs disease based on clustering evolutionary random forest,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">IEEE Journal of Biomedical and Health Informatics</em>, vol.¬†24, no.¬†10, pp. 2973‚Äì2983, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
V.¬†K. Gupta, A.¬†Gupta, D.¬†Kumar, and A.¬†Sardana, ‚ÄúPrediction of covid-19 confirmed, death, and cured cases in india using random forest model,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Big Data Mining and Analytics</em>, vol.¬†4, no.¬†2, pp. 116‚Äì123, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
F.¬†Ali, S.¬†El-Sappagh, S.¬†R. Islam, D.¬†Kwak, A.¬†Ali, M.¬†Imran, and K.-S. Kwak, ‚ÄúA smart healthcare monitoring system for heart disease prediction based on ensemble deep learning and feature fusion,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Information Fusion</em>, vol.¬†63, pp. 208‚Äì222, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
R.¬†Sun, G.¬†Wang, W.¬†Zhang, L.-T. Hsu, and W.¬†Y. Ochieng, ‚ÄúA gradient boosting decision tree based gps signal reception classification algorithm,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Applied Soft Computing</em>, vol.¬†86, p. 105942, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Z.¬†Tian, J.¬†Xiao, H.¬†Feng, and Y.¬†Wei, ‚ÄúCredit risk assessment based on gradient boosting decision tree,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Procedia Computer Science</em>, vol. 174, pp. 150‚Äì160, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
T.¬†Mahesh, V.¬†D. Kumar, V.¬†V. Kumar, J.¬†Asghar, O.¬†Geman, G.¬†Arulkumaran, and N.¬†Arun, ‚ÄúAdaboost ensemble methods using k-fold cross validation for survivability with the early detection of heart disease,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Computational Intelligence and Neuroscience</em>, vol. 2022, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
M.¬†Nilashi, R.¬†A. Abumalloh, B.¬†Minaei-Bidgoli, S.¬†Samad, M.¬†Yousoof¬†Ismail, A.¬†Alhargan, W.¬†Abdu¬†Zogaan <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">et¬†al.</em>, ‚ÄúPredicting parkinson‚Äôs disease progression: Evaluation of ensemble methods in machine learning,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib48.2.2">Journal of healthcare engineering</em>, vol. 2022, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
T.¬†Chen and C.¬†Guestrin, ‚ÄúXgboost: A scalable tree boosting system,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining</em>, 2016, pp. 785‚Äì794.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
G.¬†Ke, Q.¬†Meng, T.¬†Finley, T.¬†Wang, W.¬†Chen, W.¬†Ma, Q.¬†Ye, and T.-Y. Liu, ‚ÄúLightgbm: A highly efficient gradient boosting decision tree,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Advances in neural information processing systems</em>, vol.¬†30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
L.¬†Prokhorenkova, G.¬†Gusev, A.¬†Vorobev, A.¬†V. Dorogush, and A.¬†Gulin, ‚ÄúCatboost: unbiased boosting with categorical features,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Advances in neural information processing systems</em>, vol.¬†31, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
T.¬†Mahesh, V.¬†Vinoth¬†Kumar, V.¬†Muthukumaran, H.¬†Shashikala, B.¬†Swapna, and S.¬†Guluwadi, ‚ÄúPerformance analysis of xgboost ensemble methods for survivability with the classification of breast cancer,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Journal of Sensors</em>, vol. 2022, pp. 1‚Äì8, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
R.¬†K. Halder, ‚ÄúCardiovascular disease dataset,‚Äù 2020. [Online]. Available: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dx.doi.org/10.21227/7qm5-dz13" title="">https://dx.doi.org/10.21227/7qm5-dz13</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
‚ÄúHeart Failure Clinical Records,‚Äù UCI Machine Learning Repository, 2020, DOI: https://doi.org/10.24432/C5Z89R.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
M.¬†Little, ‚ÄúParkinsons,‚Äù UCI Machine Learning Repository, 2008, DOI: https://doi.org/10.24432/C59C74.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
O.¬†Roesler, ‚ÄúEEG Eye State,‚Äù UCI Machine Learning Repository, 2013, DOI: https://doi.org/10.24432/C57G7J.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
J.¬†Saloj√§rvi, K.¬†Puolam√§ki, J.¬†Simola, L.¬†Kovanen, I.¬†Kojo, and S.¬†Kaski, ‚ÄúInferring relevance from eye movements: Feature extraction,‚Äù in <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Workshop at NIPS</em>, 2005, p.¬†45.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
I.¬†Guyon, S.¬†Gunn, A.¬†Ben-Hur, and G.¬†Dror, ‚ÄúArcene,‚Äù UCI Machine Learning Repository, 2008, DOI: https://doi.org/10.24432/C58P55.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
D.¬†Singh, P.¬†G. Febbo, K.¬†Ross, D.¬†G. Jackson, J.¬†Manola, C.¬†Ladd, P.¬†Tamayo, A.¬†A. Renshaw, A.¬†V. D‚ÄôAmico, J.¬†P. Richie <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">et¬†al.</em>, ‚ÄúGene expression correlates of clinical prostate cancer behavior,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib59.2.2">Cancer cell</em>, vol.¬†1, no.¬†2, pp. 203‚Äì209, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
W.¬†S. McCulloch and W.¬†Pitts, ‚ÄúA logical calculus of the ideas immanent in nervous activity,‚Äù <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">The bulletin of mathematical biophysics</em>, vol.¬†5, pp. 115‚Äì133, 1943.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 25 17:11:45 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
