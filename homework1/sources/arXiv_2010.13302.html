<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2010.13302] AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild</title><meta property="og:description" content="Occlusion is probably the biggest challenge for human pose estimation in the wild. Typical solutions often rely on intrusive sensors such as IMUs to detect occluded joints. To make the task truly unconstrained, we pres…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2010.13302">

<!--Generated on Sun Mar 10 17:21:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Received: date / Accepted: date.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Human pose estimation Multiple camera fusion Epipolar geometry">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">∎


</p>
</div>
<span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Zhe Zhang </span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span><span id="id2.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>zhangzhecnjs@gmail.com</span></span></span>
</span></span></span><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Chunyu Wang </span></span></span><span id="id4" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span><span id="id4.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">email: </span>chnuwa@microsoft.com</span></span></span>
</span></span></span><span id="id5" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">institutetext: </span>Weichao Qiu </span></span></span><span id="id6" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">institutetext: </span><span id="id6.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">email: </span>qiuwc@gmail.com</span></span></span>
</span></span></span><span id="id7" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">institutetext: </span>Wenhu Qin </span></span></span><span id="id8" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">institutetext: </span><span id="id8.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">email: </span>qinwenhu@seu.edu.cn</span></span></span>
</span></span></span><span id="id9" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">institutetext: </span>Wenjun Zeng </span></span></span><span id="id10" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_note_type">institutetext: </span><span id="id10.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_note_type">email: </span>wezeng@microsoft.com</span></span></span>
</span></span></span><span id="id5a" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_note_type">institutetext: </span><sup id="id5a.1" class="ltx_sup">1</sup>   Southeast University, Nanjing, China 
<br class="ltx_break"><sup id="id5a.2" class="ltx_sup">2</sup>   Microsoft Research Asia, Beijing, China 
<br class="ltx_break"><sup id="id5a.3" class="ltx_sup">3</sup>   The Johns Hopkins University, MD, USA 
<br class="ltx_break"><sup id="id5a.4" class="ltx_sup">∗</sup>   Corresponding Author 
<br class="ltx_break"><sup id="id5a.5" class="ltx_sup"><span id="id5a.5.1" class="ltx_text ltx_font_italic">†</span></sup>   Zhe Zhang and Chunyu Wang have contributed equally. Work done when Zhe Zhang is an intern at Microsoft Research Asia 
<br class="ltx_break"></span></span></span>
<h1 class="ltx_title ltx_title_document">AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhe Zhang<sup id="id11.2.id1" class="ltx_sup"><span id="id11.2.id1.1" class="ltx_text ltx_font_italic">1†</span></sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chunyu Wang<sup id="id12.2.id1" class="ltx_sup"><span id="id12.2.id1.1" class="ltx_text ltx_font_italic">2†</span></sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Weichao Qiu<sup id="id13.2.id1" class="ltx_sup"><span id="id13.2.id1.1" class="ltx_text ltx_font_italic">3</span></sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wenhu Qin<sup id="id14.2.id1" class="ltx_sup"><span id="id14.2.id1.1" class="ltx_text ltx_font_italic">1∗</span></sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Wenjun Zeng<sup id="id15.2.id1" class="ltx_sup"><span id="id15.2.id1.1" class="ltx_text ltx_font_italic">2</span></sup>
</span></span>
</div>
<div class="ltx_dates">(Received: date / Accepted: date)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.id1" class="ltx_p">Occlusion is probably the biggest challenge for human pose estimation in the wild. Typical solutions often rely on intrusive sensors such as IMUs to detect occluded joints. To make the task truly unconstrained, we present <em id="id16.id1.1" class="ltx_emph ltx_font_italic">AdaFuse</em>, an adaptive multiview fusion method, which can enhance the features in occluded views by leveraging those in visible views. The core of <em id="id16.id1.2" class="ltx_emph ltx_font_italic">AdaFuse</em> is to determine the point-point correspondence between two views which we solve effectively by exploring the sparsity of the heatmap representation. We also learn an adaptive fusion weight for each camera view to reflect its feature quality in order to reduce the chance that good features are undesirably corrupted by “bad” views. The fusion model is trained end-to-end with the pose estimation network, and can be directly applied to new camera configurations without additional adaptation. We extensively evaluate the approach on three public datasets including Human3.6M, Total Capture and CMU Panoptic. It outperforms the state-of-the-arts on all of them. We also create a large scale synthetic dataset <em id="id16.id1.3" class="ltx_emph ltx_font_italic">Occlusion-Person</em>, which allows us to perform numerical evaluation on the occluded joints, as it provides occlusion labels for every joint in the images. The dataset and code are released at <a target="_blank" href="https://github.com/zhezh/adafuse-3d-human-pose" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zhezh/adafuse-3d-human-pose</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Human pose estimation Multiple camera fusion Epipolar geometry
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2010.13302/assets/x1.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="445" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Our approach accurately detects the poses even though they are occluded by leveraging the features in other views. The bottom three rows are images from other view angles of the scene for readers to better perceive the 3D poses of the actors.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.2" class="ltx_p">Accurately estimating <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p1.1.m1.1a"><mn id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><cn type="integer" id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">3</annotation></semantics></math>D human pose from multiple cameras has been a longstanding goal in computer vision <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib33" title="" class="ltx_ref">2011</a>; Bo and Sminchisescu, <a href="#bib.bib4" title="" class="ltx_ref">2010</a>; Gall et al., <a href="#bib.bib16" title="" class="ltx_ref">2010</a>; Rhodin et al., <a href="#bib.bib47" title="" class="ltx_ref">2018</a>; Amin et al., <a href="#bib.bib1" title="" class="ltx_ref">2013</a>; Burenius et al., <a href="#bib.bib6" title="" class="ltx_ref">2013</a>; Pavlakos et al., <a href="#bib.bib39" title="" class="ltx_ref">2017</a>; Belagiannis et al., <a href="#bib.bib3" title="" class="ltx_ref">2014</a>)</cite>. The ultimate goal is to recover absolute <math id="S1.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p1.2.m2.1a"><mn id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><cn type="integer" id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">3</annotation></semantics></math>D locations of the body joints in a world coordinate system from multiple cameras placed in natural environments. The task has attracted a lot of attention because it can benefit many applications such as augmented and virtual reality <cite class="ltx_cite ltx_citemacro_citep">(Starner et al., <a href="#bib.bib51" title="" class="ltx_ref">2003</a>)</cite>, human-computer-interaction and intelligent player analysis in sport videos <cite class="ltx_cite ltx_citemacro_citep">(Bridgeman et al., <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.8" class="ltx_p">The task is often addressed by a simple two-step framework. In the first step, it tries to detect the <math id="S1.p2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S1.p2.1.m1.1a"><mn id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><cn type="integer" id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">2</annotation></semantics></math>D poses in all camera views, for example, by a convolutional neural network <cite class="ltx_cite ltx_citemacro_citep">(Cao et al., <a href="#bib.bib7" title="" class="ltx_ref">2017</a>; Xiao et al., <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite>. Then in the second step, it recovers the <math id="S1.p2.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p2.2.m2.1a"><mn id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><cn type="integer" id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">3</annotation></semantics></math>D pose from the multiview <math id="S1.p2.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S1.p2.3.m3.1a"><mn id="S1.p2.3.m3.1.1" xref="S1.p2.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S1.p2.3.m3.1b"><cn type="integer" id="S1.p2.3.m3.1.1.cmml" xref="S1.p2.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.3.m3.1c">2</annotation></semantics></math>D poses either by analytical methods <cite class="ltx_cite ltx_citemacro_citep">(Burenius et al., <a href="#bib.bib6" title="" class="ltx_ref">2013</a>; Pavlakos et al., <a href="#bib.bib39" title="" class="ltx_ref">2017</a>; Belagiannis et al., <a href="#bib.bib3" title="" class="ltx_ref">2014</a>; Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>; Amin et al., <a href="#bib.bib1" title="" class="ltx_ref">2013</a>)</cite> or by discriminative models <cite class="ltx_cite ltx_citemacro_citep">(Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>; Tu et al., <a href="#bib.bib57" title="" class="ltx_ref">2020</a>)</cite>. The camera parameters are usually assumed known in these approaches. The development of powerful network architectures such as <cite class="ltx_cite ltx_citemacro_citep">(Newell et al., <a href="#bib.bib38" title="" class="ltx_ref">2016</a>)</cite> has notably improved the <math id="S1.p2.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S1.p2.4.m4.1a"><mn id="S1.p2.4.m4.1.1" xref="S1.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S1.p2.4.m4.1b"><cn type="integer" id="S1.p2.4.m4.1.1.cmml" xref="S1.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.4.m4.1c">2</annotation></semantics></math>D pose estimation quality, which in turn reduces the <math id="S1.p2.5.m5.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p2.5.m5.1a"><mn id="S1.p2.5.m5.1.1" xref="S1.p2.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p2.5.m5.1b"><cn type="integer" id="S1.p2.5.m5.1.1.cmml" xref="S1.p2.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.5.m5.1c">3</annotation></semantics></math>D error remarkably. For example, in <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite>, the <math id="S1.p2.6.m6.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p2.6.m6.1a"><mn id="S1.p2.6.m6.1.1" xref="S1.p2.6.m6.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p2.6.m6.1b"><cn type="integer" id="S1.p2.6.m6.1.1.cmml" xref="S1.p2.6.m6.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.6.m6.1c">3</annotation></semantics></math>D error on Human3.6M <cite class="ltx_cite ltx_citemacro_citep">(Ionescu et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite> decreases significantly from <math id="S1.p2.7.m7.1" class="ltx_Math" alttext="52" display="inline"><semantics id="S1.p2.7.m7.1a"><mn id="S1.p2.7.m7.1.1" xref="S1.p2.7.m7.1.1.cmml">52</mn><annotation-xml encoding="MathML-Content" id="S1.p2.7.m7.1b"><cn type="integer" id="S1.p2.7.m7.1.1.cmml" xref="S1.p2.7.m7.1.1">52</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.7.m7.1c">52</annotation></semantics></math>mm to <math id="S1.p2.8.m8.1" class="ltx_Math" alttext="26" display="inline"><semantics id="S1.p2.8.m8.1a"><mn id="S1.p2.8.m8.1.1" xref="S1.p2.8.m8.1.1.cmml">26</mn><annotation-xml encoding="MathML-Content" id="S1.p2.8.m8.1b"><cn type="integer" id="S1.p2.8.m8.1.1.cmml" xref="S1.p2.8.m8.1.1">26</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.8.m8.1c">26</annotation></semantics></math>mm.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, obtaining small errors on benchmark datasets does not imply that the task has been truly solved unless the challenges such as background clutter, human appearance variation and occlusion encountered in real world applications are well addressed. In fact, a growing amount of efforts <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib68" title="" class="ltx_ref">2017</a>; Ci et al., <a href="#bib.bib10" title="" class="ltx_ref">2019</a>; Yang et al., <a href="#bib.bib63" title="" class="ltx_ref">2018</a>; Rogez and Schmid, <a href="#bib.bib49" title="" class="ltx_ref">2016</a>; Pavlakos et al., <a href="#bib.bib40" title="" class="ltx_ref">2018</a>; Ci et al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> have been devoted to improving the pose estimation performance in challenging scenarios, for example, by augmenting the training dataset <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib68" title="" class="ltx_ref">2017</a>; Yang et al., <a href="#bib.bib63" title="" class="ltx_ref">2018</a>; Varol et al., <a href="#bib.bib58" title="" class="ltx_ref">2017</a>)</cite> with more images or by using more robust sensors such as IMUs <cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite>. We will discuss about this type of work in more details in section <a href="#S2" title="2 Related Work ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this work, we propose to solve the problem in a different way by multiview feature fusion. The approach is orthogonal to the previous efforts. As shown in Figure <a href="#S0.F1" title="Figure 1 ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our approach can accurately detect the joints even when they are occluded in certain views. The motivation behind our approach is that a joint occluded in one view may be visible in other views. So it is generally helpful to fuse the features at the corresponding locations in different views. To that end, we present a flexible multiview fusion approach termed <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">AdaFuse</em>. Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the pipeline. It first uses camera parameters to compute the point-line correspondence between a pair of views. Then it “finds” the matched point on the line by exploring the sparsity of the heatmap representation without performing the challenging point-point matching. Finally, the features of the matched points in different views are fused. The approach can effectively improve the feature quality in occluded views. In addition, for a new environment with different camera poses, we can directly use <em id="S1.p4.1.2" class="ltx_emph ltx_font_italic">AdaFuse</em> without re-training as long as the camera parameters are available. This improves the applicability of the approach in real applications.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The performance of <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">AdaFuse</em> is further boosted by learning an adaptive fusion weight for each view to reflect its feature quality. This weight is leveraged in fusion in order to reduce the impact of low-quality views. If a joint is occluded in one view, its features are also likely corrupted. In this case, we hope to give a small weight to this view when performing multiview fusion such that the high-quality features in the visible views are dominant, and are free from being corrupted by low-quality features. We add some simple layers to the pose estimation network to predict heatmap quality based on the heatmap distribution and cross view consistency. We observe in our experiments that the use of adaptive fusion notably improves the performance.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We evaluate our approach on three public datasets including Human3.6M <cite class="ltx_cite ltx_citemacro_citep">(Ionescu et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>, Total Capture <cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite> and CMU Panoptic <cite class="ltx_cite ltx_citemacro_citep">(Joo et al., <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>. It outperforms the state-of-the-arts demonstrating the effectiveness of our approach. In addition, we also compare it to a number of standard multiview fusion methods such as RANSAC in order to give more detailed insights. We evaluate the generalization capability of our approach by training and testing on different datasets. We also create a synthetic human pose dataset in which human are purposely occluded by objects. The dataset allows us to perform evaluation on the occluded joints.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The rest of the paper is organized as follows. In section <a href="#S2" title="2 Related Work ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we discuss the related work on multiview <math id="S1.p7.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p7.1.m1.1a"><mn id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><cn type="integer" id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">3</annotation></semantics></math>D human pose estimation with special focus on the approaches that aim to improve the performance in challenging environments. Section <a href="#S3" title="3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> introduces the basics for multiview feature fusion to lay the groundwork for <em id="S1.p7.1.1" class="ltx_emph ltx_font_italic">AdaFuse</em>. Then we describe how we learn adaptive weight for each camera view to reflect the feature quality, as well as the details of <em id="S1.p7.1.2" class="ltx_emph ltx_font_italic">AdaFuse</em>. In sections <a href="#S5" title="5 Datasets and Metrics ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and <a href="#S6" title="6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we introduce the experimental datasets and results, respectively. Section <a href="#S7" title="7 Summary and Future Work ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> concludes this work.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2010.13302/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="396" height="143" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of <em id="S1.F2.6.1" class="ltx_emph ltx_font_italic">AdaFuse</em>. It takes multiview images as input and outputs <math id="S1.F2.3.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S1.F2.3.m1.1b"><mn id="S1.F2.3.m1.1.1" xref="S1.F2.3.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S1.F2.3.m1.1c"><cn type="integer" id="S1.F2.3.m1.1.1.cmml" xref="S1.F2.3.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.3.m1.1d">2</annotation></semantics></math>D poses of all views jointly. It first uses a pose estimation network to obtain <math id="S1.F2.4.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S1.F2.4.m2.1b"><mn id="S1.F2.4.m2.1.1" xref="S1.F2.4.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S1.F2.4.m2.1c"><cn type="integer" id="S1.F2.4.m2.1.1.cmml" xref="S1.F2.4.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.4.m2.1d">2</annotation></semantics></math>D heatmaps for each view. Then on top of epipolar geometry, the heatmaps from all camera views are fused. Finally, we apply the SoftMax operator to suppress the small noises introduced in fusion. Consequently, pose estimation in each view benefits from other views.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We first review the related work on multiview <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">3</annotation></semantics></math>D human pose estimation in section <a href="#S2.SS1" title="2.1 Multiview 3D Human Pose Estimation ‣ 2 Related Work ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. Then section <a href="#S2.SS2" title="2.2 Improving “In the Wild” Performance ‣ 2 Related Work ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> summarizes the techniques that are used to improve the in-the-wild performance. Finally, in section <a href="#S2.SS3" title="2.3 Consensus Learning ‣ 2 Related Work ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>, we discuss the approaches on consensus learning such as RANSAC. This is necessary for multiple sensor fusion because the sensors could have contradictory predictions and the outliers should be removed to ensure the good fusion quality.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Multiview <math id="S2.SS1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.1.m1.1b"><mn id="S2.SS1.1.m1.1.1" xref="S2.SS1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.1.m1.1c"><cn type="integer" id="S2.SS1.1.m1.1.1.cmml" xref="S2.SS1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.1.m1.1d">3</annotation></semantics></math>D Human Pose Estimation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">We briefly classify the multiview <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mn id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><cn type="integer" id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">3</annotation></semantics></math>D human pose estimation methods into two classes. The first class is model-based approaches which are also known as analysis-by-synthesis approaches <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a href="#bib.bib33" title="" class="ltx_ref">2011</a>; Gall et al., <a href="#bib.bib16" title="" class="ltx_ref">2010</a>; Moeslund et al., <a href="#bib.bib37" title="" class="ltx_ref">2006</a>; Sigal et al., <a href="#bib.bib50" title="" class="ltx_ref">2010</a>; Perez et al., <a href="#bib.bib43" title="" class="ltx_ref">2004</a>)</cite>. They first model human body by simple primitives such as sticks and cylinders. Then the parameters of the model (<span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">i</span>.<span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">e</span>. poses) are continuously updated according to the observations in multiview images until the model can be explained by the image features. The resulted optimization problem is usually non-convex. So expensive sampling techniques are often used. The main difference among those approaches lies in the adopted image features and the optimization algorithms. We refer the interested readers to earlier survey papers such as <cite class="ltx_cite ltx_citemacro_citep">(Moeslund et al., <a href="#bib.bib37" title="" class="ltx_ref">2006</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">The advantage of the model-based approaches lies in its capability to handle occlusion because of the inherent structure prior embedded in human model. These approaches aggregate the local features as evidence to infer the global model parameters with the inherent human body structure as constraints. So if a joint is occluded, it can still rely on other joints to guess the possible locations that are consistent with the prior. However, the model-based approaches get larger <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mn id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><cn type="integer" id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">3</annotation></semantics></math>D errors than the model-free approaches due to the difficult optimization problems.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.5" class="ltx_p">The second class is model-free approaches <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>; Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>; Burenius et al., <a href="#bib.bib6" title="" class="ltx_ref">2013</a>; Pavlakos et al., <a href="#bib.bib39" title="" class="ltx_ref">2017</a>; Dong et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Amin et al., <a href="#bib.bib1" title="" class="ltx_ref">2013</a>; Belagiannis et al., <a href="#bib.bib3" title="" class="ltx_ref">2014</a>; Xie et al., <a href="#bib.bib62" title="" class="ltx_ref">2020</a>)</cite> which often follow a two-step framework. They first detect <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><mn id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><cn type="integer" id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">2</annotation></semantics></math>D poses in images of all camera views. Then with the aid of camera parameters, they recover the <math id="S2.SS1.p3.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p3.2.m2.1a"><mn id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><cn type="integer" id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">3</annotation></semantics></math>D pose using either triangulation <cite class="ltx_cite ltx_citemacro_citep">(Amin et al., <a href="#bib.bib1" title="" class="ltx_ref">2013</a>; Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite> or pictorial structure models <cite class="ltx_cite ltx_citemacro_citep">(Burenius et al., <a href="#bib.bib6" title="" class="ltx_ref">2013</a>; Pavlakos et al., <a href="#bib.bib39" title="" class="ltx_ref">2017</a>; Dong et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>)</cite>. Recursive pictorial structure model is introduced in <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite> to speed up the inference process. The authors in <cite class="ltx_cite ltx_citemacro_citep">(Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite> also propose to use learnable triangulation <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a href="#bib.bib20" title="" class="ltx_ref">2003</a>)</cite> for human pose estimation which is more robust to inaccurate <math id="S2.SS1.p3.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS1.p3.3.m3.1a"><mn id="S2.SS1.p3.3.m3.1.1" xref="S2.SS1.p3.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.1b"><cn type="integer" id="S2.SS1.p3.3.m3.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.1c">2</annotation></semantics></math>D poses. If the <math id="S2.SS1.p3.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS1.p3.4.m4.1a"><mn id="S2.SS1.p3.4.m4.1.1" xref="S2.SS1.p3.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.4.m4.1b"><cn type="integer" id="S2.SS1.p3.4.m4.1.1.cmml" xref="S2.SS1.p3.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.4.m4.1c">2</annotation></semantics></math>D poses are accurate, the recovered <math id="S2.SS1.p3.5.m5.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p3.5.m5.1a"><mn id="S2.SS1.p3.5.m5.1.1" xref="S2.SS1.p3.5.m5.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.5.m5.1b"><cn type="integer" id="S2.SS1.p3.5.m5.1.1.cmml" xref="S2.SS1.p3.5.m5.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.5.m5.1c">3</annotation></semantics></math>D poses are guaranteed to be accurate without worrying about being trapped in local optimum as the model-based methods.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.4" class="ltx_p">The development of more powerful network architectures <cite class="ltx_cite ltx_citemacro_citep">(Newell et al., <a href="#bib.bib38" title="" class="ltx_ref">2016</a>; Sun et al., <a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite> has dramatically improved the <math id="S2.SS1.p4.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS1.p4.1.m1.1a"><mn id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><cn type="integer" id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">2</annotation></semantics></math>D pose estimation accuracy on benchmark datasets, which in turn also decreases the <math id="S2.SS1.p4.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p4.2.m2.1a"><mn id="S2.SS1.p4.2.m2.1.1" xref="S2.SS1.p4.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.1b"><cn type="integer" id="S2.SS1.p4.2.m2.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.1c">3</annotation></semantics></math>D pose estimation error. For example, on the most popular benchmark Human3.6M <cite class="ltx_cite ltx_citemacro_citep">(Ionescu et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>, the <math id="S2.SS1.p4.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS1.p4.3.m3.1a"><mn id="S2.SS1.p4.3.m3.1.1" xref="S2.SS1.p4.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.3.m3.1b"><cn type="integer" id="S2.SS1.p4.3.m3.1.1.cmml" xref="S2.SS1.p4.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.3.m3.1c">3</annotation></semantics></math>D MPJPE error has decreased to about <math id="S2.SS1.p4.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S2.SS1.p4.4.m4.1a"><mn id="S2.SS1.p4.4.m4.1.1" xref="S2.SS1.p4.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.4.m4.1b"><cn type="integer" id="S2.SS1.p4.4.m4.1.1.cmml" xref="S2.SS1.p4.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.4.m4.1c">20</annotation></semantics></math>mm which can meet the requirements of many real-life applications.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Improving “In the Wild” Performance</h3>

<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Sensors</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.3" class="ltx_p">Occlusion is probably the biggest challenge for in-the-wild scenarios. One straightforward solution is to use additional sensors such as IMUs <cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite> and radio signals <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a href="#bib.bib67" title="" class="ltx_ref">2019</a>)</cite>, which are not impacted by occlusion. For example, Roetenberg et al.<cite class="ltx_cite ltx_citemacro_citep">(Roetenberg et al., <a href="#bib.bib48" title="" class="ltx_ref">2009</a>)</cite> place <math id="S2.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="17" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><mn id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">17</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">17</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">17</annotation></semantics></math> IMUs at the rigid bones. If the measurements are accurate, the <math id="S2.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.1a"><mn id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.1b"><cn type="integer" id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.1c">3</annotation></semantics></math>D pose is fully determined. In practice, however, the accuracy is limited by the drifting problem. To that end, some approaches <cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>; von Marcard et al., <a href="#bib.bib35" title="" class="ltx_ref">2018</a>; Gilbert et al., <a href="#bib.bib18" title="" class="ltx_ref">2019</a>; Malleson et al., <a href="#bib.bib34" title="" class="ltx_ref">2017</a>; Zhang et al., <a href="#bib.bib65" title="" class="ltx_ref">2020</a>)</cite> propose to fuse images and IMUs to achieve more robust pose estimation. Some works <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a href="#bib.bib67" title="" class="ltx_ref">2019</a>; Li et al., <a href="#bib.bib31" title="" class="ltx_ref">2019</a>; Zhao et al., <a href="#bib.bib66" title="" class="ltx_ref">2018</a>)</cite> leverage the fact that wireless signals in the WiFi frequencies traverse walls and reflect off the human body, and propose a radio-based system that can estimate <math id="S2.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.1a"><mn id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.1b"><cn type="integer" id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.1c">2</annotation></semantics></math>D poses even when persons are completely occluded by walls. However, these approaches also have their own problems. For example, how to effectively fuse visual and inertial signals for IMU-based approaches? Besides, wearing sensors on the body is intrusive, and is not acceptable in some scenarios such as football games. On the other hand, the WiFi-based solutions cannot deal with self-occlusion which is a big limitation.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data Augmentation</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.2" class="ltx_p">Collecting more images for model training is an effective approach to improve the generalization performance. For example in <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a href="#bib.bib68" title="" class="ltx_ref">2017</a>; Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite>, the authors propose to use the MPII <cite class="ltx_cite ltx_citemacro_citep">(Andriluka et al., <a href="#bib.bib2" title="" class="ltx_ref">2014</a>)</cite> and the COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a href="#bib.bib32" title="" class="ltx_ref">2014</a>)</cite> datasets to help train the <math id="S2.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S2.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.1c">2</annotation></semantics></math>D module of the <math id="S2.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS2.SSS0.Px2.p1.2.m2.1a"><mn id="S2.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.2.m2.1b"><cn type="integer" id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.2.m2.1c">3</annotation></semantics></math>D pose estimators which effectively reduces the risk of over-fitting to simple training datasets. However, annotating a sufficiently large pose dataset is expensive and time consuming. So some approaches <cite class="ltx_cite ltx_citemacro_citep">(Rogez and Schmid, <a href="#bib.bib49" title="" class="ltx_ref">2016</a>; Varol et al., <a href="#bib.bib58" title="" class="ltx_ref">2017</a>; Hoffmann et al., <a href="#bib.bib22" title="" class="ltx_ref">2019</a>; Chen et al., <a href="#bib.bib8" title="" class="ltx_ref">2016</a>; Lassner et al., <a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite> propose to generate synthetic images. The main issue is to bridge the gap between the synthetic and real images such that the model trained on synthetic images can be applied to real images. To that end, some approaches such as <cite class="ltx_cite ltx_citemacro_citep">(Peng et al., <a href="#bib.bib42" title="" class="ltx_ref">2018</a>)</cite> propose to use generative adversarial networks to generate realistic images.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Spatial-Temporal Context Models</h4>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.1" class="ltx_p">Some approaches propose to use spatial-temporal context models to jointly detect all joints in a video sequence such that each joint can benefit from other joints in the same or neighboring frames. Intuitively, if a body joint is occluded thus is difficult to be detected according to its own appearance, they can use the locations of other joints to guess the possible location. For example, in a previous work <cite class="ltx_cite ltx_citemacro_citep">(Cao et al., <a href="#bib.bib7" title="" class="ltx_ref">2017</a>; Kreiss et al., <a href="#bib.bib28" title="" class="ltx_ref">2019</a>)</cite>, the authors propose to detect body parts, <span id="S2.SS2.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">i</span>.<span id="S2.SS2.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">e</span>. the links connecting two joints, in addition to the individual joints. This provides a chance to mutually enhance the detection of the two linked joints. In <cite class="ltx_cite ltx_citemacro_citep">(Cheng et al., <a href="#bib.bib9" title="" class="ltx_ref">2019</a>; Pavllo et al., <a href="#bib.bib41" title="" class="ltx_ref">2019</a>)</cite>, temporal convolution is utilized to deal with occlusion in current frames. Some works such as <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite> propose to establish the spatial correspondence across multiple camera views, and leverage multi-view features for robust joint detection. Significant performance improvement has been achieved for the occluded joints on several benchmark datasets. The main drawback of the approach <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite> is the lack of flexibility in practice since it needs to train a separate fusion network for every possible camera placement. Our work differs from <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite> in that it can be applied to new environments with different numbers of cameras and different camera poses without additional adaptation. We will compare the two methods in the experiments.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Consensus Learning</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">A fundamental problem in multi-sensor fusion is to detect and remove outliers as the sensors may produce inconsistent measurements. RANSAC <cite class="ltx_cite ltx_citemacro_citep">(Fischler and Bolles, <a href="#bib.bib13" title="" class="ltx_ref">1981</a>)</cite> is the most commonly used outlier detection method. The main assumption is that the dataset consists of inliers. It produces reasonable results only with a certain probability which increases as the number of inliers. In practice, when the number of sensors is small, the probability of detecting the real outliers is also small. For example, in multiview human pose estimation, the number of cameras is only four to eight for most benchmark datasets <cite class="ltx_cite ltx_citemacro_citep">(Ionescu et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>; Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite>. For such cases, we observe that RANSAC may not be the best option.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In recent years, uncertainty learning <cite class="ltx_cite ltx_citemacro_citep">(Kendall and Gal, <a href="#bib.bib27" title="" class="ltx_ref">2017</a>; Gal and Ghahramani, <a href="#bib.bib15" title="" class="ltx_ref">2015</a>; Lakshminarayanan et al., <a href="#bib.bib29" title="" class="ltx_ref">2017</a>; Zafar et al., <a href="#bib.bib64" title="" class="ltx_ref">2019</a>; Lakshminarayanan et al., <a href="#bib.bib29" title="" class="ltx_ref">2017</a>; Pleiss et al., <a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite> has attracted a lot of attention which is particularly important for high-risk applications such as autonomous driving and medical diagnosis <cite class="ltx_cite ltx_citemacro_citep">(Gal, <a href="#bib.bib14" title="" class="ltx_ref">2016</a>; Ghahramani, <a href="#bib.bib17" title="" class="ltx_ref">2016</a>)</cite>. The main idea is that, when a model makes a prediction, it also outputs a score reflecting the confidence of the prediction. Consider an autonomous car that uses a neural network to detect people. If the network is not confident about the prediction, the car could probably rely on other sensors for making the correct decision.
Uncertainty is introduced to computer vision in <cite class="ltx_cite ltx_citemacro_citep">(Kendall and Gal, <a href="#bib.bib27" title="" class="ltx_ref">2017</a>; Kreiss et al., <a href="#bib.bib28" title="" class="ltx_ref">2019</a>; He et al., <a href="#bib.bib21" title="" class="ltx_ref">2019</a>; Ilg et al., <a href="#bib.bib23" title="" class="ltx_ref">2018</a>)</cite>. Another branch of approaches such as <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a href="#bib.bib19" title="" class="ltx_ref">2017</a>; Pleiss et al., <a href="#bib.bib44" title="" class="ltx_ref">2017</a>)</cite> propose to learn uncertainty by calibration. They propose to train the model such that the probability associated with the predicted class label agrees with its ground truth correctness likelihood.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">The concept of uncertainty can be leveraged to reduce the impact of outliers. For example, in <cite class="ltx_cite ltx_citemacro_citep">(Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>, the authors propose to predict an uncertainty score for each joint in each view. The score is used to weigh each view when doing triangulation. This dramatically reduces the <math id="S2.SS3.p3.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.SS3.p3.1.m1.1a"><mn id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><cn type="integer" id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">3</annotation></semantics></math>D pose estimation error. Inspired by the success of uncertainty learning in computer vision tasks, we propose to learn uncertainty for multiview feature fusion. The predicted uncertainty is used as a weight when fusing multiview features. We show this adaptive feature fusion could effectively improve the fusion quality.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>The Basics for Multiview Fusion</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We first introduce the basics for multiview fusion to lay the groundwork for <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">AdaFuse</em>. In particular, we discuss how to establish the point-point correspondence between two views such that the features correspond to the same <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p1.1.m1.1a"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><cn type="integer" id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">3</annotation></semantics></math>D space point can be fused together. The narrow baseline correspondence can be solved efficiently by local feature matching. However, in the context of multiview human pose estimation where only a small number of cameras are placed far away from each other, the local features cannot be robustly detected and matched especially for texture-less human regions. This poses a serious challenge.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">To solve the problem, we present a coarse-to-fine approach to find matched points. It first establishes the point-to-line correspondence between two views by epipolar geometry, and then implicitly determine the point-to-point correspondence by exploring the sparsity of the heatmap representations. The approach notably simplifies the task because it avoids the challenging step of finding the exact correspondence. We first introduce epipolar geometry in section <a href="#S3.SS1" title="3.1 Epipolar Geometry ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> in order to determine the point-to-line correspondence. Then in section <a href="#S3.SS2" title="3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we describe how we adapt epipolar geometry to perform multiview heatmap fusion. Finally, we discuss the side effect caused by the simplified fusion strategy and our solution in section <a href="#S3.SS3" title="3.3 Side Effect and Solution ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2010.13302/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="204" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of the point-line correspondence in two views. For an arbitrary point <math id="S3.F3.4.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.F3.4.m1.1b"><mi id="S3.F3.4.m1.1.1" xref="S3.F3.4.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.F3.4.m1.1c"><ci id="S3.F3.4.m1.1.1.cmml" xref="S3.F3.4.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m1.1d">\mathbf{x}</annotation></semantics></math> in one view, the corresponding point <math id="S3.F3.5.m2.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.F3.5.m2.1b"><msup id="S3.F3.5.m2.1.1" xref="S3.F3.5.m2.1.1.cmml"><mi id="S3.F3.5.m2.1.1.2" xref="S3.F3.5.m2.1.1.2.cmml">𝐱</mi><mo id="S3.F3.5.m2.1.1.3" xref="S3.F3.5.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.F3.5.m2.1c"><apply id="S3.F3.5.m2.1.1.cmml" xref="S3.F3.5.m2.1.1"><csymbol cd="ambiguous" id="S3.F3.5.m2.1.1.1.cmml" xref="S3.F3.5.m2.1.1">superscript</csymbol><ci id="S3.F3.5.m2.1.1.2.cmml" xref="S3.F3.5.m2.1.1.2">𝐱</ci><ci id="S3.F3.5.m2.1.1.3.cmml" xref="S3.F3.5.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.5.m2.1d">\mathbf{x}^{\prime}</annotation></semantics></math> in another view has to lie on the epipolar line <math id="S3.F3.6.m3.1" class="ltx_Math" alttext="\mathbf{I}^{\prime}" display="inline"><semantics id="S3.F3.6.m3.1b"><msup id="S3.F3.6.m3.1.1" xref="S3.F3.6.m3.1.1.cmml"><mi id="S3.F3.6.m3.1.1.2" xref="S3.F3.6.m3.1.1.2.cmml">𝐈</mi><mo id="S3.F3.6.m3.1.1.3" xref="S3.F3.6.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.F3.6.m3.1c"><apply id="S3.F3.6.m3.1.1.cmml" xref="S3.F3.6.m3.1.1"><csymbol cd="ambiguous" id="S3.F3.6.m3.1.1.1.cmml" xref="S3.F3.6.m3.1.1">superscript</csymbol><ci id="S3.F3.6.m3.1.1.2.cmml" xref="S3.F3.6.m3.1.1.2">𝐈</ci><ci id="S3.F3.6.m3.1.1.3.cmml" xref="S3.F3.6.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.6.m3.1d">\mathbf{I}^{\prime}</annotation></semantics></math>. This is the core of <em id="S3.F3.8.1" class="ltx_emph ltx_font_italic">AdaFuse</em> for finding corresponding points in other views.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Epipolar Geometry</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.12" class="ltx_p">Let us denote a point in <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">3</annotation></semantics></math>D space as <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{X}\in\mathcal{R}^{4\times 1}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">𝐗</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">ℛ</mi><mrow id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml"><mn id="S3.SS1.p1.2.m2.1.1.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.3.3.1" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p1.2.m2.1.1.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝐗</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">ℛ</ci><apply id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3"><times id="S3.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2">4</cn><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbf{X}\in\mathcal{R}^{4\times 1}</annotation></semantics></math> as shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This could be the location of a body joint in the context of pose estimation. Note that homogeneous coordinate and column vector are used to represent a point. The <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mn id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><cn type="integer" id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">3</annotation></semantics></math>D point is imaged in two camera views, at <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{x}=\mathbf{P}\mathbf{{X}}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">=</mo><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">𝐏𝐗</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><eq id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></eq><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝐱</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">𝐏𝐗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\mathbf{x}=\mathbf{P}\mathbf{{X}}</annotation></semantics></math> in the first, and <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}=\mathbf{P}^{\prime}\mathbf{{X}}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><msup id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">𝐱</mi><mo id="S3.SS1.p1.5.m5.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml">′</mo></msup><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml"><msup id="S3.SS1.p1.5.m5.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.3.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.2.2" xref="S3.SS1.p1.5.m5.1.1.3.2.2.cmml">𝐏</mi><mo id="S3.SS1.p1.5.m5.1.1.3.2.3" xref="S3.SS1.p1.5.m5.1.1.3.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.1.3.1" xref="S3.SS1.p1.5.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p1.5.m5.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.cmml">𝐗</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><eq id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></eq><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">𝐱</ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3">′</ci></apply><apply id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3"><times id="S3.SS1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.1"></times><apply id="S3.SS1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.3.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2">superscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.3.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2.2">𝐏</ci><ci id="S3.SS1.p1.5.m5.1.1.3.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2.3">′</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3">𝐗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathbf{x}^{\prime}=\mathbf{P}^{\prime}\mathbf{{X}}</annotation></semantics></math> in the second, where <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\mathbf{x}</annotation></semantics></math> and <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}\in\mathcal{R}^{3\times 1}" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mrow id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><msup id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2.2" xref="S3.SS1.p1.7.m7.1.1.2.2.cmml">𝐱</mi><mo id="S3.SS1.p1.7.m7.1.1.2.3" xref="S3.SS1.p1.7.m7.1.1.2.3.cmml">′</mo></msup><mo id="S3.SS1.p1.7.m7.1.1.1" xref="S3.SS1.p1.7.m7.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">ℛ</mi><mrow id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml"><mn id="S3.SS1.p1.7.m7.1.1.3.3.2" xref="S3.SS1.p1.7.m7.1.1.3.3.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.7.m7.1.1.3.3.1" xref="S3.SS1.p1.7.m7.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p1.7.m7.1.1.3.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><in id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1.1"></in><apply id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.2.1.cmml" xref="S3.SS1.p1.7.m7.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2.2">𝐱</ci><ci id="S3.SS1.p1.7.m7.1.1.2.3.cmml" xref="S3.SS1.p1.7.m7.1.1.2.3">′</ci></apply><apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">ℛ</ci><apply id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3"><times id="S3.SS1.p1.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p1.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.2">3</cn><cn type="integer" id="S3.SS1.p1.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">\mathbf{x}^{\prime}\in\mathcal{R}^{3\times 1}</annotation></semantics></math> represent <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><mn id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><cn type="integer" id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">2</annotation></semantics></math>D points in images, <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="\mathbf{P}" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">𝐏</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">𝐏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">\mathbf{P}</annotation></semantics></math> and <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="\mathbf{P}^{\prime}\in\mathcal{R}^{3\times 4}" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mrow id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml"><msup id="S3.SS1.p1.10.m10.1.1.2" xref="S3.SS1.p1.10.m10.1.1.2.cmml"><mi id="S3.SS1.p1.10.m10.1.1.2.2" xref="S3.SS1.p1.10.m10.1.1.2.2.cmml">𝐏</mi><mo id="S3.SS1.p1.10.m10.1.1.2.3" xref="S3.SS1.p1.10.m10.1.1.2.3.cmml">′</mo></msup><mo id="S3.SS1.p1.10.m10.1.1.1" xref="S3.SS1.p1.10.m10.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.10.m10.1.1.3" xref="S3.SS1.p1.10.m10.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.10.m10.1.1.3.2" xref="S3.SS1.p1.10.m10.1.1.3.2.cmml">ℛ</mi><mrow id="S3.SS1.p1.10.m10.1.1.3.3" xref="S3.SS1.p1.10.m10.1.1.3.3.cmml"><mn id="S3.SS1.p1.10.m10.1.1.3.3.2" xref="S3.SS1.p1.10.m10.1.1.3.3.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.10.m10.1.1.3.3.1" xref="S3.SS1.p1.10.m10.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p1.10.m10.1.1.3.3.3" xref="S3.SS1.p1.10.m10.1.1.3.3.3.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><apply id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1"><in id="S3.SS1.p1.10.m10.1.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1.1"></in><apply id="S3.SS1.p1.10.m10.1.1.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.2.1.cmml" xref="S3.SS1.p1.10.m10.1.1.2">superscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.2.2.cmml" xref="S3.SS1.p1.10.m10.1.1.2.2">𝐏</ci><ci id="S3.SS1.p1.10.m10.1.1.2.3.cmml" xref="S3.SS1.p1.10.m10.1.1.2.3">′</ci></apply><apply id="S3.SS1.p1.10.m10.1.1.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m10.1.1.3.1.cmml" xref="S3.SS1.p1.10.m10.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.10.m10.1.1.3.2.cmml" xref="S3.SS1.p1.10.m10.1.1.3.2">ℛ</ci><apply id="S3.SS1.p1.10.m10.1.1.3.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3.3"><times id="S3.SS1.p1.10.m10.1.1.3.3.1.cmml" xref="S3.SS1.p1.10.m10.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p1.10.m10.1.1.3.3.2.cmml" xref="S3.SS1.p1.10.m10.1.1.3.3.2">3</cn><cn type="integer" id="S3.SS1.p1.10.m10.1.1.3.3.3.cmml" xref="S3.SS1.p1.10.m10.1.1.3.3.3">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">\mathbf{P}^{\prime}\in\mathcal{R}^{3\times 4}</annotation></semantics></math> are the projection matrix for each camera.
Since the two <math id="S3.SS1.p1.11.m11.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS1.p1.11.m11.1a"><mn id="S3.SS1.p1.11.m11.1.1" xref="S3.SS1.p1.11.m11.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m11.1b"><cn type="integer" id="S3.SS1.p1.11.m11.1.1.cmml" xref="S3.SS1.p1.11.m11.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m11.1c">2</annotation></semantics></math>D points correspond to the same <math id="S3.SS1.p1.12.m12.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p1.12.m12.1a"><mn id="S3.SS1.p1.12.m12.1.1" xref="S3.SS1.p1.12.m12.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m12.1b"><cn type="integer" id="S3.SS1.p1.12.m12.1.1.cmml" xref="S3.SS1.p1.12.m12.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m12.1c">3</annotation></semantics></math>D point and have the same semantic meanings, their features can be safely fused such that each view benefits from the other view.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.5" class="ltx_p">The epipolar geometry <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a href="#bib.bib20" title="" class="ltx_ref">2003</a>)</cite> between two views is essentially the geometry of the intersection of the image planes with the pencil of planes having the baseline as axis. The baseline is the line joining the camera centers <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="C_{1}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">C</mi><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝐶</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">C_{1}</annotation></semantics></math> and <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="C_{2}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">C</mi><mn id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝐶</ci><cn type="integer" id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">C_{2}</annotation></semantics></math>. In particular, for each location <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathbf{x}</annotation></semantics></math> in the first view, it helps us to determine the location of the corresponding point <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msup id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐱</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathbf{x}^{\prime}</annotation></semantics></math> in the second view without having to know <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\mathbf{X}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.9" class="ltx_p">We can see from Figure <a href="#S3.F3" title="Figure 3 ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> that the image points <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathbf{x}</annotation></semantics></math> and <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><msup id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">𝐱</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathbf{x}^{\prime}</annotation></semantics></math>, the <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><mn id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><cn type="integer" id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">3</annotation></semantics></math>D point <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\mathbf{X}</annotation></semantics></math>, and the camera centers <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{C_{1}}" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">𝐂</mi><mn id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">𝟏</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">𝐂</ci><cn type="integer" id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\mathbf{C_{1}}</annotation></semantics></math> and <math id="S3.SS1.p3.6.m6.1" class="ltx_Math" alttext="\mathbf{C_{2}}" display="inline"><semantics id="S3.SS1.p3.6.m6.1a"><msub id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml"><mi id="S3.SS1.p3.6.m6.1.1.2" xref="S3.SS1.p3.6.m6.1.1.2.cmml">𝐂</mi><mn id="S3.SS1.p3.6.m6.1.1.3" xref="S3.SS1.p3.6.m6.1.1.3.cmml">𝟐</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><apply id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.6.m6.1.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p3.6.m6.1.1.2.cmml" xref="S3.SS1.p3.6.m6.1.1.2">𝐂</ci><cn type="integer" id="S3.SS1.p3.6.m6.1.1.3.cmml" xref="S3.SS1.p3.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">\mathbf{C_{2}}</annotation></semantics></math> lie on the same plane <math id="S3.SS1.p3.7.m7.1" class="ltx_Math" alttext="\mathbf{\pi}" display="inline"><semantics id="S3.SS1.p3.7.m7.1a"><mi id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><ci id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">\mathbf{\pi}</annotation></semantics></math>. The plane intersects with the two image planes at epipolar lines <math id="S3.SS1.p3.8.m8.1" class="ltx_Math" alttext="\mathbf{I}" display="inline"><semantics id="S3.SS1.p3.8.m8.1a"><mi id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml">𝐈</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><ci id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1">𝐈</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">\mathbf{I}</annotation></semantics></math> and <math id="S3.SS1.p3.9.m9.1" class="ltx_Math" alttext="\mathbf{I}^{\prime}" display="inline"><semantics id="S3.SS1.p3.9.m9.1a"><msup id="S3.SS1.p3.9.m9.1.1" xref="S3.SS1.p3.9.m9.1.1.cmml"><mi id="S3.SS1.p3.9.m9.1.1.2" xref="S3.SS1.p3.9.m9.1.1.2.cmml">𝐈</mi><mo id="S3.SS1.p3.9.m9.1.1.3" xref="S3.SS1.p3.9.m9.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.9.m9.1b"><apply id="S3.SS1.p3.9.m9.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.9.m9.1.1.1.cmml" xref="S3.SS1.p3.9.m9.1.1">superscript</csymbol><ci id="S3.SS1.p3.9.m9.1.1.2.cmml" xref="S3.SS1.p3.9.m9.1.1.2">𝐈</ci><ci id="S3.SS1.p3.9.m9.1.1.3.cmml" xref="S3.SS1.p3.9.m9.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.9.m9.1c">\mathbf{I}^{\prime}</annotation></semantics></math>, respectively. In particular,</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.13" class="ltx_Math" alttext="\begin{split}&amp;\mathbf{I}^{\prime}=\mathbf{F}\mathbf{x}\\
&amp;\mathbf{I}=\mathbf{F}^{\top}\mathbf{x}^{\prime},\end{split}" display="block"><semantics id="S3.E1.m1.13a"><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt" id="S3.E1.m1.13.13.2"><mtr id="S3.E1.m1.13.13.2a"><mtd id="S3.E1.m1.13.13.2b" xref="S3.E1.m1.12.12.1.1.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.13.13.2c"><mrow id="S3.E1.m1.4.4.4.4.4"><msup id="S3.E1.m1.4.4.4.4.4.5"><mi id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml">𝐈</mi><mo id="S3.E1.m1.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.1.cmml">′</mo></msup><mo id="S3.E1.m1.3.3.3.3.3.3" xref="S3.E1.m1.3.3.3.3.3.3.cmml">=</mo><mi id="S3.E1.m1.4.4.4.4.4.4" xref="S3.E1.m1.4.4.4.4.4.4.cmml">𝐅𝐱</mi></mrow></mtd></mtr><mtr id="S3.E1.m1.13.13.2d"><mtd id="S3.E1.m1.13.13.2e" xref="S3.E1.m1.12.12.1.1.1.cmml"></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.13.13.2f"><mrow id="S3.E1.m1.13.13.2.12.8.8.8"><mrow id="S3.E1.m1.13.13.2.12.8.8.8.1"><mi id="S3.E1.m1.5.5.5.1.1.1" xref="S3.E1.m1.5.5.5.1.1.1.cmml">𝐈</mi><mo id="S3.E1.m1.6.6.6.2.2.2" xref="S3.E1.m1.6.6.6.2.2.2.cmml">=</mo><mrow id="S3.E1.m1.13.13.2.12.8.8.8.1.1"><msup id="S3.E1.m1.13.13.2.12.8.8.8.1.1.2"><mi id="S3.E1.m1.7.7.7.3.3.3" xref="S3.E1.m1.7.7.7.3.3.3.cmml">𝐅</mi><mo id="S3.E1.m1.8.8.8.4.4.4.1" xref="S3.E1.m1.8.8.8.4.4.4.1.cmml">⊤</mo></msup><mo lspace="0em" rspace="0em" id="S3.E1.m1.13.13.2.12.8.8.8.1.1.1" xref="S3.E1.m1.12.12.1.1.1.cmml">​</mo><msup id="S3.E1.m1.13.13.2.12.8.8.8.1.1.3"><mi id="S3.E1.m1.9.9.9.5.5.5" xref="S3.E1.m1.9.9.9.5.5.5.cmml">𝐱</mi><mo id="S3.E1.m1.10.10.10.6.6.6.1" xref="S3.E1.m1.10.10.10.6.6.6.1.cmml">′</mo></msup></mrow></mrow><mo id="S3.E1.m1.11.11.11.7.7.7" xref="S3.E1.m1.12.12.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E1.m1.13b"><apply id="S3.E1.m1.12.12.1.1.1.cmml" xref="S3.E1.m1.13.13.2b"><and id="S3.E1.m1.12.12.1.1.1a.cmml" xref="S3.E1.m1.13.13.2b"></and><apply id="S3.E1.m1.12.12.1.1.1b.cmml" xref="S3.E1.m1.13.13.2b"><eq id="S3.E1.m1.3.3.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3.3.3"></eq><apply id="S3.E1.m1.12.12.1.1.1.2.cmml" xref="S3.E1.m1.13.13.2b"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.1.1.1.2.1.cmml" xref="S3.E1.m1.13.13.2b">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1">𝐈</ci><ci id="S3.E1.m1.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.1">′</ci></apply><apply id="S3.E1.m1.12.12.1.1.1.4.cmml" xref="S3.E1.m1.13.13.2b"><times id="S3.E1.m1.12.12.1.1.1.4.1.cmml" xref="S3.E1.m1.13.13.2b"></times><ci id="S3.E1.m1.4.4.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4.4.4">𝐅𝐱</ci><ci id="S3.E1.m1.5.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.5.1.1.1">𝐈</ci></apply></apply><apply id="S3.E1.m1.12.12.1.1.1c.cmml" xref="S3.E1.m1.13.13.2b"><eq id="S3.E1.m1.6.6.6.2.2.2.cmml" xref="S3.E1.m1.6.6.6.2.2.2"></eq><share href="#S3.E1.m1.12.12.1.1.1.4.cmml" id="S3.E1.m1.12.12.1.1.1d.cmml" xref="S3.E1.m1.13.13.2b"></share><apply id="S3.E1.m1.12.12.1.1.1.6.cmml" xref="S3.E1.m1.13.13.2b"><times id="S3.E1.m1.12.12.1.1.1.6.1.cmml" xref="S3.E1.m1.13.13.2b"></times><apply id="S3.E1.m1.12.12.1.1.1.6.2.cmml" xref="S3.E1.m1.13.13.2b"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.1.1.1.6.2.1.cmml" xref="S3.E1.m1.13.13.2b">superscript</csymbol><ci id="S3.E1.m1.7.7.7.3.3.3.cmml" xref="S3.E1.m1.7.7.7.3.3.3">𝐅</ci><csymbol cd="latexml" id="S3.E1.m1.8.8.8.4.4.4.1.cmml" xref="S3.E1.m1.8.8.8.4.4.4.1">top</csymbol></apply><apply id="S3.E1.m1.12.12.1.1.1.6.3.cmml" xref="S3.E1.m1.13.13.2b"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.1.1.1.6.3.1.cmml" xref="S3.E1.m1.13.13.2b">superscript</csymbol><ci id="S3.E1.m1.9.9.9.5.5.5.cmml" xref="S3.E1.m1.9.9.9.5.5.5">𝐱</ci><ci id="S3.E1.m1.10.10.10.6.6.6.1.cmml" xref="S3.E1.m1.10.10.10.6.6.6.1">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.13c">\begin{split}&amp;\mathbf{I}^{\prime}=\mathbf{F}\mathbf{x}\\
&amp;\mathbf{I}=\mathbf{F}^{\top}\mathbf{x}^{\prime},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p3.21" class="ltx_p">where <math id="S3.SS1.p3.10.m1.1" class="ltx_Math" alttext="\mathbf{F}\in\mathcal{R}^{3\times 3}" display="inline"><semantics id="S3.SS1.p3.10.m1.1a"><mrow id="S3.SS1.p3.10.m1.1.1" xref="S3.SS1.p3.10.m1.1.1.cmml"><mi id="S3.SS1.p3.10.m1.1.1.2" xref="S3.SS1.p3.10.m1.1.1.2.cmml">𝐅</mi><mo id="S3.SS1.p3.10.m1.1.1.1" xref="S3.SS1.p3.10.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.p3.10.m1.1.1.3" xref="S3.SS1.p3.10.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.10.m1.1.1.3.2" xref="S3.SS1.p3.10.m1.1.1.3.2.cmml">ℛ</mi><mrow id="S3.SS1.p3.10.m1.1.1.3.3" xref="S3.SS1.p3.10.m1.1.1.3.3.cmml"><mn id="S3.SS1.p3.10.m1.1.1.3.3.2" xref="S3.SS1.p3.10.m1.1.1.3.3.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p3.10.m1.1.1.3.3.1" xref="S3.SS1.p3.10.m1.1.1.3.3.1.cmml">×</mo><mn id="S3.SS1.p3.10.m1.1.1.3.3.3" xref="S3.SS1.p3.10.m1.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.10.m1.1b"><apply id="S3.SS1.p3.10.m1.1.1.cmml" xref="S3.SS1.p3.10.m1.1.1"><in id="S3.SS1.p3.10.m1.1.1.1.cmml" xref="S3.SS1.p3.10.m1.1.1.1"></in><ci id="S3.SS1.p3.10.m1.1.1.2.cmml" xref="S3.SS1.p3.10.m1.1.1.2">𝐅</ci><apply id="S3.SS1.p3.10.m1.1.1.3.cmml" xref="S3.SS1.p3.10.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p3.10.m1.1.1.3.1.cmml" xref="S3.SS1.p3.10.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p3.10.m1.1.1.3.2.cmml" xref="S3.SS1.p3.10.m1.1.1.3.2">ℛ</ci><apply id="S3.SS1.p3.10.m1.1.1.3.3.cmml" xref="S3.SS1.p3.10.m1.1.1.3.3"><times id="S3.SS1.p3.10.m1.1.1.3.3.1.cmml" xref="S3.SS1.p3.10.m1.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p3.10.m1.1.1.3.3.2.cmml" xref="S3.SS1.p3.10.m1.1.1.3.3.2">3</cn><cn type="integer" id="S3.SS1.p3.10.m1.1.1.3.3.3.cmml" xref="S3.SS1.p3.10.m1.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.10.m1.1c">\mathbf{F}\in\mathcal{R}^{3\times 3}</annotation></semantics></math> is fundamental matrix which can be derived from <math id="S3.SS1.p3.11.m2.1" class="ltx_Math" alttext="\mathbf{P}" display="inline"><semantics id="S3.SS1.p3.11.m2.1a"><mi id="S3.SS1.p3.11.m2.1.1" xref="S3.SS1.p3.11.m2.1.1.cmml">𝐏</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.11.m2.1b"><ci id="S3.SS1.p3.11.m2.1.1.cmml" xref="S3.SS1.p3.11.m2.1.1">𝐏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.11.m2.1c">\mathbf{P}</annotation></semantics></math> and <math id="S3.SS1.p3.12.m3.1" class="ltx_Math" alttext="\mathbf{P}^{\prime}" display="inline"><semantics id="S3.SS1.p3.12.m3.1a"><msup id="S3.SS1.p3.12.m3.1.1" xref="S3.SS1.p3.12.m3.1.1.cmml"><mi id="S3.SS1.p3.12.m3.1.1.2" xref="S3.SS1.p3.12.m3.1.1.2.cmml">𝐏</mi><mo id="S3.SS1.p3.12.m3.1.1.3" xref="S3.SS1.p3.12.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.12.m3.1b"><apply id="S3.SS1.p3.12.m3.1.1.cmml" xref="S3.SS1.p3.12.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.12.m3.1.1.1.cmml" xref="S3.SS1.p3.12.m3.1.1">superscript</csymbol><ci id="S3.SS1.p3.12.m3.1.1.2.cmml" xref="S3.SS1.p3.12.m3.1.1.2">𝐏</ci><ci id="S3.SS1.p3.12.m3.1.1.3.cmml" xref="S3.SS1.p3.12.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.12.m3.1c">\mathbf{P}^{\prime}</annotation></semantics></math>. Readers can refer to <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a href="#bib.bib20" title="" class="ltx_ref">2003</a>)</cite> for detail derivation.
In addition, the rays back-projected from <math id="S3.SS1.p3.13.m4.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p3.13.m4.1a"><mi id="S3.SS1.p3.13.m4.1.1" xref="S3.SS1.p3.13.m4.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.13.m4.1b"><ci id="S3.SS1.p3.13.m4.1.1.cmml" xref="S3.SS1.p3.13.m4.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.13.m4.1c">\mathbf{x}</annotation></semantics></math> and <math id="S3.SS1.p3.14.m5.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p3.14.m5.1a"><msup id="S3.SS1.p3.14.m5.1.1" xref="S3.SS1.p3.14.m5.1.1.cmml"><mi id="S3.SS1.p3.14.m5.1.1.2" xref="S3.SS1.p3.14.m5.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p3.14.m5.1.1.3" xref="S3.SS1.p3.14.m5.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.14.m5.1b"><apply id="S3.SS1.p3.14.m5.1.1.cmml" xref="S3.SS1.p3.14.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.14.m5.1.1.1.cmml" xref="S3.SS1.p3.14.m5.1.1">superscript</csymbol><ci id="S3.SS1.p3.14.m5.1.1.2.cmml" xref="S3.SS1.p3.14.m5.1.1.2">𝐱</ci><ci id="S3.SS1.p3.14.m5.1.1.3.cmml" xref="S3.SS1.p3.14.m5.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.14.m5.1c">\mathbf{x}^{\prime}</annotation></semantics></math> intersect at <math id="S3.SS1.p3.15.m6.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.p3.15.m6.1a"><mi id="S3.SS1.p3.15.m6.1.1" xref="S3.SS1.p3.15.m6.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.15.m6.1b"><ci id="S3.SS1.p3.15.m6.1.1.cmml" xref="S3.SS1.p3.15.m6.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.15.m6.1c">\mathbf{X}</annotation></semantics></math>, and the rays are coplanar, lying in <math id="S3.SS1.p3.16.m7.1" class="ltx_Math" alttext="\mathbf{\pi}" display="inline"><semantics id="S3.SS1.p3.16.m7.1a"><mi id="S3.SS1.p3.16.m7.1.1" xref="S3.SS1.p3.16.m7.1.1.cmml">π</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.16.m7.1b"><ci id="S3.SS1.p3.16.m7.1.1.cmml" xref="S3.SS1.p3.16.m7.1.1">𝜋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.16.m7.1c">\mathbf{\pi}</annotation></semantics></math>. It is straightforward to derive that the location of <math id="S3.SS1.p3.17.m8.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p3.17.m8.1a"><msup id="S3.SS1.p3.17.m8.1.1" xref="S3.SS1.p3.17.m8.1.1.cmml"><mi id="S3.SS1.p3.17.m8.1.1.2" xref="S3.SS1.p3.17.m8.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p3.17.m8.1.1.3" xref="S3.SS1.p3.17.m8.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.17.m8.1b"><apply id="S3.SS1.p3.17.m8.1.1.cmml" xref="S3.SS1.p3.17.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.17.m8.1.1.1.cmml" xref="S3.SS1.p3.17.m8.1.1">superscript</csymbol><ci id="S3.SS1.p3.17.m8.1.1.2.cmml" xref="S3.SS1.p3.17.m8.1.1.2">𝐱</ci><ci id="S3.SS1.p3.17.m8.1.1.3.cmml" xref="S3.SS1.p3.17.m8.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.17.m8.1c">\mathbf{x}^{\prime}</annotation></semantics></math> which corresponds to <math id="S3.SS1.p3.18.m9.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p3.18.m9.1a"><mi id="S3.SS1.p3.18.m9.1.1" xref="S3.SS1.p3.18.m9.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.18.m9.1b"><ci id="S3.SS1.p3.18.m9.1.1.cmml" xref="S3.SS1.p3.18.m9.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.18.m9.1c">\mathbf{x}</annotation></semantics></math> is guaranteed to lie on the epipolar line <math id="S3.SS1.p3.19.m10.1" class="ltx_Math" alttext="\mathbf{I}^{\prime}" display="inline"><semantics id="S3.SS1.p3.19.m10.1a"><msup id="S3.SS1.p3.19.m10.1.1" xref="S3.SS1.p3.19.m10.1.1.cmml"><mi id="S3.SS1.p3.19.m10.1.1.2" xref="S3.SS1.p3.19.m10.1.1.2.cmml">𝐈</mi><mo id="S3.SS1.p3.19.m10.1.1.3" xref="S3.SS1.p3.19.m10.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.19.m10.1b"><apply id="S3.SS1.p3.19.m10.1.1.cmml" xref="S3.SS1.p3.19.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.19.m10.1.1.1.cmml" xref="S3.SS1.p3.19.m10.1.1">superscript</csymbol><ci id="S3.SS1.p3.19.m10.1.1.2.cmml" xref="S3.SS1.p3.19.m10.1.1.2">𝐈</ci><ci id="S3.SS1.p3.19.m10.1.1.3.cmml" xref="S3.SS1.p3.19.m10.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.19.m10.1c">\mathbf{I}^{\prime}</annotation></semantics></math>. However, we have to leverage additional information such as appearance to determine the exact location of <math id="S3.SS1.p3.20.m11.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p3.20.m11.1a"><msup id="S3.SS1.p3.20.m11.1.1" xref="S3.SS1.p3.20.m11.1.1.cmml"><mi id="S3.SS1.p3.20.m11.1.1.2" xref="S3.SS1.p3.20.m11.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p3.20.m11.1.1.3" xref="S3.SS1.p3.20.m11.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.20.m11.1b"><apply id="S3.SS1.p3.20.m11.1.1.cmml" xref="S3.SS1.p3.20.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.20.m11.1.1.1.cmml" xref="S3.SS1.p3.20.m11.1.1">superscript</csymbol><ci id="S3.SS1.p3.20.m11.1.1.2.cmml" xref="S3.SS1.p3.20.m11.1.1.2">𝐱</ci><ci id="S3.SS1.p3.20.m11.1.1.3.cmml" xref="S3.SS1.p3.20.m11.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.20.m11.1c">\mathbf{x}^{\prime}</annotation></semantics></math> on <math id="S3.SS1.p3.21.m12.1" class="ltx_Math" alttext="\mathbf{I}^{\prime}" display="inline"><semantics id="S3.SS1.p3.21.m12.1a"><msup id="S3.SS1.p3.21.m12.1.1" xref="S3.SS1.p3.21.m12.1.1.cmml"><mi id="S3.SS1.p3.21.m12.1.1.2" xref="S3.SS1.p3.21.m12.1.1.2.cmml">𝐈</mi><mo id="S3.SS1.p3.21.m12.1.1.3" xref="S3.SS1.p3.21.m12.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.21.m12.1b"><apply id="S3.SS1.p3.21.m12.1.1.cmml" xref="S3.SS1.p3.21.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.21.m12.1.1.1.cmml" xref="S3.SS1.p3.21.m12.1.1">superscript</csymbol><ci id="S3.SS1.p3.21.m12.1.1.2.cmml" xref="S3.SS1.p3.21.m12.1.1.2">𝐈</ci><ci id="S3.SS1.p3.21.m12.1.1.3.cmml" xref="S3.SS1.p3.21.m12.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.21.m12.1c">\mathbf{I}^{\prime}</annotation></semantics></math>.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2010.13302/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="452" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Epipolar geometry based heatmap fusion. For each location <math id="S3.F4.3.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.F4.3.m1.1b"><mi id="S3.F4.3.m1.1.1" xref="S3.F4.3.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.F4.3.m1.1c"><ci id="S3.F4.3.m1.1.1.cmml" xref="S3.F4.3.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.3.m1.1d">\mathbf{x}</annotation></semantics></math> in the first view, we first compute the corresponding epipolar lines in the other two views. Then we find the largest responses on the two lines, respectively and add them to the original response at <math id="S3.F4.4.m2.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.F4.4.m2.1b"><mi id="S3.F4.4.m2.1.1" xref="S3.F4.4.m2.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.F4.4.m2.1c"><ci id="S3.F4.4.m2.1.1.cmml" xref="S3.F4.4.m2.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.m2.1d">\mathbf{x}</annotation></semantics></math>.</figcaption>
</figure>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.9" class="ltx_p">In the context of multiview feature fusion, for every image point <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\mathbf{x}</annotation></semantics></math>, we need to find the corresponding point <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><msup id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">𝐱</ci><ci id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\mathbf{x}^{\prime}</annotation></semantics></math> in the second view so that we can fuse the features at <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">\mathbf{x}</annotation></semantics></math> with those at <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><msup id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mi id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">𝐱</ci><ci id="S3.SS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\mathbf{x}^{\prime}</annotation></semantics></math> and obtain more robust pose estimations. Since we do not know the depth of <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><mi id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><ci id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">\mathbf{X}</annotation></semantics></math>, it could move freely on the line defined by the camera center <math id="S3.SS1.p4.6.m6.1" class="ltx_Math" alttext="\mathbf{C_{1}}" display="inline"><semantics id="S3.SS1.p4.6.m6.1a"><msub id="S3.SS1.p4.6.m6.1.1" xref="S3.SS1.p4.6.m6.1.1.cmml"><mi id="S3.SS1.p4.6.m6.1.1.2" xref="S3.SS1.p4.6.m6.1.1.2.cmml">𝐂</mi><mn id="S3.SS1.p4.6.m6.1.1.3" xref="S3.SS1.p4.6.m6.1.1.3.cmml">𝟏</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.1b"><apply id="S3.SS1.p4.6.m6.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m6.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p4.6.m6.1.1.2.cmml" xref="S3.SS1.p4.6.m6.1.1.2">𝐂</ci><cn type="integer" id="S3.SS1.p4.6.m6.1.1.3.cmml" xref="S3.SS1.p4.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.1c">\mathbf{C_{1}}</annotation></semantics></math> and image point <math id="S3.SS1.p4.7.m7.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.p4.7.m7.1a"><mi id="S3.SS1.p4.7.m7.1.1" xref="S3.SS1.p4.7.m7.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m7.1b"><ci id="S3.SS1.p4.7.m7.1.1.cmml" xref="S3.SS1.p4.7.m7.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m7.1c">\mathbf{x}</annotation></semantics></math>. However, we know that <math id="S3.SS1.p4.8.m8.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.p4.8.m8.1a"><msup id="S3.SS1.p4.8.m8.1.1" xref="S3.SS1.p4.8.m8.1.1.cmml"><mi id="S3.SS1.p4.8.m8.1.1.2" xref="S3.SS1.p4.8.m8.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.p4.8.m8.1.1.3" xref="S3.SS1.p4.8.m8.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m8.1b"><apply id="S3.SS1.p4.8.m8.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.8.m8.1.1.1.cmml" xref="S3.SS1.p4.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.p4.8.m8.1.1.2.cmml" xref="S3.SS1.p4.8.m8.1.1.2">𝐱</ci><ci id="S3.SS1.p4.8.m8.1.1.3.cmml" xref="S3.SS1.p4.8.m8.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m8.1c">\mathbf{x}^{\prime}</annotation></semantics></math> cannot span the entire image plane but is restricted to the line <math id="S3.SS1.p4.9.m9.1" class="ltx_Math" alttext="\mathbf{I}^{\prime}" display="inline"><semantics id="S3.SS1.p4.9.m9.1a"><msup id="S3.SS1.p4.9.m9.1.1" xref="S3.SS1.p4.9.m9.1.1.cmml"><mi id="S3.SS1.p4.9.m9.1.1.2" xref="S3.SS1.p4.9.m9.1.1.2.cmml">𝐈</mi><mo id="S3.SS1.p4.9.m9.1.1.3" xref="S3.SS1.p4.9.m9.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.9.m9.1b"><apply id="S3.SS1.p4.9.m9.1.1.cmml" xref="S3.SS1.p4.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.9.m9.1.1.1.cmml" xref="S3.SS1.p4.9.m9.1.1">superscript</csymbol><ci id="S3.SS1.p4.9.m9.1.1.2.cmml" xref="S3.SS1.p4.9.m9.1.1.2">𝐈</ci><ci id="S3.SS1.p4.9.m9.1.1.3.cmml" xref="S3.SS1.p4.9.m9.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.9.m9.1c">\mathbf{I}^{\prime}</annotation></semantics></math>. In the following section 3.2, we will describe how we perform multiview feature fusion based on epipolar geometry.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Sampson Distance</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.8" class="ltx_p">In practice, usually we have 2D measurements <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">\mathbf{x}</annotation></semantics></math> and <math id="S3.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><msup id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">𝐱</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">\mathbf{x}^{\prime}</annotation></semantics></math> corresponding to the same 3D location <math id="S3.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">\mathbf{X}</annotation></semantics></math> which is unknown. Due to measurement noise and errors, the line <math id="S3.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{C_{1}x}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><mrow id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><msub id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2.cmml">𝐂</mi><mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3.cmml">𝟏</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">𝐱</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1"><times id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1"></times><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.2">𝐂</ci><cn type="integer" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.3">1</cn></apply><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">\mathbf{C_{1}x}</annotation></semantics></math> and <math id="S3.SS1.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{C_{2}x^{\prime}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><mrow id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><msub id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2.cmml">𝐂</mi><mn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3.cmml">𝟐</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml">​</mo><msup id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2.cmml">𝐱</mi><mo id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><times id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1"></times><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.2">𝐂</ci><cn type="integer" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.3">2</cn></apply><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.2">𝐱</ci><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">\mathbf{C_{2}x^{\prime}}</annotation></semantics></math> might not intersect exactly at location <math id="S3.SS1.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.6.m6.1a"><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m6.1b"><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m6.1c">\mathbf{X}</annotation></semantics></math>.
To obtain the optimal estimation for <math id="S3.SS1.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="\mathbf{X}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.7.m7.1a"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml">𝐗</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m7.1b"><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1">𝐗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m7.1c">\mathbf{X}</annotation></semantics></math>, we search for <math id="S3.SS1.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="\mathbf{\hat{X}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.8.m8.1a"><mover accent="true" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml">𝐗</mi><mo id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1"><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1">^</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2">𝐗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m8.1c">\mathbf{\hat{X}}</annotation></semantics></math> subject to</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="d_{Reproj}^{2}=\min_{\mathbf{\hat{X}}}d^{2}\left(\mathbf{x},\mathbf{P}\mathbf{\hat{X}}\right)+d^{2}\left(\mathbf{x}^{\prime},\mathbf{P}^{\prime}\mathbf{\hat{X}}\right)," display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msubsup id="S3.E2.m1.2.2.1.1.5" xref="S3.E2.m1.2.2.1.1.5.cmml"><mi id="S3.E2.m1.2.2.1.1.5.2.2" xref="S3.E2.m1.2.2.1.1.5.2.2.cmml">d</mi><mrow id="S3.E2.m1.2.2.1.1.5.2.3" xref="S3.E2.m1.2.2.1.1.5.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.5.2.3.2" xref="S3.E2.m1.2.2.1.1.5.2.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.5.2.3.1" xref="S3.E2.m1.2.2.1.1.5.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.5.2.3.3" xref="S3.E2.m1.2.2.1.1.5.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.5.2.3.1a" xref="S3.E2.m1.2.2.1.1.5.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.5.2.3.4" xref="S3.E2.m1.2.2.1.1.5.2.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.5.2.3.1b" xref="S3.E2.m1.2.2.1.1.5.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.5.2.3.5" xref="S3.E2.m1.2.2.1.1.5.2.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.5.2.3.1c" xref="S3.E2.m1.2.2.1.1.5.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.5.2.3.6" xref="S3.E2.m1.2.2.1.1.5.2.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.5.2.3.1d" xref="S3.E2.m1.2.2.1.1.5.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.1.1.5.2.3.7" xref="S3.E2.m1.2.2.1.1.5.2.3.7.cmml">j</mi></mrow><mn id="S3.E2.m1.2.2.1.1.5.3" xref="S3.E2.m1.2.2.1.1.5.3.cmml">2</mn></msubsup><mo id="S3.E2.m1.2.2.1.1.4" xref="S3.E2.m1.2.2.1.1.4.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml"><munder id="S3.E2.m1.2.2.1.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.3.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.1.2" xref="S3.E2.m1.2.2.1.1.1.1.3.1.2.cmml">min</mi><mover accent="true" id="S3.E2.m1.2.2.1.1.1.1.3.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.3.1.3.2.cmml">𝐗</mi><mo id="S3.E2.m1.2.2.1.1.1.1.3.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.3.1.3.1.cmml">^</mo></mover></munder><mo lspace="0.167em" id="S3.E2.m1.2.2.1.1.1.1.3a" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml">⁡</mo><msup id="S3.E2.m1.2.2.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.2.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.2.cmml">d</mi><mn id="S3.E2.m1.2.2.1.1.1.1.3.2.3" xref="S3.E2.m1.2.2.1.1.1.1.3.2.3.cmml">2</mn></msup></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">𝐱</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">,</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml">𝐏</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><mover accent="true" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">𝐗</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.2.2.1.1.3.4" xref="S3.E2.m1.2.2.1.1.3.4.cmml">+</mo><mrow id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml"><msup id="S3.E2.m1.2.2.1.1.3.3.4" xref="S3.E2.m1.2.2.1.1.3.3.4.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.4.2" xref="S3.E2.m1.2.2.1.1.3.3.4.2.cmml">d</mi><mn id="S3.E2.m1.2.2.1.1.3.3.4.3" xref="S3.E2.m1.2.2.1.1.3.3.4.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.3.3" xref="S3.E2.m1.2.2.1.1.3.3.3.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.3.3.2.2" xref="S3.E2.m1.2.2.1.1.3.3.2.3.cmml"><mo id="S3.E2.m1.2.2.1.1.3.3.2.2.3" xref="S3.E2.m1.2.2.1.1.3.3.2.3.cmml">(</mo><msup id="S3.E2.m1.2.2.1.1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.2.2.1.1.1.2" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1.2.cmml">𝐱</mi><mo id="S3.E2.m1.2.2.1.1.2.2.1.1.1.3" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1.3.cmml">′</mo></msup><mo id="S3.E2.m1.2.2.1.1.3.3.2.2.4" xref="S3.E2.m1.2.2.1.1.3.3.2.3.cmml">,</mo><mrow id="S3.E2.m1.2.2.1.1.3.3.2.2.2" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.cmml"><msup id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.2" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.2.cmml">𝐏</mi><mo id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.3" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.3.cmml">′</mo></msup><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.3.3.2.2.2.1" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.1.cmml">​</mo><mover accent="true" id="S3.E2.m1.2.2.1.1.3.3.2.2.2.3" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.2" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.2.cmml">𝐗</mi><mo id="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.1" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.1.cmml">^</mo></mover></mrow><mo id="S3.E2.m1.2.2.1.1.3.3.2.2.5" xref="S3.E2.m1.2.2.1.1.3.3.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.4"></eq><apply id="S3.E2.m1.2.2.1.1.5.cmml" xref="S3.E2.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.5.1.cmml" xref="S3.E2.m1.2.2.1.1.5">superscript</csymbol><apply id="S3.E2.m1.2.2.1.1.5.2.cmml" xref="S3.E2.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.5.2.1.cmml" xref="S3.E2.m1.2.2.1.1.5">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.5.2.2.cmml" xref="S3.E2.m1.2.2.1.1.5.2.2">𝑑</ci><apply id="S3.E2.m1.2.2.1.1.5.2.3.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3"><times id="S3.E2.m1.2.2.1.1.5.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.1"></times><ci id="S3.E2.m1.2.2.1.1.5.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.2">𝑅</ci><ci id="S3.E2.m1.2.2.1.1.5.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.3">𝑒</ci><ci id="S3.E2.m1.2.2.1.1.5.2.3.4.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.4">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.5.2.3.5.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.5">𝑟</ci><ci id="S3.E2.m1.2.2.1.1.5.2.3.6.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.6">𝑜</ci><ci id="S3.E2.m1.2.2.1.1.5.2.3.7.cmml" xref="S3.E2.m1.2.2.1.1.5.2.3.7">𝑗</ci></apply></apply><cn type="integer" id="S3.E2.m1.2.2.1.1.5.3.cmml" xref="S3.E2.m1.2.2.1.1.5.3">2</cn></apply><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><plus id="S3.E2.m1.2.2.1.1.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.4"></plus><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2"></times><apply id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3"><apply id="S3.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.3.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1">subscript</csymbol><min id="S3.E2.m1.2.2.1.1.1.1.3.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1.2"></min><apply id="S3.E2.m1.2.2.1.1.1.1.3.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1.3"><ci id="S3.E2.m1.2.2.1.1.1.1.3.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1.3.1">^</ci><ci id="S3.E2.m1.2.2.1.1.1.1.3.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1.3.2">𝐗</ci></apply></apply><apply id="S3.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2.2">𝑑</ci><cn type="integer" id="S3.E2.m1.2.2.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2.3">2</cn></apply></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝐱</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1"></times><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2">𝐏</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3"><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.1">^</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.2">𝐗</ci></apply></apply></interval></apply><apply id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3"><times id="S3.E2.m1.2.2.1.1.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.3"></times><apply id="S3.E2.m1.2.2.1.1.3.3.4.cmml" xref="S3.E2.m1.2.2.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.3.4.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.4">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.3.4.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.4.2">𝑑</ci><cn type="integer" id="S3.E2.m1.2.2.1.1.3.3.4.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.4.3">2</cn></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.3.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2"><apply id="S3.E2.m1.2.2.1.1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1.2">𝐱</ci><ci id="S3.E2.m1.2.2.1.1.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.2.2.1.1.1.3">′</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.3.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2"><times id="S3.E2.m1.2.2.1.1.3.3.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.1"></times><apply id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.2">𝐏</ci><ci id="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.2.3">′</ci></apply><apply id="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.3"><ci id="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.1">^</ci><ci id="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.3.2.2.2.3.2">𝐗</ci></apply></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">d_{Reproj}^{2}=\min_{\mathbf{\hat{X}}}d^{2}\left(\mathbf{x},\mathbf{P}\mathbf{\hat{X}}\right)+d^{2}\left(\mathbf{x}^{\prime},\mathbf{P}^{\prime}\mathbf{\hat{X}}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px1.p1.13" class="ltx_p">where
<math id="S3.SS1.SSS0.Px1.p1.9.m1.1" class="ltx_Math" alttext="d(\cdot)" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.9.m1.1a"><mrow id="S3.SS1.SSS0.Px1.p1.9.m1.1.2" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.1" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.1.cmml">​</mo><mrow id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.3.2" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.3.2.1" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.9.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.3.2.2" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2"><times id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.1"></times><ci id="S3.SS1.SSS0.Px1.p1.9.m1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.2.2">𝑑</ci><ci id="S3.SS1.SSS0.Px1.p1.9.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m1.1c">d(\cdot)</annotation></semantics></math> denotes Euclidean distance, <math id="S3.SS1.SSS0.Px1.p1.10.m2.1" class="ltx_Math" alttext="d_{Reproj}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.10.m2.1a"><msub id="S3.SS1.SSS0.Px1.p1.10.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.2.cmml">d</mi><mrow id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1a" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.4" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1b" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.5" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1c" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.6" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1d" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.7" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.7.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.10.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.2">𝑑</ci><apply id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.2">𝑅</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.3">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.4.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.4">𝑝</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.5.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.5">𝑟</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.6.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.6">𝑜</ci><ci id="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.7.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m2.1.1.3.7">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.10.m2.1c">d_{Reproj}</annotation></semantics></math> represents the reprojection distance  between <math id="S3.SS1.SSS0.Px1.p1.11.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.11.m3.1a"><mi id="S3.SS1.SSS0.Px1.p1.11.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.11.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.11.m3.1b"><ci id="S3.SS1.SSS0.Px1.p1.11.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.11.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.11.m3.1c">\mathbf{x}</annotation></semantics></math> and <math id="S3.SS1.SSS0.Px1.p1.12.m4.1" class="ltx_Math" alttext="\mathbf{x}^{\prime}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.12.m4.1a"><msup id="S3.SS1.SSS0.Px1.p1.12.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.12.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1.2.cmml">𝐱</mi><mo id="S3.SS1.SSS0.Px1.p1.12.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.12.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.12.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.12.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.12.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1.2">𝐱</ci><ci id="S3.SS1.SSS0.Px1.p1.12.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.12.m4.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.12.m4.1c">\mathbf{x}^{\prime}</annotation></semantics></math>.
Since there is optimization process when obtaining <math id="S3.SS1.SSS0.Px1.p1.13.m5.1" class="ltx_Math" alttext="d_{Reproj}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.13.m5.1a"><msub id="S3.SS1.SSS0.Px1.p1.13.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.2.cmml">d</mi><mrow id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1a" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.4" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1b" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.5" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1c" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.6" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1d" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.7" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.7.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.13.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.2">𝑑</ci><apply id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3"><times id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.1"></times><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.2">𝑅</ci><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.3">𝑒</ci><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.4.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.4">𝑝</ci><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.5.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.5">𝑟</ci><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.6.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.6">𝑜</ci><ci id="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.7.cmml" xref="S3.SS1.SSS0.Px1.p1.13.m5.1.1.3.7">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.13.m5.1c">d_{Reproj}</annotation></semantics></math>, we adopt an one-step method which is its first-order approximation <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a href="#bib.bib20" title="" class="ltx_ref">2003</a>)</cite>. This approximation is also called Sampson distance as</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.7" class="ltx_Math" alttext="d_{Sampson}=\frac{\mathbf{x}^{\prime\top}\mathbf{F}\mathbf{x}}{(\mathbf{F}\mathbf{x})_{1}^{2}+(\mathbf{F}\mathbf{x})_{2}^{2}+\left(\mathbf{F}^{\top}\mathbf{x}^{\prime}\right)_{1}^{2}+\left(\mathbf{F}^{\top}\mathbf{x}^{\prime}\right)_{2}^{2}}," display="block"><semantics id="S3.E3.m1.7a"><mrow id="S3.E3.m1.7.7.1" xref="S3.E3.m1.7.7.1.1.cmml"><mrow id="S3.E3.m1.7.7.1.1" xref="S3.E3.m1.7.7.1.1.cmml"><msub id="S3.E3.m1.7.7.1.1.2" xref="S3.E3.m1.7.7.1.1.2.cmml"><mi id="S3.E3.m1.7.7.1.1.2.2" xref="S3.E3.m1.7.7.1.1.2.2.cmml">d</mi><mrow id="S3.E3.m1.7.7.1.1.2.3" xref="S3.E3.m1.7.7.1.1.2.3.cmml"><mi id="S3.E3.m1.7.7.1.1.2.3.2" xref="S3.E3.m1.7.7.1.1.2.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.1.1.2.3.1" xref="S3.E3.m1.7.7.1.1.2.3.1.cmml">​</mo><mi id="S3.E3.m1.7.7.1.1.2.3.3" xref="S3.E3.m1.7.7.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.1.1.2.3.1a" xref="S3.E3.m1.7.7.1.1.2.3.1.cmml">​</mo><mi id="S3.E3.m1.7.7.1.1.2.3.4" xref="S3.E3.m1.7.7.1.1.2.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.1.1.2.3.1b" xref="S3.E3.m1.7.7.1.1.2.3.1.cmml">​</mo><mi id="S3.E3.m1.7.7.1.1.2.3.5" xref="S3.E3.m1.7.7.1.1.2.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.1.1.2.3.1c" xref="S3.E3.m1.7.7.1.1.2.3.1.cmml">​</mo><mi id="S3.E3.m1.7.7.1.1.2.3.6" xref="S3.E3.m1.7.7.1.1.2.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.1.1.2.3.1d" xref="S3.E3.m1.7.7.1.1.2.3.1.cmml">​</mo><mi id="S3.E3.m1.7.7.1.1.2.3.7" xref="S3.E3.m1.7.7.1.1.2.3.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.1.1.2.3.1e" xref="S3.E3.m1.7.7.1.1.2.3.1.cmml">​</mo><mi id="S3.E3.m1.7.7.1.1.2.3.8" xref="S3.E3.m1.7.7.1.1.2.3.8.cmml">n</mi></mrow></msub><mo id="S3.E3.m1.7.7.1.1.1" xref="S3.E3.m1.7.7.1.1.1.cmml">=</mo><mfrac id="S3.E3.m1.6.6" xref="S3.E3.m1.6.6.cmml"><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><msup id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.4.cmml"><mi id="S3.E3.m1.2.2.2.4.2" xref="S3.E3.m1.2.2.2.4.2.cmml">𝐱</mi><mrow id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.3.cmml"><mo mathsize="142%" id="S3.E3.m1.2.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml">′</mo><mo lspace="0.222em" id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.3.cmml">⁣</mo><mo id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml">⊤</mo></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">​</mo><mi id="S3.E3.m1.2.2.2.5" xref="S3.E3.m1.2.2.2.5.cmml">𝐅𝐱</mi></mrow><mrow id="S3.E3.m1.6.6.6" xref="S3.E3.m1.6.6.6.cmml"><msubsup id="S3.E3.m1.6.6.6.6" xref="S3.E3.m1.6.6.6.6.cmml"><mrow id="S3.E3.m1.6.6.6.6.2.2.2" xref="S3.E3.m1.6.6.6.6.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.6.6.2.2.2.1" xref="S3.E3.m1.6.6.6.6.cmml">(</mo><mi id="S3.E3.m1.3.3.3.1" xref="S3.E3.m1.3.3.3.1.cmml">𝐅𝐱</mi><mo stretchy="false" id="S3.E3.m1.6.6.6.6.2.2.2.2" xref="S3.E3.m1.6.6.6.6.cmml">)</mo></mrow><mn id="S3.E3.m1.6.6.6.6.2.3" xref="S3.E3.m1.6.6.6.6.2.3.cmml">1</mn><mn id="S3.E3.m1.6.6.6.6.3" xref="S3.E3.m1.6.6.6.6.3.cmml">2</mn></msubsup><mo id="S3.E3.m1.6.6.6.5" xref="S3.E3.m1.6.6.6.5.cmml">+</mo><msubsup id="S3.E3.m1.6.6.6.7" xref="S3.E3.m1.6.6.6.7.cmml"><mrow id="S3.E3.m1.6.6.6.7.2.2.2" xref="S3.E3.m1.6.6.6.7.cmml"><mo stretchy="false" id="S3.E3.m1.6.6.6.7.2.2.2.1" xref="S3.E3.m1.6.6.6.7.cmml">(</mo><mi id="S3.E3.m1.4.4.4.2" xref="S3.E3.m1.4.4.4.2.cmml">𝐅𝐱</mi><mo stretchy="false" id="S3.E3.m1.6.6.6.7.2.2.2.2" xref="S3.E3.m1.6.6.6.7.cmml">)</mo></mrow><mn id="S3.E3.m1.6.6.6.7.2.3" xref="S3.E3.m1.6.6.6.7.2.3.cmml">2</mn><mn id="S3.E3.m1.6.6.6.7.3" xref="S3.E3.m1.6.6.6.7.3.cmml">2</mn></msubsup><mo id="S3.E3.m1.6.6.6.5a" xref="S3.E3.m1.6.6.6.5.cmml">+</mo><msubsup id="S3.E3.m1.5.5.5.3" xref="S3.E3.m1.5.5.5.3.cmml"><mrow id="S3.E3.m1.5.5.5.3.1.1.1" xref="S3.E3.m1.5.5.5.3.1.1.1.1.cmml"><mo id="S3.E3.m1.5.5.5.3.1.1.1.2" xref="S3.E3.m1.5.5.5.3.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.5.3.1.1.1.1" xref="S3.E3.m1.5.5.5.3.1.1.1.1.cmml"><msup id="S3.E3.m1.5.5.5.3.1.1.1.1.2" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2.cmml"><mi id="S3.E3.m1.5.5.5.3.1.1.1.1.2.2" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2.2.cmml">𝐅</mi><mo id="S3.E3.m1.5.5.5.3.1.1.1.1.2.3" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2.3.cmml">⊤</mo></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.5.3.1.1.1.1.1" xref="S3.E3.m1.5.5.5.3.1.1.1.1.1.cmml">​</mo><msup id="S3.E3.m1.5.5.5.3.1.1.1.1.3" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3.cmml"><mi id="S3.E3.m1.5.5.5.3.1.1.1.1.3.2" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3.2.cmml">𝐱</mi><mo id="S3.E3.m1.5.5.5.3.1.1.1.1.3.3" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3.3.cmml">′</mo></msup></mrow><mo id="S3.E3.m1.5.5.5.3.1.1.1.3" xref="S3.E3.m1.5.5.5.3.1.1.1.1.cmml">)</mo></mrow><mn id="S3.E3.m1.5.5.5.3.1.3" xref="S3.E3.m1.5.5.5.3.1.3.cmml">1</mn><mn id="S3.E3.m1.5.5.5.3.3" xref="S3.E3.m1.5.5.5.3.3.cmml">2</mn></msubsup><mo id="S3.E3.m1.6.6.6.5b" xref="S3.E3.m1.6.6.6.5.cmml">+</mo><msubsup id="S3.E3.m1.6.6.6.4" xref="S3.E3.m1.6.6.6.4.cmml"><mrow id="S3.E3.m1.6.6.6.4.1.1.1" xref="S3.E3.m1.6.6.6.4.1.1.1.1.cmml"><mo id="S3.E3.m1.6.6.6.4.1.1.1.2" xref="S3.E3.m1.6.6.6.4.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.6.6.6.4.1.1.1.1" xref="S3.E3.m1.6.6.6.4.1.1.1.1.cmml"><msup id="S3.E3.m1.6.6.6.4.1.1.1.1.2" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2.cmml"><mi id="S3.E3.m1.6.6.6.4.1.1.1.1.2.2" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2.2.cmml">𝐅</mi><mo id="S3.E3.m1.6.6.6.4.1.1.1.1.2.3" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2.3.cmml">⊤</mo></msup><mo lspace="0em" rspace="0em" id="S3.E3.m1.6.6.6.4.1.1.1.1.1" xref="S3.E3.m1.6.6.6.4.1.1.1.1.1.cmml">​</mo><msup id="S3.E3.m1.6.6.6.4.1.1.1.1.3" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3.cmml"><mi id="S3.E3.m1.6.6.6.4.1.1.1.1.3.2" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3.2.cmml">𝐱</mi><mo id="S3.E3.m1.6.6.6.4.1.1.1.1.3.3" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3.3.cmml">′</mo></msup></mrow><mo id="S3.E3.m1.6.6.6.4.1.1.1.3" xref="S3.E3.m1.6.6.6.4.1.1.1.1.cmml">)</mo></mrow><mn id="S3.E3.m1.6.6.6.4.1.3" xref="S3.E3.m1.6.6.6.4.1.3.cmml">2</mn><mn id="S3.E3.m1.6.6.6.4.3" xref="S3.E3.m1.6.6.6.4.3.cmml">2</mn></msubsup></mrow></mfrac></mrow><mo id="S3.E3.m1.7.7.1.2" xref="S3.E3.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.7b"><apply id="S3.E3.m1.7.7.1.1.cmml" xref="S3.E3.m1.7.7.1"><eq id="S3.E3.m1.7.7.1.1.1.cmml" xref="S3.E3.m1.7.7.1.1.1"></eq><apply id="S3.E3.m1.7.7.1.1.2.cmml" xref="S3.E3.m1.7.7.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.7.7.1.1.2.1.cmml" xref="S3.E3.m1.7.7.1.1.2">subscript</csymbol><ci id="S3.E3.m1.7.7.1.1.2.2.cmml" xref="S3.E3.m1.7.7.1.1.2.2">𝑑</ci><apply id="S3.E3.m1.7.7.1.1.2.3.cmml" xref="S3.E3.m1.7.7.1.1.2.3"><times id="S3.E3.m1.7.7.1.1.2.3.1.cmml" xref="S3.E3.m1.7.7.1.1.2.3.1"></times><ci id="S3.E3.m1.7.7.1.1.2.3.2.cmml" xref="S3.E3.m1.7.7.1.1.2.3.2">𝑆</ci><ci id="S3.E3.m1.7.7.1.1.2.3.3.cmml" xref="S3.E3.m1.7.7.1.1.2.3.3">𝑎</ci><ci id="S3.E3.m1.7.7.1.1.2.3.4.cmml" xref="S3.E3.m1.7.7.1.1.2.3.4">𝑚</ci><ci id="S3.E3.m1.7.7.1.1.2.3.5.cmml" xref="S3.E3.m1.7.7.1.1.2.3.5">𝑝</ci><ci id="S3.E3.m1.7.7.1.1.2.3.6.cmml" xref="S3.E3.m1.7.7.1.1.2.3.6">𝑠</ci><ci id="S3.E3.m1.7.7.1.1.2.3.7.cmml" xref="S3.E3.m1.7.7.1.1.2.3.7">𝑜</ci><ci id="S3.E3.m1.7.7.1.1.2.3.8.cmml" xref="S3.E3.m1.7.7.1.1.2.3.8">𝑛</ci></apply></apply><apply id="S3.E3.m1.6.6.cmml" xref="S3.E3.m1.6.6"><divide id="S3.E3.m1.6.6.7.cmml" xref="S3.E3.m1.6.6"></divide><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><apply id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.1.cmml" xref="S3.E3.m1.2.2.2.4">superscript</csymbol><ci id="S3.E3.m1.2.2.2.4.2.cmml" xref="S3.E3.m1.2.2.2.4.2">𝐱</ci><list id="S3.E3.m1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><ci id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1">′</ci><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">top</csymbol></list></apply><ci id="S3.E3.m1.2.2.2.5.cmml" xref="S3.E3.m1.2.2.2.5">𝐅𝐱</ci></apply><apply id="S3.E3.m1.6.6.6.cmml" xref="S3.E3.m1.6.6.6"><plus id="S3.E3.m1.6.6.6.5.cmml" xref="S3.E3.m1.6.6.6.5"></plus><apply id="S3.E3.m1.6.6.6.6.cmml" xref="S3.E3.m1.6.6.6.6"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.6.1.cmml" xref="S3.E3.m1.6.6.6.6">superscript</csymbol><apply id="S3.E3.m1.6.6.6.6.2.cmml" xref="S3.E3.m1.6.6.6.6"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.6.2.1.cmml" xref="S3.E3.m1.6.6.6.6">subscript</csymbol><ci id="S3.E3.m1.3.3.3.1.cmml" xref="S3.E3.m1.3.3.3.1">𝐅𝐱</ci><cn type="integer" id="S3.E3.m1.6.6.6.6.2.3.cmml" xref="S3.E3.m1.6.6.6.6.2.3">1</cn></apply><cn type="integer" id="S3.E3.m1.6.6.6.6.3.cmml" xref="S3.E3.m1.6.6.6.6.3">2</cn></apply><apply id="S3.E3.m1.6.6.6.7.cmml" xref="S3.E3.m1.6.6.6.7"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.7.1.cmml" xref="S3.E3.m1.6.6.6.7">superscript</csymbol><apply id="S3.E3.m1.6.6.6.7.2.cmml" xref="S3.E3.m1.6.6.6.7"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.7.2.1.cmml" xref="S3.E3.m1.6.6.6.7">subscript</csymbol><ci id="S3.E3.m1.4.4.4.2.cmml" xref="S3.E3.m1.4.4.4.2">𝐅𝐱</ci><cn type="integer" id="S3.E3.m1.6.6.6.7.2.3.cmml" xref="S3.E3.m1.6.6.6.7.2.3">2</cn></apply><cn type="integer" id="S3.E3.m1.6.6.6.7.3.cmml" xref="S3.E3.m1.6.6.6.7.3">2</cn></apply><apply id="S3.E3.m1.5.5.5.3.cmml" xref="S3.E3.m1.5.5.5.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.5.3.2.cmml" xref="S3.E3.m1.5.5.5.3">superscript</csymbol><apply id="S3.E3.m1.5.5.5.3.1.cmml" xref="S3.E3.m1.5.5.5.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.5.3.1.2.cmml" xref="S3.E3.m1.5.5.5.3">subscript</csymbol><apply id="S3.E3.m1.5.5.5.3.1.1.1.1.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1"><times id="S3.E3.m1.5.5.5.3.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.1"></times><apply id="S3.E3.m1.5.5.5.3.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.5.3.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.5.5.5.3.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2.2">𝐅</ci><csymbol cd="latexml" id="S3.E3.m1.5.5.5.3.1.1.1.1.2.3.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.2.3">top</csymbol></apply><apply id="S3.E3.m1.5.5.5.3.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.5.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.5.5.5.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3.2">𝐱</ci><ci id="S3.E3.m1.5.5.5.3.1.1.1.1.3.3.cmml" xref="S3.E3.m1.5.5.5.3.1.1.1.1.3.3">′</ci></apply></apply><cn type="integer" id="S3.E3.m1.5.5.5.3.1.3.cmml" xref="S3.E3.m1.5.5.5.3.1.3">1</cn></apply><cn type="integer" id="S3.E3.m1.5.5.5.3.3.cmml" xref="S3.E3.m1.5.5.5.3.3">2</cn></apply><apply id="S3.E3.m1.6.6.6.4.cmml" xref="S3.E3.m1.6.6.6.4"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.4.2.cmml" xref="S3.E3.m1.6.6.6.4">superscript</csymbol><apply id="S3.E3.m1.6.6.6.4.1.cmml" xref="S3.E3.m1.6.6.6.4"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.4.1.2.cmml" xref="S3.E3.m1.6.6.6.4">subscript</csymbol><apply id="S3.E3.m1.6.6.6.4.1.1.1.1.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1"><times id="S3.E3.m1.6.6.6.4.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.1"></times><apply id="S3.E3.m1.6.6.6.4.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.4.1.1.1.1.2.1.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.6.6.6.4.1.1.1.1.2.2.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2.2">𝐅</ci><csymbol cd="latexml" id="S3.E3.m1.6.6.6.4.1.1.1.1.2.3.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.2.3">top</csymbol></apply><apply id="S3.E3.m1.6.6.6.4.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.6.4.1.1.1.1.3.1.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.6.6.6.4.1.1.1.1.3.2.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3.2">𝐱</ci><ci id="S3.E3.m1.6.6.6.4.1.1.1.1.3.3.cmml" xref="S3.E3.m1.6.6.6.4.1.1.1.1.3.3">′</ci></apply></apply><cn type="integer" id="S3.E3.m1.6.6.6.4.1.3.cmml" xref="S3.E3.m1.6.6.6.4.1.3">2</cn></apply><cn type="integer" id="S3.E3.m1.6.6.6.4.3.cmml" xref="S3.E3.m1.6.6.6.4.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.7c">d_{Sampson}=\frac{\mathbf{x}^{\prime\top}\mathbf{F}\mathbf{x}}{(\mathbf{F}\mathbf{x})_{1}^{2}+(\mathbf{F}\mathbf{x})_{2}^{2}+\left(\mathbf{F}^{\top}\mathbf{x}^{\prime}\right)_{1}^{2}+\left(\mathbf{F}^{\top}\mathbf{x}^{\prime}\right)_{2}^{2}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS0.Px1.p1.18" class="ltx_p">where <math id="S3.SS1.SSS0.Px1.p1.14.m1.1" class="ltx_Math" alttext="\mathbf{F}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.14.m1.1a"><mi id="S3.SS1.SSS0.Px1.p1.14.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.14.m1.1.1.cmml">𝐅</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.14.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.14.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.14.m1.1.1">𝐅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.14.m1.1c">\mathbf{F}</annotation></semantics></math> is fundamental matrix, the subscript <math id="S3.SS1.SSS0.Px1.p1.15.m2.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.15.m2.1a"><mn id="S3.SS1.SSS0.Px1.p1.15.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.15.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.15.m2.1b"><cn type="integer" id="S3.SS1.SSS0.Px1.p1.15.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.15.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.15.m2.1c">1</annotation></semantics></math> or <math id="S3.SS1.SSS0.Px1.p1.16.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.16.m3.1a"><mn id="S3.SS1.SSS0.Px1.p1.16.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.16.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.16.m3.1b"><cn type="integer" id="S3.SS1.SSS0.Px1.p1.16.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.16.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.16.m3.1c">2</annotation></semantics></math> denotes the first or second element of a vector. By using Sampson distance, we can directly obtain distance between a pair of locations without knowing the intermediate <math id="S3.SS1.SSS0.Px1.p1.17.m4.1" class="ltx_Math" alttext="\mathbf{\hat{X}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.17.m4.1a"><mover accent="true" id="S3.SS1.SSS0.Px1.p1.17.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.17.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.17.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.17.m4.1.1.2.cmml">𝐗</mi><mo id="S3.SS1.SSS0.Px1.p1.17.m4.1.1.1" xref="S3.SS1.SSS0.Px1.p1.17.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.17.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.17.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.17.m4.1.1"><ci id="S3.SS1.SSS0.Px1.p1.17.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.17.m4.1.1.1">^</ci><ci id="S3.SS1.SSS0.Px1.p1.17.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.17.m4.1.1.2">𝐗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.17.m4.1c">\mathbf{\hat{X}}</annotation></semantics></math>. In <em id="S3.SS1.SSS0.Px1.p1.18.1" class="ltx_emph ltx_font_italic">AdaFuse</em>, we use Sampson distance to represent to what extent a pair of <math id="S3.SS1.SSS0.Px1.p1.18.m5.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.18.m5.1a"><mn id="S3.SS1.SSS0.Px1.p1.18.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.18.m5.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.18.m5.1b"><cn type="integer" id="S3.SS1.SSS0.Px1.p1.18.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.18.m5.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.18.m5.1c">2</annotation></semantics></math>D joint detections support each other.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Heatmap Fusion</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Multiview fusion is applied to heatmaps rather than intermediate features as shown in Figure <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. This is because heatmap has the nice property of sparsity which can simplify the point-point matching. A heatmap produces a per-pixel likelihood for joint locations in the image. Specifically, it is generated as a two-dimensional Gaussian distribution centered at the coordinate of the joint. So it has a small number of large responses near the joint location, and a large number of zeros at other locations. See Figure <a href="#S3.F4" title="Figure 4 ‣ 3.1 Epipolar Geometry ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> (a) for an example heatmap of the right knee joint.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.2" class="ltx_p">The sparse heatmaps allow us to safely skip the exact point-point matching because the features at the “zero” locations on the epipolar line are not contributing to the feature fusion. As a result, instead of trying to find the exact corresponding location in the other view, <em id="S3.SS2.p2.2.1" class="ltx_emph ltx_font_italic">we simply select the largest response on the epipolar line as the matched point</em>. This is a reasonable simplification because the corresponding point usually has the largest response. For example, in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.1 Epipolar Geometry ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, for each location <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbf{x}</annotation></semantics></math>, we first compute the corresponding epipolar lines in the other two camera views. Then we find the largest responses on the two epipolar lines, respectively and fuse them with the response at <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\mathbf{x}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.9" class="ltx_p">Let us denote the heatmap in view <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">v</annotation></semantics></math> as <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{H}^{v}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">𝐇</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">v</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝐇</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathbf{H}^{v}</annotation></semantics></math>. The response at the location <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{x}</annotation></semantics></math> of the heatmap is denoted as <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="\mathbf{H}^{v}(\mathbf{x})" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.2" xref="S3.SS2.p3.4.m4.1.2.cmml"><msup id="S3.SS2.p3.4.m4.1.2.2" xref="S3.SS2.p3.4.m4.1.2.2.cmml"><mi id="S3.SS2.p3.4.m4.1.2.2.2" xref="S3.SS2.p3.4.m4.1.2.2.2.cmml">𝐇</mi><mi id="S3.SS2.p3.4.m4.1.2.2.3" xref="S3.SS2.p3.4.m4.1.2.2.3.cmml">v</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS2.p3.4.m4.1.2.1" xref="S3.SS2.p3.4.m4.1.2.1.cmml">​</mo><mrow id="S3.SS2.p3.4.m4.1.2.3.2" xref="S3.SS2.p3.4.m4.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.4.m4.1.2.3.2.1" xref="S3.SS2.p3.4.m4.1.2.cmml">(</mo><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">𝐱</mi><mo stretchy="false" id="S3.SS2.p3.4.m4.1.2.3.2.2" xref="S3.SS2.p3.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.2.cmml" xref="S3.SS2.p3.4.m4.1.2"><times id="S3.SS2.p3.4.m4.1.2.1.cmml" xref="S3.SS2.p3.4.m4.1.2.1"></times><apply id="S3.SS2.p3.4.m4.1.2.2.cmml" xref="S3.SS2.p3.4.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.2.2.1.cmml" xref="S3.SS2.p3.4.m4.1.2.2">superscript</csymbol><ci id="S3.SS2.p3.4.m4.1.2.2.2.cmml" xref="S3.SS2.p3.4.m4.1.2.2.2">𝐇</ci><ci id="S3.SS2.p3.4.m4.1.2.2.3.cmml" xref="S3.SS2.p3.4.m4.1.2.2.3">𝑣</ci></apply><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\mathbf{H}^{v}(\mathbf{x})</annotation></semantics></math>. The corresponding epipolar line of <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathbf{x}</annotation></semantics></math> in view <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="u" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mi id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><ci id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">u</annotation></semantics></math> is denoted as <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="\mathbf{I}^{u}(\mathbf{x})" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.2" xref="S3.SS2.p3.7.m7.1.2.cmml"><msup id="S3.SS2.p3.7.m7.1.2.2" xref="S3.SS2.p3.7.m7.1.2.2.cmml"><mi id="S3.SS2.p3.7.m7.1.2.2.2" xref="S3.SS2.p3.7.m7.1.2.2.2.cmml">𝐈</mi><mi id="S3.SS2.p3.7.m7.1.2.2.3" xref="S3.SS2.p3.7.m7.1.2.2.3.cmml">u</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.2.1" xref="S3.SS2.p3.7.m7.1.2.1.cmml">​</mo><mrow id="S3.SS2.p3.7.m7.1.2.3.2" xref="S3.SS2.p3.7.m7.1.2.cmml"><mo stretchy="false" id="S3.SS2.p3.7.m7.1.2.3.2.1" xref="S3.SS2.p3.7.m7.1.2.cmml">(</mo><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">𝐱</mi><mo stretchy="false" id="S3.SS2.p3.7.m7.1.2.3.2.2" xref="S3.SS2.p3.7.m7.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.2.cmml" xref="S3.SS2.p3.7.m7.1.2"><times id="S3.SS2.p3.7.m7.1.2.1.cmml" xref="S3.SS2.p3.7.m7.1.2.1"></times><apply id="S3.SS2.p3.7.m7.1.2.2.cmml" xref="S3.SS2.p3.7.m7.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.2.2.1.cmml" xref="S3.SS2.p3.7.m7.1.2.2">superscript</csymbol><ci id="S3.SS2.p3.7.m7.1.2.2.2.cmml" xref="S3.SS2.p3.7.m7.1.2.2.2">𝐈</ci><ci id="S3.SS2.p3.7.m7.1.2.2.3.cmml" xref="S3.SS2.p3.7.m7.1.2.2.3">𝑢</ci></apply><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">\mathbf{I}^{u}(\mathbf{x})</annotation></semantics></math> which consists of a number of discrete locations on the heatmap <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="\mathbf{H}^{u}" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><msup id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mi id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml">𝐇</mi><mi id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml">u</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">superscript</csymbol><ci id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2">𝐇</ci><ci id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">\mathbf{H}^{u}</annotation></semantics></math>. The epipolar line can be analytically computed based on the camera parameters for every location <math id="S3.SS2.p3.9.m9.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS2.p3.9.m9.1a"><mi id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><ci id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">\mathbf{x}</annotation></semantics></math>. Then we formulate multiview fusion as</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.4" class="ltx_Math" alttext="\mathbf{\hat{H}}^{v}(\mathbf{x})=\lambda\mathbf{H}^{v}(\mathbf{x})+\frac{1-\lambda}{N}\sum_{u=1}^{N}\max_{\mathbf{x^{\prime}}\in\mathbf{I}^{u}(\mathbf{x})}{\mathbf{H}^{u}(\mathbf{x}^{\prime})}," display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4.1" xref="S3.E4.m1.4.4.1.1.cmml"><mrow id="S3.E4.m1.4.4.1.1" xref="S3.E4.m1.4.4.1.1.cmml"><mrow id="S3.E4.m1.4.4.1.1.3" xref="S3.E4.m1.4.4.1.1.3.cmml"><msup id="S3.E4.m1.4.4.1.1.3.2" xref="S3.E4.m1.4.4.1.1.3.2.cmml"><mover accent="true" id="S3.E4.m1.4.4.1.1.3.2.2" xref="S3.E4.m1.4.4.1.1.3.2.2.cmml"><mi id="S3.E4.m1.4.4.1.1.3.2.2.2" xref="S3.E4.m1.4.4.1.1.3.2.2.2.cmml">𝐇</mi><mo id="S3.E4.m1.4.4.1.1.3.2.2.1" xref="S3.E4.m1.4.4.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S3.E4.m1.4.4.1.1.3.2.3" xref="S3.E4.m1.4.4.1.1.3.2.3.cmml">v</mi></msup><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.3.1" xref="S3.E4.m1.4.4.1.1.3.1.cmml">​</mo><mrow id="S3.E4.m1.4.4.1.1.3.3.2" xref="S3.E4.m1.4.4.1.1.3.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.3.3.2.1" xref="S3.E4.m1.4.4.1.1.3.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">𝐱</mi><mo stretchy="false" id="S3.E4.m1.4.4.1.1.3.3.2.2" xref="S3.E4.m1.4.4.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.4.4.1.1.2" xref="S3.E4.m1.4.4.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.4.4.1.1.1" xref="S3.E4.m1.4.4.1.1.1.cmml"><mrow id="S3.E4.m1.4.4.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.3.cmml"><mi id="S3.E4.m1.4.4.1.1.1.3.2" xref="S3.E4.m1.4.4.1.1.1.3.2.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.3.1" xref="S3.E4.m1.4.4.1.1.1.3.1.cmml">​</mo><msup id="S3.E4.m1.4.4.1.1.1.3.3" xref="S3.E4.m1.4.4.1.1.1.3.3.cmml"><mi id="S3.E4.m1.4.4.1.1.1.3.3.2" xref="S3.E4.m1.4.4.1.1.1.3.3.2.cmml">𝐇</mi><mi id="S3.E4.m1.4.4.1.1.1.3.3.3" xref="S3.E4.m1.4.4.1.1.1.3.3.3.cmml">v</mi></msup><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.3.1a" xref="S3.E4.m1.4.4.1.1.1.3.1.cmml">​</mo><mrow id="S3.E4.m1.4.4.1.1.1.3.4.2" xref="S3.E4.m1.4.4.1.1.1.3.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.3.4.2.1" xref="S3.E4.m1.4.4.1.1.1.3.cmml">(</mo><mi id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">𝐱</mi><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.3.4.2.2" xref="S3.E4.m1.4.4.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.4.4.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.2.cmml">+</mo><mrow id="S3.E4.m1.4.4.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.cmml"><mfrac id="S3.E4.m1.4.4.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.3.cmml"><mrow id="S3.E4.m1.4.4.1.1.1.1.3.2" xref="S3.E4.m1.4.4.1.1.1.1.3.2.cmml"><mn id="S3.E4.m1.4.4.1.1.1.1.3.2.2" xref="S3.E4.m1.4.4.1.1.1.1.3.2.2.cmml">1</mn><mo id="S3.E4.m1.4.4.1.1.1.1.3.2.1" xref="S3.E4.m1.4.4.1.1.1.1.3.2.1.cmml">−</mo><mi id="S3.E4.m1.4.4.1.1.1.1.3.2.3" xref="S3.E4.m1.4.4.1.1.1.1.3.2.3.cmml">λ</mi></mrow><mi id="S3.E4.m1.4.4.1.1.1.1.3.3" xref="S3.E4.m1.4.4.1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.cmml"><munderover id="S3.E4.m1.4.4.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E4.m1.4.4.1.1.1.1.1.2.2.2" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.2" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.2.cmml">u</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.1" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.3" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E4.m1.4.4.1.1.1.1.1.2.3" xref="S3.E4.m1.4.4.1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.cmml"><munder id="S3.E4.m1.4.4.1.1.1.1.1.1.3.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.2.cmml">max</mi><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><msup id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.3.2.cmml">𝐱</mi><mo id="S3.E4.m1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.3.3.cmml">′</mo></msup><mo id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.2.cmml">∈</mo><mrow id="S3.E4.m1.1.1.1.4" xref="S3.E4.m1.1.1.1.4.cmml"><msup id="S3.E4.m1.1.1.1.4.2" xref="S3.E4.m1.1.1.1.4.2.cmml"><mi id="S3.E4.m1.1.1.1.4.2.2" xref="S3.E4.m1.1.1.1.4.2.2.cmml">𝐈</mi><mi id="S3.E4.m1.1.1.1.4.2.3" xref="S3.E4.m1.1.1.1.4.2.3.cmml">u</mi></msup><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.4.1" xref="S3.E4.m1.1.1.1.4.1.cmml">​</mo><mrow id="S3.E4.m1.1.1.1.4.3.2" xref="S3.E4.m1.1.1.1.4.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.4.3.2.1" xref="S3.E4.m1.1.1.1.4.cmml">(</mo><mi id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S3.E4.m1.1.1.1.4.3.2.2" xref="S3.E4.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mo lspace="0.167em" id="S3.E4.m1.4.4.1.1.1.1.1.1.3a" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.cmml">⁡</mo><msup id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.2.cmml">𝐇</mi><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.3.cmml">u</mi></msup></mrow><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.4.4.1.2" xref="S3.E4.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.1.1.cmml" xref="S3.E4.m1.4.4.1"><eq id="S3.E4.m1.4.4.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.2"></eq><apply id="S3.E4.m1.4.4.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.3"><times id="S3.E4.m1.4.4.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.3.1"></times><apply id="S3.E4.m1.4.4.1.1.3.2.cmml" xref="S3.E4.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.3.2.1.cmml" xref="S3.E4.m1.4.4.1.1.3.2">superscript</csymbol><apply id="S3.E4.m1.4.4.1.1.3.2.2.cmml" xref="S3.E4.m1.4.4.1.1.3.2.2"><ci id="S3.E4.m1.4.4.1.1.3.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.3.2.2.1">^</ci><ci id="S3.E4.m1.4.4.1.1.3.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.3.2.2.2">𝐇</ci></apply><ci id="S3.E4.m1.4.4.1.1.3.2.3.cmml" xref="S3.E4.m1.4.4.1.1.3.2.3">𝑣</ci></apply><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝐱</ci></apply><apply id="S3.E4.m1.4.4.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1"><plus id="S3.E4.m1.4.4.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.2"></plus><apply id="S3.E4.m1.4.4.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.3"><times id="S3.E4.m1.4.4.1.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.3.1"></times><ci id="S3.E4.m1.4.4.1.1.1.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.3.2">𝜆</ci><apply id="S3.E4.m1.4.4.1.1.1.3.3.cmml" xref="S3.E4.m1.4.4.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.3.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.3.3">superscript</csymbol><ci id="S3.E4.m1.4.4.1.1.1.3.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.3.3.2">𝐇</ci><ci id="S3.E4.m1.4.4.1.1.1.3.3.3.cmml" xref="S3.E4.m1.4.4.1.1.1.3.3.3">𝑣</ci></apply><ci id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">𝐱</ci></apply><apply id="S3.E4.m1.4.4.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1"><times id="S3.E4.m1.4.4.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.2"></times><apply id="S3.E4.m1.4.4.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3"><divide id="S3.E4.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3"></divide><apply id="S3.E4.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.2"><minus id="S3.E4.m1.4.4.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.2.1"></minus><cn type="integer" id="S3.E4.m1.4.4.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.2.2">1</cn><ci id="S3.E4.m1.4.4.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.2.3">𝜆</ci></apply><ci id="S3.E4.m1.4.4.1.1.1.1.3.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.3">𝑁</ci></apply><apply id="S3.E4.m1.4.4.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1"><apply id="S3.E4.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E4.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2">subscript</csymbol><sum id="S3.E4.m1.4.4.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.2"></sum><apply id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3"><eq id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.2">𝑢</ci><cn type="integer" id="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E4.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.2.3">𝑁</ci></apply><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1"><times id="S3.E4.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3"><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.1">subscript</csymbol><max id="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.1.2"></max><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><in id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.2"></in><apply id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.3">superscript</csymbol><ci id="S3.E4.m1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.3.2">𝐱</ci><ci id="S3.E4.m1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.3.3">′</ci></apply><apply id="S3.E4.m1.1.1.1.4.cmml" xref="S3.E4.m1.1.1.1.4"><times id="S3.E4.m1.1.1.1.4.1.cmml" xref="S3.E4.m1.1.1.1.4.1"></times><apply id="S3.E4.m1.1.1.1.4.2.cmml" xref="S3.E4.m1.1.1.1.4.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.4.2.1.cmml" xref="S3.E4.m1.1.1.1.4.2">superscript</csymbol><ci id="S3.E4.m1.1.1.1.4.2.2.cmml" xref="S3.E4.m1.1.1.1.4.2.2">𝐈</ci><ci id="S3.E4.m1.1.1.1.4.2.3.cmml" xref="S3.E4.m1.1.1.1.4.2.3">𝑢</ci></apply><ci id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1">𝐱</ci></apply></apply></apply><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2">superscript</csymbol><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.2">𝐇</ci><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.3.2.3">𝑢</ci></apply></apply><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">\mathbf{\hat{H}}^{v}(\mathbf{x})=\lambda\mathbf{H}^{v}(\mathbf{x})+\frac{1-\lambda}{N}\sum_{u=1}^{N}\max_{\mathbf{x^{\prime}}\in\mathbf{I}^{u}(\mathbf{x})}{\mathbf{H}^{u}(\mathbf{x}^{\prime})},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p4.3" class="ltx_p">where <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\mathbf{\hat{H}}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mover accent="true" id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">𝐇</mi><mo id="S3.SS2.p4.1.m1.1.1.1" xref="S3.SS2.p4.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><ci id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1">^</ci><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">𝐇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\mathbf{\hat{H}}</annotation></semantics></math> denotes the fused heatmap and <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">N</annotation></semantics></math> is the number of camera views which contribute to the fusion of current view. The parameter <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">\lambda</annotation></semantics></math> balances the responses in the current and other views.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2010.13302/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="368" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The ambiguity problem in our simplified multiview fusion approach and our solution. We can see from the “fused heatmap” that the correct location has the largest response which is as expected. However, for an incorrect location <math id="S3.F5.2.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.F5.2.m1.1b"><mi id="S3.F5.2.m1.1.1" xref="S3.F5.2.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.F5.2.m1.1c"><ci id="S3.F5.2.m1.1.1.cmml" xref="S3.F5.2.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F5.2.m1.1d">\mathbf{x}</annotation></semantics></math>, there is also a chance that the response is also enhanced by at most one view. Fortunately, the correct location will be enhanced more times (three times in this example) leading to the largest response. So we apply the SoftMax operator to the fused heatmap to reduce the responses at incorrect locations.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Side Effect and Solution</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p">One side effect caused by the simplified fusion model (<span id="S3.SS3.p1.4.1" class="ltx_text ltx_font_italic">i</span>.<span id="S3.SS3.p1.4.2" class="ltx_text ltx_font_italic">e</span>. Eq. (<a href="#S3.E4" title="In 3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>)) is that some background locations may be enhanced undesirably. We visualize an example in the second row of Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We can see that many background pixels, for example <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathbf{x}</annotation></semantics></math>, have non-zero responses which are caused by fusion. This phenomenon happens because multiple epipolar lines (in other views) may pass the ground truth joint location which has large responses, and some of the epipolar lines actually correspond to background pixels in the current view. This is explained in Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. For a location <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\mathbf{x}</annotation></semantics></math> in the current view, the corresponding epipolar lines in the other three views are drawn in the first row. We can see that although <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\mathbf{x}</annotation></semantics></math> is not at a meaningful joint location, the epipolar line in the first view passes the ground truth knee joint and leads to a large unexpected response for <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">\mathbf{x}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Fortunately, there are patterns for the background pixels that could be undesirably impacted. In general, the pixels that are impacted by a high response location in another view are guaranteed to lie on the same line. More importantly, the lines that correspond to different views do not overlap. It means, for a location <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathbf{x}</annotation></semantics></math> in the background, its response can only be enhanced by at most one view. In contrast, the location which corresponds to meaningful body joints will be enhanced by multiple views. In other words, the correct location is guaranteed to have the largest response for general cases. So we take advantage of this observation and directly apply the SoftMax operator to remove the small responses. See the third row in Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> for the effect. We can see that only the large responses around the joint location are preserved.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2010.13302/assets/x6.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="286" height="367" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Network for learning adaptive fusion weights. The backbone network for pose estimation is used to extract heatmaps <math id="S3.F6.3.m1.1" class="ltx_Math" alttext="\mathbf{H}_{v}" display="inline"><semantics id="S3.F6.3.m1.1b"><msub id="S3.F6.3.m1.1.1" xref="S3.F6.3.m1.1.1.cmml"><mi id="S3.F6.3.m1.1.1.2" xref="S3.F6.3.m1.1.1.2.cmml">𝐇</mi><mi id="S3.F6.3.m1.1.1.3" xref="S3.F6.3.m1.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F6.3.m1.1c"><apply id="S3.F6.3.m1.1.1.cmml" xref="S3.F6.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F6.3.m1.1.1.1.cmml" xref="S3.F6.3.m1.1.1">subscript</csymbol><ci id="S3.F6.3.m1.1.1.2.cmml" xref="S3.F6.3.m1.1.1.2">𝐇</ci><ci id="S3.F6.3.m1.1.1.3.cmml" xref="S3.F6.3.m1.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.3.m1.1d">\mathbf{H}_{v}</annotation></semantics></math> for each view <math id="S3.F6.4.m2.1" class="ltx_Math" alttext="\mathbf{I}_{v}" display="inline"><semantics id="S3.F6.4.m2.1b"><msub id="S3.F6.4.m2.1.1" xref="S3.F6.4.m2.1.1.cmml"><mi id="S3.F6.4.m2.1.1.2" xref="S3.F6.4.m2.1.1.2.cmml">𝐈</mi><mi id="S3.F6.4.m2.1.1.3" xref="S3.F6.4.m2.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F6.4.m2.1c"><apply id="S3.F6.4.m2.1.1.cmml" xref="S3.F6.4.m2.1.1"><csymbol cd="ambiguous" id="S3.F6.4.m2.1.1.1.cmml" xref="S3.F6.4.m2.1.1">subscript</csymbol><ci id="S3.F6.4.m2.1.1.2.cmml" xref="S3.F6.4.m2.1.1.2">𝐈</ci><ci id="S3.F6.4.m2.1.1.3.cmml" xref="S3.F6.4.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F6.4.m2.1d">\mathbf{I}_{v}</annotation></semantics></math>. The heatmaps are fed to <em id="S3.F6.8.1" class="ltx_emph ltx_font_italic">appearance embedding network</em> and <em id="S3.F6.9.2" class="ltx_emph ltx_font_italic">geometry embedding network</em>, respectively, to extract features, which are concatenated and fed to a <em id="S3.F6.10.3" class="ltx_emph ltx_font_italic">weight learning network</em> to learn the fusion weights which reflect the heatmap quality in each view. The weights are used for multiview fusion. </figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Implementation Details</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">It is worth noting that the above fusion method does not have learnable parameters. So we only need to train the backbone network such as SimpleBaseline <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite> to estimate pose heatmaps. The loss function for training the backbone network is defined as MSE loss between the estimated heatmaps and ground truth heatmaps. In the testing stage, given the heatmaps estimated by SimpleBaseline, we fuse them deterministically by our approach.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Adaptive Weight for Multiview Fusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.3" class="ltx_p">The fusion strategy introduced in the previous section treats all views evenly without considering the feature quality of each view. Note that the fusion weight is <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="\frac{1-\lambda}{N}" display="inline"><semantics id="S4.p1.1.m1.1a"><mfrac id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mrow id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml"><mn id="S4.p1.1.m1.1.1.2.2" xref="S4.p1.1.m1.1.1.2.2.cmml">1</mn><mo id="S4.p1.1.m1.1.1.2.1" xref="S4.p1.1.m1.1.1.2.1.cmml">−</mo><mi id="S4.p1.1.m1.1.1.2.3" xref="S4.p1.1.m1.1.1.2.3.cmml">λ</mi></mrow><mi id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">N</mi></mfrac><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><divide id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1"></divide><apply id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2"><minus id="S4.p1.1.m1.1.1.2.1.cmml" xref="S4.p1.1.m1.1.1.2.1"></minus><cn type="integer" id="S4.p1.1.m1.1.1.2.2.cmml" xref="S4.p1.1.m1.1.1.2.2">1</cn><ci id="S4.p1.1.m1.1.1.2.3.cmml" xref="S4.p1.1.m1.1.1.2.3">𝜆</ci></apply><ci id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">\frac{1-\lambda}{N}</annotation></semantics></math> for the <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">N</annotation></semantics></math> views in Eq. (<a href="#S3.E4" title="In 3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). However, the strategy is problematic in some cases where the heatmaps of some camera views are incorrect. This is because those features may undesirably mess up the features in good views, leading to a completely incorrect <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn type="integer" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">2</annotation></semantics></math>D pose estimation results.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.3" class="ltx_p">To solve this problem, we present a weight learning network to learn an <em id="S4.p2.3.1" class="ltx_emph ltx_font_italic">adaptive weight</em> for each view to faithfully reflect its heatmap quality. It takes inputs of the heatmaps of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">N</annotation></semantics></math>-views extracted by the pose estimation network, and regresses <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">N</annotation></semantics></math> weights <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="\omega^{u}" display="inline"><semantics id="S4.p2.3.m3.1a"><msup id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">ω</mi><mi id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">u</mi></msup><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">superscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">𝜔</ci><ci id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">\omega^{u}</annotation></semantics></math>. Then multiview fusion is rewritten to consider the weights as follows</p>
</div>
<div id="S4.p3" class="ltx_para">
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.4" class="ltx_Math" alttext="\mathbf{\hat{H}}^{v}(\mathbf{x})=\omega^{v}\mathbf{H}^{v}(\mathbf{x})+\sum_{u=1}^{N}\omega^{u}\max_{\mathbf{x^{\prime}}\in\mathbf{I}^{u}(\mathbf{x})}{\mathbf{H}^{u}(\mathbf{x}^{\prime})}," display="block"><semantics id="S4.E5.m1.4a"><mrow id="S4.E5.m1.4.4.1" xref="S4.E5.m1.4.4.1.1.cmml"><mrow id="S4.E5.m1.4.4.1.1" xref="S4.E5.m1.4.4.1.1.cmml"><mrow id="S4.E5.m1.4.4.1.1.3" xref="S4.E5.m1.4.4.1.1.3.cmml"><msup id="S4.E5.m1.4.4.1.1.3.2" xref="S4.E5.m1.4.4.1.1.3.2.cmml"><mover accent="true" id="S4.E5.m1.4.4.1.1.3.2.2" xref="S4.E5.m1.4.4.1.1.3.2.2.cmml"><mi id="S4.E5.m1.4.4.1.1.3.2.2.2" xref="S4.E5.m1.4.4.1.1.3.2.2.2.cmml">𝐇</mi><mo id="S4.E5.m1.4.4.1.1.3.2.2.1" xref="S4.E5.m1.4.4.1.1.3.2.2.1.cmml">^</mo></mover><mi id="S4.E5.m1.4.4.1.1.3.2.3" xref="S4.E5.m1.4.4.1.1.3.2.3.cmml">v</mi></msup><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.1.3.1" xref="S4.E5.m1.4.4.1.1.3.1.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.3.3.2" xref="S4.E5.m1.4.4.1.1.3.cmml"><mo stretchy="false" id="S4.E5.m1.4.4.1.1.3.3.2.1" xref="S4.E5.m1.4.4.1.1.3.cmml">(</mo><mi id="S4.E5.m1.2.2" xref="S4.E5.m1.2.2.cmml">𝐱</mi><mo stretchy="false" id="S4.E5.m1.4.4.1.1.3.3.2.2" xref="S4.E5.m1.4.4.1.1.3.cmml">)</mo></mrow></mrow><mo id="S4.E5.m1.4.4.1.1.2" xref="S4.E5.m1.4.4.1.1.2.cmml">=</mo><mrow id="S4.E5.m1.4.4.1.1.1" xref="S4.E5.m1.4.4.1.1.1.cmml"><mrow id="S4.E5.m1.4.4.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.3.cmml"><msup id="S4.E5.m1.4.4.1.1.1.3.2" xref="S4.E5.m1.4.4.1.1.1.3.2.cmml"><mi id="S4.E5.m1.4.4.1.1.1.3.2.2" xref="S4.E5.m1.4.4.1.1.1.3.2.2.cmml">ω</mi><mi id="S4.E5.m1.4.4.1.1.1.3.2.3" xref="S4.E5.m1.4.4.1.1.1.3.2.3.cmml">v</mi></msup><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.1.1.3.1" xref="S4.E5.m1.4.4.1.1.1.3.1.cmml">​</mo><msup id="S4.E5.m1.4.4.1.1.1.3.3" xref="S4.E5.m1.4.4.1.1.1.3.3.cmml"><mi id="S4.E5.m1.4.4.1.1.1.3.3.2" xref="S4.E5.m1.4.4.1.1.1.3.3.2.cmml">𝐇</mi><mi id="S4.E5.m1.4.4.1.1.1.3.3.3" xref="S4.E5.m1.4.4.1.1.1.3.3.3.cmml">v</mi></msup><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.1.1.3.1a" xref="S4.E5.m1.4.4.1.1.1.3.1.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.1.3.4.2" xref="S4.E5.m1.4.4.1.1.1.3.cmml"><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.3.4.2.1" xref="S4.E5.m1.4.4.1.1.1.3.cmml">(</mo><mi id="S4.E5.m1.3.3" xref="S4.E5.m1.3.3.cmml">𝐱</mi><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.3.4.2.2" xref="S4.E5.m1.4.4.1.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.055em" id="S4.E5.m1.4.4.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.2.cmml">+</mo><mrow id="S4.E5.m1.4.4.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.cmml"><munderover id="S4.E5.m1.4.4.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.2.cmml"><mo movablelimits="false" id="S4.E5.m1.4.4.1.1.1.1.2.2.2" xref="S4.E5.m1.4.4.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S4.E5.m1.4.4.1.1.1.1.2.2.3" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.cmml"><mi id="S4.E5.m1.4.4.1.1.1.1.2.2.3.2" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.2.cmml">u</mi><mo id="S4.E5.m1.4.4.1.1.1.1.2.2.3.1" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.E5.m1.4.4.1.1.1.1.2.2.3.3" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E5.m1.4.4.1.1.1.1.2.3" xref="S4.E5.m1.4.4.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S4.E5.m1.4.4.1.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.1.cmml"><msup id="S4.E5.m1.4.4.1.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.1.3.cmml"><mi id="S4.E5.m1.4.4.1.1.1.1.1.3.2" xref="S4.E5.m1.4.4.1.1.1.1.1.3.2.cmml">ω</mi><mi id="S4.E5.m1.4.4.1.1.1.1.1.3.3" xref="S4.E5.m1.4.4.1.1.1.1.1.3.3.cmml">u</mi></msup><mo lspace="0.167em" rspace="0em" id="S4.E5.m1.4.4.1.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.1.1.1.4" xref="S4.E5.m1.4.4.1.1.1.1.1.4.cmml"><munder id="S4.E5.m1.4.4.1.1.1.1.1.4.1" xref="S4.E5.m1.4.4.1.1.1.1.1.4.1.cmml"><mi id="S4.E5.m1.4.4.1.1.1.1.1.4.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.4.1.2.cmml">max</mi><mrow id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml"><msup id="S4.E5.m1.1.1.1.3" xref="S4.E5.m1.1.1.1.3.cmml"><mi id="S4.E5.m1.1.1.1.3.2" xref="S4.E5.m1.1.1.1.3.2.cmml">𝐱</mi><mo id="S4.E5.m1.1.1.1.3.3" xref="S4.E5.m1.1.1.1.3.3.cmml">′</mo></msup><mo id="S4.E5.m1.1.1.1.2" xref="S4.E5.m1.1.1.1.2.cmml">∈</mo><mrow id="S4.E5.m1.1.1.1.4" xref="S4.E5.m1.1.1.1.4.cmml"><msup id="S4.E5.m1.1.1.1.4.2" xref="S4.E5.m1.1.1.1.4.2.cmml"><mi id="S4.E5.m1.1.1.1.4.2.2" xref="S4.E5.m1.1.1.1.4.2.2.cmml">𝐈</mi><mi id="S4.E5.m1.1.1.1.4.2.3" xref="S4.E5.m1.1.1.1.4.2.3.cmml">u</mi></msup><mo lspace="0em" rspace="0em" id="S4.E5.m1.1.1.1.4.1" xref="S4.E5.m1.1.1.1.4.1.cmml">​</mo><mrow id="S4.E5.m1.1.1.1.4.3.2" xref="S4.E5.m1.1.1.1.4.cmml"><mo stretchy="false" id="S4.E5.m1.1.1.1.4.3.2.1" xref="S4.E5.m1.1.1.1.4.cmml">(</mo><mi id="S4.E5.m1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S4.E5.m1.1.1.1.4.3.2.2" xref="S4.E5.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mo lspace="0.167em" id="S4.E5.m1.4.4.1.1.1.1.1.4a" xref="S4.E5.m1.4.4.1.1.1.1.1.4.cmml">⁡</mo><msup id="S4.E5.m1.4.4.1.1.1.1.1.4.2" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2.cmml"><mi id="S4.E5.m1.4.4.1.1.1.1.1.4.2.2" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2.2.cmml">𝐇</mi><mi id="S4.E5.m1.4.4.1.1.1.1.1.4.2.3" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2.3.cmml">u</mi></msup></mrow><mo lspace="0em" rspace="0em" id="S4.E5.m1.4.4.1.1.1.1.1.2a" xref="S4.E5.m1.4.4.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.E5.m1.4.4.1.1.1.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mo id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo stretchy="false" id="S4.E5.m1.4.4.1.1.1.1.1.1.1.3" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S4.E5.m1.4.4.1.2" xref="S4.E5.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.4b"><apply id="S4.E5.m1.4.4.1.1.cmml" xref="S4.E5.m1.4.4.1"><eq id="S4.E5.m1.4.4.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.2"></eq><apply id="S4.E5.m1.4.4.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.3"><times id="S4.E5.m1.4.4.1.1.3.1.cmml" xref="S4.E5.m1.4.4.1.1.3.1"></times><apply id="S4.E5.m1.4.4.1.1.3.2.cmml" xref="S4.E5.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.3.2.1.cmml" xref="S4.E5.m1.4.4.1.1.3.2">superscript</csymbol><apply id="S4.E5.m1.4.4.1.1.3.2.2.cmml" xref="S4.E5.m1.4.4.1.1.3.2.2"><ci id="S4.E5.m1.4.4.1.1.3.2.2.1.cmml" xref="S4.E5.m1.4.4.1.1.3.2.2.1">^</ci><ci id="S4.E5.m1.4.4.1.1.3.2.2.2.cmml" xref="S4.E5.m1.4.4.1.1.3.2.2.2">𝐇</ci></apply><ci id="S4.E5.m1.4.4.1.1.3.2.3.cmml" xref="S4.E5.m1.4.4.1.1.3.2.3">𝑣</ci></apply><ci id="S4.E5.m1.2.2.cmml" xref="S4.E5.m1.2.2">𝐱</ci></apply><apply id="S4.E5.m1.4.4.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1"><plus id="S4.E5.m1.4.4.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.2"></plus><apply id="S4.E5.m1.4.4.1.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.1.3"><times id="S4.E5.m1.4.4.1.1.1.3.1.cmml" xref="S4.E5.m1.4.4.1.1.1.3.1"></times><apply id="S4.E5.m1.4.4.1.1.1.3.2.cmml" xref="S4.E5.m1.4.4.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.3.2.1.cmml" xref="S4.E5.m1.4.4.1.1.1.3.2">superscript</csymbol><ci id="S4.E5.m1.4.4.1.1.1.3.2.2.cmml" xref="S4.E5.m1.4.4.1.1.1.3.2.2">𝜔</ci><ci id="S4.E5.m1.4.4.1.1.1.3.2.3.cmml" xref="S4.E5.m1.4.4.1.1.1.3.2.3">𝑣</ci></apply><apply id="S4.E5.m1.4.4.1.1.1.3.3.cmml" xref="S4.E5.m1.4.4.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.3.3.1.cmml" xref="S4.E5.m1.4.4.1.1.1.3.3">superscript</csymbol><ci id="S4.E5.m1.4.4.1.1.1.3.3.2.cmml" xref="S4.E5.m1.4.4.1.1.1.3.3.2">𝐇</ci><ci id="S4.E5.m1.4.4.1.1.1.3.3.3.cmml" xref="S4.E5.m1.4.4.1.1.1.3.3.3">𝑣</ci></apply><ci id="S4.E5.m1.3.3.cmml" xref="S4.E5.m1.3.3">𝐱</ci></apply><apply id="S4.E5.m1.4.4.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1"><apply id="S4.E5.m1.4.4.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.2.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2">superscript</csymbol><apply id="S4.E5.m1.4.4.1.1.1.1.2.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.2.2.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2">subscript</csymbol><sum id="S4.E5.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2.2.2"></sum><apply id="S4.E5.m1.4.4.1.1.1.1.2.2.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3"><eq id="S4.E5.m1.4.4.1.1.1.1.2.2.3.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.1"></eq><ci id="S4.E5.m1.4.4.1.1.1.1.2.2.3.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.2">𝑢</ci><cn type="integer" id="S4.E5.m1.4.4.1.1.1.1.2.2.3.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E5.m1.4.4.1.1.1.1.2.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.2.3">𝑁</ci></apply><apply id="S4.E5.m1.4.4.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1"><times id="S4.E5.m1.4.4.1.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.2"></times><apply id="S4.E5.m1.4.4.1.1.1.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.3">superscript</csymbol><ci id="S4.E5.m1.4.4.1.1.1.1.1.3.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.3.2">𝜔</ci><ci id="S4.E5.m1.4.4.1.1.1.1.1.3.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.3.3">𝑢</ci></apply><apply id="S4.E5.m1.4.4.1.1.1.1.1.4.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4"><apply id="S4.E5.m1.4.4.1.1.1.1.1.4.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.1.4.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.1">subscript</csymbol><max id="S4.E5.m1.4.4.1.1.1.1.1.4.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.1.2"></max><apply id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1"><in id="S4.E5.m1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.2"></in><apply id="S4.E5.m1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.1.3">superscript</csymbol><ci id="S4.E5.m1.1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.1.3.2">𝐱</ci><ci id="S4.E5.m1.1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.1.3.3">′</ci></apply><apply id="S4.E5.m1.1.1.1.4.cmml" xref="S4.E5.m1.1.1.1.4"><times id="S4.E5.m1.1.1.1.4.1.cmml" xref="S4.E5.m1.1.1.1.4.1"></times><apply id="S4.E5.m1.1.1.1.4.2.cmml" xref="S4.E5.m1.1.1.1.4.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.4.2.1.cmml" xref="S4.E5.m1.1.1.1.4.2">superscript</csymbol><ci id="S4.E5.m1.1.1.1.4.2.2.cmml" xref="S4.E5.m1.1.1.1.4.2.2">𝐈</ci><ci id="S4.E5.m1.1.1.1.4.2.3.cmml" xref="S4.E5.m1.1.1.1.4.2.3">𝑢</ci></apply><ci id="S4.E5.m1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1">𝐱</ci></apply></apply></apply><apply id="S4.E5.m1.4.4.1.1.1.1.1.4.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.1.4.2.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2">superscript</csymbol><ci id="S4.E5.m1.4.4.1.1.1.1.1.4.2.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2.2">𝐇</ci><ci id="S4.E5.m1.4.4.1.1.1.1.1.4.2.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.4.2.3">𝑢</ci></apply></apply><apply id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.4.4.1.1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.4c">\mathbf{\hat{H}}^{v}(\mathbf{x})=\omega^{v}\mathbf{H}^{v}(\mathbf{x})+\sum_{u=1}^{N}\omega^{u}\max_{\mathbf{x^{\prime}}\in\mathbf{I}^{u}(\mathbf{x})}{\mathbf{H}^{u}(\mathbf{x}^{\prime})},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.2" class="ltx_p">The prediction of the adaptive fusion weight <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">\omega</annotation></semantics></math> is implemented by a lightweight neural network as shown in Figure <a href="#S3.F6" title="Figure 6 ‣ 3.3 Side Effect and Solution ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. On top of the heatmaps <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="\mathbf{H}" display="inline"><semantics id="S4.p4.2.m2.1a"><mi id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><ci id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">\mathbf{H}</annotation></semantics></math> provided by the pose estimation network, we extract two types of information for making the prediction. The first is the appearance embedding which extracts information such as the distribution characteristics of the heatmaps. The second is the geometry embedding which considers the cross-view location consistency. The two terms are complementary to each other. The proposed weight learning network can be joined with the pose estimation network for end-to-end training without enforcing supervision on the weights.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>The Appearance Embedding</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The heatmap of each joint actually contains rich information to infer its heatmap quality. For example, if the predicted heatmap has a desired shape of Gaussian kernel, then in many cases, the heatmap quality is good. In contrast, if the predicted heatmap has random and small responses all over the space (for example, when the joint is occluded), then the quality is likely to be bad.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">We propose a simple network to extract appearance embeddings for each joint in each camera view. Figure <a href="#S4.F7" title="Figure 7 ‣ 4.1 The Appearance Embedding ‣ 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the network structure. Starting from the heatmaps <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{H}_{i}" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><msub id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">𝐇</mi><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝐇</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\mathbf{H}_{i}</annotation></semantics></math>, we apply a convolutional layer to extract features. Then the features are down-sampled by average pooling and fed to a Fully Connected (FC) layer for extracting the appearance embeddings. Different joint types and camera views share the same weights. We only show the network for a single view and a single joint for simplicity. The appearance embedding network is jointly learned end-to-end with the pose estimation network.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2010.13302/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="50" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The appearance embedding network for predicting the fusion weight.
<math id="S4.F7.3.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.F7.3.m1.1b"><mi id="S4.F7.3.m1.1.1" xref="S4.F7.3.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.F7.3.m1.1c"><ci id="S4.F7.3.m1.1.1.cmml" xref="S4.F7.3.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.3.m1.1d">i</annotation></semantics></math> is the index of camera views. The parameters in the network are shared for all views and joints. See also Figure <a href="#S3.F6" title="Figure 6 ‣ 3.3 Side Effect and Solution ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> for how the appearance embedding <math id="S4.F7.4.m2.1" class="ltx_Math" alttext="A_{i}" display="inline"><semantics id="S4.F7.4.m2.1b"><msub id="S4.F7.4.m2.1.1" xref="S4.F7.4.m2.1.1.cmml"><mi id="S4.F7.4.m2.1.1.2" xref="S4.F7.4.m2.1.1.2.cmml">A</mi><mi id="S4.F7.4.m2.1.1.3" xref="S4.F7.4.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F7.4.m2.1c"><apply id="S4.F7.4.m2.1.1.cmml" xref="S4.F7.4.m2.1.1"><csymbol cd="ambiguous" id="S4.F7.4.m2.1.1.1.cmml" xref="S4.F7.4.m2.1.1">subscript</csymbol><ci id="S4.F7.4.m2.1.1.2.cmml" xref="S4.F7.4.m2.1.1.2">𝐴</ci><ci id="S4.F7.4.m2.1.1.3.cmml" xref="S4.F7.4.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.m2.1d">A_{i}</annotation></semantics></math> is used for determining the fusion weight. </figcaption>
</figure>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2010.13302/assets/x8.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="155" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>The geometry embedding network for predicting the fusion weight. For each joint in each camera view (three views are shown in this example), it generates a <math id="S4.F8.2.m1.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S4.F8.2.m1.1b"><mn id="S4.F8.2.m1.1.1" xref="S4.F8.2.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S4.F8.2.m1.1c"><cn type="integer" id="S4.F8.2.m1.1.1.cmml" xref="S4.F8.2.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F8.2.m1.1d">256</annotation></semantics></math>-dimensional embedding to reflect the heatmap (pose) quality. Note that the FC is shared for all branches.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>The Geometry Embedding</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The appearance embedding alone is not sufficient for some challenging cases where the heatmaps have the desired shape of Gaussian kernel but at the wrong locations. One such example is when the left knee is detected at the location of right knee which is usually known as the “double counting” problem to the community. To solve this problem, we propose to leverage the location consistency information among all camera views. Our core motivation is that the predicted joint location in one camera view is more reliable if it agrees with the locations in other views.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2010.13302/assets/x9.png" id="S4.F9.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="322" height="432" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>We visualize the predicted fusion weights by the size of the markers in the first column. A large marker denotes a larger weight. The rest two columns show the poses estimated by <em id="S4.F9.4.1" class="ltx_emph ltx_font_italic">HeuristicFuse</em> and <em id="S4.F9.5.2" class="ltx_emph ltx_font_italic">AdaFuse</em>, respectively. Our <em id="S4.F9.6.3" class="ltx_emph ltx_font_italic">AdaFuse</em> has clearly better estimations due to the consideration of the feature quality in every view.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.5" class="ltx_p">We implement this idea by a geometry embedding network as shown in Figure <a href="#S4.F8" title="Figure 8 ‣ 4.1 The Appearance Embedding ‣ 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Starting from the heatmaps <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{H}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\mathbf{H}</annotation></semantics></math>, we first apply the “soft-argmax” operator <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a href="#bib.bib53" title="" class="ltx_ref">2018</a>)</cite> to obtain the location <math id="S4.SS2.p2.2.m2.2" class="ltx_Math" alttext="(x,y)" display="inline"><semantics id="S4.SS2.p2.2.m2.2a"><mrow id="S4.SS2.p2.2.m2.2.3.2" xref="S4.SS2.p2.2.m2.2.3.1.cmml"><mo stretchy="false" id="S4.SS2.p2.2.m2.2.3.2.1" xref="S4.SS2.p2.2.m2.2.3.1.cmml">(</mo><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">x</mi><mo id="S4.SS2.p2.2.m2.2.3.2.2" xref="S4.SS2.p2.2.m2.2.3.1.cmml">,</mo><mi id="S4.SS2.p2.2.m2.2.2" xref="S4.SS2.p2.2.m2.2.2.cmml">y</mi><mo stretchy="false" id="S4.SS2.p2.2.m2.2.3.2.3" xref="S4.SS2.p2.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.2b"><interval closure="open" id="S4.SS2.p2.2.m2.2.3.1.cmml" xref="S4.SS2.p2.2.m2.2.3.2"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">𝑥</ci><ci id="S4.SS2.p2.2.m2.2.2.cmml" xref="S4.SS2.p2.2.m2.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.2c">(x,y)</annotation></semantics></math> of the joint in each view. We also get the heatmap response value <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mi id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><ci id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">s</annotation></semantics></math> in that location to reflect its confidence. Then we compute the Sampson distance <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a href="#bib.bib20" title="" class="ltx_ref">2003</a>)</cite> <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="dist_{i\leftrightarrow j}" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><mrow id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mi id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.4.m4.1.1.1" xref="S4.SS2.p2.4.m4.1.1.1.cmml">​</mo><mi id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.4.m4.1.1.1a" xref="S4.SS2.p2.4.m4.1.1.1.cmml">​</mo><mi id="S4.SS2.p2.4.m4.1.1.4" xref="S4.SS2.p2.4.m4.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.4.m4.1.1.1b" xref="S4.SS2.p2.4.m4.1.1.1.cmml">​</mo><msub id="S4.SS2.p2.4.m4.1.1.5" xref="S4.SS2.p2.4.m4.1.1.5.cmml"><mi id="S4.SS2.p2.4.m4.1.1.5.2" xref="S4.SS2.p2.4.m4.1.1.5.2.cmml">t</mi><mrow id="S4.SS2.p2.4.m4.1.1.5.3" xref="S4.SS2.p2.4.m4.1.1.5.3.cmml"><mi id="S4.SS2.p2.4.m4.1.1.5.3.2" xref="S4.SS2.p2.4.m4.1.1.5.3.2.cmml">i</mi><mo stretchy="false" id="S4.SS2.p2.4.m4.1.1.5.3.1" xref="S4.SS2.p2.4.m4.1.1.5.3.1.cmml">↔</mo><mi id="S4.SS2.p2.4.m4.1.1.5.3.3" xref="S4.SS2.p2.4.m4.1.1.5.3.3.cmml">j</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><times id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1.1"></times><ci id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">𝑑</ci><ci id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3">𝑖</ci><ci id="S4.SS2.p2.4.m4.1.1.4.cmml" xref="S4.SS2.p2.4.m4.1.1.4">𝑠</ci><apply id="S4.SS2.p2.4.m4.1.1.5.cmml" xref="S4.SS2.p2.4.m4.1.1.5"><csymbol cd="ambiguous" id="S4.SS2.p2.4.m4.1.1.5.1.cmml" xref="S4.SS2.p2.4.m4.1.1.5">subscript</csymbol><ci id="S4.SS2.p2.4.m4.1.1.5.2.cmml" xref="S4.SS2.p2.4.m4.1.1.5.2">𝑡</ci><apply id="S4.SS2.p2.4.m4.1.1.5.3.cmml" xref="S4.SS2.p2.4.m4.1.1.5.3"><ci id="S4.SS2.p2.4.m4.1.1.5.3.1.cmml" xref="S4.SS2.p2.4.m4.1.1.5.3.1">↔</ci><ci id="S4.SS2.p2.4.m4.1.1.5.3.2.cmml" xref="S4.SS2.p2.4.m4.1.1.5.3.2">𝑖</ci><ci id="S4.SS2.p2.4.m4.1.1.5.3.3.cmml" xref="S4.SS2.p2.4.m4.1.1.5.3.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">dist_{i\leftrightarrow j}</annotation></semantics></math> between the current view and other views to measure the correspondence or consistency error. A small <math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="dist_{i\leftrightarrow j}" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><mrow id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mi id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.5.m5.1.1.1" xref="S4.SS2.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS2.p2.5.m5.1.1.3" xref="S4.SS2.p2.5.m5.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.5.m5.1.1.1a" xref="S4.SS2.p2.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS2.p2.5.m5.1.1.4" xref="S4.SS2.p2.5.m5.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.5.m5.1.1.1b" xref="S4.SS2.p2.5.m5.1.1.1.cmml">​</mo><msub id="S4.SS2.p2.5.m5.1.1.5" xref="S4.SS2.p2.5.m5.1.1.5.cmml"><mi id="S4.SS2.p2.5.m5.1.1.5.2" xref="S4.SS2.p2.5.m5.1.1.5.2.cmml">t</mi><mrow id="S4.SS2.p2.5.m5.1.1.5.3" xref="S4.SS2.p2.5.m5.1.1.5.3.cmml"><mi id="S4.SS2.p2.5.m5.1.1.5.3.2" xref="S4.SS2.p2.5.m5.1.1.5.3.2.cmml">i</mi><mo stretchy="false" id="S4.SS2.p2.5.m5.1.1.5.3.1" xref="S4.SS2.p2.5.m5.1.1.5.3.1.cmml">↔</mo><mi id="S4.SS2.p2.5.m5.1.1.5.3.3" xref="S4.SS2.p2.5.m5.1.1.5.3.3.cmml">j</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><times id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1.1"></times><ci id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2">𝑑</ci><ci id="S4.SS2.p2.5.m5.1.1.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3">𝑖</ci><ci id="S4.SS2.p2.5.m5.1.1.4.cmml" xref="S4.SS2.p2.5.m5.1.1.4">𝑠</ci><apply id="S4.SS2.p2.5.m5.1.1.5.cmml" xref="S4.SS2.p2.5.m5.1.1.5"><csymbol cd="ambiguous" id="S4.SS2.p2.5.m5.1.1.5.1.cmml" xref="S4.SS2.p2.5.m5.1.1.5">subscript</csymbol><ci id="S4.SS2.p2.5.m5.1.1.5.2.cmml" xref="S4.SS2.p2.5.m5.1.1.5.2">𝑡</ci><apply id="S4.SS2.p2.5.m5.1.1.5.3.cmml" xref="S4.SS2.p2.5.m5.1.1.5.3"><ci id="S4.SS2.p2.5.m5.1.1.5.3.1.cmml" xref="S4.SS2.p2.5.m5.1.1.5.3.1">↔</ci><ci id="S4.SS2.p2.5.m5.1.1.5.3.2.cmml" xref="S4.SS2.p2.5.m5.1.1.5.3.2">𝑖</ci><ci id="S4.SS2.p2.5.m5.1.1.5.3.3.cmml" xref="S4.SS2.p2.5.m5.1.1.5.3.3">𝑗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">dist_{i\leftrightarrow j}</annotation></semantics></math> means the joint locations in the two views are consistent. Intuitively, the location that is consistent with most views is more reliable. Finally, we propose to use a FC layer to embed the Sampson distance into a feature vector. The feature vectors of all camera pairs are then averaged to obtain the final geometry embedding.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Weight Learning Network</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We propose a simple network consisting of three FC layers to transform the concatenated appearance and geometric embeddings to regress the final weight. It is worth noting that we do not train the weight learning network independently. Instead, we join it with the pose estimation network to minimize the fused <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mn id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><cn type="integer" id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">2</annotation></semantics></math>D heatmap loss without enforcing intermediate supervision on the fusion weights. The first column in Figure <a href="#S4.F9" title="Figure 9 ‣ 4.2 The Geometry Embedding ‣ 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows some example weights predicted by our approach. We can see that when the joints are occluded, and are localized at incorrect locations, the corresponding fusion weights are indeed smaller than other joints.</p>
</div>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2010.13302/assets/x10.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="382" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>We show some typical images, ground-truth <math id="S4.F10.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.F10.2.m1.1b"><mn id="S4.F10.2.m1.1.1" xref="S4.F10.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.F10.2.m1.1c"><cn type="integer" id="S4.F10.2.m1.1.1.cmml" xref="S4.F10.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F10.2.m1.1d">2</annotation></semantics></math>D joint locations and the depth maps from the <em id="S4.F10.5.1" class="ltx_emph ltx_font_italic">Occlusion-Person</em> dataset. The joint represented by red “x” means it is occluded. The <span id="S4.F10.6.2" class="ltx_text ltx_font_bold">bottom</span> row shows spacial configuration of the eight cameras used in the dataset from different view angles.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Datasets and Metrics</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We introduce the three datasets used for evaluation and the corresponding metrics. We also describe how we construct the synthetic person dataset <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">Occlusion-Person</em> which has a large amount of human-object occlusion.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The statistics of the public multiview pose estimation datasets. Only the <em id="S5.T1.6.1" class="ltx_emph ltx_font_italic">Occlusion-Person</em> dataset provides occlusion labels.</figcaption>
<table id="S5.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T1.4.5.1" class="ltx_tr">
<th id="S5.T1.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Dataset</th>
<th id="S5.T1.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Frames</th>
<th id="S5.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Cameras</th>
<th id="S5.T1.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Occluded Joints</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T1.1.1" class="ltx_tr">
<td id="S5.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">Human3.6M</td>
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="784" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mn id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml">784</mn><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><cn type="integer" id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1">784</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">784</annotation></semantics></math>k</td>
<td id="S5.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="S5.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S5.T1.2.2" class="ltx_tr">
<td id="S5.T1.2.2.2" class="ltx_td ltx_align_left">Total Capture</td>
<td id="S5.T1.2.2.1" class="ltx_td ltx_align_center">
<math id="S5.T1.2.2.1.m1.1" class="ltx_Math" alttext="236" display="inline"><semantics id="S5.T1.2.2.1.m1.1a"><mn id="S5.T1.2.2.1.m1.1.1" xref="S5.T1.2.2.1.m1.1.1.cmml">236</mn><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.1.m1.1b"><cn type="integer" id="S5.T1.2.2.1.m1.1.1.cmml" xref="S5.T1.2.2.1.m1.1.1">236</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.1.m1.1c">236</annotation></semantics></math>k</td>
<td id="S5.T1.2.2.3" class="ltx_td ltx_align_center">8</td>
<td id="S5.T1.2.2.4" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T1.3.3" class="ltx_tr">
<td id="S5.T1.3.3.2" class="ltx_td ltx_align_left">Panoptic</td>
<td id="S5.T1.3.3.1" class="ltx_td ltx_align_center">
<math id="S5.T1.3.3.1.m1.1" class="ltx_Math" alttext="36" display="inline"><semantics id="S5.T1.3.3.1.m1.1a"><mn id="S5.T1.3.3.1.m1.1.1" xref="S5.T1.3.3.1.m1.1.1.cmml">36</mn><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.1.m1.1b"><cn type="integer" id="S5.T1.3.3.1.m1.1.1.cmml" xref="S5.T1.3.3.1.m1.1.1">36</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.1.m1.1c">36</annotation></semantics></math>k</td>
<td id="S5.T1.3.3.3" class="ltx_td ltx_align_center">31</td>
<td id="S5.T1.3.3.4" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S5.T1.4.4" class="ltx_tr">
<td id="S5.T1.4.4.2" class="ltx_td ltx_align_left ltx_border_bb">Occlusion-Person</td>
<td id="S5.T1.4.4.1" class="ltx_td ltx_align_center ltx_border_bb">
<math id="S5.T1.4.4.1.m1.1" class="ltx_Math" alttext="73" display="inline"><semantics id="S5.T1.4.4.1.m1.1a"><mn id="S5.T1.4.4.1.m1.1.1" xref="S5.T1.4.4.1.m1.1.1.cmml">73</mn><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.1.m1.1b"><cn type="integer" id="S5.T1.4.4.1.m1.1.1.cmml" xref="S5.T1.4.4.1.m1.1.1">73</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.1.m1.1c">73</annotation></semantics></math>k</td>
<td id="S5.T1.4.4.3" class="ltx_td ltx_align_center ltx_border_bb">8</td>
<td id="S5.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_bb">20.3%</td>
</tr>
</tbody>
</table>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3>

<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The Human3.6M Dataset <cite class="ltx_cite ltx_citemacro_citep">(Ionescu et al., <a href="#bib.bib24" title="" class="ltx_ref">2014</a>)</cite>
</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.2" class="ltx_p">It provides synchronized images captured by four cameras. There are seven subjects performing daily actions. We use a cross-subject evaluation scheme where subjects <math id="S5.SS1.SSS0.Px1.p1.1.m1.5" class="ltx_Math" alttext="1,5,6,7,8" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.1.m1.5a"><mrow id="S5.SS1.SSS0.Px1.p1.1.m1.5.6.2" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.6.1.cmml"><mn id="S5.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">1</mn><mo id="S5.SS1.SSS0.Px1.p1.1.m1.5.6.2.1" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p1.1.m1.2.2" xref="S5.SS1.SSS0.Px1.p1.1.m1.2.2.cmml">5</mn><mo id="S5.SS1.SSS0.Px1.p1.1.m1.5.6.2.2" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p1.1.m1.3.3" xref="S5.SS1.SSS0.Px1.p1.1.m1.3.3.cmml">6</mn><mo id="S5.SS1.SSS0.Px1.p1.1.m1.5.6.2.3" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p1.1.m1.4.4" xref="S5.SS1.SSS0.Px1.p1.1.m1.4.4.cmml">7</mn><mo id="S5.SS1.SSS0.Px1.p1.1.m1.5.6.2.4" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.6.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p1.1.m1.5.5" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.5.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.m1.5b"><list id="S5.SS1.SSS0.Px1.p1.1.m1.5.6.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.6.2"><cn type="integer" id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1">1</cn><cn type="integer" id="S5.SS1.SSS0.Px1.p1.1.m1.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.2.2">5</cn><cn type="integer" id="S5.SS1.SSS0.Px1.p1.1.m1.3.3.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.3.3">6</cn><cn type="integer" id="S5.SS1.SSS0.Px1.p1.1.m1.4.4.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.4.4">7</cn><cn type="integer" id="S5.SS1.SSS0.Px1.p1.1.m1.5.5.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.5.5">8</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.m1.5c">1,5,6,7,8</annotation></semantics></math> are used for training and <math id="S5.SS1.SSS0.Px1.p1.2.m2.2" class="ltx_Math" alttext="9,11" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.2.m2.2a"><mrow id="S5.SS1.SSS0.Px1.p1.2.m2.2.3.2" xref="S5.SS1.SSS0.Px1.p1.2.m2.2.3.1.cmml"><mn id="S5.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">9</mn><mo id="S5.SS1.SSS0.Px1.p1.2.m2.2.3.2.1" xref="S5.SS1.SSS0.Px1.p1.2.m2.2.3.1.cmml">,</mo><mn id="S5.SS1.SSS0.Px1.p1.2.m2.2.2" xref="S5.SS1.SSS0.Px1.p1.2.m2.2.2.cmml">11</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.2.m2.2b"><list id="S5.SS1.SSS0.Px1.p1.2.m2.2.3.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.m2.2.3.2"><cn type="integer" id="S5.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.m2.1.1">9</cn><cn type="integer" id="S5.SS1.SSS0.Px1.p1.2.m2.2.2.cmml" xref="S5.SS1.SSS0.Px1.p1.2.m2.2.2">11</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.2.m2.2c">9,11</annotation></semantics></math> for testing. We also use the MPII dataset <cite class="ltx_cite ltx_citemacro_citep">(Andriluka et al., <a href="#bib.bib2" title="" class="ltx_ref">2014</a>)</cite> to augment the training data to avoid over-fitting to the simple background. Since the MPII dataset provides only monocular images, we only train the backbone network before multiview fusion.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The Total Capture Dataset <cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite>
</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">It provides synchronized person images captured by eight cameras. Following the dataset convention, the training set consists of “ROM1,2,3”, “Freestyle1,2”, “Walking1,3”, “Acting1,2” and “Running1” on subjects 1, 2 and 3. The testing set consists of “Freestyle3 (<span id="S5.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_bold">FS3</span>)”, “Acting3 (<span id="S5.SS1.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_bold">A3</span>)” and “Walking2 (<span id="S5.SS1.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_bold">W2</span>)” on subjects 1,2,3,4 and 5.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The CMU Panoptic Dataset <cite class="ltx_cite ltx_citemacro_citep">(Joo et al., <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>
</h4>

<div id="S5.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px3.p1.1" class="ltx_p">This recently introduced dataset provides images captured by dozens of cameras. We uniformly select six cameras to evaluate the impact of the number of cameras on <math id="S5.SS1.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS1.SSS0.Px3.p1.1.m1.1a"><mn id="S5.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px3.p1.1.m1.1b"><cn type="integer" id="S5.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px3.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px3.p1.1.m1.1c">3</annotation></semantics></math>D pose estimation. In particular, the cameras 1, 2, and 10 are firstly selected to construct a 3-view experiment setting. Then the cameras 13, 3 and 23 are sequentially added to the previous three cameras to construct a four, five and six view experiment setting, respectively. We follow the practice of the previous work <cite class="ltx_cite ltx_citemacro_citep">(Xiang et al., <a href="#bib.bib60" title="" class="ltx_ref">2019</a>)</cite> to select the training and testing sequences which consist of only one person. Since few works have reported numerical results on this dataset, we only compare our approach to the baselines.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The Occlusion-Person Dataset</h4>

<div id="S5.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px4.p1.4" class="ltx_p">The previous benchmarks do not provide occlusion labels for the joints in images which prevents us from performing numerical evaluation on the occluded joints. In addition, the amount of occlusion in the benchmarks is limited. To address the limitations, we propose to construct this synthetic dataset <em id="S5.SS1.SSS0.Px4.p1.4.1" class="ltx_emph ltx_font_italic">Occlusion-Person</em>. We adopt UnrealCV <cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib46" title="" class="ltx_ref">2017</a>)</cite> to render multiview images and depth maps from <math id="S5.SS1.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS1.SSS0.Px4.p1.1.m1.1a"><mn id="S5.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.1.m1.1b"><cn type="integer" id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.1.m1.1c">3</annotation></semantics></math>D models. In particular, thirteen human models of different clothes are put into nine different scenes such as living rooms, bedrooms and offices. The human models are driven by the poses selected from the CMU Motion Capture database. We purposely use objects such as sofas and desks to occlude some body joints. Eight cameras are placed in each scene to render the multiview images and the depth maps. The eight cameras are placed evenly
every 45 degree on a circle of two meters radius at about <math id="S5.SS1.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="S5.SS1.SSS0.Px4.p1.2.m2.1a"><mn id="S5.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.2.m2.1b"><cn type="float" id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.2.m2.1c">0.9</annotation></semantics></math> and <math id="S5.SS1.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="2.3" display="inline"><semantics id="S5.SS1.SSS0.Px4.p1.3.m3.1a"><mn id="S5.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">2.3</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.3.m3.1b"><cn type="float" id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1">2.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.3.m3.1c">2.3</annotation></semantics></math> meters high, respectively. We provide the <math id="S5.SS1.SSS0.Px4.p1.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS1.SSS0.Px4.p1.4.m4.1a"><mn id="S5.SS1.SSS0.Px4.p1.4.m4.1.1" xref="S5.SS1.SSS0.Px4.p1.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.4.m4.1b"><cn type="integer" id="S5.SS1.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.4.m4.1c">3</annotation></semantics></math>D locations of 15 joints as ground truth. Figure <a href="#S4.F10" title="Figure 10 ‣ 4.3 Weight Learning Network ‣ 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows some sample images from the dataset and spacial configuration of the cameras.</p>
</div>
<div id="S5.SS1.SSS0.Px4.p2" class="ltx_para">
<p id="S5.SS1.SSS0.Px4.p2.5" class="ltx_p">The occlusion label for each joint in an image is obtained by comparing its depth value (available in the depth map), to the depth of the <math id="S5.SS1.SSS0.Px4.p2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS1.SSS0.Px4.p2.1.m1.1a"><mn id="S5.SS1.SSS0.Px4.p2.1.m1.1.1" xref="S5.SS1.SSS0.Px4.p2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p2.1.m1.1b"><cn type="integer" id="S5.SS1.SSS0.Px4.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p2.1.m1.1c">3</annotation></semantics></math>D joint in the camera coordinate system. If the difference between the two depth values is smaller than <math id="S5.SS1.SSS0.Px4.p2.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S5.SS1.SSS0.Px4.p2.2.m2.1a"><mn id="S5.SS1.SSS0.Px4.p2.2.m2.1.1" xref="S5.SS1.SSS0.Px4.p2.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p2.2.m2.1b"><cn type="integer" id="S5.SS1.SSS0.Px4.p2.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p2.2.m2.1c">30</annotation></semantics></math>cm, then the joint is not occluded. Otherwise, it is occluded. Table <a href="#S5.T1" title="Table 1 ‣ 5 Datasets and Metrics ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> compares this dataset to the existing benchmarks. In particular, about <math id="S5.SS1.SSS0.Px4.p2.3.m3.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S5.SS1.SSS0.Px4.p2.3.m3.1a"><mrow id="S5.SS1.SSS0.Px4.p2.3.m3.1.1" xref="S5.SS1.SSS0.Px4.p2.3.m3.1.1.cmml"><mn id="S5.SS1.SSS0.Px4.p2.3.m3.1.1.2" xref="S5.SS1.SSS0.Px4.p2.3.m3.1.1.2.cmml">20</mn><mo id="S5.SS1.SSS0.Px4.p2.3.m3.1.1.1" xref="S5.SS1.SSS0.Px4.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p2.3.m3.1b"><apply id="S5.SS1.SSS0.Px4.p2.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.3.m3.1.1"><csymbol cd="latexml" id="S5.SS1.SSS0.Px4.p2.3.m3.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.SSS0.Px4.p2.3.m3.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p2.3.m3.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p2.3.m3.1c">20\%</annotation></semantics></math> of the body joints are occluded in our dataset. We use <math id="S5.SS1.SSS0.Px4.p2.4.m4.1" class="ltx_Math" alttext="75\%" display="inline"><semantics id="S5.SS1.SSS0.Px4.p2.4.m4.1a"><mrow id="S5.SS1.SSS0.Px4.p2.4.m4.1.1" xref="S5.SS1.SSS0.Px4.p2.4.m4.1.1.cmml"><mn id="S5.SS1.SSS0.Px4.p2.4.m4.1.1.2" xref="S5.SS1.SSS0.Px4.p2.4.m4.1.1.2.cmml">75</mn><mo id="S5.SS1.SSS0.Px4.p2.4.m4.1.1.1" xref="S5.SS1.SSS0.Px4.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p2.4.m4.1b"><apply id="S5.SS1.SSS0.Px4.p2.4.m4.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.4.m4.1.1"><csymbol cd="latexml" id="S5.SS1.SSS0.Px4.p2.4.m4.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.SSS0.Px4.p2.4.m4.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p2.4.m4.1.1.2">75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p2.4.m4.1c">75\%</annotation></semantics></math> of the dataset for training and <math id="S5.SS1.SSS0.Px4.p2.5.m5.1" class="ltx_Math" alttext="25\%" display="inline"><semantics id="S5.SS1.SSS0.Px4.p2.5.m5.1a"><mrow id="S5.SS1.SSS0.Px4.p2.5.m5.1.1" xref="S5.SS1.SSS0.Px4.p2.5.m5.1.1.cmml"><mn id="S5.SS1.SSS0.Px4.p2.5.m5.1.1.2" xref="S5.SS1.SSS0.Px4.p2.5.m5.1.1.2.cmml">25</mn><mo id="S5.SS1.SSS0.Px4.p2.5.m5.1.1.1" xref="S5.SS1.SSS0.Px4.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p2.5.m5.1b"><apply id="S5.SS1.SSS0.Px4.p2.5.m5.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.5.m5.1.1"><csymbol cd="latexml" id="S5.SS1.SSS0.Px4.p2.5.m5.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p2.5.m5.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.SSS0.Px4.p2.5.m5.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p2.5.m5.1.1.2">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p2.5.m5.1c">25\%</annotation></semantics></math> for validation.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The <math id="S5.T2.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.T2.2.m1.1b"><mn id="S5.T2.2.m1.1.1" xref="S5.T2.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.T2.2.m1.1c"><cn type="integer" id="S5.T2.2.m1.1.1.cmml" xref="S5.T2.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.m1.1d">2</annotation></semantics></math>D pose estimation accuracy (PCKh@t) of the baseline methods and our approach on the Human3.6M dataset. We report results for each individual joint and the average over all joints. </figcaption>
<table id="S5.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.3.1.1" class="ltx_tr">
<th id="S5.T2.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Methods</th>
<th id="S5.T2.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Root</th>
<th id="S5.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Belly</th>
<th id="S5.T2.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Neck</th>
<th id="S5.T2.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Nose</th>
<th id="S5.T2.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Head</th>
<th id="S5.T2.3.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Hip</th>
<th id="S5.T2.3.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Knee</th>
<th id="S5.T2.3.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Ankle</th>
<th id="S5.T2.3.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Shlder</th>
<th id="S5.T2.3.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Elbow</th>
<th id="S5.T2.3.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Wrist</th>
<th id="S5.T2.3.1.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><em id="S5.T2.3.1.1.13.1" class="ltx_emph ltx_font_italic">Mean</em></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.3.2.1" class="ltx_tr">
<th id="S5.T2.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">NoFuse</th>
<td id="S5.T2.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t">95.8</td>
<td id="S5.T2.3.2.1.3" class="ltx_td ltx_align_center ltx_border_t">77.1</td>
<td id="S5.T2.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">60.4</td>
<td id="S5.T2.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t">86.4</td>
<td id="S5.T2.3.2.1.6" class="ltx_td ltx_align_center ltx_border_t">86.2</td>
<td id="S5.T2.3.2.1.7" class="ltx_td ltx_align_center ltx_border_t">79.3</td>
<td id="S5.T2.3.2.1.8" class="ltx_td ltx_align_center ltx_border_t">81.5</td>
<td id="S5.T2.3.2.1.9" class="ltx_td ltx_align_center ltx_border_t">58.6</td>
<td id="S5.T2.3.2.1.10" class="ltx_td ltx_align_center ltx_border_t">65.1</td>
<td id="S5.T2.3.2.1.11" class="ltx_td ltx_align_center ltx_border_t">78.3</td>
<td id="S5.T2.3.2.1.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.1</td>
<td id="S5.T2.3.2.1.13" class="ltx_td ltx_align_center ltx_border_t">74.8</td>
</tr>
<tr id="S5.T2.3.3.2" class="ltx_tr">
<th id="S5.T2.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HeuristicFuse</th>
<td id="S5.T2.3.3.2.2" class="ltx_td ltx_align_center">96.0</td>
<td id="S5.T2.3.3.2.3" class="ltx_td ltx_align_center">79.3</td>
<td id="S5.T2.3.3.2.4" class="ltx_td ltx_align_center">60.7</td>
<td id="S5.T2.3.3.2.5" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.5.1" class="ltx_text ltx_font_bold">88.4</span></td>
<td id="S5.T2.3.3.2.6" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.6.1" class="ltx_text ltx_font_bold">86.8</span></td>
<td id="S5.T2.3.3.2.7" class="ltx_td ltx_align_center">83.1</td>
<td id="S5.T2.3.3.2.8" class="ltx_td ltx_align_center">84.5</td>
<td id="S5.T2.3.3.2.9" class="ltx_td ltx_align_center">60.0</td>
<td id="S5.T2.3.3.2.10" class="ltx_td ltx_align_center"><span id="S5.T2.3.3.2.10.1" class="ltx_text ltx_font_bold">66.9</span></td>
<td id="S5.T2.3.3.2.11" class="ltx_td ltx_align_center">82.1</td>
<td id="S5.T2.3.3.2.12" class="ltx_td ltx_align_center ltx_border_r">75.2</td>
<td id="S5.T2.3.3.2.13" class="ltx_td ltx_align_center">77.3</td>
</tr>
<tr id="S5.T2.3.4.3" class="ltx_tr">
<th id="S5.T2.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ScoreFuse</th>
<td id="S5.T2.3.4.3.2" class="ltx_td ltx_align_center">96.2</td>
<td id="S5.T2.3.4.3.3" class="ltx_td ltx_align_center">79.3</td>
<td id="S5.T2.3.4.3.4" class="ltx_td ltx_align_center">61.6</td>
<td id="S5.T2.3.4.3.5" class="ltx_td ltx_align_center">88.3</td>
<td id="S5.T2.3.4.3.6" class="ltx_td ltx_align_center">86.2</td>
<td id="S5.T2.3.4.3.7" class="ltx_td ltx_align_center">83.3</td>
<td id="S5.T2.3.4.3.8" class="ltx_td ltx_align_center">84.3</td>
<td id="S5.T2.3.4.3.9" class="ltx_td ltx_align_center">60.5</td>
<td id="S5.T2.3.4.3.10" class="ltx_td ltx_align_center">66.6</td>
<td id="S5.T2.3.4.3.11" class="ltx_td ltx_align_center">83.1</td>
<td id="S5.T2.3.4.3.12" class="ltx_td ltx_align_center ltx_border_r">77.4</td>
<td id="S5.T2.3.4.3.13" class="ltx_td ltx_align_center">77.8</td>
</tr>
<tr id="S5.T2.3.5.4" class="ltx_tr">
<th id="S5.T2.3.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">AdaFuse (Ours)</th>
<td id="S5.T2.3.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.2.1" class="ltx_text ltx_font_bold">96.2</span></td>
<td id="S5.T2.3.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.3.1" class="ltx_text ltx_font_bold">79.3</span></td>
<td id="S5.T2.3.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.4.1" class="ltx_text ltx_font_bold">61.6</span></td>
<td id="S5.T2.3.5.4.5" class="ltx_td ltx_align_center ltx_border_bb">88.3</td>
<td id="S5.T2.3.5.4.6" class="ltx_td ltx_align_center ltx_border_bb">86.3</td>
<td id="S5.T2.3.5.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.7.1" class="ltx_text ltx_font_bold">83.5</span></td>
<td id="S5.T2.3.5.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.8.1" class="ltx_text ltx_font_bold">86.4</span></td>
<td id="S5.T2.3.5.4.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.9.1" class="ltx_text ltx_font_bold">61.1</span></td>
<td id="S5.T2.3.5.4.10" class="ltx_td ltx_align_center ltx_border_bb">66.7</td>
<td id="S5.T2.3.5.4.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.11.1" class="ltx_text ltx_font_bold">86.0</span></td>
<td id="S5.T2.3.5.4.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T2.3.5.4.12.1" class="ltx_text ltx_font_bold">80.1</span></td>
<td id="S5.T2.3.5.4.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.3.5.4.13.1" class="ltx_text ltx_font_bold">78.8</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The 3D pose estimation error (<math id="S5.T3.2.m1.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S5.T3.2.m1.1b"><mrow id="S5.T3.2.m1.1.1" xref="S5.T3.2.m1.1.1.cmml"><mi id="S5.T3.2.m1.1.1.2" xref="S5.T3.2.m1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.T3.2.m1.1.1.1" xref="S5.T3.2.m1.1.1.1.cmml">​</mo><mi id="S5.T3.2.m1.1.1.3" xref="S5.T3.2.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.2.m1.1c"><apply id="S5.T3.2.m1.1.1.cmml" xref="S5.T3.2.m1.1.1"><times id="S5.T3.2.m1.1.1.1.cmml" xref="S5.T3.2.m1.1.1.1"></times><ci id="S5.T3.2.m1.1.1.2.cmml" xref="S5.T3.2.m1.1.1.2">𝑚</ci><ci id="S5.T3.2.m1.1.1.3.cmml" xref="S5.T3.2.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.m1.1d">mm</annotation></semantics></math>) of the baseline methods and our approach on the Human3.6M dataset. </figcaption>
<table id="S5.T3.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.3.1.1" class="ltx_tr">
<th id="S5.T3.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Methods</th>
<th id="S5.T3.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Belly</th>
<th id="S5.T3.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Neck</th>
<th id="S5.T3.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Nose</th>
<th id="S5.T3.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Head</th>
<th id="S5.T3.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Hip</th>
<th id="S5.T3.3.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Knee</th>
<th id="S5.T3.3.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Ankle</th>
<th id="S5.T3.3.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Shlder</th>
<th id="S5.T3.3.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Elbow</th>
<th id="S5.T3.3.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Wrist</th>
<th id="S5.T3.3.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.3.2.1" class="ltx_tr">
<th id="S5.T3.3.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">NoFuse</th>
<td id="S5.T3.3.2.1.2" class="ltx_td ltx_align_center ltx_border_t">21.6</td>
<td id="S5.T3.3.2.1.3" class="ltx_td ltx_align_center ltx_border_t">16.8</td>
<td id="S5.T3.3.2.1.4" class="ltx_td ltx_align_center ltx_border_t">15.7</td>
<td id="S5.T3.3.2.1.5" class="ltx_td ltx_align_center ltx_border_t">11.3</td>
<td id="S5.T3.3.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.3.2.1.6.1" class="ltx_text ltx_font_bold">17.8</span></td>
<td id="S5.T3.3.2.1.7" class="ltx_td ltx_align_center ltx_border_t">25.8</td>
<td id="S5.T3.3.2.1.8" class="ltx_td ltx_align_center ltx_border_t">35.8</td>
<td id="S5.T3.3.2.1.9" class="ltx_td ltx_align_center ltx_border_t">22.0</td>
<td id="S5.T3.3.2.1.10" class="ltx_td ltx_align_center ltx_border_t">26.8</td>
<td id="S5.T3.3.2.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">34.1</td>
<td id="S5.T3.3.2.1.12" class="ltx_td ltx_align_center ltx_border_t">22.9</td>
</tr>
<tr id="S5.T3.3.3.2" class="ltx_tr">
<th id="S5.T3.3.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HeuristicFuse</th>
<td id="S5.T3.3.3.2.2" class="ltx_td ltx_align_center">21.6</td>
<td id="S5.T3.3.3.2.3" class="ltx_td ltx_align_center">16.8</td>
<td id="S5.T3.3.3.2.4" class="ltx_td ltx_align_center">15.7</td>
<td id="S5.T3.3.3.2.5" class="ltx_td ltx_align_center">11.0</td>
<td id="S5.T3.3.3.2.6" class="ltx_td ltx_align_center">17.9</td>
<td id="S5.T3.3.3.2.7" class="ltx_td ltx_align_center">23.0</td>
<td id="S5.T3.3.3.2.8" class="ltx_td ltx_align_center">32.7</td>
<td id="S5.T3.3.3.2.9" class="ltx_td ltx_align_center">21.9</td>
<td id="S5.T3.3.3.2.10" class="ltx_td ltx_align_center">25.0</td>
<td id="S5.T3.3.3.2.11" class="ltx_td ltx_align_center ltx_border_r">25.7</td>
<td id="S5.T3.3.3.2.12" class="ltx_td ltx_align_center">21.0</td>
</tr>
<tr id="S5.T3.3.4.3" class="ltx_tr">
<th id="S5.T3.3.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ScoreFuse</th>
<td id="S5.T3.3.4.3.2" class="ltx_td ltx_align_center">21.4</td>
<td id="S5.T3.3.4.3.3" class="ltx_td ltx_align_center">16.7</td>
<td id="S5.T3.3.4.3.4" class="ltx_td ltx_align_center">15.8</td>
<td id="S5.T3.3.4.3.5" class="ltx_td ltx_align_center">10.9</td>
<td id="S5.T3.3.4.3.6" class="ltx_td ltx_align_center">18.3</td>
<td id="S5.T3.3.4.3.7" class="ltx_td ltx_align_center">21.3</td>
<td id="S5.T3.3.4.3.8" class="ltx_td ltx_align_center">30.8</td>
<td id="S5.T3.3.4.3.9" class="ltx_td ltx_align_center">21.8</td>
<td id="S5.T3.3.4.3.10" class="ltx_td ltx_align_center">23.3</td>
<td id="S5.T3.3.4.3.11" class="ltx_td ltx_align_center ltx_border_r">23.2</td>
<td id="S5.T3.3.4.3.12" class="ltx_td ltx_align_center">20.1</td>
</tr>
<tr id="S5.T3.3.5.4" class="ltx_tr">
<th id="S5.T3.3.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RANSAC</th>
<td id="S5.T3.3.5.4.2" class="ltx_td ltx_align_center">21.6</td>
<td id="S5.T3.3.5.4.3" class="ltx_td ltx_align_center">16.8</td>
<td id="S5.T3.3.5.4.4" class="ltx_td ltx_align_center"><span id="S5.T3.3.5.4.4.1" class="ltx_text ltx_font_bold">15.7</span></td>
<td id="S5.T3.3.5.4.5" class="ltx_td ltx_align_center">11.2</td>
<td id="S5.T3.3.5.4.6" class="ltx_td ltx_align_center">17.9</td>
<td id="S5.T3.3.5.4.7" class="ltx_td ltx_align_center">23.9</td>
<td id="S5.T3.3.5.4.8" class="ltx_td ltx_align_center">34.6</td>
<td id="S5.T3.3.5.4.9" class="ltx_td ltx_align_center">22.0</td>
<td id="S5.T3.3.5.4.10" class="ltx_td ltx_align_center">25.8</td>
<td id="S5.T3.3.5.4.11" class="ltx_td ltx_align_center ltx_border_r">28.2</td>
<td id="S5.T3.3.5.4.12" class="ltx_td ltx_align_center">21.8</td>
</tr>
<tr id="S5.T3.3.6.5" class="ltx_tr">
<th id="S5.T3.3.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">AdaFuse (Ours)</th>
<td id="S5.T3.3.6.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.2.1" class="ltx_text ltx_font_bold">21.3</span></td>
<td id="S5.T3.3.6.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.3.1" class="ltx_text ltx_font_bold">16.7</span></td>
<td id="S5.T3.3.6.5.4" class="ltx_td ltx_align_center ltx_border_bb">15.8</td>
<td id="S5.T3.3.6.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.5.1" class="ltx_text ltx_font_bold">10.9</span></td>
<td id="S5.T3.3.6.5.6" class="ltx_td ltx_align_center ltx_border_bb">18.3</td>
<td id="S5.T3.3.6.5.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.7.1" class="ltx_text ltx_font_bold">20.6</span></td>
<td id="S5.T3.3.6.5.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.8.1" class="ltx_text ltx_font_bold">30.2</span></td>
<td id="S5.T3.3.6.5.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.9.1" class="ltx_text ltx_font_bold">21.8</span></td>
<td id="S5.T3.3.6.5.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.10.1" class="ltx_text ltx_font_bold">21.3</span></td>
<td id="S5.T3.3.6.5.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T3.3.6.5.11.1" class="ltx_text ltx_font_bold">21.1</span></td>
<td id="S5.T3.3.6.5.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.3.6.5.12.1" class="ltx_text ltx_font_bold">19.5</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Metrics</h3>

<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">2D Metrics</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.6" class="ltx_p">The Percentage of Correct Keypoints (PCK) metric introduced in <cite class="ltx_cite ltx_citemacro_cite">Andriluka et al. (<a href="#bib.bib2" title="" class="ltx_ref">2014</a>)</cite> is commonly used for <math id="S5.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.1.m1.1a"><mn id="S5.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S5.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.1.m1.1c">2</annotation></semantics></math>D pose evaluation. PCKh@<math id="S5.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S5.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S5.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.2.m2.1c">t</annotation></semantics></math> measures the percentage of the estimated joints whose distance from the ground-truth joints is smaller than <math id="S5.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S5.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S5.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.3.m3.1c">t</annotation></semantics></math> times of the head length. Following the previous works, we report results when <math id="S5.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.4.m4.1a"><mi id="S5.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.4.m4.1b"><ci id="S5.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.4.m4.1c">t</annotation></semantics></math> is <math id="S5.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\frac{1}{2}" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.5.m5.1a"><mfrac id="S5.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml">1</mn><mn id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml">2</mn></mfrac><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.5.m5.1b"><apply id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1"><divide id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1"></divide><cn type="integer" id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.2">1</cn><cn type="integer" id="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S5.SS2.SSS0.Px1.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.5.m5.1c">\frac{1}{2}</annotation></semantics></math>. Since the head length is not provided in the used three benchmarks, we approximately set it to be <math id="S5.SS2.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="2.5\%" display="inline"><semantics id="S5.SS2.SSS0.Px1.p1.6.m6.1a"><mrow id="S5.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.cmml"><mn id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml">2.5</mn><mo id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.1" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px1.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="latexml" id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px1.p1.6.m6.1.1.2">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px1.p1.6.m6.1c">2.5\%</annotation></semantics></math> of the human bounding box width for all benchmarks.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">3D Metrics</h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.8" class="ltx_p">The <math id="S5.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.1c">3</annotation></semantics></math>D pose estimation accuracy is measured by Mean Per Joint Position Error (MPJPE) between a ground truth <math id="S5.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.2.m2.1a"><mn id="S5.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.2.m2.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.2.m2.1c">3</annotation></semantics></math>D pose <math id="S5.SS2.SSS0.Px2.p1.3.m3.3" class="ltx_Math" alttext="y=[p^{3}_{1},\cdots,p^{3}_{M}]" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.3.m3.3a"><mrow id="S5.SS2.SSS0.Px2.p1.3.m3.3.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.4" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.4.cmml">y</mi><mo id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.3.cmml">=</mo><mrow id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.3.cmml"><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">[</mo><msubsup id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.cmml"><mi id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.2.cmml">p</mi><mn id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.3.cmml">1</mn><mn id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.3.cmml">3</mn></msubsup><mo id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.4" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S5.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">⋯</mi><mo id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.5" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">,</mo><msubsup id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.2" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.2.cmml">p</mi><mi id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.3.cmml">M</mi><mn id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.3" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.3.cmml">3</mn></msubsup><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.6" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.3.m3.3b"><apply id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3"><eq id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.3"></eq><ci id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.4.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.4">𝑦</ci><list id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2"><apply id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1">superscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.2">𝑝</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.2.3">3</cn></apply><cn type="integer" id="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S5.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.1.1">⋯</ci><apply id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2">superscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.2">𝑝</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.2.3">3</cn></apply><ci id="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.3.m3.3.3.2.2.2.3">𝑀</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.3.m3.3c">y=[p^{3}_{1},\cdots,p^{3}_{M}]</annotation></semantics></math> and an estimated <math id="S5.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.4.m4.1a"><mn id="S5.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.4.m4.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.4.m4.1c">3</annotation></semantics></math>D pose <math id="S5.SS2.SSS0.Px2.p1.5.m5.3" class="ltx_Math" alttext="\bar{y}=[\bar{p^{3}_{1}},\cdots,\bar{p^{3}_{M}}]" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.5.m5.3a"><mrow id="S5.SS2.SSS0.Px2.p1.5.m5.3.4" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.cmml"><mover accent="true" id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.2.cmml">y</mi><mo id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.1.cmml">¯</mo></mover><mo id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.1.cmml">=</mo><mrow id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.1.cmml"><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.2.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.1.cmml">[</mo><mover accent="true" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.cmml"><msubsup id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.2.cmml">p</mi><mn id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.3.cmml">1</mn><mn id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.3.cmml">3</mn></msubsup><mo id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.1.cmml">¯</mo></mover><mo id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.2.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S5.SS2.SSS0.Px2.p1.5.m5.2.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.2.2.cmml">⋯</mi><mo id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.2.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.1.cmml">,</mo><mover accent="true" id="S5.SS2.SSS0.Px2.p1.5.m5.3.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.cmml"><msubsup id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.2" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.2.cmml">p</mi><mi id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.3.cmml">M</mi><mn id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.3" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.3.cmml">3</mn></msubsup><mo id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.1" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.1.cmml">¯</mo></mover><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.2.4" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.5.m5.3b"><apply id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4"><eq id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.1"></eq><apply id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2"><ci id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.1">¯</ci><ci id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.2.2">𝑦</ci></apply><list id="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.4.3.2"><apply id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1"><ci id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.1">¯</ci><apply id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2">superscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.2">𝑝</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.2.3">3</cn></apply><cn type="integer" id="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.1.1.2.3">1</cn></apply></apply><ci id="S5.SS2.SSS0.Px2.p1.5.m5.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.2.2">⋯</ci><apply id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3"><ci id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.1">¯</ci><apply id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2">superscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.2">𝑝</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.2.3">3</cn></apply><ci id="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.5.m5.3.3.2.3">𝑀</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.5.m5.3c">\bar{y}=[\bar{p^{3}_{1}},\cdots,\bar{p^{3}_{M}}]</annotation></semantics></math>: <math id="S5.SS2.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="\text{MPJPE}=\frac{1}{M}\sum_{i=1}^{M}\|p^{3}_{i}-\bar{p^{3}_{i}}\|_{2}" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.6.m6.1a"><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.cmml"><mtext id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3a.cmml">MPJPE</mtext><mo id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml">=</mo><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml"><mfrac id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.cmml"><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.2.cmml">1</mn><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.3.cmml">M</mi></mfrac><mo lspace="0em" rspace="0em" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.2.cmml">​</mo><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.cmml"><msubsup id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.cmml"><mo rspace="0em" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.cmml"><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.3.cmml">M</mi></msubsup><msub id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.cmml"><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.cmml"><msubsup id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.2.cmml">p</mi><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.3.cmml">3</mn></msubsup><mo id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.cmml"><msubsup id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.2" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.2.cmml">p</mi><mi id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.3.cmml">i</mi><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.3.cmml">3</mn></msubsup><mo id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.1" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.1.cmml">¯</mo></mover></mrow><mo stretchy="false" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.3" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.6.m6.1b"><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1"><eq id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.2"></eq><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3a.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3"><mtext id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.3">MPJPE</mtext></ci><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1"><times id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.2"></times><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3"><divide id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3"></divide><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.2">1</cn><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.3.3">𝑀</ci></apply><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1"><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2">superscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2">subscript</csymbol><sum id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.2"></sum><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3"><eq id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.1"></eq><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.2.3">𝑀</ci></apply><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1"><minus id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.1"></minus><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.2">𝑝</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.2.3">3</cn></apply><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3"><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.1">¯</ci><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><apply id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2">superscript</csymbol><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.2">𝑝</ci><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.2.3">3</cn></apply><ci id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply><cn type="integer" id="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.3.cmml" xref="S5.SS2.SSS0.Px2.p1.6.m6.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.6.m6.1c">\text{MPJPE}=\frac{1}{M}\sum_{i=1}^{M}\|p^{3}_{i}-\bar{p^{3}_{i}}\|_{2}</annotation></semantics></math> where <math id="S5.SS2.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.7.m7.1a"><mi id="S5.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S5.SS2.SSS0.Px2.p1.7.m7.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.7.m7.1b"><ci id="S5.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.7.m7.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.7.m7.1c">M</annotation></semantics></math> is the number of joints in a pose.
We do not align the estimated <math id="S5.SS2.SSS0.Px2.p1.8.m8.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.8.m8.1a"><mn id="S5.SS2.SSS0.Px2.p1.8.m8.1.1" xref="S5.SS2.SSS0.Px2.p1.8.m8.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.8.m8.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.8.m8.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.8.m8.1c">3</annotation></semantics></math>D poses to the ground truth by Procrustes. This is referred to as protocol 1 in some works <cite class="ltx_cite ltx_citemacro_citep">(Martinez et al., <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Tome et al., <a href="#bib.bib54" title="" class="ltx_ref">2018</a>)</cite></p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Experimental Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.8" class="ltx_p">We compare our approach to four baselines. The first is <em id="S6.p1.8.1" class="ltx_emph ltx_font_italic">NoFuse</em> which estimates <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.p1.1.m1.1a"><mn id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><cn type="integer" id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">2</annotation></semantics></math>D poses independently for each view without multiview fusion. The second is <em id="S6.p1.8.2" class="ltx_emph ltx_font_italic">HeuristicFuse</em> which assigns a fixed fusion weight for each view according to Eq. (<a href="#S3.E4" title="In 3.2 Heatmap Fusion ‣ 3 The Basics for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). The parameter <math id="S6.p1.2.m2.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S6.p1.2.m2.1a"><mi id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><ci id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">\lambda</annotation></semantics></math> is set to be <math id="S6.p1.3.m3.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S6.p1.3.m3.1a"><mn id="S6.p1.3.m3.1.1" xref="S6.p1.3.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S6.p1.3.m3.1b"><cn type="float" id="S6.p1.3.m3.1.1.cmml" xref="S6.p1.3.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.3.m3.1c">0.5</annotation></semantics></math> by cross-validation.
The third baseline is <em id="S6.p1.8.3" class="ltx_emph ltx_font_italic">ScoreFuse</em> which uses the same formulation as AdaFuse, i.e. Eq. (<a href="#S4.E5" title="In 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), for feature fusion. It differs from AdaFuse only in the way we compute <math id="S6.p1.4.m4.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S6.p1.4.m4.1a"><mi id="S6.p1.4.m4.1.1" xref="S6.p1.4.m4.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="S6.p1.4.m4.1b"><ci id="S6.p1.4.m4.1.1.cmml" xref="S6.p1.4.m4.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m4.1c">\omega</annotation></semantics></math>. In particular, ScoreFuse computes <math id="S6.p1.5.m5.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S6.p1.5.m5.1a"><mi id="S6.p1.5.m5.1.1" xref="S6.p1.5.m5.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="S6.p1.5.m5.1b"><ci id="S6.p1.5.m5.1.1.cmml" xref="S6.p1.5.m5.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.5.m5.1c">\omega</annotation></semantics></math> as the maximum value of the heatmap <math id="S6.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{H}" display="inline"><semantics id="S6.p1.6.m6.1a"><mi id="S6.p1.6.m6.1.1" xref="S6.p1.6.m6.1.1.cmml">𝐇</mi><annotation-xml encoding="MathML-Content" id="S6.p1.6.m6.1b"><ci id="S6.p1.6.m6.1.1.cmml" xref="S6.p1.6.m6.1.1">𝐇</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.6.m6.1c">\mathbf{H}</annotation></semantics></math>.
Our approach is denoted as <em id="S6.p1.8.4" class="ltx_emph ltx_font_italic">AdaFuse</em> which uses the predicted weight for fusion as in Eq. (<a href="#S4.E5" title="In 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>). All of the four methods use triangulation <cite class="ltx_cite ltx_citemacro_citep">(Hartley and Zisserman, <a href="#bib.bib20" title="" class="ltx_ref">2003</a>)</cite> to estimate <math id="S6.p1.7.m7.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.p1.7.m7.1a"><mn id="S6.p1.7.m7.1.1" xref="S6.p1.7.m7.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.p1.7.m7.1b"><cn type="integer" id="S6.p1.7.m7.1.1.cmml" xref="S6.p1.7.m7.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.7.m7.1c">3</annotation></semantics></math>D pose from the multiview <math id="S6.p1.8.m8.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.p1.8.m8.1a"><mn id="S6.p1.8.m8.1.1" xref="S6.p1.8.m8.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.p1.8.m8.1b"><cn type="integer" id="S6.p1.8.m8.1.1.cmml" xref="S6.p1.8.m8.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.8.m8.1c">2</annotation></semantics></math>D poses. We also compare to a baseline <em id="S6.p1.8.5" class="ltx_emph ltx_font_italic">RANSAC</em> which does not perform multiview fusion, but uses RANSAC to remove the outliers in triangulation.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Results on Human3.6M</h3>

<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">
<math id="S6.SS1.SSS0.Px1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px1.1.m1.1b"><mn id="S6.SS1.SSS0.Px1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.1.m1.1c"><cn type="integer" id="S6.SS1.SSS0.Px1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.1.m1.1d">2</annotation></semantics></math>D Pose Estimation Results</h4>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.1" class="ltx_p">The <math id="S6.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.1.m1.1c">2</annotation></semantics></math>D pose estimation results are presented in Table <a href="#S5.T2" title="Table 2 ‣ The Occlusion-Person Dataset ‣ 5.1 Datasets ‣ 5 Datasets and Metrics ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. All multiview fusion methods remarkably outperform <em id="S6.SS1.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">NoFuse</em>. The improvement is most significant for the Elbow and Wrist joints because they are frequently occluded by human body. The results demonstrate that multiview fusion is an effective strategy to handle occlusion. <em id="S6.SS1.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">AdaFuse</em> achieves the highest average accuracy among all fusion methods validating that learning appropriate fusion weights can effectively reduce the negative impact caused by the features of low-quality views.</p>
</div>
<figure id="S6.F11" class="ltx_figure"><img src="/html/2010.13302/assets/x11.png" id="S6.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="323" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>We divide the test set of Human3.6M into to six groups according to the error of <em id="S6.F11.2.1" class="ltx_emph ltx_font_italic">NoFuse</em>. We compute the average error for every baseline and every group, respectively.</figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">
<math id="S6.SS1.SSS0.Px2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.SSS0.Px2.1.m1.1b"><mn id="S6.SS1.SSS0.Px2.1.m1.1.1" xref="S6.SS1.SSS0.Px2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.1.m1.1c"><cn type="integer" id="S6.SS1.SSS0.Px2.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.1.m1.1d">3</annotation></semantics></math>D Pose Estimation Results</h4>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.3" class="ltx_p">Table <a href="#S5.T3" title="Table 3 ‣ The Occlusion-Person Dataset ‣ 5.1 Datasets ‣ 5 Datasets and Metrics ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the <math id="S6.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.SSS0.Px2.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.1.m1.1c">3</annotation></semantics></math>D pose estimation errors of the baselines and our approach. We can see that <em id="S6.SS1.SSS0.Px2.p1.3.1" class="ltx_emph ltx_font_italic">NoFuse</em> gets an average error of <math id="S6.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="22.9" display="inline"><semantics id="S6.SS1.SSS0.Px2.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">22.9</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.2.m2.1b"><cn type="float" id="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1">22.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.2.m2.1c">22.9</annotation></semantics></math>mm. This is a very strong baseline whose error is only slightly larger than the state-of-the-arts (see Table <a href="#S6.T4" title="Table 4 ‣ Comparison to the State-of-the-arts ‣ 6.1 Results on Human3.6M ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). On top of this strong baseline, we observe that adding multiview fusion can further reduce the <math id="S6.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.SSS0.Px2.p1.3.m3.1a"><mn id="S6.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S6.SS1.SSS0.Px2.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.3.m3.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S6.SS1.SSS0.Px2.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.3.m3.1c">3</annotation></semantics></math>D pose estimation errors.</p>
</div>
<div id="S6.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p2.5" class="ltx_p"><em id="S6.SS1.SSS0.Px2.p2.5.1" class="ltx_emph ltx_font_italic">HeuristicFuse</em> gets a smaller error than <em id="S6.SS1.SSS0.Px2.p2.5.2" class="ltx_emph ltx_font_italic">NoFuse</em> which is consistent with the <math id="S6.SS1.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px2.p2.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.1.m1.1c">2</annotation></semantics></math>D results in Table <a href="#S5.T2" title="Table 2 ‣ The Occlusion-Person Dataset ‣ 5.1 Datasets ‣ 5 Datasets and Metrics ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The mean error only decreases by <math id="S6.SS1.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="1.9" display="inline"><semantics id="S6.SS1.SSS0.Px2.p2.2.m2.1a"><mn id="S6.SS1.SSS0.Px2.p2.2.m2.1.1" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1.cmml">1.9</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.2.m2.1b"><cn type="float" id="S6.SS1.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.2.m2.1.1">1.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.2.m2.1c">1.9</annotation></semantics></math>mm because most examples are relatively easy leaving little space for improvement. However, significant improvement is achieved for the challenging joints such as Wrist. The <em id="S6.SS1.SSS0.Px2.p2.5.3" class="ltx_emph ltx_font_italic">ScoreFuse</em> gets a smaller error than <em id="S6.SS1.SSS0.Px2.p2.5.4" class="ltx_emph ltx_font_italic">HeuristicFuse</em>. It means assigning small weights to low-quality views helps improve the quality of the fused heatmaps. Finally, our approach <em id="S6.SS1.SSS0.Px2.p2.5.5" class="ltx_emph ltx_font_italic">AdaFuse</em>, which determines the fusion weight by considering both appearance cues and geometry consistency, notably decreases the average error to <math id="S6.SS1.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="19.5" display="inline"><semantics id="S6.SS1.SSS0.Px2.p2.3.m3.1a"><mn id="S6.SS1.SSS0.Px2.p2.3.m3.1.1" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1.cmml">19.5</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.3.m3.1b"><cn type="float" id="S6.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.3.m3.1.1">19.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.3.m3.1c">19.5</annotation></semantics></math>mm. Considering the baseline is already very strong, the improvement is significant.
We notice that AdaFuse achieves slightly worse results on a small number of joints such as hip and head. This is mainly because these joints are rarely occluded in the datasets so the <math id="S6.SS1.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px2.p2.4.m4.1a"><mn id="S6.SS1.SSS0.Px2.p2.4.m4.1.1" xref="S6.SS1.SSS0.Px2.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.4.m4.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.4.m4.1c">2</annotation></semantics></math>D pose estimator can obtain very accurate estimations for them. Further applying cross view fusion will introduce small noise to heatmaps leading to slightly worse <math id="S6.SS1.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px2.p2.5.m5.1a"><mn id="S6.SS1.SSS0.Px2.p2.5.m5.1.1" xref="S6.SS1.SSS0.Px2.p2.5.m5.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p2.5.m5.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S6.SS1.SSS0.Px2.p2.5.m5.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p2.5.m5.1c">2</annotation></semantics></math>D pose estimation accuracy. But when occlusion occurs which is often the case in practice, the benefit brought by cross view fusion will be much more significant than the harm caused by the small noise.</p>
</div>
<div id="S6.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p3.1" class="ltx_p"><em id="S6.SS1.SSS0.Px2.p3.1.1" class="ltx_emph ltx_font_italic">RANSAC</em> is the de facto standard for solving robust estimation problems. As shown in Table <a href="#S5.T3" title="Table 3 ‣ The Occlusion-Person Dataset ‣ 5.1 Datasets ‣ 5 Datasets and Metrics ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, it outperforms <em id="S6.SS1.SSS0.Px2.p3.1.2" class="ltx_emph ltx_font_italic">NoFuse</em> by removing some outlier <math id="S6.SS1.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px2.p3.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p3.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p3.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p3.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p3.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p3.1.m1.1c">2</annotation></semantics></math>D poses in triangulation. However, it is not as effective as the multiview fusion methods because the latter also attempt to refine, in addition to removing, the outlier poses. Another reason is that the number of cameras in this task is small which reduces the chance of finding the true outliers. In addition, we find that <em id="S6.SS1.SSS0.Px2.p3.1.3" class="ltx_emph ltx_font_italic">RANSAC</em> is very sensitive to the threshold used for determining whether a data point is inlier or outlier. In our experiments, we set the threshold by cross validation.</p>
</div>
<figure id="S6.F12" class="ltx_figure"><img src="/html/2010.13302/assets/x12.png" id="S6.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>We visualize the weights predicted by the <em id="S6.F12.5.1" class="ltx_emph ltx_font_italic">ScoreFuse</em> and <em id="S6.F12.6.2" class="ltx_emph ltx_font_italic">AdaFuse</em>, respectively. For example, in the first example (left sub-figure), the pose estimation network generates a high response at the wrong location for the first view. Consequently, <em id="S6.F12.7.3" class="ltx_emph ltx_font_italic">ScoreFuse</em> undesirably gives a large weight. In contrast, <em id="S6.F12.8.4" class="ltx_emph ltx_font_italic">AdaFuse</em> gives a small weight by identifying that its location are inconsistent with other views.</figcaption>
</figure>
<div id="S6.SS1.SSS0.Px2.p4" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p4.1" class="ltx_p">To better understand the improvement brought by <em id="S6.SS1.SSS0.Px2.p4.1.1" class="ltx_emph ltx_font_italic">AdaFuse</em>, we divide the testing samples of the Human3.6M dataset into six groups according to the <math id="S6.SS1.SSS0.Px2.p4.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.SSS0.Px2.p4.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p4.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p4.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p4.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p4.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p4.1.m1.1c">3</annotation></semantics></math>D errors of <em id="S6.SS1.SSS0.Px2.p4.1.2" class="ltx_emph ltx_font_italic">NoFuse</em>. Then we compute the average error for each group. Figure <a href="#S6.F11" title="Figure 11 ‣ 2D Pose Estimation Results ‣ 6.1 Results on Human3.6M ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows the results of various baselines. We can see that <em id="S6.SS1.SSS0.Px2.p4.1.3" class="ltx_emph ltx_font_italic">AdaFuse</em> achieves the most significant improvement when the original error of <em id="S6.SS1.SSS0.Px2.p4.1.4" class="ltx_emph ltx_font_italic">NoFuse</em> is large. However, even when the pose estimations of <em id="S6.SS1.SSS0.Px2.p4.1.5" class="ltx_emph ltx_font_italic">NoFuse</em> are already accurate, <em id="S6.SS1.SSS0.Px2.p4.1.6" class="ltx_emph ltx_font_italic">AdaFuse</em> can still reduce the error slightly.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Ablation Study on Fusion Weights</h4>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">One typical situation where <em id="S6.SS1.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">ScoreFuse</em> fails is when the pose estimation network generates large scores at <em id="S6.SS1.SSS0.Px3.p1.1.2" class="ltx_emph ltx_font_italic">inaccurate</em> locations. In this case, <em id="S6.SS1.SSS0.Px3.p1.1.3" class="ltx_emph ltx_font_italic">AdaFuse</em> can outperform <em id="S6.SS1.SSS0.Px3.p1.1.4" class="ltx_emph ltx_font_italic">ScoreFuse</em> by leveraging the multiview geometry consistency. To support this conjecture, we visualize some typical heatmaps and the corresponding fusion weights predicted by the two methods, respectively, in Figure <a href="#S6.F12" title="Figure 12 ‣ 3D Pose Estimation Results ‣ 6.1 Results on Human3.6M ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. We find that the heatmap responses are large for the four views although the locations are inaccurate for the first and third view. <em id="S6.SS1.SSS0.Px3.p1.1.5" class="ltx_emph ltx_font_italic">ScoreFuse</em> gives large weights for all views which finally leads to a corrupted heatmap. In contrast, <em id="S6.SS1.SSS0.Px3.p1.1.6" class="ltx_emph ltx_font_italic">AdaFuse</em> identifies that the predicted locations in the first and third view are inconsistent with the other two views in spite of their large scores. So it decreases the weights to ensure the good quality of the fused heatmap.</p>
</div>
<div id="S6.SS1.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p2.3" class="ltx_p">In addition, we also conduct ablation study on <em id="S6.SS1.SSS0.Px3.p2.3.1" class="ltx_emph ltx_font_italic">AdaFuse</em> by using only one of two embedding networks. When we only use either the <em id="S6.SS1.SSS0.Px3.p2.3.2" class="ltx_emph ltx_font_italic">appearance embedding</em> or <em id="S6.SS1.SSS0.Px3.p2.3.3" class="ltx_emph ltx_font_italic">geometry embedding</em>, the <math id="S6.SS1.SSS0.Px3.p2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.SSS0.Px3.p2.1.m1.1a"><mn id="S6.SS1.SSS0.Px3.p2.1.m1.1.1" xref="S6.SS1.SSS0.Px3.p2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px3.p2.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px3.p2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px3.p2.1.m1.1c">3</annotation></semantics></math>D errors increase to <math id="S6.SS1.SSS0.Px3.p2.2.m2.1" class="ltx_Math" alttext="20.3" display="inline"><semantics id="S6.SS1.SSS0.Px3.p2.2.m2.1a"><mn id="S6.SS1.SSS0.Px3.p2.2.m2.1.1" xref="S6.SS1.SSS0.Px3.p2.2.m2.1.1.cmml">20.3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px3.p2.2.m2.1b"><cn type="float" id="S6.SS1.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px3.p2.2.m2.1.1">20.3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px3.p2.2.m2.1c">20.3</annotation></semantics></math>mm and <math id="S6.SS1.SSS0.Px3.p2.3.m3.1" class="ltx_Math" alttext="19.9" display="inline"><semantics id="S6.SS1.SSS0.Px3.p2.3.m3.1a"><mn id="S6.SS1.SSS0.Px3.p2.3.m3.1.1" xref="S6.SS1.SSS0.Px3.p2.3.m3.1.1.cmml">19.9</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px3.p2.3.m3.1b"><cn type="float" id="S6.SS1.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S6.SS1.SSS0.Px3.p2.3.m3.1.1">19.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px3.p2.3.m3.1c">19.9</annotation></semantics></math>mm, respectively. Note that the improvement is actually much larger on those challenging examples. The results validate that the two embeddings are complementary.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Comparison to the State-of-the-arts</h4>

<div id="S6.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px4.p1.3" class="ltx_p">Table <a href="#S6.T4" title="Table 4 ‣ Comparison to the State-of-the-arts ‣ 6.1 Results on Human3.6M ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> compares our approach to the state-of-the-arts. We can see that our approach outperforms all of them. Note that two approaches, <span id="S6.SS1.SSS0.Px4.p1.3.1" class="ltx_text ltx_font_italic">i</span>.<span id="S6.SS1.SSS0.Px4.p1.3.2" class="ltx_text ltx_font_italic">e</span>. <em id="S6.SS1.SSS0.Px4.p1.3.3" class="ltx_emph ltx_font_italic">Triangulation</em> and <em id="S6.SS1.SSS0.Px4.p1.3.4" class="ltx_emph ltx_font_italic">Volumetric</em>, are used in <cite class="ltx_cite ltx_citemacro_citep">(Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite> to lift <math id="S6.SS1.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS1.SSS0.Px4.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px4.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px4.p1.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px4.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px4.p1.1.m1.1c">2</annotation></semantics></math>D poses to <math id="S6.SS1.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.SSS0.Px4.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px4.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px4.p1.2.m2.1b"><cn type="integer" id="S6.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px4.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px4.p1.2.m2.1c">3</annotation></semantics></math>D. The <em id="S6.SS1.SSS0.Px4.p1.3.5" class="ltx_emph ltx_font_italic">Triangulation</em> approach is more comparable to ours. Our approach <em id="S6.SS1.SSS0.Px4.p1.3.6" class="ltx_emph ltx_font_italic">AdaFuse</em> decreases the error of <cite class="ltx_cite ltx_citemacro_citep">(Iskakov et al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite> by about <math id="S6.SS1.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="13\%(=\frac{22.6-19.5}{22.6})" display="inline"><semantics id="S6.SS1.SSS0.Px4.p1.3.m3.1a"><mrow id="S6.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"><mrow id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml"><mn id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.2" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.2.cmml">13</mn><mo id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.1" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.1.cmml">%</mo></mrow><mspace width="0.3888888888888889em" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1a" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"></mspace><mrow id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.2" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.cmml"><mi id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.2" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.2.cmml"></mi><mo id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.1" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.1.cmml">=</mo><mfrac id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.cmml"><mrow id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.cmml"><mn id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.2" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.2.cmml">22.6</mn><mo id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.1" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.1.cmml">−</mo><mn id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.3" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.3.cmml">19.5</mn></mrow><mn id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.3" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.3.cmml">22.6</mn></mfrac></mrow><mo stretchy="false" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.3" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px4.p1.3.m3.1b"><apply id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1"><csymbol cd="latexml" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1">annotated</csymbol><apply id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3"><csymbol cd="latexml" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.1.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.1">percent</csymbol><cn type="integer" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.2.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.3.2">13</cn></apply><apply id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1"><eq id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.1.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.1"></eq><csymbol cd="latexml" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.2.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.2">absent</csymbol><apply id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3"><divide id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.1.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3"></divide><apply id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2"><minus id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.1.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.1"></minus><cn type="float" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.2.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.2">22.6</cn><cn type="float" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.3.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.2.3">19.5</cn></apply><cn type="float" id="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.3.cmml" xref="S6.SS1.SSS0.Px4.p1.3.m3.1.1.1.1.1.3.3">22.6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px4.p1.3.m3.1c">13\%(=\frac{22.6-19.5}{22.6})</annotation></semantics></math>. The improvement is significant considering that the error of the state-of-the-art is already very small.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>The <math id="S6.T4.4.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.T4.4.m1.1b"><mn id="S6.T4.4.m1.1.1" xref="S6.T4.4.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.T4.4.m1.1c"><cn type="integer" id="S6.T4.4.m1.1.1.cmml" xref="S6.T4.4.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.4.m1.1d">3</annotation></semantics></math>D pose estimation errors (<math id="S6.T4.5.m2.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S6.T4.5.m2.1b"><mrow id="S6.T4.5.m2.1.1" xref="S6.T4.5.m2.1.1.cmml"><mi id="S6.T4.5.m2.1.1.2" xref="S6.T4.5.m2.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.T4.5.m2.1.1.1" xref="S6.T4.5.m2.1.1.1.cmml">​</mo><mi id="S6.T4.5.m2.1.1.3" xref="S6.T4.5.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.5.m2.1c"><apply id="S6.T4.5.m2.1.1.cmml" xref="S6.T4.5.m2.1.1"><times id="S6.T4.5.m2.1.1.1.cmml" xref="S6.T4.5.m2.1.1.1"></times><ci id="S6.T4.5.m2.1.1.2.cmml" xref="S6.T4.5.m2.1.1.2">𝑚</ci><ci id="S6.T4.5.m2.1.1.3.cmml" xref="S6.T4.5.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.5.m2.1d">mm</annotation></semantics></math>) of the state-of-the-arts and our approach on the Human3.6M dataset. We report results for each of the <math id="S6.T4.6.m3.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S6.T4.6.m3.1b"><mn id="S6.T4.6.m3.1.1" xref="S6.T4.6.m3.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S6.T4.6.m3.1c"><cn type="integer" id="S6.T4.6.m3.1.1.cmml" xref="S6.T4.6.m3.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.6.m3.1d">15</annotation></semantics></math> actions individually and also the average error over all actions. T- <cite class="ltx_cite ltx_citemacro_cite">Iskakov et al. (<a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite> means triangulation is used. V- <cite class="ltx_cite ltx_citemacro_cite">Iskakov et al. (<a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite> means volumetric method is used.
</figcaption>
<table id="S6.T4.18" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T4.18.1.1" class="ltx_tr">
<th id="S6.T4.18.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.1.1" class="ltx_text" style="font-size:90%;">Methods</span></th>
<td id="S6.T4.18.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.2.1" class="ltx_text" style="font-size:90%;">Direct</span></td>
<td id="S6.T4.18.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.3.1" class="ltx_text" style="font-size:90%;">Disc.</span></td>
<td id="S6.T4.18.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.4.1" class="ltx_text" style="font-size:90%;">Eat</span></td>
<td id="S6.T4.18.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.5.1" class="ltx_text" style="font-size:90%;">Greet</span></td>
<td id="S6.T4.18.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.6.1" class="ltx_text" style="font-size:90%;">Phone</span></td>
<td id="S6.T4.18.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.7.1" class="ltx_text" style="font-size:90%;">Photo</span></td>
<td id="S6.T4.18.1.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.8.1" class="ltx_text" style="font-size:90%;">Pose</span></td>
<td id="S6.T4.18.1.1.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.9.1" class="ltx_text" style="font-size:90%;">Purch</span></td>
<td id="S6.T4.18.1.1.10" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.10.1" class="ltx_text" style="font-size:90%;">Sit</span></td>
<td id="S6.T4.18.1.1.11" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.11.1" class="ltx_text" style="font-size:90%;">SitD</span></td>
<td id="S6.T4.18.1.1.12" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.12.1" class="ltx_text" style="font-size:90%;">Smoke</span></td>
<td id="S6.T4.18.1.1.13" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.13.1" class="ltx_text" style="font-size:90%;">Wait</span></td>
<td id="S6.T4.18.1.1.14" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.14.1" class="ltx_text" style="font-size:90%;">WalkD</span></td>
<td id="S6.T4.18.1.1.15" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.15.1" class="ltx_text" style="font-size:90%;">Walk</span></td>
<td id="S6.T4.18.1.1.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.1.1.16.1" class="ltx_text" style="font-size:90%;">WalkT</span></td>
<td id="S6.T4.18.1.1.17" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.8pt;padding-right:2.8pt;"><em id="S6.T4.18.1.1.17.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">MPJPE</em></td>
</tr>
<tr id="S6.T4.18.2.2" class="ltx_tr">
<th id="S6.T4.18.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><cite class="ltx_cite ltx_citemacro_cite">Trumble et al. <span id="S6.T4.18.2.2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib55" title="" class="ltx_ref">2017</a><span id="S6.T4.18.2.2.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S6.T4.18.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.2.1" class="ltx_text" style="font-size:90%;">92.7</span></td>
<td id="S6.T4.18.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.3.1" class="ltx_text" style="font-size:90%;">85.9</span></td>
<td id="S6.T4.18.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.4.1" class="ltx_text" style="font-size:90%;">72.3</span></td>
<td id="S6.T4.18.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.5.1" class="ltx_text" style="font-size:90%;">93.2</span></td>
<td id="S6.T4.18.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.6.1" class="ltx_text" style="font-size:90%;">86.2</span></td>
<td id="S6.T4.18.2.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.7.1" class="ltx_text" style="font-size:90%;">101.2</span></td>
<td id="S6.T4.18.2.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.8.1" class="ltx_text" style="font-size:90%;">75.1</span></td>
<td id="S6.T4.18.2.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.9.1" class="ltx_text" style="font-size:90%;">78.0</span></td>
<td id="S6.T4.18.2.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.10.1" class="ltx_text" style="font-size:90%;">83.5</span></td>
<td id="S6.T4.18.2.2.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.11.1" class="ltx_text" style="font-size:90%;">94.8</span></td>
<td id="S6.T4.18.2.2.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.12.1" class="ltx_text" style="font-size:90%;">85.8</span></td>
<td id="S6.T4.18.2.2.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.13.1" class="ltx_text" style="font-size:90%;">82.0</span></td>
<td id="S6.T4.18.2.2.14" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.14.1" class="ltx_text" style="font-size:90%;">114.6</span></td>
<td id="S6.T4.18.2.2.15" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.15.1" class="ltx_text" style="font-size:90%;">94.9</span></td>
<td id="S6.T4.18.2.2.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.16.1" class="ltx_text" style="font-size:90%;">79.7</span></td>
<td id="S6.T4.18.2.2.17" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.2.2.17.1" class="ltx_text" style="font-size:90%;">87.3</span></td>
</tr>
<tr id="S6.T4.18.3.3" class="ltx_tr">
<th id="S6.T4.18.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><cite class="ltx_cite ltx_citemacro_cite">Pavlakos et al. <span id="S6.T4.18.3.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib39" title="" class="ltx_ref">2017</a><span id="S6.T4.18.3.3.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S6.T4.18.3.3.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.2.1" class="ltx_text" style="font-size:90%;">41.2</span></td>
<td id="S6.T4.18.3.3.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.3.1" class="ltx_text" style="font-size:90%;">49.2</span></td>
<td id="S6.T4.18.3.3.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.4.1" class="ltx_text" style="font-size:90%;">42.8</span></td>
<td id="S6.T4.18.3.3.5" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.5.1" class="ltx_text" style="font-size:90%;">43.4</span></td>
<td id="S6.T4.18.3.3.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.6.1" class="ltx_text" style="font-size:90%;">55.6</span></td>
<td id="S6.T4.18.3.3.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.7.1" class="ltx_text" style="font-size:90%;">46.9</span></td>
<td id="S6.T4.18.3.3.8" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.8.1" class="ltx_text" style="font-size:90%;">40.3</span></td>
<td id="S6.T4.18.3.3.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.9.1" class="ltx_text" style="font-size:90%;">63.7</span></td>
<td id="S6.T4.18.3.3.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.10.1" class="ltx_text" style="font-size:90%;">97.6</span></td>
<td id="S6.T4.18.3.3.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.11.1" class="ltx_text" style="font-size:90%;">119.0</span></td>
<td id="S6.T4.18.3.3.12" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.12.1" class="ltx_text" style="font-size:90%;">52.1</span></td>
<td id="S6.T4.18.3.3.13" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.13.1" class="ltx_text" style="font-size:90%;">42.7</span></td>
<td id="S6.T4.18.3.3.14" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.14.1" class="ltx_text" style="font-size:90%;">51.9</span></td>
<td id="S6.T4.18.3.3.15" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.15.1" class="ltx_text" style="font-size:90%;">41.8</span></td>
<td id="S6.T4.18.3.3.16" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.16.1" class="ltx_text" style="font-size:90%;">39.4</span></td>
<td id="S6.T4.18.3.3.17" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.3.3.17.1" class="ltx_text" style="font-size:90%;">56.9</span></td>
</tr>
<tr id="S6.T4.18.4.4" class="ltx_tr">
<th id="S6.T4.18.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><cite class="ltx_cite ltx_citemacro_cite">Tome et al. <span id="S6.T4.18.4.4.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib54" title="" class="ltx_ref">2018</a><span id="S6.T4.18.4.4.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S6.T4.18.4.4.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.2.1" class="ltx_text" style="font-size:90%;">43.3</span></td>
<td id="S6.T4.18.4.4.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.3.1" class="ltx_text" style="font-size:90%;">49.6</span></td>
<td id="S6.T4.18.4.4.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.4.1" class="ltx_text" style="font-size:90%;">42.0</span></td>
<td id="S6.T4.18.4.4.5" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.5.1" class="ltx_text" style="font-size:90%;">48.8</span></td>
<td id="S6.T4.18.4.4.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.6.1" class="ltx_text" style="font-size:90%;">51.1</span></td>
<td id="S6.T4.18.4.4.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.7.1" class="ltx_text" style="font-size:90%;">64.3</span></td>
<td id="S6.T4.18.4.4.8" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.8.1" class="ltx_text" style="font-size:90%;">40.3</span></td>
<td id="S6.T4.18.4.4.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.9.1" class="ltx_text" style="font-size:90%;">43.3</span></td>
<td id="S6.T4.18.4.4.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.10.1" class="ltx_text" style="font-size:90%;">66.0</span></td>
<td id="S6.T4.18.4.4.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.11.1" class="ltx_text" style="font-size:90%;">95.2</span></td>
<td id="S6.T4.18.4.4.12" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.12.1" class="ltx_text" style="font-size:90%;">50.2</span></td>
<td id="S6.T4.18.4.4.13" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.13.1" class="ltx_text" style="font-size:90%;">52.2</span></td>
<td id="S6.T4.18.4.4.14" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.14.1" class="ltx_text" style="font-size:90%;">51.1</span></td>
<td id="S6.T4.18.4.4.15" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.15.1" class="ltx_text" style="font-size:90%;">43.9</span></td>
<td id="S6.T4.18.4.4.16" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.16.1" class="ltx_text" style="font-size:90%;">45.3</span></td>
<td id="S6.T4.18.4.4.17" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.4.4.17.1" class="ltx_text" style="font-size:90%;">52.8</span></td>
</tr>
<tr id="S6.T4.18.5.5" class="ltx_tr">
<th id="S6.T4.18.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><cite class="ltx_cite ltx_citemacro_cite">Qiu et al. <span id="S6.T4.18.5.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib45" title="" class="ltx_ref">2019</a><span id="S6.T4.18.5.5.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></th>
<td id="S6.T4.18.5.5.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.2.1" class="ltx_text" style="font-size:90%;">24.0</span></td>
<td id="S6.T4.18.5.5.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.3.1" class="ltx_text" style="font-size:90%;">26.7</span></td>
<td id="S6.T4.18.5.5.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.4.1" class="ltx_text" style="font-size:90%;">23.2</span></td>
<td id="S6.T4.18.5.5.5" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.5.1" class="ltx_text" style="font-size:90%;">24.3</span></td>
<td id="S6.T4.18.5.5.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.6.1" class="ltx_text" style="font-size:90%;">24.8</span></td>
<td id="S6.T4.18.5.5.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.7.1" class="ltx_text" style="font-size:90%;">22.8</span></td>
<td id="S6.T4.18.5.5.8" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.8.1" class="ltx_text" style="font-size:90%;">24.1</span></td>
<td id="S6.T4.18.5.5.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.9.1" class="ltx_text" style="font-size:90%;">28.6</span></td>
<td id="S6.T4.18.5.5.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.10.1" class="ltx_text" style="font-size:90%;">32.1</span></td>
<td id="S6.T4.18.5.5.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.11.1" class="ltx_text" style="font-size:90%;">26.9</span></td>
<td id="S6.T4.18.5.5.12" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.12.1" class="ltx_text" style="font-size:90%;">30.9</span></td>
<td id="S6.T4.18.5.5.13" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.13.1" class="ltx_text" style="font-size:90%;">25.6</span></td>
<td id="S6.T4.18.5.5.14" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.14.1" class="ltx_text" style="font-size:90%;">25.0</span></td>
<td id="S6.T4.18.5.5.15" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.15.1" class="ltx_text" style="font-size:90%;">28.0</span></td>
<td id="S6.T4.18.5.5.16" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.16.1" class="ltx_text" style="font-size:90%;">24.4</span></td>
<td id="S6.T4.18.5.5.17" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.5.5.17.1" class="ltx_text" style="font-size:90%;">26.2</span></td>
</tr>
<tr id="S6.T4.18.6.6" class="ltx_tr">
<th id="S6.T4.18.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">
<span id="S6.T4.18.6.6.1.1" class="ltx_text" style="font-size:90%;">T- </span><cite class="ltx_cite ltx_citemacro_cite">Iskakov et al. <span id="S6.T4.18.6.6.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib25" title="" class="ltx_ref">2019</a><span id="S6.T4.18.6.6.1.3.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S6.T4.18.6.6.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.2.1" class="ltx_text" style="font-size:90%;">20.4</span></td>
<td id="S6.T4.18.6.6.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.3.1" class="ltx_text" style="font-size:90%;">22.6</span></td>
<td id="S6.T4.18.6.6.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.4.1" class="ltx_text" style="font-size:90%;">20.5</span></td>
<td id="S6.T4.18.6.6.5" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.5.1" class="ltx_text" style="font-size:90%;">19.7</span></td>
<td id="S6.T4.18.6.6.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.6.1" class="ltx_text" style="font-size:90%;">22.1</span></td>
<td id="S6.T4.18.6.6.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.7.1" class="ltx_text" style="font-size:90%;">20.6</span></td>
<td id="S6.T4.18.6.6.8" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.8.1" class="ltx_text" style="font-size:90%;">19.5</span></td>
<td id="S6.T4.18.6.6.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.9.1" class="ltx_text" style="font-size:90%;">23.0</span></td>
<td id="S6.T4.18.6.6.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.10.1" class="ltx_text" style="font-size:90%;">25.8</span></td>
<td id="S6.T4.18.6.6.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.11.1" class="ltx_text" style="font-size:90%;">33.0</span></td>
<td id="S6.T4.18.6.6.12" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.12.1" class="ltx_text" style="font-size:90%;">23.0</span></td>
<td id="S6.T4.18.6.6.13" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.13.1" class="ltx_text" style="font-size:90%;">21.6</span></td>
<td id="S6.T4.18.6.6.14" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.14.1" class="ltx_text" style="font-size:90%;">20.7</span></td>
<td id="S6.T4.18.6.6.15" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.15.1" class="ltx_text" style="font-size:90%;">23.7</span></td>
<td id="S6.T4.18.6.6.16" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.16.1" class="ltx_text" style="font-size:90%;">21.3</span></td>
<td id="S6.T4.18.6.6.17" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.6.6.17.1" class="ltx_text" style="font-size:90%;">22.6</span></td>
</tr>
<tr id="S6.T4.18.7.7" class="ltx_tr">
<th id="S6.T4.18.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;">
<span id="S6.T4.18.7.7.1.1" class="ltx_text" style="font-size:90%;">V- </span><cite class="ltx_cite ltx_citemacro_cite">Iskakov et al. <span id="S6.T4.18.7.7.1.2.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib25" title="" class="ltx_ref">2019</a><span id="S6.T4.18.7.7.1.3.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite>
</th>
<td id="S6.T4.18.7.7.2" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.2.1" class="ltx_text" style="font-size:90%;">18.8</span></td>
<td id="S6.T4.18.7.7.3" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.3.1" class="ltx_text" style="font-size:90%;">20.0</span></td>
<td id="S6.T4.18.7.7.4" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.4.1" class="ltx_text" style="font-size:90%;">19.3</span></td>
<td id="S6.T4.18.7.7.5" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">18.7</span></td>
<td id="S6.T4.18.7.7.6" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.6.1" class="ltx_text" style="font-size:90%;">20.2</span></td>
<td id="S6.T4.18.7.7.7" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.7.1" class="ltx_text" style="font-size:90%;">19.3</span></td>
<td id="S6.T4.18.7.7.8" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">18.7</span></td>
<td id="S6.T4.18.7.7.9" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.9.1" class="ltx_text" style="font-size:90%;">22.3</span></td>
<td id="S6.T4.18.7.7.10" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.10.1" class="ltx_text ltx_font_bold" style="font-size:90%;">23.3</span></td>
<td id="S6.T4.18.7.7.11" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.11.1" class="ltx_text" style="font-size:90%;">29.1</span></td>
<td id="S6.T4.18.7.7.12" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.12.1" class="ltx_text" style="font-size:90%;">21.2</span></td>
<td id="S6.T4.18.7.7.13" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.13.1" class="ltx_text ltx_font_bold" style="font-size:90%;">20.3</span></td>
<td id="S6.T4.18.7.7.14" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.14.1" class="ltx_text" style="font-size:90%;">19.3</span></td>
<td id="S6.T4.18.7.7.15" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.15.1" class="ltx_text" style="font-size:90%;">21.6</span></td>
<td id="S6.T4.18.7.7.16" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.16.1" class="ltx_text" style="font-size:90%;">19.8</span></td>
<td id="S6.T4.18.7.7.17" class="ltx_td ltx_align_center" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.7.7.17.1" class="ltx_text" style="font-size:90%;">20.8</span></td>
</tr>
<tr id="S6.T4.18.8.8" class="ltx_tr">
<th id="S6.T4.18.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.1.1" class="ltx_text" style="font-size:90%;">NoFuse</span></th>
<td id="S6.T4.18.8.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.2.1" class="ltx_text" style="font-size:90%;">20.1</span></td>
<td id="S6.T4.18.8.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.3.1" class="ltx_text" style="font-size:90%;">22.2</span></td>
<td id="S6.T4.18.8.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.4.1" class="ltx_text" style="font-size:90%;">20.2</span></td>
<td id="S6.T4.18.8.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.5.1" class="ltx_text" style="font-size:90%;">22.2</span></td>
<td id="S6.T4.18.8.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.6.1" class="ltx_text" style="font-size:90%;">23.9</span></td>
<td id="S6.T4.18.8.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.7.1" class="ltx_text" style="font-size:90%;">18.2</span></td>
<td id="S6.T4.18.8.8.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.8.1" class="ltx_text" style="font-size:90%;">20.6</span></td>
<td id="S6.T4.18.8.8.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.9.1" class="ltx_text" style="font-size:90%;">25.9</span></td>
<td id="S6.T4.18.8.8.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.10.1" class="ltx_text" style="font-size:90%;">37.0</span></td>
<td id="S6.T4.18.8.8.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.11.1" class="ltx_text" style="font-size:90%;">24.6</span></td>
<td id="S6.T4.18.8.8.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.12.1" class="ltx_text" style="font-size:90%;">22.4</span></td>
<td id="S6.T4.18.8.8.13" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.13.1" class="ltx_text" style="font-size:90%;">22.5</span></td>
<td id="S6.T4.18.8.8.14" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.14.1" class="ltx_text" style="font-size:90%;">18.2</span></td>
<td id="S6.T4.18.8.8.15" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.15.1" class="ltx_text" style="font-size:90%;">22.8</span></td>
<td id="S6.T4.18.8.8.16" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.16.1" class="ltx_text" style="font-size:90%;">18.5</span></td>
<td id="S6.T4.18.8.8.17" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.8.8.17.1" class="ltx_text" style="font-size:90%;">22.9</span></td>
</tr>
<tr id="S6.T4.18.9.9" class="ltx_tr">
<th id="S6.T4.18.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.1.1" class="ltx_text" style="font-size:90%;">AdaFuse (Ours)</span></th>
<td id="S6.T4.18.9.9.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">17.8</span></td>
<td id="S6.T4.18.9.9.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">19.5</span></td>
<td id="S6.T4.18.9.9.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">17.6</span></td>
<td id="S6.T4.18.9.9.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.5.1" class="ltx_text" style="font-size:90%;">20.7</span></td>
<td id="S6.T4.18.9.9.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">19.3</span></td>
<td id="S6.T4.18.9.9.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">16.8</span></td>
<td id="S6.T4.18.9.9.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.8.1" class="ltx_text" style="font-size:90%;">18.9</span></td>
<td id="S6.T4.18.9.9.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">20.2</span></td>
<td id="S6.T4.18.9.9.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.10.1" class="ltx_text" style="font-size:90%;">25.7</span></td>
<td id="S6.T4.18.9.9.11" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.11.1" class="ltx_text ltx_font_bold" style="font-size:90%;">20.1</span></td>
<td id="S6.T4.18.9.9.12" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.12.1" class="ltx_text ltx_font_bold" style="font-size:90%;">19.2</span></td>
<td id="S6.T4.18.9.9.13" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.13.1" class="ltx_text" style="font-size:90%;">20.5</span></td>
<td id="S6.T4.18.9.9.14" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.14.1" class="ltx_text ltx_font_bold" style="font-size:90%;">17.2</span></td>
<td id="S6.T4.18.9.9.15" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.15.1" class="ltx_text ltx_font_bold" style="font-size:90%;">20.5</span></td>
<td id="S6.T4.18.9.9.16" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.16.1" class="ltx_text ltx_font_bold" style="font-size:90%;">17.3</span></td>
<td id="S6.T4.18.9.9.17" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:2.8pt;padding-right:2.8pt;"><span id="S6.T4.18.9.9.17.1" class="ltx_text ltx_font_bold" style="font-size:90%;">19.5</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Results on Panoptic</h3>

<figure id="S6.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>The <math id="S6.T5.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.T5.2.m1.1b"><mn id="S6.T5.2.m1.1.1" xref="S6.T5.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.T5.2.m1.1c"><cn type="integer" id="S6.T5.2.m1.1.1.cmml" xref="S6.T5.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.2.m1.1d">2</annotation></semantics></math>D pose estimation accuracy (PCKh@t) of the baselines and our approach for the <span id="S6.T5.10.1" class="ltx_text ltx_font_bold">occluded joints</span> on the <em id="S6.T5.11.2" class="ltx_emph ltx_font_italic">Occlusion-Person</em> dataset. We report results for each joint type individually, and also the average accuracy over all joint types.</figcaption>
<table id="S6.T5.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T5.12.1.1" class="ltx_tr">
<th id="S6.T5.12.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S6.T5.12.1.1.1.1" class="ltx_text" style="font-size:70%;">Methods</span></th>
<th id="S6.T5.12.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T5.12.1.1.2.1" class="ltx_text" style="font-size:70%;">Hip</span></th>
<th id="S6.T5.12.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T5.12.1.1.3.1" class="ltx_text" style="font-size:70%;">Knee</span></th>
<th id="S6.T5.12.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T5.12.1.1.4.1" class="ltx_text" style="font-size:70%;">Ankle</span></th>
<th id="S6.T5.12.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T5.12.1.1.5.1" class="ltx_text" style="font-size:70%;">Shlder</span></th>
<th id="S6.T5.12.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T5.12.1.1.6.1" class="ltx_text" style="font-size:70%;">Elbow</span></th>
<th id="S6.T5.12.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S6.T5.12.1.1.7.1" class="ltx_text" style="font-size:70%;">Wrist</span></th>
<th id="S6.T5.12.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S6.T5.12.1.1.8.1" class="ltx_text" style="font-size:70%;">Avg.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T5.12.2.1" class="ltx_tr">
<th id="S6.T5.12.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S6.T5.12.2.1.1.1" class="ltx_text" style="font-size:70%;">NoFuse</span></th>
<td id="S6.T5.12.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.12.2.1.2.1" class="ltx_text" style="font-size:70%;">63.4</span></td>
<td id="S6.T5.12.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.12.2.1.3.1" class="ltx_text" style="font-size:70%;">21.5</span></td>
<td id="S6.T5.12.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.12.2.1.4.1" class="ltx_text" style="font-size:70%;">17.0</span></td>
<td id="S6.T5.12.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.12.2.1.5.1" class="ltx_text" style="font-size:70%;">29.5</span></td>
<td id="S6.T5.12.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.12.2.1.6.1" class="ltx_text" style="font-size:70%;">14.6</span></td>
<td id="S6.T5.12.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T5.12.2.1.7.1" class="ltx_text" style="font-size:70%;">12.4</span></td>
<td id="S6.T5.12.2.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T5.12.2.1.8.1" class="ltx_text" style="font-size:70%;">30.9</span></td>
</tr>
<tr id="S6.T5.12.3.2" class="ltx_tr">
<th id="S6.T5.12.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S6.T5.12.3.2.1.1" class="ltx_text" style="font-size:70%;">HeuristicFuse</span></th>
<td id="S6.T5.12.3.2.2" class="ltx_td ltx_align_center"><span id="S6.T5.12.3.2.2.1" class="ltx_text" style="font-size:70%;">76.9</span></td>
<td id="S6.T5.12.3.2.3" class="ltx_td ltx_align_center"><span id="S6.T5.12.3.2.3.1" class="ltx_text" style="font-size:70%;">59.0</span></td>
<td id="S6.T5.12.3.2.4" class="ltx_td ltx_align_center"><span id="S6.T5.12.3.2.4.1" class="ltx_text" style="font-size:70%;">73.4</span></td>
<td id="S6.T5.12.3.2.5" class="ltx_td ltx_align_center"><span id="S6.T5.12.3.2.5.1" class="ltx_text" style="font-size:70%;">63.5</span></td>
<td id="S6.T5.12.3.2.6" class="ltx_td ltx_align_center"><span id="S6.T5.12.3.2.6.1" class="ltx_text" style="font-size:70%;">49.0</span></td>
<td id="S6.T5.12.3.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T5.12.3.2.7.1" class="ltx_text" style="font-size:70%;">54.8</span></td>
<td id="S6.T5.12.3.2.8" class="ltx_td ltx_align_center"><span id="S6.T5.12.3.2.8.1" class="ltx_text" style="font-size:70%;">65.0</span></td>
</tr>
<tr id="S6.T5.12.4.3" class="ltx_tr">
<th id="S6.T5.12.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S6.T5.12.4.3.1.1" class="ltx_text" style="font-size:70%;">ScoreFuse</span></th>
<td id="S6.T5.12.4.3.2" class="ltx_td ltx_align_center"><span id="S6.T5.12.4.3.2.1" class="ltx_text" style="font-size:70%;">90.9</span></td>
<td id="S6.T5.12.4.3.3" class="ltx_td ltx_align_center"><span id="S6.T5.12.4.3.3.1" class="ltx_text" style="font-size:70%;">88.6</span></td>
<td id="S6.T5.12.4.3.4" class="ltx_td ltx_align_center"><span id="S6.T5.12.4.3.4.1" class="ltx_text" style="font-size:70%;">88.1</span></td>
<td id="S6.T5.12.4.3.5" class="ltx_td ltx_align_center"><span id="S6.T5.12.4.3.5.1" class="ltx_text" style="font-size:70%;">86.0</span></td>
<td id="S6.T5.12.4.3.6" class="ltx_td ltx_align_center"><span id="S6.T5.12.4.3.6.1" class="ltx_text" style="font-size:70%;">93.2</span></td>
<td id="S6.T5.12.4.3.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T5.12.4.3.7.1" class="ltx_text" style="font-size:70%;">86.8</span></td>
<td id="S6.T5.12.4.3.8" class="ltx_td ltx_align_center"><span id="S6.T5.12.4.3.8.1" class="ltx_text" style="font-size:70%;">89.8</span></td>
</tr>
<tr id="S6.T5.12.5.4" class="ltx_tr">
<th id="S6.T5.12.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S6.T5.12.5.4.1.1" class="ltx_text" style="font-size:70%;">AdaFuse</span></th>
<td id="S6.T5.12.5.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T5.12.5.4.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">96.5</span></td>
<td id="S6.T5.12.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T5.12.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">96.0</span></td>
<td id="S6.T5.12.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T5.12.5.4.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.5</span></td>
<td id="S6.T5.12.5.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T5.12.5.4.5.1" class="ltx_text ltx_font_bold" style="font-size:70%;">94.1</span></td>
<td id="S6.T5.12.5.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T5.12.5.4.6.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.3</span></td>
<td id="S6.T5.12.5.4.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S6.T5.12.5.4.7.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.2</span></td>
<td id="S6.T5.12.5.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T5.12.5.4.8.1" class="ltx_text ltx_font_bold" style="font-size:70%;">95.5</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.2" class="ltx_p">We evaluate the impact of the number of cameras on this dataset. Figure <a href="#S6.F13" title="Figure 13 ‣ 3D Pose Estimation Results ‣ 6.3 Results on Occlusion-Person ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> shows the mean <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mn id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><cn type="integer" id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">3</annotation></semantics></math>D errors when three to six cameras are used, respectively. In general, the error decreases when more cameras are used for most baselines. However, we observe that the error of <em id="S6.SS2.p1.2.1" class="ltx_emph ltx_font_italic">NoFuse</em> actually becomes larger when the camera number increases from three to four. This undesirable phenomenon happens because the new camera view is very challenging thus the <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><mn id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><cn type="integer" id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">2</annotation></semantics></math>D pose estimation results are inaccurate. However, for our approach <em id="S6.SS2.p1.2.2" class="ltx_emph ltx_font_italic">AdaFuse</em>, the negative impact of low-quality heatmaps in individual views is limited due to the adaptive multiview fusion. We can see that the error of <em id="S6.SS2.p1.2.3" class="ltx_emph ltx_font_italic">AdaFuse</em> consistently decreases when the number of cameras increases. Since there is not a commonly adopted evaluation protocol and very few works have reported results on this new dataset, we do not compare our approach to the other approaches.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Results on Occlusion-Person</h3>

<section id="S6.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">
<math id="S6.SS3.SSS0.Px1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS3.SSS0.Px1.1.m1.1b"><mn id="S6.SS3.SSS0.Px1.1.m1.1.1" xref="S6.SS3.SSS0.Px1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px1.1.m1.1c"><cn type="integer" id="S6.SS3.SSS0.Px1.1.m1.1.1.cmml" xref="S6.SS3.SSS0.Px1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px1.1.m1.1d">2</annotation></semantics></math>D Pose Estimation Results</h4>

<div id="S6.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px1.p1.2" class="ltx_p">Table <a href="#S6.T5" title="Table 5 ‣ 6.2 Results on Panoptic ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the results on the <em id="S6.SS3.SSS0.Px1.p1.2.1" class="ltx_emph ltx_font_italic">occluded</em> joints. Only about <math id="S6.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="30.9\%" display="inline"><semantics id="S6.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S6.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="S6.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S6.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml">30.9</mn><mo id="S6.SS3.SSS0.Px1.p1.1.m1.1.1.1" xref="S6.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S6.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S6.SS3.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S6.SS3.SSS0.Px1.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S6.SS3.SSS0.Px1.p1.1.m1.1.1.2">30.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px1.p1.1.m1.1c">30.9\%</annotation></semantics></math> of the occluded joints can be accurately detected by <em id="S6.SS3.SSS0.Px1.p1.2.2" class="ltx_emph ltx_font_italic">NoFuse</em>. The result is reasonable because the features of the occluded joints are severely corrupted. All of the three multiview fusion methods remarkably improve the accuracy. In particular, more than <math id="S6.SS3.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S6.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S6.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mn id="S6.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S6.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">90</mn><mo id="S6.SS3.SSS0.Px1.p1.2.m2.1.1.1" xref="S6.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S6.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S6.SS3.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S6.SS3.SSS0.Px1.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S6.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S6.SS3.SSS0.Px1.p1.2.m2.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px1.p1.2.m2.1c">90\%</annotation></semantics></math> of the occluded joints are correctly detected by <em id="S6.SS3.SSS0.Px1.p1.2.3" class="ltx_emph ltx_font_italic">AdaFuse</em>. The results demonstrate the advantages of our strategy for learning the fusion weights.</p>
</div>
</section>
<section id="S6.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">
<math id="S6.SS3.SSS0.Px2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS3.SSS0.Px2.1.m1.1b"><mn id="S6.SS3.SSS0.Px2.1.m1.1.1" xref="S6.SS3.SSS0.Px2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px2.1.m1.1c"><cn type="integer" id="S6.SS3.SSS0.Px2.1.m1.1.1.cmml" xref="S6.SS3.SSS0.Px2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px2.1.m1.1d">3</annotation></semantics></math>D Pose Estimation Results</h4>

<div id="S6.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px2.p1.4" class="ltx_p">We show the 3D pose estimation error (<math id="S6.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S6.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="S6.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.1" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1"><times id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.1"></times><ci id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.2">𝑚</ci><ci id="S6.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S6.SS3.SSS0.Px2.p1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px2.p1.1.m1.1c">mm</annotation></semantics></math>) for each joint type in Table <a href="#S6.T6" title="Table 6 ‣ Impact of Number of Occluded Views ‣ 6.3 Results on Occlusion-Person ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. <em id="S6.SS3.SSS0.Px2.p1.4.1" class="ltx_emph ltx_font_italic">NoFuse</em> results in a large error of <math id="S6.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="48.1" display="inline"><semantics id="S6.SS3.SSS0.Px2.p1.2.m2.1a"><mn id="S6.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S6.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">48.1</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px2.p1.2.m2.1b"><cn type="float" id="S6.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S6.SS3.SSS0.Px2.p1.2.m2.1.1">48.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px2.p1.2.m2.1c">48.1</annotation></semantics></math>mm. By improving the 2D pose estimation results on the occluded joints, the 3D errors are also significantly reduced, especially for the joints on the limbs such as Ankles and Wrists. In particular, our approach decreases the <math id="S6.SS3.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS3.SSS0.Px2.p1.3.m3.1a"><mn id="S6.SS3.SSS0.Px2.p1.3.m3.1.1" xref="S6.SS3.SSS0.Px2.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px2.p1.3.m3.1b"><cn type="integer" id="S6.SS3.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S6.SS3.SSS0.Px2.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px2.p1.3.m3.1c">3</annotation></semantics></math>D error significantly to <math id="S6.SS3.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="12.6" display="inline"><semantics id="S6.SS3.SSS0.Px2.p1.4.m4.1a"><mn id="S6.SS3.SSS0.Px2.p1.4.m4.1.1" xref="S6.SS3.SSS0.Px2.p1.4.m4.1.1.cmml">12.6</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px2.p1.4.m4.1b"><cn type="float" id="S6.SS3.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S6.SS3.SSS0.Px2.p1.4.m4.1.1">12.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px2.p1.4.m4.1c">12.6</annotation></semantics></math>mm.</p>
</div>
<figure id="S6.F13" class="ltx_figure"><img src="/html/2010.13302/assets/x13.png" id="S6.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="278" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>The <math id="S6.F13.2.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.F13.2.m1.1b"><mn id="S6.F13.2.m1.1.1" xref="S6.F13.2.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.F13.2.m1.1c"><cn type="integer" id="S6.F13.2.m1.1.1.cmml" xref="S6.F13.2.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F13.2.m1.1d">3</annotation></semantics></math>D pose estimation errors on the Panoptic dataset when different numbers of cameras are used. </figcaption>
</figure>
</section>
<section id="S6.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Impact of Number of Occluded Views</h4>

<div id="S6.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px3.p1.2" class="ltx_p">We also evaluate the impact of the number of occluded views on this dataset. In particular, we classify each joint into one of five groups according to the number of occluded views, and report the average joint error for each group, respectively. The results are shown in Table <a href="#S6.T7" title="Table 7 ‣ Impact of Number of Occluded Views ‣ 6.3 Results on Occlusion-Person ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We can see that when the joints are visible in all views, the simple baseline <em id="S6.SS3.SSS0.Px3.p1.2.1" class="ltx_emph ltx_font_italic">NoFuse</em> also achieves a very small error of <math id="S6.SS3.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="13.0" display="inline"><semantics id="S6.SS3.SSS0.Px3.p1.1.m1.1a"><mn id="S6.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S6.SS3.SSS0.Px3.p1.1.m1.1.1.cmml">13.0</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px3.p1.1.m1.1b"><cn type="float" id="S6.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S6.SS3.SSS0.Px3.p1.1.m1.1.1">13.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px3.p1.1.m1.1c">13.0</annotation></semantics></math>mm. However, the error increases dramatically to <math id="S6.SS3.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="82.6" display="inline"><semantics id="S6.SS3.SSS0.Px3.p1.2.m2.1a"><mn id="S6.SS3.SSS0.Px3.p1.2.m2.1.1" xref="S6.SS3.SSS0.Px3.p1.2.m2.1.1.cmml">82.6</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px3.p1.2.m2.1b"><cn type="float" id="S6.SS3.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S6.SS3.SSS0.Px3.p1.2.m2.1.1">82.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px3.p1.2.m2.1c">82.6</annotation></semantics></math>mm when four views are occluded. Recall that there are eight views in total for this dataset. In contrast, the multiview fusion methods, especially our <em id="S6.SS3.SSS0.Px3.p1.2.2" class="ltx_emph ltx_font_italic">AdaFuse</em>, achieves consistently smaller errors than <em id="S6.SS3.SSS0.Px3.p1.2.3" class="ltx_emph ltx_font_italic">NoFuse</em>. More importantly, the error increase is much slower than <em id="S6.SS3.SSS0.Px3.p1.2.4" class="ltx_emph ltx_font_italic">NoFuse</em> when more camera views are occluded which validates the robustness of our approach to occlusion.</p>
</div>
<figure id="S6.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>The 3D pose estimation error (<span id="S6.T6.3.1" class="ltx_text ltx_font_italic">mm</span>) of the baselines and our approach on the <em id="S6.T6.4.2" class="ltx_emph ltx_font_italic">Occlusion-Person</em> dataset. We report the result on each joint individually and also the average over all joints. The second row shows the percentage of the joints that are occluded for each joint type.</figcaption>
<table id="S6.T6.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.5.1.1" class="ltx_tr">
<th id="S6.T6.5.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S6.T6.5.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Root</th>
<th id="S6.T6.5.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Belly</th>
<th id="S6.T6.5.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Neck</th>
<th id="S6.T6.5.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Hip</th>
<th id="S6.T6.5.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Knee</th>
<th id="S6.T6.5.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Ankle</th>
<th id="S6.T6.5.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Shlder</th>
<th id="S6.T6.5.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Elbow</th>
<th id="S6.T6.5.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Wrist</th>
<th id="S6.T6.5.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean</th>
</tr>
<tr id="S6.T6.5.2.2" class="ltx_tr">
<th id="S6.T6.5.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r">Occluded (%)</th>
<th id="S6.T6.5.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">14.3%</th>
<th id="S6.T6.5.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">13.7%</th>
<th id="S6.T6.5.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">7.6%</th>
<th id="S6.T6.5.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">23.0%</th>
<th id="S6.T6.5.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">25.0%</th>
<th id="S6.T6.5.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">23.5%</th>
<th id="S6.T6.5.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column">16.8%</th>
<th id="S6.T6.5.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column">25.3%</th>
<th id="S6.T6.5.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">21.7%</th>
<th id="S6.T6.5.2.2.11" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.5.3.1" class="ltx_tr">
<th id="S6.T6.5.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">NoFuse</th>
<td id="S6.T6.5.3.1.2" class="ltx_td ltx_align_center ltx_border_t">10.0</td>
<td id="S6.T6.5.3.1.3" class="ltx_td ltx_align_center ltx_border_t">12.2</td>
<td id="S6.T6.5.3.1.4" class="ltx_td ltx_align_center ltx_border_t">12.5</td>
<td id="S6.T6.5.3.1.5" class="ltx_td ltx_align_center ltx_border_t">16.8</td>
<td id="S6.T6.5.3.1.6" class="ltx_td ltx_align_center ltx_border_t">61.1</td>
<td id="S6.T6.5.3.1.7" class="ltx_td ltx_align_center ltx_border_t">113.9</td>
<td id="S6.T6.5.3.1.8" class="ltx_td ltx_align_center ltx_border_t">28.0</td>
<td id="S6.T6.5.3.1.9" class="ltx_td ltx_align_center ltx_border_t">63.7</td>
<td id="S6.T6.5.3.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.3</td>
<td id="S6.T6.5.3.1.11" class="ltx_td ltx_align_center ltx_border_t">48.1</td>
</tr>
<tr id="S6.T6.5.4.2" class="ltx_tr">
<th id="S6.T6.5.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HeuristicFuse</th>
<td id="S6.T6.5.4.2.2" class="ltx_td ltx_align_center">8.8</td>
<td id="S6.T6.5.4.2.3" class="ltx_td ltx_align_center">10.7</td>
<td id="S6.T6.5.4.2.4" class="ltx_td ltx_align_center"><span id="S6.T6.5.4.2.4.1" class="ltx_text ltx_font_bold">11.5</span></td>
<td id="S6.T6.5.4.2.5" class="ltx_td ltx_align_center">14.2</td>
<td id="S6.T6.5.4.2.6" class="ltx_td ltx_align_center">21.1</td>
<td id="S6.T6.5.4.2.7" class="ltx_td ltx_align_center">19.2</td>
<td id="S6.T6.5.4.2.8" class="ltx_td ltx_align_center">17.5</td>
<td id="S6.T6.5.4.2.9" class="ltx_td ltx_align_center">23.6</td>
<td id="S6.T6.5.4.2.10" class="ltx_td ltx_align_center ltx_border_r">24.1</td>
<td id="S6.T6.5.4.2.11" class="ltx_td ltx_align_center">18.0</td>
</tr>
<tr id="S6.T6.5.5.3" class="ltx_tr">
<th id="S6.T6.5.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ScoreFuse</th>
<td id="S6.T6.5.5.3.2" class="ltx_td ltx_align_center">8.4</td>
<td id="S6.T6.5.5.3.3" class="ltx_td ltx_align_center">12.6</td>
<td id="S6.T6.5.5.3.4" class="ltx_td ltx_align_center">12.6</td>
<td id="S6.T6.5.5.3.5" class="ltx_td ltx_align_center">14.7</td>
<td id="S6.T6.5.5.3.6" class="ltx_td ltx_align_center">17.5</td>
<td id="S6.T6.5.5.3.7" class="ltx_td ltx_align_center">17.1</td>
<td id="S6.T6.5.5.3.8" class="ltx_td ltx_align_center">16.1</td>
<td id="S6.T6.5.5.3.9" class="ltx_td ltx_align_center">13.2</td>
<td id="S6.T6.5.5.3.10" class="ltx_td ltx_align_center ltx_border_r">16.9</td>
<td id="S6.T6.5.5.3.11" class="ltx_td ltx_align_center">15.0</td>
</tr>
<tr id="S6.T6.5.6.4" class="ltx_tr">
<th id="S6.T6.5.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RANSAC</th>
<td id="S6.T6.5.6.4.2" class="ltx_td ltx_align_center">8.6</td>
<td id="S6.T6.5.6.4.3" class="ltx_td ltx_align_center">11.2</td>
<td id="S6.T6.5.6.4.4" class="ltx_td ltx_align_center">11.7</td>
<td id="S6.T6.5.6.4.5" class="ltx_td ltx_align_center">12.9</td>
<td id="S6.T6.5.6.4.6" class="ltx_td ltx_align_center">18.8</td>
<td id="S6.T6.5.6.4.7" class="ltx_td ltx_align_center">17.9</td>
<td id="S6.T6.5.6.4.8" class="ltx_td ltx_align_center">17.1</td>
<td id="S6.T6.5.6.4.9" class="ltx_td ltx_align_center">14.5</td>
<td id="S6.T6.5.6.4.10" class="ltx_td ltx_align_center ltx_border_r">19.7</td>
<td id="S6.T6.5.6.4.11" class="ltx_td ltx_align_center">15.5</td>
</tr>
<tr id="S6.T6.5.7.5" class="ltx_tr">
<th id="S6.T6.5.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">AdaFuse (Ours)</th>
<td id="S6.T6.5.7.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.2.1" class="ltx_text ltx_font_bold">7.2</span></td>
<td id="S6.T6.5.7.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.3.1" class="ltx_text ltx_font_bold">10.6</span></td>
<td id="S6.T6.5.7.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.4.1" class="ltx_text ltx_font_bold">11.6</span></td>
<td id="S6.T6.5.7.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.5.1" class="ltx_text ltx_font_bold">11.7</span></td>
<td id="S6.T6.5.7.5.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.6.1" class="ltx_text ltx_font_bold">13.8</span></td>
<td id="S6.T6.5.7.5.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.7.1" class="ltx_text ltx_font_bold">15.7</span></td>
<td id="S6.T6.5.7.5.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.8.1" class="ltx_text ltx_font_bold">14.2</span></td>
<td id="S6.T6.5.7.5.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.9.1" class="ltx_text ltx_font_bold">9.9</span></td>
<td id="S6.T6.5.7.5.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S6.T6.5.7.5.10.1" class="ltx_text ltx_font_bold">14.4</span></td>
<td id="S6.T6.5.7.5.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T6.5.7.5.11.1" class="ltx_text ltx_font_bold">12.6</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S6.F14" class="ltx_figure"><img src="/html/2010.13302/assets/x14.png" id="S6.F14.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="201" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>We demonstrate some <math id="S6.F14.2.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.F14.2.m1.1b"><mn id="S6.F14.2.m1.1.1" xref="S6.F14.2.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.F14.2.m1.1c"><cn type="integer" id="S6.F14.2.m1.1.1.cmml" xref="S6.F14.2.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F14.2.m1.1d">3</annotation></semantics></math>D pose estimation examples obtained by <em id="S6.F14.4.1" class="ltx_emph ltx_font_italic">AdaFuse</em>. The last row shows some failure cases. </figcaption>
</figure>
<figure id="S6.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>The 3D pose estimation error (<math id="S6.T7.2.m1.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S6.T7.2.m1.1b"><mrow id="S6.T7.2.m1.1.1" xref="S6.T7.2.m1.1.1.cmml"><mi id="S6.T7.2.m1.1.1.2" xref="S6.T7.2.m1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.T7.2.m1.1.1.1" xref="S6.T7.2.m1.1.1.1.cmml">​</mo><mi id="S6.T7.2.m1.1.1.3" xref="S6.T7.2.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.T7.2.m1.1c"><apply id="S6.T7.2.m1.1.1.cmml" xref="S6.T7.2.m1.1.1"><times id="S6.T7.2.m1.1.1.1.cmml" xref="S6.T7.2.m1.1.1.1"></times><ci id="S6.T7.2.m1.1.1.2.cmml" xref="S6.T7.2.m1.1.1.2">𝑚</ci><ci id="S6.T7.2.m1.1.1.3.cmml" xref="S6.T7.2.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T7.2.m1.1d">mm</annotation></semantics></math>) of the baseline methods and our approach on the Occlusion-Person dataset. We group the the 3D joints by number of occluded views (8 views in all). We show each group’s joint number percentage in the second row.</figcaption>
<table id="S6.T7.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T7.3.1.1" class="ltx_tr">
<th id="S6.T7.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Occluded Views</th>
<th id="S6.T7.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">4</th>
<th id="S6.T7.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">3</th>
<th id="S6.T7.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">2</th>
<th id="S6.T7.3.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">1</th>
<th id="S6.T7.3.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">0</th>
</tr>
<tr id="S6.T7.3.2.2" class="ltx_tr">
<th id="S6.T7.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r">Percentage</th>
<th id="S6.T7.3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">2%</th>
<th id="S6.T7.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">15%</th>
<th id="S6.T7.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">38%</th>
<th id="S6.T7.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">35%</th>
<th id="S6.T7.3.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">10%</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T7.3.3.1" class="ltx_tr">
<th id="S6.T7.3.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">NoFuse</th>
<td id="S6.T7.3.3.1.2" class="ltx_td ltx_align_center ltx_border_t">82.6</td>
<td id="S6.T7.3.3.1.3" class="ltx_td ltx_align_center ltx_border_t">70.2</td>
<td id="S6.T7.3.3.1.4" class="ltx_td ltx_align_center ltx_border_t">59.7</td>
<td id="S6.T7.3.3.1.5" class="ltx_td ltx_align_center ltx_border_t">33.7</td>
<td id="S6.T7.3.3.1.6" class="ltx_td ltx_align_center ltx_border_t">13.0</td>
</tr>
<tr id="S6.T7.3.4.2" class="ltx_tr">
<th id="S6.T7.3.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">HeuristicFuse</th>
<td id="S6.T7.3.4.2.2" class="ltx_td ltx_align_center">30.5</td>
<td id="S6.T7.3.4.2.3" class="ltx_td ltx_align_center">19.9</td>
<td id="S6.T7.3.4.2.4" class="ltx_td ltx_align_center">15.9</td>
<td id="S6.T7.3.4.2.5" class="ltx_td ltx_align_center">13.5</td>
<td id="S6.T7.3.4.2.6" class="ltx_td ltx_align_center">11.1</td>
</tr>
<tr id="S6.T7.3.5.3" class="ltx_tr">
<th id="S6.T7.3.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ScoreFuse</th>
<td id="S6.T7.3.5.3.2" class="ltx_td ltx_align_center">25.0</td>
<td id="S6.T7.3.5.3.3" class="ltx_td ltx_align_center">18.1</td>
<td id="S6.T7.3.5.3.4" class="ltx_td ltx_align_center">15.2</td>
<td id="S6.T7.3.5.3.5" class="ltx_td ltx_align_center">13.4</td>
<td id="S6.T7.3.5.3.6" class="ltx_td ltx_align_center">12.6</td>
</tr>
<tr id="S6.T7.3.6.4" class="ltx_tr">
<th id="S6.T7.3.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RANSAC</th>
<td id="S6.T7.3.6.4.2" class="ltx_td ltx_align_center">36.5</td>
<td id="S6.T7.3.6.4.3" class="ltx_td ltx_align_center">24.5</td>
<td id="S6.T7.3.6.4.4" class="ltx_td ltx_align_center">19.4</td>
<td id="S6.T7.3.6.4.5" class="ltx_td ltx_align_center">14.3</td>
<td id="S6.T7.3.6.4.6" class="ltx_td ltx_align_center">11.7</td>
</tr>
<tr id="S6.T7.3.7.5" class="ltx_tr">
<th id="S6.T7.3.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">AdaFuse (Ours)</th>
<td id="S6.T7.3.7.5.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T7.3.7.5.2.1" class="ltx_text ltx_font_bold">21.7</span></td>
<td id="S6.T7.3.7.5.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T7.3.7.5.3.1" class="ltx_text ltx_font_bold">14.8</span></td>
<td id="S6.T7.3.7.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T7.3.7.5.4.1" class="ltx_text ltx_font_bold">12.5</span></td>
<td id="S6.T7.3.7.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T7.3.7.5.5.1" class="ltx_text ltx_font_bold">11.5</span></td>
<td id="S6.T7.3.7.5.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T7.3.7.5.6.1" class="ltx_text ltx_font_bold">10.8</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S6.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span> The <math id="S6.T8.4.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.T8.4.m1.1b"><mn id="S6.T8.4.m1.1.1" xref="S6.T8.4.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.T8.4.m1.1c"><cn type="integer" id="S6.T8.4.m1.1.1.cmml" xref="S6.T8.4.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T8.4.m1.1d">3</annotation></semantics></math>D pose estimation errors MPJPE (<math id="S6.T8.5.m2.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S6.T8.5.m2.1b"><mrow id="S6.T8.5.m2.1.1" xref="S6.T8.5.m2.1.1.cmml"><mi id="S6.T8.5.m2.1.1.2" xref="S6.T8.5.m2.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.T8.5.m2.1.1.1" xref="S6.T8.5.m2.1.1.1.cmml">​</mo><mi id="S6.T8.5.m2.1.1.3" xref="S6.T8.5.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.T8.5.m2.1c"><apply id="S6.T8.5.m2.1.1.cmml" xref="S6.T8.5.m2.1.1"><times id="S6.T8.5.m2.1.1.1.cmml" xref="S6.T8.5.m2.1.1.1"></times><ci id="S6.T8.5.m2.1.1.2.cmml" xref="S6.T8.5.m2.1.1.2">𝑚</ci><ci id="S6.T8.5.m2.1.1.3.cmml" xref="S6.T8.5.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T8.5.m2.1d">mm</annotation></semantics></math>) when <em id="S6.T8.9.1" class="ltx_emph ltx_font_italic">AdaFuse</em> weight prediction network is trained on <em id="S6.T8.10.2" class="ltx_emph ltx_font_italic">Occlusion-Person</em> or directly trained on the Evaluation dataset, respectively. The <math id="S6.T8.6.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.T8.6.m3.1b"><mn id="S6.T8.6.m3.1.1" xref="S6.T8.6.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.T8.6.m3.1c"><cn type="integer" id="S6.T8.6.m3.1.1.cmml" xref="S6.T8.6.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T8.6.m3.1d">2</annotation></semantics></math>D pose estimators for generating the initial heatmaps are trained on each Evaluation dataset separately.</figcaption>
<table id="S6.T8.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T8.11.1.1" class="ltx_tr">
<th id="S6.T8.11.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Evaluation Dataset</th>
<th id="S6.T8.11.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2">AdaFuse</th>
<th id="S6.T8.11.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">NoFuse</th>
<th id="S6.T8.11.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">HeuristicFuse</th>
<th id="S6.T8.11.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">ScoreFuse</th>
<th id="S6.T8.11.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RANSAC</th>
</tr>
<tr id="S6.T8.11.2.2" class="ltx_tr">
<th id="S6.T8.11.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S6.T8.11.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="2">Trained on</th>
<th id="S6.T8.11.2.2.3" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T8.11.2.2.4" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T8.11.2.2.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T8.11.2.2.6" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
<tr id="S6.T8.11.3.3" class="ltx_tr">
<th id="S6.T8.11.3.3.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S6.T8.11.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_column">Evaluation Dataset</th>
<th id="S6.T8.11.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Occlusion-Person</th>
<th id="S6.T8.11.3.3.4" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T8.11.3.3.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T8.11.3.3.6" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S6.T8.11.3.3.7" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T8.11.4.1" class="ltx_tr">
<th id="S6.T8.11.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Human3.6M</th>
<td id="S6.T8.11.4.1.2" class="ltx_td ltx_align_center ltx_border_t">19.5</td>
<td id="S6.T8.11.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">19.4</td>
<td id="S6.T8.11.4.1.4" class="ltx_td ltx_align_center ltx_border_t">22.9</td>
<td id="S6.T8.11.4.1.5" class="ltx_td ltx_align_center ltx_border_t">21.0</td>
<td id="S6.T8.11.4.1.6" class="ltx_td ltx_align_center ltx_border_t">20.1</td>
<td id="S6.T8.11.4.1.7" class="ltx_td ltx_align_center ltx_border_t">21.8</td>
</tr>
<tr id="S6.T8.11.5.2" class="ltx_tr">
<th id="S6.T8.11.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Panoptic 4 views</th>
<td id="S6.T8.11.5.2.2" class="ltx_td ltx_align_center">14.7</td>
<td id="S6.T8.11.5.2.3" class="ltx_td ltx_align_center ltx_border_r">14.6</td>
<td id="S6.T8.11.5.2.4" class="ltx_td ltx_align_center">33.2</td>
<td id="S6.T8.11.5.2.5" class="ltx_td ltx_align_center">22.5</td>
<td id="S6.T8.11.5.2.6" class="ltx_td ltx_align_center">21.9</td>
<td id="S6.T8.11.5.2.7" class="ltx_td ltx_align_center">16.9</td>
</tr>
<tr id="S6.T8.11.6.3" class="ltx_tr">
<th id="S6.T8.11.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Panoptic 6 views</th>
<td id="S6.T8.11.6.3.2" class="ltx_td ltx_align_center">13.6</td>
<td id="S6.T8.11.6.3.3" class="ltx_td ltx_align_center ltx_border_r">13.9</td>
<td id="S6.T8.11.6.3.4" class="ltx_td ltx_align_center">29.6</td>
<td id="S6.T8.11.6.3.5" class="ltx_td ltx_align_center">19.8</td>
<td id="S6.T8.11.6.3.6" class="ltx_td ltx_align_center">19.4</td>
<td id="S6.T8.11.6.3.7" class="ltx_td ltx_align_center">15.5</td>
</tr>
<tr id="S6.T8.11.7.4" class="ltx_tr">
<th id="S6.T8.11.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Total Capture</th>
<td id="S6.T8.11.7.4.2" class="ltx_td ltx_align_center ltx_border_bb">19.2</td>
<td id="S6.T8.11.7.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">20.1</td>
<td id="S6.T8.11.7.4.4" class="ltx_td ltx_align_center ltx_border_bb">29.4</td>
<td id="S6.T8.11.7.4.5" class="ltx_td ltx_align_center ltx_border_bb">20.0</td>
<td id="S6.T8.11.7.4.6" class="ltx_td ltx_align_center ltx_border_bb">20.5</td>
<td id="S6.T8.11.7.4.7" class="ltx_td ltx_align_center ltx_border_bb">20.5</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Generalization Power</h4>

<div id="S6.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS3.SSS0.Px4.p1.2" class="ltx_p">The only learnable parameters in our fusion approach are in the appearance embedding and geometry embedding networks. In this section, we evaluate whether the <em id="S6.SS3.SSS0.Px4.p1.2.1" class="ltx_emph ltx_font_italic">AdaFuse</em> weight prediction network learned on <em id="S6.SS3.SSS0.Px4.p1.2.2" class="ltx_emph ltx_font_italic">Occlusion-Person</em> can be directly applied to the other datasets. In particular, we append the <em id="S6.SS3.SSS0.Px4.p1.2.3" class="ltx_emph ltx_font_italic">AdaFuse</em> weight prediction network learned on <em id="S6.SS3.SSS0.Px4.p1.2.4" class="ltx_emph ltx_font_italic">Occlusion-Person</em> to the <math id="S6.SS3.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS3.SSS0.Px4.p1.1.m1.1a"><mn id="S6.SS3.SSS0.Px4.p1.1.m1.1.1" xref="S6.SS3.SSS0.Px4.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px4.p1.1.m1.1b"><cn type="integer" id="S6.SS3.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S6.SS3.SSS0.Px4.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px4.p1.1.m1.1c">2</annotation></semantics></math>D pose estimators trained on each dataset itself as the final model for evaluation. Table <a href="#S6.T8" title="Table 8 ‣ Impact of Number of Occluded Views ‣ 6.3 Results on Occlusion-Person ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the <math id="S6.SS3.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS3.SSS0.Px4.p1.2.m2.1a"><mn id="S6.SS3.SSS0.Px4.p1.2.m2.1.1" xref="S6.SS3.SSS0.Px4.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.SSS0.Px4.p1.2.m2.1b"><cn type="integer" id="S6.SS3.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S6.SS3.SSS0.Px4.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.SSS0.Px4.p1.2.m2.1c">3</annotation></semantics></math>D pose estimation results on various datasets. We find that the fusion network learned on the synthetic <em id="S6.SS3.SSS0.Px4.p1.2.5" class="ltx_emph ltx_font_italic">Occlusion-Person</em> dataset achieves
similar performance on the three realistic datasets compared to the networks learned on each of the target dataset, respectively. The promising results validate that the fusion model has strong generalization power. It is also worth noting that our approach can naturally handle different numbers of cameras for two reasons. First, the parameters in the appearance embedding network and the geometry embedding network are shared for all camera views. Second, the “Mean” operator in the geometry embedding network makes it independent of the number of views as shown in Figure <a href="#S4.F7" title="Figure 7 ‣ 4.1 The Appearance Embedding ‣ 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Figure <a href="#S4.F8" title="Figure 8 ‣ 4.1 The Appearance Embedding ‣ 4 Adaptive Weight for Multiview Fusion ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. In summary, <em id="S6.SS3.SSS0.Px4.p1.2.6" class="ltx_emph ltx_font_italic">AdaFuse</em> is ready to be deployed in new environments of different camera poses without additional adaptation.</p>
</div>
</section>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Results on Total Capture</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">We report the <math id="S6.SS4.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS4.p1.1.m1.1a"><mn id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><cn type="integer" id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">3</annotation></semantics></math>D pose estimation results on the Total Capture dataset in Table <a href="#S6.T9" title="Table 9 ‣ 6.4 Results on Total Capture ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. It is worth noting that some methods also use IMUs in addition to the multiview images. We can see that our approach outperforms all of the previous methods. We notice that the error of our approach is slightly larger than LSTM-AE <cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib56" title="" class="ltx_ref">2018</a>)</cite> for the “W2 (walking)” action of S4,5. We tend to think it is because LSTM can get significant benefits when it is applied to periodic actions such as “walking”. This is also observed independently in another work <cite class="ltx_cite ltx_citemacro_citep">(Gilbert et al., <a href="#bib.bib18" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.4" class="ltx_p">We show some <math id="S6.SS4.p2.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS4.p2.1.m1.1a"><mn id="S6.SS4.p2.1.m1.1.1" xref="S6.SS4.p2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.1.m1.1b"><cn type="integer" id="S6.SS4.p2.1.m1.1.1.cmml" xref="S6.SS4.p2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.1.m1.1c">3</annotation></semantics></math>D pose estimation examples in Figure <a href="#S6.F14" title="Figure 14 ‣ Impact of Number of Occluded Views ‣ 6.3 Results on Occlusion-Person ‣ 6 Experimental Results ‣ AdaFuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>. In most cases, our approach can accurately estimate the <math id="S6.SS4.p2.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS4.p2.2.m2.1a"><mn id="S6.SS4.p2.2.m2.1.1" xref="S6.SS4.p2.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.2.m2.1b"><cn type="integer" id="S6.SS4.p2.2.m2.1.1.cmml" xref="S6.SS4.p2.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.2.m2.1c">3</annotation></semantics></math>D poses. One typical situation where the approach fails is when <math id="S6.SS4.p2.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS4.p2.3.m3.1a"><mn id="S6.SS4.p2.3.m3.1.1" xref="S6.SS4.p2.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.3.m3.1b"><cn type="integer" id="S6.SS4.p2.3.m3.1.1.cmml" xref="S6.SS4.p2.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.3.m3.1c">2</annotation></semantics></math>D pose estimation results are inaccurate for many camera views. For example in the Panoptic dataset, when human begin to enter the dome, they may be occluded in multiple views. In this case, the heatmaps in each view are of low-quality. Therefore the fused heatmaps will also have degraded quality, leading to inaccurate <math id="S6.SS4.p2.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS4.p2.4.m4.1a"><mn id="S6.SS4.p2.4.m4.1.1" xref="S6.SS4.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p2.4.m4.1b"><cn type="integer" id="S6.SS4.p2.4.m4.1.1.cmml" xref="S6.SS4.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p2.4.m4.1c">2</annotation></semantics></math>D pose estimations.</p>
</div>
<figure id="S6.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>The <math id="S6.T9.3.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.T9.3.m1.1b"><mn id="S6.T9.3.m1.1.1" xref="S6.T9.3.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.T9.3.m1.1c"><cn type="integer" id="S6.T9.3.m1.1.1.cmml" xref="S6.T9.3.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T9.3.m1.1d">3</annotation></semantics></math>D pose estimation errors MPJPE (<math id="S6.T9.4.m2.1" class="ltx_Math" alttext="mm" display="inline"><semantics id="S6.T9.4.m2.1b"><mrow id="S6.T9.4.m2.1.1" xref="S6.T9.4.m2.1.1.cmml"><mi id="S6.T9.4.m2.1.1.2" xref="S6.T9.4.m2.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S6.T9.4.m2.1.1.1" xref="S6.T9.4.m2.1.1.1.cmml">​</mo><mi id="S6.T9.4.m2.1.1.3" xref="S6.T9.4.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S6.T9.4.m2.1c"><apply id="S6.T9.4.m2.1.1.cmml" xref="S6.T9.4.m2.1.1"><times id="S6.T9.4.m2.1.1.1.cmml" xref="S6.T9.4.m2.1.1.1"></times><ci id="S6.T9.4.m2.1.1.2.cmml" xref="S6.T9.4.m2.1.1.2">𝑚</ci><ci id="S6.T9.4.m2.1.1.3.cmml" xref="S6.T9.4.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T9.4.m2.1d">mm</annotation></semantics></math>) of different methods on the Total Capture dataset.</figcaption>
<table id="S6.T9.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T9.5.1.1" class="ltx_tr">
<td id="S6.T9.5.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Methods</td>
<td id="S6.T9.5.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">IMUs</td>
<td id="S6.T9.5.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Temporal</td>
<td id="S6.T9.5.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Subjects(S1,2,3)</td>
<td id="S6.T9.5.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Subjects(S4,5)</td>
<td id="S6.T9.5.1.1.6" class="ltx_td ltx_align_center ltx_border_tt">Mean</td>
</tr>
<tr id="S6.T9.5.2.2" class="ltx_tr">
<td id="S6.T9.5.2.2.1" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.2.2.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.2.2.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.2.2.4" class="ltx_td ltx_align_center">W2</td>
<td id="S6.T9.5.2.2.5" class="ltx_td ltx_align_center">A3</td>
<td id="S6.T9.5.2.2.6" class="ltx_td ltx_align_center">FS3</td>
<td id="S6.T9.5.2.2.7" class="ltx_td ltx_align_center">W2</td>
<td id="S6.T9.5.2.2.8" class="ltx_td ltx_align_center">A3</td>
<td id="S6.T9.5.2.2.9" class="ltx_td ltx_align_center">FS3</td>
<td id="S6.T9.5.2.2.10" class="ltx_td"></td>
</tr>
<tr id="S6.T9.5.3.3" class="ltx_tr">
<td id="S6.T9.5.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib55" title="" class="ltx_ref">2017</a>)</cite></td>
<td id="S6.T9.5.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S6.T9.5.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="S6.T9.5.3.3.4" class="ltx_td ltx_align_center ltx_border_t">48.3</td>
<td id="S6.T9.5.3.3.5" class="ltx_td ltx_align_center ltx_border_t">94.3</td>
<td id="S6.T9.5.3.3.6" class="ltx_td ltx_align_center ltx_border_t">122.3</td>
<td id="S6.T9.5.3.3.7" class="ltx_td ltx_align_center ltx_border_t">84.3</td>
<td id="S6.T9.5.3.3.8" class="ltx_td ltx_align_center ltx_border_t">154.5</td>
<td id="S6.T9.5.3.3.9" class="ltx_td ltx_align_center ltx_border_t">168.5</td>
<td id="S6.T9.5.3.3.10" class="ltx_td ltx_align_center ltx_border_t">107.3</td>
</tr>
<tr id="S6.T9.5.4.4" class="ltx_tr">
<td id="S6.T9.5.4.4.1" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a href="#bib.bib59" title="" class="ltx_ref">2016</a>)</cite></td>
<td id="S6.T9.5.4.4.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.4.4.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.4.4.4" class="ltx_td ltx_align_center">79.0</td>
<td id="S6.T9.5.4.4.5" class="ltx_td ltx_align_center">106.5</td>
<td id="S6.T9.5.4.4.6" class="ltx_td ltx_align_center">112.1</td>
<td id="S6.T9.5.4.4.7" class="ltx_td ltx_align_center">79.0</td>
<td id="S6.T9.5.4.4.8" class="ltx_td ltx_align_center">73.7</td>
<td id="S6.T9.5.4.4.9" class="ltx_td ltx_align_center">149.3</td>
<td id="S6.T9.5.4.4.10" class="ltx_td ltx_align_center">99.8</td>
</tr>
<tr id="S6.T9.5.5.5" class="ltx_tr">
<td id="S6.T9.5.5.5.1" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Gilbert et al., <a href="#bib.bib18" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="S6.T9.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S6.T9.5.5.5.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.5.5.4" class="ltx_td ltx_align_center">19.2</td>
<td id="S6.T9.5.5.5.5" class="ltx_td ltx_align_center">42.3</td>
<td id="S6.T9.5.5.5.6" class="ltx_td ltx_align_center">48.8</td>
<td id="S6.T9.5.5.5.7" class="ltx_td ltx_align_center">24.7</td>
<td id="S6.T9.5.5.5.8" class="ltx_td ltx_align_center">58.8</td>
<td id="S6.T9.5.5.5.9" class="ltx_td ltx_align_center">61.8</td>
<td id="S6.T9.5.5.5.10" class="ltx_td ltx_align_center">42.6</td>
</tr>
<tr id="S6.T9.5.6.6" class="ltx_tr">
<td id="S6.T9.5.6.6.1" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Trumble et al., <a href="#bib.bib56" title="" class="ltx_ref">2018</a>)</cite></td>
<td id="S6.T9.5.6.6.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.6.6.3" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S6.T9.5.6.6.4" class="ltx_td ltx_align_center">13.0</td>
<td id="S6.T9.5.6.6.5" class="ltx_td ltx_align_center">23.0</td>
<td id="S6.T9.5.6.6.6" class="ltx_td ltx_align_center">47.0</td>
<td id="S6.T9.5.6.6.7" class="ltx_td ltx_align_center"><span id="S6.T9.5.6.6.7.1" class="ltx_text ltx_font_bold">21.8</span></td>
<td id="S6.T9.5.6.6.8" class="ltx_td ltx_align_center">40.9</td>
<td id="S6.T9.5.6.6.9" class="ltx_td ltx_align_center">68.5</td>
<td id="S6.T9.5.6.6.10" class="ltx_td ltx_align_center">34.1</td>
</tr>
<tr id="S6.T9.5.7.7" class="ltx_tr">
<td id="S6.T9.5.7.7.1" class="ltx_td ltx_align_left ltx_border_r"><cite class="ltx_cite ltx_citemacro_citep">(Qiu et al., <a href="#bib.bib45" title="" class="ltx_ref">2019</a>)</cite></td>
<td id="S6.T9.5.7.7.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.7.7.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.7.7.4" class="ltx_td ltx_align_center">19</td>
<td id="S6.T9.5.7.7.5" class="ltx_td ltx_align_center">21</td>
<td id="S6.T9.5.7.7.6" class="ltx_td ltx_align_center">28</td>
<td id="S6.T9.5.7.7.7" class="ltx_td ltx_align_center">32</td>
<td id="S6.T9.5.7.7.8" class="ltx_td ltx_align_center">33</td>
<td id="S6.T9.5.7.7.9" class="ltx_td ltx_align_center">54</td>
<td id="S6.T9.5.7.7.10" class="ltx_td ltx_align_center">29</td>
</tr>
<tr id="S6.T9.5.8.8" class="ltx_tr">
<td id="S6.T9.5.8.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NoFuse</td>
<td id="S6.T9.5.8.8.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T9.5.8.8.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T9.5.8.8.4" class="ltx_td ltx_align_center ltx_border_t">15.9</td>
<td id="S6.T9.5.8.8.5" class="ltx_td ltx_align_center ltx_border_t">18.5</td>
<td id="S6.T9.5.8.8.6" class="ltx_td ltx_align_center ltx_border_t">29.9</td>
<td id="S6.T9.5.8.8.7" class="ltx_td ltx_align_center ltx_border_t">33.9</td>
<td id="S6.T9.5.8.8.8" class="ltx_td ltx_align_center ltx_border_t">33.8</td>
<td id="S6.T9.5.8.8.9" class="ltx_td ltx_align_center ltx_border_t">60.0</td>
<td id="S6.T9.5.8.8.10" class="ltx_td ltx_align_center ltx_border_t">29.4</td>
</tr>
<tr id="S6.T9.5.9.9" class="ltx_tr">
<td id="S6.T9.5.9.9.1" class="ltx_td ltx_align_left ltx_border_r">HeuristicFuse</td>
<td id="S6.T9.5.9.9.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.9.9.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.9.9.4" class="ltx_td ltx_align_center">7.8</td>
<td id="S6.T9.5.9.9.5" class="ltx_td ltx_align_center">11.6</td>
<td id="S6.T9.5.9.9.6" class="ltx_td ltx_align_center">19.6</td>
<td id="S6.T9.5.9.9.7" class="ltx_td ltx_align_center">23.3</td>
<td id="S6.T9.5.9.9.8" class="ltx_td ltx_align_center">26.9</td>
<td id="S6.T9.5.9.9.9" class="ltx_td ltx_align_center">44.8</td>
<td id="S6.T9.5.9.9.10" class="ltx_td ltx_align_center">20.0</td>
</tr>
<tr id="S6.T9.5.10.10" class="ltx_tr">
<td id="S6.T9.5.10.10.1" class="ltx_td ltx_align_left ltx_border_r">ScoreFuse</td>
<td id="S6.T9.5.10.10.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.10.10.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.10.10.4" class="ltx_td ltx_align_center">9.7</td>
<td id="S6.T9.5.10.10.5" class="ltx_td ltx_align_center">13.1</td>
<td id="S6.T9.5.10.10.6" class="ltx_td ltx_align_center">19.9</td>
<td id="S6.T9.5.10.10.7" class="ltx_td ltx_align_center">23.9</td>
<td id="S6.T9.5.10.10.8" class="ltx_td ltx_align_center">27.2</td>
<td id="S6.T9.5.10.10.9" class="ltx_td ltx_align_center">41.4</td>
<td id="S6.T9.5.10.10.10" class="ltx_td ltx_align_center">20.5</td>
</tr>
<tr id="S6.T9.5.11.11" class="ltx_tr">
<td id="S6.T9.5.11.11.1" class="ltx_td ltx_align_left ltx_border_r">RANSAC</td>
<td id="S6.T9.5.11.11.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.11.11.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T9.5.11.11.4" class="ltx_td ltx_align_center">8.4</td>
<td id="S6.T9.5.11.11.5" class="ltx_td ltx_align_center">11.6</td>
<td id="S6.T9.5.11.11.6" class="ltx_td ltx_align_center">20.5</td>
<td id="S6.T9.5.11.11.7" class="ltx_td ltx_align_center">23.3</td>
<td id="S6.T9.5.11.11.8" class="ltx_td ltx_align_center">27.2</td>
<td id="S6.T9.5.11.11.9" class="ltx_td ltx_align_center">45.7</td>
<td id="S6.T9.5.11.11.10" class="ltx_td ltx_align_center">20.5</td>
</tr>
<tr id="S6.T9.5.12.12" class="ltx_tr">
<td id="S6.T9.5.12.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">AdaFuse (Ours)</td>
<td id="S6.T9.5.12.12.2" class="ltx_td ltx_border_bb ltx_border_r"></td>
<td id="S6.T9.5.12.12.3" class="ltx_td ltx_border_bb ltx_border_r"></td>
<td id="S6.T9.5.12.12.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T9.5.12.12.4.1" class="ltx_text ltx_font_bold">7.2</span></td>
<td id="S6.T9.5.12.12.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T9.5.12.12.5.1" class="ltx_text ltx_font_bold">10.8</span></td>
<td id="S6.T9.5.12.12.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T9.5.12.12.6.1" class="ltx_text ltx_font_bold">18.5</span></td>
<td id="S6.T9.5.12.12.7" class="ltx_td ltx_align_center ltx_border_bb">22.8</td>
<td id="S6.T9.5.12.12.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T9.5.12.12.8.1" class="ltx_text ltx_font_bold">26.6</span></td>
<td id="S6.T9.5.12.12.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T9.5.12.12.9.1" class="ltx_text ltx_font_bold">42.9</span></td>
<td id="S6.T9.5.12.12.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S6.T9.5.12.12.10.1" class="ltx_text ltx_font_bold">19.2</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Summary and Future Work</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We present a multiview fusion approach <em id="S7.p1.1.1" class="ltx_emph ltx_font_italic">AdaFuse</em> to handle the occlusion problem in human pose estimation. <em id="S7.p1.1.2" class="ltx_emph ltx_font_italic">AdaFuse</em> has practical values in that it is very simple and can be flexibly applied to new environments without additional adaptation. In addition, it can be combined with any <math id="S7.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S7.p1.1.m1.1a"><mn id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><cn type="integer" id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">2</annotation></semantics></math>D pose estimation networks. We extensively evaluate the effectiveness of the approach on three benchmark datasets. The approach outperforms the state-of-the-arts remarkably. We also construct a large scale human dataset which has severe occlusion to promote more research along this direction. Our next step of work is to leverage temporal information to further improve the pose estimation accuracy.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amin et al. (2013)</span>
<span class="ltx_bibblock">
Amin S, Andriluka M, Rohrbach M, Schiele B (2013) Multi-view pictorial
structures for 3D human pose estimation. In: BMVC

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andriluka et al. (2014)</span>
<span class="ltx_bibblock">
Andriluka M, Pishchulin L, Gehler P, Schiele B (2014) 2D human pose
estimation: New benchmark and state of the art analysis. In: CVPR, pp
3686–3693

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belagiannis et al. (2014)</span>
<span class="ltx_bibblock">
Belagiannis V, Amin S, Andriluka M, Schiele B, Navab N, Ilic S (2014) 3d
pictorial structures for multiple human pose estimation. In: CVPR, pp
1669–1676

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bo and Sminchisescu (2010)</span>
<span class="ltx_bibblock">
Bo L, Sminchisescu C (2010) Twin gaussian processes for structured prediction.
IJCV 87(1-2):28

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bridgeman et al. (2019)</span>
<span class="ltx_bibblock">
Bridgeman L, Volino M, Guillemaut JY, Hilton A (2019) Multi-person 3d pose
estimation and tracking in sports. In: CVPRW, pp 0–0

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burenius et al. (2013)</span>
<span class="ltx_bibblock">
Burenius M, Sullivan J, Carlsson S (2013) 3D pictorial structures for
multiple view articulated pose estimation. In: CVPR, pp 3618–3625

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et al. (2017)</span>
<span class="ltx_bibblock">
Cao Z, Simon T, Wei SE, Sheikh Y (2017) Realtime multi-person 2d pose
estimation using part affinity fields. In: CVPR, pp 7291–7299

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2016)</span>
<span class="ltx_bibblock">
Chen W, Wang H, Li Y, Su H, Wang Z, Tu C, Lischinski D, Cohen-Or D, Chen B
(2016) Synthesizing training images for boosting human 3d pose estimation.
In: 3DV, IEEE, pp 479–488

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2019)</span>
<span class="ltx_bibblock">
Cheng Y, Yang B, Wang B, Yan W, Tan RT (2019) Occlusion-aware networks for 3d
human pose estimation in video. In: ICCV, pp 723–732

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ci et al. (2019)</span>
<span class="ltx_bibblock">
Ci H, Wang C, Ma X, Wang Y (2019) Optimizing network structure for 3d human
pose estimation. In: ICCV, pp 915–922

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ci et al. (2020)</span>
<span class="ltx_bibblock">
Ci H, Ma X, Wang C, Wang Y (2020) Locally connected network for monocular 3d
human pose estimation. In: T-PAMI

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2019)</span>
<span class="ltx_bibblock">
Dong J, Jiang W, Huang Q, Bao H, Zhou X (2019) Fast and robust multi-person 3d
pose estimation from multiple views. In: CVPR, pp 7792–7801

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fischler and Bolles (1981)</span>
<span class="ltx_bibblock">
Fischler MA, Bolles RC (1981) Random sample consensus: a paradigm for model
fitting with applications to image analysis and automated cartography.
Communications of the ACM 24(6):381–395

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gal (2016)</span>
<span class="ltx_bibblock">
Gal Y (2016) Uncertainty in deep learning. PhD thesis, PhD thesis, University
of Cambridge

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gal and Ghahramani (2015)</span>
<span class="ltx_bibblock">
Gal Y, Ghahramani Z (2015) Dropout as a bayesian approximation: Insights and
applications. In: Deep Learning Workshop, ICML, vol 1, p 2

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gall et al. (2010)</span>
<span class="ltx_bibblock">
Gall J, Rosenhahn B, Brox T, Seidel HP (2010) Optimization and filtering for
human motion capture. IJCV 87(1-2):75

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghahramani (2016)</span>
<span class="ltx_bibblock">
Ghahramani Z (2016) A history of bayesian neural networks. In: NIPS Workshop on
Bayesian Deep Learning

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilbert et al. (2019)</span>
<span class="ltx_bibblock">
Gilbert A, Trumble M, Malleson C, Hilton A, Collomosse J (2019) Fusing visual
and inertial sensors with semantics for 3d human pose estimation. IJCV
127(4):381–397

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2017)</span>
<span class="ltx_bibblock">
Guo C, Pleiss G, Sun Y, Weinberger KQ (2017) On calibration of modern neural
networks. In: ICML, JMLR. org, pp 1321–1330

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartley and Zisserman (2003)</span>
<span class="ltx_bibblock">
Hartley R, Zisserman A (2003) Multiple view geometry in computer vision.
Cambridge university press

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2019)</span>
<span class="ltx_bibblock">
He Y, Zhu C, Wang J, Savvides M, Zhang X (2019) Bounding box regression with
uncertainty for accurate object detection. In: CVPR, pp 2888–2897

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et al. (2019)</span>
<span class="ltx_bibblock">
Hoffmann DT, Tzionas D, Black MJ, Tang S (2019) Learning to train with
synthetic humans. In: German Conference on Pattern Recognition, Springer, pp
609–623

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ilg et al. (2018)</span>
<span class="ltx_bibblock">
Ilg E, Cicek O, Galesso S, Klein A, Makansi O, Hutter F, Brox T (2018)
Uncertainty estimates and multi-hypotheses networks for optical flow. In:
ECCV, pp 652–667

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ionescu et al. (2014)</span>
<span class="ltx_bibblock">
Ionescu C, Papava D, Olaru V, Sminchisescu C (2014) Human3. 6m: Large scale
datasets and predictive methods for 3D human sensing in natural
environments. T-PAMI pp 1325–1339

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iskakov et al. (2019)</span>
<span class="ltx_bibblock">
Iskakov K, Burkov E, Lempitsky V, Malkov Y (2019) Learnable triangulation of
human pose. arXiv preprint arXiv:190505754

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joo et al. (2019)</span>
<span class="ltx_bibblock">
Joo H, Simon T, Li X, Liu H, Tan L, Gui L, Banerjee S, Godisart T, Nabbe B,
Matthews I, et al. (2019) Panoptic studio: A massively multiview system for
social interaction capture. T-PAMI 41(1):190–204

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kendall and Gal (2017)</span>
<span class="ltx_bibblock">
Kendall A, Gal Y (2017) What uncertainties do we need in bayesian deep learning
for computer vision? In: NIPS, pp 5574–5584

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kreiss et al. (2019)</span>
<span class="ltx_bibblock">
Kreiss S, Bertoni L, Alahi A (2019) Pifpaf: Composite fields for human pose
estimation. In: CVPR, pp 11977–11986

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lakshminarayanan et al. (2017)</span>
<span class="ltx_bibblock">
Lakshminarayanan B, Pritzel A, Blundell C (2017) Simple and scalable predictive
uncertainty estimation using deep ensembles. In: NIPS, pp 6402–6413

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lassner et al. (2017)</span>
<span class="ltx_bibblock">
Lassner C, Romero J, Kiefel M, Bogo F, Black MJ, Gehler PV (2017) Unite the
people: Closing the loop between 3d and 2d human representations. In: CVPR,
pp 6050–6059

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2019)</span>
<span class="ltx_bibblock">
Li T, Fan L, Zhao M, Liu Y, Katabi D (2019) Making the invisible visible:
Action recognition through walls and occlusions. In: ICCV, pp 872–881

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2014)</span>
<span class="ltx_bibblock">
Lin TY, Maire M, Belongie S, Hays J, Perona P, Ramanan D, Dollár P, Zitnick
CL (2014) Microsoft coco: Common objects in context. In: ECCV, Springer, pp
740–755

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2011)</span>
<span class="ltx_bibblock">
Liu Y, Stoll C, Gall J, Seidel HP, Theobalt C (2011) Markerless motion capture
of interacting characters using multi-view image segmentation. In: CVPR,
IEEE, pp 1249–1256

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malleson et al. (2017)</span>
<span class="ltx_bibblock">
Malleson C, Gilbert A, Trumble M, Collomosse J, Hilton A, Volino M (2017)
Real-time full-body motion capture from video and imus. In: 3DV, IEEE, pp
449–457

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Marcard et al. (2018)</span>
<span class="ltx_bibblock">
von Marcard T, Henschel R, Black MJ, Rosenhahn B, Pons-Moll G (2018) Recovering
accurate 3d human pose in the wild using imus and a moving camera. In: ECCV,
pp 601–617

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martinez et al. (2017)</span>
<span class="ltx_bibblock">
Martinez J, Hossain R, Romero J, Little JJ (2017) A simple yet effective
baseline for 3D human pose estimation. In: ICCV, p 5

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moeslund et al. (2006)</span>
<span class="ltx_bibblock">
Moeslund TB, Hilton A, Krüger V (2006) A survey of advances in vision-based
human motion capture and analysis. Computer vision and image understanding
104(2-3):90–126

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Newell et al. (2016)</span>
<span class="ltx_bibblock">
Newell A, Yang K, Deng J (2016) Stacked hourglass networks for human pose
estimation. In: ECCV, Springer, pp 483–499

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pavlakos et al. (2017)</span>
<span class="ltx_bibblock">
Pavlakos G, Zhou X, Derpanis KG, Daniilidis K (2017) Harvesting multiple views
for marker-less 3D human pose annotations. In: CVPR, pp 1253–1262

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pavlakos et al. (2018)</span>
<span class="ltx_bibblock">
Pavlakos G, Zhou X, Daniilidis K (2018) Ordinal depth supervision for 3d human
pose estimation. In: CVPR, pp 7307–7316

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pavllo et al. (2019)</span>
<span class="ltx_bibblock">
Pavllo D, Feichtenhofer C, Grangier D, Auli M (2019) 3d human pose estimation
in video with temporal convolutions and semi-supervised training. In: CVPR,
pp 7753–7762

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2018)</span>
<span class="ltx_bibblock">
Peng X, Tang Z, Yang F, Feris RS, Metaxas D (2018) Jointly optimize data
augmentation and network training: Adversarial data augmentation in human
pose estimation. In: CVPR, pp 2226–2234

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perez et al. (2004)</span>
<span class="ltx_bibblock">
Perez P, Vermaak J, Blake A (2004) Data fusion for visual tracking with
particles. Proceedings of the IEEE 92(3):495–513

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pleiss et al. (2017)</span>
<span class="ltx_bibblock">
Pleiss G, Raghavan M, Wu F, Kleinberg J, Weinberger KQ (2017) On fairness and
calibration. In: NIPS, pp 5680–5689

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al. (2019)</span>
<span class="ltx_bibblock">
Qiu H, Wang C, Wang J, Wang N, Zeng W (2019) Cross view fusion for 3d human
pose estimation. In: ICCV, pp 4342–4351

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qiu et al. (2017)</span>
<span class="ltx_bibblock">
Qiu W, Zhong F, Zhang Y, Qiao S, Xiao Z, Kim TS, Wang Y (2017) Unrealcv:
Virtual worlds for computer vision. In: Proceedings of the 25th ACM
international conference on Multimedia, ACM, pp 1221–1224

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rhodin et al. (2018)</span>
<span class="ltx_bibblock">
Rhodin H, Spörri J, Katircioglu I, Constantin V, Meyer F, Müller E,
Salzmann M, Fua P (2018) Learning monocular 3d human pose estimation from
multi-view images. In: CVPR, pp 8437–8446

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roetenberg et al. (2009)</span>
<span class="ltx_bibblock">
Roetenberg D, Luinge H, Slycke P (2009) Xsens mvn: full 6dof human motion
tracking using miniature inertial sensors. Xsens Motion Technologies BV, Tech
Rep 1

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rogez and Schmid (2016)</span>
<span class="ltx_bibblock">
Rogez G, Schmid C (2016) Mocap-guided data augmentation for 3d pose estimation
in the wild. In: NIPS, pp 3108–3116

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sigal et al. (2010)</span>
<span class="ltx_bibblock">
Sigal L, Balan AO, Black MJ (2010) Humaneva: Synchronized video and motion
capture dataset and baseline algorithm for evaluation of articulated human
motion. IJCV 87(1-2):4

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Starner et al. (2003)</span>
<span class="ltx_bibblock">
Starner T, Leibe B, Minnen D, Westyn T, Hurst A, Weeks J (2003) The perceptive
workbench: Computer-vision-based gesture tracking, object tracking, and 3d
reconstruction for augmented desks. Machine Vision and Applications
14(1):59–71

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2019)</span>
<span class="ltx_bibblock">
Sun K, Xiao B, Liu D, Wang J (2019) Deep high-resolution representation
learning for human pose estimation. In: CVPR, pp 5693–5703

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2018)</span>
<span class="ltx_bibblock">
Sun X, Xiao B, Wei F, Liang S, Wei Y (2018) Integral human pose regression. In:
ECCV, pp 529–545

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tome et al. (2018)</span>
<span class="ltx_bibblock">
Tome D, Toso M, Agapito L, Russell C (2018) Rethinking pose in 3D:
Multi-stage refinement and recovery for markerless motion capture. In: 3DV,
pp 474–483

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trumble et al. (2017)</span>
<span class="ltx_bibblock">
Trumble M, Gilbert A, Malleson C, Hilton A, Collomosse J (2017) Total capture:
3D human pose estimation fusing video and inertial sensors. In: BMVC, pp
1–13

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trumble et al. (2018)</span>
<span class="ltx_bibblock">
Trumble M, Gilbert A, Hilton A, Collomosse J (2018) Deep autoencoder for
combined human pose estimation and body model upscaling. In: ECCV, pp
784–800

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al. (2020)</span>
<span class="ltx_bibblock">
Tu H, Wang C, Zeng W (2020) Voxelpose: Towards multi-camera 3d human pose
estimation in wild environment. In: ECCV, pp 1–16

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Varol et al. (2017)</span>
<span class="ltx_bibblock">
Varol G, Romero J, Martin X, Mahmood N, Black MJ, Laptev I, Schmid C (2017)
Learning from synthetic humans. In: CVPR, pp 109–117

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2016)</span>
<span class="ltx_bibblock">
Wei SE, Ramakrishna V, Kanade T, Sheikh Y (2016) Convolutional pose machines.
In: CVPR, pp 4724–4732

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang et al. (2019)</span>
<span class="ltx_bibblock">
Xiang D, Joo H, Sheikh Y (2019) Monocular total capture: Posing face, body, and
hands in the wild. In: CVPR

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. (2018)</span>
<span class="ltx_bibblock">
Xiao B, Wu H, Wei Y (2018) Simple baselines for human pose estimation and
tracking. In: ECCV, pp 466–481

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2020)</span>
<span class="ltx_bibblock">
Xie R, Wang C, Wang C (2020) Metafuse: A pre-trained fusion model for human
pose estimation. In: CVPR

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2018)</span>
<span class="ltx_bibblock">
Yang W, Ouyang W, Wang X, Ren J, Li H, Wang X (2018) 3d human pose estimation
in the wild by adversarial learning. In: CVPR, pp 5255–5264

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zafar et al. (2019)</span>
<span class="ltx_bibblock">
Zafar U, Ghafoor M, Zia T, Ahmed G, Latif A, Malik KR, Sharif AM (2019) Face
recognition with bayesian convolutional networks for robust surveillance
systems. EURASIP Journal on Image and Video Processing 2019(1):10

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Zhang Z, Wang C, Qin W, Zeng W (2020) Fusing wearable imus with multi-view
images for human pose estimation: A geometric approach. In: CVPR, pp
2200–2209

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2018)</span>
<span class="ltx_bibblock">
Zhao M, Li T, Abu Alsheikh M, Tian Y, Zhao H, Torralba A, Katabi D (2018)
Through-wall human pose estimation using radio signals. In: CVPR, pp
7356–7365

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2019)</span>
<span class="ltx_bibblock">
Zhao M, Liu Y, Raghu A, Li T, Zhao H, Torralba A, Katabi D (2019) Through-wall
human mesh recovery using radio signals. In: ICCV, pp 10113–10122

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2017)</span>
<span class="ltx_bibblock">
Zhou X, Huang Q, Sun X, Xue X, Wei Y (2017) Towards 3D human pose estimation
in the wild: a weakly-supervised approach. In: ICCV, pp 398–407

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2010.13299" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2010.13302" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2010.13302">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2010.13302" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2010.13303" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 10 17:21:40 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
