<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2310.19372] RGB-X Object Detection via Scene-Specific Fusion Modules</title><meta property="og:description" content="Multimodal deep sensor fusion has the potential to enable autonomous vehicles to visually understand their surrounding environments in all weather conditions. However, existing deep sensor fusion methods usually employ…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="RGB-X Object Detection via Scene-Specific Fusion Modules">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="RGB-X Object Detection via Scene-Specific Fusion Modules">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2310.19372">

<!--Generated on Tue Feb 27 22:47:00 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">RGB-X Object Detection via Scene-Specific Fusion Modules</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sri Aditya Deevi<sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Equal contribution</span></span></span>    Connor Lee<sup id="id10.10.id2" class="ltx_sup"><span id="id10.10.id2.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Equal contribution</span></span></span>    Lu Gan<sup id="id11.11.id3" class="ltx_sup"><span id="id11.11.id3.1" class="ltx_text ltx_font_italic">1</span></sup><span id="footnotex3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Equal contribution</span></span></span>    Sushruth Nagesh<sup id="id12.12.id4" class="ltx_sup"><span id="id12.12.id4.1" class="ltx_text ltx_font_italic">2</span></sup> 
<br class="ltx_break">Gaurav Pandey<sup id="id13.13.id5" class="ltx_sup"><span id="id13.13.id5.1" class="ltx_text ltx_font_italic">2</span></sup>    Soon-Jo Chung<sup id="id14.14.id6" class="ltx_sup"><span id="id14.14.id6.1" class="ltx_text ltx_font_italic">1</span></sup> 
<br class="ltx_break"><sup id="id15.15.id7" class="ltx_sup"><span id="id15.15.id7.1" class="ltx_text ltx_font_italic">1</span></sup>California Institute of Technology  <sup id="id16.16.id8" class="ltx_sup"><span id="id16.16.id8.1" class="ltx_text ltx_font_italic">2</span></sup>Ford Motor Company 
<br class="ltx_break"><span id="id17.17.id9" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{sdeevi, clee, ganlu, sjchung}@caltech.edu</span>  <span id="id18.18.id10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{snagesh1, gpandey2}@ford.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id19.id1" class="ltx_p">Multimodal deep sensor fusion has the potential to enable autonomous vehicles to visually understand their surrounding environments in all weather conditions. However, existing deep sensor fusion methods usually employ convoluted architectures with intermingled multimodal features, requiring large coregistered multimodal datasets for training. In this work, we present an efficient and modular RGB-X fusion network that can leverage and fuse pretrained single-modal models via scene-specific fusion modules, thereby enabling joint input-adaptive network architectures to be created using small, coregistered multimodal datasets. Our experiments demonstrate the superiority of our method compared to existing works on RGB-thermal and RGB-gated datasets, performing fusion using only a small amount of additional parameters. Our code is available at <a target="_blank" href="https://github.com/dsriaditya999/RGBXFusion" title="" class="ltx_ref ltx_href">https://github.com/dsriaditya999/RGBXFusion</a>.</p>
</div>
<span id="footnotex4" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotetext: </span>This work was funded by the Ford University Research Program.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Autonomous vehicles rely on object detection algorithms to understand and interact with their surrounding environments. In order to be robust against different driving conditions, these algorithms operate on data from various sensor modalities ranging from optical cameras to LiDAR, each with their own advantages and disadvantages. Because no single sensor modality is robust to all possible conditions that may be encountered during driving, multiple sensor modalities are often used in conjunction via <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">deep sensor fusion (DSF)</span> to boost performance during normal driving operations, as well as to ensure segmentation and object detection reliability in adverse weather conditions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2310.19372/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="231" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Our multimodal object detection approach combines RGB and thermal pretrained networks using lightweight, scene-specific fusion modules. Fusion modules are trained using categorized scene images and are used adaptively during inference with an auxiliary scene classifier.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Unlike traditional sensor fusion which merges processed sensor data outputs coming from independent pipelines, current works in DSF generally require joint end-to-end training of multi-branch sensor networks on large multimodal datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> such as NuScenes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, Berkeley Deep Drive <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, and Waymo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> prior to deployment in the wild <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
This means that fusion architectures must undergo time-consuming and potentially expensive retraining (in cost and carbon emissions) anytime a sensor modality is removed or added <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and that they fail to take full advantage of state-of-the-art RGB pretrained networks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we propose the use of existing, well-known attention blocks as lightweight, scene-specific attention modules in order to easily fuse pretrained networks and to better adapt to common weather disturbances. We demonstrate our approach (<a href="#S1.F1" title="In 1 Introduction ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>) for object detection applications, training RGB-thermal and RGB-gated fusion models on RGB, thermal, and gated imagery collected in adverse driving conditions such as night, fog, snow, and rain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. We also leverage the attention modules as a method to visually interpret the contributions of each sensor modality. Compared to prior works, our approach takes us another step closer to enabling a modular, <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">drag-and-drop</span> design for deep sensor fusion that absolves the need for extensive and expensive retraining while delivering on-par or better performance. <span id="S1.p3.1.2" class="ltx_text ltx_font_bold">Our contributions are as follows:</span>
<span id="S1.p3.1.3" class="ltx_text ltx_font_bold">1.</span> A lightweight, modular RGB-X fusion network for object detection that leverages pretrained single-modality networks. <span id="S1.p3.1.4" class="ltx_text ltx_font_bold">2.</span> A scene-adaptive fusion approach that selectively uses different fusion modules for different scene/weather conditions. <span id="S1.p3.1.5" class="ltx_text ltx_font_bold">3.</span> Extensive experiments on publicly available RGB-X datasets that demonstrate the superiority of our approach in terms of detection performance and computational efficiency.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Object Detection:</span> Most modern methods for detecting objects utilize convolutional neural networks (CNN) or transformers. CNN object detectors include two-stage and single-shot detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. A two-stage detector has an additional region proposal step while a single-shot detector relies only on a feature extractor and a detection head that directly predicts bounding boxes and classes, resulting in faster inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. To deploy on mobile devices, neural architecture search (NAS) has been used to develop faster and lighter networks and detection architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. In this work, we adopt the EfficientDet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> detection architecture to target self-driving car applications that operate on mobile computing devices. Recent large vision transformer models have achieved state-of-the-art object detection results, but are not suitable for real-time use on robotic platforms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Deep Sensor Fusion:</span>
Robotic perception applications, notably for self-driving cars, rely on DSF to add sensor redundancy and to increase perception robustness and performance in both common and adverse operating scenarios. Current DSF algorithms consume multimodal data using deep networks and are trained end-to-end, combining different features at various points throughout a network depending on their particular fusion policy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Early fusion policies aggregate raw inputs or features extracted early on in the network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> while mid-fusion approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> operate on deeper, intermediate representations. Late fusion methods operate directly on bounding box outputs and can be used directly with pretrained detectors, but are subject to the performance of pretrained models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. In our work, we opt for a mid-fusion approach in order to take full advantage of the different feature modalities at various stages.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Regardless of fusion policies, current DSF algorithms and datasets for self-driving cars mainly focus on incorporating sensors like LiDAR and radar with RGB cameras <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. In our work, we are interested in supplementing RGB with 2D image data from thermal and gated cameras due to the rich semantic information they provide and their robustness to fog and lighting in driving scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">RGB-Thermal Object Detection:</span> Current RGB-thermal (RGB-T) object detection methods typically operate on aligned RGB-thermal image pairs and utilize some form of attention-based modules to perform mid-fusion on RGB and thermal image features. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> utilizes intra-modality and inter-modality spatial attention modules to enhance and adaptively fuse intermediate features, respectively, prior to passing downstream to a detection head. Recently, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> proposed mid-fusion modules that utilize channel attention to dynamically swap RGB and thermal feature channels. This helps to maximize feature usefulness before enhancing local features via parameter-free spatial attention. Other works including <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> fuse multi-modal data in a similar fashion but instead leverage transformer-based attention modules that increase model size and computational cost. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> does not use thermal images, but similarly fuses RGB, gated, and projected LiDAR and radar data using local entropy masks in lieu of attention. In our work, we demonstrate that pretrained, single-modality detectors can be fused using simple, scene-specific channel and spatial attention modules to achieve strong RGB-T object detection performance.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2310.19372/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="231" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Overall framework of our scene-adaptive CBAM model for RGB-X fusion illustrated by RGB-T fusion. RGB and thermal images are processed by separate EfficientNet backbones, followed by BiFPNs. The features from BiFPNs are used for cross-modal feature fusion using modules selected by the scene classifier. The detector head utilizes these fused features to obtain the final detection results. The right side of the figure illustrates the CBAM fusion module, consisting of channel and spatial attention blocks, for feature fusion. </span></figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We propose a modular RGB-X fusion network for object detection that is built upon pretrained single-modal detection architecture and multi-stage convolutional block attention modules (CBAM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> for cross-modal feature fusion. This modularity separates the training of single-modal backbones that contain the majority of network parameters and the training of a small fusion module, mitigating the requirement of large-scale multi-modal training data. The overall architecture for RGB-X fusion is shown in <a href="#S2.F2" title="In 2 Related Work ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a> using RGB-T as an example. We have an individual EfficientDet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> for each image modality consisting of an EfficientNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> backbone network, a bidirectional feature pyramid network (BiFPN) and a detector head. While we choose to use EfficientDet to demonstrate our approach, we note that this architecture can be built using any single-modal detection network.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">We employ CBAM to fuse the RGB and thermal features output from the respective BiFPN at various stages. Each CBAM fuses features at the same scale, resulting in 5 CBAM fusion modules. During training, only CBAM parameters are updated while pretrained object detector weights are frozen. CBAM modules are trained per scene category and are selected for use during inference time using an auxiliary scene classifier.
In the rest of this section, we go over the details of our fusion mechanism and the auxiliary scene classifier, before describing the overall scene-adaptive fusion algorithm for RGB-X object detection.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Convolutional Block Attention Fusion</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.3" class="ltx_p">We use CBAM to fuse RGB and thermal (or gated) CNN feature maps <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{F_{rgb}}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">𝐅</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">𝐫𝐠𝐛</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝐅</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">𝐫𝐠𝐛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathbf{F_{rgb}}</annotation></semantics></math> and <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{F_{x}}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">𝐅</mi><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">𝐱</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝐅</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbf{F_{x}}</annotation></semantics></math>, respectively. We concatenate features from both modalities across the channel dimension to create an input feature map <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{F}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">𝐅</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝐅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathbf{F}</annotation></semantics></math> for CBAM:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathbf{F}=[\mathbf{F_{rgb}};\mathbf{F_{x}}]\in\mathbf{R}^{B\times C\times H\times W}," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml">𝐅</mi><mo id="S3.E1.m1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">[</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">𝐅</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">𝐫𝐠𝐛</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.2.4" xref="S3.E1.m1.1.1.1.1.2.3.cmml">;</mo><msub id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.cmml">𝐅</mi><mi id="S3.E1.m1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.3.cmml">𝐱</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.2.2.5" xref="S3.E1.m1.1.1.1.1.2.3.cmml">]</mo></mrow><mo id="S3.E1.m1.1.1.1.1.6" xref="S3.E1.m1.1.1.1.1.6.cmml">∈</mo><msup id="S3.E1.m1.1.1.1.1.7" xref="S3.E1.m1.1.1.1.1.7.cmml"><mi id="S3.E1.m1.1.1.1.1.7.2" xref="S3.E1.m1.1.1.1.1.7.2.cmml">𝐑</mi><mrow id="S3.E1.m1.1.1.1.1.7.3" xref="S3.E1.m1.1.1.1.1.7.3.cmml"><mi id="S3.E1.m1.1.1.1.1.7.3.2" xref="S3.E1.m1.1.1.1.1.7.3.2.cmml">B</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.7.3.1" xref="S3.E1.m1.1.1.1.1.7.3.1.cmml">×</mo><mi id="S3.E1.m1.1.1.1.1.7.3.3" xref="S3.E1.m1.1.1.1.1.7.3.3.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.7.3.1a" xref="S3.E1.m1.1.1.1.1.7.3.1.cmml">×</mo><mi id="S3.E1.m1.1.1.1.1.7.3.4" xref="S3.E1.m1.1.1.1.1.7.3.4.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E1.m1.1.1.1.1.7.3.1b" xref="S3.E1.m1.1.1.1.1.7.3.1.cmml">×</mo><mi id="S3.E1.m1.1.1.1.1.7.3.5" xref="S3.E1.m1.1.1.1.1.7.3.5.cmml">W</mi></mrow></msup></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><and id="S3.E1.m1.1.1.1.1a.cmml" xref="S3.E1.m1.1.1.1"></and><apply id="S3.E1.m1.1.1.1.1b.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.5"></eq><ci id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4">𝐅</ci><list id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">𝐅</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">𝐫𝐠𝐛</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2">𝐅</ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.3">𝐱</ci></apply></list></apply><apply id="S3.E1.m1.1.1.1.1c.cmml" xref="S3.E1.m1.1.1.1"><in id="S3.E1.m1.1.1.1.1.6.cmml" xref="S3.E1.m1.1.1.1.1.6"></in><share href="#S3.E1.m1.1.1.1.1.2.cmml" id="S3.E1.m1.1.1.1.1d.cmml" xref="S3.E1.m1.1.1.1"></share><apply id="S3.E1.m1.1.1.1.1.7.cmml" xref="S3.E1.m1.1.1.1.1.7"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.7.1.cmml" xref="S3.E1.m1.1.1.1.1.7">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.7.2.cmml" xref="S3.E1.m1.1.1.1.1.7.2">𝐑</ci><apply id="S3.E1.m1.1.1.1.1.7.3.cmml" xref="S3.E1.m1.1.1.1.1.7.3"><times id="S3.E1.m1.1.1.1.1.7.3.1.cmml" xref="S3.E1.m1.1.1.1.1.7.3.1"></times><ci id="S3.E1.m1.1.1.1.1.7.3.2.cmml" xref="S3.E1.m1.1.1.1.1.7.3.2">𝐵</ci><ci id="S3.E1.m1.1.1.1.1.7.3.3.cmml" xref="S3.E1.m1.1.1.1.1.7.3.3">𝐶</ci><ci id="S3.E1.m1.1.1.1.1.7.3.4.cmml" xref="S3.E1.m1.1.1.1.1.7.3.4">𝐻</ci><ci id="S3.E1.m1.1.1.1.1.7.3.5.cmml" xref="S3.E1.m1.1.1.1.1.7.3.5">𝑊</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathbf{F}=[\mathbf{F_{rgb}};\mathbf{F_{x}}]\in\mathbf{R}^{B\times C\times H\times W},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.8" class="ltx_p">where <math id="S3.SS1.p1.4.m1.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS1.p1.4.m1.1a"><mi id="S3.SS1.p1.4.m1.1.1" xref="S3.SS1.p1.4.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m1.1b"><ci id="S3.SS1.p1.4.m1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m1.1c">B</annotation></semantics></math> denotes the batch size, and <math id="S3.SS1.p1.5.m2.3" class="ltx_Math" alttext="C,H,W" display="inline"><semantics id="S3.SS1.p1.5.m2.3a"><mrow id="S3.SS1.p1.5.m2.3.4.2" xref="S3.SS1.p1.5.m2.3.4.1.cmml"><mi id="S3.SS1.p1.5.m2.1.1" xref="S3.SS1.p1.5.m2.1.1.cmml">C</mi><mo id="S3.SS1.p1.5.m2.3.4.2.1" xref="S3.SS1.p1.5.m2.3.4.1.cmml">,</mo><mi id="S3.SS1.p1.5.m2.2.2" xref="S3.SS1.p1.5.m2.2.2.cmml">H</mi><mo id="S3.SS1.p1.5.m2.3.4.2.2" xref="S3.SS1.p1.5.m2.3.4.1.cmml">,</mo><mi id="S3.SS1.p1.5.m2.3.3" xref="S3.SS1.p1.5.m2.3.3.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m2.3b"><list id="S3.SS1.p1.5.m2.3.4.1.cmml" xref="S3.SS1.p1.5.m2.3.4.2"><ci id="S3.SS1.p1.5.m2.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1">𝐶</ci><ci id="S3.SS1.p1.5.m2.2.2.cmml" xref="S3.SS1.p1.5.m2.2.2">𝐻</ci><ci id="S3.SS1.p1.5.m2.3.3.cmml" xref="S3.SS1.p1.5.m2.3.3">𝑊</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m2.3c">C,H,W</annotation></semantics></math> denote the channel and spatial dimensions of the feature, respectively.
Following the notation in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, a CBAM module takes the feature map <math id="S3.SS1.p1.6.m3.1" class="ltx_Math" alttext="\mathbf{F}" display="inline"><semantics id="S3.SS1.p1.6.m3.1a"><mi id="S3.SS1.p1.6.m3.1.1" xref="S3.SS1.p1.6.m3.1.1.cmml">𝐅</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m3.1b"><ci id="S3.SS1.p1.6.m3.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1">𝐅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m3.1c">\mathbf{F}</annotation></semantics></math> and masks it using channel and spatial attention operators <math id="S3.SS1.p1.7.m4.1" class="ltx_Math" alttext="M_{c}" display="inline"><semantics id="S3.SS1.p1.7.m4.1a"><msub id="S3.SS1.p1.7.m4.1.1" xref="S3.SS1.p1.7.m4.1.1.cmml"><mi id="S3.SS1.p1.7.m4.1.1.2" xref="S3.SS1.p1.7.m4.1.1.2.cmml">M</mi><mi id="S3.SS1.p1.7.m4.1.1.3" xref="S3.SS1.p1.7.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m4.1b"><apply id="S3.SS1.p1.7.m4.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m4.1.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m4.1.1.2.cmml" xref="S3.SS1.p1.7.m4.1.1.2">𝑀</ci><ci id="S3.SS1.p1.7.m4.1.1.3.cmml" xref="S3.SS1.p1.7.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m4.1c">M_{c}</annotation></semantics></math>, <math id="S3.SS1.p1.8.m5.1" class="ltx_Math" alttext="M_{s}" display="inline"><semantics id="S3.SS1.p1.8.m5.1a"><msub id="S3.SS1.p1.8.m5.1.1" xref="S3.SS1.p1.8.m5.1.1.cmml"><mi id="S3.SS1.p1.8.m5.1.1.2" xref="S3.SS1.p1.8.m5.1.1.2.cmml">M</mi><mi id="S3.SS1.p1.8.m5.1.1.3" xref="S3.SS1.p1.8.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m5.1b"><apply id="S3.SS1.p1.8.m5.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m5.1.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m5.1.1.2.cmml" xref="S3.SS1.p1.8.m5.1.1.2">𝑀</ci><ci id="S3.SS1.p1.8.m5.1.1.3.cmml" xref="S3.SS1.p1.8.m5.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m5.1c">M_{s}</annotation></semantics></math> such that</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{F^{\prime}}" display="inline"><semantics id="S3.E2.m1.1a"><msup id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">𝐅</mi><mo id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1">superscript</csymbol><ci id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2">𝐅</ci><ci id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\mathbf{F^{\prime}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m2.2" class="ltx_Math" alttext="\displaystyle=M_{c}(\mathbf{F})\otimes\mathbf{F}," display="inline"><semantics id="S3.E2.m2.2a"><mrow id="S3.E2.m2.2.2.1" xref="S3.E2.m2.2.2.1.1.cmml"><mrow id="S3.E2.m2.2.2.1.1" xref="S3.E2.m2.2.2.1.1.cmml"><mi id="S3.E2.m2.2.2.1.1.2" xref="S3.E2.m2.2.2.1.1.2.cmml"></mi><mo id="S3.E2.m2.2.2.1.1.1" xref="S3.E2.m2.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m2.2.2.1.1.3" xref="S3.E2.m2.2.2.1.1.3.cmml"><mrow id="S3.E2.m2.2.2.1.1.3.2" xref="S3.E2.m2.2.2.1.1.3.2.cmml"><msub id="S3.E2.m2.2.2.1.1.3.2.2" xref="S3.E2.m2.2.2.1.1.3.2.2.cmml"><mi id="S3.E2.m2.2.2.1.1.3.2.2.2" xref="S3.E2.m2.2.2.1.1.3.2.2.2.cmml">M</mi><mi id="S3.E2.m2.2.2.1.1.3.2.2.3" xref="S3.E2.m2.2.2.1.1.3.2.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m2.2.2.1.1.3.2.1" xref="S3.E2.m2.2.2.1.1.3.2.1.cmml">​</mo><mrow id="S3.E2.m2.2.2.1.1.3.2.3.2" xref="S3.E2.m2.2.2.1.1.3.2.cmml"><mo stretchy="false" id="S3.E2.m2.2.2.1.1.3.2.3.2.1" xref="S3.E2.m2.2.2.1.1.3.2.cmml">(</mo><mi id="S3.E2.m2.1.1" xref="S3.E2.m2.1.1.cmml">𝐅</mi><mo rspace="0.055em" stretchy="false" id="S3.E2.m2.2.2.1.1.3.2.3.2.2" xref="S3.E2.m2.2.2.1.1.3.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E2.m2.2.2.1.1.3.1" xref="S3.E2.m2.2.2.1.1.3.1.cmml">⊗</mo><mi id="S3.E2.m2.2.2.1.1.3.3" xref="S3.E2.m2.2.2.1.1.3.3.cmml">𝐅</mi></mrow></mrow><mo id="S3.E2.m2.2.2.1.2" xref="S3.E2.m2.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m2.2b"><apply id="S3.E2.m2.2.2.1.1.cmml" xref="S3.E2.m2.2.2.1"><eq id="S3.E2.m2.2.2.1.1.1.cmml" xref="S3.E2.m2.2.2.1.1.1"></eq><csymbol cd="latexml" id="S3.E2.m2.2.2.1.1.2.cmml" xref="S3.E2.m2.2.2.1.1.2">absent</csymbol><apply id="S3.E2.m2.2.2.1.1.3.cmml" xref="S3.E2.m2.2.2.1.1.3"><csymbol cd="latexml" id="S3.E2.m2.2.2.1.1.3.1.cmml" xref="S3.E2.m2.2.2.1.1.3.1">tensor-product</csymbol><apply id="S3.E2.m2.2.2.1.1.3.2.cmml" xref="S3.E2.m2.2.2.1.1.3.2"><times id="S3.E2.m2.2.2.1.1.3.2.1.cmml" xref="S3.E2.m2.2.2.1.1.3.2.1"></times><apply id="S3.E2.m2.2.2.1.1.3.2.2.cmml" xref="S3.E2.m2.2.2.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.1.1.3.2.2.1.cmml" xref="S3.E2.m2.2.2.1.1.3.2.2">subscript</csymbol><ci id="S3.E2.m2.2.2.1.1.3.2.2.2.cmml" xref="S3.E2.m2.2.2.1.1.3.2.2.2">𝑀</ci><ci id="S3.E2.m2.2.2.1.1.3.2.2.3.cmml" xref="S3.E2.m2.2.2.1.1.3.2.2.3">𝑐</ci></apply><ci id="S3.E2.m2.1.1.cmml" xref="S3.E2.m2.1.1">𝐅</ci></apply><ci id="S3.E2.m2.2.2.1.1.3.3.cmml" xref="S3.E2.m2.2.2.1.1.3.3">𝐅</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m2.2c">\displaystyle=M_{c}(\mathbf{F})\otimes\mathbf{F},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{F^{\prime\prime}}" display="inline"><semantics id="S3.E3.m1.1a"><msup id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mi id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">𝐅</mi><mo id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml">′′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1">superscript</csymbol><ci id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2">𝐅</ci><ci id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3">′′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle\mathbf{F^{\prime\prime}}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E3.m2.1" class="ltx_Math" alttext="\displaystyle=M_{s}(\mathbf{F^{\prime}})\otimes\mathbf{F^{\prime}}," display="inline"><semantics id="S3.E3.m2.1a"><mrow id="S3.E3.m2.1.1.1" xref="S3.E3.m2.1.1.1.1.cmml"><mrow id="S3.E3.m2.1.1.1.1" xref="S3.E3.m2.1.1.1.1.cmml"><mi id="S3.E3.m2.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.3.cmml"></mi><mo id="S3.E3.m2.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m2.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.cmml"><mrow id="S3.E3.m2.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.cmml"><msub id="S3.E3.m2.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.3.2" xref="S3.E3.m2.1.1.1.1.1.1.3.2.cmml">M</mi><mi id="S3.E3.m2.1.1.1.1.1.1.3.3" xref="S3.E3.m2.1.1.1.1.1.1.3.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m2.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E3.m2.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m2.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E3.m2.1.1.1.1.1.1.1.1.1" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m2.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.2.cmml">𝐅</mi><mo id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.cmml">′</mo></msup><mo rspace="0.055em" stretchy="false" id="S3.E3.m2.1.1.1.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S3.E3.m2.1.1.1.1.1.2" xref="S3.E3.m2.1.1.1.1.1.2.cmml">⊗</mo><msup id="S3.E3.m2.1.1.1.1.1.3" xref="S3.E3.m2.1.1.1.1.1.3.cmml"><mi id="S3.E3.m2.1.1.1.1.1.3.2" xref="S3.E3.m2.1.1.1.1.1.3.2.cmml">𝐅</mi><mo id="S3.E3.m2.1.1.1.1.1.3.3" xref="S3.E3.m2.1.1.1.1.1.3.3.cmml">′</mo></msup></mrow></mrow><mo id="S3.E3.m2.1.1.1.2" xref="S3.E3.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m2.1b"><apply id="S3.E3.m2.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1"><eq id="S3.E3.m2.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.2"></eq><csymbol cd="latexml" id="S3.E3.m2.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.3">absent</csymbol><apply id="S3.E3.m2.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m2.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.2">tensor-product</csymbol><apply id="S3.E3.m2.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1"><times id="S3.E3.m2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.2"></times><apply id="S3.E3.m2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3.2">𝑀</ci><ci id="S3.E3.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.3.3">𝑠</ci></apply><apply id="S3.E3.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.2">𝐅</ci><ci id="S3.E3.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.1.1.1.1.3">′</ci></apply></apply><apply id="S3.E3.m2.1.1.1.1.1.3.cmml" xref="S3.E3.m2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m2.1.1.1.1.1.3.1.cmml" xref="S3.E3.m2.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m2.1.1.1.1.1.3.2.cmml" xref="S3.E3.m2.1.1.1.1.1.3.2">𝐅</ci><ci id="S3.E3.m2.1.1.1.1.1.3.3.cmml" xref="S3.E3.m2.1.1.1.1.1.3.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m2.1c">\displaystyle=M_{s}(\mathbf{F^{\prime}})\otimes\mathbf{F^{\prime}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.12" class="ltx_p">where <math id="S3.SS1.p1.9.m1.1" class="ltx_Math" alttext="\otimes" display="inline"><semantics id="S3.SS1.p1.9.m1.1a"><mo id="S3.SS1.p1.9.m1.1.1" xref="S3.SS1.p1.9.m1.1.1.cmml">⊗</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m1.1b"><csymbol cd="latexml" id="S3.SS1.p1.9.m1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m1.1c">\otimes</annotation></semantics></math> denotes element-wise multiplication.
We further convolve <math id="S3.SS1.p1.10.m2.1" class="ltx_Math" alttext="\mathbf{F^{\prime\prime}}" display="inline"><semantics id="S3.SS1.p1.10.m2.1a"><msup id="S3.SS1.p1.10.m2.1.1" xref="S3.SS1.p1.10.m2.1.1.cmml"><mi id="S3.SS1.p1.10.m2.1.1.2" xref="S3.SS1.p1.10.m2.1.1.2.cmml">𝐅</mi><mo id="S3.SS1.p1.10.m2.1.1.3" xref="S3.SS1.p1.10.m2.1.1.3.cmml">′′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m2.1b"><apply id="S3.SS1.p1.10.m2.1.1.cmml" xref="S3.SS1.p1.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.10.m2.1.1.1.cmml" xref="S3.SS1.p1.10.m2.1.1">superscript</csymbol><ci id="S3.SS1.p1.10.m2.1.1.2.cmml" xref="S3.SS1.p1.10.m2.1.1.2">𝐅</ci><ci id="S3.SS1.p1.10.m2.1.1.3.cmml" xref="S3.SS1.p1.10.m2.1.1.3">′′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m2.1c">\mathbf{F^{\prime\prime}}</annotation></semantics></math> with <math id="S3.SS1.p1.11.m3.1" class="ltx_Math" alttext="C/2" display="inline"><semantics id="S3.SS1.p1.11.m3.1a"><mrow id="S3.SS1.p1.11.m3.1.1" xref="S3.SS1.p1.11.m3.1.1.cmml"><mi id="S3.SS1.p1.11.m3.1.1.2" xref="S3.SS1.p1.11.m3.1.1.2.cmml">C</mi><mo id="S3.SS1.p1.11.m3.1.1.1" xref="S3.SS1.p1.11.m3.1.1.1.cmml">/</mo><mn id="S3.SS1.p1.11.m3.1.1.3" xref="S3.SS1.p1.11.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m3.1b"><apply id="S3.SS1.p1.11.m3.1.1.cmml" xref="S3.SS1.p1.11.m3.1.1"><divide id="S3.SS1.p1.11.m3.1.1.1.cmml" xref="S3.SS1.p1.11.m3.1.1.1"></divide><ci id="S3.SS1.p1.11.m3.1.1.2.cmml" xref="S3.SS1.p1.11.m3.1.1.2">𝐶</ci><cn type="integer" id="S3.SS1.p1.11.m3.1.1.3.cmml" xref="S3.SS1.p1.11.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m3.1c">C/2</annotation></semantics></math> kernels resulting in <math id="S3.SS1.p1.12.m4.1" class="ltx_Math" alttext="C/2" display="inline"><semantics id="S3.SS1.p1.12.m4.1a"><mrow id="S3.SS1.p1.12.m4.1.1" xref="S3.SS1.p1.12.m4.1.1.cmml"><mi id="S3.SS1.p1.12.m4.1.1.2" xref="S3.SS1.p1.12.m4.1.1.2.cmml">C</mi><mo id="S3.SS1.p1.12.m4.1.1.1" xref="S3.SS1.p1.12.m4.1.1.1.cmml">/</mo><mn id="S3.SS1.p1.12.m4.1.1.3" xref="S3.SS1.p1.12.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m4.1b"><apply id="S3.SS1.p1.12.m4.1.1.cmml" xref="S3.SS1.p1.12.m4.1.1"><divide id="S3.SS1.p1.12.m4.1.1.1.cmml" xref="S3.SS1.p1.12.m4.1.1.1"></divide><ci id="S3.SS1.p1.12.m4.1.1.2.cmml" xref="S3.SS1.p1.12.m4.1.1.2">𝐶</ci><cn type="integer" id="S3.SS1.p1.12.m4.1.1.3.cmml" xref="S3.SS1.p1.12.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m4.1c">C/2</annotation></semantics></math> channels which is the original feature dimension.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Channel attention operator <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="M_{c}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑀</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">M_{c}</annotation></semantics></math> is computed via</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.2" class="ltx_Math" alttext="M_{c}(\mathbf{F})=\sigma(\mathbf{W_{1}}\mathbf{W_{0}}\mathbf{F^{c}_{avg}}+\mathbf{W_{1}}\mathbf{W_{0}}\mathbf{F^{c}_{max}})," display="block"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2.1" xref="S3.E4.m1.2.2.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1" xref="S3.E4.m1.2.2.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1.3" xref="S3.E4.m1.2.2.1.1.3.cmml"><msub id="S3.E4.m1.2.2.1.1.3.2" xref="S3.E4.m1.2.2.1.1.3.2.cmml"><mi id="S3.E4.m1.2.2.1.1.3.2.2" xref="S3.E4.m1.2.2.1.1.3.2.2.cmml">M</mi><mi id="S3.E4.m1.2.2.1.1.3.2.3" xref="S3.E4.m1.2.2.1.1.3.2.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.3.1" xref="S3.E4.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S3.E4.m1.2.2.1.1.3.3.2" xref="S3.E4.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.1.1.3.3.2.1" xref="S3.E4.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">𝐅</mi><mo stretchy="false" id="S3.E4.m1.2.2.1.1.3.3.2.2" xref="S3.E4.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.2.2.1.1.2" xref="S3.E4.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.2.2.1.1.1" xref="S3.E4.m1.2.2.1.1.1.cmml"><mi id="S3.E4.m1.2.2.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.2.2.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">𝐖</mi><mn id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.3.cmml">𝟏</mn></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.2.cmml">𝐖</mi><mn id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.3.cmml">𝟎</mn></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.1a" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.1.cmml">​</mo><msubsup id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.2.cmml">𝐅</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.3.cmml">𝐚𝐯𝐠</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.3.cmml">𝐜</mi></msubsup></mrow><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.2.cmml">𝐖</mi><mn id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.3.cmml">𝟏</mn></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.2.cmml">𝐖</mi><mn id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.3.cmml">𝟎</mn></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.1a" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.1.cmml">​</mo><msubsup id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.2.cmml">𝐅</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.3.cmml">𝐦𝐚𝐱</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.3.cmml">𝐜</mi></msubsup></mrow></mrow><mo stretchy="false" id="S3.E4.m1.2.2.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.2.2.1.2" xref="S3.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.1.1.cmml" xref="S3.E4.m1.2.2.1"><eq id="S3.E4.m1.2.2.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.2"></eq><apply id="S3.E4.m1.2.2.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.3"><times id="S3.E4.m1.2.2.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.3.1"></times><apply id="S3.E4.m1.2.2.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.3.2.1.cmml" xref="S3.E4.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.3.2.2.cmml" xref="S3.E4.m1.2.2.1.1.3.2.2">𝑀</ci><ci id="S3.E4.m1.2.2.1.1.3.2.3.cmml" xref="S3.E4.m1.2.2.1.1.3.2.3">𝑐</ci></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝐅</ci></apply><apply id="S3.E4.m1.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1"><times id="S3.E4.m1.2.2.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.2"></times><ci id="S3.E4.m1.2.2.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.3">𝜎</ci><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1"><plus id="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1"></plus><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2"><times id="S3.E4.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.2">𝐖</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.2.3">1</cn></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.2">𝐖</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.3.3">0</cn></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4">subscript</csymbol><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4">superscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.2">𝐅</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.2.3">𝐜</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.4.3">𝐚𝐯𝐠</ci></apply></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3"><times id="S3.E4.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.2">𝐖</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.2.3">1</cn></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.2">𝐖</ci><cn type="integer" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.3.3">0</cn></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4">subscript</csymbol><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4">superscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.2">𝐅</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.2.3">𝐜</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.4.3">𝐦𝐚𝐱</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">M_{c}(\mathbf{F})=\sigma(\mathbf{W_{1}}\mathbf{W_{0}}\mathbf{F^{c}_{avg}}+\mathbf{W_{1}}\mathbf{W_{0}}\mathbf{F^{c}_{max}}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.5" class="ltx_p">where <math id="S3.SS1.p2.2.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS1.p2.2.m1.1a"><mi id="S3.SS1.p2.2.m1.1.1" xref="S3.SS1.p2.2.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m1.1b"><ci id="S3.SS1.p2.2.m1.1.1.cmml" xref="S3.SS1.p2.2.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m1.1c">\sigma</annotation></semantics></math>, <math id="S3.SS1.p2.3.m2.1" class="ltx_Math" alttext="\mathbf{W}" display="inline"><semantics id="S3.SS1.p2.3.m2.1a"><mi id="S3.SS1.p2.3.m2.1.1" xref="S3.SS1.p2.3.m2.1.1.cmml">𝐖</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m2.1b"><ci id="S3.SS1.p2.3.m2.1.1.cmml" xref="S3.SS1.p2.3.m2.1.1">𝐖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m2.1c">\mathbf{W}</annotation></semantics></math>, <math id="S3.SS1.p2.4.m3.1" class="ltx_Math" alttext="\mathbf{F^{c}_{avg}}" display="inline"><semantics id="S3.SS1.p2.4.m3.1a"><msubsup id="S3.SS1.p2.4.m3.1.1" xref="S3.SS1.p2.4.m3.1.1.cmml"><mi id="S3.SS1.p2.4.m3.1.1.2.2" xref="S3.SS1.p2.4.m3.1.1.2.2.cmml">𝐅</mi><mi id="S3.SS1.p2.4.m3.1.1.3" xref="S3.SS1.p2.4.m3.1.1.3.cmml">𝐚𝐯𝐠</mi><mi id="S3.SS1.p2.4.m3.1.1.2.3" xref="S3.SS1.p2.4.m3.1.1.2.3.cmml">𝐜</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m3.1b"><apply id="S3.SS1.p2.4.m3.1.1.cmml" xref="S3.SS1.p2.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m3.1.1.1.cmml" xref="S3.SS1.p2.4.m3.1.1">subscript</csymbol><apply id="S3.SS1.p2.4.m3.1.1.2.cmml" xref="S3.SS1.p2.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m3.1.1.2.1.cmml" xref="S3.SS1.p2.4.m3.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m3.1.1.2.2.cmml" xref="S3.SS1.p2.4.m3.1.1.2.2">𝐅</ci><ci id="S3.SS1.p2.4.m3.1.1.2.3.cmml" xref="S3.SS1.p2.4.m3.1.1.2.3">𝐜</ci></apply><ci id="S3.SS1.p2.4.m3.1.1.3.cmml" xref="S3.SS1.p2.4.m3.1.1.3">𝐚𝐯𝐠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m3.1c">\mathbf{F^{c}_{avg}}</annotation></semantics></math>, <math id="S3.SS1.p2.5.m4.1" class="ltx_Math" alttext="\mathbf{F^{c}_{max}}" display="inline"><semantics id="S3.SS1.p2.5.m4.1a"><msubsup id="S3.SS1.p2.5.m4.1.1" xref="S3.SS1.p2.5.m4.1.1.cmml"><mi id="S3.SS1.p2.5.m4.1.1.2.2" xref="S3.SS1.p2.5.m4.1.1.2.2.cmml">𝐅</mi><mi id="S3.SS1.p2.5.m4.1.1.3" xref="S3.SS1.p2.5.m4.1.1.3.cmml">𝐦𝐚𝐱</mi><mi id="S3.SS1.p2.5.m4.1.1.2.3" xref="S3.SS1.p2.5.m4.1.1.2.3.cmml">𝐜</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m4.1b"><apply id="S3.SS1.p2.5.m4.1.1.cmml" xref="S3.SS1.p2.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m4.1.1.1.cmml" xref="S3.SS1.p2.5.m4.1.1">subscript</csymbol><apply id="S3.SS1.p2.5.m4.1.1.2.cmml" xref="S3.SS1.p2.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m4.1.1.2.1.cmml" xref="S3.SS1.p2.5.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.5.m4.1.1.2.2.cmml" xref="S3.SS1.p2.5.m4.1.1.2.2">𝐅</ci><ci id="S3.SS1.p2.5.m4.1.1.2.3.cmml" xref="S3.SS1.p2.5.m4.1.1.2.3">𝐜</ci></apply><ci id="S3.SS1.p2.5.m4.1.1.3.cmml" xref="S3.SS1.p2.5.m4.1.1.3">𝐦𝐚𝐱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m4.1c">\mathbf{F^{c}_{max}}</annotation></semantics></math> denotes the sigmoid function, linear layer weights, the global average and max pooled features, respectively.
Spatial attention is computed via</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.2" class="ltx_Math" alttext="M_{s}(\mathbf{F})=\sigma(f^{7\times 7}([\mathbf{F^{c}_{avg}};\mathbf{F^{c}_{max}}]))," display="block"><semantics id="S3.E5.m1.2a"><mrow id="S3.E5.m1.2.2.1" xref="S3.E5.m1.2.2.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1" xref="S3.E5.m1.2.2.1.1.cmml"><mrow id="S3.E5.m1.2.2.1.1.3" xref="S3.E5.m1.2.2.1.1.3.cmml"><msub id="S3.E5.m1.2.2.1.1.3.2" xref="S3.E5.m1.2.2.1.1.3.2.cmml"><mi id="S3.E5.m1.2.2.1.1.3.2.2" xref="S3.E5.m1.2.2.1.1.3.2.2.cmml">M</mi><mi id="S3.E5.m1.2.2.1.1.3.2.3" xref="S3.E5.m1.2.2.1.1.3.2.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.3.1" xref="S3.E5.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.3.3.2" xref="S3.E5.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.3.3.2.1" xref="S3.E5.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">𝐅</mi><mo stretchy="false" id="S3.E5.m1.2.2.1.1.3.3.2.2" xref="S3.E5.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.2.2.1.1.2" xref="S3.E5.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.2.2.1.1.1" xref="S3.E5.m1.2.2.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.3.cmml">σ</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml"><msup id="S3.E5.m1.2.2.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.2.cmml">f</mi><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.cmml"><mn id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">×</mo><mn id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.3.cmml">7</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">[</mo><msubsup id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">𝐅</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">𝐚𝐯𝐠</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">𝐜</mi></msubsup><mo id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.4" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">;</mo><msubsup id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">𝐅</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3.cmml">𝐦𝐚𝐱</mi><mi id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">𝐜</mi></msubsup><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.5" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml">]</mo></mrow><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E5.m1.2.2.1.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.2.2.1.2" xref="S3.E5.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.2b"><apply id="S3.E5.m1.2.2.1.1.cmml" xref="S3.E5.m1.2.2.1"><eq id="S3.E5.m1.2.2.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.2"></eq><apply id="S3.E5.m1.2.2.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.3"><times id="S3.E5.m1.2.2.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.3.1"></times><apply id="S3.E5.m1.2.2.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.3.2.1.cmml" xref="S3.E5.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.3.2.2.cmml" xref="S3.E5.m1.2.2.1.1.3.2.2">𝑀</ci><ci id="S3.E5.m1.2.2.1.1.3.2.3.cmml" xref="S3.E5.m1.2.2.1.1.3.2.3">𝑠</ci></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">𝐅</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.2"></times><ci id="S3.E5.m1.2.2.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.3">𝜎</ci><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.2"></times><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.2">𝑓</ci><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3"><times id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.1"></times><cn type="integer" id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.2">7</cn><cn type="integer" id="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.3.3.3">7</cn></apply></apply><list id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2"><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.2">𝐅</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.3">𝐜</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">𝐚𝐯𝐠</ci></apply><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><apply id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2">superscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.2">𝐅</ci><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.2.3">𝐜</ci></apply><ci id="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.1.1.1.1.1.2.2.3">𝐦𝐚𝐱</ci></apply></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.2c">M_{s}(\mathbf{F})=\sigma(f^{7\times 7}([\mathbf{F^{c}_{avg}};\mathbf{F^{c}_{max}}])),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p2.7" class="ltx_p">where <math id="S3.SS1.p2.6.m1.2" class="ltx_Math" alttext="\mathbf{F^{c}_{avg}},\mathbf{F^{c}_{max}}" display="inline"><semantics id="S3.SS1.p2.6.m1.2a"><mrow id="S3.SS1.p2.6.m1.2.2.2" xref="S3.SS1.p2.6.m1.2.2.3.cmml"><msubsup id="S3.SS1.p2.6.m1.1.1.1.1" xref="S3.SS1.p2.6.m1.1.1.1.1.cmml"><mi id="S3.SS1.p2.6.m1.1.1.1.1.2.2" xref="S3.SS1.p2.6.m1.1.1.1.1.2.2.cmml">𝐅</mi><mi id="S3.SS1.p2.6.m1.1.1.1.1.3" xref="S3.SS1.p2.6.m1.1.1.1.1.3.cmml">𝐚𝐯𝐠</mi><mi id="S3.SS1.p2.6.m1.1.1.1.1.2.3" xref="S3.SS1.p2.6.m1.1.1.1.1.2.3.cmml">𝐜</mi></msubsup><mo id="S3.SS1.p2.6.m1.2.2.2.3" xref="S3.SS1.p2.6.m1.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p2.6.m1.2.2.2.2" xref="S3.SS1.p2.6.m1.2.2.2.2.cmml"><mi id="S3.SS1.p2.6.m1.2.2.2.2.2.2" xref="S3.SS1.p2.6.m1.2.2.2.2.2.2.cmml">𝐅</mi><mi id="S3.SS1.p2.6.m1.2.2.2.2.3" xref="S3.SS1.p2.6.m1.2.2.2.2.3.cmml">𝐦𝐚𝐱</mi><mi id="S3.SS1.p2.6.m1.2.2.2.2.2.3" xref="S3.SS1.p2.6.m1.2.2.2.2.2.3.cmml">𝐜</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m1.2b"><list id="S3.SS1.p2.6.m1.2.2.3.cmml" xref="S3.SS1.p2.6.m1.2.2.2"><apply id="S3.SS1.p2.6.m1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m1.1.1.1.1.1.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p2.6.m1.1.1.1.1.2.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m1.1.1.1.1.2.1.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p2.6.m1.1.1.1.1.2.2.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1.2.2">𝐅</ci><ci id="S3.SS1.p2.6.m1.1.1.1.1.2.3.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1.2.3">𝐜</ci></apply><ci id="S3.SS1.p2.6.m1.1.1.1.1.3.cmml" xref="S3.SS1.p2.6.m1.1.1.1.1.3">𝐚𝐯𝐠</ci></apply><apply id="S3.SS1.p2.6.m1.2.2.2.2.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m1.2.2.2.2.1.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p2.6.m1.2.2.2.2.2.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2">superscript</csymbol><ci id="S3.SS1.p2.6.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2.2.2">𝐅</ci><ci id="S3.SS1.p2.6.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2.2.3">𝐜</ci></apply><ci id="S3.SS1.p2.6.m1.2.2.2.2.3.cmml" xref="S3.SS1.p2.6.m1.2.2.2.2.3">𝐦𝐚𝐱</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m1.2c">\mathbf{F^{c}_{avg}},\mathbf{F^{c}_{max}}</annotation></semantics></math> are computed via channel-wise mean and max operations and <math id="S3.SS1.p2.7.m2.1" class="ltx_Math" alttext="f^{7\times 7}" display="inline"><semantics id="S3.SS1.p2.7.m2.1a"><msup id="S3.SS1.p2.7.m2.1.1" xref="S3.SS1.p2.7.m2.1.1.cmml"><mi id="S3.SS1.p2.7.m2.1.1.2" xref="S3.SS1.p2.7.m2.1.1.2.cmml">f</mi><mrow id="S3.SS1.p2.7.m2.1.1.3" xref="S3.SS1.p2.7.m2.1.1.3.cmml"><mn id="S3.SS1.p2.7.m2.1.1.3.2" xref="S3.SS1.p2.7.m2.1.1.3.2.cmml">7</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.7.m2.1.1.3.1" xref="S3.SS1.p2.7.m2.1.1.3.1.cmml">×</mo><mn id="S3.SS1.p2.7.m2.1.1.3.3" xref="S3.SS1.p2.7.m2.1.1.3.3.cmml">7</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m2.1b"><apply id="S3.SS1.p2.7.m2.1.1.cmml" xref="S3.SS1.p2.7.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m2.1.1.1.cmml" xref="S3.SS1.p2.7.m2.1.1">superscript</csymbol><ci id="S3.SS1.p2.7.m2.1.1.2.cmml" xref="S3.SS1.p2.7.m2.1.1.2">𝑓</ci><apply id="S3.SS1.p2.7.m2.1.1.3.cmml" xref="S3.SS1.p2.7.m2.1.1.3"><times id="S3.SS1.p2.7.m2.1.1.3.1.cmml" xref="S3.SS1.p2.7.m2.1.1.3.1"></times><cn type="integer" id="S3.SS1.p2.7.m2.1.1.3.2.cmml" xref="S3.SS1.p2.7.m2.1.1.3.2">7</cn><cn type="integer" id="S3.SS1.p2.7.m2.1.1.3.3.cmml" xref="S3.SS1.p2.7.m2.1.1.3.3">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m2.1c">f^{7\times 7}</annotation></semantics></math> denotes convolution with a kernel size of 7.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Auxiliary Scene Classification</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We utilize a simple scene classifier during inference time to adaptively select the most suitable set of fusion modules for the current setting, based on the intuition that the fusion module should attend different modalities under different scene/weather conditions. The scene classifier consists of a 2D adaptive average pooling operator followed by a fully connected layer, taking in the features from the RGB object detector encoder and outputs probabilities of possible scene categories. We choose RGB features as the input for scene classification due to their high variance in different scenes.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Scene-Specific Fusion</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We train different CBAM fusion modules for various scenes by considering scene-specific dataset splits (<a href="#S4.T2.st3" title="In Table 2 ‣ 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2(c)</span></a>). The number of parameters in different parts of the proposed fusion model is shown in <a href="#S3.T1" title="In 3.3 Scene-Specific Fusion ‣ 3 Approach ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">1</span></a>. The total number of trainable parameters per scene is significantly less than the total number of parameters, making our approach expeditious. During inference of scene-adaptive fusion, we use the CBAM fusion modules trained on the scene with the highest probability, as indicated by the scene classifier.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Parameter statistics of the proposed RGB-X fusion model.</span></figcaption>
<div id="S3.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:197.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(47.1pt,-26.9pt) scale(1.37309322738963,1.37309322738963) ;">
<table id="S3.T1.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r">
<span id="S3.T1.4.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
Network Part</th>
<th id="S3.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"># Parameters</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.1.2.1" class="ltx_tr">
<th id="S3.T1.4.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Backbones (RGB + X)</th>
<td id="S3.T1.4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">24.8 M</td>
</tr>
<tr id="S3.T1.4.1.3.2" class="ltx_tr">
<th id="S3.T1.4.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">BiFPNs (RGB + X)</th>
<td id="S3.T1.4.1.3.2.2" class="ltx_td ltx_align_center">0.12 M</td>
</tr>
<tr id="S3.T1.4.1.4.3" class="ltx_tr">
<th id="S3.T1.4.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Detection Head</th>
<td id="S3.T1.4.1.4.3.2" class="ltx_td ltx_align_center">1.60 M</td>
</tr>
<tr id="S3.T1.4.1.5.4" class="ltx_tr">
<th id="S3.T1.4.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Fusion Modules (one per fusion level)</th>
<td id="S3.T1.4.1.5.4.2" class="ltx_td ltx_align_center">0.21 M</td>
</tr>
<tr id="S3.T1.4.1.6.5" class="ltx_tr">
<th id="S3.T1.4.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Total</th>
<td id="S3.T1.4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_t">26.7 M</td>
</tr>
<tr id="S3.T1.4.1.7.6" class="ltx_tr">
<th id="S3.T1.4.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Total Trainable (per scene)</th>
<td id="S3.T1.4.1.7.6.2" class="ltx_td ltx_align_center">0.21 M</td>
</tr>
<tr id="S3.T1.4.1.8.7" class="ltx_tr">
<th id="S3.T1.4.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S3.T1.4.1.8.7.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S3.T1.4.1.8.7.2" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implementation and Training Details</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.6" class="ltx_p">Our code is written in PyTorch and based on the EfficientDet<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/rwightman/efficientdet-pytorch" title="" class="ltx_ref ltx_href">https://github.com/rwightman/efficientdet-pytorch</a></span></span></span> repository. Pretrained RGB detectors on COCO dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> were taken from the same repository. All other networks were trained using the Adam optimizer, a batch size of 8, an initial learning rate of 1e<sup id="S4.SS1.p1.6.1" class="ltx_sup"><span id="S4.SS1.p1.6.1.1" class="ltx_text ltx_font_italic">-3</span></sup> with an exponential learning rate schedule, and a <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msub id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">L</mi><mn id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝐿</ci><cn type="integer" id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">L_{2}</annotation></semantics></math> weight decay of 1e<sup id="S4.SS1.p1.6.2" class="ltx_sup"><span id="S4.SS1.p1.6.2.1" class="ltx_text ltx_font_italic">-3</span></sup>. The maximum number of epochs is set to <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mn id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><cn type="integer" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">300</annotation></semantics></math> and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mn id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><cn type="integer" id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">50</annotation></semantics></math> for pretraining single modality networks and fine-tuning RGB-X fusion networks, respectively. The scene classifier is trained for <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mn id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><cn type="integer" id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">50</annotation></semantics></math> epochs while the RGB backbone remains frozen. Networks were trained using an Nvidia P100 GPU.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Datasets</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We use the following RGB-X datasets to validate our method and compare against state-of-the-art baselines. The train/val/test split statistics we use for various datasets and scene conditions are shown in <a href="#S4.T2.st3" title="In Table 2 ‣ 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2(c)</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">Dataset scene and train/val/test splits in our experiments.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T2.st1" class="ltx_table ltx_figure_panel">
<div id="S4.T2.st1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:325.2pt;height:158.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(33.6pt,-16.4pt) scale(1.26038548714215,1.26038548714215) ;">
<table id="S4.T2.st1.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.st1.2.1.1.1" class="ltx_tr">
<th id="S4.T2.st1.2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" rowspan="3">
<span id="S4.T2.st1.2.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T2.st1.2.1.1.1.1.2" class="ltx_text">Split</span>
</th>
<td id="S4.T2.st1.2.1.1.1.2" class="ltx_td ltx_align_center" colspan="6">Scene Condition</td>
</tr>
<tr id="S4.T2.st1.2.1.2.2" class="ltx_tr">
<td id="S4.T2.st1.2.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Clear</td>
<td id="S4.T2.st1.2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Fog</td>
<td id="S4.T2.st1.2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" colspan="2">Snow</td>
</tr>
<tr id="S4.T2.st1.2.1.3.3" class="ltx_tr">
<td id="S4.T2.st1.2.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Day</td>
<td id="S4.T2.st1.2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Night</td>
<td id="S4.T2.st1.2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Day</td>
<td id="S4.T2.st1.2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Night</td>
<td id="S4.T2.st1.2.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Day</td>
<td id="S4.T2.st1.2.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">Night</td>
</tr>
<tr id="S4.T2.st1.2.1.4.4" class="ltx_tr">
<th id="S4.T2.st1.2.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Train</th>
<td id="S4.T2.st1.2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2147</td>
<td id="S4.T2.st1.2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1572</td>
<td id="S4.T2.st1.2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">712</td>
<td id="S4.T2.st1.2.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">438</td>
<td id="S4.T2.st1.2.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1365</td>
<td id="S4.T2.st1.2.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t">1455</td>
</tr>
<tr id="S4.T2.st1.2.1.5.5" class="ltx_tr">
<th id="S4.T2.st1.2.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Val</th>
<td id="S4.T2.st1.2.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">537</td>
<td id="S4.T2.st1.2.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">393</td>
<td id="S4.T2.st1.2.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">438</td>
<td id="S4.T2.st1.2.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">110</td>
<td id="S4.T2.st1.2.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">342</td>
<td id="S4.T2.st1.2.1.5.5.7" class="ltx_td ltx_align_center">364</td>
</tr>
<tr id="S4.T2.st1.2.1.6.6" class="ltx_tr">
<th id="S4.T2.st1.2.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Test</th>
<td id="S4.T2.st1.2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">895</td>
<td id="S4.T2.st1.2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">655</td>
<td id="S4.T2.st1.2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">297</td>
<td id="S4.T2.st1.2.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r">183</td>
<td id="S4.T2.st1.2.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r">570</td>
<td id="S4.T2.st1.2.1.6.6.7" class="ltx_td ltx_align_center">607</td>
</tr>
<tr id="S4.T2.st1.2.1.7.7" class="ltx_tr">
<th id="S4.T2.st1.2.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T2.st1.2.1.7.7.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T2.st1.2.1.7.7.2" class="ltx_td"></td>
<td id="S4.T2.st1.2.1.7.7.3" class="ltx_td"></td>
<td id="S4.T2.st1.2.1.7.7.4" class="ltx_td"></td>
<td id="S4.T2.st1.2.1.7.7.5" class="ltx_td"></td>
<td id="S4.T2.st1.2.1.7.7.6" class="ltx_td"></td>
<td id="S4.T2.st1.2.1.7.7.7" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.st1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.T2.st1.4.2" class="ltx_text" style="font-size:90%;">Seeing Through Fog</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T2.st2" class="ltx_table ltx_figure_panel">
<div id="S4.T2.st2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:379.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(155.1pt,-135.6pt) scale(3.51108743840432,3.51108743840432) ;">
<table id="S4.T2.st2.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.st2.2.1.1.1" class="ltx_tr">
<th id="S4.T2.st2.2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2">
<span id="S4.T2.st2.2.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T2.st2.2.1.1.1.1.2" class="ltx_text">Split</span>
</th>
<th id="S4.T2.st2.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Scene Condition</th>
</tr>
<tr id="S4.T2.st2.2.1.2.2" class="ltx_tr">
<th id="S4.T2.st2.2.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Day</th>
<th id="S4.T2.st2.2.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Night</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.st2.2.1.3.1" class="ltx_tr">
<th id="S4.T2.st2.2.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Train</th>
<td id="S4.T2.st2.2.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3476</td>
<td id="S4.T2.st2.2.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">653</td>
</tr>
<tr id="S4.T2.st2.2.1.4.2" class="ltx_tr">
<th id="S4.T2.st2.2.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Val</th>
<td id="S4.T2.st2.2.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T2.st2.2.1.4.2.3" class="ltx_td ltx_align_center">—</td>
</tr>
<tr id="S4.T2.st2.2.1.5.3" class="ltx_tr">
<th id="S4.T2.st2.2.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Test</th>
<td id="S4.T2.st2.2.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r">702</td>
<td id="S4.T2.st2.2.1.5.3.3" class="ltx_td ltx_align_center">311</td>
</tr>
<tr id="S4.T2.st2.2.1.6.4" class="ltx_tr">
<th id="S4.T2.st2.2.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T2.st2.2.1.6.4.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T2.st2.2.1.6.4.2" class="ltx_td"></td>
<td id="S4.T2.st2.2.1.6.4.3" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.st2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.T2.st2.4.2" class="ltx_text" style="font-size:90%;">FLIR Aligned <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T2.st3" class="ltx_table ltx_figure_panel">
<div id="S4.T2.st3.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:206.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(103.6pt,-49.5pt) scale(1.915844013515,1.915844013515) ;">
<table id="S4.T2.st3.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.st3.4.1.1.1" class="ltx_tr">
<th id="S4.T2.st3.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" rowspan="2">
<span id="S4.T2.st3.4.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T2.st3.4.1.1.1.1.2" class="ltx_text">Split</span>
</th>
<td id="S4.T2.st3.4.1.1.1.2" class="ltx_td ltx_align_center" colspan="4">Scene Condition</td>
</tr>
<tr id="S4.T2.st3.4.1.2.2" class="ltx_tr">
<td id="S4.T2.st3.4.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Day</td>
<td id="S4.T2.st3.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Night</td>
<td id="S4.T2.st3.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Overcast</td>
<td id="S4.T2.st3.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Challenge</td>
</tr>
<tr id="S4.T2.st3.4.1.3.3" class="ltx_tr">
<th id="S4.T2.st3.4.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Train</th>
<td id="S4.T2.st3.4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">992</td>
<td id="S4.T2.st3.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">488</td>
<td id="S4.T2.st3.4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">746</td>
<td id="S4.T2.st3.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">484</td>
</tr>
<tr id="S4.T2.st3.4.1.4.4" class="ltx_tr">
<th id="S4.T2.st3.4.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Val</th>
<td id="S4.T2.st3.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r">216</td>
<td id="S4.T2.st3.4.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r">108</td>
<td id="S4.T2.st3.4.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">190</td>
<td id="S4.T2.st3.4.1.4.4.5" class="ltx_td ltx_align_center">122</td>
</tr>
<tr id="S4.T2.st3.4.1.5.5" class="ltx_tr">
<th id="S4.T2.st3.4.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Test</th>
<td id="S4.T2.st3.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">323</td>
<td id="S4.T2.st3.4.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">140</td>
<td id="S4.T2.st3.4.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">205</td>
<td id="S4.T2.st3.4.1.5.5.5" class="ltx_td ltx_align_center">156</td>
</tr>
<tr id="S4.T2.st3.4.1.6.6" class="ltx_tr">
<th id="S4.T2.st3.4.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T2.st3.4.1.6.6.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T2.st3.4.1.6.6.2" class="ltx_td"></td>
<td id="S4.T2.st3.4.1.6.6.3" class="ltx_td"></td>
<td id="S4.T2.st3.4.1.6.6.4" class="ltx_td"></td>
<td id="S4.T2.st3.4.1.6.6.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.st3.6.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.T2.st3.2.1" class="ltx_text" style="font-size:90%;">M<sup id="S4.T2.st3.2.1.1" class="ltx_sup">3</sup>FD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></span></figcaption>
</figure>
</div>
</div>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">FLIR Aligned:</span> The FLIR Aligned dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> consists of 5,142 aligned RGB-thermal image pairs from the original FLIR ADAS object detection dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. This derived dataset consists of bounding box annotations for <span id="S4.SS2.p2.1.2" class="ltx_text ltx_font_italic">person</span>, <span id="S4.SS2.p2.1.3" class="ltx_text ltx_font_italic">bicycle</span> and <span id="S4.SS2.p2.1.4" class="ltx_text ltx_font_italic">car</span> classes. The provided train and test splits contain 4,129 and 1,013 image pairs, respectively. We manually divided them into <em id="S4.SS2.p2.1.5" class="ltx_emph ltx_font_italic">day</em> and <em id="S4.SS2.p2.1.6" class="ltx_emph ltx_font_italic">night</em> scene categories based on the appearance.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.2" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">M<sup id="S4.SS2.p3.1.1.1" class="ltx_sup"><span id="S4.SS2.p3.1.1.1.1" class="ltx_text ltx_font_medium">3</span></sup>FD:</span> The M<sup id="S4.SS2.p3.2.2" class="ltx_sup">3</sup>FD object detection dataset consists of 4,200 coregistered, time-synchronized RGB-thermal image pairs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Bounding box annotations for <span id="S4.SS2.p3.2.3" class="ltx_text ltx_font_italic">people, car, bus, motorcycle, truck</span> and <span id="S4.SS2.p3.2.4" class="ltx_text ltx_font_italic">lamp</span> classes are provided. The data is also split into four scene categories <span id="S4.SS2.p3.2.5" class="ltx_text ltx_font_italic">(day, night, overcast, challenge)</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> according to environment characteristics. We use the train/val/test splits provided by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> due to the unavailability in the original dataset.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Seeing Through Fog:</span> The Seeing Through Fog (STF) multispectral object detection dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> consists of synchronized RGB/gated/LiDAR/radar/unaligned thermal data for a variety of weather conditions. The dataset also provides bounding box annotations for <span id="S4.SS2.p4.1.2" class="ltx_text ltx_font_italic">pedestrian</span>, <span id="S4.SS2.p4.1.3" class="ltx_text ltx_font_italic">truck</span>, <span id="S4.SS2.p4.1.4" class="ltx_text ltx_font_italic">car</span>, <span id="S4.SS2.p4.1.5" class="ltx_text ltx_font_italic">cyclist</span>, and <span id="S4.SS2.p4.1.6" class="ltx_text ltx_font_italic">dontcare</span> classes. For training our scene-adaptive model, we considered the scene splits in <a href="#S4.T2.st1" title="In Table 2 ‣ 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2(a)</span></a> due to overlaps in original splits. For evaluation, we follow the original scene splits including <span id="S4.SS2.p4.1.7" class="ltx_text ltx_font_italic">clear</span>, <span id="S4.SS2.p4.1.8" class="ltx_text ltx_font_italic">light fog</span>, <span id="S4.SS2.p4.1.9" class="ltx_text ltx_font_italic">dense fog</span>, and <span id="S4.SS2.p4.1.10" class="ltx_text ltx_font_italic">snow/rain</span>. We use pairs of aligned 12-bit RGB and 10-bit gated images throughout this work.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/03353_rgb_agn_anno.jpg" id="S4.F3.sf1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/03353_rgb_agn_big.jpg" id="S4.F3.sf1.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00465_rgb_agn_anno.jpg" id="S4.F3.sf1.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00465_rgb_agn_big.jpg" id="S4.F3.sf1.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01871_rgb_agn_anno.jpg" id="S4.F3.sf1.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01871_rgb_agn_big.jpg" id="S4.F3.sf1.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.4.2" class="ltx_text" style="font-size:80%;">Scene-Agnostic CBAM</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/03353_rgb_ada_anno.jpg" id="S4.F3.sf2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/03353_rgb_ada_big.jpg" id="S4.F3.sf2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00465_rgb_ada_anno.jpg" id="S4.F3.sf2.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00465_rgb_ada_big.jpg" id="S4.F3.sf2.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01871_rgb_ada_anno.jpg" id="S4.F3.sf2.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01871_rgb_ada_big.jpg" id="S4.F3.sf2.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="150" height="113" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.4.2" class="ltx_text" style="font-size:80%;">Scene-Adaptive CBAM</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.5.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.2.1" class="ltx_text" style="font-size:90%;">Qualitative detection results on M<sup id="S4.F3.2.1.1" class="ltx_sup">3</sup>FD dataset. Zoomed-in images (yellow rectangle) are shown on the right of the original images for better visualization.</span></figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09705_rgb_gt.jpg" id="S4.F4.sf1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09757_rgb_gt.jpg" id="S4.F4.sf1.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09780_rgb_gt.jpg" id="S4.F4.sf1.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08894_rgb_gt.jpg" id="S4.F4.sf1.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08906_rgb_gt.jpg" id="S4.F4.sf1.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09630_rgb_gt.jpg" id="S4.F4.sf1.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F4.sf1.4.2" class="ltx_text" style="font-size:80%;">RGB with GT</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09705_thermal_gt.jpg" id="S4.F4.sf2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09757_thermal_gt.jpg" id="S4.F4.sf2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09780_thermal_gt.jpg" id="S4.F4.sf2.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08894_thermal_gt.jpg" id="S4.F4.sf2.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08906_thermal_gt.jpg" id="S4.F4.sf2.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09630_thermal_gt.jpg" id="S4.F4.sf2.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F4.sf2.4.2" class="ltx_text" style="font-size:80%;">Thermal with GT</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09705_rgb_agn.jpg" id="S4.F4.sf3.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09757_rgb_agn.jpg" id="S4.F4.sf3.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09780_rgb_agn.jpg" id="S4.F4.sf3.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08894_rgb_agn.jpg" id="S4.F4.sf3.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08906_rgb_agn.jpg" id="S4.F4.sf3.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09630_rgb_agn.jpg" id="S4.F4.sf3.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F4.sf3.4.2" class="ltx_text" style="font-size:80%;">Agnostic CBAM</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09705_cam_agn.jpg" id="S4.F4.sf4.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="239" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09757_cam_agn.jpg" id="S4.F4.sf4.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="241" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09780_cam_agn.jpg" id="S4.F4.sf4.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="241" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08894_cam_agn.jpg" id="S4.F4.sf4.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="239" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08906_cam_agn.jpg" id="S4.F4.sf4.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="241" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09630_cam_agn.jpg" id="S4.F4.sf4.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F4.sf4.4.2" class="ltx_text" style="font-size:80%;">CAM Visual.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F4.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09705_rgb_ada.jpg" id="S4.F4.sf5.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09757_rgb_ada.jpg" id="S4.F4.sf5.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09780_rgb_ada.jpg" id="S4.F4.sf5.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08894_rgb_ada.jpg" id="S4.F4.sf5.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08906_rgb_ada.jpg" id="S4.F4.sf5.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09630_rgb_ada.jpg" id="S4.F4.sf5.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="240" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf5.3.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S4.F4.sf5.4.2" class="ltx_text" style="font-size:80%;">Adaptive CBAM</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F4.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09705_cam_ada.jpg" id="S4.F4.sf6.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="241" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09757_cam_ada.jpg" id="S4.F4.sf6.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="239" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09780_cam_ada.jpg" id="S4.F4.sf6.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="239" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08894_cam_ada.jpg" id="S4.F4.sf6.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="239" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_08906_cam_ada.jpg" id="S4.F4.sf6.g5" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="241" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_flir/FLIR_09630_cam_ada.jpg" id="S4.F4.sf6.g6" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="239" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf6.3.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S4.F4.sf6.4.2" class="ltx_text" style="font-size:80%;">CAM Visual.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.4.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.5.2" class="ltx_text" style="font-size:90%;">Qualitative detection results on FLIR Aligned dataset with <em id="S4.F4.5.2.1" class="ltx_emph ltx_font_italic">day</em> examples in the upper rows and <em id="S4.F4.5.2.2" class="ltx_emph ltx_font_italic">night</em> examples in the lower rows. The input RGB and thermal images are overlaid with ground truth (GT) bounding boxes. For each fusion model, we plot the detected bounding boxes and Eigen-CAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> visualizations of the CBAM fusion module. (d) and (f) are visualizations of (c) and (e), respectively.</span></figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-08_13-05-10_01100_rgb_gt.jpg" id="S4.F5.sf1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-08_13-05-10_01100_gated_gt.jpg" id="S4.F5.sf1.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-08_13-05-10_01100_rgb_agn.jpg" id="S4.F5.sf1.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-08_13-05-10_01100_rgb_ada.jpg" id="S4.F5.sf1.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F5.sf1.4.2" class="ltx_text" style="font-size:80%;">Clear-Day</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-10_18-05-49_00000_rgb_gt.jpg" id="S4.F5.sf2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-10_18-05-49_00000_gated_gt.jpg" id="S4.F5.sf2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-10_18-05-49_00000_rgb_agn.jpg" id="S4.F5.sf2.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-10_18-05-49_00000_rgb_ada.jpg" id="S4.F5.sf2.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F5.sf2.4.2" class="ltx_text" style="font-size:80%;">Clear-Night</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-10-29_14-50-14_01700_rgb_gt.jpg" id="S4.F5.sf3.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-10-29_14-50-14_01700_gated_gt.jpg" id="S4.F5.sf3.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-10-29_14-50-14_01700_rgb_agn.jpg" id="S4.F5.sf3.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-10-29_14-50-14_01700_rgb_ada.jpg" id="S4.F5.sf3.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F5.sf3.4.2" class="ltx_text" style="font-size:80%;">Fog-Day</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-12_15-21-22_02000_rgb_gt.jpg" id="S4.F5.sf4.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-12_15-21-22_02000_gated_gt.jpg" id="S4.F5.sf4.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-12_15-21-22_02000_rgb_agn.jpg" id="S4.F5.sf4.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-12_15-21-22_02000_rgb_ada.jpg" id="S4.F5.sf4.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F5.sf4.4.2" class="ltx_text" style="font-size:80%;">Fog-Night</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-12_10-00-09_00100_rgb_gt.jpg" id="S4.F5.sf5.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-12_10-00-09_00100_gated_gt.jpg" id="S4.F5.sf5.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-12_10-00-09_00100_rgb_agn.jpg" id="S4.F5.sf5.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-02-12_10-00-09_00100_rgb_ada.jpg" id="S4.F5.sf5.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf5.3.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S4.F5.sf5.4.2" class="ltx_text" style="font-size:80%;">Snow-Day</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F5.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-17_06-30-54_15500_rgb_gt.jpg" id="S4.F5.sf6.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-17_06-30-54_15500_gated_gt.jpg" id="S4.F5.sf6.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-17_06-30-54_15500_rgb_agn.jpg" id="S4.F5.sf6.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_stf/2018-12-17_06-30-54_15500_rgb_ada.jpg" id="S4.F5.sf6.g4" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="180" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.sf6.3.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S4.F5.sf6.4.2" class="ltx_text" style="font-size:80%;">Snow-Night</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Object detection results on STF dataset in various scene conditions. From top to bottom: RGB images, gated images, scene-agnostic CBAM detections, and scene-adaptive CBAM detections. RGB and gated images are overlaid with ground truth bounding boxes.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Performance Evaluation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this section, we validate the proposed method on the three datasets for RGB-X object detection. Auxiliary scene classification is employed to adaptively select suitable fusion modules per input image.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Auxiliary Scene Classification:</span> We train our scene classifiers using ground truth scene labels provided in <a href="#S4.T2.st3" title="In Table 2 ‣ 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">2(c)</span></a> by minimizing the standard cross-entropy loss for image classification. Top-1 accuracy of the scene classification is reported in <a href="#S4.T3" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">3</span></a>, where the classifier attains high accuracy for categorizing various scenes in M<sup id="S4.SS3.p2.1.2" class="ltx_sup">3</sup>FD, FLIR and STF-Clear (the subset of STF dataset consists of <em id="S4.SS3.p2.1.3" class="ltx_emph ltx_font_italic">clear-day</em> and <em id="S4.SS3.p2.1.4" class="ltx_emph ltx_font_italic">clear-night</em>) datasets. The classifier does not perform as high for STF-Full, possibly because a large portion of <em id="S4.SS3.p2.1.5" class="ltx_emph ltx_font_italic">snow</em> images are also foggy and confused the classifier.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.5.2.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.2.1" class="ltx_text" style="font-size:90%;">Top-1 Accuracy (<math id="S4.T3.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T3.2.1.m1.1b"><mo id="S4.T3.2.1.m1.1.1" xref="S4.T3.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.1.m1.1c"><csymbol cd="latexml" id="S4.T3.2.1.m1.1.1.cmml" xref="S4.T3.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.1.m1.1d">\%</annotation></semantics></math>) of our scene classifier on the test set of three datasets.</span></figcaption>
<div id="S4.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:162.6pt;height:55.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.9pt,8.4pt) scale(0.765831398509191,0.765831398509191) ;">
<table id="S4.T3.3.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.3.1.1" class="ltx_tr">
<td id="S4.T3.3.1.1.2" class="ltx_td ltx_align_center ltx_border_r" rowspan="2">
<span id="S4.T3.3.1.1.2.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T3.3.1.1.2.2" class="ltx_text">Dataset</span>
</td>
<td id="S4.T3.3.1.1.1" class="ltx_td ltx_align_center ltx_border_r" rowspan="2"><span id="S4.T3.3.1.1.1.1" class="ltx_text">M<sup id="S4.T3.3.1.1.1.1.1" class="ltx_sup">3</sup>FD</span></td>
<td id="S4.T3.3.1.1.3" class="ltx_td ltx_align_center ltx_border_r" rowspan="2"><span id="S4.T3.3.1.1.3.1" class="ltx_text">FLIR</span></td>
<td id="S4.T3.3.1.1.4" class="ltx_td ltx_align_center" colspan="2">Seeing Through Fog</td>
</tr>
<tr id="S4.T3.3.1.2.1" class="ltx_tr">
<td id="S4.T3.3.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Clear</td>
<td id="S4.T3.3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Full</td>
</tr>
<tr id="S4.T3.3.1.3.2" class="ltx_tr">
<td id="S4.T3.3.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy</td>
<td id="S4.T3.3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.42</td>
<td id="S4.T3.3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.35</td>
<td id="S4.T3.3.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.01</td>
<td id="S4.T3.3.1.3.2.5" class="ltx_td ltx_align_center ltx_border_t">77.02</td>
</tr>
<tr id="S4.T3.3.1.4.3" class="ltx_tr">
<td id="S4.T3.3.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T3.3.1.4.3.1.1" class="ltx_ERROR undefined">\hlineB</span>3</td>
<td id="S4.T3.3.1.4.3.2" class="ltx_td"></td>
<td id="S4.T3.3.1.4.3.3" class="ltx_td"></td>
<td id="S4.T3.3.1.4.3.4" class="ltx_td"></td>
<td id="S4.T3.3.1.4.3.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.9.2.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.2.1" class="ltx_text" style="font-size:90%;">Object detection results (mAP@0.5) and speed (s) on M<sup id="S4.T4.2.1.1" class="ltx_sup">3</sup>FD dataset. Due to the difference in scene splits between baselines and our models, only results on the <em id="S4.T4.2.1.2" class="ltx_emph ltx_font_italic">full</em> test set are comparable across all methods.</span></figcaption>
<div id="S4.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:91.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-105.1pt,44.3pt) scale(0.507688869873941,0.507688869873941) ;">
<table id="S4.T4.4.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.4.2.3.1" class="ltx_tr">
<th id="S4.T4.4.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" rowspan="2">
<span id="S4.T4.4.2.3.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T4.4.2.3.1.1.2" class="ltx_text">Method</span>
</th>
<td id="S4.T4.4.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r" colspan="5">Test Scene</td>
<td id="S4.T4.4.2.3.1.3" class="ltx_td ltx_align_center" rowspan="2"><span id="S4.T4.4.2.3.1.3.1" class="ltx_text">
<span id="S4.T4.4.2.3.1.3.1.1" class="ltx_inline-block ltx_align_center">
<span id="S4.T4.4.2.3.1.3.1.1.1" class="ltx_p">Inference</span>
<span id="S4.T4.4.2.3.1.3.1.1.2" class="ltx_p">Speed (s)</span>
</span></span></td>
</tr>
<tr id="S4.T4.4.2.4.2" class="ltx_tr">
<td id="S4.T4.4.2.4.2.1" class="ltx_td ltx_align_center ltx_border_t">Day</td>
<td id="S4.T4.4.2.4.2.2" class="ltx_td ltx_align_center ltx_border_t">Night</td>
<td id="S4.T4.4.2.4.2.3" class="ltx_td ltx_align_center ltx_border_t">Overcast</td>
<td id="S4.T4.4.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Challenge</td>
<td id="S4.T4.4.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Full</td>
</tr>
<tr id="S4.T4.4.2.5.3" class="ltx_tr">
<th id="S4.T4.4.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T4.4.2.5.3.1.1" class="ltx_ERROR undefined">\hlineB</span>3
RGB only</th>
<td id="S4.T4.4.2.5.3.2" class="ltx_td ltx_align_center">71.59</td>
<td id="S4.T4.4.2.5.3.3" class="ltx_td ltx_align_center">91.06</td>
<td id="S4.T4.4.2.5.3.4" class="ltx_td ltx_align_center">81.55</td>
<td id="S4.T4.4.2.5.3.5" class="ltx_td ltx_align_center ltx_border_r">80.03</td>
<td id="S4.T4.4.2.5.3.6" class="ltx_td ltx_align_center ltx_border_r">77.79</td>
<td id="S4.T4.4.2.5.3.7" class="ltx_td ltx_align_center">0.016</td>
</tr>
<tr id="S4.T4.4.2.6.4" class="ltx_tr">
<th id="S4.T4.4.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Thermal only</th>
<td id="S4.T4.4.2.6.4.2" class="ltx_td ltx_align_center">65.68</td>
<td id="S4.T4.4.2.6.4.3" class="ltx_td ltx_align_center">89.17</td>
<td id="S4.T4.4.2.6.4.4" class="ltx_td ltx_align_center">79.66</td>
<td id="S4.T4.4.2.6.4.5" class="ltx_td ltx_align_center ltx_border_r">76.39</td>
<td id="S4.T4.4.2.6.4.6" class="ltx_td ltx_align_center ltx_border_r">74.64</td>
<td id="S4.T4.4.2.6.4.7" class="ltx_td ltx_align_center">0.016</td>
</tr>
<tr id="S4.T4.3.1.1" class="ltx_tr">
<th id="S4.T4.3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T4.3.1.1.2.1" class="ltx_ERROR undefined">\hlineB</span>3
U2F <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</th>
<td id="S4.T4.3.1.1.3" class="ltx_td ltx_align_center">73.80</td>
<td id="S4.T4.3.1.1.4" class="ltx_td ltx_align_center">86.8</td>
<td id="S4.T4.3.1.1.5" class="ltx_td ltx_align_center">73.10</td>
<td id="S4.T4.3.1.1.6" class="ltx_td ltx_align_center ltx_border_r">97.6</td>
<td id="S4.T4.3.1.1.7" class="ltx_td ltx_align_center ltx_border_r">77.5</td>
<td id="S4.T4.3.1.1.1" class="ltx_td ltx_align_center">0.129<sup id="S4.T4.3.1.1.1.1" class="ltx_sup"><span id="S4.T4.3.1.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
</tr>
<tr id="S4.T4.4.2.2" class="ltx_tr">
<th id="S4.T4.4.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TarDAL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</th>
<td id="S4.T4.4.2.2.3" class="ltx_td ltx_align_center">74.50</td>
<td id="S4.T4.4.2.2.4" class="ltx_td ltx_align_center">89.30</td>
<td id="S4.T4.4.2.2.5" class="ltx_td ltx_align_center">74.10</td>
<td id="S4.T4.4.2.2.6" class="ltx_td ltx_align_center ltx_border_r">98.30</td>
<td id="S4.T4.4.2.2.7" class="ltx_td ltx_align_center ltx_border_r">77.80</td>
<td id="S4.T4.4.2.2.1" class="ltx_td ltx_align_center">0.047<sup id="S4.T4.4.2.2.1.1" class="ltx_sup"><span id="S4.T4.4.2.2.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
</tr>
<tr id="S4.T4.4.2.7.5" class="ltx_tr">
<th id="S4.T4.4.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">EAEFNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</th>
<td id="S4.T4.4.2.7.5.2" class="ltx_td ltx_align_center">78.30</td>
<td id="S4.T4.4.2.7.5.3" class="ltx_td ltx_align_center">89.50</td>
<td id="S4.T4.4.2.7.5.4" class="ltx_td ltx_align_center">78.60</td>
<td id="S4.T4.4.2.7.5.5" class="ltx_td ltx_align_center ltx_border_r">97.90</td>
<td id="S4.T4.4.2.7.5.6" class="ltx_td ltx_align_center ltx_border_r">80.10</td>
<td id="S4.T4.4.2.7.5.7" class="ltx_td ltx_align_center">—</td>
</tr>
<tr id="S4.T4.4.2.8.6" class="ltx_tr">
<th id="S4.T4.4.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Scene-Agnostic CBAM <span id="S4.T4.4.2.8.6.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</th>
<td id="S4.T4.4.2.8.6.2" class="ltx_td ltx_align_center ltx_border_t">74.53</td>
<td id="S4.T4.4.2.8.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.4.2.8.6.3.1" class="ltx_text ltx_font_bold">93.09</span></td>
<td id="S4.T4.4.2.8.6.4" class="ltx_td ltx_align_center ltx_border_t">84.11</td>
<td id="S4.T4.4.2.8.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">81.06</td>
<td id="S4.T4.4.2.8.6.6" class="ltx_td ltx_align_center ltx_border_r">80.46</td>
<td id="S4.T4.4.2.8.6.7" class="ltx_td ltx_align_center">0.028</td>
</tr>
<tr id="S4.T4.4.2.9.7" class="ltx_tr">
<th id="S4.T4.4.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Scene-Adaptive CBAM <span id="S4.T4.4.2.9.7.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</th>
<td id="S4.T4.4.2.9.7.2" class="ltx_td ltx_align_center"><span id="S4.T4.4.2.9.7.2.1" class="ltx_text ltx_font_bold">75.92</span></td>
<td id="S4.T4.4.2.9.7.3" class="ltx_td ltx_align_center">92.55</td>
<td id="S4.T4.4.2.9.7.4" class="ltx_td ltx_align_center"><span id="S4.T4.4.2.9.7.4.1" class="ltx_text ltx_font_bold">85.14</span></td>
<td id="S4.T4.4.2.9.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.4.2.9.7.5.1" class="ltx_text ltx_font_bold">82.72</span></td>
<td id="S4.T4.4.2.9.7.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.4.2.9.7.6.1" class="ltx_text ltx_font_bold">81.46</span></td>
<td id="S4.T4.4.2.9.7.7" class="ltx_td ltx_align_center">0.032</td>
</tr>
<tr id="S4.T4.4.2.10.8" class="ltx_tr">
<th id="S4.T4.4.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T4.4.2.10.8.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T4.4.2.10.8.2" class="ltx_td"></td>
<td id="S4.T4.4.2.10.8.3" class="ltx_td"></td>
<td id="S4.T4.4.2.10.8.4" class="ltx_td"></td>
<td id="S4.T4.4.2.10.8.5" class="ltx_td"></td>
<td id="S4.T4.4.2.10.8.6" class="ltx_td"></td>
<td id="S4.T4.4.2.10.8.7" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><sup id="S4.T4.10.1" class="ltx_sup"><span id="S4.T4.10.1.1" class="ltx_text ltx_font_italic">†</span></sup> Includes image fusion and object detection inference time.</figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.4.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.5.2" class="ltx_text" style="font-size:90%;">Object detection results and speed (s) on FLIR Aligned dataset. AP@0.5 for each object category is reported.</span></figcaption>
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:108.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-151.6pt,75.6pt) scale(0.416972769581612,0.416972769581612) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T5.1.1.1.2.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T5.1.1.1.2.2" class="ltx_text">Method</span>
</td>
<td id="S4.T5.1.1.1.3" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.1.3.1" class="ltx_text">Person</span></td>
<td id="S4.T5.1.1.1.4" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.1.4.1" class="ltx_text">Bicycle</span></td>
<td id="S4.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.1.1.5.1" class="ltx_text">Car</span></td>
<td id="S4.T5.1.1.1.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.1.6.1" class="ltx_text">mAP@0.5</span></td>
<td id="S4.T5.1.1.1.7" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.1.7.1" class="ltx_text">mAP@0.75</span></td>
<td id="S4.T5.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.1.1.1.1" class="ltx_text">mAP<sup id="S4.T5.1.1.1.1.1.1" class="ltx_sup"><span id="S4.T5.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup></span></td>
<td id="S4.T5.1.1.1.8" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.1.8.1" class="ltx_text">
<span id="S4.T5.1.1.1.8.1.1" class="ltx_inline-block ltx_align_center">
<span id="S4.T5.1.1.1.8.1.1.1" class="ltx_p">Inference</span>
<span id="S4.T5.1.1.1.8.1.1.2" class="ltx_p">Speed (s)</span>
</span></span></td>
</tr>
<tr id="S4.T5.1.1.2.1" class="ltx_tr">
<td id="S4.T5.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T5.1.1.2.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
RGB only</td>
<td id="S4.T5.1.1.2.1.2" class="ltx_td ltx_align_center">60.79</td>
<td id="S4.T5.1.1.2.1.3" class="ltx_td ltx_align_center">37.25</td>
<td id="S4.T5.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r">73.94</td>
<td id="S4.T5.1.1.2.1.5" class="ltx_td ltx_align_center">57.32</td>
<td id="S4.T5.1.1.2.1.6" class="ltx_td ltx_align_center">17.6</td>
<td id="S4.T5.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r">24.7</td>
<td id="S4.T5.1.1.2.1.8" class="ltx_td ltx_align_center">0.016</td>
</tr>
<tr id="S4.T5.1.1.3.2" class="ltx_tr">
<td id="S4.T5.1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r">Thermal only</td>
<td id="S4.T5.1.1.3.2.2" class="ltx_td ltx_align_center">82.86</td>
<td id="S4.T5.1.1.3.2.3" class="ltx_td ltx_align_center">50.80</td>
<td id="S4.T5.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">82.83</td>
<td id="S4.T5.1.1.3.2.5" class="ltx_td ltx_align_center">72.16</td>
<td id="S4.T5.1.1.3.2.6" class="ltx_td ltx_align_center">33.4</td>
<td id="S4.T5.1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r">37.0</td>
<td id="S4.T5.1.1.3.2.8" class="ltx_td ltx_align_center">0.016</td>
</tr>
<tr id="S4.T5.1.1.4.3" class="ltx_tr">
<td id="S4.T5.1.1.4.3.1" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T5.1.1.4.3.1.1" class="ltx_ERROR undefined">\hlineB</span>3
GAFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T5.1.1.4.3.2" class="ltx_td ltx_align_center">76.60</td>
<td id="S4.T5.1.1.4.3.3" class="ltx_td ltx_align_center">59.40</td>
<td id="S4.T5.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r">85.50</td>
<td id="S4.T5.1.1.4.3.5" class="ltx_td ltx_align_center">72.9</td>
<td id="S4.T5.1.1.4.3.6" class="ltx_td ltx_align_center">32.9</td>
<td id="S4.T5.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_r">37.5</td>
<td id="S4.T5.1.1.4.3.8" class="ltx_td ltx_align_center">0.061</td>
</tr>
<tr id="S4.T5.1.1.5.4" class="ltx_tr">
<td id="S4.T5.1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r">CFR_3<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</td>
<td id="S4.T5.1.1.5.4.2" class="ltx_td ltx_align_center">74.49</td>
<td id="S4.T5.1.1.5.4.3" class="ltx_td ltx_align_center">57.77</td>
<td id="S4.T5.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r">84.91</td>
<td id="S4.T5.1.1.5.4.5" class="ltx_td ltx_align_center">72.93</td>
<td id="S4.T5.1.1.5.4.6" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.5.4.8" class="ltx_td ltx_align_center">0.050</td>
</tr>
<tr id="S4.T5.1.1.6.5" class="ltx_tr">
<td id="S4.T5.1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_r">RetinaNet + MFPT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="S4.T5.1.1.6.5.2" class="ltx_td ltx_align_center">78.1</td>
<td id="S4.T5.1.1.6.5.3" class="ltx_td ltx_align_center">65.0</td>
<td id="S4.T5.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">87.3</td>
<td id="S4.T5.1.1.6.5.5" class="ltx_td ltx_align_center">76.80</td>
<td id="S4.T5.1.1.6.5.6" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.6.5.7" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.6.5.8" class="ltx_td ltx_align_center">0.050</td>
</tr>
<tr id="S4.T5.1.1.7.6" class="ltx_tr">
<td id="S4.T5.1.1.7.6.1" class="ltx_td ltx_align_left ltx_border_r">UA-CMDet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="S4.T5.1.1.7.6.2" class="ltx_td ltx_align_center">83.20</td>
<td id="S4.T5.1.1.7.6.3" class="ltx_td ltx_align_center">64.30</td>
<td id="S4.T5.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r">88.40</td>
<td id="S4.T5.1.1.7.6.5" class="ltx_td ltx_align_center">78.60</td>
<td id="S4.T5.1.1.7.6.6" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.7.6.7" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.7.6.8" class="ltx_td ltx_align_center">—</td>
</tr>
<tr id="S4.T5.1.1.8.7" class="ltx_tr">
<td id="S4.T5.1.1.8.7.1" class="ltx_td ltx_align_left ltx_border_r">CFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T5.1.1.8.7.2" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.8.7.3" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.8.7.5" class="ltx_td ltx_align_center">78.7</td>
<td id="S4.T5.1.1.8.7.6" class="ltx_td ltx_align_center">35.5</td>
<td id="S4.T5.1.1.8.7.7" class="ltx_td ltx_align_center ltx_border_r">40.2</td>
<td id="S4.T5.1.1.8.7.8" class="ltx_td ltx_align_center">0.026</td>
</tr>
<tr id="S4.T5.1.1.9.8" class="ltx_tr">
<td id="S4.T5.1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_r">CSAA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>
</td>
<td id="S4.T5.1.1.9.8.2" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.9.8.3" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.9.8.5" class="ltx_td ltx_align_center">79.20</td>
<td id="S4.T5.1.1.9.8.6" class="ltx_td ltx_align_center">37.4</td>
<td id="S4.T5.1.1.9.8.7" class="ltx_td ltx_align_center ltx_border_r">41.3</td>
<td id="S4.T5.1.1.9.8.8" class="ltx_td ltx_align_center">0.031</td>
</tr>
<tr id="S4.T5.1.1.10.9" class="ltx_tr">
<td id="S4.T5.1.1.10.9.1" class="ltx_td ltx_align_left ltx_border_r">FasterRCNN + MFPT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="S4.T5.1.1.10.9.2" class="ltx_td ltx_align_center">83.2</td>
<td id="S4.T5.1.1.10.9.3" class="ltx_td ltx_align_center">67.7</td>
<td id="S4.T5.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_r">89.0</td>
<td id="S4.T5.1.1.10.9.5" class="ltx_td ltx_align_center">80.00</td>
<td id="S4.T5.1.1.10.9.6" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.10.9.7" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.10.9.8" class="ltx_td ltx_align_center">0.080</td>
</tr>
<tr id="S4.T5.1.1.11.10" class="ltx_tr">
<td id="S4.T5.1.1.11.10.1" class="ltx_td ltx_align_left ltx_border_r">LRAF-Net<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</td>
<td id="S4.T5.1.1.11.10.2" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.11.10.3" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.11.10.4" class="ltx_td ltx_align_center ltx_border_r">—</td>
<td id="S4.T5.1.1.11.10.5" class="ltx_td ltx_align_center">80.50</td>
<td id="S4.T5.1.1.11.10.6" class="ltx_td ltx_align_center">—</td>
<td id="S4.T5.1.1.11.10.7" class="ltx_td ltx_align_center ltx_border_r">42.8</td>
<td id="S4.T5.1.1.11.10.8" class="ltx_td ltx_align_center">—</td>
</tr>
<tr id="S4.T5.1.1.12.11" class="ltx_tr">
<td id="S4.T5.1.1.12.11.1" class="ltx_td ltx_align_left ltx_border_r">Scene-agnostic CBAM <span id="S4.T5.1.1.12.11.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</td>
<td id="S4.T5.1.1.12.11.2" class="ltx_td ltx_align_center">88.26</td>
<td id="S4.T5.1.1.12.11.3" class="ltx_td ltx_align_center">77.43</td>
<td id="S4.T5.1.1.12.11.4" class="ltx_td ltx_align_center ltx_border_r">90.68</td>
<td id="S4.T5.1.1.12.11.5" class="ltx_td ltx_align_center">85.45</td>
<td id="S4.T5.1.1.12.11.6" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.12.11.6.1" class="ltx_text ltx_font_bold">43.3</span></td>
<td id="S4.T5.1.1.12.11.7" class="ltx_td ltx_align_center ltx_border_r">46.8</td>
<td id="S4.T5.1.1.12.11.8" class="ltx_td ltx_align_center">0.028</td>
</tr>
<tr id="S4.T5.1.1.13.12" class="ltx_tr">
<td id="S4.T5.1.1.13.12.1" class="ltx_td ltx_align_left ltx_border_r">Scene-adaptive CBAM <span id="S4.T5.1.1.13.12.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</td>
<td id="S4.T5.1.1.13.12.2" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.13.12.2.1" class="ltx_text ltx_font_bold">88.92</span></td>
<td id="S4.T5.1.1.13.12.3" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.13.12.3.1" class="ltx_text ltx_font_bold">78.61</span></td>
<td id="S4.T5.1.1.13.12.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.1.13.12.4.1" class="ltx_text ltx_font_bold">90.94</span></td>
<td id="S4.T5.1.1.13.12.5" class="ltx_td ltx_align_center"><span id="S4.T5.1.1.13.12.5.1" class="ltx_text ltx_font_bold">86.16</span></td>
<td id="S4.T5.1.1.13.12.6" class="ltx_td ltx_align_center">43.0</td>
<td id="S4.T5.1.1.13.12.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.1.1.13.12.7.1" class="ltx_text ltx_font_bold">47.1</span></td>
<td id="S4.T5.1.1.13.12.8" class="ltx_td ltx_align_center">0.032</td>
</tr>
<tr id="S4.T5.1.1.14.13" class="ltx_tr">
<td id="S4.T5.1.1.14.13.1" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T5.1.1.14.13.1.1" class="ltx_ERROR undefined">\hlineB</span>3</td>
<td id="S4.T5.1.1.14.13.2" class="ltx_td"></td>
<td id="S4.T5.1.1.14.13.3" class="ltx_td"></td>
<td id="S4.T5.1.1.14.13.4" class="ltx_td"></td>
<td id="S4.T5.1.1.14.13.5" class="ltx_td"></td>
<td id="S4.T5.1.1.14.13.6" class="ltx_td"></td>
<td id="S4.T5.1.1.14.13.7" class="ltx_td"></td>
<td id="S4.T5.1.1.14.13.8" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><sup id="S4.T5.6.1" class="ltx_sup"><span id="S4.T5.6.1.1" class="ltx_text ltx_font_italic">†</span></sup> mAP refers to mAP@0.5:0.95</figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.7" class="ltx_p"><span id="S4.SS3.p3.7.2" class="ltx_text ltx_font_bold">Scene-Adaptive Object Detection:</span>
This subsection reports quantitative and qualitative object detection results of our proposed methods, compared with existing works. From <a href="#S4.T4" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, our scene-adaptive CBAM model outperforms existing methods on the M<sup id="S4.SS3.p3.7.3" class="ltx_sup">3</sup>FD dataset using the mean Average Precision <span id="S4.SS3.p3.2.1" class="ltx_text"><math id="S4.SS3.p3.2.1.m1.1" class="ltx_Math" alttext="\text{IoU}=0.5" display="inline"><semantics id="S4.SS3.p3.2.1.m1.1a"><mrow id="S4.SS3.p3.2.1.m1.1.1" xref="S4.SS3.p3.2.1.m1.1.1.cmml"><mtext id="S4.SS3.p3.2.1.m1.1.1.2" xref="S4.SS3.p3.2.1.m1.1.1.2a.cmml">IoU</mtext><mo id="S4.SS3.p3.2.1.m1.1.1.1" xref="S4.SS3.p3.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.p3.2.1.m1.1.1.3" xref="S4.SS3.p3.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.1.m1.1b"><apply id="S4.SS3.p3.2.1.m1.1.1.cmml" xref="S4.SS3.p3.2.1.m1.1.1"><eq id="S4.SS3.p3.2.1.m1.1.1.1.cmml" xref="S4.SS3.p3.2.1.m1.1.1.1"></eq><ci id="S4.SS3.p3.2.1.m1.1.1.2a.cmml" xref="S4.SS3.p3.2.1.m1.1.1.2"><mtext id="S4.SS3.p3.2.1.m1.1.1.2.cmml" xref="S4.SS3.p3.2.1.m1.1.1.2">IoU</mtext></ci><cn type="float" id="S4.SS3.p3.2.1.m1.1.1.3.cmml" xref="S4.SS3.p3.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.1.m1.1c">\text{IoU}=0.5</annotation></semantics></math></span> (mAP@0.5) metric used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. On the <em id="S4.SS3.p3.7.4" class="ltx_emph ltx_font_italic">full</em> test set, it outperforms EAEFNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> by <math id="S4.SS3.p3.3.m2.1" class="ltx_Math" alttext="1.4\%" display="inline"><semantics id="S4.SS3.p3.3.m2.1a"><mrow id="S4.SS3.p3.3.m2.1.1" xref="S4.SS3.p3.3.m2.1.1.cmml"><mn id="S4.SS3.p3.3.m2.1.1.2" xref="S4.SS3.p3.3.m2.1.1.2.cmml">1.4</mn><mo id="S4.SS3.p3.3.m2.1.1.1" xref="S4.SS3.p3.3.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m2.1b"><apply id="S4.SS3.p3.3.m2.1.1.cmml" xref="S4.SS3.p3.3.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p3.3.m2.1.1.1.cmml" xref="S4.SS3.p3.3.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.3.m2.1.1.2.cmml" xref="S4.SS3.p3.3.m2.1.1.2">1.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m2.1c">1.4\%</annotation></semantics></math> and the scene-agnostic CBAM model (in which only one set of CBAM fusion modules are trained using all training images) by <math id="S4.SS3.p3.4.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.SS3.p3.4.m3.1a"><mrow id="S4.SS3.p3.4.m3.1.1" xref="S4.SS3.p3.4.m3.1.1.cmml"><mn id="S4.SS3.p3.4.m3.1.1.2" xref="S4.SS3.p3.4.m3.1.1.2.cmml">1</mn><mo id="S4.SS3.p3.4.m3.1.1.1" xref="S4.SS3.p3.4.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m3.1b"><apply id="S4.SS3.p3.4.m3.1.1.cmml" xref="S4.SS3.p3.4.m3.1.1"><csymbol cd="latexml" id="S4.SS3.p3.4.m3.1.1.1.cmml" xref="S4.SS3.p3.4.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.p3.4.m3.1.1.2.cmml" xref="S4.SS3.p3.4.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m3.1c">1\%</annotation></semantics></math>. A comparison of qualitative detection results on M<sup id="S4.SS3.p3.7.5" class="ltx_sup">3</sup>FD dataset between the scene-agnostic and scene-adaptive models is shown in <a href="#S4.F3" title="In 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>. From the zoomed-in area of the figures, we can see that the scene-adaptive model detects some occluded, blurred objects that the scene-agnostic model fails to detect. Note that, the single-modality models used in this experiment are pretrained on COCO and further fine-tuned on the M<sup id="S4.SS3.p3.7.6" class="ltx_sup">3</sup>FD training set for better performance. We also show some failure cases on M<sup id="S4.SS3.p3.7.7" class="ltx_sup">3</sup>FD in <a href="#S4.F6" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a> where both fusion models struggled with distant small objects in <em id="S4.SS3.p3.7.8" class="ltx_emph ltx_font_italic">overcast</em> and <em id="S4.SS3.p3.7.9" class="ltx_emph ltx_font_italic">night</em> scenes, and cluttered objects under daylight.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00694_rgb_gt.jpg" id="S4.F6.sf1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01038_rgb_gt.jpg" id="S4.F6.sf1.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/02068_rgb_gt.jpg" id="S4.F6.sf1.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F6.sf1.4.2" class="ltx_text" style="font-size:70%;">RGB-GT</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00694_thermal_gt.jpg" id="S4.F6.sf2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01038_thermal_gt.jpg" id="S4.F6.sf2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/02068_thermal_gt.jpg" id="S4.F6.sf2.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F6.sf2.4.2" class="ltx_text" style="font-size:70%;">Thermal-GT</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00694_rgb_agn.jpg" id="S4.F6.sf3.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01038_rgb_agn.jpg" id="S4.F6.sf3.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/02068_rgb_agn.jpg" id="S4.F6.sf3.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F6.sf3.4.2" class="ltx_text" style="font-size:70%;">Agnostic CBAM</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/00694_rgb_ada.jpg" id="S4.F6.sf4.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/01038_rgb_ada.jpg" id="S4.F6.sf4.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2310.19372/assets/figures/compressed_m3fd/02068_rgb_ada.jpg" id="S4.F6.sf4.g3" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="299" height="225" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F6.sf4.4.2" class="ltx_text" style="font-size:70%;">Adaptive CBAM</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.8.2.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.2.1" class="ltx_text" style="font-size:90%;">Example of failure cases on M<sup id="S4.F6.2.1.1" class="ltx_sup">3</sup>FD dataset. Both models struggled with distant small objects in <em id="S4.F6.2.1.2" class="ltx_emph ltx_font_italic">night</em> and <em id="S4.F6.2.1.3" class="ltx_emph ltx_font_italic">overcast</em> images and cluttered objects in <em id="S4.F6.2.1.4" class="ltx_emph ltx_font_italic">day</em> images.</span></figcaption>
</figure>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x3.png" id="S4.F7.sf1.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F7.sf1.2.1" class="ltx_text" style="font-size:70%;">M<sup id="S4.F7.sf1.2.1.1" class="ltx_sup">3</sup>FD-Day</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x4.png" id="S4.F7.sf2.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf2.4.2.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F7.sf2.2.1" class="ltx_text" style="font-size:70%;">M<sup id="S4.F7.sf2.2.1.1" class="ltx_sup">3</sup>FD-Overc.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x5.png" id="S4.F7.sf3.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf3.4.2.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F7.sf3.2.1" class="ltx_text" style="font-size:70%;">M<sup id="S4.F7.sf3.2.1.1" class="ltx_sup">3</sup>FD-Night</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x6.png" id="S4.F7.sf4.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf4.4.2.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F7.sf4.2.1" class="ltx_text" style="font-size:70%;">M<sup id="S4.F7.sf4.2.1.1" class="ltx_sup">3</sup>FD-Chall.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x7.png" id="S4.F7.sf5.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf5.3.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S4.F7.sf5.4.2" class="ltx_text" style="font-size:70%;">FLIR-Day</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf6" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x8.png" id="S4.F7.sf6.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf6.3.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span><span id="S4.F7.sf6.4.2" class="ltx_text" style="font-size:70%;">FLIR-Night</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf7" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x9.png" id="S4.F7.sf7.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf7.3.1.1" class="ltx_text" style="font-size:90%;">(g)</span> </span><span id="S4.F7.sf7.4.2" class="ltx_text" style="font-size:70%;">FLIR-Full</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf8" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2310.19372/assets/x10.png" id="S4.F7.sf8.g1" class="ltx_graphics ltx_img_landscape" width="332" height="251" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf8.4.2.1" class="ltx_text" style="font-size:90%;">(h)</span> </span><span id="S4.F7.sf8.2.1" class="ltx_text" style="font-size:70%;">M<sup id="S4.F7.sf8.2.1.1" class="ltx_sup">3</sup>FD-Full</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.5.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.6.2" class="ltx_text" style="font-size:90%;">Normalized attention weights for 256 feature channels in CBAM fusion module trained on different scenes. Thermal channels are in black, and RGB channels in crimson. The fusion module trained on the entire dataset (g-h) exhibits similar attention patterns across all scene/weather conditions, whereas from <em id="S4.F7.6.2.1" class="ltx_emph ltx_font_italic">day</em> to <em id="S4.F7.6.2.2" class="ltx_emph ltx_font_italic">overcast</em> to <em id="S4.F7.6.2.3" class="ltx_emph ltx_font_italic">night</em>, the scene-specific fusion module (a-f) attends increasingly on thermal features.</span></figcaption>
</figure>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.7.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.8.2" class="ltx_text" style="font-size:90%;">Quantitative detection AP on the <em id="S4.T6.8.2.1" class="ltx_emph ltx_font_italic">clear</em> scene and unseen scenes for <em id="S4.T6.8.2.2" class="ltx_emph ltx_font_italic">car</em> following the KITTI evaluation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Models are all trained on the training set of the <em id="S4.T6.8.2.3" class="ltx_emph ltx_font_italic">clear</em> scene. Our scene-adaptive CBAM model is trained on <em id="S4.T6.8.2.4" class="ltx_emph ltx_font_italic">clear-day</em> and <em id="S4.T6.8.2.5" class="ltx_emph ltx_font_italic">clear-night</em> splits.</span></figcaption>
<div id="S4.T6.9" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:486.9pt;height:152.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-72.3pt,22.7pt) scale(0.771050968157225,0.771050968157225) ;">
<table id="S4.T6.9.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T6.9.1.1.1" class="ltx_tr">
<th id="S4.T6.9.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" rowspan="3">
<span id="S4.T6.9.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T6.9.1.1.1.1.2" class="ltx_text">Method</span>
</th>
<td id="S4.T6.9.1.1.1.2" class="ltx_td ltx_align_center" colspan="12">Test Scene</td>
</tr>
<tr id="S4.T6.9.1.2.2" class="ltx_tr">
<td id="S4.T6.9.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Clear</td>
<td id="S4.T6.9.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Light Fog</td>
<td id="S4.T6.9.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Dense Fog</td>
<td id="S4.T6.9.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t" colspan="3">Snow/Rain</td>
</tr>
<tr id="S4.T6.9.1.3.3" class="ltx_tr">
<td id="S4.T6.9.1.3.3.1" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T6.9.1.3.3.2" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T6.9.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T6.9.1.3.3.4" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T6.9.1.3.3.5" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T6.9.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T6.9.1.3.3.7" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T6.9.1.3.3.8" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T6.9.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T6.9.1.3.3.10" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T6.9.1.3.3.11" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T6.9.1.3.3.12" class="ltx_td ltx_align_center">hard</td>
</tr>
<tr id="S4.T6.9.1.4.4" class="ltx_tr">
<th id="S4.T6.9.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T6.9.1.4.4.1.1" class="ltx_ERROR undefined">\hlineB</span>3
RGB only</th>
<td id="S4.T6.9.1.4.4.2" class="ltx_td ltx_align_center">90.14</td>
<td id="S4.T6.9.1.4.4.3" class="ltx_td ltx_align_center">87.56</td>
<td id="S4.T6.9.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">80.87</td>
<td id="S4.T6.9.1.4.4.5" class="ltx_td ltx_align_center">91.19</td>
<td id="S4.T6.9.1.4.4.6" class="ltx_td ltx_align_center">88.47</td>
<td id="S4.T6.9.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">82.02</td>
<td id="S4.T6.9.1.4.4.8" class="ltx_td ltx_align_center">90.43</td>
<td id="S4.T6.9.1.4.4.9" class="ltx_td ltx_align_center">85.59</td>
<td id="S4.T6.9.1.4.4.10" class="ltx_td ltx_align_center ltx_border_r">80.79</td>
<td id="S4.T6.9.1.4.4.11" class="ltx_td ltx_align_center">89.44</td>
<td id="S4.T6.9.1.4.4.12" class="ltx_td ltx_align_center">82.87</td>
<td id="S4.T6.9.1.4.4.13" class="ltx_td ltx_align_center">77.81</td>
</tr>
<tr id="S4.T6.9.1.5.5" class="ltx_tr">
<th id="S4.T6.9.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Gated only</th>
<td id="S4.T6.9.1.5.5.2" class="ltx_td ltx_align_center">88.51</td>
<td id="S4.T6.9.1.5.5.3" class="ltx_td ltx_align_center">80.09</td>
<td id="S4.T6.9.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">74.65</td>
<td id="S4.T6.9.1.5.5.5" class="ltx_td ltx_align_center">87.98</td>
<td id="S4.T6.9.1.5.5.6" class="ltx_td ltx_align_center">78.92</td>
<td id="S4.T6.9.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">73.59</td>
<td id="S4.T6.9.1.5.5.8" class="ltx_td ltx_align_center">80.52</td>
<td id="S4.T6.9.1.5.5.9" class="ltx_td ltx_align_center">75.86</td>
<td id="S4.T6.9.1.5.5.10" class="ltx_td ltx_align_center ltx_border_r">70.42</td>
<td id="S4.T6.9.1.5.5.11" class="ltx_td ltx_align_center">80.58</td>
<td id="S4.T6.9.1.5.5.12" class="ltx_td ltx_align_center">75.59</td>
<td id="S4.T6.9.1.5.5.13" class="ltx_td ltx_align_center">69.52</td>
</tr>
<tr id="S4.T6.9.1.6.6" class="ltx_tr">
<th id="S4.T6.9.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Fusion SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</th>
<td id="S4.T6.9.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t">87.73</td>
<td id="S4.T6.9.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t">78.02</td>
<td id="S4.T6.9.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.49</td>
<td id="S4.T6.9.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t">88.33</td>
<td id="S4.T6.9.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t">78.65</td>
<td id="S4.T6.9.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.54</td>
<td id="S4.T6.9.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t">74.07</td>
<td id="S4.T6.9.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t">68.46</td>
<td id="S4.T6.9.1.6.6.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.23</td>
<td id="S4.T6.9.1.6.6.11" class="ltx_td ltx_align_center ltx_border_t">85.49</td>
<td id="S4.T6.9.1.6.6.12" class="ltx_td ltx_align_center ltx_border_t">75.28</td>
<td id="S4.T6.9.1.6.6.13" class="ltx_td ltx_align_center ltx_border_t">67.48</td>
</tr>
<tr id="S4.T6.9.1.7.7" class="ltx_tr">
<th id="S4.T6.9.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Deep Fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</th>
<td id="S4.T6.9.1.7.7.2" class="ltx_td ltx_align_center">90.07</td>
<td id="S4.T6.9.1.7.7.3" class="ltx_td ltx_align_center">80.31</td>
<td id="S4.T6.9.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">77.82</td>
<td id="S4.T6.9.1.7.7.5" class="ltx_td ltx_align_center">90.60</td>
<td id="S4.T6.9.1.7.7.6" class="ltx_td ltx_align_center">81.08</td>
<td id="S4.T6.9.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r">79.63</td>
<td id="S4.T6.9.1.7.7.8" class="ltx_td ltx_align_center">86.77</td>
<td id="S4.T6.9.1.7.7.9" class="ltx_td ltx_align_center">77.28</td>
<td id="S4.T6.9.1.7.7.10" class="ltx_td ltx_align_center ltx_border_r">73.93</td>
<td id="S4.T6.9.1.7.7.11" class="ltx_td ltx_align_center">89.25</td>
<td id="S4.T6.9.1.7.7.12" class="ltx_td ltx_align_center">79.09</td>
<td id="S4.T6.9.1.7.7.13" class="ltx_td ltx_align_center">70.51</td>
</tr>
<tr id="S4.T6.9.1.8.8" class="ltx_tr">
<th id="S4.T6.9.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Deep Entropy Fusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</th>
<td id="S4.T6.9.1.8.8.2" class="ltx_td ltx_align_center">89.84</td>
<td id="S4.T6.9.1.8.8.3" class="ltx_td ltx_align_center">85.57</td>
<td id="S4.T6.9.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r">79.46</td>
<td id="S4.T6.9.1.8.8.5" class="ltx_td ltx_align_center">90.54</td>
<td id="S4.T6.9.1.8.8.6" class="ltx_td ltx_align_center">87.99</td>
<td id="S4.T6.9.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r">84.90</td>
<td id="S4.T6.9.1.8.8.8" class="ltx_td ltx_align_center">87.68</td>
<td id="S4.T6.9.1.8.8.9" class="ltx_td ltx_align_center">81.49</td>
<td id="S4.T6.9.1.8.8.10" class="ltx_td ltx_align_center ltx_border_r">76.69</td>
<td id="S4.T6.9.1.8.8.11" class="ltx_td ltx_align_center">88.99</td>
<td id="S4.T6.9.1.8.8.12" class="ltx_td ltx_align_center">83.71</td>
<td id="S4.T6.9.1.8.8.13" class="ltx_td ltx_align_center">77.85</td>
</tr>
<tr id="S4.T6.9.1.9.9" class="ltx_tr">
<th id="S4.T6.9.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Scene-agnostic CBAM <span id="S4.T6.9.1.9.9.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</th>
<td id="S4.T6.9.1.9.9.2" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.9.9.2.1" class="ltx_text ltx_font_bold">90.33</span></td>
<td id="S4.T6.9.1.9.9.3" class="ltx_td ltx_align_center">88.53</td>
<td id="S4.T6.9.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.9.1.9.9.4.1" class="ltx_text ltx_font_bold">81.16</span></td>
<td id="S4.T6.9.1.9.9.5" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.9.9.5.1" class="ltx_text ltx_font_bold">91.43</span></td>
<td id="S4.T6.9.1.9.9.6" class="ltx_td ltx_align_center">89.05</td>
<td id="S4.T6.9.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.9.1.9.9.7.1" class="ltx_text ltx_font_bold">84.94</span></td>
<td id="S4.T6.9.1.9.9.8" class="ltx_td ltx_align_center">90.75</td>
<td id="S4.T6.9.1.9.9.9" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.9.9.9.1" class="ltx_text ltx_font_bold">88.66</span></td>
<td id="S4.T6.9.1.9.9.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.9.1.9.9.10.1" class="ltx_text ltx_font_bold">82.07</span></td>
<td id="S4.T6.9.1.9.9.11" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.9.9.11.1" class="ltx_text ltx_font_bold">89.99</span></td>
<td id="S4.T6.9.1.9.9.12" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.9.9.12.1" class="ltx_text ltx_font_bold">86.57</span></td>
<td id="S4.T6.9.1.9.9.13" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.9.9.13.1" class="ltx_text ltx_font_bold">79.79</span></td>
</tr>
<tr id="S4.T6.9.1.10.10" class="ltx_tr">
<th id="S4.T6.9.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Scene-adaptive CBAM <span id="S4.T6.9.1.10.10.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</th>
<td id="S4.T6.9.1.10.10.2" class="ltx_td ltx_align_center">90.29</td>
<td id="S4.T6.9.1.10.10.3" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.10.10.3.1" class="ltx_text ltx_font_bold">88.53</span></td>
<td id="S4.T6.9.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r">81.07</td>
<td id="S4.T6.9.1.10.10.5" class="ltx_td ltx_align_center">91.13</td>
<td id="S4.T6.9.1.10.10.6" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.10.10.6.1" class="ltx_text ltx_font_bold">89.13</span></td>
<td id="S4.T6.9.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r">84.20</td>
<td id="S4.T6.9.1.10.10.8" class="ltx_td ltx_align_center"><span id="S4.T6.9.1.10.10.8.1" class="ltx_text ltx_font_bold">90.77</span></td>
<td id="S4.T6.9.1.10.10.9" class="ltx_td ltx_align_center">88.37</td>
<td id="S4.T6.9.1.10.10.10" class="ltx_td ltx_align_center ltx_border_r">81.68</td>
<td id="S4.T6.9.1.10.10.11" class="ltx_td ltx_align_center">89.96</td>
<td id="S4.T6.9.1.10.10.12" class="ltx_td ltx_align_center">86.30</td>
<td id="S4.T6.9.1.10.10.13" class="ltx_td ltx_align_center">79.74</td>
</tr>
<tr id="S4.T6.9.1.11.11" class="ltx_tr">
<th id="S4.T6.9.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T6.9.1.11.11.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T6.9.1.11.11.2" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.3" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.4" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.5" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.6" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.7" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.8" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.9" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.10" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.11" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.12" class="ltx_td"></td>
<td id="S4.T6.9.1.11.11.13" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.6.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T7.7.2" class="ltx_text" style="font-size:90%;">Quantitative detection AP on all scenes for <em id="S4.T7.7.2.1" class="ltx_emph ltx_font_italic">pedestrian</em>, <em id="S4.T7.7.2.2" class="ltx_emph ltx_font_italic">truck</em>, <em id="S4.T7.7.2.3" class="ltx_emph ltx_font_italic">car</em>, and <em id="S4.T7.7.2.4" class="ltx_emph ltx_font_italic">cyclist</em> following the KITTI evaluation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Models are trained on the training set of all scenes. The last column shows mAP@0.5 for all objects on all test images.</span></figcaption>
<div id="S4.T7.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:486.9pt;height:100.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-106.8pt,22.0pt) scale(0.694987631366233,0.694987631366233) ;">
<table id="S4.T7.8.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T7.8.1.1.1" class="ltx_tr">
<td id="S4.T7.8.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r" rowspan="3">
<span id="S4.T7.8.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T7.8.1.1.1.1.2" class="ltx_text">Method</span>
</td>
<td id="S4.T7.8.1.1.1.2" class="ltx_td ltx_align_center" colspan="16">Test Scene</td>
</tr>
<tr id="S4.T7.8.1.2.2" class="ltx_tr">
<td id="S4.T7.8.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Clear</td>
<td id="S4.T7.8.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Light Fog</td>
<td id="S4.T7.8.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Dense Fog</td>
<td id="S4.T7.8.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">Snow/Rain</td>
<td id="S4.T7.8.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" colspan="4">Full</td>
</tr>
<tr id="S4.T7.8.1.3.3" class="ltx_tr">
<td id="S4.T7.8.1.3.3.1" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T7.8.1.3.3.2" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T7.8.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T7.8.1.3.3.4" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T7.8.1.3.3.5" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T7.8.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T7.8.1.3.3.7" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T7.8.1.3.3.8" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T7.8.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T7.8.1.3.3.10" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T7.8.1.3.3.11" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T7.8.1.3.3.12" class="ltx_td ltx_align_center ltx_border_r">hard</td>
<td id="S4.T7.8.1.3.3.13" class="ltx_td ltx_align_center">easy</td>
<td id="S4.T7.8.1.3.3.14" class="ltx_td ltx_align_center">mod.</td>
<td id="S4.T7.8.1.3.3.15" class="ltx_td ltx_align_center">hard</td>
<td id="S4.T7.8.1.3.3.16" class="ltx_td ltx_align_center">all</td>
</tr>
<tr id="S4.T7.8.1.4.4" class="ltx_tr">
<td id="S4.T7.8.1.4.4.1" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T7.8.1.4.4.1.1" class="ltx_ERROR undefined">\hlineB</span>3
RGB only</td>
<td id="S4.T7.8.1.4.4.2" class="ltx_td ltx_align_center">87.05</td>
<td id="S4.T7.8.1.4.4.3" class="ltx_td ltx_align_center">83.88</td>
<td id="S4.T7.8.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r">82.93</td>
<td id="S4.T7.8.1.4.4.5" class="ltx_td ltx_align_center">89.68</td>
<td id="S4.T7.8.1.4.4.6" class="ltx_td ltx_align_center">88.88</td>
<td id="S4.T7.8.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">87.99</td>
<td id="S4.T7.8.1.4.4.8" class="ltx_td ltx_align_center">88.61</td>
<td id="S4.T7.8.1.4.4.9" class="ltx_td ltx_align_center">88.28</td>
<td id="S4.T7.8.1.4.4.10" class="ltx_td ltx_align_center ltx_border_r">87.90</td>
<td id="S4.T7.8.1.4.4.11" class="ltx_td ltx_align_center">88.92</td>
<td id="S4.T7.8.1.4.4.12" class="ltx_td ltx_align_center">86.01</td>
<td id="S4.T7.8.1.4.4.13" class="ltx_td ltx_align_center ltx_border_r">83.73</td>
<td id="S4.T7.8.1.4.4.14" class="ltx_td ltx_align_center">84.22</td>
<td id="S4.T7.8.1.4.4.15" class="ltx_td ltx_align_center">79.94</td>
<td id="S4.T7.8.1.4.4.16" class="ltx_td ltx_align_center">76.30</td>
<td id="S4.T7.8.1.4.4.17" class="ltx_td ltx_align_center">80.85</td>
</tr>
<tr id="S4.T7.8.1.5.5" class="ltx_tr">
<td id="S4.T7.8.1.5.5.1" class="ltx_td ltx_align_left ltx_border_r">Gated only</td>
<td id="S4.T7.8.1.5.5.2" class="ltx_td ltx_align_center">81.69</td>
<td id="S4.T7.8.1.5.5.3" class="ltx_td ltx_align_center">76.19</td>
<td id="S4.T7.8.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">74.57</td>
<td id="S4.T7.8.1.5.5.5" class="ltx_td ltx_align_center">85.63</td>
<td id="S4.T7.8.1.5.5.6" class="ltx_td ltx_align_center">84.01</td>
<td id="S4.T7.8.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">80.19</td>
<td id="S4.T7.8.1.5.5.8" class="ltx_td ltx_align_center">83.40</td>
<td id="S4.T7.8.1.5.5.9" class="ltx_td ltx_align_center">82.00</td>
<td id="S4.T7.8.1.5.5.10" class="ltx_td ltx_align_center ltx_border_r">79.88</td>
<td id="S4.T7.8.1.5.5.11" class="ltx_td ltx_align_center">84.03</td>
<td id="S4.T7.8.1.5.5.12" class="ltx_td ltx_align_center">79.54</td>
<td id="S4.T7.8.1.5.5.13" class="ltx_td ltx_align_center ltx_border_r">77.38</td>
<td id="S4.T7.8.1.5.5.14" class="ltx_td ltx_align_center">80.70</td>
<td id="S4.T7.8.1.5.5.15" class="ltx_td ltx_align_center">73.58</td>
<td id="S4.T7.8.1.5.5.16" class="ltx_td ltx_align_center">70.13</td>
<td id="S4.T7.8.1.5.5.17" class="ltx_td ltx_align_center">75.15</td>
</tr>
<tr id="S4.T7.8.1.6.6" class="ltx_tr">
<td id="S4.T7.8.1.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Scene-agnostic CBAM <span id="S4.T7.8.1.6.6.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</td>
<td id="S4.T7.8.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.8.1.6.6.2.1" class="ltx_text ltx_font_bold">88.65</span></td>
<td id="S4.T7.8.1.6.6.3" class="ltx_td ltx_align_center ltx_border_t">85.12</td>
<td id="S4.T7.8.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.8.1.6.6.4.1" class="ltx_text ltx_font_bold">84.25</span></td>
<td id="S4.T7.8.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t">90.30</td>
<td id="S4.T7.8.1.6.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.8.1.6.6.6.1" class="ltx_text ltx_font_bold">89.68</span></td>
<td id="S4.T7.8.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.8.1.6.6.7.1" class="ltx_text ltx_font_bold">88.95</span></td>
<td id="S4.T7.8.1.6.6.8" class="ltx_td ltx_align_center ltx_border_t">89.78</td>
<td id="S4.T7.8.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t">89.18</td>
<td id="S4.T7.8.1.6.6.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.82</td>
<td id="S4.T7.8.1.6.6.11" class="ltx_td ltx_align_center ltx_border_t">89.25</td>
<td id="S4.T7.8.1.6.6.12" class="ltx_td ltx_align_center ltx_border_t">87.01</td>
<td id="S4.T7.8.1.6.6.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.8.1.6.6.13.1" class="ltx_text ltx_font_bold">85.77</span></td>
<td id="S4.T7.8.1.6.6.14" class="ltx_td ltx_align_center ltx_border_t">86.11</td>
<td id="S4.T7.8.1.6.6.15" class="ltx_td ltx_align_center ltx_border_t">81.84</td>
<td id="S4.T7.8.1.6.6.16" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.8.1.6.6.16.1" class="ltx_text ltx_font_bold">78.52</span></td>
<td id="S4.T7.8.1.6.6.17" class="ltx_td ltx_align_center ltx_border_t">83.01</td>
</tr>
<tr id="S4.T7.8.1.7.7" class="ltx_tr">
<td id="S4.T7.8.1.7.7.1" class="ltx_td ltx_align_left ltx_border_r">Scene-adaptive CBAM <span id="S4.T7.8.1.7.7.1.1" class="ltx_text ltx_font_bold">(ours)</span>
</td>
<td id="S4.T7.8.1.7.7.2" class="ltx_td ltx_align_center">88.60</td>
<td id="S4.T7.8.1.7.7.3" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.3.1" class="ltx_text ltx_font_bold">85.24</span></td>
<td id="S4.T7.8.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">84.22</td>
<td id="S4.T7.8.1.7.7.5" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.5.1" class="ltx_text ltx_font_bold">90.53</span></td>
<td id="S4.T7.8.1.7.7.6" class="ltx_td ltx_align_center">89.39</td>
<td id="S4.T7.8.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r">88.89</td>
<td id="S4.T7.8.1.7.7.8" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.8.1" class="ltx_text ltx_font_bold">89.79</span></td>
<td id="S4.T7.8.1.7.7.9" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.9.1" class="ltx_text ltx_font_bold">89.33</span></td>
<td id="S4.T7.8.1.7.7.10" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T7.8.1.7.7.10.1" class="ltx_text ltx_font_bold">89.03</span></td>
<td id="S4.T7.8.1.7.7.11" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.11.1" class="ltx_text ltx_font_bold">89.37</span></td>
<td id="S4.T7.8.1.7.7.12" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.12.1" class="ltx_text ltx_font_bold">87.46</span></td>
<td id="S4.T7.8.1.7.7.13" class="ltx_td ltx_align_center ltx_border_r">85.69</td>
<td id="S4.T7.8.1.7.7.14" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.14.1" class="ltx_text ltx_font_bold">86.13</span></td>
<td id="S4.T7.8.1.7.7.15" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.15.1" class="ltx_text ltx_font_bold">81.85</span></td>
<td id="S4.T7.8.1.7.7.16" class="ltx_td ltx_align_center">78.48</td>
<td id="S4.T7.8.1.7.7.17" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.7.7.17.1" class="ltx_text ltx_font_bold">83.11</span></td>
</tr>
<tr id="S4.T7.8.1.8.8" class="ltx_tr">
<td id="S4.T7.8.1.8.8.1" class="ltx_td ltx_align_left ltx_border_r">
<span id="S4.T7.8.1.8.8.1.1" class="ltx_ERROR undefined">\hlineB</span>3</td>
<td id="S4.T7.8.1.8.8.2" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.3" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.4" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.5" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.6" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.7" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.8" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.9" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.10" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.11" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.12" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.13" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.14" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.15" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.16" class="ltx_td"></td>
<td id="S4.T7.8.1.8.8.17" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">For the FLIR Aligned dataset, we evaluate fusion networks built from an RGB network pretrained on COCO and a thermal network trained on the unaligned FLIR thermal training set. In general, both our scene-agnostic and scene-adaptive fusion models outperform the baselines by a large margin (<a href="#S4.T5" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a>), due to the increase in data the thermal and RGB networks had access to. Some qualitative detection results on FLIR test images along with attention visualizations are given in <a href="#S4.F4" title="In 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>. We observe that scene-adaptive model tends to detect bicycles more successfully than scene-agnostic model, especially when the bicycle is rode by a person (see row 2 and 6 in <a href="#S4.F4" title="In 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>). The higher margin of AP@0.5 for <em id="S4.SS3.p4.1.1" class="ltx_emph ltx_font_italic">bicycle</em> in <a href="#S4.T5" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">5</span></a> also aligns with this observation. In order to exam the effects of scene-adaptive CBAM, we visualize the CBAM using class activation map (CAM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> where the spatial attention is shown by a heat map. From the visualization, we can see there is generally no difference between scene-agnostic CBAM and scene-adaptive CBAM for day images. However, the spatial attention in scene-adaptive CBAM attend more on small areas.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">We visualize the channel attention of the scene-specific fusion module by plotting the normalized attention weights of thermal (black) and RGB (crimson) features for various scenes in <a href="#S4.F7" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a>. Higher value implies CBAM attends more on that feature channel. We find that scene-agnostic CBAM exhibits similar channel attention patterns across all scenes, while scene-adaptive CBAM shows tailored attention patterns per scene. Moreover, we observe attention weight increases on thermal features compared with RGB features from day to overcast to night images, likely as RGB images contain less information under lower illumination.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p">For the STF dataset, we first follow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and train our fusion modules only on <em id="S4.SS3.p6.1.1" class="ltx_emph ltx_font_italic">clear-day</em> and <em id="S4.SS3.p6.1.2" class="ltx_emph ltx_font_italic">clear-night</em> RGB-gated image pairs for fair comparison. As shown in <a href="#S4.T6" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">6</span></a>, the scene-agnostic and scene-adaptive CBAM models achieve similar performance on different scenes and outperform the baseline models using even more modalities than RGB-gated images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. When training on all scenes in <a href="#S4.T7" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">7</span></a>, we can see that our scene-adaptive model outperforms the scene-agnostic model by <math id="S4.SS3.p6.1.m1.1" class="ltx_Math" alttext="0.1\%" display="inline"><semantics id="S4.SS3.p6.1.m1.1a"><mrow id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml"><mn id="S4.SS3.p6.1.m1.1.1.2" xref="S4.SS3.p6.1.m1.1.1.2.cmml">0.1</mn><mo id="S4.SS3.p6.1.m1.1.1.1" xref="S4.SS3.p6.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><apply id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p6.1.m1.1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p6.1.m1.1.1.2.cmml" xref="S4.SS3.p6.1.m1.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">0.1\%</annotation></semantics></math> on mAP@0.5. Single-modality models used for this experiment are also further trained on STF training data, due to their use of 10 and 12 bit gated and RGB imagery. <a href="#S4.F5" title="In 4.2 Datasets ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a> presents a few examples of the qualitative detection results in various scenes.</p>
</div>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T8.5.2.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="S4.T8.2.1" class="ltx_text" style="font-size:90%;">Ablation study on different fusion modules. Object detection results (mAP@0.5) on M<sup id="S4.T8.2.1.1" class="ltx_sup">3</sup>FD dataset are reported.</span></figcaption>
<div id="S4.T8.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:315.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-83.1pt,121.0pt) scale(0.566164769078883,0.566164769078883) ;">
<table id="S4.T8.6.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T8.6.1.1.1" class="ltx_tr">
<th id="S4.T8.6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" rowspan="2">
<span id="S4.T8.6.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T8.6.1.1.1.1.2" class="ltx_text">Fusion Module</span>
</th>
<th id="S4.T8.6.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" rowspan="2"><span id="S4.T8.6.1.1.1.2.1" class="ltx_text">
<span id="S4.T8.6.1.1.1.2.1.1" class="ltx_inline-block ltx_align_center">
<span id="S4.T8.6.1.1.1.2.1.1.1" class="ltx_p">Train/Search</span>
<span id="S4.T8.6.1.1.1.2.1.1.2" class="ltx_p">Scene</span>
</span></span></th>
<td id="S4.T8.6.1.1.1.3" class="ltx_td ltx_align_center" colspan="5">Test Scene</td>
</tr>
<tr id="S4.T8.6.1.2.2" class="ltx_tr">
<td id="S4.T8.6.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Day</td>
<td id="S4.T8.6.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Night</td>
<td id="S4.T8.6.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Overcast</td>
<td id="S4.T8.6.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Challenge</td>
<td id="S4.T8.6.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">Full</td>
</tr>
<tr id="S4.T8.6.1.3.3" class="ltx_tr">
<th id="S4.T8.6.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T8.6.1.3.3.1.1" class="ltx_ERROR undefined">\hlineB</span>3
RGB only</th>
<th id="S4.T8.6.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" rowspan="11"><span id="S4.T8.6.1.3.3.2.1" class="ltx_text">Full</span></th>
<td id="S4.T8.6.1.3.3.3" class="ltx_td ltx_align_center">71.59</td>
<td id="S4.T8.6.1.3.3.4" class="ltx_td ltx_align_center">91.06</td>
<td id="S4.T8.6.1.3.3.5" class="ltx_td ltx_align_center">81.55</td>
<td id="S4.T8.6.1.3.3.6" class="ltx_td ltx_align_center">80.03</td>
<td id="S4.T8.6.1.3.3.7" class="ltx_td ltx_align_center">77.79</td>
</tr>
<tr id="S4.T8.6.1.4.4" class="ltx_tr">
<th id="S4.T8.6.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Thermal only</th>
<td id="S4.T8.6.1.4.4.2" class="ltx_td ltx_align_center">65.68</td>
<td id="S4.T8.6.1.4.4.3" class="ltx_td ltx_align_center">89.17</td>
<td id="S4.T8.6.1.4.4.4" class="ltx_td ltx_align_center">79.66</td>
<td id="S4.T8.6.1.4.4.5" class="ltx_td ltx_align_center">76.39</td>
<td id="S4.T8.6.1.4.4.6" class="ltx_td ltx_align_center">74.63</td>
</tr>
<tr id="S4.T8.6.1.5.5" class="ltx_tr">
<th id="S4.T8.6.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ECAAttn (Tr)</th>
<td id="S4.T8.6.1.5.5.2" class="ltx_td ltx_align_center">73.38</td>
<td id="S4.T8.6.1.5.5.3" class="ltx_td ltx_align_center">93.39</td>
<td id="S4.T8.6.1.5.5.4" class="ltx_td ltx_align_center">83.55</td>
<td id="S4.T8.6.1.5.5.5" class="ltx_td ltx_align_center">82.28</td>
<td id="S4.T8.6.1.5.5.6" class="ltx_td ltx_align_center">80.17</td>
</tr>
<tr id="S4.T8.6.1.6.6" class="ltx_tr">
<th id="S4.T8.6.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ECAAttn (RH)</th>
<td id="S4.T8.6.1.6.6.2" class="ltx_td ltx_align_center">72.25</td>
<td id="S4.T8.6.1.6.6.3" class="ltx_td ltx_align_center">92.83</td>
<td id="S4.T8.6.1.6.6.4" class="ltx_td ltx_align_center">81.98</td>
<td id="S4.T8.6.1.6.6.5" class="ltx_td ltx_align_center">80.53</td>
<td id="S4.T8.6.1.6.6.6" class="ltx_td ltx_align_center">78.81</td>
</tr>
<tr id="S4.T8.6.1.7.7" class="ltx_tr">
<th id="S4.T8.6.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ECAAttn (TH)</th>
<td id="S4.T8.6.1.7.7.2" class="ltx_td ltx_align_center">74.02</td>
<td id="S4.T8.6.1.7.7.3" class="ltx_td ltx_align_center">93.38</td>
<td id="S4.T8.6.1.7.7.4" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.7.7.4.1" class="ltx_text ltx_font_bold">84.25</span></td>
<td id="S4.T8.6.1.7.7.5" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.7.7.5.1" class="ltx_text ltx_font_bold">81.48</span></td>
<td id="S4.T8.6.1.7.7.6" class="ltx_td ltx_align_center">80.32</td>
</tr>
<tr id="S4.T8.6.1.8.8" class="ltx_tr">
<th id="S4.T8.6.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ShuffleAttn (Tr)</th>
<td id="S4.T8.6.1.8.8.2" class="ltx_td ltx_align_center">73.47</td>
<td id="S4.T8.6.1.8.8.3" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.8.8.3.1" class="ltx_text ltx_font_bold">94.56</span></td>
<td id="S4.T8.6.1.8.8.4" class="ltx_td ltx_align_center">84.61</td>
<td id="S4.T8.6.1.8.8.5" class="ltx_td ltx_align_center">80.91</td>
<td id="S4.T8.6.1.8.8.6" class="ltx_td ltx_align_center">80.17</td>
</tr>
<tr id="S4.T8.6.1.9.9" class="ltx_tr">
<th id="S4.T8.6.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ShuffleAttn (RH)</th>
<td id="S4.T8.6.1.9.9.2" class="ltx_td ltx_align_center">72.78</td>
<td id="S4.T8.6.1.9.9.3" class="ltx_td ltx_align_center">92.63</td>
<td id="S4.T8.6.1.9.9.4" class="ltx_td ltx_align_center">83.61</td>
<td id="S4.T8.6.1.9.9.5" class="ltx_td ltx_align_center">80.37</td>
<td id="S4.T8.6.1.9.9.6" class="ltx_td ltx_align_center">79.28</td>
</tr>
<tr id="S4.T8.6.1.10.10" class="ltx_tr">
<th id="S4.T8.6.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">ShuffleAttn (TH)</th>
<td id="S4.T8.6.1.10.10.2" class="ltx_td ltx_align_center">74.07</td>
<td id="S4.T8.6.1.10.10.3" class="ltx_td ltx_align_center">93.21</td>
<td id="S4.T8.6.1.10.10.4" class="ltx_td ltx_align_center">84.19</td>
<td id="S4.T8.6.1.10.10.5" class="ltx_td ltx_align_center">81.43</td>
<td id="S4.T8.6.1.10.10.6" class="ltx_td ltx_align_center">80.34</td>
</tr>
<tr id="S4.T8.6.1.11.11" class="ltx_tr">
<th id="S4.T8.6.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CBAM (Tr)</th>
<td id="S4.T8.6.1.11.11.2" class="ltx_td ltx_align_center">73.11</td>
<td id="S4.T8.6.1.11.11.3" class="ltx_td ltx_align_center">93.01</td>
<td id="S4.T8.6.1.11.11.4" class="ltx_td ltx_align_center">83.11</td>
<td id="S4.T8.6.1.11.11.5" class="ltx_td ltx_align_center">80.17</td>
<td id="S4.T8.6.1.11.11.6" class="ltx_td ltx_align_center">79.33</td>
</tr>
<tr id="S4.T8.6.1.12.12" class="ltx_tr">
<th id="S4.T8.6.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CBAM (RH)</th>
<td id="S4.T8.6.1.12.12.2" class="ltx_td ltx_align_center">72.85</td>
<td id="S4.T8.6.1.12.12.3" class="ltx_td ltx_align_center">92.46</td>
<td id="S4.T8.6.1.12.12.4" class="ltx_td ltx_align_center">83.54</td>
<td id="S4.T8.6.1.12.12.5" class="ltx_td ltx_align_center">80.73</td>
<td id="S4.T8.6.1.12.12.6" class="ltx_td ltx_align_center">79.21</td>
</tr>
<tr id="S4.T8.6.1.13.13" class="ltx_tr">
<th id="S4.T8.6.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">CBAM (TH)</th>
<td id="S4.T8.6.1.13.13.2" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.13.13.2.1" class="ltx_text ltx_font_bold">74.53</span></td>
<td id="S4.T8.6.1.13.13.3" class="ltx_td ltx_align_center">93.09</td>
<td id="S4.T8.6.1.13.13.4" class="ltx_td ltx_align_center">84.11</td>
<td id="S4.T8.6.1.13.13.5" class="ltx_td ltx_align_center">81.06</td>
<td id="S4.T8.6.1.13.13.6" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.13.13.6.1" class="ltx_text ltx_font_bold">80.46</span></td>
</tr>
<tr id="S4.T8.6.1.14.14" class="ltx_tr">
<th id="S4.T8.6.1.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T8.6.1.14.14.1.1" class="ltx_text">
<span id="S4.T8.6.1.14.14.1.1.1" class="ltx_inline-block ltx_align_left">
<span id="S4.T8.6.1.14.14.1.1.1.1" class="ltx_p">ECAAttn</span>
<span id="S4.T8.6.1.14.14.1.1.1.2" class="ltx_p">(TH)</span>
</span></span></th>
<th id="S4.T8.6.1.14.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Day</th>
<td id="S4.T8.6.1.14.14.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.14.14.3.1" class="ltx_text ltx_font_bold">74.75</span></td>
<td id="S4.T8.6.1.14.14.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.14.14.4.1" class="ltx_text ltx_font_bold">94.51</span></td>
<td id="S4.T8.6.1.14.14.5" class="ltx_td ltx_align_center ltx_border_t">84.16</td>
<td id="S4.T8.6.1.14.14.6" class="ltx_td ltx_align_center ltx_border_t">81.09</td>
<td id="S4.T8.6.1.14.14.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.14.14.7.1" class="ltx_text ltx_font_bold">80.65</span></td>
</tr>
<tr id="S4.T8.6.1.15.15" class="ltx_tr">
<th id="S4.T8.6.1.15.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Night</th>
<td id="S4.T8.6.1.15.15.2" class="ltx_td ltx_align_center">72.00</td>
<td id="S4.T8.6.1.15.15.3" class="ltx_td ltx_align_center">91.84</td>
<td id="S4.T8.6.1.15.15.4" class="ltx_td ltx_align_center">83.56</td>
<td id="S4.T8.6.1.15.15.5" class="ltx_td ltx_align_center">79.74</td>
<td id="S4.T8.6.1.15.15.6" class="ltx_td ltx_align_center">78.74</td>
</tr>
<tr id="S4.T8.6.1.16.16" class="ltx_tr">
<th id="S4.T8.6.1.16.16.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Overcast</th>
<td id="S4.T8.6.1.16.16.2" class="ltx_td ltx_align_center">71.96</td>
<td id="S4.T8.6.1.16.16.3" class="ltx_td ltx_align_center">92.67</td>
<td id="S4.T8.6.1.16.16.4" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.16.16.4.1" class="ltx_text ltx_font_bold">84.44</span></td>
<td id="S4.T8.6.1.16.16.5" class="ltx_td ltx_align_center">80.09</td>
<td id="S4.T8.6.1.16.16.6" class="ltx_td ltx_align_center">79.18</td>
</tr>
<tr id="S4.T8.6.1.17.17" class="ltx_tr">
<th id="S4.T8.6.1.17.17.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Challenge</th>
<td id="S4.T8.6.1.17.17.2" class="ltx_td ltx_align_center">73.25</td>
<td id="S4.T8.6.1.17.17.3" class="ltx_td ltx_align_center">93.11</td>
<td id="S4.T8.6.1.17.17.4" class="ltx_td ltx_align_center">83.78</td>
<td id="S4.T8.6.1.17.17.5" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.17.17.5.1" class="ltx_text ltx_font_bold">81.88</span></td>
<td id="S4.T8.6.1.17.17.6" class="ltx_td ltx_align_center">80.14</td>
</tr>
<tr id="S4.T8.6.1.18.18" class="ltx_tr">
<th id="S4.T8.6.1.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T8.6.1.18.18.1.1" class="ltx_text">
<span id="S4.T8.6.1.18.18.1.1.1" class="ltx_inline-block ltx_align_left">
<span id="S4.T8.6.1.18.18.1.1.1.1" class="ltx_p">ShuffleAttn</span>
<span id="S4.T8.6.1.18.18.1.1.1.2" class="ltx_p">(TH)</span>
</span></span></th>
<th id="S4.T8.6.1.18.18.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Day</th>
<td id="S4.T8.6.1.18.18.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.18.18.3.1" class="ltx_text ltx_font_bold">75.28</span></td>
<td id="S4.T8.6.1.18.18.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.18.18.4.1" class="ltx_text ltx_font_bold">94.64</span></td>
<td id="S4.T8.6.1.18.18.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.18.18.5.1" class="ltx_text ltx_font_bold">84.72</span></td>
<td id="S4.T8.6.1.18.18.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.18.18.6.1" class="ltx_text ltx_font_bold">81.85</span></td>
<td id="S4.T8.6.1.18.18.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.18.18.7.1" class="ltx_text ltx_font_bold">81.04</span></td>
</tr>
<tr id="S4.T8.6.1.19.19" class="ltx_tr">
<th id="S4.T8.6.1.19.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Night</th>
<td id="S4.T8.6.1.19.19.2" class="ltx_td ltx_align_center">71.79</td>
<td id="S4.T8.6.1.19.19.3" class="ltx_td ltx_align_center">92.21</td>
<td id="S4.T8.6.1.19.19.4" class="ltx_td ltx_align_center">83.30</td>
<td id="S4.T8.6.1.19.19.5" class="ltx_td ltx_align_center">78.95</td>
<td id="S4.T8.6.1.19.19.6" class="ltx_td ltx_align_center">78.21</td>
</tr>
<tr id="S4.T8.6.1.20.20" class="ltx_tr">
<th id="S4.T8.6.1.20.20.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Overcast</th>
<td id="S4.T8.6.1.20.20.2" class="ltx_td ltx_align_center">73.57</td>
<td id="S4.T8.6.1.20.20.3" class="ltx_td ltx_align_center">92.42</td>
<td id="S4.T8.6.1.20.20.4" class="ltx_td ltx_align_center">84.32</td>
<td id="S4.T8.6.1.20.20.5" class="ltx_td ltx_align_center">80.95</td>
<td id="S4.T8.6.1.20.20.6" class="ltx_td ltx_align_center">80.00</td>
</tr>
<tr id="S4.T8.6.1.21.21" class="ltx_tr">
<th id="S4.T8.6.1.21.21.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Challenge</th>
<td id="S4.T8.6.1.21.21.2" class="ltx_td ltx_align_center">72.42</td>
<td id="S4.T8.6.1.21.21.3" class="ltx_td ltx_align_center">92.90</td>
<td id="S4.T8.6.1.21.21.4" class="ltx_td ltx_align_center">84.21</td>
<td id="S4.T8.6.1.21.21.5" class="ltx_td ltx_align_center">81.27</td>
<td id="S4.T8.6.1.21.21.6" class="ltx_td ltx_align_center">79.62</td>
</tr>
<tr id="S4.T8.6.1.22.22" class="ltx_tr">
<th id="S4.T8.6.1.22.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T8.6.1.22.22.1.1" class="ltx_text">
<span id="S4.T8.6.1.22.22.1.1.1" class="ltx_inline-block ltx_align_left">
<span id="S4.T8.6.1.22.22.1.1.1.1" class="ltx_p">CBAM</span>
<span id="S4.T8.6.1.22.22.1.1.1.2" class="ltx_p">(TH)</span>
</span></span></th>
<th id="S4.T8.6.1.22.22.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Day</th>
<td id="S4.T8.6.1.22.22.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.22.22.3.1" class="ltx_text ltx_font_bold">76.04</span></td>
<td id="S4.T8.6.1.22.22.4" class="ltx_td ltx_align_center ltx_border_t">94.07</td>
<td id="S4.T8.6.1.22.22.5" class="ltx_td ltx_align_center ltx_border_t">84.89</td>
<td id="S4.T8.6.1.22.22.6" class="ltx_td ltx_align_center ltx_border_t">80.78</td>
<td id="S4.T8.6.1.22.22.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.22.22.7.1" class="ltx_text ltx_font_bold">81.07</span></td>
</tr>
<tr id="S4.T8.6.1.23.23" class="ltx_tr">
<th id="S4.T8.6.1.23.23.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Night</th>
<td id="S4.T8.6.1.23.23.2" class="ltx_td ltx_align_center">72.68</td>
<td id="S4.T8.6.1.23.23.3" class="ltx_td ltx_align_center">92.55</td>
<td id="S4.T8.6.1.23.23.4" class="ltx_td ltx_align_center">83.20</td>
<td id="S4.T8.6.1.23.23.5" class="ltx_td ltx_align_center">78.77</td>
<td id="S4.T8.6.1.23.23.6" class="ltx_td ltx_align_center">78.62</td>
</tr>
<tr id="S4.T8.6.1.24.24" class="ltx_tr">
<th id="S4.T8.6.1.24.24.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Overcast</th>
<td id="S4.T8.6.1.24.24.2" class="ltx_td ltx_align_center">73.30</td>
<td id="S4.T8.6.1.24.24.3" class="ltx_td ltx_align_center">92.53</td>
<td id="S4.T8.6.1.24.24.4" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.24.24.4.1" class="ltx_text ltx_font_bold">85.15</span></td>
<td id="S4.T8.6.1.24.24.5" class="ltx_td ltx_align_center">80.67</td>
<td id="S4.T8.6.1.24.24.6" class="ltx_td ltx_align_center">79.94</td>
</tr>
<tr id="S4.T8.6.1.25.25" class="ltx_tr">
<th id="S4.T8.6.1.25.25.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Challenge</th>
<td id="S4.T8.6.1.25.25.2" class="ltx_td ltx_align_center">74.10</td>
<td id="S4.T8.6.1.25.25.3" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.25.25.3.1" class="ltx_text ltx_font_bold">94.28</span></td>
<td id="S4.T8.6.1.25.25.4" class="ltx_td ltx_align_center">82.70</td>
<td id="S4.T8.6.1.25.25.5" class="ltx_td ltx_align_center"><span id="S4.T8.6.1.25.25.5.1" class="ltx_text ltx_font_bold">82.61</span></td>
<td id="S4.T8.6.1.25.25.6" class="ltx_td ltx_align_center">80.93</td>
</tr>
<tr id="S4.T8.6.1.26.26" class="ltx_tr">
<th id="S4.T8.6.1.26.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="5"><span id="S4.T8.6.1.26.26.1.1" class="ltx_text">DSF-NAS</span></th>
<th id="S4.T8.6.1.26.26.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Day</th>
<td id="S4.T8.6.1.26.26.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.26.26.3.1" class="ltx_text ltx_font_bold">75.68</span></td>
<td id="S4.T8.6.1.26.26.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.26.26.4.1" class="ltx_text ltx_font_bold">94.25</span></td>
<td id="S4.T8.6.1.26.26.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.26.26.5.1" class="ltx_text ltx_font_bold">84.35</span></td>
<td id="S4.T8.6.1.26.26.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.26.26.6.1" class="ltx_text ltx_font_bold">81.85</span></td>
<td id="S4.T8.6.1.26.26.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.6.1.26.26.7.1" class="ltx_text ltx_font_bold">81.03</span></td>
</tr>
<tr id="S4.T8.6.1.27.27" class="ltx_tr">
<th id="S4.T8.6.1.27.27.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Night</th>
<td id="S4.T8.6.1.27.27.2" class="ltx_td ltx_align_center">72.32</td>
<td id="S4.T8.6.1.27.27.3" class="ltx_td ltx_align_center">91.94</td>
<td id="S4.T8.6.1.27.27.4" class="ltx_td ltx_align_center">83.85</td>
<td id="S4.T8.6.1.27.27.5" class="ltx_td ltx_align_center">80.51</td>
<td id="S4.T8.6.1.27.27.6" class="ltx_td ltx_align_center">79.12</td>
</tr>
<tr id="S4.T8.6.1.28.28" class="ltx_tr">
<th id="S4.T8.6.1.28.28.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Overcast</th>
<td id="S4.T8.6.1.28.28.2" class="ltx_td ltx_align_center">73.15</td>
<td id="S4.T8.6.1.28.28.3" class="ltx_td ltx_align_center">93.46</td>
<td id="S4.T8.6.1.28.28.4" class="ltx_td ltx_align_center">83.79</td>
<td id="S4.T8.6.1.28.28.5" class="ltx_td ltx_align_center">80.60</td>
<td id="S4.T8.6.1.28.28.6" class="ltx_td ltx_align_center">79.52</td>
</tr>
<tr id="S4.T8.6.1.29.29" class="ltx_tr">
<th id="S4.T8.6.1.29.29.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Challenge</th>
<td id="S4.T8.6.1.29.29.2" class="ltx_td ltx_align_center">72.90</td>
<td id="S4.T8.6.1.29.29.3" class="ltx_td ltx_align_center">93.44</td>
<td id="S4.T8.6.1.29.29.4" class="ltx_td ltx_align_center">83.29</td>
<td id="S4.T8.6.1.29.29.5" class="ltx_td ltx_align_center">81.59</td>
<td id="S4.T8.6.1.29.29.6" class="ltx_td ltx_align_center">79.81</td>
</tr>
<tr id="S4.T8.6.1.30.30" class="ltx_tr">
<th id="S4.T8.6.1.30.30.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Full</th>
<td id="S4.T8.6.1.30.30.2" class="ltx_td ltx_align_center">74.68</td>
<td id="S4.T8.6.1.30.30.3" class="ltx_td ltx_align_center">92.65</td>
<td id="S4.T8.6.1.30.30.4" class="ltx_td ltx_align_center">83.90</td>
<td id="S4.T8.6.1.30.30.5" class="ltx_td ltx_align_center">81.67</td>
<td id="S4.T8.6.1.30.30.6" class="ltx_td ltx_align_center">80.56</td>
</tr>
<tr id="S4.T8.6.1.31.31" class="ltx_tr">
<th id="S4.T8.6.1.31.31.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T8.6.1.31.31.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<th id="S4.T8.6.1.31.31.2" class="ltx_td ltx_th ltx_th_row"></th>
<td id="S4.T8.6.1.31.31.3" class="ltx_td"></td>
<td id="S4.T8.6.1.31.31.4" class="ltx_td"></td>
<td id="S4.T8.6.1.31.31.5" class="ltx_td"></td>
<td id="S4.T8.6.1.31.31.6" class="ltx_td"></td>
<td id="S4.T8.6.1.31.31.7" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering">Tr – Trained head  TH – Thermal head  RH – RGB head</figcaption>
</figure>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p"><span id="S4.SS3.p7.1.1" class="ltx_text ltx_font_bold">Computational Benchmarks:</span> We compiled our CBAM fusion models using TorchInductor and conducted benchmarks on a Titan RTX. The inference time for the scene-adaptive fusion model is 0.032 seconds per individual image pair, while the scene-agnostic variant clocks in at 0.028 seconds. These times are comparable with other recent multimodal object detection approaches (<a href="#S4.T4" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>, <a href="#S4.T5" title="Table 5 ‣ 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) and meet the speed requirements for real-time autonomous driving applications.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Studies</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p"><span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_bold">Fusion Module Design:</span> We conduct an ablation study using the M<sup id="S4.SS4.p1.1.2" class="ltx_sup">3</sup>FD dataset to explore the effects of different fusion modules and architectures (<a href="#S4.T8" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">8</span></a>). We compare our CBAM-based RGB-X fusion approach against two other attention modules: ECAAttn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and ShuffleAttn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. Furthermore, we also compare against custom fusion modules (DSF-NAS) designed purposely for this fusion task via neural architecture search. In particular, we use Bilevel Multimodal Neural Architecture Search <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> (BM-NAS) to automate this design as its gradient-based optimization approach makes it faster compared to other NAS methods based on reinforcement learning and genetic algorithms. Specifically, we allow BM-NAS to optimize over sequential applications of two operations chosen from sum, spatial attention, channel attentions from CBAM and ECAAttn, and 2D convolution of concatenated features.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">We first train for fusion using scene-agnostic CBAM, ECAAttn, and ShuffleAttn modules along with either a trainable, frozen thermal, or frozen RGB detector head. We find that training with a frozen detector head initialized with thermal weights performs the best in <a href="#S4.T8" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">8</span></a>, possibly due to the lower variance of thermal data across different scenes. We repeat the study under the scene-adaptive regime, with the previous three attention modules and frozen thermal detection heads, along with DSF-NAS fusion modules. Overall, we find similar performance between DSF-NAS and CBAM-based fusion networks. However, CBAM fusion models exhibit better performance on scene-specific data verifying its use in our proposed modular framework.</p>
</div>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T9.3.1.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="S4.T9.4.2" class="ltx_text" style="font-size:90%;">Object detection results (mAP@0.5) of our scene-adaptive CBAM model trained using decreasing amounts of data.</span></figcaption>
<div id="S4.T9.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:213.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(71.1pt,-43.8pt) scale(1.69516505485922,1.69516505485922) ;">
<table id="S4.T9.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T9.1.1.2.1" class="ltx_tr">
<th id="S4.T9.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" rowspan="2">
<span id="S4.T9.1.1.2.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T9.1.1.2.1.1.2" class="ltx_text">Dataset</span>
</th>
<td id="S4.T9.1.1.2.1.2" class="ltx_td ltx_align_center" colspan="4">% of Original Training Set</td>
</tr>
<tr id="S4.T9.1.1.3.2" class="ltx_tr">
<td id="S4.T9.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">100%</td>
<td id="S4.T9.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50%</td>
<td id="S4.T9.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25%</td>
<td id="S4.T9.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">1%</td>
</tr>
<tr id="S4.T9.1.1.4.3" class="ltx_tr">
<th id="S4.T9.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T9.1.1.4.3.1.1" class="ltx_ERROR undefined">\hlineB</span>3
FLIR</th>
<td id="S4.T9.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r">86.16</td>
<td id="S4.T9.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r">85.70</td>
<td id="S4.T9.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r">84.60</td>
<td id="S4.T9.1.1.4.3.5" class="ltx_td ltx_align_center">75.72</td>
</tr>
<tr id="S4.T9.1.1.1" class="ltx_tr">
<th id="S4.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">M<sup id="S4.T9.1.1.1.1.1" class="ltx_sup">3</sup>FD</th>
<td id="S4.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">81.46</td>
<td id="S4.T9.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">78.34</td>
<td id="S4.T9.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">77.65</td>
<td id="S4.T9.1.1.1.5" class="ltx_td ltx_align_center">41.94</td>
</tr>
<tr id="S4.T9.1.1.5.4" class="ltx_tr">
<th id="S4.T9.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">STF-Clear</th>
<td id="S4.T9.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r">80.65</td>
<td id="S4.T9.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r">80.73</td>
<td id="S4.T9.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r">80.10</td>
<td id="S4.T9.1.1.5.4.5" class="ltx_td ltx_align_center">73.76</td>
</tr>
<tr id="S4.T9.1.1.6.5" class="ltx_tr">
<th id="S4.T9.1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">STF-Full</th>
<td id="S4.T9.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r">83.11</td>
<td id="S4.T9.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r">83.06</td>
<td id="S4.T9.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r">82.99</td>
<td id="S4.T9.1.1.6.5.5" class="ltx_td ltx_align_center">75.64</td>
</tr>
<tr id="S4.T9.1.1.7.6" class="ltx_tr">
<th id="S4.T9.1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T9.1.1.7.6.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T9.1.1.7.6.2" class="ltx_td"></td>
<td id="S4.T9.1.1.7.6.3" class="ltx_td"></td>
<td id="S4.T9.1.1.7.6.4" class="ltx_td"></td>
<td id="S4.T9.1.1.7.6.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Effect of Training Dataset Size on Fusion: </span>
As our proposed fusion method looks to fuse pretrained networks with lightweight fusion modules, the fusion process should still be effective and be able to generalize even when done with limited amounts of training data. To determine the extent of this, we perform fusion using 100%, 50%, 25%, and 1% of the original datasets in <a href="#S4.T9" title="In 4.4 Ablation Studies ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">9</span></a>. Overall, we find that competitive results can still be achieved using only 25% of the original training data results, with the exception of M<sup id="S4.SS4.p3.1.2" class="ltx_sup">3</sup>FD which decays quicker than the rest.</p>
</div>
<figure id="S4.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T10.5.2.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="S4.T10.2.1" class="ltx_text" style="font-size:90%;">Object detection results (mAP@0.5) of our scene-adaptive CBAM model on unknown scenes in M<sup id="S4.T10.2.1.1" class="ltx_sup">3</sup>FD dataset.</span></figcaption>
<div id="S4.T10.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:173.4pt;height:60.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-43.2pt,15.0pt) scale(0.667251769734755,0.667251769734755) ;">
<table id="S4.T10.6.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T10.6.1.1.1" class="ltx_tr">
<th id="S4.T10.6.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" rowspan="2">
<span id="S4.T10.6.1.1.1.1.1" class="ltx_ERROR undefined">\hlineB</span>3
<span id="S4.T10.6.1.1.1.1.2" class="ltx_text">Test</span>
</th>
<td id="S4.T10.6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_l" colspan="4">Excluded Training Scene</td>
</tr>
<tr id="S4.T10.6.1.2.2" class="ltx_tr">
<td id="S4.T10.6.1.2.2.1" class="ltx_td ltx_align_center ltx_border_t">Day</td>
<td id="S4.T10.6.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">Night</td>
<td id="S4.T10.6.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Overcast</td>
<td id="S4.T10.6.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Challenge</td>
</tr>
<tr id="S4.T10.6.1.3.3" class="ltx_tr">
<th id="S4.T10.6.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Excluded Scene</th>
<td id="S4.T10.6.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">73.17</td>
<td id="S4.T10.6.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">93.50</td>
<td id="S4.T10.6.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">84.18</td>
<td id="S4.T10.6.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">80.74</td>
</tr>
<tr id="S4.T10.6.1.4.4" class="ltx_tr">
<th id="S4.T10.6.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">All Scenes</th>
<td id="S4.T10.6.1.4.4.2" class="ltx_td ltx_align_center">80.48</td>
<td id="S4.T10.6.1.4.4.3" class="ltx_td ltx_align_center">81.30</td>
<td id="S4.T10.6.1.4.4.4" class="ltx_td ltx_align_center">81.27</td>
<td id="S4.T10.6.1.4.4.5" class="ltx_td ltx_align_center">80.98</td>
</tr>
<tr id="S4.T10.6.1.5.5" class="ltx_tr">
<th id="S4.T10.6.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T10.6.1.5.5.1.1" class="ltx_ERROR undefined">\hlineB</span>3</th>
<td id="S4.T10.6.1.5.5.2" class="ltx_td"></td>
<td id="S4.T10.6.1.5.5.3" class="ltx_td"></td>
<td id="S4.T10.6.1.5.5.4" class="ltx_td"></td>
<td id="S4.T10.6.1.5.5.5" class="ltx_td"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_bold">Performance on Unknown Scenes:</span> As our proposed method requires scenes to be known during training, we further investigate the performance of our method on unknown/unexpected scenes. In this experiment, our scene-specific CBAM fusion modules and scene classifiers are trained with one scene data excluded, and tested on that excluded scene and all test images. We observed minor regression in overall performance (row 2 in <a href="#S4.T10" title="In 4.4 Ablation Studies ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">10</span></a>) compared with our scene-adaptive model trained on all scenes (81.46 in <a href="#S4.T4" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>), which is expected as there is no fusion module trained specifically for that unknown scene. However, the overall mAP@0.5 in all cases is still higher than scene-agnostic model trained on all scenes (80.46 in <a href="#S4.T4" title="In 4.3 Performance Evaluation ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">4</span></a>). Specifically, in the case of <em id="S4.SS4.p4.1.2" class="ltx_emph ltx_font_italic">night</em> or <em id="S4.SS4.p4.1.3" class="ltx_emph ltx_font_italic">overcast</em> scene excluded, the object detection performance on the unknown scene (row 1 in <a href="#S4.T10" title="In 4.4 Ablation Studies ‣ 4 Results ‣ RGB-X Object Detection via Scene-Specific Fusion Modules" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span> <span class="ltx_text ltx_ref_tag">10</span></a>) is higher than the scene-agnostic model. This is possibly because our scene classifier tends to select a fusion module trained on a similar scene, for instance, classifying <em id="S4.SS4.p4.1.4" class="ltx_emph ltx_font_italic">night</em> image as <em id="S4.SS4.p4.1.5" class="ltx_emph ltx_font_italic">overcast</em> and vice versa.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our method requires aligned RGB-X data, which is not always available. The scene-specific modules require scenes to be known during training, and the approach is not expected to work as well in unexpected weather conditions. Future work looks to incorporate unsupervised <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and online learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to adapt to unexpected conditions.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We presented a novel RGB-X object detection model that improves autonomous vehicle perception in different weather and lighting conditions. We showed that our method is superior compared to existing works on two RGB-T and one RGB-gated object detection benchmarks, demonstrating the robustness of our scene-adaptive models and generalizability to different modalities. Furthermore, our use of lightweight fusion modules brings us closer to achieving a more modular design for deep sensor fusion. For future work, we look to train and leverage larger pretrained models for both RGB and thermal modalities via multitask learning and to incorporate into an online learning framework to adapt to unexpected weather patterns.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Mario Bijelic, Tobias Gruber, Fahim Mannan, Florian Kraus, Werner Ritter, Klaus Dietmayer, and Felix Heide.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Seeing through fog without seeing fog: Deep multimodal sensor fusion in unseen adverse weather.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">nuscenes: A multimodal dataset for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 11621–11631, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Yue Cao, Junchi Bin, Jozsef Hamari, Erik Blasch, and Zheng Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Multimodal object detection by channel switching and spatial attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 403–411, 2023.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">End-to-end object detection with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I 16</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 213–229. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Yi-Ting Chen, Jinghao Shi, Zelin Ye, Christoph Mertz, Deva Ramanan, and Shu Kong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Multimodal object detection via probabilistic ensembling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part IX</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 139–158. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Sri Aditya Deevi and Deepak Mishra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Expeditious object pose estimation for autonomous robotic grasping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision and Image Processing</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 15–30. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Flir thermal adas dataset, 2019.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Jamil Fayyad, Mohammad A. Jaradat, Dominique Gruyer, and Homayoun Najjaran.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Deep Learning Sensor Fusion for Autonomous Vehicle Perception and Localization: A Review.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Sensors</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 20(15):4220, July 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Di Feng, Christian Haase-Schütz, Lars Rosenbaum, Heinz Hertlein, Claudius Glaeser, Fabian Timm, Werner Wiesbeck, and Klaus Dietmayer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Deep multi-modal object detection and semantic segmentation for autonomous driving: Datasets, methods, and challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Intelligent Transportation Systems</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 22(3):1341–1360, Mar 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Haolong Fu, Shixun Wang, Puhong Duan, Changyan Xiao, Renwei Dian, Shutao Li, and Zhiyong Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Lraf-net: Long-range attention fusion network for visible–infrared object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Neural Networks and Learning Systems</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Lu Gan, Connor Lee, and Soon-Jo Chung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Unsupervised RGB-to-thermal domain adaptation via multi-domain attention network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2023 IEEE International Conference on Robotics and Automation (ICRA)</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 6014–6020. IEEE, 2023.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Vision meets robotics: The kitti dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The International Journal of Robotics Research</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 32(11):1231–1237, 2013.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Are we ready for autonomous driving? the kitti vision benchmark suite.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2012 IEEE conference on computer vision and pattern recognition</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 3354–3361. IEEE, 2012.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Searching for mobilenetv3.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 1314–1324, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Connor Lee, Jonathan Gustafsson Frennert, Lu Gan, Matthew Anderson, and Soon-Jo Chung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Online self-supervised thermal water segmentation for aerial vehicles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">. Accepted, 2023.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Mingjian Liang, Junjie Hu, Chenyu Bao, Hua Feng, Fuqin Deng, and Tin Lun Lam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Explicit attention-enhanced fusion for rgb-thermal perception tasks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Deep continuous fusion for multi-sensor 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision (ECCV)</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 641–656, 2018.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Microsoft COCO: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision – ECCV 2014</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 740–755, Cham, 2014. Springer International Publishing.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Jinyuan Liu, Xin Fan, Zhanbo Huang, Guanyao Wu, Risheng Liu, Wei Zhong, and Zhongxuan Luo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Target-aware dual adversarial learning and a multi-scenario multi-modality benchmark to fuse infrared and visible for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 5802–5811, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Jingjing Liu, Shaoting Zhang, Shu Wang, and Dimitris Metaxas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Multispectral Deep Neural Networks for Pedestrian Detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Procedings of the British Machine Vision Conference 2016</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 73.1–73.13, York, UK, 2016. British Machine Vision Association.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Ssd: Single shot multibox detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part I 14</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 21–37. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Swin transformer: Hierarchical vision transformer using shifted windows.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 10012–10022, 2021.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Mohammed Bany Muhammad and Mohammed Yeasin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Eigen-cam: Class activation map using principal components.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 International Joint Conference on Neural Networks (IJCNN)</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 1–7. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Carbon emissions and large neural network training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.10350</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Fang Qingyun, Han Dapeng, and Wang Zhaokui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Cross-modality fusion transformer for multispectral object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2111.00273</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Joseph Redmon and Ali Farhadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Yolov3: An incremental improvement.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1804.02767</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 28, 2015.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Scalability in perception for autonomous driving: Waymo open dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 2446–2454, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Yiming Sun, Bing Cao, Pengfei Zhu, and Qinghua Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Drone-based rgb-infrared cross-modality vehicle detection via uncertainty-aware learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Circuits and Systems for Video Technology</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 32(10):6700–6713, 2022.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Mingxing Tan and Quoc Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Efficientnet: Rethinking model scaling for convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International conference on machine learning</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 6105–6114. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Mingxing Tan, Ruoming Pang, and Quoc V Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Efficientdet: Scalable and efficient object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 10781–10790, 2020.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Jörg Wagner, Volker Fischer, Michael Herman, and Sven Behnke.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Multispectral Pedestrian Detection using Deep Fusion Convolutional Neural Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ESANN</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Qilong Wang, Banggu Wu, Pengfei Zhu, Peihua Li, Wangmeng Zuo, and Qinghua Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Eca-net: Efficient channel attention for deep convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 11534–11542, 2020.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Cbam: Convolutional block attention module.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European conference on computer vision (ECCV)</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 3–19, 2018.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Danfei Xu, Dragomir Anguelov, and Ashesh Jain.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Pointfusion: Deep sensor fusion for 3d bounding box estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 244–253, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Han Xu, Jiayi Ma, Junjun Jiang, Xiaojie Guo, and Haibin Ling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">U2fusion: A unified unsupervised image fusion network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 44(1):502–518, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Yihang Yin, Siyu Huang, and Xiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Bm-nas: Bilevel multimodal neural architecture search.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial Intelligence</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, volume 36, pages 8901–8909, 2022.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashisht Madhavan, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Bdd100k: A diverse driving dataset for heterogeneous multitask learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, June 2020.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Heng Zhang, Elisa Fromont, Sébastien Lefevre, and Bruno Avignon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Multispectral fusion for object detection with cyclic fuse-and-refine blocks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE International Conference on Image Processing (ICIP)</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 276–280. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Heng Zhang, Elisa Fromont, Sébastien Lefèvre, and Bruno Avignon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Guided attentive feature fusion for multispectral pedestrian detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, pages 72–80, 2021.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Qing-Long Zhang and Yu-Bin Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Sa-net: Shuffle attention for deep convolutional neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, pages 2235–2239. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Yaohui Zhu, Xiaoyu Sun, Miao Wang, and Hua Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Multi-modal feature pyramid transformer for rgb-infrared object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Intelligent Transportation Systems</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Zhengxia Zou, Keyan Chen, Zhenwei Shi, Yuhong Guo, and Jieping Ye.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Object detection in 20 years: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:title" content="RGB-X Object Detection via Scene-Specific Fusion Modules"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2310.19371" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2310.19372" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2310.19372">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2310.19372" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2310.19373" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 22:47:00 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
