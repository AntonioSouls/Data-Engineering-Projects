<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2010.09355] SHREC 2020 track: 6D object pose estimation</title><meta property="og:description" content="6D pose estimation is crucial for augmented reality, virtual reality, robotic manipulation and visual navigation. However, the problem is challenging due to the variety of objects in the real world. They have varying 3…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SHREC 2020 track: 6D object pose estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SHREC 2020 track: 6D object pose estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2010.09355">

<!--Generated on Mon Feb 26 22:41:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\ConferenceSubmission</span><span id="p1.2" class="ltx_ERROR undefined">\WsPaper</span><span id="p1.3" class="ltx_ERROR undefined">\BibtexOrBiblatex</span><span id="p1.4" class="ltx_ERROR undefined">\electronicVersion</span><span id="p1.5" class="ltx_ERROR undefined">\PrintedOrElectronic</span>
</div>
<h1 class="ltx_title ltx_title_document">SHREC 2020 track: 6D object pose estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span id="id6.6.6" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:433.6pt;">
<span id="id6.6.6.6" class="ltx_p">Honglin Yuan<sup id="id6.6.6.6.1" class="ltx_sup"><span id="id6.6.6.6.1.1" class="ltx_text ltx_font_italic">1,∗</span></sup>,
Remco C. Veltkamp<sup id="id6.6.6.6.2" class="ltx_sup"><span id="id6.6.6.6.2.1" class="ltx_text ltx_font_italic">1,∗</span></sup>,
Georgios Albanis<sup id="id6.6.6.6.3" class="ltx_sup">2</sup>,
Nikolaos Zioulis<sup id="id6.6.6.6.4" class="ltx_sup">2</sup>,
Dimitrios Zarpalas<sup id="id6.6.6.6.5" class="ltx_sup">2</sup>,
Petros Daras<sup id="id6.6.6.6.6" class="ltx_sup">2</sup></span>
</span>

<br class="ltx_break">
<span id="id9.9.9" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:433.6pt;">
<span id="id7.7.7.1" class="ltx_p"><sup id="id7.7.7.1.1" class="ltx_sup">∗</sup> Track organizers</span>
<span id="id8.8.8.2" class="ltx_p ltx_align_center"><sup id="id8.8.8.2.1" class="ltx_sup">1</sup>Utrecht University, Netherlands</span>
<span id="id9.9.9.3" class="ltx_p ltx_align_center"><sup id="id9.9.9.3.1" class="ltx_sup">2</sup>Centre for Research and Technology Hellas, Greece</span>
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">6D pose estimation is crucial for augmented reality, virtual reality, robotic manipulation and visual navigation. However, the problem is challenging due to the variety of objects in the real world. They have varying 3D shape and their appearances in captured images are affected by sensor noise, changing lighting conditions and occlusions between objects. Different pose estimation methods have different strengths and weaknesses, depending on feature representations and scene contents. At the same time, existing 3D datasets that are used for data-driven methods to estimate 6D poses have limited view angles and low resolution.</p>
<p id="id11.id2" class="ltx_p">To address these issues, we organize the Shape Retrieval Challenge benchmark on 6D pose estimation and create a physically accurate simulator that is able to generate photo-realistic color-and-depth image pairs with corresponding ground truth 6D poses. From captured color and depth images, we use this simulator to generate a 3D dataset which has 400 photo-realistic synthesized color-and-depth image pairs with various view angles for training, and another 100 captured and synthetic images for testing. Five research groups register in this track and two of them submitted their results.</p>
<p id="id12.id3" class="ltx_p">Data-driven methods are the current trend in 6D object pose estimation and our evaluation results show that approaches which fully exploit the color and geometric features are more robust for 6D pose estimation of reflective and texture-less objects and occlusion. This benchmark and comparative evaluation results have the potential to further enrich and boost the research of 6D object pose estimation and its applications.</p>
<span id="id13.id4" class="ltx_ERROR undefined">{CCSXML}</span>
<p id="id14.id5" class="ltx_p">&lt;ccs2012&gt;
&lt;concept&gt;
&lt;concept_id&gt;10002951.10003317.10003371.10003386&lt;/concept_id&gt;
&lt;concept_desc&gt;Information systems Multimedia and multimodal retrieval&lt;/concept_desc&gt;
&lt;concept_significance&gt;500&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;concept&gt;
&lt;concept_id&gt;10002951.10003317.10003359&lt;/concept_id&gt;
&lt;concept_desc&gt;Information systems Evaluation of retrieval results&lt;/concept_desc&gt;
&lt;concept_significance&gt;500&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;concept&gt;
&lt;concept_id&gt;10002951.10003317.10003371&lt;/concept_id&gt;
&lt;concept_desc&gt;Information systems Specialized information retrieval&lt;/concept_desc&gt;
&lt;concept_significance&gt;500&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;/ccs2012&gt;</p>
<span id="id15.id6" class="ltx_ERROR undefined">\ccsdesc</span>
<p id="id16.id7" class="ltx_p">[500]Information systems Multimedia and multimodal retrieval
<span id="id16.id7.1" class="ltx_ERROR undefined">\ccsdesc</span>[500]Information systems Evaluation of retrieval results
<span id="id16.id7.2" class="ltx_ERROR undefined">\ccsdesc</span>[500]Information systems Specialized information retrieval
<span id="id16.id7.3" class="ltx_ERROR undefined">\printccsdesc</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The ability to estimate 6D object pose including its orientation and location is essential for many applications, such as visual navigation, robot manipulation and virtual reality. The awareness of the 3D rotation and 3D translation matrix of objects in a scene is referred to as 6D, where the D stands for degrees of freedom pose. While it is possible to obtain the 6D pose with hand-crafted features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">MAMT15</a>]</cite>, these methods fail to predict poses for texture-less objects. With the advent of cheap RGB-D sensors, the precision of 6D object pose estimation is improved for both rich and low texture objects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">TSF18</a>]</cite>. Nonetheless, it remains a challenge as accurate 6D object pose and real-time object instance recognition are both required for the real-world applications.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Traditional 6D object pose estimation approaches work by first extracting color features from the RGB image and performing feature matching to get correspondences. Based on these correspondences, the 6D pose is estimated by solving a Perspective-n-Point (PnP) problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">KLS14</a>]</cite>.
Hand-crafted features, such as SIFT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">NH03</a>]</cite> and ORB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">MAMT15</a>]</cite>, are often used by these methods, for they are robust to scale, rotation, illumination and view angles. However, the heavy dependence on hand-crafted features and fixed matching process have limited empirical performances of these methods to predict 6D poses for texture-less object in poor light conditions or clustered scenes.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The emergency of commodity depth cameras has enabled many methods with RGB-D images as input <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">CC16</a>, <a href="#bib.bibx27" title="" class="ltx_ref">ZC17</a>]</cite> to estimate more accurate 6D pose for texture-less objects. Choi et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">CC16</a>]</cite> introduce a voting-based approach which further incorporates geometric and color information to predict poses in clustered scenes. To handle low texture objects, Hinterstoisser et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">HHC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>11</a>]</cite> propose template matching approach that builds different modalities to detect the known object and then estimate 6D poses. However, template-based methods are not robust to changing lighting conditions and occlusions. To address these issues, Brachmann et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">BKM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>14</a>]</cite> first regress an intermediate object coordinate with different voting scores which are used to predict correspondences and then predict the object pose with these correspondences.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">More recently, Convolutional Neural Networks (CNNs) and deep learning have been applied to the 6D pose estimation problem. PoseCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>]</cite> and PoseNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">KGC15</a>]</cite> directly regress from a RGB image to a 6D object pose by a CNN-based architecture. Unlike PoseCNN, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">TTS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>18</a>, <a href="#bib.bibx17" title="" class="ltx_ref">PZC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>17</a>]</cite> first predicts 2D projection of predefined 3D key points and then use these correspondence to estimate poses. The aforementioned approaches do not utilize the depth information, resulting in failing to predict poses for the same object with different scales.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To further improve the performance of the 6D object pose estimation, recent approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>, <a href="#bib.bibx11" title="" class="ltx_ref">JMP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>18</a>, <a href="#bib.bibx24" title="" class="ltx_ref">WXZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite> combine the color and depth information to estimate the 6D object pose. Ipose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">JMP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>18</a>]</cite> first processes the RGB image with the encoder-decoder architecture to obtain a coarse 6D pose and then refines the pose by the iterative closest point (ICP) algorithm based on depth information. However, the refinement method using ICP is time-consuming and cannot achieve real-time inference speed. Instead of using color and depth information separately, Michel et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">MKB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>17</a>]</cite> fuse the color and depth information in the early stage, where the depth information is treated as a fourth channel and concatenated with RGB channels. Other solutions including Densefusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">WXZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>, <a href="#bib.bibx5" title="" class="ltx_ref">CZA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite>, fuse the depth information in the later stage, which first extract visual and geometric features and then fuse these features together. The fused features are used to directly predict the 6D object pose. With depth information, these methods are more robust to occlusion and changing light conditions.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Even though more and more algorithms, aiming to estimate the 6D object pose have been published, it is unclear how well scenarios and methods perform. New approaches are usually compared with only a few competitors on a particular dataset. To address these issues, the BOP benchmark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">HMB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>18</a>]</cite> is proposed, which combines eight datasets in a unified format. However, their datasts have several limitations: the objects are often located in the center of the image plane; images are generated in similar distances; generating these datasets has high cost (time and money) associated with
ground truth annotation. Since we use synthetic data, we can provide high-quality data with minimum cost (e.g., human labor ). To compare and evaluate algorithms for robotics grasping, the OpenGRASP benchmarking suite <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">UKA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>11</a>]</cite> provides the simulation environment containing test cases, robot models and scenarios to test methods and rank them. However, the simulation environment is not photo-realistic and has the reality gap, while our simulator provides high-resolution extremely realistic images.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The LineMOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">HHC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>11</a>]</cite> and YCB-Video <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>]</cite> dataset are the two mostly used 3D object datasets for the 6D pose estimation. However, the view angles of captured images are limited and the objects are not easily accessible to other researchers. Other works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">DFI<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>15</a>]</cite> combine real and synthesized data to generate 3D object datasets, which render 3D object models on real backgrounds to produce images. While the backgrounds are realistic, the synthesized images are not photo-realistic. For example, the rendered objects are flying midair and out of context <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">DFI<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>15</a>]</cite>. Unlike these approaches, we use depth image based rendering (DIBR) to generate a 3D object dataset, which provides photo-realistic color-and-depth image pairs with ground truth 6D poses.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Our main contributions are summarized as follows:</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">(1) Datasets. Our training dataset is generated by a free-viewpoint DIBR approach, which provides a large amount of high-resolution photo-realistic color-and-depth images pairs with ground truth 6D poses. Besides, the synthesized images have plausible physical locations, lighting, and scale. A testing dataset combines real captured and synthesized images for testing approaches. Our datasets contain 3D models with a wide range of sizes, shapes, texture and occlusion.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">(2) A comprehensive evaluation of 6D object pose estimation approaches. We organize the Shape Retrieval Challenge (SHREC) benchmark on 6D pose estimation and use different evaluation metrics to compare the proposed methods based on our datasets. Evaluation results indicate that approaches that fully exploit the color and geometric features are more robust for 6D pose estimation of reflective and texture-less objects and occlusion.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Benchmark</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.3" class="ltx_p">Our 6D object pose estimation retrieval benchmark includes <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">8</annotation></semantics></math> objects of varying shape and texture. It has high resolution color-and-depth image pairs and high-quality 3D models. To facilitate data-driven approaches, we apply DIBR to generate 400 synthesized color-and-depth image pairs with resolution of <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="1280\times 720" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mn id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">1280</mn><mo lspace="0.222em" rspace="0.222em" id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">×</mo><mn id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml">720</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><times id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></times><cn type="integer" id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">1280</cn><cn type="integer" id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">720</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">1280\times 720</annotation></semantics></math> for training. Another <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S2.p1.3.m3.1a"><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><cn type="integer" id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">100</annotation></semantics></math> captured and synthesized color and depth images are used for testing.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Dataset</h3>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2010.09355/assets/dataset.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="287" height="174" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the dataset</figcaption>
</figure>
<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In order to cover as many aspects of pose estimation challenges as possible, our dataset contains a variety of objects with different sizes, shapes, texture, and reflective characteristics. For example, it is a challenge to estimate the pose of the texture-less object. Thus, when selecting objects, this issue should be considered. Besides, we also consider the portability. We aim to provide datasets with easily carrying, shipping and stored objects. In order to make the dataset reproducible, the cost of the object is taken into consideration as well. We choose the popular consumer products which are low price and easy to buy. With consideration of these practical issues, we choose eight representative objects to create our dataset, as shown in Figure <a href="#S2.F1" title="Figure 1 ‣ 2.1 Dataset ‣ 2 Benchmark ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">We use both real-world data and data generated from simulation for the 6D object pose estimation retrieval. The real-world data is captured by the Intel RealSense depth camera D415 with resolution of <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="1280\times 720" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mn id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">1280</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">720</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><times id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">1280</cn><cn type="integer" id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">720</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">1280\times 720</annotation></semantics></math>. However, the captured color-and-depth image pairs suffer from motion blur and misalignment caused by the hand-hold camera. We remove blurring images with the blur metric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">CDLN07</a>]</cite>. Even though an alignment method from Intel RealSense camera is applied, the captured color and depth image are still misaligned, especially when the camera is near the object. This is because it is difficult for previous approaches to find correspondences between color and depth images to achieve alignment.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Instead of finding correspondences between color-and-depth image pairs, we create a different depth map for each color image, which has better alignment with the color image. This map is generated by multi-view stereo from COLMAP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">SF16</a>]</cite>, a state-of-the-art 3D reconstruction system. Then we align the captured depth map to the estimated map by comparing the values and normals between two maps. In this way, we align the captured depth map to the captured color image. Apart from depth maps, we estimate object poses using the Structure-from-Motion(SfM) from COLMAP.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2010.09355/assets/x1.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="117" height="59" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The 3D warping process. It projects a point <math id="S2.F2.5.m1.1" class="ltx_Math" alttext="p_{1}" display="inline"><semantics id="S2.F2.5.m1.1b"><msub id="S2.F2.5.m1.1.1" xref="S2.F2.5.m1.1.1.cmml"><mi id="S2.F2.5.m1.1.1.2" xref="S2.F2.5.m1.1.1.2.cmml">p</mi><mn id="S2.F2.5.m1.1.1.3" xref="S2.F2.5.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F2.5.m1.1c"><apply id="S2.F2.5.m1.1.1.cmml" xref="S2.F2.5.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.5.m1.1.1.1.cmml" xref="S2.F2.5.m1.1.1">subscript</csymbol><ci id="S2.F2.5.m1.1.1.2.cmml" xref="S2.F2.5.m1.1.1.2">𝑝</ci><cn type="integer" id="S2.F2.5.m1.1.1.3.cmml" xref="S2.F2.5.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.5.m1.1d">p_{1}</annotation></semantics></math> in the left image plane to a world point <math id="S2.F2.6.m2.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S2.F2.6.m2.1b"><mi id="S2.F2.6.m2.1.1" xref="S2.F2.6.m2.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S2.F2.6.m2.1c"><ci id="S2.F2.6.m2.1.1.cmml" xref="S2.F2.6.m2.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.6.m2.1d">P</annotation></semantics></math> and then <math id="S2.F2.7.m3.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S2.F2.7.m3.1b"><mi id="S2.F2.7.m3.1.1" xref="S2.F2.7.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S2.F2.7.m3.1c"><ci id="S2.F2.7.m3.1.1.cmml" xref="S2.F2.7.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.7.m3.1d">P</annotation></semantics></math> is projected into the pixel position <math id="S2.F2.8.m4.1" class="ltx_Math" alttext="p_{2}" display="inline"><semantics id="S2.F2.8.m4.1b"><msub id="S2.F2.8.m4.1.1" xref="S2.F2.8.m4.1.1.cmml"><mi id="S2.F2.8.m4.1.1.2" xref="S2.F2.8.m4.1.1.2.cmml">p</mi><mn id="S2.F2.8.m4.1.1.3" xref="S2.F2.8.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F2.8.m4.1c"><apply id="S2.F2.8.m4.1.1.cmml" xref="S2.F2.8.m4.1.1"><csymbol cd="ambiguous" id="S2.F2.8.m4.1.1.1.cmml" xref="S2.F2.8.m4.1.1">subscript</csymbol><ci id="S2.F2.8.m4.1.1.2.cmml" xref="S2.F2.8.m4.1.1.2">𝑝</ci><cn type="integer" id="S2.F2.8.m4.1.1.3.cmml" xref="S2.F2.8.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.8.m4.1d">p_{2}</annotation></semantics></math> in the right image plane.</figcaption>
</figure>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">Our aim is to build 3D datasets containing rich viewpoints, scales and high resolutions which are the limitation for captured datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">HHC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>11</a>, <a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>]</cite>. Inspired by the low cost of producing very large-scale synthetic datasets with complete and accurate ground-truth information, as well as the recent successes of synthetic data
for training 6D pose estimation systems, we build a physically accurate simulator. Our simulator is based on DIBR and can generate high resolution photot-realistic color and depth images, and their corresponding ground truth 6D poses. DIBR performs 3D warping that projects pixels in the reference image to the world coordinate and then projects the world points to new positions in another image plane to get the new image, which avoids the global 3D reconstruction of the scene. Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1 Dataset ‣ 2 Benchmark ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the 3D warping process of DIBR.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p">During simulation, we provide sufficient variations of viewpoints to mimic a variety of object locations. For it is difficult to generate new images from the same image distribution, previous methods often randomly project objects into an arbitrary scene to produce the synthesized image. However, such synthesized images are unrealistic compared to real-world scenes. On contrast, our simulator provides realistic imagery with the corresponding 6D pose.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.2" class="ltx_p">We combine the synthesized and captured data to build the final dataset. It consists of two subsets: a training set of <math id="S2.SS1.p6.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="S2.SS1.p6.1.m1.1a"><mn id="S2.SS1.p6.1.m1.1.1" xref="S2.SS1.p6.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.1b"><cn type="integer" id="S2.SS1.p6.1.m1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.1c">400</annotation></semantics></math> synthesized color-and-depth image pairs and a testing set of <math id="S2.SS1.p6.2.m2.1" class="ltx_Math" alttext="100" display="inline"><semantics id="S2.SS1.p6.2.m2.1a"><mn id="S2.SS1.p6.2.m2.1.1" xref="S2.SS1.p6.2.m2.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.2.m2.1b"><cn type="integer" id="S2.SS1.p6.2.m2.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.2.m2.1c">100</annotation></semantics></math> captured and synthesized color-and-depth image pairs. For each frame we provide the following data:</p>
</div>
<div id="S2.SS1.p7" class="ltx_para">
<p id="S2.SS1.p7.1" class="ltx_p"><math id="S2.SS1.p7.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p7.1.m1.1a"><mo id="S2.SS1.p7.1.m1.1.1" xref="S2.SS1.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.1.m1.1b"><ci id="S2.SS1.p7.1.m1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.1.m1.1c">\bullet</annotation></semantics></math> 6D poses for each object.</p>
</div>
<div id="S2.SS1.p8" class="ltx_para">
<p id="S2.SS1.p8.2" class="ltx_p"><math id="S2.SS1.p8.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p8.1.m1.1a"><mo id="S2.SS1.p8.1.m1.1.1" xref="S2.SS1.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.1.m1.1b"><ci id="S2.SS1.p8.1.m1.1.1.cmml" xref="S2.SS1.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.1.m1.1c">\bullet</annotation></semantics></math> Color images with resolution of <math id="S2.SS1.p8.2.m2.1" class="ltx_Math" alttext="1280\times 720" display="inline"><semantics id="S2.SS1.p8.2.m2.1a"><mrow id="S2.SS1.p8.2.m2.1.1" xref="S2.SS1.p8.2.m2.1.1.cmml"><mn id="S2.SS1.p8.2.m2.1.1.2" xref="S2.SS1.p8.2.m2.1.1.2.cmml">1280</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p8.2.m2.1.1.1" xref="S2.SS1.p8.2.m2.1.1.1.cmml">×</mo><mn id="S2.SS1.p8.2.m2.1.1.3" xref="S2.SS1.p8.2.m2.1.1.3.cmml">720</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p8.2.m2.1b"><apply id="S2.SS1.p8.2.m2.1.1.cmml" xref="S2.SS1.p8.2.m2.1.1"><times id="S2.SS1.p8.2.m2.1.1.1.cmml" xref="S2.SS1.p8.2.m2.1.1.1"></times><cn type="integer" id="S2.SS1.p8.2.m2.1.1.2.cmml" xref="S2.SS1.p8.2.m2.1.1.2">1280</cn><cn type="integer" id="S2.SS1.p8.2.m2.1.1.3.cmml" xref="S2.SS1.p8.2.m2.1.1.3">720</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p8.2.m2.1c">1280\times 720</annotation></semantics></math> in PNG.</p>
</div>
<div id="S2.SS1.p9" class="ltx_para">
<p id="S2.SS1.p9.2" class="ltx_p"><math id="S2.SS1.p9.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p9.1.m1.1a"><mo id="S2.SS1.p9.1.m1.1.1" xref="S2.SS1.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.1.m1.1b"><ci id="S2.SS1.p9.1.m1.1.1.cmml" xref="S2.SS1.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.1.m1.1c">\bullet</annotation></semantics></math> Depth images with resolution of <math id="S2.SS1.p9.2.m2.1" class="ltx_Math" alttext="1280\times 720" display="inline"><semantics id="S2.SS1.p9.2.m2.1a"><mrow id="S2.SS1.p9.2.m2.1.1" xref="S2.SS1.p9.2.m2.1.1.cmml"><mn id="S2.SS1.p9.2.m2.1.1.2" xref="S2.SS1.p9.2.m2.1.1.2.cmml">1280</mn><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p9.2.m2.1.1.1" xref="S2.SS1.p9.2.m2.1.1.1.cmml">×</mo><mn id="S2.SS1.p9.2.m2.1.1.3" xref="S2.SS1.p9.2.m2.1.1.3.cmml">720</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.2.m2.1b"><apply id="S2.SS1.p9.2.m2.1.1.cmml" xref="S2.SS1.p9.2.m2.1.1"><times id="S2.SS1.p9.2.m2.1.1.1.cmml" xref="S2.SS1.p9.2.m2.1.1.1"></times><cn type="integer" id="S2.SS1.p9.2.m2.1.1.2.cmml" xref="S2.SS1.p9.2.m2.1.1.2">1280</cn><cn type="integer" id="S2.SS1.p9.2.m2.1.1.3.cmml" xref="S2.SS1.p9.2.m2.1.1.3">720</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.2.m2.1c">1280\times 720</annotation></semantics></math> in PNG.</p>
</div>
<div id="S2.SS1.p10" class="ltx_para">
<p id="S2.SS1.p10.1" class="ltx_p"><math id="S2.SS1.p10.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p10.1.m1.1a"><mo id="S2.SS1.p10.1.m1.1.1" xref="S2.SS1.p10.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p10.1.m1.1b"><ci id="S2.SS1.p10.1.m1.1.1.cmml" xref="S2.SS1.p10.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p10.1.m1.1c">\bullet</annotation></semantics></math> Binary segmentation masks for each image.</p>
</div>
<div id="S2.SS1.p11" class="ltx_para">
<p id="S2.SS1.p11.1" class="ltx_p"><math id="S2.SS1.p11.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p11.1.m1.1a"><mo id="S2.SS1.p11.1.m1.1.1" xref="S2.SS1.p11.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p11.1.m1.1b"><ci id="S2.SS1.p11.1.m1.1.1.cmml" xref="S2.SS1.p11.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p11.1.m1.1c">\bullet</annotation></semantics></math> 2D bounding boxes for each object.</p>
</div>
<div id="S2.SS1.p12" class="ltx_para">
<p id="S2.SS1.p12.1" class="ltx_p"><math id="S2.SS1.p12.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p12.1.m1.1a"><mo id="S2.SS1.p12.1.m1.1.1" xref="S2.SS1.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p12.1.m1.1b"><ci id="S2.SS1.p12.1.m1.1.1.cmml" xref="S2.SS1.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p12.1.m1.1c">\bullet</annotation></semantics></math> 3D point clouds with RGB color and normals for each object.</p>
</div>
<div id="S2.SS1.p13" class="ltx_para">
<p id="S2.SS1.p13.1" class="ltx_p"><math id="S2.SS1.p13.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S2.SS1.p13.1.m1.1a"><mo id="S2.SS1.p13.1.m1.1.1" xref="S2.SS1.p13.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p13.1.m1.1b"><ci id="S2.SS1.p13.1.m1.1.1.cmml" xref="S2.SS1.p13.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p13.1.m1.1c">\bullet</annotation></semantics></math> Calibration information for each image.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Evaluation metrics</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In this benchmark, we require the participants to submit the estimated 6D object poses of the testing set. The performance of 6D object pose estimation is evaluated by ADD(-S) which are the average distance metric (ADD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">HLI<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>12</a>]</cite> and the average closest point distance (ADD-S) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.7" class="ltx_p">Given the ground truth rotation matrix <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mi id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><ci id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">R</annotation></semantics></math> and translation matrix <math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mi id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">T</annotation></semantics></math> and its corresponding estimated rotation matrix <math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="\hat{R}" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><mover accent="true" id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml"><mi id="S2.SS2.p2.3.m3.1.1.2" xref="S2.SS2.p2.3.m3.1.1.2.cmml">R</mi><mo id="S2.SS2.p2.3.m3.1.1.1" xref="S2.SS2.p2.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><apply id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1"><ci id="S2.SS2.p2.3.m3.1.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1.1">^</ci><ci id="S2.SS2.p2.3.m3.1.1.2.cmml" xref="S2.SS2.p2.3.m3.1.1.2">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">\hat{R}</annotation></semantics></math> and translation matirx <math id="S2.SS2.p2.4.m4.1" class="ltx_Math" alttext="\hat{T}" display="inline"><semantics id="S2.SS2.p2.4.m4.1a"><mover accent="true" id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml"><mi id="S2.SS2.p2.4.m4.1.1.2" xref="S2.SS2.p2.4.m4.1.1.2.cmml">T</mi><mo id="S2.SS2.p2.4.m4.1.1.1" xref="S2.SS2.p2.4.m4.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><apply id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1"><ci id="S2.SS2.p2.4.m4.1.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1.1">^</ci><ci id="S2.SS2.p2.4.m4.1.1.2.cmml" xref="S2.SS2.p2.4.m4.1.1.2">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">\hat{T}</annotation></semantics></math>, the ADD computes mean distances between all 3D model points <math id="S2.SS2.p2.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS2.p2.5.m5.1a"><mi id="S2.SS2.p2.5.m5.1.1" xref="S2.SS2.p2.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.5.m5.1b"><ci id="S2.SS2.p2.5.m5.1.1.cmml" xref="S2.SS2.p2.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.5.m5.1c">x</annotation></semantics></math> transformed by <math id="S2.SS2.p2.6.m6.1" class="ltx_Math" alttext="[\hat{R}|\hat{T}]" display="inline"><semantics id="S2.SS2.p2.6.m6.1a"><mrow id="S2.SS2.p2.6.m6.1.1.1" xref="S2.SS2.p2.6.m6.1.1.2.cmml"><mo stretchy="false" id="S2.SS2.p2.6.m6.1.1.1.2" xref="S2.SS2.p2.6.m6.1.1.2.1.cmml">[</mo><mrow id="S2.SS2.p2.6.m6.1.1.1.1" xref="S2.SS2.p2.6.m6.1.1.1.1.cmml"><mover accent="true" id="S2.SS2.p2.6.m6.1.1.1.1.2" xref="S2.SS2.p2.6.m6.1.1.1.1.2.cmml"><mi id="S2.SS2.p2.6.m6.1.1.1.1.2.2" xref="S2.SS2.p2.6.m6.1.1.1.1.2.2.cmml">R</mi><mo id="S2.SS2.p2.6.m6.1.1.1.1.2.1" xref="S2.SS2.p2.6.m6.1.1.1.1.2.1.cmml">^</mo></mover><mo fence="false" id="S2.SS2.p2.6.m6.1.1.1.1.1" xref="S2.SS2.p2.6.m6.1.1.1.1.1.cmml">|</mo><mover accent="true" id="S2.SS2.p2.6.m6.1.1.1.1.3" xref="S2.SS2.p2.6.m6.1.1.1.1.3.cmml"><mi id="S2.SS2.p2.6.m6.1.1.1.1.3.2" xref="S2.SS2.p2.6.m6.1.1.1.1.3.2.cmml">T</mi><mo id="S2.SS2.p2.6.m6.1.1.1.1.3.1" xref="S2.SS2.p2.6.m6.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S2.SS2.p2.6.m6.1.1.1.3" xref="S2.SS2.p2.6.m6.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.6.m6.1b"><apply id="S2.SS2.p2.6.m6.1.1.2.cmml" xref="S2.SS2.p2.6.m6.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.6.m6.1.1.2.1.cmml" xref="S2.SS2.p2.6.m6.1.1.1.2">delimited-[]</csymbol><apply id="S2.SS2.p2.6.m6.1.1.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.6.m6.1.1.1.1.1.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.1">conditional</csymbol><apply id="S2.SS2.p2.6.m6.1.1.1.1.2.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.2"><ci id="S2.SS2.p2.6.m6.1.1.1.1.2.1.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.2.1">^</ci><ci id="S2.SS2.p2.6.m6.1.1.1.1.2.2.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.2.2">𝑅</ci></apply><apply id="S2.SS2.p2.6.m6.1.1.1.1.3.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.3"><ci id="S2.SS2.p2.6.m6.1.1.1.1.3.1.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.3.1">^</ci><ci id="S2.SS2.p2.6.m6.1.1.1.1.3.2.cmml" xref="S2.SS2.p2.6.m6.1.1.1.1.3.2">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.6.m6.1c">[\hat{R}|\hat{T}]</annotation></semantics></math> and <math id="S2.SS2.p2.7.m7.1" class="ltx_Math" alttext="[R|T]" display="inline"><semantics id="S2.SS2.p2.7.m7.1a"><mrow id="S2.SS2.p2.7.m7.1.1.1" xref="S2.SS2.p2.7.m7.1.1.2.cmml"><mo stretchy="false" id="S2.SS2.p2.7.m7.1.1.1.2" xref="S2.SS2.p2.7.m7.1.1.2.1.cmml">[</mo><mrow id="S2.SS2.p2.7.m7.1.1.1.1" xref="S2.SS2.p2.7.m7.1.1.1.1.cmml"><mi id="S2.SS2.p2.7.m7.1.1.1.1.2" xref="S2.SS2.p2.7.m7.1.1.1.1.2.cmml">R</mi><mo fence="false" id="S2.SS2.p2.7.m7.1.1.1.1.1" xref="S2.SS2.p2.7.m7.1.1.1.1.1.cmml">|</mo><mi id="S2.SS2.p2.7.m7.1.1.1.1.3" xref="S2.SS2.p2.7.m7.1.1.1.1.3.cmml">T</mi></mrow><mo stretchy="false" id="S2.SS2.p2.7.m7.1.1.1.3" xref="S2.SS2.p2.7.m7.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.7.m7.1b"><apply id="S2.SS2.p2.7.m7.1.1.2.cmml" xref="S2.SS2.p2.7.m7.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.7.m7.1.1.2.1.cmml" xref="S2.SS2.p2.7.m7.1.1.1.2">delimited-[]</csymbol><apply id="S2.SS2.p2.7.m7.1.1.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p2.7.m7.1.1.1.1.1.cmml" xref="S2.SS2.p2.7.m7.1.1.1.1.1">conditional</csymbol><ci id="S2.SS2.p2.7.m7.1.1.1.1.2.cmml" xref="S2.SS2.p2.7.m7.1.1.1.1.2">𝑅</ci><ci id="S2.SS2.p2.7.m7.1.1.1.1.3.cmml" xref="S2.SS2.p2.7.m7.1.1.1.1.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.7.m7.1c">[R|T]</annotation></semantics></math>:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="ADD=\frac{1}{N}\sum_{x\in S}||(Rx+T)-(\hat{R}x+\hat{T})||," display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.3.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.1a" xref="S2.E1.m1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3.4" xref="S2.E1.m1.1.1.1.1.3.4.cmml">D</mi></mrow><mo id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.cmml"><mfrac id="S2.E1.m1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.3.cmml"><mn id="S2.E1.m1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.3.2.cmml">1</mn><mi id="S2.E1.m1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><munder id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.2.3.2" xref="S2.E1.m1.1.1.1.1.1.1.2.3.2.cmml">x</mi><mo id="S2.E1.m1.1.1.1.1.1.1.2.3.1" xref="S2.E1.m1.1.1.1.1.1.1.2.3.1.cmml">∈</mo><mi id="S2.E1.m1.1.1.1.1.1.1.2.3.3" xref="S2.E1.m1.1.1.1.1.1.1.2.3.3.cmml">S</mi></mrow></munder><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">T</mi></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.cmml"><mover accent="true" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml">R</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml">^</mo></mover><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">+</mo><mover accent="true" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml">T</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"></eq><apply id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"><times id="S2.E1.m1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2">𝐴</ci><ci id="S2.E1.m1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3">𝐷</ci><ci id="S2.E1.m1.1.1.1.1.3.4.cmml" xref="S2.E1.m1.1.1.1.1.3.4">𝐷</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3"><divide id="S2.E1.m1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.3"></divide><cn type="integer" id="S2.E1.m1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.3.2">1</cn><ci id="S2.E1.m1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.3.3">𝑁</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><apply id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.2"></sum><apply id="S2.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3"><in id="S2.E1.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3.1"></in><ci id="S2.E1.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3.2">𝑥</ci><ci id="S2.E1.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.3.3">𝑆</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3"></minus><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1"><plus id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2"><times id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑅</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">𝑥</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑇</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1"><plus id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.1"></plus><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2"><times id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.1"></times><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2"><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.1">^</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.2.2">𝑅</ci></apply><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.2.3">𝑥</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3"><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.1">^</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.1.1.3.2">𝑇</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">ADD=\frac{1}{N}\sum_{x\in S}||(Rx+T)-(\hat{R}x+\hat{T})||,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p2.9" class="ltx_p">where <math id="S2.SS2.p2.8.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S2.SS2.p2.8.m1.1a"><mi id="S2.SS2.p2.8.m1.1.1" xref="S2.SS2.p2.8.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.8.m1.1b"><ci id="S2.SS2.p2.8.m1.1.1.cmml" xref="S2.SS2.p2.8.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.8.m1.1c">S</annotation></semantics></math> is the set of 3D model points and <math id="S2.SS2.p2.9.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS2.p2.9.m2.1a"><mi id="S2.SS2.p2.9.m2.1.1" xref="S2.SS2.p2.9.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.9.m2.1b"><ci id="S2.SS2.p2.9.m2.1.1.cmml" xref="S2.SS2.p2.9.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.9.m2.1c">N</annotation></semantics></math> is the number of points.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.3" class="ltx_p">The ADD-S is an ambiguity-invariant pose error metric, which takes care of both symmetric and non-symmetric objects into an overall evaluation.</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="ADD{\text{-}}S=\frac{1}{N}\sum_{x_{1}\in S}\min_{x_{2}\in S}||(Rx_{1}+T)-(\hat{R}x_{2}+\hat{T})||" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mrow id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.1" xref="S2.E2.m1.1.1.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.1a" xref="S2.E2.m1.1.1.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.3.4" xref="S2.E2.m1.1.1.3.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.1b" xref="S2.E2.m1.1.1.3.1.cmml">​</mo><mtext id="S2.E2.m1.1.1.3.5" xref="S2.E2.m1.1.1.3.5a.cmml">-</mtext><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.1c" xref="S2.E2.m1.1.1.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.3.6" xref="S2.E2.m1.1.1.3.6.cmml">S</mi></mrow><mo id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml">=</mo><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml"><mfrac id="S2.E2.m1.1.1.1.3" xref="S2.E2.m1.1.1.1.3.cmml"><mn id="S2.E2.m1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.3.2.cmml">1</mn><mi id="S2.E2.m1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.3.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><munder id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E2.m1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.E2.m1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.2.3.cmml"><msub id="S2.E2.m1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.2.3.2.cmml"><mi id="S2.E2.m1.1.1.1.1.2.3.2.2" xref="S2.E2.m1.1.1.1.1.2.3.2.2.cmml">x</mi><mn id="S2.E2.m1.1.1.1.1.2.3.2.3" xref="S2.E2.m1.1.1.1.1.2.3.2.3.cmml">1</mn></msub><mo id="S2.E2.m1.1.1.1.1.2.3.1" xref="S2.E2.m1.1.1.1.1.2.3.1.cmml">∈</mo><mi id="S2.E2.m1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.2.3.3.cmml">S</mi></mrow></munder><mrow id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><munder id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.1.3.2.cmml">min</mi><mrow id="S2.E2.m1.1.1.1.1.1.3.3" xref="S2.E2.m1.1.1.1.1.1.3.3.cmml"><msub id="S2.E2.m1.1.1.1.1.1.3.3.2" xref="S2.E2.m1.1.1.1.1.1.3.3.2.cmml"><mi id="S2.E2.m1.1.1.1.1.1.3.3.2.2" xref="S2.E2.m1.1.1.1.1.1.3.3.2.2.cmml">x</mi><mn id="S2.E2.m1.1.1.1.1.1.3.3.2.3" xref="S2.E2.m1.1.1.1.1.1.3.3.2.3.cmml">2</mn></msub><mo id="S2.E2.m1.1.1.1.1.1.3.3.1" xref="S2.E2.m1.1.1.1.1.1.3.3.1.cmml">∈</mo><mi id="S2.E2.m1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.1.1.1.1.1.3.3.3.cmml">S</mi></mrow></munder><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">x</mi><mn id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">1</mn></msub></mrow><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">T</mi></mrow><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.cmml"><mover accent="true" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml">R</mi><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml">^</mo></mover><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">​</mo><msub id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2.cmml">x</mi><mn id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3.cmml">2</mn></msub></mrow><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml">+</mo><mover accent="true" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.cmml"><mi id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.2" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml">T</mi><mo id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.1" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.3" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.E2.m1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><eq id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2"></eq><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><times id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3.1"></times><ci id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2">𝐴</ci><ci id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3">𝐷</ci><ci id="S2.E2.m1.1.1.3.4.cmml" xref="S2.E2.m1.1.1.3.4">𝐷</ci><ci id="S2.E2.m1.1.1.3.5a.cmml" xref="S2.E2.m1.1.1.3.5"><mtext id="S2.E2.m1.1.1.3.5.cmml" xref="S2.E2.m1.1.1.3.5">-</mtext></ci><ci id="S2.E2.m1.1.1.3.6.cmml" xref="S2.E2.m1.1.1.3.6">𝑆</ci></apply><apply id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><times id="S2.E2.m1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.3"><divide id="S2.E2.m1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.3"></divide><cn type="integer" id="S2.E2.m1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.3.2">1</cn><ci id="S2.E2.m1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.3.3">𝑁</ci></apply><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1"><apply id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2">subscript</csymbol><sum id="S2.E2.m1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2"></sum><apply id="S2.E2.m1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3"><in id="S2.E2.m1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.2.3.1"></in><apply id="S2.E2.m1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.2.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2.2">𝑥</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.2.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2.3">1</cn></apply><ci id="S2.E2.m1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3.3">𝑆</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><times id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.3">subscript</csymbol><min id="S2.E2.m1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.3.2"></min><apply id="S2.E2.m1.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3"><in id="S2.E2.m1.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3.1"></in><apply id="S2.E2.m1.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.3.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.3.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3.2.2">𝑥</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.1.3.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3.2.3">2</cn></apply><ci id="S2.E2.m1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3.3.3">𝑆</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1"><minus id="S2.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.3"></minus><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1"><plus id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2"><times id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑅</ci><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.2">𝑥</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.1.1.1.3">𝑇</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1"><plus id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.1"></plus><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2"><times id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.1"></times><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2"><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.1">^</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.2.2">𝑅</ci></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.2">𝑥</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.2.3.3">2</cn></apply></apply><apply id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3"><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.1">^</ci><ci id="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.1.1.1.1.2.1.1.3.2">𝑇</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">ADD{\text{-}}S=\frac{1}{N}\sum_{x_{1}\in S}\min_{x_{2}\in S}||(Rx_{1}+T)-(\hat{R}x_{2}+\hat{T})||</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p3.2" class="ltx_p">The area under the accuracy-threshold curve (AUC) which is calculated from ADD(-S) is another evaluation metric. Specifically, if the ADD(-S) is smaller than a threshold defined from the diameter of the 3D object model, we consider the estimated pose is correct. Based on that, we define a variable range of thresholds from <math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="0\%" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><mrow id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml"><mn id="S2.SS2.p3.1.m1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.2.cmml">0</mn><mo id="S2.SS2.p3.1.m1.1.1.1" xref="S2.SS2.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"><csymbol cd="latexml" id="S2.SS2.p3.1.m1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.SS2.p3.1.m1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.2">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">0\%</annotation></semantics></math> to <math id="S2.SS2.p3.2.m2.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="S2.SS2.p3.2.m2.1a"><mrow id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml"><mn id="S2.SS2.p3.2.m2.1.1.2" xref="S2.SS2.p3.2.m2.1.1.2.cmml">100</mn><mo id="S2.SS2.p3.2.m2.1.1.1" xref="S2.SS2.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><apply id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1"><csymbol cd="latexml" id="S2.SS2.p3.2.m2.1.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S2.SS2.p3.2.m2.1.1.2.cmml" xref="S2.SS2.p3.2.m2.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">100\%</annotation></semantics></math> of the 3D object diameter and then compute the ADD(-S) for each threshold. With the two sets of values, we can get the accuracy-threshold curve referred to as AUC. Then the area under the AUC is calculated.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">We also use the reprojection error, which is often used for 6D object pose estimation of feature matching methods, as our fourth performance metric. Rather than computing distance between two 3D point pairs, the reprojection error is calculated by first projecting 3D points into an image plane and then computing the pairwise distances in the image space.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">All the proposed methods are described in the following subsections. We choose DenseFusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">WXZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite> as a baseline approach for the 6D object pose estimation. Two research groups contributed their methods in this joint experimental comparison.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Baseline: DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">DenseFusion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">WXZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite> is a heterogeneous neural network architecture with RGB-D images as input. It processes color and depth information separately and uses a dense fusion network to extract pixel-wise dense features, from which the 6D object pose is estimated. Furthermore, an end-to-end iterative pose refinement network is proposed to further improve the accuracy of the predicted pose while achieving real-time speed.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2010.09355/assets/densefusion.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="317" height="157" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Pipeline of the DenseFusion networks. The network first generates object segmentation masks and 2D bounding boxes from color images. The color-and-depth image pairs are cropped using the bounding boxes and fed into embeddings and fused at each corresponding pixel. The pose predictor estimates a 6D pose for each fused feature and the predictions are voted to obtain the final 6D object pose. </figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Figure <a href="#S3.F3" title="Figure 3 ‣ 3.1 Baseline: DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion ‣ 3 Methods ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the overall architecture of DenseFusion. The architecture consists of two stages. Firstly, the target object is detected in the input color image using semantic segmentation from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>]</cite>. After that, the color and depth images are cropped based on the segmentation and the cropped depth image is transformed to a point cloud using the intrinsic camera matrix. Both cropped images are fed to the second stage.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In the second stage, the cropped color image is fed to a CNN-based network Resnet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">HZRS16</a>]</cite> encoder followed by <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mn id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><cn type="integer" id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">4</annotation></semantics></math> up-sampling layers as decoder to extract color features. The point cloud converted by the cropped depth map is fed into a PointNet-based network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">QSMG17</a>]</cite> by applying a multi-layer perceptron (MLP) to produce geometric features. After that, the color and depth features are fused to estimate the 6D object pose based on an unsupervised confidence score. Lastly, the predicted pose is refined by the iterative pose refinement network.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.3" class="ltx_p">We implement the DenseFusion network within the PyTorch framework and the model is trained using Adam optimizer with an initial learning rate at <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="0.0001" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mn id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">0.0001</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><cn type="float" id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">0.0001</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">0.0001</annotation></semantics></math>. The iterative pose refinement module contains a <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mn id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><cn type="integer" id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">4</annotation></semantics></math> fully connected layers and <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mn id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><cn type="integer" id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">2</annotation></semantics></math> refinement iterations is used for the experiments.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>ASS3D: Adaptive Single-Shot 3D Object Pose Estimation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Multimodal inputs can improve the performance of various computer vision tasks, but it is usually at the cost of efficiency and increased complexity. In this work, they focus on RGB-D 6D object pose estimation and exploit multimodal inputs using a lightweight fusion scheme which is complemented by multimodal supervision through rendering. In this way, they overcome the complexity of multimodal inputs by transferring it to the model training phase instead of the inference phase. Given the distinct domains that color and depth information resides in, they employ a disentangled architecture, as depicted in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.2 ASS3D: Adaptive Single-Shot 3D Object Pose Estimation ‣ 3 Methods ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, to process them separately and enable for a learnable fusion scheme.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2010.09355/assets/giorgos_new.jpg" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="491" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Overall Network Architecture. The color and depth images are processed separately and the extracted features are fused in a later stage. They employ an average-pooling function as the symmetric reduction function. The features are then driven into a pose encoder which eventually directly regresses a rotation and translation. The predicted pose is subsequently used for rendering the object and deriving its projected silhouette. This allows utilizing an additional supervision signal during training and increase the overall performance of the model.</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.3" class="ltx_p">More specifically, they use two ResNet-34 models as their backbone encoders for extracting features, which are later fused and flattened by an average-pooling function. This approach allows them to associate the geometric feature of each point to its corresponding image feature pixel based on a projection onto the image plane using the known camera intrinsic parameters as it has been already shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">WXZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite>. The fused features are then fed into a pose encoder consisting of three fully connected layers that eventually disentangled to 3D rotation and 3D translation heads. Following the definition of their model’s architecture, they supervise it using a direct pose regression objective as the weighted sum of two different losses. Particularly, they use a <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="L2" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">​</mo><mn id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><times id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"></times><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">L2</annotation></semantics></math> loss <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\varepsilon_{t}=||t-\tilde{t}||" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><msub id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.3.2.cmml">ε</mi><mi id="S3.SS2.p2.2.m2.1.1.3.3" xref="S3.SS2.p2.2.m2.1.1.3.3.cmml">t</mi></msub><mo id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS2.p2.2.m2.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.2.m2.1.1.1.1.2" xref="S3.SS2.p2.2.m2.1.1.1.2.1.cmml">‖</mo><mrow id="S3.SS2.p2.2.m2.1.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.1.1.1.2" xref="S3.SS2.p2.2.m2.1.1.1.1.1.2.cmml">t</mi><mo id="S3.SS2.p2.2.m2.1.1.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S3.SS2.p2.2.m2.1.1.1.1.1.3" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.1.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p2.2.m2.1.1.1.1.1.3.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo stretchy="false" id="S3.SS2.p2.2.m2.1.1.1.1.3" xref="S3.SS2.p2.2.m2.1.1.1.2.1.cmml">‖</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><eq id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2"></eq><apply id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.2">𝜀</ci><ci id="S3.SS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3">𝑡</ci></apply><apply id="S3.SS2.p2.2.m2.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p2.2.m2.1.1.1.2.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.2">norm</csymbol><apply id="S3.SS2.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1"><minus id="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1"></minus><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.2">𝑡</ci><apply id="S3.SS2.p2.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3"><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3.1">~</ci><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.3.2">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\varepsilon_{t}=||t-\tilde{t}||</annotation></semantics></math> for the translation and a geodesic distance for the rotation <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\varepsilon_{r}=\arccos\frac{trace(R\tilde{R}^{T})-1}{2}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.2" xref="S3.SS2.p2.3.m3.1.2.cmml"><msub id="S3.SS2.p2.3.m3.1.2.2" xref="S3.SS2.p2.3.m3.1.2.2.cmml"><mi id="S3.SS2.p2.3.m3.1.2.2.2" xref="S3.SS2.p2.3.m3.1.2.2.2.cmml">ε</mi><mi id="S3.SS2.p2.3.m3.1.2.2.3" xref="S3.SS2.p2.3.m3.1.2.2.3.cmml">r</mi></msub><mo id="S3.SS2.p2.3.m3.1.2.1" xref="S3.SS2.p2.3.m3.1.2.1.cmml">=</mo><mrow id="S3.SS2.p2.3.m3.1.2.3" xref="S3.SS2.p2.3.m3.1.2.3.cmml"><mi id="S3.SS2.p2.3.m3.1.2.3.1" xref="S3.SS2.p2.3.m3.1.2.3.1.cmml">arccos</mi><mo lspace="0.167em" id="S3.SS2.p2.3.m3.1.2.3a" xref="S3.SS2.p2.3.m3.1.2.3.cmml">⁡</mo><mfrac id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mrow id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml"><mrow id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p2.3.m3.1.1.1.1.4" xref="S3.SS2.p2.3.m3.1.1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1.1.2a" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p2.3.m3.1.1.1.1.5" xref="S3.SS2.p2.3.m3.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1.1.2b" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p2.3.m3.1.1.1.1.6" xref="S3.SS2.p2.3.m3.1.1.1.1.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1.1.2c" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">​</mo><mi id="S3.SS2.p2.3.m3.1.1.1.1.7" xref="S3.SS2.p2.3.m3.1.1.1.1.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1.1.2d" xref="S3.SS2.p2.3.m3.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS2.p2.3.m3.1.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.1.cmml">​</mo><msup id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.cmml"><mover accent="true" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.2" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.2.cmml">R</mi><mo id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.1" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.3.cmml">T</mi></msup></mrow><mo stretchy="false" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p2.3.m3.1.1.1.2" xref="S3.SS2.p2.3.m3.1.1.1.2.cmml">−</mo><mn id="S3.SS2.p2.3.m3.1.1.1.3" xref="S3.SS2.p2.3.m3.1.1.1.3.cmml">1</mn></mrow><mn id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">2</mn></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.2.cmml" xref="S3.SS2.p2.3.m3.1.2"><eq id="S3.SS2.p2.3.m3.1.2.1.cmml" xref="S3.SS2.p2.3.m3.1.2.1"></eq><apply id="S3.SS2.p2.3.m3.1.2.2.cmml" xref="S3.SS2.p2.3.m3.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.2.2.1.cmml" xref="S3.SS2.p2.3.m3.1.2.2">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.2.2.2.cmml" xref="S3.SS2.p2.3.m3.1.2.2.2">𝜀</ci><ci id="S3.SS2.p2.3.m3.1.2.2.3.cmml" xref="S3.SS2.p2.3.m3.1.2.2.3">𝑟</ci></apply><apply id="S3.SS2.p2.3.m3.1.2.3.cmml" xref="S3.SS2.p2.3.m3.1.2.3"><arccos id="S3.SS2.p2.3.m3.1.2.3.1.cmml" xref="S3.SS2.p2.3.m3.1.2.3.1"></arccos><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><divide id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1"></divide><apply id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1"><minus id="S3.SS2.p2.3.m3.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.2"></minus><apply id="S3.SS2.p2.3.m3.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1"><times id="S3.SS2.p2.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.2"></times><ci id="S3.SS2.p2.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.3">𝑡</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.4.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.4">𝑟</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.5.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.5">𝑎</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.6.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.6">𝑐</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.7.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.7">𝑒</ci><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1"><times id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.1"></times><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.2">𝑅</ci><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2"><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.1">~</ci><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.2.2">𝑅</ci></apply><ci id="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1.1.1.1.3.3">𝑇</ci></apply></apply></apply><cn type="integer" id="S3.SS2.p2.3.m3.1.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.1.3">1</cn></apply><cn type="integer" id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\varepsilon_{r}=\arccos\frac{trace(R\tilde{R}^{T})-1}{2}</annotation></semantics></math>, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">AZD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>]</cite>. The loss for the predicted pose is then:</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\varepsilon_{pose}=\lambda_{six_{d}}\varepsilon_{t}+(1-\lambda_{six_{d}})\varepsilon_{r}," display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2.cmml">ε</mi><mrow id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.1a" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.4" xref="S3.E3.m1.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.3.3.1b" xref="S3.E3.m1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.3.3.5" xref="S3.E3.m1.1.1.1.1.3.3.5.cmml">e</mi></mrow></msub><mo id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.3.cmml"><msub id="S3.E3.m1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.3.2.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.1.1.1.1.1.3.2.2.cmml">λ</mi><mrow id="S3.E3.m1.1.1.1.1.1.3.2.3" xref="S3.E3.m1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.2.3.2" xref="S3.E3.m1.1.1.1.1.1.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.3.2.3.1" xref="S3.E3.m1.1.1.1.1.1.3.2.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.1.3.2.3.3" xref="S3.E3.m1.1.1.1.1.1.3.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.3.2.3.1a" xref="S3.E3.m1.1.1.1.1.1.3.2.3.1.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.1.3.2.3.4" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.2.3.4.2" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4.2.cmml">x</mi><mi id="S3.E3.m1.1.1.1.1.1.3.2.3.4.3" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4.3.cmml">d</mi></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.3.1" xref="S3.E3.m1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.3.3.2.cmml">ε</mi><mi id="S3.E3.m1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.1.3.3.3.cmml">t</mi></msub></mrow><mo id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">λ</mi><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.1a" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.2.cmml">x</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.3.cmml">d</mi></msub></mrow></msub></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">​</mo><msub id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.3.2.cmml">ε</mi><mi id="S3.E3.m1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.3.3.cmml">r</mi></msub></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"></eq><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">𝜀</ci><apply id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3"><times id="S3.E3.m1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.2">𝑝</ci><ci id="S3.E3.m1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3">𝑜</ci><ci id="S3.E3.m1.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.3.4">𝑠</ci><ci id="S3.E3.m1.1.1.1.1.3.3.5.cmml" xref="S3.E3.m1.1.1.1.1.3.3.5">𝑒</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><plus id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.2"></plus><apply id="S3.E3.m1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.1"></times><apply id="S3.E3.m1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.2">𝜆</ci><apply id="S3.E3.m1.1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3"><times id="S3.E3.m1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.1"></times><ci id="S3.E3.m1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.2">𝑠</ci><ci id="S3.E3.m1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.3">𝑖</ci><apply id="S3.E3.m1.1.1.1.1.1.3.2.3.4.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.3.2.3.4.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.3.2.3.4.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4.2">𝑥</ci><ci id="S3.E3.m1.1.1.1.1.1.3.2.3.4.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.2.3.4.3">𝑑</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.2">𝜀</ci><ci id="S3.E3.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.2">1</cn><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.2">𝜆</ci><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3"><times id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.2">𝑠</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.2">𝑥</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.3.3.4.3">𝑑</ci></apply></apply></apply></apply><apply id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2">𝜀</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3">𝑟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\varepsilon_{pose}=\lambda_{six_{d}}\varepsilon_{t}+(1-\lambda_{six_{d}})\varepsilon_{r},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.2" class="ltx_p">where the weight <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="\lambda_{six_{d}}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msub id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">λ</mi><mrow id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.3.2" xref="S3.SS2.p4.1.m1.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p4.1.m1.1.1.3.3" xref="S3.SS2.p4.1.m1.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1a" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">​</mo><msub id="S3.SS2.p4.1.m1.1.1.3.4" xref="S3.SS2.p4.1.m1.1.1.3.4.cmml"><mi id="S3.SS2.p4.1.m1.1.1.3.4.2" xref="S3.SS2.p4.1.m1.1.1.3.4.2.cmml">x</mi><mi id="S3.SS2.p4.1.m1.1.1.3.4.3" xref="S3.SS2.p4.1.m1.1.1.3.4.3.cmml">d</mi></msub></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">𝜆</ci><apply id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><times id="S3.SS2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3.1"></times><ci id="S3.SS2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.2">𝑠</ci><ci id="S3.SS2.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.3">𝑖</ci><apply id="S3.SS2.p4.1.m1.1.1.3.4.cmml" xref="S3.SS2.p4.1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.3.4.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3.4">subscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.3.4.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.4.2">𝑥</ci><ci id="S3.SS2.p4.1.m1.1.1.3.4.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.4.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">\lambda_{six_{d}}</annotation></semantics></math> acts as a regularization term. This is complemented by a silhouette loss which is enabled by a point splatting differentiable renderer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">YSW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite>. They transform the 3D vertices <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="\nu\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">ν</mi><mo id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2" xref="S3.SS2.p4.2.m2.1.1.3.2.cmml">ℝ</mi><mn id="S3.SS2.p4.2.m2.1.1.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><in id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1"></in><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝜈</ci><apply id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2">ℝ</ci><cn type="integer" id="S3.SS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">\nu\in\mathbb{R}^{3}</annotation></semantics></math> of each object’s point cloud using the predicted pose. The differentiable point cloud renderer then renders the transformed model’s silhouette, which is used along with the ground truth annotated silhouettes as an additional supervision signal. Instead of using a traditional intersection over union (IoU) loss, they apply a Gaussian smooth silhouette loss as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">AZD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>]</cite> for their silhouette loss:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\varepsilon_{silhouette}=\frac{1}{N}\sum_{\in\Omega}S\astrosun\mathscr{S}(\tilde{S})+\tilde{S}\astrosun\mathscr{S}(S)," display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><msub id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml"><mi id="S3.E4.m1.3.3.1.1.2.2" xref="S3.E4.m1.3.3.1.1.2.2.cmml">ε</mi><mrow id="S3.E4.m1.3.3.1.1.2.3" xref="S3.E4.m1.3.3.1.1.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.2.3.2" xref="S3.E4.m1.3.3.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.3" xref="S3.E4.m1.3.3.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1a" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.4" xref="S3.E4.m1.3.3.1.1.2.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1b" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.5" xref="S3.E4.m1.3.3.1.1.2.3.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1c" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.6" xref="S3.E4.m1.3.3.1.1.2.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1d" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.7" xref="S3.E4.m1.3.3.1.1.2.3.7.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1e" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.8" xref="S3.E4.m1.3.3.1.1.2.3.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1f" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.9" xref="S3.E4.m1.3.3.1.1.2.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1g" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.10" xref="S3.E4.m1.3.3.1.1.2.3.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.2.3.1h" xref="S3.E4.m1.3.3.1.1.2.3.1.cmml">​</mo><mi id="S3.E4.m1.3.3.1.1.2.3.11" xref="S3.E4.m1.3.3.1.1.2.3.11.cmml">e</mi></mrow></msub><mo id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><mrow id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml"><mfrac id="S3.E4.m1.3.3.1.1.3.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.cmml"><mn id="S3.E4.m1.3.3.1.1.3.2.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.2.cmml">1</mn><mi id="S3.E4.m1.3.3.1.1.3.2.2.3" xref="S3.E4.m1.3.3.1.1.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.1" xref="S3.E4.m1.3.3.1.1.3.2.1.cmml">​</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.3" xref="S3.E4.m1.3.3.1.1.3.2.3.cmml"><munder id="S3.E4.m1.3.3.1.1.3.2.3.1" xref="S3.E4.m1.3.3.1.1.3.2.3.1.cmml"><mo movablelimits="false" id="S3.E4.m1.3.3.1.1.3.2.3.1.2" xref="S3.E4.m1.3.3.1.1.3.2.3.1.2.cmml">∑</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.3.1.3" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.3.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.2.cmml"></mi><mo id="S3.E4.m1.3.3.1.1.3.2.3.1.3.1" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.1.cmml">∈</mo><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.3.2.3.1.3.3" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.3.cmml">Ω</mi></mrow></munder><mrow id="S3.E4.m1.3.3.1.1.3.2.3.2" xref="S3.E4.m1.3.3.1.1.3.2.3.2.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.3.2.2" xref="S3.E4.m1.3.3.1.1.3.2.3.2.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.2.1" xref="S3.E4.m1.3.3.1.1.3.2.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.3.2.3.2.3" xref="S3.E4.m1.3.3.1.1.3.2.3.2.3.cmml">☉</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.2.1a" xref="S3.E4.m1.3.3.1.1.3.2.3.2.1.cmml">​</mo><mi class="ltx_font_mathscript" id="S3.E4.m1.3.3.1.1.3.2.3.2.4" xref="S3.E4.m1.3.3.1.1.3.2.3.2.4.cmml">𝒮</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.2.1b" xref="S3.E4.m1.3.3.1.1.3.2.3.2.1.cmml">​</mo><mrow id="S3.E4.m1.3.3.1.1.3.2.3.2.5.2" xref="S3.E4.m1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.3.2.5.2.1" xref="S3.E4.m1.1.1.cmml">(</mo><mover accent="true" id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">S</mi><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.2.3.2.5.2.2" xref="S3.E4.m1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.3.3.1.1.3.1" xref="S3.E4.m1.3.3.1.1.3.1.cmml">+</mo><mrow id="S3.E4.m1.3.3.1.1.3.3" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.3.2.cmml"><mi id="S3.E4.m1.3.3.1.1.3.3.2.2" xref="S3.E4.m1.3.3.1.1.3.3.2.2.cmml">S</mi><mo id="S3.E4.m1.3.3.1.1.3.3.2.1" xref="S3.E4.m1.3.3.1.1.3.3.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.3.1" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.3.3.3" xref="S3.E4.m1.3.3.1.1.3.3.3.cmml">☉</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.3.1a" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">​</mo><mi class="ltx_font_mathscript" id="S3.E4.m1.3.3.1.1.3.3.4" xref="S3.E4.m1.3.3.1.1.3.3.4.cmml">𝒮</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.3.1b" xref="S3.E4.m1.3.3.1.1.3.3.1.cmml">​</mo><mrow id="S3.E4.m1.3.3.1.1.3.3.5.2" xref="S3.E4.m1.3.3.1.1.3.3.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.3.5.2.1" xref="S3.E4.m1.3.3.1.1.3.3.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">S</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.3.5.2.2" xref="S3.E4.m1.3.3.1.1.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"></eq><apply id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.2">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.2.2">𝜀</ci><apply id="S3.E4.m1.3.3.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.2.3"><times id="S3.E4.m1.3.3.1.1.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.2.3.1"></times><ci id="S3.E4.m1.3.3.1.1.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.2.3.2">𝑠</ci><ci id="S3.E4.m1.3.3.1.1.2.3.3.cmml" xref="S3.E4.m1.3.3.1.1.2.3.3">𝑖</ci><ci id="S3.E4.m1.3.3.1.1.2.3.4.cmml" xref="S3.E4.m1.3.3.1.1.2.3.4">𝑙</ci><ci id="S3.E4.m1.3.3.1.1.2.3.5.cmml" xref="S3.E4.m1.3.3.1.1.2.3.5">ℎ</ci><ci id="S3.E4.m1.3.3.1.1.2.3.6.cmml" xref="S3.E4.m1.3.3.1.1.2.3.6">𝑜</ci><ci id="S3.E4.m1.3.3.1.1.2.3.7.cmml" xref="S3.E4.m1.3.3.1.1.2.3.7">𝑢</ci><ci id="S3.E4.m1.3.3.1.1.2.3.8.cmml" xref="S3.E4.m1.3.3.1.1.2.3.8">𝑒</ci><ci id="S3.E4.m1.3.3.1.1.2.3.9.cmml" xref="S3.E4.m1.3.3.1.1.2.3.9">𝑡</ci><ci id="S3.E4.m1.3.3.1.1.2.3.10.cmml" xref="S3.E4.m1.3.3.1.1.2.3.10">𝑡</ci><ci id="S3.E4.m1.3.3.1.1.2.3.11.cmml" xref="S3.E4.m1.3.3.1.1.2.3.11">𝑒</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><plus id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.1"></plus><apply id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2"><times id="S3.E4.m1.3.3.1.1.3.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.1"></times><apply id="S3.E4.m1.3.3.1.1.3.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2"><divide id="S3.E4.m1.3.3.1.1.3.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2"></divide><cn type="integer" id="S3.E4.m1.3.3.1.1.3.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.2">1</cn><ci id="S3.E4.m1.3.3.1.1.3.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2.3">𝑁</ci></apply><apply id="S3.E4.m1.3.3.1.1.3.2.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3"><apply id="S3.E4.m1.3.3.1.1.3.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.2.3.1.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1">subscript</csymbol><sum id="S3.E4.m1.3.3.1.1.3.2.3.1.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1.2"></sum><apply id="S3.E4.m1.3.3.1.1.3.2.3.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3"><in id="S3.E4.m1.3.3.1.1.3.2.3.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.1"></in><csymbol cd="latexml" id="S3.E4.m1.3.3.1.1.3.2.3.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.2">absent</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.3.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1.3.3">Ω</ci></apply></apply><apply id="S3.E4.m1.3.3.1.1.3.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2"><times id="S3.E4.m1.3.3.1.1.3.2.3.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2.1"></times><ci id="S3.E4.m1.3.3.1.1.3.2.3.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2.2">𝑆</ci><ci id="S3.E4.m1.3.3.1.1.3.2.3.2.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2.3">☉</ci><ci id="S3.E4.m1.3.3.1.1.3.2.3.2.4.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2.4">𝒮</ci><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2.5.2"><ci id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1">~</ci><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">𝑆</ci></apply></apply></apply></apply><apply id="S3.E4.m1.3.3.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3"><times id="S3.E4.m1.3.3.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3.1"></times><apply id="S3.E4.m1.3.3.1.1.3.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2"><ci id="S3.E4.m1.3.3.1.1.3.3.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2.1">~</ci><ci id="S3.E4.m1.3.3.1.1.3.3.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.3.2.2">𝑆</ci></apply><ci id="S3.E4.m1.3.3.1.1.3.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.3.3">☉</ci><ci id="S3.E4.m1.3.3.1.1.3.3.4.cmml" xref="S3.E4.m1.3.3.1.1.3.3.4">𝒮</ci><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">𝑆</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\varepsilon_{silhouette}=\frac{1}{N}\sum_{\in\Omega}S\astrosun\mathscr{S}(\tilde{S})+\tilde{S}\astrosun\mathscr{S}(S),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p5" class="ltx_para ltx_noindent">
<p id="S3.SS2.p5.1" class="ltx_p">where <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">S</annotation></semantics></math> is a Gaussian smoothing function. The silhouette loss is a smoother objective function compared to the common IoU loss, while it takes into account the ground truth silhouette simultaneously, offering that way a fully symmetric objective. However, the most appropriate Gaussian filter to be used is dependent on each object shape, and can also vary during training, offering higher precision as the model converges. Towards that end, they use a new adaptive filter by also learning the standard deviation of the Gaussian during training. Their final learning objective is a weighted sum of the aforementioned losses:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.1" class="ltx_Math" alttext="\varepsilon_{total}=\lambda_{pose}\varepsilon_{pose}+\lambda_{silhouette}\varepsilon_{silhouette}" display="block"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><msub id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.2.2" xref="S3.E5.m1.1.1.2.2.cmml">ε</mi><mrow id="S3.E5.m1.1.1.2.3" xref="S3.E5.m1.1.1.2.3.cmml"><mi id="S3.E5.m1.1.1.2.3.2" xref="S3.E5.m1.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.2.3.1" xref="S3.E5.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.2.3.3" xref="S3.E5.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.2.3.1a" xref="S3.E5.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.2.3.4" xref="S3.E5.m1.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.2.3.1b" xref="S3.E5.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.2.3.5" xref="S3.E5.m1.1.1.2.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.2.3.1c" xref="S3.E5.m1.1.1.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.2.3.6" xref="S3.E5.m1.1.1.2.3.6.cmml">l</mi></mrow></msub><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.3" xref="S3.E5.m1.1.1.3.cmml"><mrow id="S3.E5.m1.1.1.3.2" xref="S3.E5.m1.1.1.3.2.cmml"><msub id="S3.E5.m1.1.1.3.2.2" xref="S3.E5.m1.1.1.3.2.2.cmml"><mi id="S3.E5.m1.1.1.3.2.2.2" xref="S3.E5.m1.1.1.3.2.2.2.cmml">λ</mi><mrow id="S3.E5.m1.1.1.3.2.2.3" xref="S3.E5.m1.1.1.3.2.2.3.cmml"><mi id="S3.E5.m1.1.1.3.2.2.3.2" xref="S3.E5.m1.1.1.3.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.2.3.1" xref="S3.E5.m1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.2.3.3" xref="S3.E5.m1.1.1.3.2.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.2.3.1a" xref="S3.E5.m1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.2.3.4" xref="S3.E5.m1.1.1.3.2.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.2.3.1b" xref="S3.E5.m1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.2.3.5" xref="S3.E5.m1.1.1.3.2.2.3.5.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.1" xref="S3.E5.m1.1.1.3.2.1.cmml">​</mo><msub id="S3.E5.m1.1.1.3.2.3" xref="S3.E5.m1.1.1.3.2.3.cmml"><mi id="S3.E5.m1.1.1.3.2.3.2" xref="S3.E5.m1.1.1.3.2.3.2.cmml">ε</mi><mrow id="S3.E5.m1.1.1.3.2.3.3" xref="S3.E5.m1.1.1.3.2.3.3.cmml"><mi id="S3.E5.m1.1.1.3.2.3.3.2" xref="S3.E5.m1.1.1.3.2.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.3.3.1" xref="S3.E5.m1.1.1.3.2.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.3.3.3" xref="S3.E5.m1.1.1.3.2.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.3.3.1a" xref="S3.E5.m1.1.1.3.2.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.3.3.4" xref="S3.E5.m1.1.1.3.2.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.2.3.3.1b" xref="S3.E5.m1.1.1.3.2.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.2.3.3.5" xref="S3.E5.m1.1.1.3.2.3.3.5.cmml">e</mi></mrow></msub></mrow><mo id="S3.E5.m1.1.1.3.1" xref="S3.E5.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E5.m1.1.1.3.3" xref="S3.E5.m1.1.1.3.3.cmml"><msub id="S3.E5.m1.1.1.3.3.2" xref="S3.E5.m1.1.1.3.3.2.cmml"><mi id="S3.E5.m1.1.1.3.3.2.2" xref="S3.E5.m1.1.1.3.3.2.2.cmml">λ</mi><mrow id="S3.E5.m1.1.1.3.3.2.3" xref="S3.E5.m1.1.1.3.3.2.3.cmml"><mi id="S3.E5.m1.1.1.3.3.2.3.2" xref="S3.E5.m1.1.1.3.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.3" xref="S3.E5.m1.1.1.3.3.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1a" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.4" xref="S3.E5.m1.1.1.3.3.2.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1b" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.5" xref="S3.E5.m1.1.1.3.3.2.3.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1c" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.6" xref="S3.E5.m1.1.1.3.3.2.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1d" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.7" xref="S3.E5.m1.1.1.3.3.2.3.7.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1e" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.8" xref="S3.E5.m1.1.1.3.3.2.3.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1f" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.9" xref="S3.E5.m1.1.1.3.3.2.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1g" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.10" xref="S3.E5.m1.1.1.3.3.2.3.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.2.3.1h" xref="S3.E5.m1.1.1.3.3.2.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.2.3.11" xref="S3.E5.m1.1.1.3.3.2.3.11.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.1" xref="S3.E5.m1.1.1.3.3.1.cmml">​</mo><msub id="S3.E5.m1.1.1.3.3.3" xref="S3.E5.m1.1.1.3.3.3.cmml"><mi id="S3.E5.m1.1.1.3.3.3.2" xref="S3.E5.m1.1.1.3.3.3.2.cmml">ε</mi><mrow id="S3.E5.m1.1.1.3.3.3.3" xref="S3.E5.m1.1.1.3.3.3.3.cmml"><mi id="S3.E5.m1.1.1.3.3.3.3.2" xref="S3.E5.m1.1.1.3.3.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.3" xref="S3.E5.m1.1.1.3.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1a" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.4" xref="S3.E5.m1.1.1.3.3.3.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1b" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.5" xref="S3.E5.m1.1.1.3.3.3.3.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1c" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.6" xref="S3.E5.m1.1.1.3.3.3.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1d" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.7" xref="S3.E5.m1.1.1.3.3.3.3.7.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1e" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.8" xref="S3.E5.m1.1.1.3.3.3.3.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1f" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.9" xref="S3.E5.m1.1.1.3.3.3.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1g" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.10" xref="S3.E5.m1.1.1.3.3.3.3.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.1.1.3.3.3.3.1h" xref="S3.E5.m1.1.1.3.3.3.3.1.cmml">​</mo><mi id="S3.E5.m1.1.1.3.3.3.3.11" xref="S3.E5.m1.1.1.3.3.3.3.11.cmml">e</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><eq id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"></eq><apply id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.2">subscript</csymbol><ci id="S3.E5.m1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.2.2">𝜀</ci><apply id="S3.E5.m1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.2.3"><times id="S3.E5.m1.1.1.2.3.1.cmml" xref="S3.E5.m1.1.1.2.3.1"></times><ci id="S3.E5.m1.1.1.2.3.2.cmml" xref="S3.E5.m1.1.1.2.3.2">𝑡</ci><ci id="S3.E5.m1.1.1.2.3.3.cmml" xref="S3.E5.m1.1.1.2.3.3">𝑜</ci><ci id="S3.E5.m1.1.1.2.3.4.cmml" xref="S3.E5.m1.1.1.2.3.4">𝑡</ci><ci id="S3.E5.m1.1.1.2.3.5.cmml" xref="S3.E5.m1.1.1.2.3.5">𝑎</ci><ci id="S3.E5.m1.1.1.2.3.6.cmml" xref="S3.E5.m1.1.1.2.3.6">𝑙</ci></apply></apply><apply id="S3.E5.m1.1.1.3.cmml" xref="S3.E5.m1.1.1.3"><plus id="S3.E5.m1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.3.1"></plus><apply id="S3.E5.m1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.3.2"><times id="S3.E5.m1.1.1.3.2.1.cmml" xref="S3.E5.m1.1.1.3.2.1"></times><apply id="S3.E5.m1.1.1.3.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.2.1.cmml" xref="S3.E5.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.2.2.cmml" xref="S3.E5.m1.1.1.3.2.2.2">𝜆</ci><apply id="S3.E5.m1.1.1.3.2.2.3.cmml" xref="S3.E5.m1.1.1.3.2.2.3"><times id="S3.E5.m1.1.1.3.2.2.3.1.cmml" xref="S3.E5.m1.1.1.3.2.2.3.1"></times><ci id="S3.E5.m1.1.1.3.2.2.3.2.cmml" xref="S3.E5.m1.1.1.3.2.2.3.2">𝑝</ci><ci id="S3.E5.m1.1.1.3.2.2.3.3.cmml" xref="S3.E5.m1.1.1.3.2.2.3.3">𝑜</ci><ci id="S3.E5.m1.1.1.3.2.2.3.4.cmml" xref="S3.E5.m1.1.1.3.2.2.3.4">𝑠</ci><ci id="S3.E5.m1.1.1.3.2.2.3.5.cmml" xref="S3.E5.m1.1.1.3.2.2.3.5">𝑒</ci></apply></apply><apply id="S3.E5.m1.1.1.3.2.3.cmml" xref="S3.E5.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.2.3.1.cmml" xref="S3.E5.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.2.3.2.cmml" xref="S3.E5.m1.1.1.3.2.3.2">𝜀</ci><apply id="S3.E5.m1.1.1.3.2.3.3.cmml" xref="S3.E5.m1.1.1.3.2.3.3"><times id="S3.E5.m1.1.1.3.2.3.3.1.cmml" xref="S3.E5.m1.1.1.3.2.3.3.1"></times><ci id="S3.E5.m1.1.1.3.2.3.3.2.cmml" xref="S3.E5.m1.1.1.3.2.3.3.2">𝑝</ci><ci id="S3.E5.m1.1.1.3.2.3.3.3.cmml" xref="S3.E5.m1.1.1.3.2.3.3.3">𝑜</ci><ci id="S3.E5.m1.1.1.3.2.3.3.4.cmml" xref="S3.E5.m1.1.1.3.2.3.3.4">𝑠</ci><ci id="S3.E5.m1.1.1.3.2.3.3.5.cmml" xref="S3.E5.m1.1.1.3.2.3.3.5">𝑒</ci></apply></apply></apply><apply id="S3.E5.m1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.3.3"><times id="S3.E5.m1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.1"></times><apply id="S3.E5.m1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.2.1.cmml" xref="S3.E5.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.2.2.cmml" xref="S3.E5.m1.1.1.3.3.2.2">𝜆</ci><apply id="S3.E5.m1.1.1.3.3.2.3.cmml" xref="S3.E5.m1.1.1.3.3.2.3"><times id="S3.E5.m1.1.1.3.3.2.3.1.cmml" xref="S3.E5.m1.1.1.3.3.2.3.1"></times><ci id="S3.E5.m1.1.1.3.3.2.3.2.cmml" xref="S3.E5.m1.1.1.3.3.2.3.2">𝑠</ci><ci id="S3.E5.m1.1.1.3.3.2.3.3.cmml" xref="S3.E5.m1.1.1.3.3.2.3.3">𝑖</ci><ci id="S3.E5.m1.1.1.3.3.2.3.4.cmml" xref="S3.E5.m1.1.1.3.3.2.3.4">𝑙</ci><ci id="S3.E5.m1.1.1.3.3.2.3.5.cmml" xref="S3.E5.m1.1.1.3.3.2.3.5">ℎ</ci><ci id="S3.E5.m1.1.1.3.3.2.3.6.cmml" xref="S3.E5.m1.1.1.3.3.2.3.6">𝑜</ci><ci id="S3.E5.m1.1.1.3.3.2.3.7.cmml" xref="S3.E5.m1.1.1.3.3.2.3.7">𝑢</ci><ci id="S3.E5.m1.1.1.3.3.2.3.8.cmml" xref="S3.E5.m1.1.1.3.3.2.3.8">𝑒</ci><ci id="S3.E5.m1.1.1.3.3.2.3.9.cmml" xref="S3.E5.m1.1.1.3.3.2.3.9">𝑡</ci><ci id="S3.E5.m1.1.1.3.3.2.3.10.cmml" xref="S3.E5.m1.1.1.3.3.2.3.10">𝑡</ci><ci id="S3.E5.m1.1.1.3.3.2.3.11.cmml" xref="S3.E5.m1.1.1.3.3.2.3.11">𝑒</ci></apply></apply><apply id="S3.E5.m1.1.1.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E5.m1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.3.2">𝜀</ci><apply id="S3.E5.m1.1.1.3.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3.3"><times id="S3.E5.m1.1.1.3.3.3.3.1.cmml" xref="S3.E5.m1.1.1.3.3.3.3.1"></times><ci id="S3.E5.m1.1.1.3.3.3.3.2.cmml" xref="S3.E5.m1.1.1.3.3.3.3.2">𝑠</ci><ci id="S3.E5.m1.1.1.3.3.3.3.3.cmml" xref="S3.E5.m1.1.1.3.3.3.3.3">𝑖</ci><ci id="S3.E5.m1.1.1.3.3.3.3.4.cmml" xref="S3.E5.m1.1.1.3.3.3.3.4">𝑙</ci><ci id="S3.E5.m1.1.1.3.3.3.3.5.cmml" xref="S3.E5.m1.1.1.3.3.3.3.5">ℎ</ci><ci id="S3.E5.m1.1.1.3.3.3.3.6.cmml" xref="S3.E5.m1.1.1.3.3.3.3.6">𝑜</ci><ci id="S3.E5.m1.1.1.3.3.3.3.7.cmml" xref="S3.E5.m1.1.1.3.3.3.3.7">𝑢</ci><ci id="S3.E5.m1.1.1.3.3.3.3.8.cmml" xref="S3.E5.m1.1.1.3.3.3.3.8">𝑒</ci><ci id="S3.E5.m1.1.1.3.3.3.3.9.cmml" xref="S3.E5.m1.1.1.3.3.3.3.9">𝑡</ci><ci id="S3.E5.m1.1.1.3.3.3.3.10.cmml" xref="S3.E5.m1.1.1.3.3.3.3.10">𝑡</ci><ci id="S3.E5.m1.1.1.3.3.3.3.11.cmml" xref="S3.E5.m1.1.1.3.3.3.3.11">𝑒</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">\varepsilon_{total}=\lambda_{pose}\varepsilon_{pose}+\lambda_{silhouette}\varepsilon_{silhouette}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.2" class="ltx_p">It is apparent that the introduction of the weights <math id="S3.SS2.p6.1.m1.1" class="ltx_Math" alttext="\lambda_{pose}" display="inline"><semantics id="S3.SS2.p6.1.m1.1a"><msub id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml"><mi id="S3.SS2.p6.1.m1.1.1.2" xref="S3.SS2.p6.1.m1.1.1.2.cmml">λ</mi><mrow id="S3.SS2.p6.1.m1.1.1.3" xref="S3.SS2.p6.1.m1.1.1.3.cmml"><mi id="S3.SS2.p6.1.m1.1.1.3.2" xref="S3.SS2.p6.1.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.1.m1.1.1.3.1" xref="S3.SS2.p6.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.1.m1.1.1.3.3" xref="S3.SS2.p6.1.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.1.m1.1.1.3.1a" xref="S3.SS2.p6.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.1.m1.1.1.3.4" xref="S3.SS2.p6.1.m1.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.1.m1.1.1.3.1b" xref="S3.SS2.p6.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.1.m1.1.1.3.5" xref="S3.SS2.p6.1.m1.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><apply id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.1.m1.1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p6.1.m1.1.1.2.cmml" xref="S3.SS2.p6.1.m1.1.1.2">𝜆</ci><apply id="S3.SS2.p6.1.m1.1.1.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3"><times id="S3.SS2.p6.1.m1.1.1.3.1.cmml" xref="S3.SS2.p6.1.m1.1.1.3.1"></times><ci id="S3.SS2.p6.1.m1.1.1.3.2.cmml" xref="S3.SS2.p6.1.m1.1.1.3.2">𝑝</ci><ci id="S3.SS2.p6.1.m1.1.1.3.3.cmml" xref="S3.SS2.p6.1.m1.1.1.3.3">𝑜</ci><ci id="S3.SS2.p6.1.m1.1.1.3.4.cmml" xref="S3.SS2.p6.1.m1.1.1.3.4">𝑠</ci><ci id="S3.SS2.p6.1.m1.1.1.3.5.cmml" xref="S3.SS2.p6.1.m1.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">\lambda_{pose}</annotation></semantics></math> and
<math id="S3.SS2.p6.2.m2.1" class="ltx_Math" alttext="\lambda_{silhouette}" display="inline"><semantics id="S3.SS2.p6.2.m2.1a"><msub id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml"><mi id="S3.SS2.p6.2.m2.1.1.2" xref="S3.SS2.p6.2.m2.1.1.2.cmml">λ</mi><mrow id="S3.SS2.p6.2.m2.1.1.3" xref="S3.SS2.p6.2.m2.1.1.3.cmml"><mi id="S3.SS2.p6.2.m2.1.1.3.2" xref="S3.SS2.p6.2.m2.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.3" xref="S3.SS2.p6.2.m2.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1a" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.4" xref="S3.SS2.p6.2.m2.1.1.3.4.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1b" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.5" xref="S3.SS2.p6.2.m2.1.1.3.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1c" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.6" xref="S3.SS2.p6.2.m2.1.1.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1d" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.7" xref="S3.SS2.p6.2.m2.1.1.3.7.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1e" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.8" xref="S3.SS2.p6.2.m2.1.1.3.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1f" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.9" xref="S3.SS2.p6.2.m2.1.1.3.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1g" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.10" xref="S3.SS2.p6.2.m2.1.1.3.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.2.m2.1.1.3.1h" xref="S3.SS2.p6.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p6.2.m2.1.1.3.11" xref="S3.SS2.p6.2.m2.1.1.3.11.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><apply id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p6.2.m2.1.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p6.2.m2.1.1.2.cmml" xref="S3.SS2.p6.2.m2.1.1.2">𝜆</ci><apply id="S3.SS2.p6.2.m2.1.1.3.cmml" xref="S3.SS2.p6.2.m2.1.1.3"><times id="S3.SS2.p6.2.m2.1.1.3.1.cmml" xref="S3.SS2.p6.2.m2.1.1.3.1"></times><ci id="S3.SS2.p6.2.m2.1.1.3.2.cmml" xref="S3.SS2.p6.2.m2.1.1.3.2">𝑠</ci><ci id="S3.SS2.p6.2.m2.1.1.3.3.cmml" xref="S3.SS2.p6.2.m2.1.1.3.3">𝑖</ci><ci id="S3.SS2.p6.2.m2.1.1.3.4.cmml" xref="S3.SS2.p6.2.m2.1.1.3.4">𝑙</ci><ci id="S3.SS2.p6.2.m2.1.1.3.5.cmml" xref="S3.SS2.p6.2.m2.1.1.3.5">ℎ</ci><ci id="S3.SS2.p6.2.m2.1.1.3.6.cmml" xref="S3.SS2.p6.2.m2.1.1.3.6">𝑜</ci><ci id="S3.SS2.p6.2.m2.1.1.3.7.cmml" xref="S3.SS2.p6.2.m2.1.1.3.7">𝑢</ci><ci id="S3.SS2.p6.2.m2.1.1.3.8.cmml" xref="S3.SS2.p6.2.m2.1.1.3.8">𝑒</ci><ci id="S3.SS2.p6.2.m2.1.1.3.9.cmml" xref="S3.SS2.p6.2.m2.1.1.3.9">𝑡</ci><ci id="S3.SS2.p6.2.m2.1.1.3.10.cmml" xref="S3.SS2.p6.2.m2.1.1.3.10">𝑡</ci><ci id="S3.SS2.p6.2.m2.1.1.3.11.cmml" xref="S3.SS2.p6.2.m2.1.1.3.11">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">\lambda_{silhouette}</annotation></semantics></math> will introduce similar challenges as aforementioned (i.e. finding the best combination for each object will be challenging and time-consuming). Motivated by that, they treat those two weights as learnable parameters adding them to the learning objective. Thus, the weights are able to adapt to the various objects and, additionally, to better regularize the two losses during training.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.4" class="ltx_p">Finally, the model is trained for 100 epochs on a GeForce RTX 2080 TI 11 GB. All the images (i.e. color and depth) are resized to <math id="S3.SS2.p7.1.m1.1" class="ltx_Math" alttext="320\times 180" display="inline"><semantics id="S3.SS2.p7.1.m1.1a"><mrow id="S3.SS2.p7.1.m1.1.1" xref="S3.SS2.p7.1.m1.1.1.cmml"><mn id="S3.SS2.p7.1.m1.1.1.2" xref="S3.SS2.p7.1.m1.1.1.2.cmml">320</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p7.1.m1.1.1.1" xref="S3.SS2.p7.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.p7.1.m1.1.1.3" xref="S3.SS2.p7.1.m1.1.1.3.cmml">180</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.1.m1.1b"><apply id="S3.SS2.p7.1.m1.1.1.cmml" xref="S3.SS2.p7.1.m1.1.1"><times id="S3.SS2.p7.1.m1.1.1.1.cmml" xref="S3.SS2.p7.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p7.1.m1.1.1.2.cmml" xref="S3.SS2.p7.1.m1.1.1.2">320</cn><cn type="integer" id="S3.SS2.p7.1.m1.1.1.3.cmml" xref="S3.SS2.p7.1.m1.1.1.3">180</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.1.m1.1c">320\times 180</annotation></semantics></math> resolution, and the batch size is set to <math id="S3.SS2.p7.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S3.SS2.p7.2.m2.1a"><mn id="S3.SS2.p7.2.m2.1.1" xref="S3.SS2.p7.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.2.m2.1b"><cn type="integer" id="S3.SS2.p7.2.m2.1.1.cmml" xref="S3.SS2.p7.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.2.m2.1c">16</annotation></semantics></math>. For optimizing the model’s parameters they use the Adam optimizer with a learning rate of <math id="S3.SS2.p7.3.m3.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S3.SS2.p7.3.m3.1a"><mrow id="S3.SS2.p7.3.m3.1.1" xref="S3.SS2.p7.3.m3.1.1.cmml"><mn id="S3.SS2.p7.3.m3.1.1.2" xref="S3.SS2.p7.3.m3.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p7.3.m3.1.1.1" xref="S3.SS2.p7.3.m3.1.1.1.cmml">×</mo><msup id="S3.SS2.p7.3.m3.1.1.3" xref="S3.SS2.p7.3.m3.1.1.3.cmml"><mn id="S3.SS2.p7.3.m3.1.1.3.2" xref="S3.SS2.p7.3.m3.1.1.3.2.cmml">10</mn><mrow id="S3.SS2.p7.3.m3.1.1.3.3" xref="S3.SS2.p7.3.m3.1.1.3.3.cmml"><mo id="S3.SS2.p7.3.m3.1.1.3.3a" xref="S3.SS2.p7.3.m3.1.1.3.3.cmml">−</mo><mn id="S3.SS2.p7.3.m3.1.1.3.3.2" xref="S3.SS2.p7.3.m3.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.3.m3.1b"><apply id="S3.SS2.p7.3.m3.1.1.cmml" xref="S3.SS2.p7.3.m3.1.1"><times id="S3.SS2.p7.3.m3.1.1.1.cmml" xref="S3.SS2.p7.3.m3.1.1.1"></times><cn type="integer" id="S3.SS2.p7.3.m3.1.1.2.cmml" xref="S3.SS2.p7.3.m3.1.1.2">1</cn><apply id="S3.SS2.p7.3.m3.1.1.3.cmml" xref="S3.SS2.p7.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p7.3.m3.1.1.3.1.cmml" xref="S3.SS2.p7.3.m3.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS2.p7.3.m3.1.1.3.2.cmml" xref="S3.SS2.p7.3.m3.1.1.3.2">10</cn><apply id="S3.SS2.p7.3.m3.1.1.3.3.cmml" xref="S3.SS2.p7.3.m3.1.1.3.3"><minus id="S3.SS2.p7.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.p7.3.m3.1.1.3.3"></minus><cn type="integer" id="S3.SS2.p7.3.m3.1.1.3.3.2.cmml" xref="S3.SS2.p7.3.m3.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.3.m3.1c">1\times 10^{-4}</annotation></semantics></math>. Additionally, learnable Gaussian standard deviation and the weights of <a href="#S3.E5" title="In 3.2 ASS3D: Adaptive Single-Shot 3D Object Pose Estimation ‣ 3 Methods ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> are optimized with a SGD optimizer with a learning rate of <math id="S3.SS2.p7.4.m4.1" class="ltx_Math" alttext="1\times 10^{-5}" display="inline"><semantics id="S3.SS2.p7.4.m4.1a"><mrow id="S3.SS2.p7.4.m4.1.1" xref="S3.SS2.p7.4.m4.1.1.cmml"><mn id="S3.SS2.p7.4.m4.1.1.2" xref="S3.SS2.p7.4.m4.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p7.4.m4.1.1.1" xref="S3.SS2.p7.4.m4.1.1.1.cmml">×</mo><msup id="S3.SS2.p7.4.m4.1.1.3" xref="S3.SS2.p7.4.m4.1.1.3.cmml"><mn id="S3.SS2.p7.4.m4.1.1.3.2" xref="S3.SS2.p7.4.m4.1.1.3.2.cmml">10</mn><mrow id="S3.SS2.p7.4.m4.1.1.3.3" xref="S3.SS2.p7.4.m4.1.1.3.3.cmml"><mo id="S3.SS2.p7.4.m4.1.1.3.3a" xref="S3.SS2.p7.4.m4.1.1.3.3.cmml">−</mo><mn id="S3.SS2.p7.4.m4.1.1.3.3.2" xref="S3.SS2.p7.4.m4.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p7.4.m4.1b"><apply id="S3.SS2.p7.4.m4.1.1.cmml" xref="S3.SS2.p7.4.m4.1.1"><times id="S3.SS2.p7.4.m4.1.1.1.cmml" xref="S3.SS2.p7.4.m4.1.1.1"></times><cn type="integer" id="S3.SS2.p7.4.m4.1.1.2.cmml" xref="S3.SS2.p7.4.m4.1.1.2">1</cn><apply id="S3.SS2.p7.4.m4.1.1.3.cmml" xref="S3.SS2.p7.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p7.4.m4.1.1.3.1.cmml" xref="S3.SS2.p7.4.m4.1.1.3">superscript</csymbol><cn type="integer" id="S3.SS2.p7.4.m4.1.1.3.2.cmml" xref="S3.SS2.p7.4.m4.1.1.3.2">10</cn><apply id="S3.SS2.p7.4.m4.1.1.3.3.cmml" xref="S3.SS2.p7.4.m4.1.1.3.3"><minus id="S3.SS2.p7.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p7.4.m4.1.1.3.3"></minus><cn type="integer" id="S3.SS2.p7.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p7.4.m4.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p7.4.m4.1c">1\times 10^{-5}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>GraphFusion: 6D object pose estimation with graph based multi-feature fusion </h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">They propose a graph based multi-feature fusion network to improve 6D pose prediction performance, which combines effective feature extraction networks and a graph attention network (GAT) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">VCC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>17</a>]</cite> to fully exploit the relationship between visual and geometric features.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2010.09355/assets/x2.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="221" height="117" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Overview of the graph based pose estimation architecture. The input of their networks are captured color-and-depth images pairs. These images are cropped with the semantic segmentation architecture. After that, the visual and geometric features are extracted and fused by a graph attention network which is introduced to exploit the fusion strategy between color and geometric features. The 6D object pose and its corresponding confidence score are predicted by the fused features and the final pose is chosen based on the confidences. </figcaption>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The aim of their approach is to achieve the real-time 6D pose estimation, using RGB-D images as input, as shown in Figure<a href="#S3.F5" title="Figure 5 ‣ 3.3 GraphFusion: 6D object pose estimation with graph based multi-feature fusion ‣ 3 Methods ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Handcrafted features such as SIFT or ORB are key factors for classical methods to estimate 6D poses. However, it is difficult to estimate 6D poses for texture-less objects. Instead of relying on improving handcrafted features, they learn more robust features and semantic cues by applying deep learning models.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">They use a Convolutional Neural Network (CNN) based encoder-decoder architecture to learn visual features from color images. To extract geometric features from the depth map, they first convert the depth map to the point cloud using the camera intrinsic matrix. There are two ways to process the point cloud. Classic approaches often convert point cloud data into regular grids by projecting 3D data into 2D images or splitting raw data into 3D voxel grids. Then they process the transformed data using approaches based on regular data. Other approaches are to directly process each point in the point cloud. PointNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">QSMG17</a>]</cite> is the first one to apply this idea, which achieves permutation invariance by use of a symmetric function. Instead of transforming to regular data, they use PointNet-based network to extract geometric features from the point cloud.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">Even with learned features that contains the visual appearance and geometry structure information, accurate 6D object pose also depends on the fused features. To effectively fuse features, they introduce a graph attention based framework to exploit relationship between visual and geometric features, as opposed to prior works which just concatenates these features. Combining the insights above, their approach works as follows:</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p">The input are captured color-and-depth image pairs and a semantic segmentation architecture from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">XSNF17</a>]</cite> is used to segment the target object and crop the color and depth images. Next, the visual features are extracted by a CNN-based network and geometric representations are computed from the point cloud using PointNet. The point cloud is generated by converting its corresponding depth map. With these features, a graph attention network is introduced to perform the fusion between color and geometric features. After that, the 6D object pose and its corresponding confidence score are predicted by the fused features, one pose per fused feature. Then, the pose with the highest confidence is chosen as the estimated pose. Lastly, the 6D pose is further improved by iterative pose refinement.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Overall performance</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The overall performance of DenseFusion, ASS3D, GraphFusion without refinement (GraphFusion_wo) and GraphFusion is shown in Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a href="#S4.T2" title="Table 2 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. DenseFusion and ASS3D are proposed from two different research groups, and GraphFusion without refinement (GraphFusion_wo) and GraphFusion is proposed from one research group. We use ADD, ADD-S and the area under ADD curve (AUC) to measure the prediction.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Quantitative evaluation of the 6D pose (ADD and ADD-S).</figcaption>
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:403.6pt;height:198pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T1.1.1" class="ltx_p"><span id="S4.T1.1.1.1" class="ltx_text">
<span id="S4.T1.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T1.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.T1.1.1.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t ltx_rowspan ltx_rowspan_2"></span>
<span id="S4.T1.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">DenseFusion</span>
<span id="S4.T1.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">ASS3D</span>
<span id="S4.T1.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t ltx_colspan ltx_colspan_2">GraphFusion_wo</span>
<span id="S4.T1.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t ltx_colspan ltx_colspan_2">GraphFusion</span></span>
<span id="S4.T1.1.1.1.1.2.2" class="ltx_tr">
<span id="S4.T1.1.1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</span>
<span id="S4.T1.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</span>
<span id="S4.T1.1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</span>
<span id="S4.T1.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</span>
<span id="S4.T1.1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</span>
<span id="S4.T1.1.1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</span>
<span id="S4.T1.1.1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</span>
<span id="S4.T1.1.1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_t">ADD-S</span></span>
<span id="S4.T1.1.1.1.1.3.3" class="ltx_tr">
<span id="S4.T1.1.1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">banana</span>
<span id="S4.T1.1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.3.3.2.1" class="ltx_text ltx_font_bold">0.86</span></span>
<span id="S4.T1.1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.86</span>
<span id="S4.T1.1.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.70</span>
<span id="S4.T1.1.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.75</span>
<span id="S4.T1.1.1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.76</span>
<span id="S4.T1.1.1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.80</span>
<span id="S4.T1.1.1.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.83</span>
<span id="S4.T1.1.1.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.3.3.9.1" class="ltx_text ltx_font_bold">0.87</span></span></span>
<span id="S4.T1.1.1.1.1.4.4" class="ltx_tr">
<span id="S4.T1.1.1.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">biscuit_box</span>
<span id="S4.T1.1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.91</span>
<span id="S4.T1.1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.95</span>
<span id="S4.T1.1.1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.78</span>
<span id="S4.T1.1.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.88</span>
<span id="S4.T1.1.1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.80</span>
<span id="S4.T1.1.1.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.84</span>
<span id="S4.T1.1.1.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.4.4.8.1" class="ltx_text ltx_font_bold">0.93</span></span>
<span id="S4.T1.1.1.1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.4.4.9.1" class="ltx_text ltx_font_bold">0.96</span></span></span>
<span id="S4.T1.1.1.1.1.5.5" class="ltx_tr">
<span id="S4.T1.1.1.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">chips_can</span>
<span id="S4.T1.1.1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.56</span>
<span id="S4.T1.1.1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.94</span>
<span id="S4.T1.1.1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.5.5.4.1" class="ltx_text ltx_font_bold">0.75</span></span>
<span id="S4.T1.1.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.85</span>
<span id="S4.T1.1.1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.53</span>
<span id="S4.T1.1.1.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.57</span>
<span id="S4.T1.1.1.1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.69</span>
<span id="S4.T1.1.1.1.1.5.5.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.5.5.9.1" class="ltx_text ltx_font_bold">0.97</span></span></span>
<span id="S4.T1.1.1.1.1.6.6" class="ltx_tr">
<span id="S4.T1.1.1.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">cookie_box</span>
<span id="S4.T1.1.1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.6.6.2.1" class="ltx_text ltx_font_bold">0.62</span></span>
<span id="S4.T1.1.1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.74</span>
<span id="S4.T1.1.1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.49</span>
<span id="S4.T1.1.1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.66</span>
<span id="S4.T1.1.1.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</span>
<span id="S4.T1.1.1.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.56</span>
<span id="S4.T1.1.1.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.61</span>
<span id="S4.T1.1.1.1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.6.6.9.1" class="ltx_text ltx_font_bold">0.75</span></span></span>
<span id="S4.T1.1.1.1.1.7.7" class="ltx_tr">
<span id="S4.T1.1.1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">gingerbread_box</span>
<span id="S4.T1.1.1.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.87</span>
<span id="S4.T1.1.1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.94</span>
<span id="S4.T1.1.1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.63</span>
<span id="S4.T1.1.1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.86</span>
<span id="S4.T1.1.1.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.79</span>
<span id="S4.T1.1.1.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.83</span>
<span id="S4.T1.1.1.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.7.7.8.1" class="ltx_text ltx_font_bold">0.90</span></span>
<span id="S4.T1.1.1.1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.7.7.9.1" class="ltx_text ltx_font_bold">0.95</span></span></span>
<span id="S4.T1.1.1.1.1.8.8" class="ltx_tr">
<span id="S4.T1.1.1.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">milk_box</span>
<span id="S4.T1.1.1.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</span>
<span id="S4.T1.1.1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.8.8.3.1" class="ltx_text ltx_font_bold">0.81</span></span>
<span id="S4.T1.1.1.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.58</span>
<span id="S4.T1.1.1.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.62</span>
<span id="S4.T1.1.1.1.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</span>
<span id="S4.T1.1.1.1.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.53</span>
<span id="S4.T1.1.1.1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.8.8.8.1" class="ltx_text ltx_font_bold">0.66</span></span>
<span id="S4.T1.1.1.1.1.8.8.9" class="ltx_td ltx_align_center ltx_border_t">0.77</span></span>
<span id="S4.T1.1.1.1.1.9.9" class="ltx_tr">
<span id="S4.T1.1.1.1.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">pasta_box</span>
<span id="S4.T1.1.1.1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.77</span>
<span id="S4.T1.1.1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.91</span>
<span id="S4.T1.1.1.1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.63</span>
<span id="S4.T1.1.1.1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.72</span>
<span id="S4.T1.1.1.1.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.76</span>
<span id="S4.T1.1.1.1.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.78</span>
<span id="S4.T1.1.1.1.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.9.9.8.1" class="ltx_text ltx_font_bold">0.84</span></span>
<span id="S4.T1.1.1.1.1.9.9.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.9.9.9.1" class="ltx_text ltx_font_bold">0.96</span></span></span>
<span id="S4.T1.1.1.1.1.10.10" class="ltx_tr">
<span id="S4.T1.1.1.1.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">vacuum_cup</span>
<span id="S4.T1.1.1.1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.61</span>
<span id="S4.T1.1.1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.90</span>
<span id="S4.T1.1.1.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.10.10.4.1" class="ltx_text ltx_font_bold">0.65</span></span>
<span id="S4.T1.1.1.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.75</span>
<span id="S4.T1.1.1.1.1.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</span>
<span id="S4.T1.1.1.1.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.53</span>
<span id="S4.T1.1.1.1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.63</span>
<span id="S4.T1.1.1.1.1.10.10.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.10.10.9.1" class="ltx_text ltx_font_bold">0.97</span></span></span>
<span id="S4.T1.1.1.1.1.11.11" class="ltx_tr">
<span id="S4.T1.1.1.1.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">MEAN</span>
<span id="S4.T1.1.1.1.1.11.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.71</span>
<span id="S4.T1.1.1.1.1.11.11.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.88</span>
<span id="S4.T1.1.1.1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.65</span>
<span id="S4.T1.1.1.1.1.11.11.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.76</span>
<span id="S4.T1.1.1.1.1.11.11.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.65</span>
<span id="S4.T1.1.1.1.1.11.11.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.68</span>
<span id="S4.T1.1.1.1.1.11.11.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.1.1.1.1.11.11.8.1" class="ltx_text ltx_font_bold">0.76</span></span>
<span id="S4.T1.1.1.1.1.11.11.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T1.1.1.1.1.11.11.9.1" class="ltx_text ltx_font_bold">0.90</span></span></span>
</span>
</span></span></p>
</span></div>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The 6D pose estimation accuracy in terms of the area under AUC.</figcaption>
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:350.9pt;height:180pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T2.1.1" class="ltx_p"><span id="S4.T2.1.1.1" class="ltx_text">
<span id="S4.T2.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T2.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.T2.1.1.1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></span>
<span id="S4.T2.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DenseFusin</span>
<span id="S4.T2.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ASS3D</span>
<span id="S4.T2.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GraphFusion_wo</span>
<span id="S4.T2.1.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t">GraphFusion</span></span>
<span id="S4.T2.1.1.1.1.2.2" class="ltx_tr">
<span id="S4.T2.1.1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">banana</span>
<span id="S4.T2.1.1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.1.1.2.2.2.1" class="ltx_text ltx_font_bold">0.77</span></span>
<span id="S4.T2.1.1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.66</span>
<span id="S4.T2.1.1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.66</span>
<span id="S4.T2.1.1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t">0.75</span></span>
<span id="S4.T2.1.1.1.1.3.3" class="ltx_tr">
<span id="S4.T2.1.1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">biscuit_box</span>
<span id="S4.T2.1.1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.77</span>
<span id="S4.T2.1.1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.74</span>
<span id="S4.T2.1.1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.68</span>
<span id="S4.T2.1.1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.1.1.3.3.5.1" class="ltx_text ltx_font_bold">0.79</span></span></span>
<span id="S4.T2.1.1.1.1.4.4" class="ltx_tr">
<span id="S4.T2.1.1.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">chips_can</span>
<span id="S4.T2.1.1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.74</span>
<span id="S4.T2.1.1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.72</span>
<span id="S4.T2.1.1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.55</span>
<span id="S4.T2.1.1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.1.1.4.4.5.1" class="ltx_text ltx_font_bold">0.76</span></span></span>
<span id="S4.T2.1.1.1.1.5.5" class="ltx_tr">
<span id="S4.T2.1.1.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">cookie_box</span>
<span id="S4.T2.1.1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.1.1.5.5.2.1" class="ltx_text ltx_font_bold">0.67</span></span>
<span id="S4.T2.1.1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.56</span>
<span id="S4.T2.1.1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.53</span>
<span id="S4.T2.1.1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_t">0.66</span></span>
<span id="S4.T2.1.1.1.1.6.6" class="ltx_tr">
<span id="S4.T2.1.1.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">gingerbread_box</span>
<span id="S4.T2.1.1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.76</span>
<span id="S4.T2.1.1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.71</span>
<span id="S4.T2.1.1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.64</span>
<span id="S4.T2.1.1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.1.1.6.6.5.1" class="ltx_text ltx_font_bold">0.78</span></span></span>
<span id="S4.T2.1.1.1.1.7.7" class="ltx_tr">
<span id="S4.T2.1.1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">milk_box</span>
<span id="S4.T2.1.1.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.66</span>
<span id="S4.T2.1.1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</span>
<span id="S4.T2.1.1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</span>
<span id="S4.T2.1.1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.1.1.7.7.5.1" class="ltx_text ltx_font_bold">0.67</span></span></span>
<span id="S4.T2.1.1.1.1.8.8" class="ltx_tr">
<span id="S4.T2.1.1.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">pasta_box</span>
<span id="S4.T2.1.1.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.74</span>
<span id="S4.T2.1.1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.61</span>
<span id="S4.T2.1.1.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.61</span>
<span id="S4.T2.1.1.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.1.1.8.8.5.1" class="ltx_text ltx_font_bold">0.77</span></span></span>
<span id="S4.T2.1.1.1.1.9.9" class="ltx_tr">
<span id="S4.T2.1.1.1.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">vacuum_cup</span>
<span id="S4.T2.1.1.1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.71</span>
<span id="S4.T2.1.1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.64</span>
<span id="S4.T2.1.1.1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.63</span>
<span id="S4.T2.1.1.1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.1.1.1.1.9.9.5.1" class="ltx_text ltx_font_bold">0.74</span></span></span>
<span id="S4.T2.1.1.1.1.10.10" class="ltx_tr">
<span id="S4.T2.1.1.1.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">MEAN</span>
<span id="S4.T2.1.1.1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.72</span>
<span id="S4.T2.1.1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.64</span>
<span id="S4.T2.1.1.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.60</span>
<span id="S4.T2.1.1.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.1.1.1.1.10.10.5.1" class="ltx_text ltx_font_bold">0.74</span></span></span>
</span>
</span></span></p>
</span></div>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.2" class="ltx_p">We can see that GraphFusion achieves the best performance. GraphFusion outperforms ASS3D and DenseFusion <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="11\%" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mn id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">11</mn><mo id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">11\%</annotation></semantics></math> and <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mn id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">5</mn><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">5\%</annotation></semantics></math> in terms of ADD, respectively. Besides, evaluation results show that DenseFusion, ASS3D and GraphFusion allow transforming models trained in synthesized datasets to real captured datasets without domain adaptation.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x3.png" id="S4.F6.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf1.3.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F6.sf1.4.2" class="ltx_text" style="font-size:80%;">banana</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf2.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x4.png" id="S4.F6.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf2.3.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F6.sf2.4.2" class="ltx_text" style="font-size:80%;">biscuit_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf3.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x5.png" id="S4.F6.sf3.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf3.3.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F6.sf3.4.2" class="ltx_text" style="font-size:80%;">chips_can</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf4.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x6.png" id="S4.F6.sf4.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf4.3.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S4.F6.sf4.4.2" class="ltx_text" style="font-size:80%;">cookie_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf5.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x7.png" id="S4.F6.sf5.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf5.3.1.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><span id="S4.F6.sf5.4.2" class="ltx_text" style="font-size:80%;">gingerbread_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf6.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x8.png" id="S4.F6.sf6.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf6.3.1.1" class="ltx_text" style="font-size:80%;">(f)</span> </span><span id="S4.F6.sf6.4.2" class="ltx_text" style="font-size:80%;">milk_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf7" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf7.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x9.png" id="S4.F6.sf7.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf7.3.1.1" class="ltx_text" style="font-size:80%;">(g)</span> </span><span id="S4.F6.sf7.4.2" class="ltx_text" style="font-size:80%;">pasta_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F6.sf8" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F6.sf8.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x10.png" id="S4.F6.sf8.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="68" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.sf8.3.1.1" class="ltx_text" style="font-size:80%;">(h)</span> </span><span id="S4.F6.sf8.4.2" class="ltx_text" style="font-size:80%;">vacuum_cup</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The successful rate of pose estimation in terms of ADD.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation studies</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We present ablation studies to help better understand the functionalities of different network architectures.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Effectiveness of pose refinement.</span> From Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Table <a href="#S4.T2" title="Table 2 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we can see that compared with ASS3D and GraphFusion without pose refinement, DenseFusion and GraphFusion that perform iterative pose refinement are able to further improve the accuracy of the 6D pose. The effectiveness is further verified by Figure <a href="#S4.F6" title="Figure 6 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Figure <a href="#S4.F6" title="Figure 6 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the successful pose rate measured by ADD for <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">8</annotation></semantics></math> objects, which is obtained by varying the ADD threshold. DenseFusion and GraphFusion outperform other approaches by a large margin, especially when the threshold is small.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Effectiveness of multi-feature fusion.</span> Apart from the successful pose rate generated by ADD, we calculate the successful pose rate by varying the reprojection error threshold, as shown in Figure <a href="#S4.F7" title="Figure 7 ‣ 4.2 Ablation studies ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. From Figure <a href="#S4.F6" title="Figure 6 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and Figure <a href="#S4.F7" title="Figure 7 ‣ 4.2 Ablation studies ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> we can see that GraphFusion is superior to other approaches, which indicates that fusion mechanism considering the relationship between color and geometric features has a clear advantage over methods ignoring the correlation information between RGB-D images. As Figure <a href="#S4.F7" title="Figure 7 ‣ 4.2 Ablation studies ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> makes clear that the performance of ASS3D degrade significantly as the reprojection error decreases. In contrast, the performance of DenseFusion and GraphFusion has a smaller decrease.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x11.png" id="S4.F7.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="83" height="65" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf1.3.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F7.sf1.4.2" class="ltx_text" style="font-size:80%;">banana</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf2.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x12.png" id="S4.F7.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf2.3.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F7.sf2.4.2" class="ltx_text" style="font-size:80%;">biscuit_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf3.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x13.png" id="S4.F7.sf3.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf3.3.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F7.sf3.4.2" class="ltx_text" style="font-size:80%;">chips_can</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf4.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x14.png" id="S4.F7.sf4.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf4.3.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S4.F7.sf4.4.2" class="ltx_text" style="font-size:80%;">cookie_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf5.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x15.png" id="S4.F7.sf5.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf5.3.1.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><span id="S4.F7.sf5.4.2" class="ltx_text" style="font-size:80%;">gingerbread_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf6.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x16.png" id="S4.F7.sf6.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf6.3.1.1" class="ltx_text" style="font-size:80%;">(f)</span> </span><span id="S4.F7.sf6.4.2" class="ltx_text" style="font-size:80%;">milk_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf7" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf7.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x17.png" id="S4.F7.sf7.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf7.3.1.1" class="ltx_text" style="font-size:80%;">(g)</span> </span><span id="S4.F7.sf7.4.2" class="ltx_text" style="font-size:80%;">pasta_box</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F7.sf8" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F7.sf8.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:99.7pt;">
<img src="/html/2010.09355/assets/x18.png" id="S4.F7.sf8.1.g1" class="ltx_graphics ltx_img_landscape" width="89" height="69" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf8.3.1.1" class="ltx_text" style="font-size:80%;">(h)</span> </span><span id="S4.F7.sf8.4.2" class="ltx_text" style="font-size:80%;">vacuum_cup</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The successful rate of pose estimation in terms of reprojection errors.</figcaption>
</figure>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Time efficiency and accuracy robustness of the single shot model.</span> Compared with DenseFusion and GraphFusion, ASS3D estimates the 6D pose in a single, consecutive network pass. It runs faster than other approaches, as show in Table <a href="#S4.T3" title="Table 3 ‣ 4.2 Ablation studies ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> which compares the time efficiency among different methods. In particular, ASS3D runs at least 4 times faster than GraphFusion. Besides, for the texture-less objects such as milk box, ASS3D is more robust and has a better performance as shown in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.1 Overall performance ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of the computational run time among different approaches (second per frame).</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:263.0pt;height:180pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T3.1.1" class="ltx_p"><span id="S4.T3.1.1.1" class="ltx_text">
<span id="S4.T3.1.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S4.T3.1.1.1.1.1.1" class="ltx_tr">
<span id="S4.T3.1.1.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"></span>
<span id="S4.T3.1.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">DenseFusin</span>
<span id="S4.T3.1.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">ASS3D</span>
<span id="S4.T3.1.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">GraphFusion</span></span>
</span>
<span class="ltx_tbody">
<span id="S4.T3.1.1.1.1.2.1" class="ltx_tr">
<span id="S4.T3.1.1.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">banana</span>
<span id="S4.T3.1.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.2.1.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.3.2" class="ltx_tr">
<span id="S4.T3.1.1.1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">biscuit_box</span>
<span id="S4.T3.1.1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.3.2.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.4.3" class="ltx_tr">
<span id="S4.T3.1.1.1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">chips_can</span>
<span id="S4.T3.1.1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.4.3.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.5.4" class="ltx_tr">
<span id="S4.T3.1.1.1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">cookie_box</span>
<span id="S4.T3.1.1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.5.4.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.6.5" class="ltx_tr">
<span id="S4.T3.1.1.1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">gingerbread_box</span>
<span id="S4.T3.1.1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.6.5.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.7.6" class="ltx_tr">
<span id="S4.T3.1.1.1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">milk_box</span>
<span id="S4.T3.1.1.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.7.6.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.8.7" class="ltx_tr">
<span id="S4.T3.1.1.1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">pasta_box</span>
<span id="S4.T3.1.1.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.8.7.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.9.8" class="ltx_tr">
<span id="S4.T3.1.1.1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">vacuum_cup</span>
<span id="S4.T3.1.1.1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.9.8.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_t">0.04</span></span>
<span id="S4.T3.1.1.1.1.10.9" class="ltx_tr">
<span id="S4.T3.1.1.1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">MEAN</span>
<span id="S4.T3.1.1.1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.03</span>
<span id="S4.T3.1.1.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.1.10.9.3.1" class="ltx_text ltx_font_bold">0.01</span></span>
<span id="S4.T3.1.1.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">0.04</span></span>
</span>
</span></span></p>
</span></div>
</figure>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">Furthermore, we also visualize the comparison results as shown in Figure <a href="#S4.F8" title="Figure 8 ‣ 4.2 Ablation studies ‣ 4 Results ‣ SHREC 2020 track: 6D object pose estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. It can be seen that DenseFusion, ASS3D and GraphFusion provide more accurate 6D pose for colorful objects, such as banana, gingerbread box and chips can, while these approaches are less robust against dark color or low texture objects, such as cookie box and milk box.</p>
</div>
<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F8.sf1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:390.3pt;">
<img src="/html/2010.09355/assets/x19.png" id="S4.F8.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="318" height="41" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf1.3.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S4.F8.sf1.4.2" class="ltx_text" style="font-size:80%;">DenseFusion</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F8.sf2.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:390.3pt;">
<img src="/html/2010.09355/assets/x20.png" id="S4.F8.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="320" height="40" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf2.3.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S4.F8.sf2.4.2" class="ltx_text" style="font-size:80%;">ASS3D</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F8.sf3.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:390.3pt;">
<img src="/html/2010.09355/assets/x21.png" id="S4.F8.sf3.1.g1" class="ltx_graphics ltx_img_landscape" width="318" height="41" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.sf3.3.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S4.F8.sf3.4.2" class="ltx_text" style="font-size:80%;">GraphFusion</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Examples of accuracy performance. Each 3D model is projected to the image plane with the estimated 6D pose. </figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The 6D object pose estimation is a challenging but important research direction for virtual reality, robotics and visual navigation. With this benchmark, we have captured some state-of-the-art approaches in this field and will be able to systematically measure its progress in the future. The evaluation results indicate that the approach fully exploiting color and depth features performs best, outperforming pixel fusion based method and the approach with multimodal supervision. As open problems, our analysis takes varying texture and shape objects, and object symmetries into consideration. We also note some limitations of our datasets, which we hope to improve in the future. Firstly, the synthetic dataset needs to be expanded by adding more reflective objects, occlusion, varying lighting conditions and objects with different sizes. On the other hand, more accurate depth maps and 3D models need to be provided.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Part of ASS3D research has been supported by the European Commission funded program FASTER, under H2020 Grant Agreement 833507. The organizers have been partially supported by the China Scholarship Council (CSC).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AZD<sup id="bib.bibx1.4.4.1" class="ltx_sup"><span id="bib.bibx1.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>20]</span>
<span class="ltx_bibblock">
<span id="bib.bibx1.7.1" class="ltx_text ltx_font_smallcaps">Albanis G., Zioulis N., Dimou A., Zarpalas D., Daras P.</span>:

</span>
<span class="ltx_bibblock">Dronepose: Photorealistic uav-assistant dataset synthesis for 3d pose
estimation via a smooth silhouette loss.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx1.8.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV) Workshops</em> (August 2020).

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[BKM<sup id="bib.bibx2.4.4.1" class="ltx_sup"><span id="bib.bibx2.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>14]</span>
<span class="ltx_bibblock">
<span id="bib.bibx2.7.1" class="ltx_text ltx_font_smallcaps">Brachmann E., Krull A., Michel F., Gumhold S., Shotton J., Rother C.</span>:

</span>
<span class="ltx_bibblock">Learning 6d object pose estimation using 3d object coordinates.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx2.8.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em> (2014), Springer,
pp. 536–551.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CC16]</span>
<span class="ltx_bibblock">
<span id="bib.bibx3.1.1" class="ltx_text ltx_font_smallcaps">Choi C., Christensen H. I.</span>:

</span>
<span class="ltx_bibblock">Rgb-d object pose estimation in unstructured environments.

</span>
<span class="ltx_bibblock"><em id="bib.bibx3.2.1" class="ltx_emph ltx_font_italic">Robotics and Autonomous Systems 75</em> (2016), 595–613.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CDLN07]</span>
<span class="ltx_bibblock">
<span id="bib.bibx4.1.1" class="ltx_text ltx_font_smallcaps">Crete F., Dolmiere T., Ladret P., Nicolas M.</span>:

</span>
<span class="ltx_bibblock">The blur effect: perception and estimation with a new no-reference
perceptual blur metric.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx4.2.1" class="ltx_emph ltx_font_italic">Human vision and electronic imaging XII</em> (2007), vol. 6492,
International Society for Optics and Photonics, p. 64920I.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[CZA<sup id="bib.bibx5.4.4.1" class="ltx_sup"><span id="bib.bibx5.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>19]</span>
<span class="ltx_bibblock">
<span id="bib.bibx5.7.1" class="ltx_text ltx_font_smallcaps">Cheng Y., Zhu H., Acar C., Jing W., Wu Y., Li L., Tan C., Lim J.-H.</span>:

</span>
<span class="ltx_bibblock">6d pose estimation with correlation fusion.

</span>
<span class="ltx_bibblock"><em id="bib.bibx5.8.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.12936</em> (2019).

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[DFI<sup id="bib.bibx6.4.4.1" class="ltx_sup"><span id="bib.bibx6.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>15]</span>
<span class="ltx_bibblock">
<span id="bib.bibx6.7.1" class="ltx_text ltx_font_smallcaps">Dosovitskiy A., Fischer P., Ilg E., Hausser P., Hazirbas C., Golkov V.,
Van Der Smagt P., Cremers D., Brox T.</span>:

</span>
<span class="ltx_bibblock">Flownet: Learning optical flow with convolutional networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx6.8.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em> (2015), pp. 2758–2766.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HHC<sup id="bib.bibx7.4.4.1" class="ltx_sup"><span id="bib.bibx7.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>11]</span>
<span class="ltx_bibblock">
<span id="bib.bibx7.7.1" class="ltx_text ltx_font_smallcaps">Hinterstoisser S., Holzer S., Cagniart C., Ilic S., Konolige K., Navab
N., Lepetit V.</span>:

</span>
<span class="ltx_bibblock">Multimodal templates for real-time detection of texture-less objects
in heavily cluttered scenes.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx7.8.1" class="ltx_emph ltx_font_italic">2011 international conference on computer vision</em> (2011),
IEEE, pp. 858–865.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HLI<sup id="bib.bibx8.4.4.1" class="ltx_sup"><span id="bib.bibx8.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>12]</span>
<span class="ltx_bibblock">
<span id="bib.bibx8.7.1" class="ltx_text ltx_font_smallcaps">Hinterstoisser S., Lepetit V., Ilic S., Holzer S., Bradski G., Konolige
K., Navab N.</span>:

</span>
<span class="ltx_bibblock">Model based training, detection and pose estimation of texture-less
3d objects in heavily cluttered scenes.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx8.8.1" class="ltx_emph ltx_font_italic">Asian conference on computer vision</em> (2012), Springer,
pp. 548–562.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HMB<sup id="bib.bibx9.4.4.1" class="ltx_sup"><span id="bib.bibx9.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>18]</span>
<span class="ltx_bibblock">
<span id="bib.bibx9.7.1" class="ltx_text ltx_font_smallcaps">Hodan T., Michel F., Brachmann E., Kehl W., GlentBuch A., Kraft D.,
Drost B., Vidal J., Ihrke S., Zabulis X., et al.</span>:

</span>
<span class="ltx_bibblock">Bop: Benchmark for 6d object pose estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx9.8.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer Vision
(ECCV)</em> (2018), pp. 19–34.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[HZRS16]</span>
<span class="ltx_bibblock">
<span id="bib.bibx10.1.1" class="ltx_text ltx_font_smallcaps">He K., Zhang X., Ren S., Sun J.</span>:

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx10.2.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em> (2016), pp. 770–778.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[JMP<sup id="bib.bibx11.4.4.1" class="ltx_sup"><span id="bib.bibx11.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>18]</span>
<span class="ltx_bibblock">
<span id="bib.bibx11.7.1" class="ltx_text ltx_font_smallcaps">Jafari O. H., Mustikovela S. K., Pertsch K., Brachmann E., Rother C.</span>:

</span>
<span class="ltx_bibblock">ipose: instance-aware 6d pose estimation of partly occluded objects.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx11.8.1" class="ltx_emph ltx_font_italic">Asian Conference on Computer Vision</em> (2018), Springer,
pp. 477–492.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KGC15]</span>
<span class="ltx_bibblock">
<span id="bib.bibx12.1.1" class="ltx_text ltx_font_smallcaps">Kendall A., Grimes M., Cipolla R.</span>:

</span>
<span class="ltx_bibblock">Posenet: A convolutional network for real-time 6-dof camera
relocalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx12.2.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em> (2015), pp. 2938–2946.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KLS14]</span>
<span class="ltx_bibblock">
<span id="bib.bibx13.1.1" class="ltx_text ltx_font_smallcaps">Kneip L., Li H., Seo Y.</span>:

</span>
<span class="ltx_bibblock">Upnp: An optimal o(n) solution to the absolute pose problem with
universal applicability.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx13.2.1" class="ltx_emph ltx_font_italic">European Conference on Computer Vision</em> (2014), Springer,
pp. 127–142.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MAMT15]</span>
<span class="ltx_bibblock">
<span id="bib.bibx14.1.1" class="ltx_text ltx_font_smallcaps">Mur-Artal R., Montiel J. M. M., Tardos J. D.</span>:

</span>
<span class="ltx_bibblock">Orb-slam: a versatile and accurate monocular slam system.

</span>
<span class="ltx_bibblock"><em id="bib.bibx14.2.1" class="ltx_emph ltx_font_italic">IEEE transactions on robotics 31</em>, 5 (2015), 1147–1163.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[MKB<sup id="bib.bibx15.4.4.1" class="ltx_sup"><span id="bib.bibx15.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>17]</span>
<span class="ltx_bibblock">
<span id="bib.bibx15.7.1" class="ltx_text ltx_font_smallcaps">Michel F., Kirillov A., Brachmann E., Krull A., Gumhold S., Savchynskyy
B., Rother C.</span>:

</span>
<span class="ltx_bibblock">Global hypothesis generation for 6d object pose estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx15.8.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em> (2017), pp. 462–471.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[NH03]</span>
<span class="ltx_bibblock">
<span id="bib.bibx16.1.1" class="ltx_text ltx_font_smallcaps">Ng P. C., Henikoff S.</span>:

</span>
<span class="ltx_bibblock">Sift: Predicting amino acid changes that affect protein function.

</span>
<span class="ltx_bibblock"><em id="bib.bibx16.2.1" class="ltx_emph ltx_font_italic">Nucleic acids research 31</em>, 13 (2003), 3812–3814.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PZC<sup id="bib.bibx17.4.4.1" class="ltx_sup"><span id="bib.bibx17.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>17]</span>
<span class="ltx_bibblock">
<span id="bib.bibx17.7.1" class="ltx_text ltx_font_smallcaps">Pavlakos G., Zhou X., Chan A., Derpanis K. G., Daniilidis K.</span>:

</span>
<span class="ltx_bibblock">6-dof object pose from semantic keypoints.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx17.8.1" class="ltx_emph ltx_font_italic">2017 IEEE international conference on robotics and
automation (ICRA)</em> (2017), IEEE, pp. 2011–2018.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[QSMG17]</span>
<span class="ltx_bibblock">
<span id="bib.bibx18.1.1" class="ltx_text ltx_font_smallcaps">Qi C. R., Su H., Mo K., Guibas L. J.</span>:

</span>
<span class="ltx_bibblock">Pointnet: Deep learning on point sets for 3d classification and
segmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx18.2.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em> (2017), pp. 652–660.

</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[SF16]</span>
<span class="ltx_bibblock">
<span id="bib.bibx19.1.1" class="ltx_text ltx_font_smallcaps">Schonberger J. L., Frahm J.-M.</span>:

</span>
<span class="ltx_bibblock">Structure-from-motion revisited.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx19.2.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em> (2016), pp. 4104–4113.

</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TSF18]</span>
<span class="ltx_bibblock">
<span id="bib.bibx20.1.1" class="ltx_text ltx_font_smallcaps">Tekin B., Sinha S. N., Fua P.</span>:

</span>
<span class="ltx_bibblock">Real-time seamless single shot 6d object pose prediction.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx20.2.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em> (2018), pp. 292–301.

</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TTS<sup id="bib.bibx21.4.4.1" class="ltx_sup"><span id="bib.bibx21.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>18]</span>
<span class="ltx_bibblock">
<span id="bib.bibx21.7.1" class="ltx_text ltx_font_smallcaps">Tremblay J., To T., Sundaralingam B., Xiang Y., Fox D., Birchfield S.</span>:

</span>
<span class="ltx_bibblock">Deep object pose estimation for semantic robotic grasping of
household objects.

</span>
<span class="ltx_bibblock"><em id="bib.bibx21.8.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1809.10790</em> (2018).

</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[UKA<sup id="bib.bibx22.4.4.1" class="ltx_sup"><span id="bib.bibx22.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>11]</span>
<span class="ltx_bibblock">
<span id="bib.bibx22.7.1" class="ltx_text ltx_font_smallcaps">Ulbrich S., Kappler D., Asfour T., Vahrenkamp N., Bierbaum A.,
Przybylski M., Dillmann R.</span>:

</span>
<span class="ltx_bibblock">The opengrasp benchmarking suite: An environment for the comparative
analysis of grasping and dexterous manipulation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx22.8.1" class="ltx_emph ltx_font_italic">2011 IEEE/RSJ International Conference on Intelligent Robots
and Systems</em> (2011), IEEE, pp. 1761–1767.

</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VCC<sup id="bib.bibx23.4.4.1" class="ltx_sup"><span id="bib.bibx23.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>17]</span>
<span class="ltx_bibblock">
<span id="bib.bibx23.7.1" class="ltx_text ltx_font_smallcaps">Veličković P., Cucurull G., Casanova A., Romero A., Lio P.,
Bengio Y.</span>:

</span>
<span class="ltx_bibblock">Graph attention networks.

</span>
<span class="ltx_bibblock"><em id="bib.bibx23.8.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.10903</em> (2017).

</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[WXZ<sup id="bib.bibx24.4.4.1" class="ltx_sup"><span id="bib.bibx24.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>19]</span>
<span class="ltx_bibblock">
<span id="bib.bibx24.7.1" class="ltx_text ltx_font_smallcaps">Wang C., Xu D., Zhu Y., Martín-Martín R., Lu C., Fei-Fei L.,
Savarese S.</span>:

</span>
<span class="ltx_bibblock">Densefusion: 6d object pose estimation by iterative dense fusion.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx24.8.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em> (2019), pp. 3343–3352.

</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XSNF17]</span>
<span class="ltx_bibblock">
<span id="bib.bibx25.1.1" class="ltx_text ltx_font_smallcaps">Xiang Y., Schmidt T., Narayanan V., Fox D.</span>:

</span>
<span class="ltx_bibblock">Posecnn: A convolutional neural network for 6d object pose estimation
in cluttered scenes.

</span>
<span class="ltx_bibblock"><em id="bib.bibx25.2.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.00199</em> (2017).

</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[YSW<sup id="bib.bibx26.4.4.1" class="ltx_sup"><span id="bib.bibx26.4.4.1.1" class="ltx_text ltx_font_italic">∗</span></sup>19]</span>
<span class="ltx_bibblock">
<span id="bib.bibx26.7.1" class="ltx_text ltx_font_smallcaps">Yifan W., Serena F., Wu S., Öztireli C., Sorkine-Hornung O.</span>:

</span>
<span class="ltx_bibblock">Differentiable surface splatting for point-based geometry processing.

</span>
<span class="ltx_bibblock"><em id="bib.bibx26.8.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics (TOG) 38</em>, 6 (2019), 1–14.

</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[ZC17]</span>
<span class="ltx_bibblock">
<span id="bib.bibx27.1.1" class="ltx_text ltx_font_smallcaps">Zhang H., Cao Q.</span>:

</span>
<span class="ltx_bibblock">Texture-less object detection and 6d pose estimation in rgb-d images.

</span>
<span class="ltx_bibblock"><em id="bib.bibx27.2.1" class="ltx_emph ltx_font_italic">Robotics and Autonomous Systems 95</em> (2017), 64–79.

</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:creator" content="{\@shortauthor}"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="{Computer Graphics Forum"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="{\pdf@Subject}"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="{\@shorttitle}"></div>

<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2010.09354" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2010.09355" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2010.09355">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2010.09355" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2010.09356" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Feb 26 22:41:15 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
