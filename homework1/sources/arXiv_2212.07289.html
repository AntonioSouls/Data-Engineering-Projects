<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.07289] ConQueR: Query Contrast Voxel-DETR for 3D Object Detection</title><meta property="og:description" content="Although DETR-based 3D detectors can simplify the detection pipeline and achieve direct sparse predictions, their performance still lags behind dense detectors with post-processing for 3D object detection from point cl…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ConQueR: Query Contrast Voxel-DETR for 3D Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ConQueR: Query Contrast Voxel-DETR for 3D Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.07289">

<!--Generated on Fri Mar  1 11:05:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">ConQueR: Query Contrast Voxel-DETR for 3D Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Benjin Zhu<sup id="id3.1.id1" class="ltx_sup">1</sup>  Zhe Wang<sup id="id4.2.id2" class="ltx_sup">1</sup>  Shaoshuai Shi<sup id="id5.3.id3" class="ltx_sup">2</sup>  Hang Xu<sup id="id6.4.id4" class="ltx_sup">3</sup>  Lanqing Hong<sup id="id7.5.id5" class="ltx_sup">3</sup>  Hongsheng Li<sup id="id8.6.id6" class="ltx_sup">1</sup> 
<br class="ltx_break"><sup id="id9.7.id7" class="ltx_sup">1</sup>Multimedia Laboratory, The Chinese University of Hong Kong 
<br class="ltx_break"><sup id="id10.8.id8" class="ltx_sup">2</sup>Max Planck Institute for Informatics 
<br class="ltx_break"><sup id="id11.9.id9" class="ltx_sup">3</sup>Huawei Noah’s Ark Lab 
<br class="ltx_break"><span id="id12.10.id10" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{benjinzhu@link,hsli@ee}.cuhk.edu.hk</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.2" class="ltx_p">Although DETR-based 3D detectors can simplify the detection pipeline and achieve <span id="id2.2.1" class="ltx_text ltx_font_bold">direct</span> sparse predictions, their performance still lags behind dense detectors with post-processing for 3D object detection from point clouds. DETRs usually adopt a larger number of queries than GTs (<em id="id2.2.2" class="ltx_emph ltx_font_italic">e.g.</em>, 300 queries v.s. <math id="id1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="id1.1.m1.1a"><mo id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><csymbol cd="latexml" id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\sim</annotation></semantics></math>40 objects in Waymo) in a scene, which inevitably incur many false positives during inference. In this paper, we propose a simple yet effective sparse 3D detector, named <span id="id2.2.3" class="ltx_text ltx_font_bold">Que</span>ry <span id="id2.2.4" class="ltx_text ltx_font_bold">Con</span>trast Voxel-DET<span id="id2.2.5" class="ltx_text ltx_font_bold">R</span> (<span id="id2.2.6" class="ltx_text ltx_font_bold">ConQueR</span>), to eliminate the challenging false positives, and achieve more accurate and sparser predictions. We observe that most false positives are highly overlapping in local regions, caused by the lack of explicit supervision to discriminate locally similar queries. We thus propose a Query Contrast mechanism to explicitly enhance queries towards their best-matched GTs over all unmatched query predictions. This is achieved by the construction of positive and negative GT-query pairs for each GT, and a contrastive loss to enhance positive GT-query pairs against negative ones based on feature similarities. ConQueR closes the gap of sparse and dense 3D detectors, and reduces up to <math id="id2.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="id2.2.m2.1a"><mo id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><csymbol cd="latexml" id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\sim</annotation></semantics></math><span id="id2.2.7" class="ltx_text ltx_font_bold">60%</span> false positives. Our single-frame ConQueR achieves new state-of-the-art (sota) 71.6 mAPH/L2 on the challenging Waymo Open Dataset validation set, outperforming previous sota methods (<em id="id2.2.8" class="ltx_emph ltx_font_italic">e.g.</em>, PV-RCNN++) by over <span id="id2.2.9" class="ltx_text ltx_font_bold">2.0</span> mAPH/L2.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">3D object detection from point clouds has received much attention in recent years <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> as its wide applications in autonomous driving, robots navigation, etc.
State-of-the-art 3D detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> still adopt dense predictions with post-processing (<em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, NMS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>) to obtain final sparse detections. This <em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">indirect</em> pipeline usually involves many hand-crafted components (e.g., anchors, center masks) based on human experience, which involves much effort for tuning, and prevents dense detectors from being optimized end-to-end to achieve optimal performance.
Recently, DETR-based 2D detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> show that transformers with <em id="S1.p1.1.3" class="ltx_emph ltx_font_italic">direct</em> sparse predictions can greatly simplify the detection pipeline, and lead to better performance.
However, although many efforts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> have been made towards <em id="S1.p1.1.4" class="ltx_emph ltx_font_italic">direct</em> sparse predictions for 3D object detection, because of the different characteristics of images and point clouds (<em id="S1.p1.1.5" class="ltx_emph ltx_font_italic">i.e.</em>, dense and ordered images <em id="S1.p1.1.6" class="ltx_emph ltx_font_italic">v.s.</em> sparse and irregular points clouds),
performance of sparse 3D object detectors still largely lags behind state-of-the-art dense detectors.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2212.07289/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="231" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.4.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.5.2" class="ltx_text" style="font-size:90%;">Comparison of our baseline Voxel-DETR and ConQueR. GTs (<span id="S1.F1.5.2.1" class="ltx_text" style="color:#00FF00;">green</span>) and predictions (<span id="S1.F1.5.2.2" class="ltx_text" style="color:#0000FF;">blue</span>) of an example scene in the WOD is visualized. Sparse predictions of Voxel-DETR still contain many highly overlapped false positives (in the red dashed circle), while ConQueR can generate much sparser predictions.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.5" class="ltx_p">To achieve direct sparse predictions, DETRs usually adopt a set of object queries <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and resort to the one-to-one Hungarian Matching <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to assign ground-truths (GTs) to object queries.
However, to guarantee a high recall rate, those detectors need to impose much more queries than the actual number of objects in a scene. For example, recent works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> select top-<math id="S1.p2.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S1.p2.1.m1.1a"><mn id="S1.p2.1.m1.1.1" xref="S1.p2.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S1.p2.1.m1.1b"><cn type="integer" id="S1.p2.1.m1.1.1.cmml" xref="S1.p2.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.1.m1.1c">300</annotation></semantics></math> scored query predictions to cover only <math id="S1.p2.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p2.2.m2.1a"><mo id="S1.p2.2.m2.1.1" xref="S1.p2.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p2.2.m2.1b"><csymbol cd="latexml" id="S1.p2.2.m2.1.1.cmml" xref="S1.p2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.2.m2.1c">\sim</annotation></semantics></math>40 objects in each scene of Waymo Open Dataset (WOD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, while 2D DETR detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> use 10<math id="S1.p2.3.m3.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S1.p2.3.m3.1a"><mo id="S1.p2.3.m3.1.1" xref="S1.p2.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.p2.3.m3.1b"><times id="S1.p2.3.m3.1.1.cmml" xref="S1.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.3.m3.1c">\times</annotation></semantics></math> more predictions than the average GT number of MS COCO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. As shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(a), we visualize an example scene by a baseline DETR-based 3D detector, named Voxel-DETR, which shows its top-<math id="S1.p2.4.m4.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S1.p2.4.m4.1a"><mn id="S1.p2.4.m4.1.1" xref="S1.p2.4.m4.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S1.p2.4.m4.1b"><cn type="integer" id="S1.p2.4.m4.1.1.cmml" xref="S1.p2.4.m4.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.4.m4.1c">300</annotation></semantics></math> scored predictions.
Objects are generally small and densely populated in autonomous driving scenes, while 3D DETRs adopt the same fixed top-<math id="S1.p2.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S1.p2.5.m5.1a"><mi id="S1.p2.5.m5.1.1" xref="S1.p2.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S1.p2.5.m5.1b"><ci id="S1.p2.5.m5.1.1.cmml" xref="S1.p2.5.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p2.5.m5.1c">N</annotation></semantics></math> scored predictions as 2D DETRs, and lack a mechanism to handle such small and dense objects. Consequently, they tend to generate densely overlapped false positives (in the red-dashed circle), harming both the accuracy and <em id="S1.p2.5.1" class="ltx_emph ltx_font_italic">sparsity</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> of final predictions.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We argue the key reason is that the Hungarian Matching in existing 3D DETRs only assigns each GT to its best matched query, while all other unmatched queries near this GT are not effectively suppressed. For each GT, the one-to-one matching loss solely forces all unmatched queries to predict the same “no-object” label, and the best matched query are supervised <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">without</em> considering its relative ranking to its surrounding unmatched queries. This design causes the detectors to be insufficiently supervised in discriminating similar query predictions for each GT, leading to duplicated false positives for scenes with densely populated objects.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To overcome the limitations of current supervision, we introduce a simple yet novel Query Contrast strategy to explicitly suppress predictions of all unmatched queries for each GT, and simultaneously enhance the best matched query to generate more accurate predictions in a contrastive manner.
The Query Contrast strategy is integrated into our baseline Voxel-DETR, which consists of a sparse 3D convolution backbone to extract features from voxel grids, and a transformer encoder-decoder architecture with a bipartite matching loss to directly generate sparse predictions.
Our Query Contrast mechanism involves the construction of positive and negative GT-query pairs, and the contrastive learning on all GT-query pairs to supervise both matched and unmatched queries with knowledge of the states of their surrounding queries. Such GT-query pairs are directly created by reusing the Hungarian Matching results: each GT and its best matched query form the positive pair, and all other unmatched queries of the same GT then form negative pairs.
To quantitively measure the similarities of the GT-query pairs, we formulate the object queries to be the same as GT boxes (<em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, using only box categories, locations, sizes and orientations), such that GTs and object queries can be processed by the same transformer decoder, and embedded into a unified feature space to properly calculate their similarities.
Given the GT-query similarities, we adopt the contrastive learning loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> to effectively enhance the positive (matched) query’s prediction for each GT, and suppress those of all its negative queries at the same time. Moreover, to further improve the contrastive supervision, we construct multiple positive GT-query pairs for each GT by adding small random noises to the original GTs, which greatly boost the training efficiency and effectiveness.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.2" class="ltx_p">The resulting sparse 3D detector, named <span id="S1.p5.2.1" class="ltx_text ltx_font_bold">Que</span>ry <span id="S1.p5.2.2" class="ltx_text ltx_font_bold">Con</span>trast Voxel-DET<span id="S1.p5.2.3" class="ltx_text ltx_font_bold">R</span> (<span id="S1.p5.2.4" class="ltx_text ltx_font_bold">ConQueR</span>), significantly improves the detection performance and sparsity of final predictions, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b). Moreover, ConQueR abandons the fixed top-<math id="S1.p5.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S1.p5.1.m1.1a"><mi id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><ci id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">N</annotation></semantics></math> prediction scheme and enables to output a vary number of predictions for different scenes. ConQueR reduces up to <math id="S1.p5.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S1.p5.2.m2.1a"><mo id="S1.p5.2.m2.1.1" xref="S1.p5.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S1.p5.2.m2.1b"><csymbol cd="latexml" id="S1.p5.2.m2.1.1.cmml" xref="S1.p5.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">\sim</annotation></semantics></math><span id="S1.p5.2.5" class="ltx_text ltx_font_bold">60%</span> false positives and sets new records on the challenging Waymo Open Dataset (WOD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Contributions are summarized as bellow:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We introduce a novel Query Contrast strategy into DETR-based 3D detectors to effectively eliminate densely overlapped false positives and achieve more accurate predictions.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We propose to construct multi-positive contrastive training, which greatly improve the effectiveness and efficiency of our Query Contrast mechanism.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Our proposed sparse 3D detector ConQueR closes the gap between sparse and dense 3D detectors, and sets new records on the challenging WOD benchmark.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">End-to-End 2D Object Detection.</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">End-to-end object detection aims to generate final sparse predictions without non-differentiable components like NMS. RelationNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposes an object relation module and DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> greatly simplifies the detection pipeline by removing many hand-crafted components like anchors, NMS, etc. DETR introduce a set of object queries and resorts to the Hungarian Matching to associate each GT with the query predictions of minimal matching cost, and selects top-<math id="S2.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">N</annotation></semantics></math> scored predictions for inference. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> also reveal that one-to-one matching is the key to achieve sparse predictions. Following works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> improves DETR in many aspects including query design, convergence speed, and performance, surpassing CNN-based dense detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> by a large margin. However, they still need to select a fixed number of predictions as final results, no matter how many objects are there in an image.
Recently, DINO-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> introduces a “contrastive” denoising training strategy. It creates positive and negative GTs conceptually, and supervise these GTs with different targets separately, which has no relation with contrastive learning.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2212.07289/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="191" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.4.2.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.2.1" class="ltx_text" style="font-size:90%;">Overall pipeline of the proposed ConQueR. It consists of a 3D Sparse ResNet-FPN backbone to extract dense BEV features, and a transformer encoder-decoder architecture with one-to-one matching. Top-<math id="S2.F2.2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.F2.2.1.m1.1b"><mi id="S2.F2.2.1.m1.1.1" xref="S2.F2.2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.F2.2.1.m1.1c"><ci id="S2.F2.2.1.m1.1.1.cmml" xref="S2.F2.2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.1.m1.1d">k</annotation></semantics></math> scored object proposals from a class-agnostic FFN form the object queries to input to the transformer decoder. During training, GTs (noised) are concatenated with object queries to input to the transformer decoder to obtain unified embeddings, which are then used for Query Contrast at each decoder layer. During inference, Top-scored predictions from the last decoder layer are kept as final sparse predictions. “VFE” denotes the voxel feature extractor in  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.
</span></figcaption>
</figure>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">3D Object Detection from Point Clouds.</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">State-of-the-art 3D detectors usually adopts voxel-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, range-view <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> or point-based <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> paradigms to convert raw point clouds into dense feature representations, followed by detection heads to generate dense predictions and resort to NMS to filter out low-quality predictions. Many attempts have also been made to incorporate transformer architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> into 3D object detection, but they still rely on post-processing. Others <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> make a step further to use the one-to-one matching loss to achieve direct sparse 3D predictions. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> proposes Box-Attention, a variant of deformable attention to better capture local informations and applies it to 3D object detection. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> introduce image features into a decoder-only architecture to enhance query features. However, their performance still largely lags behind state-of-the-art dense 3D detectors.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Contrastive Learning for Object Detection.</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Contrastive learning aims to learn an embedding space such that similar data pairs stay close while dissimilar ones are far apart.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> proposes to learn representations by contrasting positive pairs against negative ones. The popular InfoNCE loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> uses categorical cross-entropy loss to learn such an embedding space. Following works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> demonstrate the superiority of contrastive learning on providing pre-trained weights for downstream tasks (<em id="S2.SS0.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, 2D detection). Few works explore the use of contrastive loss in object detection.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> introduces semantically structured embeddings from knowledge graphs to alleviate misclassifications.  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> conducts contrastive distillation between different feature regions to better capture teacher’s information. As far as we know, we are the first to introduce the contrastive learning process into DETR-based detectors.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Query Contrast Voxel-DETR (ConQueR)</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">State-of-the-art 3D detectors usually generate dense object predictions, which require many hand-designed components (<em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, anchors, box masks) based on prior knowledge, and resort to post-processing to filter out low-quality and duplicated boxes. This <em id="S3.p1.1.2" class="ltx_emph ltx_font_italic">indirect</em> pipeline hinders the detectors from being optimized end-to-end and achieving optimal performance. 3D DETRs aim at streamlining these hand-crafted modules, and <em id="S3.p1.1.3" class="ltx_emph ltx_font_italic">directly</em> generating sparse predictions via the transformer architecture and one-to-one matching loss, but they still cannot compete with state-of-the-art dense 3D detectors and face the problem of highly overlapped false positives, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(a). To solve these challenges, we first introduce our competitive DETR-based 3D framework, named Voxel-DETR in Sec. <a href="#S3.SS1" title="3.1 Voxel-DETR ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>, and present the Query Contrast strategy to tackle with the duplicated false positives and further improve the detection performance in Sec. <a href="#S3.SS2" title="3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Voxel-DETR</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As illustrated in Fig. <a href="#S2.F2" title="Figure 2 ‣ End-to-End 2D Object Detection. ‣ 2 Related Works ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, Voxel-DETR consists of a 3D backbone, an encoder-decoder transformer architecture, and a set-matching loss to achieve direct sparse predictions.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Backbone.</span> Point cloud is rasterized into sparse voxel grids and fed into a 3D Sparse ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> backbone network to extract sparse 3D features. These features are transformed into dense Bird Eye View (BEV) feature maps, followed by an FPN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> to extract multi-scale features.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.2" class="ltx_p"><span id="S3.SS1.p3.2.1" class="ltx_text ltx_font_bold">Transformer.</span>
The encoder-decoder transformer is similar to the two-stage Deformable-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. The <math id="S3.SS1.p3.1.m1.1" class="ltx_math_unparsed" alttext="8\times" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1b"><mn id="S3.SS1.p3.1.m1.1.1">8</mn><mo lspace="0.222em" id="S3.SS1.p3.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">8\times</annotation></semantics></math> downscaled BEV features from the FPN are input to the transformer encoder, which consists of 3 encoder layers.
Considering the characteristics of 3D detection from point clouds (<em id="S3.SS1.p3.2.2" class="ltx_emph ltx_font_italic">i.e.</em>, all objects are relatively small and densely distributed),
we adopt BoxAttention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, which applies spatial in-box constraints to Deformable Attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, to perform local self-attention.
A class-agnostic feed-forward network (FFN) head is used to generate initial object proposals from encoder features. Top-<math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">k</annotation></semantics></math> scored box proposals are selected as object queries to input to the 3-layer transformer decoder. Decoder layers conduct inter-query self-attention and cross-attention between query and encoder features, followed by prediction heads to perform iterative box refinement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. Predicted query boxes from the previous decoder layer’s FFN head are transformed by a 3-layer MLP and added with the updated query features (initialized as zero) from the previous decoder layer.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Losses.</span> During training, all FFN prediction heads use the Hungarian Matching to assign GTs to object queries. The detection loss <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{det}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml"><mi id="S3.SS1.p4.1.m1.1.1.3.2" xref="S3.SS1.p4.1.m1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.1.m1.1.1.3.1" xref="S3.SS1.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p4.1.m1.1.1.3.3" xref="S3.SS1.p4.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p4.1.m1.1.1.3.1a" xref="S3.SS1.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.p4.1.m1.1.1.3.4" xref="S3.SS1.p4.1.m1.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ℒ</ci><apply id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3"><times id="S3.SS1.p4.1.m1.1.1.3.1.cmml" xref="S3.SS1.p4.1.m1.1.1.3.1"></times><ci id="S3.SS1.p4.1.m1.1.1.3.2.cmml" xref="S3.SS1.p4.1.m1.1.1.3.2">𝑑</ci><ci id="S3.SS1.p4.1.m1.1.1.3.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3.3">𝑒</ci><ci id="S3.SS1.p4.1.m1.1.1.3.4.cmml" xref="S3.SS1.p4.1.m1.1.1.3.4">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\mathcal{L}_{det}</annotation></semantics></math> consists of a focal loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> for classification, a smooth L1 loss and a 3D GIoU loss for box regression:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{\rm det}=\alpha\mathcal{L}_{\rm focal}+\beta\mathcal{L}_{\rm l1}+\gamma\mathcal{L}_{\rm GIoU}," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml">ℒ</mi><mi id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">det</mi></msub><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">​</mo><msub id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.1.1.3.2.3.2.cmml">ℒ</mi><mi id="S3.E1.m1.1.1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.1.1.3.2.3.3.cmml">focal</mi></msub></mrow><mo id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.2.cmml">β</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.3.3.1.cmml">​</mo><msub id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.3.2.cmml">ℒ</mi><mi id="S3.E1.m1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.cmml">l1</mi></msub></mrow><mo id="S3.E1.m1.1.1.1.1.3.1a" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.3.4" xref="S3.E1.m1.1.1.1.1.3.4.cmml"><mi id="S3.E1.m1.1.1.1.1.3.4.2" xref="S3.E1.m1.1.1.1.1.3.4.2.cmml">γ</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.4.1" xref="S3.E1.m1.1.1.1.1.3.4.1.cmml">​</mo><msub id="S3.E1.m1.1.1.1.1.3.4.3" xref="S3.E1.m1.1.1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.3.4.3.2" xref="S3.E1.m1.1.1.1.1.3.4.3.2.cmml">ℒ</mi><mi id="S3.E1.m1.1.1.1.1.3.4.3.3" xref="S3.E1.m1.1.1.1.1.3.4.3.3.cmml">GIoU</mi></msub></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2">ℒ</ci><ci id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3">det</ci></apply><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><plus id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><times id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1"></times><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">𝛼</ci><apply id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.2">ℒ</ci><ci id="S3.E1.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.3">focal</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2">𝛽</ci><apply id="S3.E1.m1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.2">ℒ</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3">l1</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.1.1.3.4"><times id="S3.E1.m1.1.1.1.1.3.4.1.cmml" xref="S3.E1.m1.1.1.1.1.3.4.1"></times><ci id="S3.E1.m1.1.1.1.1.3.4.2.cmml" xref="S3.E1.m1.1.1.1.1.3.4.2">𝛾</ci><apply id="S3.E1.m1.1.1.1.1.3.4.3.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.2">ℒ</ci><ci id="S3.E1.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.4.3.3">GIoU</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{L}_{\rm det}=\alpha\mathcal{L}_{\rm focal}+\beta\mathcal{L}_{\rm l1}+\gamma\mathcal{L}_{\rm GIoU},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p4.3" class="ltx_p">where <math id="S3.SS1.p4.2.m1.3" class="ltx_Math" alttext="\alpha,\beta,\gamma" display="inline"><semantics id="S3.SS1.p4.2.m1.3a"><mrow id="S3.SS1.p4.2.m1.3.4.2" xref="S3.SS1.p4.2.m1.3.4.1.cmml"><mi id="S3.SS1.p4.2.m1.1.1" xref="S3.SS1.p4.2.m1.1.1.cmml">α</mi><mo id="S3.SS1.p4.2.m1.3.4.2.1" xref="S3.SS1.p4.2.m1.3.4.1.cmml">,</mo><mi id="S3.SS1.p4.2.m1.2.2" xref="S3.SS1.p4.2.m1.2.2.cmml">β</mi><mo id="S3.SS1.p4.2.m1.3.4.2.2" xref="S3.SS1.p4.2.m1.3.4.1.cmml">,</mo><mi id="S3.SS1.p4.2.m1.3.3" xref="S3.SS1.p4.2.m1.3.3.cmml">γ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m1.3b"><list id="S3.SS1.p4.2.m1.3.4.1.cmml" xref="S3.SS1.p4.2.m1.3.4.2"><ci id="S3.SS1.p4.2.m1.1.1.cmml" xref="S3.SS1.p4.2.m1.1.1">𝛼</ci><ci id="S3.SS1.p4.2.m1.2.2.cmml" xref="S3.SS1.p4.2.m1.2.2">𝛽</ci><ci id="S3.SS1.p4.2.m1.3.3.cmml" xref="S3.SS1.p4.2.m1.3.3">𝛾</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m1.3c">\alpha,\beta,\gamma</annotation></semantics></math> are hyper-parameters to balance the loss terms.
During inference, top-<math id="S3.SS1.p4.3.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p4.3.m2.1a"><mi id="S3.SS1.p4.3.m2.1.1" xref="S3.SS1.p4.3.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m2.1b"><ci id="S3.SS1.p4.3.m2.1.1.cmml" xref="S3.SS1.p4.3.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m2.1c">N</annotation></semantics></math> scored predictions from the last decoder layer are kept as the final sparse detections.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Query Contrast</h3>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2212.07289/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="155" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.5.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.6.2" class="ltx_text" style="font-size:90%;">Illustration of Query Contrast. Given the GT (<span id="S3.F3.6.2.1" class="ltx_text" style="color:#00FF00;">green</span>), Hungarian Matching gives its best matched (<span id="S3.F3.6.2.2" class="ltx_text" style="color:#0000FF;">blue</span>) and all other unmatched (<span id="S3.F3.6.2.3" class="ltx_text" style="color:#808080;">gray</span>) object queries. Query embeddings are projected by an extra MLP to align with GT embeddings. The contrastive loss is applied to all positive and negative GT-query pairs based on their feature similarities.
</span></figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Although Voxel-DETR already achieves satisfactory performance, its top-<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">N</annotation></semantics></math> scored predictions still suffer from densely overlapped false positives (as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(a)). To tackle this problem,
we present a novel Query Contrast mechanism (depicted in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) to explicitly enhance each GT’s best matched query over unmatched ones. We first construct positive and negative GT-query pairs for each GT, which are then processed by each decoder layer to generate aligned GT and query embeddings. To promote the positive queries’ similarity towards a GT against negative ones, the contrastive loss is applied at each decoder layer.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Construction of positive/negative GT-query pairs.</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">To determine queries to be enhanced or suppressed for each GT, we first construct positive and negative GT-query pairs by reusing the Hungarian Matching results (used for Eq.(<a href="#S3.E1" title="Equation 1 ‣ 3.1 Voxel-DETR ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>)), which is naturally compatible with our Voxel-DETR framework. Given a GT, the query with the minimal matching cost forms a positive pair with the GT, all other queries and this GT then form negative GT-query pairs. These GT-query pairs help to identify the object queries that need to be further enhanced or suppressed in our Voxel-DETR. Motivated by the SwAV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> that incorporates multiple image crops to form multiple positive pairs to boost the training process, we further add small noises of different magnitudes on each GT to generate multiple noised GT copies. The multiple noised GT copies then form additional GT-query pairs with the same positive/negative query partitions as original GTs.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">In practice, if a noised copy deviates too much from its original GT, the noised GT-query pairs would harm the contrastive training process. However, finding proper noise magnitudes is rather laboursome and cannot generalise well across scenarios. We thus add an auxiliary GT de-noising loss similar to that in DN-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> to obligate the detector to recover the original GT from its noised versions, which ensures that the noised GT copies would not diverge. Note that the “noising-denoising” step alone only has marginal effects to detection performance, while our multi-positive Query Contrast based on the noised GT copies leads to superior detection performance, as shown in our ablation studies.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Contrast positive pairs against negative pairs.</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">Before applying supervisions to the positive and negative GT-query pairs, we need to quantitatively measure the similarities of these pairs.
However, simple geometric metrics (<em id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, IoU) cannot sufficiently model the similarities between GTs and queries (<em id="S3.SS2.SSS0.Px2.p1.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, category, appearance, location, size, etc.). We thus propose to embed GTs and queries into a latent space for comprehensive similarity measurement. In our Voxel-DETR, object queries are formulated as proposal boxes (<em id="S3.SS2.SSS0.Px2.p1.1.3" class="ltx_emph ltx_font_italic">i.e.</em> object category, box location, size, and orientation). Therefore, the transformer decoder can naturally be used to encode both GTs and queries into feature embeddings at a chosen layer. We simply select the output layer of the FFN prediction head after each decoder layer (as shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ End-to-End 2D Object Detection. ‣ 2 Related Works ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), followed by a shared MLP for similarity estimation.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.1" class="ltx_p">However, we observe that the distributions of GT objects and query boxes can be quite different: GTs have no overlap with each other and generally distribute following the roadmap layouts, while queries might correspond to densely overlapped boxes and show up at random locations. As the transformer decoder utilizes self-attention to capture inter-box relations, the different distributions of GTs and query boxes would greatly affect estimation of their similarities. To mitigate the distribution gap, we adopt an extra MLP to project query features to align with GTs’ latent space (the “Projector” in Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). With the aligned GT and query embeddings, we estimate all positive and negative GT-query pairs’ similarities with cosine similarity metric, and adopt the InfoNCE loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> to encourage the best matched query to generate more accurate predictions towards its assigned GT, and force all other unmatched queries to deviate away. Moreover, to obtain more stable GT representations for supervising queries, we adopt an exponential moving average (EMA) copy for each decoder layer to embed GTs, which is shown to be effective in our ablations.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p3.9" class="ltx_p">Assume that for the <math id="S3.SS2.SSS0.Px2.p3.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p3.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.1.m1.1c">i</annotation></semantics></math>-th GT in a point cloud scene, we add <math id="S3.SS2.SSS0.Px2.p3.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.2.m2.1a"><mi id="S3.SS2.SSS0.Px2.p3.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.2.m2.1b"><ci id="S3.SS2.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.2.m2.1c">T</annotation></semantics></math> different noises and denote the noised GT embeddings as <math id="S3.SS2.SSS0.Px2.p3.3.m3.4" class="ltx_Math" alttext="\{b^{1}_{i},b^{2}_{i},...,b^{T}_{i}\}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.3.m3.4a"><mrow id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.4" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml">{</mo><msubsup id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.2" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.3.cmml">i</mi><mn id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.3.cmml">1</mn></msubsup><mo id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.5" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml">,</mo><msubsup id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.cmml"><mi id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.2" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.3.cmml">i</mi><mn id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.6" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.SSS0.Px2.p3.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p3.3.m3.1.1.cmml">…</mi><mo id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.7" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml">,</mo><msubsup id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.cmml"><mi id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.2" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.2.cmml">b</mi><mi id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.3.cmml">i</mi><mi id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.3" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.8" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.3.m3.4b"><set id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.4.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3"><apply id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1">subscript</csymbol><apply id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.2">𝑏</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.2.3">1</cn></apply><ci id="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.2.2.1.1.3">𝑖</ci></apply><apply id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2">subscript</csymbol><apply id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.2">𝑏</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.3.3.2.2.3">𝑖</ci></apply><ci id="S3.SS2.SSS0.Px2.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.1.1">…</ci><apply id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3">subscript</csymbol><apply id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.2">𝑏</ci><ci id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.2.3">𝑇</ci></apply><ci id="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.3.m3.4.4.3.3.3">𝑖</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.3.m3.4c">\{b^{1}_{i},b^{2}_{i},...,b^{T}_{i}\}</annotation></semantics></math>, and denote <math id="S3.SS2.SSS0.Px2.p3.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.4.m4.1a"><mi id="S3.SS2.SSS0.Px2.p3.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p3.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.4.m4.1b"><ci id="S3.SS2.SSS0.Px2.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.4.m4.1c">K</annotation></semantics></math> query embeddings as <math id="S3.SS2.SSS0.Px2.p3.5.m5.4" class="ltx_Math" alttext="\{q_{1},q_{2},...,q_{K}\}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.5.m5.4a"><mrow id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.4" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml">{</mo><msub id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.cmml"><mi id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.2" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.2.cmml">q</mi><mn id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.3" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.5" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml">,</mo><msub id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.cmml"><mi id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.2" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.2.cmml">q</mi><mn id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.3" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.6" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.SSS0.Px2.p3.5.m5.1.1" xref="S3.SS2.SSS0.Px2.p3.5.m5.1.1.cmml">…</mi><mo id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.7" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml">,</mo><msub id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.cmml"><mi id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.2" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.2.cmml">q</mi><mi id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.3" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.3.cmml">K</mi></msub><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.8" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.5.m5.4b"><set id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.4.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3"><apply id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.2">𝑞</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.2.2.1.1.3">1</cn></apply><apply id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.2">𝑞</ci><cn type="integer" id="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.3.3.2.2.3">2</cn></apply><ci id="S3.SS2.SSS0.Px2.p3.5.m5.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.1.1">…</ci><apply id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.2.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.2">𝑞</ci><ci id="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.3.cmml" xref="S3.SS2.SSS0.Px2.p3.5.m5.4.4.3.3.3">𝐾</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.5.m5.4c">\{q_{1},q_{2},...,q_{K}\}</annotation></semantics></math>. Suppose that the Hungarian Matching assigns the <math id="S3.SS2.SSS0.Px2.p3.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.6.m6.1a"><mi id="S3.SS2.SSS0.Px2.p3.6.m6.1.1" xref="S3.SS2.SSS0.Px2.p3.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.6.m6.1b"><ci id="S3.SS2.SSS0.Px2.p3.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.6.m6.1c">i</annotation></semantics></math>-th GT to the <math id="S3.SS2.SSS0.Px2.p3.7.m7.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.7.m7.1a"><mi id="S3.SS2.SSS0.Px2.p3.7.m7.1.1" xref="S3.SS2.SSS0.Px2.p3.7.m7.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.7.m7.1b"><ci id="S3.SS2.SSS0.Px2.p3.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.7.m7.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.7.m7.1c">j</annotation></semantics></math>-th query, then our Query Contrast loss for the <math id="S3.SS2.SSS0.Px2.p3.8.m8.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.8.m8.1a"><mi id="S3.SS2.SSS0.Px2.p3.8.m8.1.1" xref="S3.SS2.SSS0.Px2.p3.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.8.m8.1b"><ci id="S3.SS2.SSS0.Px2.p3.8.m8.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.8.m8.1c">i</annotation></semantics></math>-th GT <math id="S3.SS2.SSS0.Px2.p3.9.m9.1" class="ltx_Math" alttext="\mathcal{L}^{\rm QC}_{i}" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.9.m9.1a"><msubsup id="S3.SS2.SSS0.Px2.p3.9.m9.1.1" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.2" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.2.cmml">ℒ</mi><mi id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.3" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.3.cmml">i</mi><mi id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.3" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.3.cmml">QC</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.9.m9.1b"><apply id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1">subscript</csymbol><apply id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.2">ℒ</ci><ci id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.3.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.2.3">QC</ci></apply><ci id="S3.SS2.SSS0.Px2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p3.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.9.m9.1c">\mathcal{L}^{\rm QC}_{i}</annotation></semantics></math> can be formulated as</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.8" class="ltx_Math" alttext="\mathcal{L}^{\rm QC}_{i}=-\sum_{t=1}^{T}\log\left(\frac{\exp(\cos(b^{t}_{i},g(q_{j}))/\tau)}{\sum_{k=1}^{K}\exp(\cos(b^{t}_{i},g(q_{k}))/\tau)}\right)," display="block"><semantics id="S3.E2.m1.8a"><mrow id="S3.E2.m1.8.8.1" xref="S3.E2.m1.8.8.1.1.cmml"><mrow id="S3.E2.m1.8.8.1.1" xref="S3.E2.m1.8.8.1.1.cmml"><msubsup id="S3.E2.m1.8.8.1.1.2" xref="S3.E2.m1.8.8.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.8.8.1.1.2.2.2" xref="S3.E2.m1.8.8.1.1.2.2.2.cmml">ℒ</mi><mi id="S3.E2.m1.8.8.1.1.2.3" xref="S3.E2.m1.8.8.1.1.2.3.cmml">i</mi><mi id="S3.E2.m1.8.8.1.1.2.2.3" xref="S3.E2.m1.8.8.1.1.2.2.3.cmml">QC</mi></msubsup><mo id="S3.E2.m1.8.8.1.1.1" xref="S3.E2.m1.8.8.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.8.8.1.1.3" xref="S3.E2.m1.8.8.1.1.3.cmml"><mo id="S3.E2.m1.8.8.1.1.3a" xref="S3.E2.m1.8.8.1.1.3.cmml">−</mo><mrow id="S3.E2.m1.8.8.1.1.3.2" xref="S3.E2.m1.8.8.1.1.3.2.cmml"><munderover id="S3.E2.m1.8.8.1.1.3.2.1" xref="S3.E2.m1.8.8.1.1.3.2.1.cmml"><mo movablelimits="false" id="S3.E2.m1.8.8.1.1.3.2.1.2.2" xref="S3.E2.m1.8.8.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S3.E2.m1.8.8.1.1.3.2.1.2.3" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.cmml"><mi id="S3.E2.m1.8.8.1.1.3.2.1.2.3.2" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.2.cmml">t</mi><mo id="S3.E2.m1.8.8.1.1.3.2.1.2.3.1" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E2.m1.8.8.1.1.3.2.1.2.3.3" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.8.8.1.1.3.2.1.3" xref="S3.E2.m1.8.8.1.1.3.2.1.3.cmml">T</mi></munderover><mrow id="S3.E2.m1.8.8.1.1.3.2.2.2" xref="S3.E2.m1.8.8.1.1.3.2.2.1.cmml"><mi id="S3.E2.m1.7.7" xref="S3.E2.m1.7.7.cmml">log</mi><mo id="S3.E2.m1.8.8.1.1.3.2.2.2a" xref="S3.E2.m1.8.8.1.1.3.2.2.1.cmml">⁡</mo><mrow id="S3.E2.m1.8.8.1.1.3.2.2.2.1" xref="S3.E2.m1.8.8.1.1.3.2.2.1.cmml"><mo id="S3.E2.m1.8.8.1.1.3.2.2.2.1.1" xref="S3.E2.m1.8.8.1.1.3.2.2.1.cmml">(</mo><mfrac id="S3.E2.m1.6.6" xref="S3.E2.m1.6.6.cmml"><mrow id="S3.E2.m1.3.3.3.3" xref="S3.E2.m1.3.3.3.4.cmml"><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">exp</mi><mo id="S3.E2.m1.3.3.3.3a" xref="S3.E2.m1.3.3.3.4.cmml">⁡</mo><mrow id="S3.E2.m1.3.3.3.3.1" xref="S3.E2.m1.3.3.3.4.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.3.3.1.2" xref="S3.E2.m1.3.3.3.4.cmml">(</mo><mrow id="S3.E2.m1.3.3.3.3.1.1" xref="S3.E2.m1.3.3.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.3.3.1.1.2.2" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">cos</mi><mo id="S3.E2.m1.3.3.3.3.1.1.2.2a" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml">⁡</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.2.2.2" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.3.3.1.1.2.2.2.3" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml">(</mo><msubsup id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.2.cmml">b</mi><mi id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.3.cmml">i</mi><mi id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.E2.m1.3.3.3.3.1.1.2.2.2.4" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml">,</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.3" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.2" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.2.cmml">​</mo><mrow id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.2" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.2" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.2.cmml">q</mi><mi id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.3" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.3" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.3.3.3.3.1.1.2.2.2.5" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.3.3.1.1.3" xref="S3.E2.m1.3.3.3.3.1.1.3.cmml">/</mo><mi id="S3.E2.m1.3.3.3.3.1.1.4" xref="S3.E2.m1.3.3.3.3.1.1.4.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E2.m1.3.3.3.3.1.3" xref="S3.E2.m1.3.3.3.4.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.6.6.6" xref="S3.E2.m1.6.6.6.cmml"><msubsup id="S3.E2.m1.6.6.6.4" xref="S3.E2.m1.6.6.6.4.cmml"><mo id="S3.E2.m1.6.6.6.4.2.2" xref="S3.E2.m1.6.6.6.4.2.2.cmml">∑</mo><mrow id="S3.E2.m1.6.6.6.4.2.3" xref="S3.E2.m1.6.6.6.4.2.3.cmml"><mi id="S3.E2.m1.6.6.6.4.2.3.2" xref="S3.E2.m1.6.6.6.4.2.3.2.cmml">k</mi><mo id="S3.E2.m1.6.6.6.4.2.3.1" xref="S3.E2.m1.6.6.6.4.2.3.1.cmml">=</mo><mn id="S3.E2.m1.6.6.6.4.2.3.3" xref="S3.E2.m1.6.6.6.4.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.6.6.6.4.3" xref="S3.E2.m1.6.6.6.4.3.cmml">K</mi></msubsup><mrow id="S3.E2.m1.6.6.6.3.1" xref="S3.E2.m1.6.6.6.3.2.cmml"><mi id="S3.E2.m1.5.5.5.2" xref="S3.E2.m1.5.5.5.2.cmml">exp</mi><mo id="S3.E2.m1.6.6.6.3.1a" xref="S3.E2.m1.6.6.6.3.2.cmml">⁡</mo><mrow id="S3.E2.m1.6.6.6.3.1.1" xref="S3.E2.m1.6.6.6.3.2.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.6.3.1.1.2" xref="S3.E2.m1.6.6.6.3.2.cmml">(</mo><mrow id="S3.E2.m1.6.6.6.3.1.1.1" xref="S3.E2.m1.6.6.6.3.1.1.1.cmml"><mrow id="S3.E2.m1.6.6.6.3.1.1.1.2.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml"><mi id="S3.E2.m1.4.4.4.1" xref="S3.E2.m1.4.4.4.1.cmml">cos</mi><mo id="S3.E2.m1.6.6.6.3.1.1.1.2.2a" xref="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml">⁡</mo><mrow id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.3" xref="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml">(</mo><msubsup id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.2.cmml">b</mi><mi id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.3" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.3.cmml">i</mi><mi id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.4" xref="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml">,</mo><mrow id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.3" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.2.cmml">​</mo><mrow id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.cmml">(</mo><msub id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.2.cmml">q</mi><mi id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.3" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.3" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.5" xref="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.6.6.6.3.1.1.1.3" xref="S3.E2.m1.6.6.6.3.1.1.1.3.cmml">/</mo><mi id="S3.E2.m1.6.6.6.3.1.1.1.4" xref="S3.E2.m1.6.6.6.3.1.1.1.4.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E2.m1.6.6.6.3.1.1.3" xref="S3.E2.m1.6.6.6.3.2.cmml">)</mo></mrow></mrow></mrow></mfrac><mo id="S3.E2.m1.8.8.1.1.3.2.2.2.1.2" xref="S3.E2.m1.8.8.1.1.3.2.2.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.8.8.1.2" xref="S3.E2.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.8b"><apply id="S3.E2.m1.8.8.1.1.cmml" xref="S3.E2.m1.8.8.1"><eq id="S3.E2.m1.8.8.1.1.1.cmml" xref="S3.E2.m1.8.8.1.1.1"></eq><apply id="S3.E2.m1.8.8.1.1.2.cmml" xref="S3.E2.m1.8.8.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.1.1.2.1.cmml" xref="S3.E2.m1.8.8.1.1.2">subscript</csymbol><apply id="S3.E2.m1.8.8.1.1.2.2.cmml" xref="S3.E2.m1.8.8.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.1.1.2.2.1.cmml" xref="S3.E2.m1.8.8.1.1.2">superscript</csymbol><ci id="S3.E2.m1.8.8.1.1.2.2.2.cmml" xref="S3.E2.m1.8.8.1.1.2.2.2">ℒ</ci><ci id="S3.E2.m1.8.8.1.1.2.2.3.cmml" xref="S3.E2.m1.8.8.1.1.2.2.3">QC</ci></apply><ci id="S3.E2.m1.8.8.1.1.2.3.cmml" xref="S3.E2.m1.8.8.1.1.2.3">𝑖</ci></apply><apply id="S3.E2.m1.8.8.1.1.3.cmml" xref="S3.E2.m1.8.8.1.1.3"><minus id="S3.E2.m1.8.8.1.1.3.1.cmml" xref="S3.E2.m1.8.8.1.1.3"></minus><apply id="S3.E2.m1.8.8.1.1.3.2.cmml" xref="S3.E2.m1.8.8.1.1.3.2"><apply id="S3.E2.m1.8.8.1.1.3.2.1.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.1.1.3.2.1.1.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1">superscript</csymbol><apply id="S3.E2.m1.8.8.1.1.3.2.1.2.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E2.m1.8.8.1.1.3.2.1.2.1.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1">subscript</csymbol><sum id="S3.E2.m1.8.8.1.1.3.2.1.2.2.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1.2.2"></sum><apply id="S3.E2.m1.8.8.1.1.3.2.1.2.3.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3"><eq id="S3.E2.m1.8.8.1.1.3.2.1.2.3.1.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.1"></eq><ci id="S3.E2.m1.8.8.1.1.3.2.1.2.3.2.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.2">𝑡</ci><cn type="integer" id="S3.E2.m1.8.8.1.1.3.2.1.2.3.3.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.8.8.1.1.3.2.1.3.cmml" xref="S3.E2.m1.8.8.1.1.3.2.1.3">𝑇</ci></apply><apply id="S3.E2.m1.8.8.1.1.3.2.2.1.cmml" xref="S3.E2.m1.8.8.1.1.3.2.2.2"><log id="S3.E2.m1.7.7.cmml" xref="S3.E2.m1.7.7"></log><apply id="S3.E2.m1.6.6.cmml" xref="S3.E2.m1.6.6"><divide id="S3.E2.m1.6.6.7.cmml" xref="S3.E2.m1.6.6"></divide><apply id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.3"><exp id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"></exp><apply id="S3.E2.m1.3.3.3.3.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1"><divide id="S3.E2.m1.3.3.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.3"></divide><apply id="S3.E2.m1.3.3.3.3.1.1.2.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2"><cos id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"></cos><apply id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.2">𝑏</ci><ci id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2"><times id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.2"></times><ci id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.3">𝑔</ci><apply id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.2">𝑞</ci><ci id="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2.2.2.1.1.1.3">𝑗</ci></apply></apply></apply><ci id="S3.E2.m1.3.3.3.3.1.1.4.cmml" xref="S3.E2.m1.3.3.3.3.1.1.4">𝜏</ci></apply></apply><apply id="S3.E2.m1.6.6.6.cmml" xref="S3.E2.m1.6.6.6"><apply id="S3.E2.m1.6.6.6.4.cmml" xref="S3.E2.m1.6.6.6.4"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.4.1.cmml" xref="S3.E2.m1.6.6.6.4">superscript</csymbol><apply id="S3.E2.m1.6.6.6.4.2.cmml" xref="S3.E2.m1.6.6.6.4"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.4.2.1.cmml" xref="S3.E2.m1.6.6.6.4">subscript</csymbol><sum id="S3.E2.m1.6.6.6.4.2.2.cmml" xref="S3.E2.m1.6.6.6.4.2.2"></sum><apply id="S3.E2.m1.6.6.6.4.2.3.cmml" xref="S3.E2.m1.6.6.6.4.2.3"><eq id="S3.E2.m1.6.6.6.4.2.3.1.cmml" xref="S3.E2.m1.6.6.6.4.2.3.1"></eq><ci id="S3.E2.m1.6.6.6.4.2.3.2.cmml" xref="S3.E2.m1.6.6.6.4.2.3.2">𝑘</ci><cn type="integer" id="S3.E2.m1.6.6.6.4.2.3.3.cmml" xref="S3.E2.m1.6.6.6.4.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.6.6.6.4.3.cmml" xref="S3.E2.m1.6.6.6.4.3">𝐾</ci></apply><apply id="S3.E2.m1.6.6.6.3.2.cmml" xref="S3.E2.m1.6.6.6.3.1"><exp id="S3.E2.m1.5.5.5.2.cmml" xref="S3.E2.m1.5.5.5.2"></exp><apply id="S3.E2.m1.6.6.6.3.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1"><divide id="S3.E2.m1.6.6.6.3.1.1.1.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.3"></divide><apply id="S3.E2.m1.6.6.6.3.1.1.1.2.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2"><cos id="S3.E2.m1.4.4.4.1.cmml" xref="S3.E2.m1.4.4.4.1"></cos><apply id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.2">𝑏</ci><ci id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2"><times id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.2"></times><ci id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.3">𝑔</ci><apply id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.2">𝑞</ci><ci id="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2.2.2.2.1.1.1.3">𝑘</ci></apply></apply></apply><ci id="S3.E2.m1.6.6.6.3.1.1.1.4.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.4">𝜏</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.8c">\mathcal{L}^{\rm QC}_{i}=-\sum_{t=1}^{T}\log\left(\frac{\exp(\cos(b^{t}_{i},g(q_{j}))/\tau)}{\sum_{k=1}^{K}\exp(\cos(b^{t}_{i},g(q_{k}))/\tau)}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS0.Px2.p3.11" class="ltx_p">where <math id="S3.SS2.SSS0.Px2.p3.10.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.10.m1.1a"><mi id="S3.SS2.SSS0.Px2.p3.10.m1.1.1" xref="S3.SS2.SSS0.Px2.p3.10.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.10.m1.1b"><ci id="S3.SS2.SSS0.Px2.p3.10.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.10.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.10.m1.1c">\tau</annotation></semantics></math> is the temperature coefficient, and <math id="S3.SS2.SSS0.Px2.p3.11.m2.1" class="ltx_Math" alttext="g(\cdot)" display="inline"><semantics id="S3.SS2.SSS0.Px2.p3.11.m2.1a"><mrow id="S3.SS2.SSS0.Px2.p3.11.m2.1.2" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.2" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.1" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.1.cmml">​</mo><mrow id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.3.2" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.3.2.1" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px2.p3.11.m2.1.1" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.3.2.2" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p3.11.m2.1b"><apply id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.cmml" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2"><times id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.1"></times><ci id="S3.SS2.SSS0.Px2.p3.11.m2.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.2.2">𝑔</ci><ci id="S3.SS2.SSS0.Px2.p3.11.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p3.11.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p3.11.m2.1c">g(\cdot)</annotation></semantics></math> denotes the extra MLP projector to align query features to GTs’.
As shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ End-to-End 2D Object Detection. ‣ 2 Related Works ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the Query Contrast loss is adopted at every decoder layer.</p>
</div>
<div id="S3.SS2.SSS0.Px2.p4" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p4.2" class="ltx_p">During inference, we abandon the widely adopted top-<math id="S3.SS2.SSS0.Px2.p4.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.SSS0.Px2.p4.1.m1.1a"><mi id="S3.SS2.SSS0.Px2.p4.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p4.1.m1.1b"><ci id="S3.SS2.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p4.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p4.1.m1.1c">N</annotation></semantics></math> scored prediction strategy and use a score threshold (<em id="S3.SS2.SSS0.Px2.p4.2.1" class="ltx_emph ltx_font_italic">e.g.</em>, 0.1) to filter out low-quality query predictions. Query Contrast works quite well on suppressing similar query predictions in local neighborhoods, as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b). ConQueR greatly boosts the detection accuracy, and reduces up to <math id="S3.SS2.SSS0.Px2.p4.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS2.SSS0.Px2.p4.2.m2.1a"><mo id="S3.SS2.SSS0.Px2.p4.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p4.2.m2.1b"><csymbol cd="latexml" id="S3.SS2.SSS0.Px2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p4.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p4.2.m2.1c">\sim</annotation></semantics></math><span id="S3.SS2.SSS0.Px2.p4.2.2" class="ltx_text ltx_font_bold">60%</span> false positives.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Discussion: Why does Query Contrast improve DETR-based 3D detectors?</h4>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">As discussed in Sec. <a href="#S1" title="1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, current detection losses (<em id="S3.SS2.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, focal loss for classification, smooth L1 and GIoU loss for regression) supervise each query without considering its surrounding queries, which lack supervision to train detectors to discriminate similar object queries especially in local regions. The proposed Query Contrast strategy tackles this issue by constructing a contrastive objective to supervise <em id="S3.SS2.SSS0.Px3.p1.1.2" class="ltx_emph ltx_font_italic">all</em> queries simultaneously. As suggested in Eq.(<a href="#S3.E2" title="Equation 2 ‣ Contrast positive pairs against negative pairs. ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), for each GT object, the detector is instructed to identify the best matched query, and is forced to learn to differentiate it from all other unmatched counterparts, even if some of them are highly overlapping with the best matched query. As a result, all unmatched queries are trained to deviate from the GT, thus the duplicated false positives in our baseline Voxel-DETR can be effectively suppressed.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p2.1" class="ltx_p">Another core design of our Query Contrast is to encode the GTs and queries into a unified learnable latent space. GT objects are encoded to provide better forms of supervision for both matched and unmatched queries. Previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> in 2D object detection also show that encoding labels into feature embeddings to serve as extra supervision can perform better than the common hand-designed learning targets (<em id="S3.SS2.SSS0.Px3.p2.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, classification logits and regression offsets), but they generally work in a knowledge distillation (KD) manner, which cannot be utilized to supervise negative queries. In contrast, our contrastive loss does not force matched queries to approach GTs directly, but encourages them to be “closer” to their corresponding GT embeddings than other close-by duplicated queries. Note that in our Query Contrast mechanism, GT embeddings are processed in an off-line manner and encoded into a unified space as queries’, which serve as a type of supervision and force the detector to generate more similar query features as GTs’.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p3" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p3.1" class="ltx_p">According to our experiments, the proposed Query Contrast strategy can not only suppress those duplicated false positives, but also contribute to better detection performance, which are consistent with the above discussions.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">ConQueR is mainly evaluated on the Waymo Open Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> (WOD) benchmark using the official detection metrics: mAP and mAPH (mAP weighted by heading) for Vehicle (Veh.), Pedestrian (Ped.), and Cyclist (Cyc.). The metrics are further splitted into two difficulty levels according to the point numbers in GT boxes: LEVEL_1 (<math id="S4.p1.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.p1.1.m1.1a"><mo id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><gt id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">&gt;</annotation></semantics></math>5) and LEVEL_2 (<math id="S4.p1.2.m2.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S4.p1.2.m2.1a"><mo id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><geq id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">\geq</annotation></semantics></math>1). We conduct ablation studies on the <span id="S4.p1.2.1" class="ltx_text ltx_font_italic">validation</span> set, and compare with state-of-the-art detectors on both <span id="S4.p1.2.2" class="ltx_text ltx_font_italic">validation</span> and <span id="S4.p1.2.3" class="ltx_text ltx_font_italic">test</span> set.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_t" rowspan="2"><span id="S4.T1.1.2.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<th id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T1.1.2.1.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">
<span id="S4.T1.1.2.1.2.1.1" class="ltx_inline-block">
<span id="S4.T1.1.2.1.2.1.1.1" class="ltx_p">mAP/mAPH</span>
<span id="S4.T1.1.2.1.2.1.1.2" class="ltx_p">L2</span>
</span></span></th>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" colspan="2">
<em id="S4.T1.1.2.1.3.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">Vehicle</em><span id="S4.T1.1.2.1.3.2" class="ltx_text" style="font-size:80%;"> 3D AP/APH</span>
</td>
<td id="S4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" colspan="2">
<em id="S4.T1.1.2.1.4.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">Pedestrian</em><span id="S4.T1.1.2.1.4.2" class="ltx_text" style="font-size:80%;"> 3D AP/APH</span>
</td>
<td id="S4.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" colspan="2">
<em id="S4.T1.1.2.1.5.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">Cyclist</em><span id="S4.T1.1.2.1.5.2" class="ltx_text" style="font-size:80%;"> 3D AP/APH</span>
</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.3.2.1.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">L2</span></th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.2.2.1" class="ltx_text" style="font-size:80%;">L2</span></td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.2.3.1" class="ltx_text" style="font-size:80%;">L1</span></td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.2.4.1" class="ltx_text" style="font-size:80%;">L2</span></td>
<td id="S4.T1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.2.5.1" class="ltx_text" style="font-size:80%;">L1</span></td>
<td id="S4.T1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.2.6.1" class="ltx_text" style="font-size:80%;">L2</span></td>
<td id="S4.T1.1.3.2.7" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.7.1" class="ltx_text" style="font-size:80%;">L1</span></td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="8"><span id="S4.T1.1.4.3.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Dense Detectors</span></th>
</tr>
<tr id="S4.T1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.1.1.1" class="ltx_text" style="font-size:80%;">CenterPoint</span><sub id="S4.T1.1.1.1.2" class="ltx_sub"><span id="S4.T1.1.1.1.2.1" class="ltx_text" style="font-size:80%;">ts</span></sub><span id="S4.T1.1.1.1.3" class="ltx_text" style="font-size:80%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.1.1.4.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib47" title="" class="ltx_ref">47</a><span id="S4.T1.1.1.1.5.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.1.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">-/67.4</span></th>
<td id="S4.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.1.3.1" class="ltx_text" style="font-size:80%;">-/67.9</span></td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.1.4.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.1.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.1.5.1" class="ltx_text" style="font-size:80%;">-/65.6</span></td>
<td id="S4.T1.1.1.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.1.6.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.1.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.1.7.1" class="ltx_text" style="font-size:80%;">-/68.6-/-</span></td>
<td id="S4.T1.1.1.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.1.8.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
</tr>
<tr id="S4.T1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.5.4.1.1" class="ltx_text" style="font-size:80%;">PV-RCNN </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.5.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib32" title="" class="ltx_ref">32</a><span id="S4.T1.1.5.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.5.4.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">66.8/63.3</span></th>
<td id="S4.T1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.5.4.3.1" class="ltx_text" style="font-size:80%;">69.0/68.4</span></td>
<td id="S4.T1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.5.4.4.1" class="ltx_text" style="font-size:80%;">77.5/76.9</span></td>
<td id="S4.T1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.5.4.5.1" class="ltx_text" style="font-size:80%;">66.0/57.6</span></td>
<td id="S4.T1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.5.4.6.1" class="ltx_text" style="font-size:80%;">75.0/65.6</span></td>
<td id="S4.T1.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.5.4.7.1" class="ltx_text" style="font-size:80%;">65.4/64.0</span></td>
<td id="S4.T1.1.5.4.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.5.4.8.1" class="ltx_text" style="font-size:80%;">67.8/66.4</span></td>
</tr>
<tr id="S4.T1.1.6.5" class="ltx_tr">
<th id="S4.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.6.5.1.1" class="ltx_text" style="font-size:80%;">AFDetV2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.6.5.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S4.T1.1.6.5.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.6.5.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">71.0/68.8</span></th>
<td id="S4.T1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.6.5.3.1" class="ltx_text" style="font-size:80%;">69.7/69.2</span></td>
<td id="S4.T1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.6.5.4.1" class="ltx_text" style="font-size:80%;">77.6/77.1</span></td>
<td id="S4.T1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.6.5.5.1" class="ltx_text" style="font-size:80%;">72.2/67.0</span></td>
<td id="S4.T1.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.6.5.6.1" class="ltx_text" style="font-size:80%;">80.2/74.6</span></td>
<td id="S4.T1.1.6.5.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.6.5.7.1" class="ltx_text" style="font-size:80%;">71.0/70.1</span></td>
<td id="S4.T1.1.6.5.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.6.5.8.1" class="ltx_text" style="font-size:80%;">73.7/72.7</span></td>
</tr>
<tr id="S4.T1.1.7.6" class="ltx_tr">
<th id="S4.T1.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.7.6.1.1" class="ltx_text" style="font-size:80%;">SST_TS </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.7.6.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S4.T1.1.7.6.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.7.6.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">-/-</span></th>
<td id="S4.T1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.7.6.3.1" class="ltx_text" style="font-size:80%;">68.0/67.6</span></td>
<td id="S4.T1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.7.6.4.1" class="ltx_text" style="font-size:80%;">76.2/75.8</span></td>
<td id="S4.T1.1.7.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.7.6.5.1" class="ltx_text" style="font-size:80%;">72.8/65.9</span></td>
<td id="S4.T1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.7.6.6.1" class="ltx_text" style="font-size:80%;">81.4/74.1</span></td>
<td id="S4.T1.1.7.6.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.7.6.7.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.7.6.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.7.6.8.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
</tr>
<tr id="S4.T1.1.8.7" class="ltx_tr">
<th id="S4.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.8.7.1.1" class="ltx_text" style="font-size:80%;">SWFormer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.8.7.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib37" title="" class="ltx_ref">37</a><span id="S4.T1.1.8.7.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.8.7.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">-/-</span></th>
<td id="S4.T1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.7.3.1" class="ltx_text" style="font-size:80%;">69.2/68.8</span></td>
<td id="S4.T1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.7.4.1" class="ltx_text" style="font-size:80%;">77.8/77.3</span></td>
<td id="S4.T1.1.8.7.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.7.5.1" class="ltx_text" style="font-size:80%;">72.5/64.9</span></td>
<td id="S4.T1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.7.6.1" class="ltx_text" style="font-size:80%;">80.9/72.7</span></td>
<td id="S4.T1.1.8.7.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.8.7.7.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.8.7.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.8.7.8.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
</tr>
<tr id="S4.T1.1.9.8" class="ltx_tr">
<th id="S4.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.9.8.1.1" class="ltx_text" style="font-size:80%;">PillarNet-34 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.9.8.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S4.T1.1.9.8.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.9.8.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">71.0/68.5</span></th>
<td id="S4.T1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.9.8.3.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">70.9</span><span id="S4.T1.1.9.8.3.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.9.8.3.3" class="ltx_text ltx_font_bold" style="font-size:80%;">70.5</span>
</td>
<td id="S4.T1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.9.8.4.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">79.1</span><span id="S4.T1.1.9.8.4.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.9.8.4.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">78.6</span>
</td>
<td id="S4.T1.1.9.8.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.9.8.5.1" class="ltx_text" style="font-size:80%;">72.3/66.2</span></td>
<td id="S4.T1.1.9.8.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.9.8.6.1" class="ltx_text" style="font-size:80%;">80.6/74.0</span></td>
<td id="S4.T1.1.9.8.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.9.8.7.1" class="ltx_text" style="font-size:80%;">69.7/68.7</span></td>
<td id="S4.T1.1.9.8.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.9.8.8.1" class="ltx_text" style="font-size:80%;">72.3/71.2</span></td>
</tr>
<tr id="S4.T1.1.10.9" class="ltx_tr">
<th id="S4.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.10.9.1.1" class="ltx_text" style="font-size:80%;">CenterFormer</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.10.9.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib53" title="" class="ltx_ref">53</a><span id="S4.T1.1.10.9.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.10.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.10.9.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">71.2/69.0</span></th>
<td id="S4.T1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.10.9.3.1" class="ltx_text" style="font-size:80%;">70.2/69.7</span></td>
<td id="S4.T1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.10.9.4.1" class="ltx_text" style="font-size:80%;">75.2/74.7</span></td>
<td id="S4.T1.1.10.9.5" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.10.9.5.1" class="ltx_text" style="font-size:80%;">73.6/</span><span id="S4.T1.1.10.9.5.2" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">68.3</span>
</td>
<td id="S4.T1.1.10.9.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.10.9.6.1" class="ltx_text" style="font-size:80%;">78.6/73.0</span></td>
<td id="S4.T1.1.10.9.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.10.9.7.1" class="ltx_text" style="font-size:80%;">69.8/68.8</span></td>
<td id="S4.T1.1.10.9.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.10.9.8.1" class="ltx_text" style="font-size:80%;">72.3/71.3</span></td>
</tr>
<tr id="S4.T1.1.11.10" class="ltx_tr">
<th id="S4.T1.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">
<span id="S4.T1.1.11.10.1.1" class="ltx_text" style="font-size:80%;">PV-RCNN++ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T1.1.11.10.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S4.T1.1.11.10.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<th id="S4.T1.1.11.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.11.10.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">71.7/69.5</span></th>
<td id="S4.T1.1.11.10.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.11.10.3.1" class="ltx_text" style="font-size:80%;">70.6/</span><span id="S4.T1.1.11.10.3.2" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">70.2</span>
</td>
<td id="S4.T1.1.11.10.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.11.10.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">79.3/78.8</span></td>
<td id="S4.T1.1.11.10.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.11.10.5.1" class="ltx_text" style="font-size:80%;">73.2/68.0</span></td>
<td id="S4.T1.1.11.10.6" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.11.10.6.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">81.3</span><span id="S4.T1.1.11.10.6.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.11.10.6.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">76.3</span>
</td>
<td id="S4.T1.1.11.10.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.11.10.7.1" class="ltx_text" style="font-size:80%;">71.2/70.2</span></td>
<td id="S4.T1.1.11.10.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.11.10.8.1" class="ltx_text" style="font-size:80%;">73.7/72.7</span></td>
</tr>
<tr id="S4.T1.1.12.11" class="ltx_tr">
<th id="S4.T1.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="8"><span id="S4.T1.1.12.11.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Sparse Detectors</span></th>
</tr>
<tr id="S4.T1.1.13.12" class="ltx_tr">
<th id="S4.T1.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.1.13.12.1.1" class="ltx_text" style="font-size:80%;">BoxeR-3D</span></th>
<th id="S4.T1.1.13.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.13.12.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">-/-</span></th>
<td id="S4.T1.1.13.12.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.13.12.3.1" class="ltx_text" style="font-size:80%;">63.9/63.7</span></td>
<td id="S4.T1.1.13.12.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.13.12.4.1" class="ltx_text" style="font-size:80%;">70.4/70.0</span></td>
<td id="S4.T1.1.13.12.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.13.12.5.1" class="ltx_text" style="font-size:80%;">61.5/53.7</span></td>
<td id="S4.T1.1.13.12.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.13.12.6.1" class="ltx_text" style="font-size:80%;">64.7/53.5</span></td>
<td id="S4.T1.1.13.12.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.13.12.7.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.13.12.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.13.12.8.1" class="ltx_text" style="font-size:80%;">50.2/48.9</span></td>
</tr>
<tr id="S4.T1.1.14.13" class="ltx_tr">
<th id="S4.T1.1.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.1.14.13.1.1" class="ltx_text" style="font-size:80%;">TransFusion-L</span></th>
<th id="S4.T1.1.14.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.14.13.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">-/64.9</span></th>
<td id="S4.T1.1.14.13.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.14.13.3.1" class="ltx_text" style="font-size:80%;">-/65.1</span></td>
<td id="S4.T1.1.14.13.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.14.13.4.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.14.13.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.14.13.5.1" class="ltx_text" style="font-size:80%;">-/63.7</span></td>
<td id="S4.T1.1.14.13.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.14.13.6.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
<td id="S4.T1.1.14.13.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.14.13.7.1" class="ltx_text" style="font-size:80%;">-/65.9</span></td>
<td id="S4.T1.1.14.13.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.14.13.8.1" class="ltx_text" style="font-size:80%;">-/-</span></td>
</tr>
<tr id="S4.T1.1.15.14" class="ltx_tr">
<th id="S4.T1.1.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.1.15.14.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR (ours)</span></th>
<th id="S4.T1.1.15.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.15.14.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">68.8/66.1</span></th>
<td id="S4.T1.1.15.14.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.15.14.3.1" class="ltx_text" style="font-size:80%;">67.8/67.2</span></td>
<td id="S4.T1.1.15.14.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.15.14.4.1" class="ltx_text" style="font-size:80%;">75.4/74.9</span></td>
<td id="S4.T1.1.15.14.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.15.14.5.1" class="ltx_text" style="font-size:80%;">69.7/63.1</span></td>
<td id="S4.T1.1.15.14.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.15.14.6.1" class="ltx_text" style="font-size:80%;">77.6/70.5</span></td>
<td id="S4.T1.1.15.14.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.15.14.7.1" class="ltx_text" style="font-size:80%;">69.0/67.9</span></td>
<td id="S4.T1.1.15.14.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.15.14.8.1" class="ltx_text" style="font-size:80%;">71.7/70.5</span></td>
</tr>
<tr id="S4.T1.1.16.15" class="ltx_tr">
<th id="S4.T1.1.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.1.16.15.1.1" class="ltx_text" style="font-size:80%;">ConQueR (ours)</span></th>
<th id="S4.T1.1.16.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.16.15.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">70.3/67.7</span></th>
<td id="S4.T1.1.16.15.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.16.15.3.1" class="ltx_text" style="font-size:80%;">68.7/68.2</span></td>
<td id="S4.T1.1.16.15.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.16.15.4.1" class="ltx_text" style="font-size:80%;">76.1/75.6</span></td>
<td id="S4.T1.1.16.15.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.16.15.5.1" class="ltx_text" style="font-size:80%;">70.9/64.7</span></td>
<td id="S4.T1.1.16.15.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.16.15.6.1" class="ltx_text" style="font-size:80%;">79.0/72.3</span></td>
<td id="S4.T1.1.16.15.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.16.15.7.1" class="ltx_text" style="font-size:80%;">71.4/70.1</span></td>
<td id="S4.T1.1.16.15.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.16.15.8.1" class="ltx_text" style="font-size:80%;">73.9/72.5</span></td>
</tr>
<tr id="S4.T1.1.17.16" class="ltx_tr">
<th id="S4.T1.1.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.1.17.16.1.1" class="ltx_text" style="font-size:80%;">ConQueR †(ours)</span></th>
<th id="S4.T1.1.17.16.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="background-color:#F2F2F2;">
<span id="S4.T1.1.17.16.2.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;background-color:#F2F2F2;">73.1</span><span id="S4.T1.1.17.16.2.2" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">/<span id="S4.T1.1.17.16.2.2.1" class="ltx_text ltx_framed ltx_framed_underline">70.6</span></span>
</th>
<td id="S4.T1.1.17.16.3" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.17.16.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">71.0</span><span id="S4.T1.1.17.16.3.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.17.16.3.3" class="ltx_text ltx_font_bold" style="font-size:80%;">70.5</span>
</td>
<td id="S4.T1.1.17.16.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.17.16.4.1" class="ltx_text" style="font-size:80%;">78.4/77.9</span></td>
<td id="S4.T1.1.17.16.5" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.17.16.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">73.7</span><span id="S4.T1.1.17.16.5.2" class="ltx_text" style="font-size:80%;">/68.1</span>
</td>
<td id="S4.T1.1.17.16.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.17.16.6.1" class="ltx_text" style="font-size:80%;">80.9/75.2</span></td>
<td id="S4.T1.1.17.16.7" class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T1.1.17.16.7.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">74.5</span><span id="S4.T1.1.17.16.7.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.17.16.7.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">73.3</span>
</td>
<td id="S4.T1.1.17.16.8" class="ltx_td ltx_align_center">
<span id="S4.T1.1.17.16.8.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">77.3</span><span id="S4.T1.1.17.16.8.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.17.16.8.3" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">76.1</span>
</td>
</tr>
<tr id="S4.T1.1.18.17" class="ltx_tr">
<th id="S4.T1.1.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r"><span id="S4.T1.1.18.17.1.1" class="ltx_text" style="font-size:80%;">ConQueR ‡(ours)</span></th>
<th id="S4.T1.1.18.17.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b ltx_border_r" style="background-color:#F2F2F2;"><span id="S4.T1.1.18.17.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#F2F2F2;">74.0<span id="S4.T1.1.18.17.2.1.1" class="ltx_text ltx_font_medium" style="background-color:#F2F2F2;">/</span>71.6</span></th>
<td id="S4.T1.1.18.17.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">
<span id="S4.T1.1.18.17.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">71.0</span><span id="S4.T1.1.18.17.3.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.18.17.3.3" class="ltx_text ltx_font_bold" style="font-size:80%;">70.5</span>
</td>
<td id="S4.T1.1.18.17.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r"><span id="S4.T1.1.18.17.4.1" class="ltx_text" style="font-size:80%;">78.4/77.9</span></td>
<td id="S4.T1.1.18.17.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">
<span id="S4.T1.1.18.17.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">75.8</span><span id="S4.T1.1.18.17.5.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.18.17.5.3" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span>
</td>
<td id="S4.T1.1.18.17.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">
<span id="S4.T1.1.18.17.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">82.4</span><span id="S4.T1.1.18.17.6.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.18.17.6.3" class="ltx_text ltx_font_bold" style="font-size:80%;">76.6</span>
</td>
<td id="S4.T1.1.18.17.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">
<span id="S4.T1.1.18.17.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">75.2</span><span id="S4.T1.1.18.17.7.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.18.17.7.3" class="ltx_text ltx_font_bold" style="font-size:80%;">74.1</span>
</td>
<td id="S4.T1.1.18.17.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b">
<span id="S4.T1.1.18.17.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">77.5</span><span id="S4.T1.1.18.17.8.2" class="ltx_text" style="font-size:80%;">/</span><span id="S4.T1.1.18.17.8.3" class="ltx_text ltx_font_bold" style="font-size:80%;">76.4</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.30.6.1" class="ltx_text" style="font-size:113%;">Table 1</span>: </span><span id="S4.T1.11.5" class="ltx_text" style="font-size:113%;">Performances on the WOD <em id="S4.T1.11.5.1" class="ltx_emph ltx_font_italic">validation</em> split. All models take single-frame input with the same range, no pre-training or ensembling is required. <math id="S4.T1.7.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S4.T1.7.1.m1.1b"><mo id="S4.T1.7.1.m1.1.1" xref="S4.T1.7.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.1.m1.1c"><ci id="S4.T1.7.1.m1.1.1.cmml" xref="S4.T1.7.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.1.m1.1d">{\dagger}</annotation></semantics></math> denotes using the 2<math id="S4.T1.8.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.8.2.m2.1b"><mo id="S4.T1.8.2.m2.1.1" xref="S4.T1.8.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.2.m2.1c"><times id="S4.T1.8.2.m2.1.1.cmml" xref="S4.T1.8.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.2.m2.1d">\times</annotation></semantics></math> wider ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> with <math id="S4.T1.9.3.m3.1" class="ltx_Math" alttext="1/4" display="inline"><semantics id="S4.T1.9.3.m3.1b"><mrow id="S4.T1.9.3.m3.1.1" xref="S4.T1.9.3.m3.1.1.cmml"><mn id="S4.T1.9.3.m3.1.1.2" xref="S4.T1.9.3.m3.1.1.2.cmml">1</mn><mo id="S4.T1.9.3.m3.1.1.1" xref="S4.T1.9.3.m3.1.1.1.cmml">/</mo><mn id="S4.T1.9.3.m3.1.1.3" xref="S4.T1.9.3.m3.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.9.3.m3.1c"><apply id="S4.T1.9.3.m3.1.1.cmml" xref="S4.T1.9.3.m3.1.1"><divide id="S4.T1.9.3.m3.1.1.1.cmml" xref="S4.T1.9.3.m3.1.1.1"></divide><cn type="integer" id="S4.T1.9.3.m3.1.1.2.cmml" xref="S4.T1.9.3.m3.1.1.2">1</cn><cn type="integer" id="S4.T1.9.3.m3.1.1.3.cmml" xref="S4.T1.9.3.m3.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.3.m3.1d">1/4</annotation></semantics></math> downscaled BEV feature map in our backbone. <math id="S4.T1.10.4.m4.1" class="ltx_Math" alttext="{\ddagger}" display="inline"><semantics id="S4.T1.10.4.m4.1b"><mo id="S4.T1.10.4.m4.1.1" xref="S4.T1.10.4.m4.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.4.m4.1c"><ci id="S4.T1.10.4.m4.1.1.cmml" xref="S4.T1.10.4.m4.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.4.m4.1d">{\ddagger}</annotation></semantics></math> denotes conducting NMS on pedestrians and cyclists. <span id="S4.T1.11.5.2" class="ltx_text ltx_font_bold">Bold</span> denotes the best entries, and <span id="S4.T1.11.5.3" class="ltx_text ltx_framed ltx_framed_underline">underline</span> denotes the second-best entries. <sub id="S4.T1.11.5.4" class="ltx_sub">ts</sub> denotes the two-stage model.
</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implementation Details</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.5" class="ltx_p"><span id="S4.SS1.p1.5.1" class="ltx_text ltx_font_bold">Training.</span> We follow common practice as previous voxel-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> to use point cloud range of <math id="S4.SS1.p1.1.m1.6" class="ltx_Math" alttext="[-75.2m,75.2m]\times[-75.2m,75.2m]\times[-2.0m,4.0m]" display="inline"><semantics id="S4.SS1.p1.1.m1.6a"><mrow id="S4.SS1.p1.1.m1.6.6" xref="S4.SS1.p1.1.m1.6.6.cmml"><mrow id="S4.SS1.p1.1.m1.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.2.2.2.2.3" xref="S4.SS1.p1.1.m1.2.2.2.3.cmml">[</mo><mrow id="S4.SS1.p1.1.m1.1.1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.1.1.cmml"><mo id="S4.SS1.p1.1.m1.1.1.1.1.1a" xref="S4.SS1.p1.1.m1.1.1.1.1.1.cmml">−</mo><mrow id="S4.SS1.p1.1.m1.1.1.1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.cmml"><mn id="S4.SS1.p1.1.m1.1.1.1.1.1.2.2" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.2.cmml">75.2</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.1.1.1.1.2.1" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.1.1.1.1.1.2.3" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.3.cmml">m</mi></mrow></mrow><mo id="S4.SS1.p1.1.m1.2.2.2.2.4" xref="S4.SS1.p1.1.m1.2.2.2.3.cmml">,</mo><mrow id="S4.SS1.p1.1.m1.2.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.2.cmml"><mn id="S4.SS1.p1.1.m1.2.2.2.2.2.2" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2.cmml">75.2</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.2.2.2.2.2.1" xref="S4.SS1.p1.1.m1.2.2.2.2.2.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.2.2.2.2.2.3" xref="S4.SS1.p1.1.m1.2.2.2.2.2.3.cmml">m</mi></mrow><mo rspace="0.055em" stretchy="false" id="S4.SS1.p1.1.m1.2.2.2.2.5" xref="S4.SS1.p1.1.m1.2.2.2.3.cmml">]</mo></mrow><mo rspace="0.222em" id="S4.SS1.p1.1.m1.6.6.7" xref="S4.SS1.p1.1.m1.6.6.7.cmml">×</mo><mrow id="S4.SS1.p1.1.m1.4.4.4.2" xref="S4.SS1.p1.1.m1.4.4.4.3.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.4.4.4.2.3" xref="S4.SS1.p1.1.m1.4.4.4.3.cmml">[</mo><mrow id="S4.SS1.p1.1.m1.3.3.3.1.1" xref="S4.SS1.p1.1.m1.3.3.3.1.1.cmml"><mo id="S4.SS1.p1.1.m1.3.3.3.1.1a" xref="S4.SS1.p1.1.m1.3.3.3.1.1.cmml">−</mo><mrow id="S4.SS1.p1.1.m1.3.3.3.1.1.2" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.cmml"><mn id="S4.SS1.p1.1.m1.3.3.3.1.1.2.2" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.2.cmml">75.2</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.3.3.3.1.1.2.1" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.3.3.3.1.1.2.3" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.3.cmml">m</mi></mrow></mrow><mo id="S4.SS1.p1.1.m1.4.4.4.2.4" xref="S4.SS1.p1.1.m1.4.4.4.3.cmml">,</mo><mrow id="S4.SS1.p1.1.m1.4.4.4.2.2" xref="S4.SS1.p1.1.m1.4.4.4.2.2.cmml"><mn id="S4.SS1.p1.1.m1.4.4.4.2.2.2" xref="S4.SS1.p1.1.m1.4.4.4.2.2.2.cmml">75.2</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.4.4.4.2.2.1" xref="S4.SS1.p1.1.m1.4.4.4.2.2.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.4.4.4.2.2.3" xref="S4.SS1.p1.1.m1.4.4.4.2.2.3.cmml">m</mi></mrow><mo rspace="0.055em" stretchy="false" id="S4.SS1.p1.1.m1.4.4.4.2.5" xref="S4.SS1.p1.1.m1.4.4.4.3.cmml">]</mo></mrow><mo rspace="0.222em" id="S4.SS1.p1.1.m1.6.6.7a" xref="S4.SS1.p1.1.m1.6.6.7.cmml">×</mo><mrow id="S4.SS1.p1.1.m1.6.6.6.2" xref="S4.SS1.p1.1.m1.6.6.6.3.cmml"><mo stretchy="false" id="S4.SS1.p1.1.m1.6.6.6.2.3" xref="S4.SS1.p1.1.m1.6.6.6.3.cmml">[</mo><mrow id="S4.SS1.p1.1.m1.5.5.5.1.1" xref="S4.SS1.p1.1.m1.5.5.5.1.1.cmml"><mo id="S4.SS1.p1.1.m1.5.5.5.1.1a" xref="S4.SS1.p1.1.m1.5.5.5.1.1.cmml">−</mo><mrow id="S4.SS1.p1.1.m1.5.5.5.1.1.2" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.cmml"><mn id="S4.SS1.p1.1.m1.5.5.5.1.1.2.2" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.2.cmml">2.0</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.5.5.5.1.1.2.1" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.5.5.5.1.1.2.3" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.3.cmml">m</mi></mrow></mrow><mo id="S4.SS1.p1.1.m1.6.6.6.2.4" xref="S4.SS1.p1.1.m1.6.6.6.3.cmml">,</mo><mrow id="S4.SS1.p1.1.m1.6.6.6.2.2" xref="S4.SS1.p1.1.m1.6.6.6.2.2.cmml"><mn id="S4.SS1.p1.1.m1.6.6.6.2.2.2" xref="S4.SS1.p1.1.m1.6.6.6.2.2.2.cmml">4.0</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.6.6.6.2.2.1" xref="S4.SS1.p1.1.m1.6.6.6.2.2.1.cmml">​</mo><mi id="S4.SS1.p1.1.m1.6.6.6.2.2.3" xref="S4.SS1.p1.1.m1.6.6.6.2.2.3.cmml">m</mi></mrow><mo stretchy="false" id="S4.SS1.p1.1.m1.6.6.6.2.5" xref="S4.SS1.p1.1.m1.6.6.6.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.6b"><apply id="S4.SS1.p1.1.m1.6.6.cmml" xref="S4.SS1.p1.1.m1.6.6"><times id="S4.SS1.p1.1.m1.6.6.7.cmml" xref="S4.SS1.p1.1.m1.6.6.7"></times><interval closure="closed" id="S4.SS1.p1.1.m1.2.2.2.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2"><apply id="S4.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1"><minus id="S4.SS1.p1.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1"></minus><apply id="S4.SS1.p1.1.m1.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2"><times id="S4.SS1.p1.1.m1.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.1"></times><cn type="float" id="S4.SS1.p1.1.m1.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.2">75.2</cn><ci id="S4.SS1.p1.1.m1.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p1.1.m1.1.1.1.1.1.2.3">𝑚</ci></apply></apply><apply id="S4.SS1.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2"><times id="S4.SS1.p1.1.m1.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.1"></times><cn type="float" id="S4.SS1.p1.1.m1.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.2">75.2</cn><ci id="S4.SS1.p1.1.m1.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.1.m1.2.2.2.2.2.3">𝑚</ci></apply></interval><interval closure="closed" id="S4.SS1.p1.1.m1.4.4.4.3.cmml" xref="S4.SS1.p1.1.m1.4.4.4.2"><apply id="S4.SS1.p1.1.m1.3.3.3.1.1.cmml" xref="S4.SS1.p1.1.m1.3.3.3.1.1"><minus id="S4.SS1.p1.1.m1.3.3.3.1.1.1.cmml" xref="S4.SS1.p1.1.m1.3.3.3.1.1"></minus><apply id="S4.SS1.p1.1.m1.3.3.3.1.1.2.cmml" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2"><times id="S4.SS1.p1.1.m1.3.3.3.1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.1"></times><cn type="float" id="S4.SS1.p1.1.m1.3.3.3.1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.2">75.2</cn><ci id="S4.SS1.p1.1.m1.3.3.3.1.1.2.3.cmml" xref="S4.SS1.p1.1.m1.3.3.3.1.1.2.3">𝑚</ci></apply></apply><apply id="S4.SS1.p1.1.m1.4.4.4.2.2.cmml" xref="S4.SS1.p1.1.m1.4.4.4.2.2"><times id="S4.SS1.p1.1.m1.4.4.4.2.2.1.cmml" xref="S4.SS1.p1.1.m1.4.4.4.2.2.1"></times><cn type="float" id="S4.SS1.p1.1.m1.4.4.4.2.2.2.cmml" xref="S4.SS1.p1.1.m1.4.4.4.2.2.2">75.2</cn><ci id="S4.SS1.p1.1.m1.4.4.4.2.2.3.cmml" xref="S4.SS1.p1.1.m1.4.4.4.2.2.3">𝑚</ci></apply></interval><interval closure="closed" id="S4.SS1.p1.1.m1.6.6.6.3.cmml" xref="S4.SS1.p1.1.m1.6.6.6.2"><apply id="S4.SS1.p1.1.m1.5.5.5.1.1.cmml" xref="S4.SS1.p1.1.m1.5.5.5.1.1"><minus id="S4.SS1.p1.1.m1.5.5.5.1.1.1.cmml" xref="S4.SS1.p1.1.m1.5.5.5.1.1"></minus><apply id="S4.SS1.p1.1.m1.5.5.5.1.1.2.cmml" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2"><times id="S4.SS1.p1.1.m1.5.5.5.1.1.2.1.cmml" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.1"></times><cn type="float" id="S4.SS1.p1.1.m1.5.5.5.1.1.2.2.cmml" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.2">2.0</cn><ci id="S4.SS1.p1.1.m1.5.5.5.1.1.2.3.cmml" xref="S4.SS1.p1.1.m1.5.5.5.1.1.2.3">𝑚</ci></apply></apply><apply id="S4.SS1.p1.1.m1.6.6.6.2.2.cmml" xref="S4.SS1.p1.1.m1.6.6.6.2.2"><times id="S4.SS1.p1.1.m1.6.6.6.2.2.1.cmml" xref="S4.SS1.p1.1.m1.6.6.6.2.2.1"></times><cn type="float" id="S4.SS1.p1.1.m1.6.6.6.2.2.2.cmml" xref="S4.SS1.p1.1.m1.6.6.6.2.2.2">4.0</cn><ci id="S4.SS1.p1.1.m1.6.6.6.2.2.3.cmml" xref="S4.SS1.p1.1.m1.6.6.6.2.2.3">𝑚</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.6c">[-75.2m,75.2m]\times[-75.2m,75.2m]\times[-2.0m,4.0m]</annotation></semantics></math> with voxel size <math id="S4.SS1.p1.2.m2.3" class="ltx_Math" alttext="[0.1m,0.1m,0.15m]" display="inline"><semantics id="S4.SS1.p1.2.m2.3a"><mrow id="S4.SS1.p1.2.m2.3.3.3" xref="S4.SS1.p1.2.m2.3.3.4.cmml"><mo stretchy="false" id="S4.SS1.p1.2.m2.3.3.3.4" xref="S4.SS1.p1.2.m2.3.3.4.cmml">[</mo><mrow id="S4.SS1.p1.2.m2.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.cmml"><mn id="S4.SS1.p1.2.m2.1.1.1.1.2" xref="S4.SS1.p1.2.m2.1.1.1.1.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.1.1.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.1.1.cmml">​</mo><mi id="S4.SS1.p1.2.m2.1.1.1.1.3" xref="S4.SS1.p1.2.m2.1.1.1.1.3.cmml">m</mi></mrow><mo id="S4.SS1.p1.2.m2.3.3.3.5" xref="S4.SS1.p1.2.m2.3.3.4.cmml">,</mo><mrow id="S4.SS1.p1.2.m2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.2.cmml"><mn id="S4.SS1.p1.2.m2.2.2.2.2.2" xref="S4.SS1.p1.2.m2.2.2.2.2.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.2.2.2.2.1" xref="S4.SS1.p1.2.m2.2.2.2.2.1.cmml">​</mo><mi id="S4.SS1.p1.2.m2.2.2.2.2.3" xref="S4.SS1.p1.2.m2.2.2.2.2.3.cmml">m</mi></mrow><mo id="S4.SS1.p1.2.m2.3.3.3.6" xref="S4.SS1.p1.2.m2.3.3.4.cmml">,</mo><mrow id="S4.SS1.p1.2.m2.3.3.3.3" xref="S4.SS1.p1.2.m2.3.3.3.3.cmml"><mn id="S4.SS1.p1.2.m2.3.3.3.3.2" xref="S4.SS1.p1.2.m2.3.3.3.3.2.cmml">0.15</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.3.3.3.3.1" xref="S4.SS1.p1.2.m2.3.3.3.3.1.cmml">​</mo><mi id="S4.SS1.p1.2.m2.3.3.3.3.3" xref="S4.SS1.p1.2.m2.3.3.3.3.3.cmml">m</mi></mrow><mo stretchy="false" id="S4.SS1.p1.2.m2.3.3.3.7" xref="S4.SS1.p1.2.m2.3.3.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.3b"><list id="S4.SS1.p1.2.m2.3.3.4.cmml" xref="S4.SS1.p1.2.m2.3.3.3"><apply id="S4.SS1.p1.2.m2.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.1"></times><cn type="float" id="S4.SS1.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.2">0.1</cn><ci id="S4.SS1.p1.2.m2.1.1.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.1.1.3">𝑚</ci></apply><apply id="S4.SS1.p1.2.m2.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2"><times id="S4.SS1.p1.2.m2.2.2.2.2.1.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.1"></times><cn type="float" id="S4.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.2">0.1</cn><ci id="S4.SS1.p1.2.m2.2.2.2.2.3.cmml" xref="S4.SS1.p1.2.m2.2.2.2.2.3">𝑚</ci></apply><apply id="S4.SS1.p1.2.m2.3.3.3.3.cmml" xref="S4.SS1.p1.2.m2.3.3.3.3"><times id="S4.SS1.p1.2.m2.3.3.3.3.1.cmml" xref="S4.SS1.p1.2.m2.3.3.3.3.1"></times><cn type="float" id="S4.SS1.p1.2.m2.3.3.3.3.2.cmml" xref="S4.SS1.p1.2.m2.3.3.3.3.2">0.15</cn><ci id="S4.SS1.p1.2.m2.3.3.3.3.3.cmml" xref="S4.SS1.p1.2.m2.3.3.3.3.3">𝑚</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.3c">[0.1m,0.1m,0.15m]</annotation></semantics></math> in <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mi id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">x</annotation></semantics></math>, <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mi id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><ci id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">y</annotation></semantics></math>, and <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">z</annotation></semantics></math>-axes respectively. The same set of augmentations (<em id="S4.SS1.p1.5.2" class="ltx_emph ltx_font_italic">i.e.</em>, GT-Aug, flip, rotation, scaling) are adopted following the previous works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. We follow  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to use the “fade-strategy” to drop GT-Aug at the last epoch to avoid overfitting. Both our baseline Voxel-DETR and ConQueR are trained for 6 epochs unless otherwise specified. We use the OneCycle <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> learning rate scheduler and AdamW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> optimizer with maximal learning rate 0.001.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.8" class="ltx_p"><span id="S4.SS1.p2.8.1" class="ltx_text ltx_font_bold">Network.</span> For the 3D backbone in Fig. <a href="#S2.F2" title="Figure 2 ‣ End-to-End 2D Object Detection. ‣ 2 Related Works ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we use the same architecture as ResNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> but use sparse 3D convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> to replace the 2D ones. No pre-trained weights are used. The same FPN structure as RetinaNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> is used to obtain multi-scale BEV features. For simplicity, we only use the 8<math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mo id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><times id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\times</annotation></semantics></math> downscaled features as input to the transformer, which adopts 3 encoder layers and 3 decoder layers for computation efficiency. We select top-<math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn type="integer" id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">1000</annotation></semantics></math> scored query predictions from the encoder’s class-agnostic prediction head as object queries. We adopt top-N (<em id="S4.SS1.p2.8.2" class="ltx_emph ltx_font_italic">e.g.</em>, 300) scored predictions, or score threshold (<em id="S4.SS1.p2.8.3" class="ltx_emph ltx_font_italic">e.g.</em>, <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mo id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><geq id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">\geq</annotation></semantics></math> 0.1) during inference. We set <math id="S4.SS1.p2.4.m4.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S4.SS1.p2.4.m4.1a"><mrow id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml"><mi id="S4.SS1.p2.4.m4.1.1.2" xref="S4.SS1.p2.4.m4.1.1.2.cmml">α</mi><mo id="S4.SS1.p2.4.m4.1.1.1" xref="S4.SS1.p2.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.4.m4.1.1.3" xref="S4.SS1.p2.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><apply id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1"><eq id="S4.SS1.p2.4.m4.1.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1.1"></eq><ci id="S4.SS1.p2.4.m4.1.1.2.cmml" xref="S4.SS1.p2.4.m4.1.1.2">𝛼</ci><cn type="integer" id="S4.SS1.p2.4.m4.1.1.3.cmml" xref="S4.SS1.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">\alpha=1</annotation></semantics></math>, <math id="S4.SS1.p2.5.m5.1" class="ltx_Math" alttext="\beta=4" display="inline"><semantics id="S4.SS1.p2.5.m5.1a"><mrow id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.2" xref="S4.SS1.p2.5.m5.1.1.2.cmml">β</mi><mo id="S4.SS1.p2.5.m5.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.5.m5.1.1.3" xref="S4.SS1.p2.5.m5.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1"><eq id="S4.SS1.p2.5.m5.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1"></eq><ci id="S4.SS1.p2.5.m5.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.2">𝛽</ci><cn type="integer" id="S4.SS1.p2.5.m5.1.1.3.cmml" xref="S4.SS1.p2.5.m5.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">\beta=4</annotation></semantics></math>, <math id="S4.SS1.p2.6.m6.1" class="ltx_Math" alttext="\gamma=2" display="inline"><semantics id="S4.SS1.p2.6.m6.1a"><mrow id="S4.SS1.p2.6.m6.1.1" xref="S4.SS1.p2.6.m6.1.1.cmml"><mi id="S4.SS1.p2.6.m6.1.1.2" xref="S4.SS1.p2.6.m6.1.1.2.cmml">γ</mi><mo id="S4.SS1.p2.6.m6.1.1.1" xref="S4.SS1.p2.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.6.m6.1.1.3" xref="S4.SS1.p2.6.m6.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.6.m6.1b"><apply id="S4.SS1.p2.6.m6.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1"><eq id="S4.SS1.p2.6.m6.1.1.1.cmml" xref="S4.SS1.p2.6.m6.1.1.1"></eq><ci id="S4.SS1.p2.6.m6.1.1.2.cmml" xref="S4.SS1.p2.6.m6.1.1.2">𝛾</ci><cn type="integer" id="S4.SS1.p2.6.m6.1.1.3.cmml" xref="S4.SS1.p2.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.6.m6.1c">\gamma=2</annotation></semantics></math> in Eq. (<a href="#S3.E1" title="Equation 1 ‣ 3.1 Voxel-DETR ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). For the proposed Query Contrast, we use <math id="S4.SS1.p2.7.m7.1" class="ltx_Math" alttext="\tau=0.7" display="inline"><semantics id="S4.SS1.p2.7.m7.1a"><mrow id="S4.SS1.p2.7.m7.1.1" xref="S4.SS1.p2.7.m7.1.1.cmml"><mi id="S4.SS1.p2.7.m7.1.1.2" xref="S4.SS1.p2.7.m7.1.1.2.cmml">τ</mi><mo id="S4.SS1.p2.7.m7.1.1.1" xref="S4.SS1.p2.7.m7.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.7.m7.1.1.3" xref="S4.SS1.p2.7.m7.1.1.3.cmml">0.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.7.m7.1b"><apply id="S4.SS1.p2.7.m7.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1"><eq id="S4.SS1.p2.7.m7.1.1.1.cmml" xref="S4.SS1.p2.7.m7.1.1.1"></eq><ci id="S4.SS1.p2.7.m7.1.1.2.cmml" xref="S4.SS1.p2.7.m7.1.1.2">𝜏</ci><cn type="float" id="S4.SS1.p2.7.m7.1.1.3.cmml" xref="S4.SS1.p2.7.m7.1.1.3">0.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.7.m7.1c">\tau=0.7</annotation></semantics></math> in Eq. (<a href="#S3.E2" title="Equation 2 ‣ Contrast positive pairs against negative pairs. ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>), and adopt <math id="S4.SS1.p2.8.m8.1" class="ltx_Math" alttext="T=3" display="inline"><semantics id="S4.SS1.p2.8.m8.1a"><mrow id="S4.SS1.p2.8.m8.1.1" xref="S4.SS1.p2.8.m8.1.1.cmml"><mi id="S4.SS1.p2.8.m8.1.1.2" xref="S4.SS1.p2.8.m8.1.1.2.cmml">T</mi><mo id="S4.SS1.p2.8.m8.1.1.1" xref="S4.SS1.p2.8.m8.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.8.m8.1.1.3" xref="S4.SS1.p2.8.m8.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.8.m8.1b"><apply id="S4.SS1.p2.8.m8.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1"><eq id="S4.SS1.p2.8.m8.1.1.1.cmml" xref="S4.SS1.p2.8.m8.1.1.1"></eq><ci id="S4.SS1.p2.8.m8.1.1.2.cmml" xref="S4.SS1.p2.8.m8.1.1.2">𝑇</ci><cn type="integer" id="S4.SS1.p2.8.m8.1.1.3.cmml" xref="S4.SS1.p2.8.m8.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.8.m8.1c">T=3</annotation></semantics></math> noising groups with a maximal box noise ratio of 0.4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, and label noise ratio of 0.5 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Category labels are simply encoded as one-hot embeddings rather than the learnable embeddings in DN-DETR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Main Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For fair comparison, all methods included use the same point cloud input range, do not use any pre-trained weights, test-time augmentation or model ensembling.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Performance.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.4" class="ltx_p">As shown in Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, state-of-the-art 3D detectors are divided into dense and sparse categories according to whether they can <em id="S4.SS2.SSS0.Px1.p1.4.1" class="ltx_emph ltx_font_italic">directly</em> generate sparse detections. Our sparse detector ConQueR sets new records on <em id="S4.SS2.SSS0.Px1.p1.4.2" class="ltx_emph ltx_font_italic">all categories</em> of the WOD <em id="S4.SS2.SSS0.Px1.p1.4.3" class="ltx_emph ltx_font_italic">validation</em> set. ConQueR with direct sparse predictions (the second-last entry) achieves <math id="S4.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">\sim</annotation></semantics></math>1.0 mAPH/L2 higher than the previous best single-frame model PV-RCNN++ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, and is over 3.0 mAPH/L2 higher than the popular anchor-free CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. Notably, ConQueR demonstrates overwhelming performance on pedestrians and cyclists, outperforming previous best methods by <math id="S4.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.2.m2.1a"><mo id="S4.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.2.m2.1c">\sim</annotation></semantics></math><span id="S4.SS2.SSS0.Px1.p1.4.4" class="ltx_text ltx_font_bold">2.0</span> APH/L2, which shows the effectiveness of our Query Contrast strategy especially for densely populated categories. The significant performance improvements can also be validated on the WOD <em id="S4.SS2.SSS0.Px1.p1.4.5" class="ltx_emph ltx_font_italic">test</em> set in Table <a href="#S4.T2" title="Table 2 ‣ Performance. ‣ 4.2 Main Results ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Moreover, ConQueR surpasses previous best sparse detectors TransFusion-L by <math id="S4.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.3.m3.1a"><mo id="S4.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.3.m3.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.3.m3.1c">\sim</annotation></semantics></math><span id="S4.SS2.SSS0.Px1.p1.4.6" class="ltx_text ltx_font_bold">6.0</span> mAPH/L2, closing the performance gap between sparse and dense 3D detectors. When compared with our baseline Voxel-DETR, the proposed Query Contrast mechanism brings over <span id="S4.SS2.SSS0.Px1.p1.4.7" class="ltx_text ltx_font_bold">1.6</span> mAPH/L2 without any extra inference cost. Besides, our baseline Voxel-DETR with only 6 epochs of training outperforms previous sparse 3D detectors, and achieves comparable performance with CenterPoint (36-epoch training) with only <math id="S4.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="1/6" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.4.m4.1a"><mrow id="S4.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml"><mn id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.2" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml">1</mn><mo id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml">/</mo><mn id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.3" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1"><divide id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.1"></divide><cn type="integer" id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.2">1</cn><cn type="integer" id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.4.m4.1c">1/6</annotation></semantics></math> GPU hours. In addition, ConQueR has an inference latency of 70ms (46ms for CenterPoint)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Latency is measured with batch size 1 on NVIDIA A100 GPU.</span></span></span>.</p>
</div>
<div id="S4.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p2.1" class="ltx_p">Although ConQueR with <em id="S4.SS2.SSS0.Px1.p2.1.1" class="ltx_emph ltx_font_italic">direct</em> sparse predictions already achieves state-of-the-art performance, we find that applying NMS onto ConQueR’s sparse predictions can further improve small and densely populated categories such as pedestrians, while NMS causes <math id="S4.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.1.m1.1a"><mo id="S4.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.1.m1.1c">\sim</annotation></semantics></math>1.2 APH/L2 performance drop on the well-trained vehicles (as shown in Appendix. <a href="#A1" title="Appendix A Effects of NMS ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>). This is also the case with our baseline Voxel-DETR. We speculate this is caused by the learning difficulties inherent in the data for extremely similar queries (as shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(b)) . We thus report ConQueR’s performance after conducting NMS on pedestrians and cyclists (the last entry of Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>FSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> adopts larger point cloud ranges and requires a point segmentation pre-train weights. It is <math id="footnote2.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="footnote2.m1.1b"><mo id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><csymbol cd="latexml" id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">\sim</annotation></semantics></math>1.0 mAPH/L2 lower than our ConQueR.</span></span></span></p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.2.1.1" class="ltx_tr">
<th id="S4.T2.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T2.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<th id="S4.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.2.1.1.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">All</span></th>
<th id="S4.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.2.1.1.3.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T2.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.2.1.1.4.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T2.2.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.2.1.1.5.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.2.2.1" class="ltx_tr">
<th id="S4.T2.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T2.2.2.1.1.1" class="ltx_text" style="font-size:80%;">CenterPoint </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.2.1.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib47" title="" class="ltx_ref">47</a><span id="S4.T2.2.2.1.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<td id="S4.T2.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.2.2.1.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">69.0</span></td>
<td id="S4.T2.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.2.1.3.1" class="ltx_text" style="font-size:80%;">71.9</span></td>
<td id="S4.T2.2.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.2.1.4.1" class="ltx_text" style="font-size:80%;">67.0</span></td>
<td id="S4.T2.2.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.2.1.5.1" class="ltx_text" style="font-size:80%;">68.2</span></td>
</tr>
<tr id="S4.T2.2.3.2" class="ltx_tr">
<th id="S4.T2.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T2.2.3.2.1.1" class="ltx_text" style="font-size:80%;">PV-RCNN++ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.3.2.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S4.T2.2.3.2.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<td id="S4.T2.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.2.3.2.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">70.2</span></td>
<td id="S4.T2.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.3.2.3.1" class="ltx_text" style="font-size:80%;">73.5</span></td>
<td id="S4.T2.2.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.3.2.4.1" class="ltx_text" style="font-size:80%;">69.0</span></td>
<td id="S4.T2.2.3.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.3.2.5.1" class="ltx_text" style="font-size:80%;">68.2</span></td>
</tr>
<tr id="S4.T2.2.4.3" class="ltx_tr">
<th id="S4.T2.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T2.2.4.3.1.1" class="ltx_text" style="font-size:80%;">AFDetv2 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.4.3.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S4.T2.2.4.3.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<td id="S4.T2.2.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.2.4.3.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">70.0</span></td>
<td id="S4.T2.2.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.4.3.3.1" class="ltx_text" style="font-size:80%;">72.6</span></td>
<td id="S4.T2.2.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.4.3.4.1" class="ltx_text" style="font-size:80%;">68.6</span></td>
<td id="S4.T2.2.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.4.3.5.1" class="ltx_text" style="font-size:80%;">68.7</span></td>
</tr>
<tr id="S4.T2.2.5.4" class="ltx_tr">
<th id="S4.T2.2.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T2.2.5.4.1.1" class="ltx_text" style="font-size:80%;">PillarNet-34 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T2.2.5.4.1.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S4.T2.2.5.4.1.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</th>
<td id="S4.T2.2.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.2.5.4.2.1" class="ltx_text" style="font-size:80%;background-color:#F2F2F2;">69.6</span></td>
<td id="S4.T2.2.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">74.7</span></td>
<td id="S4.T2.2.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.2.5.4.4.1" class="ltx_text" style="font-size:80%;">68.5</span></td>
<td id="S4.T2.2.5.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.2.5.4.5.1" class="ltx_text" style="font-size:80%;">65.5</span></td>
</tr>
<tr id="S4.T2.2.6.5" class="ltx_tr">
<th id="S4.T2.2.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.6.5.1.1" class="ltx_text" style="font-size:80%;">ConQueR (Ours)</span></th>
<td id="S4.T2.2.6.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#F2F2F2;"><span id="S4.T2.2.6.5.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;background-color:#F2F2F2;">72.0</span></td>
<td id="S4.T2.2.6.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.6.5.3.1" class="ltx_text" style="font-size:80%;">73.3</span></td>
<td id="S4.T2.2.6.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.2.6.5.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.9</span></td>
<td id="S4.T2.2.6.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.2.6.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">71.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.7.1.1" class="ltx_text" style="font-size:113%;">Table 2</span>: </span><span id="S4.T2.8.2" class="ltx_text" style="font-size:113%;">Single-frame performance comparisons on the WOD <em id="S4.T2.8.2.1" class="ltx_emph ltx_font_italic">test</em> set. APH/L2 results are reported.</span></figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T3.7.8.1" class="ltx_tr">
<th id="S4.T3.7.8.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.7.8.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<th id="S4.T3.7.8.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.7.8.1.2.1" class="ltx_text" style="font-size:80%;">Preds/Scene</span></th>
<td id="S4.T3.7.8.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.7.8.1.3.1" class="ltx_text" style="font-size:80%;">Veh.</span></td>
<td id="S4.T3.7.8.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.7.8.1.4.1" class="ltx_text" style="font-size:80%;">Ped.</span></td>
<td id="S4.T3.7.8.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.7.8.1.5.1" class="ltx_text" style="font-size:80%;">Cyc.</span></td>
</tr>
<tr id="S4.T3.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="\text{CenterPoint}_{\rm nms}" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><msub id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.m1.1.1.2a.cmml">CenterPoint</mtext><mi mathsize="80%" id="S4.T3.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.m1.1.1.3.cmml">nms</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T3.1.1.1.m1.1.1.2a.cmml" xref="S4.T3.1.1.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.m1.1.1.2">CenterPoint</mtext></ci><ci id="S4.T3.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.m1.1.1.3">nms</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\text{CenterPoint}_{\rm nms}</annotation></semantics></math></th>
<th id="S4.T3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.1.1.2.1" class="ltx_text" style="font-size:80%;">192</span></th>
<td id="S4.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.3.1" class="ltx_text" style="font-size:80%;">66.4</span></td>
<td id="S4.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.1.4.1" class="ltx_text" style="font-size:80%;">62.9</span></td>
<td id="S4.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.1.1.5.1" class="ltx_text" style="font-size:80%;">67.9</span></td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<th id="S4.T3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><math id="S4.T3.2.2.1.m1.1" class="ltx_Math" alttext="\text{Transfusion}_{\rm topN}" display="inline"><semantics id="S4.T3.2.2.1.m1.1a"><msub id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.2.2.1.m1.1.1.2" xref="S4.T3.2.2.1.m1.1.1.2a.cmml">Transfusion</mtext><mi mathsize="80%" id="S4.T3.2.2.1.m1.1.1.3" xref="S4.T3.2.2.1.m1.1.1.3.cmml">topN</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><apply id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.2.2.1.m1.1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1">subscript</csymbol><ci id="S4.T3.2.2.1.m1.1.1.2a.cmml" xref="S4.T3.2.2.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.2.2.1.m1.1.1.2.cmml" xref="S4.T3.2.2.1.m1.1.1.2">Transfusion</mtext></ci><ci id="S4.T3.2.2.1.m1.1.1.3.cmml" xref="S4.T3.2.2.1.m1.1.1.3">topN</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">\text{Transfusion}_{\rm topN}</annotation></semantics></math></th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.2.2.2.1" class="ltx_text" style="font-size:80%;">300</span></th>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.2.2.3.1" class="ltx_text" style="font-size:80%;">65.1</span></td>
<td id="S4.T3.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.2.2.4.1" class="ltx_text" style="font-size:80%;">63.7</span></td>
<td id="S4.T3.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.2.2.5.1" class="ltx_text" style="font-size:80%;">65.9</span></td>
</tr>
<tr id="S4.T3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt"><math id="S4.T3.3.3.1.m1.1" class="ltx_Math" alttext="\text{Voxel-DETR}_{\rm topN}" display="inline"><semantics id="S4.T3.3.3.1.m1.1a"><msub id="S4.T3.3.3.1.m1.1.1" xref="S4.T3.3.3.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.3.3.1.m1.1.1.2" xref="S4.T3.3.3.1.m1.1.1.2a.cmml">Voxel-DETR</mtext><mi mathsize="80%" id="S4.T3.3.3.1.m1.1.1.3" xref="S4.T3.3.3.1.m1.1.1.3.cmml">topN</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.1.m1.1b"><apply id="S4.T3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.3.3.1.m1.1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T3.3.3.1.m1.1.1.2a.cmml" xref="S4.T3.3.3.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.3.3.1.m1.1.1.2.cmml" xref="S4.T3.3.3.1.m1.1.1.2">Voxel-DETR</mtext></ci><ci id="S4.T3.3.3.1.m1.1.1.3.cmml" xref="S4.T3.3.3.1.m1.1.1.3">topN</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.1.m1.1c">\text{Voxel-DETR}_{\rm topN}</annotation></semantics></math></th>
<th id="S4.T3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.3.3.2.1" class="ltx_text" style="font-size:80%;">300</span></th>
<td id="S4.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.3.3.3.1" class="ltx_text" style="font-size:80%;">67.1</span></td>
<td id="S4.T3.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.3.3.4.1" class="ltx_text" style="font-size:80%;">63.0</span></td>
<td id="S4.T3.3.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.3.3.5.1" class="ltx_text" style="font-size:80%;">67.8</span></td>
</tr>
<tr id="S4.T3.4.4" class="ltx_tr">
<th id="S4.T3.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><math id="S4.T3.4.4.1.m1.1" class="ltx_Math" alttext="\text{Voxel-DETR}_{\rm score}" display="inline"><semantics id="S4.T3.4.4.1.m1.1a"><msub id="S4.T3.4.4.1.m1.1.1" xref="S4.T3.4.4.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.4.4.1.m1.1.1.2" xref="S4.T3.4.4.1.m1.1.1.2a.cmml">Voxel-DETR</mtext><mi mathsize="80%" id="S4.T3.4.4.1.m1.1.1.3" xref="S4.T3.4.4.1.m1.1.1.3.cmml">score</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.1.m1.1b"><apply id="S4.T3.4.4.1.m1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.4.4.1.m1.1.1.1.cmml" xref="S4.T3.4.4.1.m1.1.1">subscript</csymbol><ci id="S4.T3.4.4.1.m1.1.1.2a.cmml" xref="S4.T3.4.4.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.4.4.1.m1.1.1.2.cmml" xref="S4.T3.4.4.1.m1.1.1.2">Voxel-DETR</mtext></ci><ci id="S4.T3.4.4.1.m1.1.1.3.cmml" xref="S4.T3.4.4.1.m1.1.1.3">score</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.1.m1.1c">\text{Voxel-DETR}_{\rm score}</annotation></semantics></math></th>
<th id="S4.T3.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.4.4.2.1" class="ltx_text" style="font-size:80%;">222</span></th>
<td id="S4.T3.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.4.3.1" class="ltx_text" style="font-size:80%;">67.2</span></td>
<td id="S4.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.4.4.4.1" class="ltx_text" style="font-size:80%;">63.1</span></td>
<td id="S4.T3.4.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.4.4.5.1" class="ltx_text" style="font-size:80%;">67.9</span></td>
</tr>
<tr id="S4.T3.5.5" class="ltx_tr">
<th id="S4.T3.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt"><math id="S4.T3.5.5.1.m1.1" class="ltx_Math" alttext="\text{ConQueR}_{\rm topN}" display="inline"><semantics id="S4.T3.5.5.1.m1.1a"><msub id="S4.T3.5.5.1.m1.1.1" xref="S4.T3.5.5.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.5.5.1.m1.1.1.2" xref="S4.T3.5.5.1.m1.1.1.2a.cmml">ConQueR</mtext><mi mathsize="80%" id="S4.T3.5.5.1.m1.1.1.3" xref="S4.T3.5.5.1.m1.1.1.3.cmml">topN</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.1.m1.1b"><apply id="S4.T3.5.5.1.m1.1.1.cmml" xref="S4.T3.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.5.5.1.m1.1.1.1.cmml" xref="S4.T3.5.5.1.m1.1.1">subscript</csymbol><ci id="S4.T3.5.5.1.m1.1.1.2a.cmml" xref="S4.T3.5.5.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.5.5.1.m1.1.1.2.cmml" xref="S4.T3.5.5.1.m1.1.1.2">ConQueR</mtext></ci><ci id="S4.T3.5.5.1.m1.1.1.3.cmml" xref="S4.T3.5.5.1.m1.1.1.3">topN</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.1.m1.1c">\text{ConQueR}_{\rm topN}</annotation></semantics></math></th>
<th id="S4.T3.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S4.T3.5.5.2.1" class="ltx_text" style="font-size:80%;">300</span></th>
<td id="S4.T3.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.5.5.3.1" class="ltx_text" style="font-size:80%;">68.0</span></td>
<td id="S4.T3.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T3.5.5.4.1" class="ltx_text" style="font-size:80%;">64.6</span></td>
<td id="S4.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T3.5.5.5.1" class="ltx_text" style="font-size:80%;">70.0</span></td>
</tr>
<tr id="S4.T3.6.6" class="ltx_tr">
<th id="S4.T3.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><math id="S4.T3.6.6.1.m1.1" class="ltx_Math" alttext="\text{ConQueR}_{\rm score}" display="inline"><semantics id="S4.T3.6.6.1.m1.1a"><msub id="S4.T3.6.6.1.m1.1.1" xref="S4.T3.6.6.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.6.6.1.m1.1.1.2" xref="S4.T3.6.6.1.m1.1.1.2a.cmml">ConQueR</mtext><mi mathsize="80%" id="S4.T3.6.6.1.m1.1.1.3" xref="S4.T3.6.6.1.m1.1.1.3.cmml">score</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.1.m1.1b"><apply id="S4.T3.6.6.1.m1.1.1.cmml" xref="S4.T3.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.6.6.1.m1.1.1.1.cmml" xref="S4.T3.6.6.1.m1.1.1">subscript</csymbol><ci id="S4.T3.6.6.1.m1.1.1.2a.cmml" xref="S4.T3.6.6.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.6.6.1.m1.1.1.2.cmml" xref="S4.T3.6.6.1.m1.1.1.2">ConQueR</mtext></ci><ci id="S4.T3.6.6.1.m1.1.1.3.cmml" xref="S4.T3.6.6.1.m1.1.1.3">score</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.1.m1.1c">\text{ConQueR}_{\rm score}</annotation></semantics></math></th>
<th id="S4.T3.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T3.6.6.2.1" class="ltx_text" style="font-size:80%;">131</span></th>
<td id="S4.T3.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.6.6.3.1" class="ltx_text" style="font-size:80%;">68.2</span></td>
<td id="S4.T3.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.6.6.4.1" class="ltx_text" style="font-size:80%;">64.7</span></td>
<td id="S4.T3.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.6.6.5.1" class="ltx_text" style="font-size:80%;">70.1</span></td>
</tr>
<tr id="S4.T3.7.7" class="ltx_tr">
<th id="S4.T3.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<math id="S4.T3.7.7.1.m1.1" class="ltx_Math" alttext="\text{ConQueR}_{\rm score}" display="inline"><semantics id="S4.T3.7.7.1.m1.1a"><msub id="S4.T3.7.7.1.m1.1.1" xref="S4.T3.7.7.1.m1.1.1.cmml"><mtext mathsize="80%" id="S4.T3.7.7.1.m1.1.1.2" xref="S4.T3.7.7.1.m1.1.1.2a.cmml">ConQueR</mtext><mi mathsize="80%" id="S4.T3.7.7.1.m1.1.1.3" xref="S4.T3.7.7.1.m1.1.1.3.cmml">score</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T3.7.7.1.m1.1b"><apply id="S4.T3.7.7.1.m1.1.1.cmml" xref="S4.T3.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.7.7.1.m1.1.1.1.cmml" xref="S4.T3.7.7.1.m1.1.1">subscript</csymbol><ci id="S4.T3.7.7.1.m1.1.1.2a.cmml" xref="S4.T3.7.7.1.m1.1.1.2"><mtext mathsize="80%" id="S4.T3.7.7.1.m1.1.1.2.cmml" xref="S4.T3.7.7.1.m1.1.1.2">ConQueR</mtext></ci><ci id="S4.T3.7.7.1.m1.1.1.3.cmml" xref="S4.T3.7.7.1.m1.1.1.3">score</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.7.1.m1.1c">\text{ConQueR}_{\rm score}</annotation></semantics></math><span id="S4.T3.7.7.1.1" class="ltx_text" style="font-size:80%;"> †</span>
</th>
<th id="S4.T3.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.7.7.2.1" class="ltx_text" style="font-size:80%;">122</span></th>
<td id="S4.T3.7.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.7.7.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.5</span></td>
<td id="S4.T3.7.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T3.7.7.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.1</span></td>
<td id="S4.T3.7.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.7.7.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">73.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.32.6.1" class="ltx_text" style="font-size:113%;">Table 3</span>: </span><span id="S4.T3.17.5" class="ltx_text" style="font-size:113%;">Sparsity of final predictions. APH/L2 results are reported on the WOD <span id="S4.T3.17.5.1" class="ltx_text ltx_font_italic">validation</span> set. The subscripts of each entry denotes the way they obtain final predictions. For example, CenterPoint<sub id="S4.T3.17.5.2" class="ltx_sub">nms</sub> uses NMS to filter out duplicated boxes, and Voxel-DETR<sub id="S4.T3.17.5.3" class="ltx_sub">topN</sub> denotes it uses top-<math id="S4.T3.15.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.T3.15.3.m3.1b"><mi id="S4.T3.15.3.m3.1.1" xref="S4.T3.15.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.T3.15.3.m3.1c"><ci id="S4.T3.15.3.m3.1.1.cmml" xref="S4.T3.15.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.3.m3.1d">N</annotation></semantics></math> scored proposals as final predictions, while ConQueR<sub id="S4.T3.17.5.4" class="ltx_sub">score</sub> denotes that using score thresholding to generate final sparse predictions. <math id="S4.T3.17.5.m5.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S4.T3.17.5.m5.1b"><mo id="S4.T3.17.5.m5.1.1" xref="S4.T3.17.5.m5.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T3.17.5.m5.1c"><ci id="S4.T3.17.5.m5.1.1.cmml" xref="S4.T3.17.5.m5.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.5.m5.1d">{\dagger}</annotation></semantics></math> denotes our best model in Table <a href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Sparsity.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.4" class="ltx_p">Apart from the performance improvements on the WOD official metrics, ConQueR shows great potential in reducing false positives and improving the sparsity of final predictions. We list the average number of predictions per scene for different 3D detectors in Table <a href="#S4.T3" title="Table 3 ‣ Performance. ‣ 4.2 Main Results ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. For the baseline Voxel-DETR, thresholding according to scores helps to reduce <math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mo id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">\sim</annotation></semantics></math>25% predictions per sample with slightly better performance. With the help of Query Contrast, ConQueR further reduces the number of predictions substantially by <math id="S4.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.1a"><mo id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.1b"><csymbol cd="latexml" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.1c">\sim</annotation></semantics></math>60%. Besides, as the performance of ConQueR continually improves (the last two lines), the sparsity of final predictions steadily improve as well.
When we adopt the same top-300 predictions as baseline Voxel-DETR<sub id="S4.SS2.SSS0.Px2.p1.4.1" class="ltx_sub">topN</sub> for evaluation, ConQueR<sub id="S4.SS2.SSS0.Px2.p1.4.2" class="ltx_sub">topN</sub> still improves the detection performance significantly. This indicates the Query Contrast mechanism contributes to generating more accurate predictions from best matched queries.
Furthermore, our ConQueR can achieve much sparser predictions even compared with NMS-based dense detectors such as CenterPoint.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Study</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Components of Query Contrast.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">We deduce the components of ConQueR to baseline Voxel-DETR by gradually removing multi-positive pairs, auxiliary de-noising loss, and contrastive loss in Table <a href="#S4.T4" title="Table 4 ‣ Components of Query Contrast. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
Compared to ConQueR (the first row), removing the multiple noised copies of GTs from contrastive learning (the second row) causes over 0.6 mAPH/L2 performance drop. If we further remove the auxiliary denoising loss (the third row), performances of vehicles and pedestrians classes even become slightly better, indicating that the auxiliary denoising loss alone is not the key for performance improvements. Moreover, we can find that Query Contrast with only original GTs (the second last entry) already improves over the baseline (the last entry) dramatically especially on pedestrians and cyclists. Overall, the Query Contrast scheme brings <span id="S4.SS3.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_bold">1.1, 1.7, 2.3</span> APH/L2 improvements for vehicles, pedestrians and cyclists respectively.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span id="S4.T4.2.1.1.1.1" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.2.1.1.1.1.1" class="ltx_inline-block">
<span id="S4.T4.2.1.1.1.1.1.1" class="ltx_p">InfoNCE</span>
<span id="S4.T4.2.1.1.1.1.1.2" class="ltx_p">Loss</span>
</span></span></th>
<th id="S4.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span id="S4.T4.2.1.1.2.1" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.2.1.1.2.1.1" class="ltx_inline-block">
<span id="S4.T4.2.1.1.2.1.1.1" class="ltx_p">Aux</span>
<span id="S4.T4.2.1.1.2.1.1.2" class="ltx_p">DN</span>
</span></span></th>
<th id="S4.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T4.2.1.1.3.1" class="ltx_text" style="font-size:80%;">
<span id="S4.T4.2.1.1.3.1.1" class="ltx_inline-block">
<span id="S4.T4.2.1.1.3.1.1.1" class="ltx_p">Multi</span>
<span id="S4.T4.2.1.1.3.1.1.2" class="ltx_p">Pos</span>
</span></span></th>
<th id="S4.T4.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3"><span id="S4.T4.2.1.1.4.1" class="ltx_text" style="font-size:80%;">APH/L2</span></th>
</tr>
<tr id="S4.T4.2.2.2" class="ltx_tr">
<th id="S4.T4.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T4.2.2.2.1.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T4.2.2.2.2.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T4.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S4.T4.2.2.2.3.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
<tr id="S4.T4.2.3.3" class="ltx_tr">
<th id="S4.T4.2.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S4.T4.2.3.3.1.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T4.2.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S4.T4.2.3.3.2.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T4.2.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.2.3.3.3.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T4.2.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.2.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></th>
<th id="S4.T4.2.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.2.3.3.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></th>
<th id="S4.T4.2.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T4.2.3.3.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.2.4.1" class="ltx_tr">
<th id="S4.T4.2.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T4.2.4.1.1.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T4.2.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T4.2.4.1.2.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T4.2.4.1.3" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S4.T4.2.4.1.4" class="ltx_td ltx_align_center">
<span id="S4.T4.2.4.1.4.1" class="ltx_text" style="font-size:80%;">67.4 (</span><span id="S4.T4.2.4.1.4.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -0.8</span><span id="S4.T4.2.4.1.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T4.2.4.1.5" class="ltx_td ltx_align_center">
<span id="S4.T4.2.4.1.5.1" class="ltx_text" style="font-size:80%;">64.1 (</span><span id="S4.T4.2.4.1.5.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -0.6</span><span id="S4.T4.2.4.1.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T4.2.4.1.6" class="ltx_td ltx_align_center">
<span id="S4.T4.2.4.1.6.1" class="ltx_text" style="font-size:80%;">69.6 (</span><span id="S4.T4.2.4.1.6.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -0.5</span><span id="S4.T4.2.4.1.6.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
<tr id="S4.T4.2.5.2" class="ltx_tr">
<th id="S4.T4.2.5.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T4.2.5.2.1.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T4.2.5.2.2" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T4.2.5.2.3" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S4.T4.2.5.2.4" class="ltx_td ltx_align_center">
<span id="S4.T4.2.5.2.4.1" class="ltx_text" style="font-size:80%;">67.5 (</span><span id="S4.T4.2.5.2.4.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +0.1</span><span id="S4.T4.2.5.2.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T4.2.5.2.5" class="ltx_td ltx_align_center">
<span id="S4.T4.2.5.2.5.1" class="ltx_text" style="font-size:80%;">64.2 (</span><span id="S4.T4.2.5.2.5.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +0.1</span><span id="S4.T4.2.5.2.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T4.2.5.2.6" class="ltx_td ltx_align_center">
<span id="S4.T4.2.5.2.6.1" class="ltx_text" style="font-size:80%;">69.3 (</span><span id="S4.T4.2.5.2.6.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -0.3</span><span id="S4.T4.2.5.2.6.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
<tr id="S4.T4.2.6.3" class="ltx_tr">
<th id="S4.T4.2.6.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_bb"></th>
<th id="S4.T4.2.6.3.2" class="ltx_td ltx_th ltx_th_row ltx_border_bb"></th>
<th id="S4.T4.2.6.3.3" class="ltx_td ltx_th ltx_th_row ltx_border_bb ltx_border_r"></th>
<td id="S4.T4.2.6.3.4" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T4.2.6.3.4.1" class="ltx_text" style="font-size:80%;">67.1 (</span><span id="S4.T4.2.6.3.4.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -0.4</span><span id="S4.T4.2.6.3.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T4.2.6.3.5" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T4.2.6.3.5.1" class="ltx_text" style="font-size:80%;">63.0 (</span><span id="S4.T4.2.6.3.5.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -1.2</span><span id="S4.T4.2.6.3.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T4.2.6.3.6" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S4.T4.2.6.3.6.1" class="ltx_text" style="font-size:80%;">67.8 (</span><span id="S4.T4.2.6.3.6.2" class="ltx_text" style="font-size:80%;color:#FF0000;"> -1.5</span><span id="S4.T4.2.6.3.6.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.10.1.1" class="ltx_text" style="font-size:113%;">Table 4</span>: </span><span id="S4.T4.11.2" class="ltx_text" style="font-size:113%;">Effects of components in Query Contrast. The numbers in brackets denotes the performance drop (<span id="S4.T4.11.2.1" class="ltx_text" style="color:#FF0000;">red</span>) or increase (<span id="S4.T4.11.2.2" class="ltx_text" style="color:#0000FF;">blue</span>) for each component. Both the multi-positive contrastive loss (Multi-Pos) and the InfoNCE loss (Eq. (<a href="#S3.E2" title="Equation 2 ‣ Contrast positive pairs against negative pairs. ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>)) from only original GTs have deep impact on performance, while the auxiliary denoising loss (Aux-DN) only has marginal effects.</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Effects of different supervisions or similarity metrics for GT-query pairs.</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">We demonstrate the effects of different type of supervision or similarity metrics applied to GT-query pairs in Table <a href="#S4.T5" title="Table 5 ‣ Effects of different supervisions or similarity metrics for GT-query pairs. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. As discussed in Sec. <a href="#S3.SS2" title="3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, simple geometric relations like GIoU cannot sufficiently measure the similarities between GTs and queries because they cannot take the appearance information into account, thus only have marginal effects compared to our baseline Voxel-DETR. If we replace Query Contrast with the MSE loss in knowledge distillation (KD) to supervise positive GT-query pairs, performance of vehicles is still comparable with our Query Contrast strategy (the last entry), but it cannot handle densely populated categories like pedestrians and cyclists, indicating the importance of suppressing negative GT-query pairs in our Query Contrast strategy.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.3.4.1" class="ltx_tr">
<th id="S4.T5.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T5.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<th id="S4.T5.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T5.3.4.1.2.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T5.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T5.3.4.1.3.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T5.3.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T5.3.4.1.4.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.3.5.1" class="ltx_tr">
<th id="S4.T5.3.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T5.3.5.1.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR</span></th>
<td id="S4.T5.3.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.3.5.1.2.1" class="ltx_text" style="font-size:80%;">67.1</span></td>
<td id="S4.T5.3.5.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.3.5.1.3.1" class="ltx_text" style="font-size:80%;">63.0</span></td>
<td id="S4.T5.3.5.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.3.5.1.4.1" class="ltx_text" style="font-size:80%;">67.8</span></td>
</tr>
<tr id="S4.T5.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T5.1.1.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span><sub id="S4.T5.1.1.1.2" class="ltx_sub"><span id="S4.T5.1.1.1.2.1" class="ltx_text" style="font-size:80%;">KD-MSE</span></sub>
</th>
<td id="S4.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.1.1.2.1" class="ltx_text" style="font-size:80%;">68.1</span></td>
<td id="S4.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.1.1.3.1" class="ltx_text" style="font-size:80%;">63.4</span></td>
<td id="S4.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.1.1.4.1" class="ltx_text" style="font-size:80%;">68.2</span></td>
</tr>
<tr id="S4.T5.2.2" class="ltx_tr">
<th id="S4.T5.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T5.2.2.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span><sub id="S4.T5.2.2.1.2" class="ltx_sub"><span id="S4.T5.2.2.1.2.1" class="ltx_text" style="font-size:80%;">QC-GIoU</span></sub>
</th>
<td id="S4.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.2.2.2.1" class="ltx_text" style="font-size:80%;">66.6</span></td>
<td id="S4.T5.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.2.2.3.1" class="ltx_text" style="font-size:80%;">63.6</span></td>
<td id="S4.T5.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.2.2.4.1" class="ltx_text" style="font-size:80%;">68.4</span></td>
</tr>
<tr id="S4.T5.3.3" class="ltx_tr">
<th id="S4.T5.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T5.3.3.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span><sub id="S4.T5.3.3.1.2" class="ltx_sub"><span id="S4.T5.3.3.1.2.1" class="ltx_text" style="font-size:80%;">QC-Cos</span></sub>
</th>
<td id="S4.T5.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T5.3.3.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></td>
<td id="S4.T5.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T5.3.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></td>
<td id="S4.T5.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T5.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.19.4.1" class="ltx_text" style="font-size:113%;">Table 5</span>: </span><span id="S4.T5.9.3" class="ltx_text" style="font-size:113%;">Effects of different supervisions or similarity metrics applied to GT-query pairs. APH/L2 results are reported. <sub id="S4.T5.9.3.1" class="ltx_sub">QC-Cos</sub> denotes our default Query Contrast with the cosine similarity metric, while <sub id="S4.T5.9.3.2" class="ltx_sub">QC-GIoU</sub> denotes using GIoU as the similarity measurement of GT-query pairs. <sub id="S4.T5.9.3.3" class="ltx_sub">KD-MSE</sub> indicates replacing Query Contrast with Knowledge Distillation MSE loss to supervise positive GT-query pairs only.</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Number of positive pairs.</h4>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.1" class="ltx_p">We present the results of using different numbers of noised GT copies in Table <a href="#S4.T6" title="Table 6 ‣ Number of positive pairs. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. We observe that using 3 groups of noised copies without original GTs (default setting) achieves the best performance. Moreover, incorporating original GT into the multi-positive contrastive loss harms the performance. The first two entries show that using single noised copies of GTs is better than using the original GTs. We conjecture this is caused by the lack of training for original GT boxes. The detector is only trained to recover from noised GTs, while having no idea how to deal with perfectly located original GTs.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1" class="ltx_tr">
<th id="S4.T6.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.1.2.1" class="ltx_text" style="font-size:80%;">Original GTs</span></th>
<th id="S4.T6.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<math id="S4.T6.1.1.1.m1.1" class="ltx_Math" alttext="\#" display="inline"><semantics id="S4.T6.1.1.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T6.1.1.1.m1.1.1" xref="S4.T6.1.1.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.m1.1c">\#</annotation></semantics></math><span id="S4.T6.1.1.1.1" class="ltx_text" style="font-size:80%;"> Noised GT Groups</span>
</th>
<td id="S4.T6.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.1.3.1" class="ltx_text" style="font-size:80%;">Veh</span></td>
<td id="S4.T6.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.1.4.1" class="ltx_text" style="font-size:80%;">Ped</span></td>
<td id="S4.T6.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.1.5.1" class="ltx_text" style="font-size:80%;">Cyc</span></td>
</tr>
<tr id="S4.T6.1.2.1" class="ltx_tr">
<th id="S4.T6.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="S4.T6.1.2.1.1.1" class="ltx_text" style="font-size:80%;">✓</span></th>
<th id="S4.T6.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.2.1.2.1" class="ltx_text" style="font-size:80%;">0</span></th>
<td id="S4.T6.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.2.1.3.1" class="ltx_text" style="font-size:80%;">67.5</span></td>
<td id="S4.T6.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.2.1.4.1" class="ltx_text" style="font-size:80%;">64.2</span></td>
<td id="S4.T6.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.2.1.5.1" class="ltx_text" style="font-size:80%;">69.3</span></td>
</tr>
<tr id="S4.T6.1.3.2" class="ltx_tr">
<th id="S4.T6.1.3.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T6.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T6.1.3.2.2.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">1</span></th>
<td id="S4.T6.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.3.2.3.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">67.9</span></td>
<td id="S4.T6.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.3.2.4.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">64.4</span></td>
<td id="S4.T6.1.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T6.1.3.2.5.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">69.6</span></td>
</tr>
<tr id="S4.T6.1.4.3" class="ltx_tr">
<th id="S4.T6.1.4.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T6.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.4.3.2.1" class="ltx_text" style="font-size:80%;">2</span></th>
<td id="S4.T6.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.4.3.3.1" class="ltx_text" style="font-size:80%;">68.2</span></td>
<td id="S4.T6.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.4.3.4.1" class="ltx_text" style="font-size:80%;">64.3</span></td>
<td id="S4.T6.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.4.3.5.1" class="ltx_text" style="font-size:80%;">69.9</span></td>
</tr>
<tr id="S4.T6.1.5.4" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S4.T6.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T6.1.5.4.1.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">✓</span></th>
<th id="S4.T6.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T6.1.5.4.2.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">2</span></th>
<td id="S4.T6.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.5.4.3.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">67.8</span></td>
<td id="S4.T6.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.5.4.4.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">64.4</span></td>
<td id="S4.T6.1.5.4.5" class="ltx_td ltx_align_center"><span id="S4.T6.1.5.4.5.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">68.8</span></td>
</tr>
<tr id="S4.T6.1.6.5" class="ltx_tr">
<th id="S4.T6.1.6.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T6.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T6.1.6.5.2.1" class="ltx_text" style="font-size:80%;">3</span></th>
<td id="S4.T6.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.6.5.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></td>
<td id="S4.T6.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.1.6.5.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></td>
<td id="S4.T6.1.6.5.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T6.1.6.5.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></td>
</tr>
<tr id="S4.T6.1.7.6" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="S4.T6.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S4.T6.1.7.6.1.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">✓</span></th>
<th id="S4.T6.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T6.1.7.6.2.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">3</span></th>
<td id="S4.T6.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.7.6.3.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">68.0</span></td>
<td id="S4.T6.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.7.6.4.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">64.3</span></td>
<td id="S4.T6.1.7.6.5" class="ltx_td ltx_align_center"><span id="S4.T6.1.7.6.5.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">69.9</span></td>
</tr>
<tr id="S4.T6.1.8.7" class="ltx_tr">
<th id="S4.T6.1.8.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_b"></th>
<th id="S4.T6.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T6.1.8.7.2.1" class="ltx_text" style="font-size:80%;">4</span></th>
<td id="S4.T6.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.1.8.7.3.1" class="ltx_text" style="font-size:80%;">67.7</span></td>
<td id="S4.T6.1.8.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.1.8.7.4.1" class="ltx_text" style="font-size:80%;">64.4</span></td>
<td id="S4.T6.1.8.7.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T6.1.8.7.5.1" class="ltx_text" style="font-size:80%;">70.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.11.2.1" class="ltx_text" style="font-size:113%;">Table 6</span>: </span><span id="S4.T6.3.1" class="ltx_text" style="font-size:113%;">Number of positive pairs in the contrastive loss. APH/L2 results are reported on the WOD <em id="S4.T6.3.1.1" class="ltx_emph ltx_font_italic">validation</em> split. <math id="S4.T6.3.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T6.3.1.m1.1b"><mi mathvariant="normal" id="S4.T6.3.1.m1.1.1" xref="S4.T6.3.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T6.3.1.m1.1c"><ci id="S4.T6.3.1.m1.1.1.cmml" xref="S4.T6.3.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.1.m1.1d">\checkmark</annotation></semantics></math> denotes including the original GT group into Eq. (<a href="#S3.E2" title="Equation 2 ‣ Contrast positive pairs against negative pairs. ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Query-GT feature alignment.</h4>

<div id="S4.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px4.p1.1" class="ltx_p">We demonstrate the importance of aligning query embeddings to GTs’ with an extra MLP in Table <a href="#S4.T7" title="Table 7 ‣ Query-GT feature alignment. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Removing the MLP for query embeddings alignment (the first row) or applying the MLP alignment for both GT and query embeddings (the last row) causes <math id="S4.SS3.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S4.SS3.SSS0.Px4.p1.1.m1.1a"><mo id="S4.SS3.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px4.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px4.p1.1.m1.1b"><csymbol cd="latexml" id="S4.SS3.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px4.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px4.p1.1.m1.1c">\sim</annotation></semantics></math>1 APH/L2 performance drop, indicating the importance of the asymmetric alignment design to mitigate the distribution gap between GT and query embeddings.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<table id="S4.T7.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.2.1.1" class="ltx_tr">
<th id="S4.T7.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T7.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Projection</span></th>
<th id="S4.T7.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T7.2.1.1.2.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T7.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T7.2.1.1.3.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T7.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T7.2.1.1.4.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.2.2.1" class="ltx_tr">
<td id="S4.T7.2.2.1.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T7.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.2.2.1.2.1" class="ltx_text" style="font-size:80%;">67.2</span></td>
<td id="S4.T7.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.2.2.1.3.1" class="ltx_text" style="font-size:80%;">64.2</span></td>
<td id="S4.T7.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.2.2.1.4.1" class="ltx_text" style="font-size:80%;">69.3</span></td>
</tr>
<tr id="S4.T7.2.3.2" class="ltx_tr">
<td id="S4.T7.2.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.2.3.2.1.1" class="ltx_text" style="font-size:80%;">Q</span></td>
<td id="S4.T7.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.2.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></td>
<td id="S4.T7.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.2.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></td>
<td id="S4.T7.2.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.2.3.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></td>
</tr>
<tr id="S4.T7.2.4.3" class="ltx_tr">
<td id="S4.T7.2.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T7.2.4.3.1.1" class="ltx_text" style="font-size:80%;">G&amp;Q</span></td>
<td id="S4.T7.2.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T7.2.4.3.2.1" class="ltx_text" style="font-size:80%;">67.3</span></td>
<td id="S4.T7.2.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T7.2.4.3.3.1" class="ltx_text" style="font-size:80%;">64.1</span></td>
<td id="S4.T7.2.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T7.2.4.3.4.1" class="ltx_text" style="font-size:80%;">68.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.5.1.1" class="ltx_text" style="font-size:113%;">Table 7</span>: </span><span id="S4.T7.6.2" class="ltx_text" style="font-size:113%;">Design choices of the asymmetric feature alignment. APH/L2 results are reported. ‘G’ and ‘Q’ denotes GT and query embeddings respectively from the selected layer in detector or prediction heads.</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Neural Layers for conducting Query Contrast.</h4>

<div id="S4.SS3.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px5.p1.1" class="ltx_p">We compare 3 layer alternatives to conduct Query Contrast in Table <a href="#S4.T8" title="Table 8 ‣ Neural Layers for conducting Query Contrast. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>: the output layer of each decoder layer, the output layer of each FFN prediction head, and the second-last layer of each FFN prediction head. The Query Contrast scheme can bring consistent improvements for all layer choices, and the features from the last layer of FFN prediction head performs the best, indicating that directly regulate the detection outputs via the contrastive loss can achieve the “enhance-suppress” effects onto queries to the utmost.</p>
</div>
<figure id="S4.T8" class="ltx_table">
<table id="S4.T8.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T8.3.4.1" class="ltx_tr">
<th id="S4.T8.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T8.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Layer to Contrast</span></th>
<th id="S4.T8.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T8.3.4.1.2.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T8.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T8.3.4.1.3.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T8.3.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T8.3.4.1.4.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T8.1.1" class="ltx_tr">
<th id="S4.T8.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T8.1.1.1.1" class="ltx_text" style="font-size:80%;">Last</span><sub id="S4.T8.1.1.1.2" class="ltx_sub"><span id="S4.T8.1.1.1.2.1" class="ltx_text" style="font-size:80%;">decoder</span></sub>
</th>
<td id="S4.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T8.1.1.2.1" class="ltx_text" style="font-size:80%;">68.1</span></td>
<td id="S4.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T8.1.1.3.1" class="ltx_text" style="font-size:80%;">63.9</span></td>
<td id="S4.T8.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.1.1.4.1" class="ltx_text" style="font-size:80%;">69.7</span></td>
</tr>
<tr id="S4.T8.2.2" class="ltx_tr">
<th id="S4.T8.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="S4.T8.2.2.1.1" class="ltx_text" style="font-size:80%;">Last</span><sub id="S4.T8.2.2.1.2" class="ltx_sub"><span id="S4.T8.2.2.1.2.1" class="ltx_text" style="font-size:80%;">FFN</span></sub>
</th>
<td id="S4.T8.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T8.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></td>
<td id="S4.T8.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T8.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></td>
<td id="S4.T8.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></td>
</tr>
<tr id="S4.T8.3.3" class="ltx_tr">
<th id="S4.T8.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T8.3.3.1.1" class="ltx_text" style="font-size:80%;">SecondLast</span><sub id="S4.T8.3.3.1.2" class="ltx_sub"><span id="S4.T8.3.3.1.2.1" class="ltx_text" style="font-size:80%;">FFN</span></sub>
</th>
<td id="S4.T8.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T8.3.3.2.1" class="ltx_text" style="font-size:80%;">67.4</span></td>
<td id="S4.T8.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T8.3.3.3.1" class="ltx_text" style="font-size:80%;">64.6</span></td>
<td id="S4.T8.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T8.3.3.4.1" class="ltx_text" style="font-size:80%;">69.6</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T8.21.4.1" class="ltx_text" style="font-size:113%;">Table 8</span>: </span><span id="S4.T8.9.3" class="ltx_text" style="font-size:113%;">Layers to conduct Query Contrast. Results are the APH/L2 reported on the WOD <em id="S4.T8.9.3.1" class="ltx_emph ltx_font_italic">validation</em> split. Last<sub id="S4.T8.9.3.2" class="ltx_sub">decoder</sub> and Last<sub id="S4.T8.9.3.3" class="ltx_sub">FFN</sub> denotes the output layer of each decoder layer and FFN prediction head respectively, while SecondLast<sub id="S4.T8.9.3.4" class="ltx_sub">FFN</sub> indicates the second-last layer of each FFN prediction head is chosen to conduct Query Contrast.</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Generalisation ability w.r.t. query numbers.</h4>

<div id="S4.SS3.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px6.p1.1" class="ltx_p">We verify the generalization ability of Query Contrast by varying query numbers in Table <a href="#S4.T9" title="Table 9 ‣ Generalisation ability w.r.t. query numbers. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. By default we adopt top-1000 scored proposals as initial queries to input to the transformer decoder. The performance gain of Query Contrast is relatively stable when we gradually reduce query numbers to 500 and 300.</p>
</div>
<figure id="S4.T9" class="ltx_table">
<table id="S4.T9.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T9.1.1" class="ltx_tr">
<th id="S4.T9.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.1.2.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<th id="S4.T9.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">
<math id="S4.T9.1.1.1.m1.1" class="ltx_Math" alttext="\#" display="inline"><semantics id="S4.T9.1.1.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S4.T9.1.1.1.m1.1.1" xref="S4.T9.1.1.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S4.T9.1.1.1.m1.1b"><ci id="S4.T9.1.1.1.m1.1.1.cmml" xref="S4.T9.1.1.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.1.1.1.m1.1c">\#</annotation></semantics></math><span id="S4.T9.1.1.1.1" class="ltx_text" style="font-size:80%;">Query</span>
</th>
<td id="S4.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.1.3.1" class="ltx_text" style="font-size:80%;">Veh.</span></td>
<td id="S4.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.1.4.1" class="ltx_text" style="font-size:80%;">Ped.</span></td>
<td id="S4.T9.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.1.5.1" class="ltx_text" style="font-size:80%;">Cyc.</span></td>
</tr>
<tr id="S4.T9.1.2.1" class="ltx_tr">
<th id="S4.T9.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.2.1.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR</span></th>
<th id="S4.T9.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.2.1.2.1" class="ltx_text" style="font-size:80%;">300</span></th>
<td id="S4.T9.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.2.1.3.1" class="ltx_text" style="font-size:80%;">66.3</span></td>
<td id="S4.T9.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.2.1.4.1" class="ltx_text" style="font-size:80%;">62.0</span></td>
<td id="S4.T9.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.2.1.5.1" class="ltx_text" style="font-size:80%;">66.5</span></td>
</tr>
<tr id="S4.T9.1.3.2" class="ltx_tr">
<th id="S4.T9.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.3.2.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span></th>
<th id="S4.T9.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.3.2.2.1" class="ltx_text" style="font-size:80%;">300</span></th>
<td id="S4.T9.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T9.1.3.2.3.1" class="ltx_text" style="font-size:80%;">67.0 (</span><span id="S4.T9.1.3.2.3.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +0.7</span><span id="S4.T9.1.3.2.3.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T9.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T9.1.3.2.4.1" class="ltx_text" style="font-size:80%;">63.6 (</span><span id="S4.T9.1.3.2.4.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +1.6</span><span id="S4.T9.1.3.2.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T9.1.3.2.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T9.1.3.2.5.1" class="ltx_text" style="font-size:80%;">68.9 (</span><span id="S4.T9.1.3.2.5.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +2.4</span><span id="S4.T9.1.3.2.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
<tr id="S4.T9.1.4.3" class="ltx_tr">
<th id="S4.T9.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.4.3.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR</span></th>
<th id="S4.T9.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.4.3.2.1" class="ltx_text" style="font-size:80%;">500</span></th>
<td id="S4.T9.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.4.3.3.1" class="ltx_text" style="font-size:80%;">66.9</span></td>
<td id="S4.T9.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.4.3.4.1" class="ltx_text" style="font-size:80%;">62.8</span></td>
<td id="S4.T9.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.4.3.5.1" class="ltx_text" style="font-size:80%;">67.3</span></td>
</tr>
<tr id="S4.T9.1.5.4" class="ltx_tr">
<th id="S4.T9.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.5.4.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span></th>
<th id="S4.T9.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.5.4.2.1" class="ltx_text" style="font-size:80%;">500</span></th>
<td id="S4.T9.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T9.1.5.4.3.1" class="ltx_text" style="font-size:80%;">67.8 (</span><span id="S4.T9.1.5.4.3.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +0.9</span><span id="S4.T9.1.5.4.3.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T9.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S4.T9.1.5.4.4.1" class="ltx_text" style="font-size:80%;">64.4 (</span><span id="S4.T9.1.5.4.4.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +1.6</span><span id="S4.T9.1.5.4.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T9.1.5.4.5" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T9.1.5.4.5.1" class="ltx_text" style="font-size:80%;">69.0 (</span><span id="S4.T9.1.5.4.5.2" class="ltx_text" style="font-size:80%;color:#0000FF;"> +1.7</span><span id="S4.T9.1.5.4.5.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
<tr id="S4.T9.1.6.5" class="ltx_tr">
<th id="S4.T9.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.6.5.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR</span></th>
<th id="S4.T9.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T9.1.6.5.2.1" class="ltx_text" style="font-size:80%;">1000</span></th>
<td id="S4.T9.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.6.5.3.1" class="ltx_text" style="font-size:80%;">67.1</span></td>
<td id="S4.T9.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T9.1.6.5.4.1" class="ltx_text" style="font-size:80%;">63.0</span></td>
<td id="S4.T9.1.6.5.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.1.6.5.5.1" class="ltx_text" style="font-size:80%;">67.8</span></td>
</tr>
<tr id="S4.T9.1.7.6" class="ltx_tr">
<th id="S4.T9.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T9.1.7.6.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span></th>
<th id="S4.T9.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T9.1.7.6.2.1" class="ltx_text" style="font-size:80%;">1000</span></th>
<td id="S4.T9.1.7.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T9.1.7.6.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span><span id="S4.T9.1.7.6.3.2" class="ltx_text" style="font-size:80%;"> (</span><span id="S4.T9.1.7.6.3.3" class="ltx_text" style="font-size:80%;color:#0000FF;"> +1.1</span><span id="S4.T9.1.7.6.3.4" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T9.1.7.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="S4.T9.1.7.6.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span><span id="S4.T9.1.7.6.4.2" class="ltx_text" style="font-size:80%;"> (</span><span id="S4.T9.1.7.6.4.3" class="ltx_text" style="font-size:80%;color:#0000FF;"> +1.7</span><span id="S4.T9.1.7.6.4.4" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="S4.T9.1.7.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="S4.T9.1.7.6.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span><span id="S4.T9.1.7.6.5.2" class="ltx_text" style="font-size:80%;"> (</span><span id="S4.T9.1.7.6.5.3" class="ltx_text" style="font-size:80%;color:#0000FF;"> +2.3</span><span id="S4.T9.1.7.6.5.4" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T9.7.1.1" class="ltx_text" style="font-size:113%;">Table 9</span>: </span><span id="S4.T9.8.2" class="ltx_text" style="font-size:113%;">Improvements of Query Contrast under different query numbers. APH/L2 results are reported. The <span id="S4.T9.8.2.1" class="ltx_text" style="color:#0000FF;"> blue</span> numbers in brackets indicates the performance gains.</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px7" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">EMA coefficients for generating GT embeddings.</h4>

<div id="S4.SS3.SSS0.Px7.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px7.p1.1" class="ltx_p">Here we show results of different momentums of our EMA decoder, which is used to embed GT boxes, in Table <a href="#S4.T10" title="Table 10 ‣ EMA coefficients for generating GT embeddings. ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. The performance of using the same decoder as queries (the first line) already achieves satisfactory results, while introducing a more stable decoder for GT boxes can further improve the performance especially on categories with fewer instances (<em id="S4.SS3.SSS0.Px7.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, cyclists).</p>
</div>
<figure id="S4.T10" class="ltx_table">
<table id="S4.T10.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T10.2.1.1" class="ltx_tr">
<th id="S4.T10.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T10.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Momentum</span></th>
<th id="S4.T10.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T10.2.1.1.2.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T10.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T10.2.1.1.3.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T10.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T10.2.1.1.4.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T10.2.2.1" class="ltx_tr">
<td id="S4.T10.2.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.2.1.1.1" class="ltx_text" style="font-size:80%;">0</span></td>
<td id="S4.T10.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.2.1.2.1" class="ltx_text" style="font-size:80%;">67.9</span></td>
<td id="S4.T10.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.2.1.3.1" class="ltx_text" style="font-size:80%;">64.4</span></td>
<td id="S4.T10.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T10.2.2.1.4.1" class="ltx_text" style="font-size:80%;">69.0</span></td>
</tr>
<tr id="S4.T10.2.3.2" class="ltx_tr">
<td id="S4.T10.2.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.3.2.1.1" class="ltx_text" style="font-size:80%;">0.9</span></td>
<td id="S4.T10.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.3.2.2.1" class="ltx_text" style="font-size:80%;">67.6</span></td>
<td id="S4.T10.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.3.2.3.1" class="ltx_text" style="font-size:80%;">64.3</span></td>
<td id="S4.T10.2.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T10.2.3.2.4.1" class="ltx_text" style="font-size:80%;">69.1</span></td>
</tr>
<tr id="S4.T10.2.4.3" class="ltx_tr">
<td id="S4.T10.2.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.4.3.1.1" class="ltx_text" style="font-size:80%;">0.99</span></td>
<td id="S4.T10.2.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.4.3.2.1" class="ltx_text" style="font-size:80%;">68.0</span></td>
<td id="S4.T10.2.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.2.4.3.3.1" class="ltx_text" style="font-size:80%;">64.5</span></td>
<td id="S4.T10.2.4.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T10.2.4.3.4.1" class="ltx_text" style="font-size:80%;">69.2</span></td>
</tr>
<tr id="S4.T10.2.5.4" class="ltx_tr">
<td id="S4.T10.2.5.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T10.2.5.4.1.1" class="ltx_text" style="font-size:80%;">0.999</span></td>
<td id="S4.T10.2.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T10.2.5.4.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></td>
<td id="S4.T10.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T10.2.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></td>
<td id="S4.T10.2.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T10.2.5.4.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T10.5.1.1" class="ltx_text" style="font-size:113%;">Table 10</span>: </span><span id="S4.T10.6.2" class="ltx_text" style="font-size:113%;">Effects of EMA momentum coefficient.</span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px8" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Temperature coefficient in Eq. (<a href="#S3.E2" title="Equation 2 ‣ Contrast positive pairs against negative pairs. ‣ 3.2 Query Contrast ‣ 3 Query Contrast Voxel-DETR (ConQueR) ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</h4>

<div id="S4.SS3.SSS0.Px8.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px8.p1.3" class="ltx_p">We shown the effects of different <math id="S4.SS3.SSS0.Px8.p1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS3.SSS0.Px8.p1.1.m1.1a"><mi id="S4.SS3.SSS0.Px8.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px8.p1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px8.p1.1.m1.1b"><ci id="S4.SS3.SSS0.Px8.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px8.p1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px8.p1.1.m1.1c">\tau</annotation></semantics></math> in Table <a href="#S4.T11" title="Table 11 ‣ Temperature coefficient in Eq. (2). ‣ 4.3 Ablation Study ‣ 4 Experiments ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. <math id="S4.SS3.SSS0.Px8.p1.2.m2.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.SS3.SSS0.Px8.p1.2.m2.1a"><mi id="S4.SS3.SSS0.Px8.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px8.p1.2.m2.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px8.p1.2.m2.1b"><ci id="S4.SS3.SSS0.Px8.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px8.p1.2.m2.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px8.p1.2.m2.1c">\tau</annotation></semantics></math> controls the contrastive learning difficulty of the GT-query similarities, and we find <math id="S4.SS3.SSS0.Px8.p1.3.m3.1" class="ltx_Math" alttext="\tau=0.7" display="inline"><semantics id="S4.SS3.SSS0.Px8.p1.3.m3.1a"><mrow id="S4.SS3.SSS0.Px8.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.cmml"><mi id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.2" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.2.cmml">τ</mi><mo id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.3" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.3.cmml">0.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px8.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1"><eq id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.1"></eq><ci id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.2">𝜏</ci><cn type="float" id="S4.SS3.SSS0.Px8.p1.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px8.p1.3.m3.1.1.3">0.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px8.p1.3.m3.1c">\tau=0.7</annotation></semantics></math> leads to the best performance.</p>
</div>
<figure id="S4.T11" class="ltx_table">
<table id="S4.T11.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T11.1.1" class="ltx_tr">
<th id="S4.T11.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S4.T11.1.1.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.T11.1.1.1.m1.1a"><mi mathsize="80%" id="S4.T11.1.1.1.m1.1.1" xref="S4.T11.1.1.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.T11.1.1.1.m1.1b"><ci id="S4.T11.1.1.1.m1.1.1.cmml" xref="S4.T11.1.1.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.1.1.1.m1.1c">\tau</annotation></semantics></math></th>
<th id="S4.T11.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T11.1.1.2.1" class="ltx_text" style="font-size:80%;">Veh.</span></th>
<th id="S4.T11.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T11.1.1.3.1" class="ltx_text" style="font-size:80%;">Ped.</span></th>
<th id="S4.T11.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T11.1.1.4.1" class="ltx_text" style="font-size:80%;">Cyc.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T11.1.2.1" class="ltx_tr">
<td id="S4.T11.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T11.1.2.1.1.1" class="ltx_text" style="font-size:80%;">1.0</span></td>
<td id="S4.T11.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T11.1.2.1.2.1" class="ltx_text" style="font-size:80%;">67.9</span></td>
<td id="S4.T11.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T11.1.2.1.3.1" class="ltx_text" style="font-size:80%;">64.2</span></td>
<td id="S4.T11.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T11.1.2.1.4.1" class="ltx_text" style="font-size:80%;">69.8</span></td>
</tr>
<tr id="S4.T11.1.3.2" class="ltx_tr">
<td id="S4.T11.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T11.1.3.2.1.1" class="ltx_text" style="font-size:80%;">0.7</span></td>
<td id="S4.T11.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T11.1.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.2</span></td>
<td id="S4.T11.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T11.1.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">64.7</span></td>
<td id="S4.T11.1.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T11.1.3.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.1</span></td>
</tr>
<tr id="S4.T11.1.4.3" class="ltx_tr">
<td id="S4.T11.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T11.1.4.3.1.1" class="ltx_text" style="font-size:80%;">0.5</span></td>
<td id="S4.T11.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T11.1.4.3.2.1" class="ltx_text" style="font-size:80%;">67.6</span></td>
<td id="S4.T11.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T11.1.4.3.3.1" class="ltx_text" style="font-size:80%;">64.5</span></td>
<td id="S4.T11.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T11.1.4.3.4.1" class="ltx_text" style="font-size:80%;">69.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T11.8.2.1" class="ltx_text" style="font-size:113%;">Table 11</span>: </span><span id="S4.T11.3.1" class="ltx_text" style="font-size:113%;">Effects of <math id="S4.T11.3.1.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S4.T11.3.1.m1.1b"><mi id="S4.T11.3.1.m1.1.1" xref="S4.T11.3.1.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S4.T11.3.1.m1.1c"><ci id="S4.T11.3.1.m1.1.1.cmml" xref="S4.T11.3.1.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T11.3.1.m1.1d">\tau</annotation></semantics></math>. APH/L2 results are reported.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">DETR-based sparse 3D detectors faces the problem of duplicated false positives, and lags in detection performance. In this paper, we solve these challenges with our simple yet effective Query Contrast Voxel-DETR (ConQueR). The problem of duplicated false positives is mainly caused by the lack of supervisions in handlings dense similar queries. Based on our sparse 3D detection framework Voxel-DETR, we propose a Query Contrast strategy to explicitly suppress densely overlapping false positives, and simultaneously promote the best matched queries towards their assigned GTs in a contrastive manner. ConQueR reduces <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.p1.1.m1.1a"><mo id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><csymbol cd="latexml" id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">\sim</annotation></semantics></math>60<math id="S5.p1.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.p1.2.m2.1a"><mo id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><csymbol cd="latexml" id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\%</annotation></semantics></math> false positives in the final sparse predictions, closes the gap between sparse and dense 3D detectors, and surpasses previous state-of-the-art 3D detectors by a large margin on the challenging WOD benchmark.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Xuyang Bai, Zeyu Hu, Xinge Zhu, Qingqiu Huang, Yilun Chen, Hongbo Fu, and
Chiew-Lan Tai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Transfusion: Robust lidar-camera fusion for 3d object detection with
transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
John Canny.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">A computational approach to edge detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">TPAMI</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 1986.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
Kirillov, and Sergey Zagoruyko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">End-to-end object detection with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and
Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Unsupervised learning of visual features by contrasting cluster
assignments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">A simple framework for contrastive learning of visual
representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICML</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Lue Fan, Ziqi Pang, Tianyuan Zhang, Yu-Xiong Wang, Hang Zhao, Feng Wang, Naiyan
Wang, and Zhaoxiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Embracing single stride 3d object detector with sparse transformer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Lue Fan, Feng Wang, Naiyan Wang, and Zhaoxiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Fully sparse 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Zheng Ge, Songtao Liu, Zeming Li, Osamu Yoshie, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Ota: Optimal transport assignment for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Benjamin Graham and Laurens van der Maaten.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Submanifold sparse convolutional networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Raia Hadsell, Sumit Chopra, and Yann LeCun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Dimensionality reduction by learning an invariant mapping.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, 2006.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Miao Hao, Yitao Liu, Xiangyu Zhang, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Labelenc: A new intermediate supervision method for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Momentum contrast for unsupervised visual representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, and Yichen Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Relation networks for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Yihan Hu, Zhuangzhuang Ding, Runzhou Ge, Wenxin Shao, Li Huang, Kun Li, and
Qiang Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Afdetv2: Rethinking the necessity of the second stage for object
detection from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Ding Jia, Yuhui Yuan, Haodi He, Xiaopei Wu, Haojun Yu, Weihong Lin, Lei Sun,
Chao Zhang, and Han Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Detrs with hybrid matching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Harold W Kuhn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">The hungarian method for the assignment problem.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Naval research logistics quarterly</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, 1955.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Christopher Lang, Alexander Braun, and Abhinav Valada.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Contrastive object detection using knowledge graph embeddings.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Feng Li, Hao Zhang, Shilong Liu, Jian Guo, Lionel M Ni, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Dn-detr: Accelerate detr training by introducing query denoising.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan,
and Serge Belongie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Feature pyramid networks for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Focal loss for dense object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr Dollár, and C Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Ilya Loshchilov and Frank Hutter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Decoupled weight decay regularization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang,
Hang Xu, and Chunjing Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Voxel transformer for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei
Sun, and Jingdong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Conditional detr for fast training convergence.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Ishan Misra, Rohit Girdhar, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">An end-to-end transformer model for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Duy-Kien Nguyen, Jihong Ju, Olaf Booij, Martin R Oswald, and Cees GM Snoek.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Boxer: Box-attention for 2d and 3d transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Aaron van den Oord, Yazhe Li, and Oriol Vinyals.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Representation learning with contrastive predictive coding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Byungseok Roh, JaeWoong Shin, Wuhyun Shin, and Saehoon Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Sparse detr: Efficient end-to-end object detection with learnable
sparsity.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Hualian Sheng, Sijia Cai, Yuan Liu, Bing Deng, Jianqiang Huang, Xian-Sheng Hua,
and Min-Jian Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Improving 3d object detection with channel-wise transformer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Guangsheng Shi, Ruifeng Li, and Chao Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Pillarnet: High-performance pillar-based 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and
Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Pv-rcnn: Point-voxel feature set abstraction for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Li Jiang, Jiajun Deng, Zhe Wang, Chaoxu Guo, Jianping Shi,
Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Pv-rcnn++: Point-voxel feature set abstraction with local vector
representation for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IJCV</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Pointrcnn: 3d object proposal generation and detection from point
cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Leslie N Smith and Nicholay Topin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Super-convergence: Very fast training of neural networks using large
learning rates.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AIMLMDO</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai
Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Scalability in perception for autonomous driving: Waymo open dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Mingxing Tan, Weiyue Wang, Chenxi Liu, Fei Xia, Zhaoqi Leng, and Drago
Anguelov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Swformer: Sparse window transformer for 3d object detection in point
clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Weiyue Wang, Yuning Chai, Gamaleldin Elsayed, Alex Bewley, Xiao Zhang,
Cristian Sminchisescu, and Dragomir Anguelov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Rsn: Range sparse net for efficient, accurate lidar 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi
Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Sparse r-cnn: End-to-end object detection with learnable proposals.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Zhi Tian, Xiangxiang Chu, Xiaoming Wang, Xiaolin Wei, and Chunhua Shen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Fully convolutional one-stage 3d object detection on lidar range
images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Chunwei Wang, Chao Ma, Ming Zhu, and Xiaokang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Pointaugmenting: Cross-modal augmentation for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Jianfeng Wang, Lin Song, Zeming Li, Hongbin Sun, Jian Sun, and Nanning Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">End-to-end object detection with fully convolutional network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Yingming Wang, Xiangyu Zhang, Tong Yang, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Anchor detr: Query design for transformer-based detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Yan Yan, Yuxing Mao, and Bo Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Second: Sparsely embedded convolutional detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Sensors</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Zetong Yang, Yanan Sun, Shu Liu, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">3dssd: Point-based 3d single stage object detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Lewei Yao, Renjie Pi, Hang Xu, Wei Zhang, Zhenguo Li, and Tong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">G-detkd: Towards general distillation framework for object detectors
via contrastive and semantic-guided feature imitation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Center-based 3d object detection and tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Sergey Zagoruyko and Nikos Komodakis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Wide residual networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib48.4.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel M Ni, and
Heung-Yeung Shum.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Dino: Detr with improved denoising anchor boxes for end-to-end object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib49.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Peizhen Zhang, Zijian Kang, Tong Yang, Xiangyu Zhang, Nanning Zheng, and Jian
Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Lgd: Label-guided self-distillation for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Shifeng Zhang, Cheng Chi, Yongqiang Yao, Zhen Lei, and Stan Z Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Bridging the gap between anchor-based and anchor-free detection via
adaptive training sample selection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Yin Zhou and Oncel Tuzel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Voxelnet: End-to-end learning for point cloud based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Zixiang Zhou, Xiangchen Zhao, Yu Wang, Panqu Wang, and Hassan Foroosh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Centerformer: Center-based transformer for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib53.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Benjin Zhu, Junqiang Huang, Zeming Li, Xiangyu Zhang, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Eqco: Equivalent rules for self-supervised contrastive learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib54.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Benjin Zhu, Zhengkai Jiang, Xiangxin Zhou, Zeming Li, and Gang Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Class-balanced grouping and sampling for point cloud 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib55.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Benjin Zhu, Jianfeng Wang, Zhengkai Jiang, Fuhang Zong, Songtao Liu, Zeming Li,
and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Autoassign: Differentiable label assignment for dense object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv</span><span id="bib.bib56.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Deformable detr: Deformable transformers for end-to-end object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib57.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Effects of NMS</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Here we demonstrate the effects of NMS on the sparse predictions of our Voxel-DETR and ConQueR in Table <a href="#A1.T12" title="Table 12 ‣ Appendix A Effects of NMS ‣ ConQueR: Query Contrast Voxel-DETR for 3D Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. Improper NMS configurations (<em id="A1.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, score and IoU thresholds) can cause performance degradation for all categories. And we find that the NMS configuration adopted by dense detectors (<em id="A1.p1.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, score threshold 0.1, IoU threshold 0.7) performs the best. For small and densely populated categories such as pedestrians, NMS can bring noticeable performance gains, which can be observed from our baseline Voxel-DETR. However, for the well-trained large vehicles, NMS comes with a significant performance penalty, which in turn demonstrates the effectiveness of our sparse 3D object detection framework. For cyclists, NMS fluctuates in its effects on detection performance, which indicates that NMS is not necessarily required for this category. We conclude that the impact of NMS on detection performance is originates from our baseline Voxel-DETR and the inherent learning difficulty in data for extremely close query predictions, rather the Query Contrast mechanism.</p>
</div>
<figure id="A1.T12" class="ltx_table">
<table id="A1.T12.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T12.3.4.1" class="ltx_tr">
<th id="A1.T12.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="A1.T12.3.4.1.1.1" class="ltx_text" style="font-size:80%;">Methods</span></th>
<td id="A1.T12.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T12.3.4.1.2.1" class="ltx_text" style="font-size:80%;">Veh.</span></td>
<td id="A1.T12.3.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T12.3.4.1.3.1" class="ltx_text" style="font-size:80%;">Ped.</span></td>
<td id="A1.T12.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T12.3.4.1.4.1" class="ltx_text" style="font-size:80%;">Cyc.</span></td>
</tr>
<tr id="A1.T12.3.5.2" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="A1.T12.3.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="4">
<em id="A1.T12.3.5.2.1.1" class="ltx_emph ltx_font_bold ltx_font_italic" style="font-size:80%;background-color:#E6E6E6;">validation</em><span id="A1.T12.3.5.2.1.2" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;"> set</span>
</th>
</tr>
<tr id="A1.T12.3.6.3" class="ltx_tr">
<th id="A1.T12.3.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="A1.T12.3.6.3.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR</span></th>
<td id="A1.T12.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A1.T12.3.6.3.2.1" class="ltx_text" style="font-size:80%;">68.2</span></td>
<td id="A1.T12.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A1.T12.3.6.3.3.1" class="ltx_text" style="font-size:80%;">64.7</span></td>
<td id="A1.T12.3.6.3.4" class="ltx_td ltx_align_center"><span id="A1.T12.3.6.3.4.1" class="ltx_text" style="font-size:80%;">70.1</span></td>
</tr>
<tr id="A1.T12.1.1" class="ltx_tr">
<th id="A1.T12.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="A1.T12.1.1.1.1" class="ltx_text" style="font-size:80%;">Voxel-DETR</span><sub id="A1.T12.1.1.1.2" class="ltx_sub"><span id="A1.T12.1.1.1.2.1" class="ltx_text" style="font-size:80%;">nms</span></sub>
</th>
<td id="A1.T12.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A1.T12.1.1.2.1" class="ltx_text" style="font-size:80%;">67.1 (</span><span id="A1.T12.1.1.2.2" class="ltx_text" style="font-size:80%;color:#FF0000;">-1.1</span><span id="A1.T12.1.1.2.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="A1.T12.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A1.T12.1.1.3.1" class="ltx_text" style="font-size:80%;">67.1 (</span><span id="A1.T12.1.1.3.2" class="ltx_text" style="font-size:80%;color:#0000FF;">+2.4</span><span id="A1.T12.1.1.3.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="A1.T12.1.1.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="A1.T12.1.1.4.1" class="ltx_text" style="font-size:80%;">70.2 (</span><span id="A1.T12.1.1.4.2" class="ltx_text" style="font-size:80%;color:#0000FF;">+0.1</span><span id="A1.T12.1.1.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
<tr id="A1.T12.3.7.4" class="ltx_tr">
<th id="A1.T12.3.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="A1.T12.3.7.4.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span></th>
<td id="A1.T12.3.7.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T12.3.7.4.2.1" class="ltx_text" style="font-size:80%;">70.5</span></td>
<td id="A1.T12.3.7.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T12.3.7.4.3.1" class="ltx_text" style="font-size:80%;">68.1</span></td>
<td id="A1.T12.3.7.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T12.3.7.4.4.1" class="ltx_text" style="font-size:80%;">73.3</span></td>
</tr>
<tr id="A1.T12.2.2" class="ltx_tr">
<th id="A1.T12.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">
<span id="A1.T12.2.2.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span><sub id="A1.T12.2.2.1.2" class="ltx_sub"><span id="A1.T12.2.2.1.2.1" class="ltx_text" style="font-size:80%;">nms</span></sub>
</th>
<td id="A1.T12.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A1.T12.2.2.2.1" class="ltx_text" style="font-size:80%;">69.2(</span><span id="A1.T12.2.2.2.2" class="ltx_text" style="font-size:80%;color:#FF0000;">-1.3</span><span id="A1.T12.2.2.2.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="A1.T12.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="A1.T12.2.2.3.1" class="ltx_text" style="font-size:80%;">70.1 (</span><span id="A1.T12.2.2.3.2" class="ltx_text" style="font-size:80%;color:#0000FF;">+2.0</span><span id="A1.T12.2.2.3.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="A1.T12.2.2.4" class="ltx_td ltx_align_center ltx_border_t">
<span id="A1.T12.2.2.4.1" class="ltx_text" style="font-size:80%;">74.1 (</span><span id="A1.T12.2.2.4.2" class="ltx_text" style="font-size:80%;color:#0000FF;">+0.8</span><span id="A1.T12.2.2.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
<tr id="A1.T12.3.8.5" class="ltx_tr" style="background-color:#E6E6E6;">
<th id="A1.T12.3.8.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" colspan="4">
<em id="A1.T12.3.8.5.1.1" class="ltx_emph ltx_font_bold ltx_font_italic" style="font-size:80%;background-color:#E6E6E6;">test</em><span id="A1.T12.3.8.5.1.2" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;"> set</span>
</th>
</tr>
<tr id="A1.T12.3.9.6" class="ltx_tr">
<th id="A1.T12.3.9.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="A1.T12.3.9.6.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span></th>
<td id="A1.T12.3.9.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="A1.T12.3.9.6.2.1" class="ltx_text" style="font-size:80%;">73.3</span></td>
<td id="A1.T12.3.9.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="A1.T12.3.9.6.3.1" class="ltx_text" style="font-size:80%;">68.7</span></td>
<td id="A1.T12.3.9.6.4" class="ltx_td ltx_align_center"><span id="A1.T12.3.9.6.4.1" class="ltx_text" style="font-size:80%;">71.9</span></td>
</tr>
<tr id="A1.T12.3.3" class="ltx_tr">
<th id="A1.T12.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t">
<span id="A1.T12.3.3.1.1" class="ltx_text" style="font-size:80%;">ConQueR</span><sub id="A1.T12.3.3.1.2" class="ltx_sub"><span id="A1.T12.3.3.1.2.1" class="ltx_text" style="font-size:80%;">nms</span></sub>
</th>
<td id="A1.T12.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="A1.T12.3.3.2.1" class="ltx_text" style="font-size:80%;">72.6 (</span><span id="A1.T12.3.3.2.2" class="ltx_text" style="font-size:80%;color:#FF0000;">-0.7</span><span id="A1.T12.3.3.2.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="A1.T12.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<span id="A1.T12.3.3.3.1" class="ltx_text" style="font-size:80%;">70.9 (</span><span id="A1.T12.3.3.3.2" class="ltx_text" style="font-size:80%;color:#0000FF;">+2.2</span><span id="A1.T12.3.3.3.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
<td id="A1.T12.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">
<span id="A1.T12.3.3.4.1" class="ltx_text" style="font-size:80%;">71.7 (</span><span id="A1.T12.3.3.4.2" class="ltx_text" style="font-size:80%;color:#FF0000;">-0.2</span><span id="A1.T12.3.3.4.3" class="ltx_text" style="font-size:80%;">)</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table"><span id="A1.T12.15.2.1" class="ltx_text" style="font-size:113%;">Table 12</span>: </span><span id="A1.T12.5.1" class="ltx_text" style="font-size:113%;">Effects of NMS. APH/L2 results are reported. The numbers in brackets indicates increase (<span id="A1.T12.5.1.1" class="ltx_text" style="color:#0000FF;">blue</span>) or drop (<span id="A1.T12.5.1.2" class="ltx_text" style="color:#FF0000;">red</span>) in detection performance. <sub id="A1.T12.5.1.3" class="ltx_sub">nms</sub> denotes further conducting NMS on their corresponding sparse predictions.</span></figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.07288" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.07289" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2212.07289">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.07289" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.07290" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 11:05:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
