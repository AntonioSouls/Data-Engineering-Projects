<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.11301] VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking</title><meta property="og:description" content="3D object detectors usually rely on hand-crafted proxies, e.g., anchors or centers, and translate well-studied 2D frameworks to 3D. Thus, sparse voxel features need to be densified and processed by dense prediction hea…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.11301">

<!--Generated on Thu Feb 29 19:22:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yukang Chen<sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">1</span></sup>,
   
Jianhui Liu<sup id="id10.10.id2" class="ltx_sup"><span id="id10.10.id2.1" class="ltx_text ltx_font_italic">2</span></sup>,   
Xiangyu Zhang<sup id="id11.11.id3" class="ltx_sup"><span id="id11.11.id3.1" class="ltx_text ltx_font_italic">3</span></sup>,   
Xiaojuan Qi<sup id="id12.12.id4" class="ltx_sup"><span id="id12.12.id4.1" class="ltx_text ltx_font_italic">2</span></sup>,   
Jiaya Jia<sup id="id13.13.id5" class="ltx_sup"><span id="id13.13.id5.1" class="ltx_text ltx_font_italic">1</span></sup>

<br class="ltx_break">
<sup id="id14.14.id6" class="ltx_sup">1</sup>The Chinese University of Hong Kong  
<sup id="id15.15.id7" class="ltx_sup">2</sup>The University of Hong Kong  
<sup id="id16.16.id8" class="ltx_sup">3</sup>MEGVII Technology
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id17.id1" class="ltx_p">3D object detectors usually rely on hand-crafted proxies, <span id="id17.id1.1" class="ltx_text ltx_font_italic">e.g.</span>, anchors or centers, and translate well-studied 2D frameworks to 3D. Thus, sparse voxel features need to be densified and processed by dense prediction heads, which inevitably costs extra computation.
In this paper, we instead propose VoxelNext for fully sparse 3D object detection. Our core insight is to predict objects directly based on sparse voxel features, without relying on hand-crafted proxies.
Our strong sparse convolutional network VoxelNeXt detects and tracks 3D objects through voxel features entirely. It is an elegant and efficient framework, with no need for sparse-to-dense conversion or NMS post-processing. Our method achieves a better speed-accuracy trade-off than other mainframe detectors on the nuScenes dataset.
For the first time, we show that a fully sparse voxel-based representation works decently for LIDAR 3D object detection and tracking. Extensive experiments on nuScenes, Waymo, and Argoverse2 benchmarks validate the effectiveness of our approach. Without bells and whistles, our model outperforms all existing LIDAR methods on the nuScenes tracking test benchmark. Code and models are available at <a target="_blank" href="https://github.com/dvlab-research/VoxelNeXt" title="" class="ltx_ref ltx_href">github.com/dvlab-research/VoxelNeXt</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">3D perception is a fundamental component in autonomous driving systems. 3D detection networks take sparse point clouds or voxels as input, and localize and categorize 3D objects. Recent 3D object detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> usually apply sparse convolutional networks (Sparse CNNs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> for feature extraction owing to its efficiency. Inspired by 2D object detection frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, anchors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> or centers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, dense point anchors in CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, are commonly utilized for prediction.
Both of them are hand-crafted and taken as intermediate proxies for 3D objects.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Anchors and centers are designed for regular and grid-structured image data in the first place, and do not consider sparsity and irregularity of 3D data. To employ these proxy representations, the main stream of detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> convert 3D sparse features to 2D dense features, so as to build a dense detection head for the ordered anchors or centers. Albeit useful, this dense head tradition leads to other limitations, including <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">inefficiency</span> and <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">complicated pipelines</span>, as explained below.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2303.11301/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="219" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.5.2.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2.1" class="ltx_text" style="font-size:90%;">Visualization of input and heatmaps of CenterPoint in BEV for <math id="S1.F1.3.2.1.m1.1" class="ltx_Math" alttext="Car" display="inline"><semantics id="S1.F1.3.2.1.m1.1b"><mrow id="S1.F1.3.2.1.m1.1.1" xref="S1.F1.3.2.1.m1.1.1.cmml"><mi id="S1.F1.3.2.1.m1.1.1.2" xref="S1.F1.3.2.1.m1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S1.F1.3.2.1.m1.1.1.1" xref="S1.F1.3.2.1.m1.1.1.1.cmml">​</mo><mi id="S1.F1.3.2.1.m1.1.1.3" xref="S1.F1.3.2.1.m1.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S1.F1.3.2.1.m1.1.1.1b" xref="S1.F1.3.2.1.m1.1.1.1.cmml">​</mo><mi id="S1.F1.3.2.1.m1.1.1.4" xref="S1.F1.3.2.1.m1.1.1.4.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.3.2.1.m1.1c"><apply id="S1.F1.3.2.1.m1.1.1.cmml" xref="S1.F1.3.2.1.m1.1.1"><times id="S1.F1.3.2.1.m1.1.1.1.cmml" xref="S1.F1.3.2.1.m1.1.1.1"></times><ci id="S1.F1.3.2.1.m1.1.1.2.cmml" xref="S1.F1.3.2.1.m1.1.1.2">𝐶</ci><ci id="S1.F1.3.2.1.m1.1.1.3.cmml" xref="S1.F1.3.2.1.m1.1.1.3">𝑎</ci><ci id="S1.F1.3.2.1.m1.1.1.4.cmml" xref="S1.F1.3.2.1.m1.1.1.4">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.3.2.1.m1.1d">Car</annotation></semantics></math>. Most values in the heatmaps are nearly zero, while the dense head computes over all BEV features, which is wasteful.</span></figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2303.11301/assets/x2.png" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="65" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.4.2" class="ltx_text" style="font-size:90%;">Pipelines of mainstream 3D object detectors and VoxelNeXt. These 3D detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> rely on sparse-to-dense conversion, anchors/centers, and dense heads with NMS. RoI pooling is an option for two-stage detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. In contrast, VoxelNeXt is a fully sparse convolutional network, which predicts results directly upon voxel features, with either fully connected layers or sparse convolutions.</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In Fig. <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we visualize the heatmap in CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. It is clear that a large portion of space has nearly zero prediction scores. Due to inherent sparsity and many background points, only a small number of points have responses, <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">i.e.</span>, less than 1% for <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">Car</span> class on average of nuScenes validation set. However, the dense prediction head computes over all positions in the feature map, as required by the dense convolution computation. They not only waste much computation, but also <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">complicate detection pipelines</span> with redundant predictions. It requires to use non-maximum suppression (NMS) like post-processing to remove duplicate detections, preventing the detector from being elegant. These limitations motivate us to seek alternative sparse detection solutions.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we instead propose <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">VoxelNeXt</span>. It is a simple, efficient, and post-processing-free 3D object detector. The core of our design is a voxel-to-object scheme, which directly predicts 3D objects from voxel features, with a strong fully sparse convolutional network.
The key advantage is that our approach can get rid of anchor proxies, sparse-to-dense conversion, region proposal networks, and other complicate components. We illustrates the pipelines of mainstream 3D detectors and ours in Fig. <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">High inference <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">efficiency</span> is due to our <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">voxel-to-object</span> scheme avoiding dense feature maps. It predicts only upon sparse and necessary locations, as listed in Tab. <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> with comparison to CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.
This representation also makes <span id="S1.p5.1.3" class="ltx_text ltx_font_italic">VoxelNeXt</span> easily extended to <span id="S1.p5.1.4" class="ltx_text ltx_font_italic">3D tracking</span> with an offline tracker. Previous work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> only tracks for the predicted object centers, which might involve prediction bias to its positions. In VoxelNeXt, the <span id="S1.p5.1.5" class="ltx_text ltx_font_italic">query voxels</span>, <span id="S1.p5.1.6" class="ltx_text ltx_font_italic">i.e.</span>, the voxels for box prediction, can also be tracked for association.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Recently, FSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> exploits the fully sparse framework. Motivated by VoteNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, it votes for object centers and resorts to iterative refinement.
Since 3D sparse data is generally scattered on object surfaces, this voting process inevitably introduces bias or error. Consequently, refinement, such as iterative group correction, is needed to ensure final accuracy. The system is complicated by its heavy belief in object centers. FSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> is promising at the large-range Argoverse2, while its efficiency is inferior to ours, as in Fig. <a href="#S2.F3" title="Figure 3 ‣ 2 Related Work ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">To demonstrate the effectiveness of VoxelNeXt, we evaluate our models on three large-scale benchmarks of nuScenes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, Waymo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, Argoverse2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> datasets. VoxelNeXt achieves leading performance with high efficiency on 3D object detection on both these benchmarks. It also yields state-of-the-art performance on 3D tracking. Without bells and whistles, it ranks 1<sup id="S1.p7.1.1" class="ltx_sup"><span id="S1.p7.1.1.1" class="ltx_text ltx_font_italic">st</span></sup> among all LIDAR-only entries on the nuScenes tracking test split <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">LIDAR Detectors</span>
3D detectors usually work similar to their 2D counterparts, such as R-CNN series <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> and CenterPoint series <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. 3D detection distinguishes from the 2D task due to the sparsity of data distribution. But many approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> still seek 2D dense convolutional heads as a solution.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">Comparison with CenterPoint on nuScenes dataset. VoxelNeXt presents better performance with high efficiency.</span></figcaption>
<div id="S2.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:398.9pt;height:89.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(39.0pt,-8.8pt) scale(1.24315927764121,1.24315927764121) ;">
<table id="S2.T1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<td id="S2.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S2.T1.4.1.1.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S2.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S2.T1.4.1.1.2.1" class="ltx_text">mAP</span></td>
<td id="S2.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S2.T1.4.1.1.3.1" class="ltx_text">NDS</span></td>
<td id="S2.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">FLOPs</td>
</tr>
<tr id="S2.T1.4.1.2" class="ltx_tr">
<td id="S2.T1.4.1.2.1" class="ltx_td ltx_align_center">Sparse CNN</td>
<td id="S2.T1.4.1.2.2" class="ltx_td ltx_align_center ltx_border_r">Head</td>
</tr>
<tr id="S2.T1.4.1.3" class="ltx_tr">
<td id="S2.T1.4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S2.T1.4.1.3.2" class="ltx_td ltx_align_center ltx_border_t">58.6</td>
<td id="S2.T1.4.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.2</td>
<td id="S2.T1.4.1.3.4" class="ltx_td ltx_align_center ltx_border_t">62.9 G</td>
<td id="S2.T1.4.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">123.7 G</td>
</tr>
<tr id="S2.T1.4.1.4" class="ltx_tr">
<td id="S2.T1.4.1.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt</td>
<td id="S2.T1.4.1.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S2.T1.4.1.4.2.1" class="ltx_text ltx_font_bold">60.0</span></td>
<td id="S2.T1.4.1.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S2.T1.4.1.4.3.1" class="ltx_text ltx_font_bold">67.1</span></td>
<td id="S2.T1.4.1.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S2.T1.4.1.4.4.1" class="ltx_text ltx_font_bold">33.6 G</span></td>
<td id="S2.T1.4.1.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S2.T1.4.1.4.5.1" class="ltx_text ltx_font_bold">5.1 G</span></td>
</tr>
</table>
</span></div>
</figure>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2303.11301/assets/x3.png" id="S2.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="165" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.4.2" class="ltx_text" style="font-size:90%;">Latency on Argoverse2 and various perception ranges.</span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">VoxelNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> uses PointNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> for voxel feature encoding and then applies dense region proposal network and head for prediction. SECOND <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> improves VoxelNet by efficient sparse convolutions with the dense anchor-based head. Other state-of-the-art methods, including PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, Voxel R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and VoTr <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, still keep the sparse-to-dense scheme to enlarge the receptive field.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Motivated by 2D CenterNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> is applied to 3D detection and tracking. It converts the sparse output of a backbone network into a map-view dense feature map and predicts a dense heatmap of the center locations of objects, based on the dense feature. This dense center-based prediction has been adopted by several dense-head approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. In this paper, we take a new direction and surprisingly show that a simple and strong sparse CNN is sufficient for direct prediction. The notable finding is that the dense head is not always necessary.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Sparse Detectors</span>
Methods of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> avoid dense detection heads and instead introduce other complicated pipelines. RSN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> performs foreground segmentation on range images and then detects 3D objects on the remained sparse data. SWFormer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> proposes a sparse transformer with delicate window splitting and multiple heads with feature pyramids. Motivated by VoteNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, FSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
use point clustering and group correction to solve the issue of center feature missing. These detectors conduct sparse prediction, but complicate detection pipelines in different ways. In our work, this center-missing issue can also be simply skipped through sparse networks that have large receptive fields. We make minimal adaptations to commonly-used sparse CNNs to realize fully sparse detectors.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Sparse Convolutional Networks</span>
Sparse CNNs become mainframe backbone networks in 3D deep learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> for its efficiency. It is common wisdom that its representation ability is limited for prediction. To remedy it, 3D detectors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> rely on dense convolutional heads for feature enhancement. Recent methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> make convolutional modifications upon sparse CNNs. Approaches of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> even substitute it with transformers for large receptive fields. Contrary to all these solutions, we demonstrate that the insufficient receptive field bottleneck can be simply addressed by additional down-sampling layers without any other complicated design.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2303.11301/assets/x4.png" id="S2.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="171" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.9.4.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S2.F4.7.6.3" class="ltx_text" style="font-size:90%;">Detailed structure of VoxelNeXt framework. Circled numbers in the figure correspond to the paragraphs in Sections <a href="#S3.SS1" title="3.1 Sparse CNN Backbone Adaptation ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> and <a href="#S3.SS2" title="3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. 1 - Additional down-samplings. 2 - Sparse height compression. 3 - Voxel selection. 4 - Box regression.
We omit the generation of <math id="S2.F4.5.4.1.m1.1" class="ltx_Math" alttext="F_{1}" display="inline"><semantics id="S2.F4.5.4.1.m1.1b"><msub id="S2.F4.5.4.1.m1.1.1" xref="S2.F4.5.4.1.m1.1.1.cmml"><mi id="S2.F4.5.4.1.m1.1.1.2" xref="S2.F4.5.4.1.m1.1.1.2.cmml">F</mi><mn id="S2.F4.5.4.1.m1.1.1.3" xref="S2.F4.5.4.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F4.5.4.1.m1.1c"><apply id="S2.F4.5.4.1.m1.1.1.cmml" xref="S2.F4.5.4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.F4.5.4.1.m1.1.1.1.cmml" xref="S2.F4.5.4.1.m1.1.1">subscript</csymbol><ci id="S2.F4.5.4.1.m1.1.1.2.cmml" xref="S2.F4.5.4.1.m1.1.1.2">𝐹</ci><cn type="integer" id="S2.F4.5.4.1.m1.1.1.3.cmml" xref="S2.F4.5.4.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.5.4.1.m1.1d">F_{1}</annotation></semantics></math>, <math id="S2.F4.6.5.2.m2.1" class="ltx_Math" alttext="F_{2}" display="inline"><semantics id="S2.F4.6.5.2.m2.1b"><msub id="S2.F4.6.5.2.m2.1.1" xref="S2.F4.6.5.2.m2.1.1.cmml"><mi id="S2.F4.6.5.2.m2.1.1.2" xref="S2.F4.6.5.2.m2.1.1.2.cmml">F</mi><mn id="S2.F4.6.5.2.m2.1.1.3" xref="S2.F4.6.5.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F4.6.5.2.m2.1c"><apply id="S2.F4.6.5.2.m2.1.1.cmml" xref="S2.F4.6.5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.F4.6.5.2.m2.1.1.1.cmml" xref="S2.F4.6.5.2.m2.1.1">subscript</csymbol><ci id="S2.F4.6.5.2.m2.1.1.2.cmml" xref="S2.F4.6.5.2.m2.1.1.2">𝐹</ci><cn type="integer" id="S2.F4.6.5.2.m2.1.1.3.cmml" xref="S2.F4.6.5.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.6.5.2.m2.1d">F_{2}</annotation></semantics></math>, and <math id="S2.F4.7.6.3.m3.1" class="ltx_Math" alttext="F_{3}" display="inline"><semantics id="S2.F4.7.6.3.m3.1b"><msub id="S2.F4.7.6.3.m3.1.1" xref="S2.F4.7.6.3.m3.1.1.cmml"><mi id="S2.F4.7.6.3.m3.1.1.2" xref="S2.F4.7.6.3.m3.1.1.2.cmml">F</mi><mn id="S2.F4.7.6.3.m3.1.1.3" xref="S2.F4.7.6.3.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S2.F4.7.6.3.m3.1c"><apply id="S2.F4.7.6.3.m3.1.1.cmml" xref="S2.F4.7.6.3.m3.1.1"><csymbol cd="ambiguous" id="S2.F4.7.6.3.m3.1.1.1.cmml" xref="S2.F4.7.6.3.m3.1.1">subscript</csymbol><ci id="S2.F4.7.6.3.m3.1.1.2.cmml" xref="S2.F4.7.6.3.m3.1.1.2">𝐹</ci><cn type="integer" id="S2.F4.7.6.3.m3.1.1.3.cmml" xref="S2.F4.7.6.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F4.7.6.3.m3.1d">F_{3}</annotation></semantics></math> here for the simplicity sake.</span></figcaption>
</figure>
<div id="S2.p6" class="ltx_para ltx_noindent">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">3D Object Tracking</span>
3D object tracking models tracklets of multiple objects along multi-frame LIDAR. Most previous methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> directly use the Kalman filter upon detection results, such as AB3DMOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> predicts the velocities to associate object centers through multiple frames, following CenterTrack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. In this paper, we include query voxels for association, which effectively relieve the prediction bias of object centers.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Fully Sparse Voxel-based Network</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Point clouds or voxels are irregularly distributed and usually scattered at the surface of 3D objects, not at the center or inside. This motivates us to study along a new direction to <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">predict 3D boxes directly based on the voxels</span> instead of the hand-crafted anchors or centers.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">To this end, we aim for <span id="S3.p2.1.1" class="ltx_text ltx_font_italic">minimal modification</span> to adapt a plain 3D sparse CNN network to the direct-voxel prediction. In the following, we introduce the backbone adaptation (Section <a href="#S3.SS1" title="3.1 Sparse CNN Backbone Adaptation ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), the sparse head design (Section <a href="#S3.SS2" title="3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>), and the extension to 3D object tracking (Section <a href="#S3.SS3" title="3.3 3D Tracking ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2303.11301/assets/x5.png" id="S3.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="235" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.4.2" class="ltx_text" style="font-size:90%;">Effects of additional down-sampling layers on effective receptive fields (ERFs) and the predicted boxes.</span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Sparse CNN Backbone Adaptation</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">Additional Down-sampling</span>
Strong feature representation with sufficient receptive fields is a must to ensure direct and correct prediction upon sparse voxel features.
Although the plain sparse CNN backbone network has been widely used in 3D object detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, recent work presents its weakness and proposes various methods to enhance the sparse backbone using, <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">e.g.</span>, well-designed convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, large kernels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, and transformers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.14" class="ltx_p">Unlike all these approaches, we make as little as possible modification to accomplish this, only using additional down-sampling layers. By default, the plain sparse CNN backbone network has 4 stages, with the feature strides {1, 2, 4, 8}. We name the output sparse features {<math id="S3.SS1.p2.1.m1.4" class="ltx_Math" alttext="F_{1},F_{2},F_{3},F_{4}" display="inline"><semantics id="S3.SS1.p2.1.m1.4a"><mrow id="S3.SS1.p2.1.m1.4.4.4" xref="S3.SS1.p2.1.m1.4.4.5.cmml"><msub id="S3.SS1.p2.1.m1.1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.1.1.2.cmml">F</mi><mn id="S3.SS1.p2.1.m1.1.1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p2.1.m1.4.4.4.5" xref="S3.SS1.p2.1.m1.4.4.5.cmml">,</mo><msub id="S3.SS1.p2.1.m1.2.2.2.2" xref="S3.SS1.p2.1.m1.2.2.2.2.cmml"><mi id="S3.SS1.p2.1.m1.2.2.2.2.2" xref="S3.SS1.p2.1.m1.2.2.2.2.2.cmml">F</mi><mn id="S3.SS1.p2.1.m1.2.2.2.2.3" xref="S3.SS1.p2.1.m1.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p2.1.m1.4.4.4.6" xref="S3.SS1.p2.1.m1.4.4.5.cmml">,</mo><msub id="S3.SS1.p2.1.m1.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.3.cmml"><mi id="S3.SS1.p2.1.m1.3.3.3.3.2" xref="S3.SS1.p2.1.m1.3.3.3.3.2.cmml">F</mi><mn id="S3.SS1.p2.1.m1.3.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.3.3.cmml">3</mn></msub><mo id="S3.SS1.p2.1.m1.4.4.4.7" xref="S3.SS1.p2.1.m1.4.4.5.cmml">,</mo><msub id="S3.SS1.p2.1.m1.4.4.4.4" xref="S3.SS1.p2.1.m1.4.4.4.4.cmml"><mi id="S3.SS1.p2.1.m1.4.4.4.4.2" xref="S3.SS1.p2.1.m1.4.4.4.4.2.cmml">F</mi><mn id="S3.SS1.p2.1.m1.4.4.4.4.3" xref="S3.SS1.p2.1.m1.4.4.4.4.3.cmml">4</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.4b"><list id="S3.SS1.p2.1.m1.4.4.5.cmml" xref="S3.SS1.p2.1.m1.4.4.4"><apply id="S3.SS1.p2.1.m1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p2.1.m1.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.2.2.2.2.1.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.1.m1.2.2.2.2.3.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2.3">2</cn></apply><apply id="S3.SS1.p2.1.m1.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.3.3.3.3.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.1.m1.3.3.3.3.2.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.1.m1.3.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3.3">3</cn></apply><apply id="S3.SS1.p2.1.m1.4.4.4.4.cmml" xref="S3.SS1.p2.1.m1.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.4.4.4.4.1.cmml" xref="S3.SS1.p2.1.m1.4.4.4.4">subscript</csymbol><ci id="S3.SS1.p2.1.m1.4.4.4.4.2.cmml" xref="S3.SS1.p2.1.m1.4.4.4.4.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.1.m1.4.4.4.4.3.cmml" xref="S3.SS1.p2.1.m1.4.4.4.4.3">4</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.4c">F_{1},F_{2},F_{3},F_{4}</annotation></semantics></math>} respectively. This setting is incapable of direct prediction, especially for large objects. To enhance its ability, we simply include two additional down-sampling layers to obtain features with strides {16, 32} for {<math id="S3.SS1.p2.2.m2.2" class="ltx_Math" alttext="F_{5},F_{6}" display="inline"><semantics id="S3.SS1.p2.2.m2.2a"><mrow id="S3.SS1.p2.2.m2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.3.cmml"><msub id="S3.SS1.p2.2.m2.1.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.1.1.2" xref="S3.SS1.p2.2.m2.1.1.1.1.2.cmml">F</mi><mn id="S3.SS1.p2.2.m2.1.1.1.1.3" xref="S3.SS1.p2.2.m2.1.1.1.1.3.cmml">5</mn></msub><mo id="S3.SS1.p2.2.m2.2.2.2.3" xref="S3.SS1.p2.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS1.p2.2.m2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.2.cmml"><mi id="S3.SS1.p2.2.m2.2.2.2.2.2" xref="S3.SS1.p2.2.m2.2.2.2.2.2.cmml">F</mi><mn id="S3.SS1.p2.2.m2.2.2.2.2.3" xref="S3.SS1.p2.2.m2.2.2.2.2.3.cmml">6</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.2b"><list id="S3.SS1.p2.2.m2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2"><apply id="S3.SS1.p2.2.m2.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.2.m2.1.1.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.1.1.3">5</cn></apply><apply id="S3.SS1.p2.2.m2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.2.2.2.2.1.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.2.m2.2.2.2.2.3.cmml" xref="S3.SS1.p2.2.m2.2.2.2.2.3">6</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.2c">F_{5},F_{6}</annotation></semantics></math>}. This small change directly imposes notable effects to enlarge receptive fields. We combine the sparse features from the last three stages {<math id="S3.SS1.p2.3.m3.3" class="ltx_Math" alttext="F_{4},F_{5},F_{6}" display="inline"><semantics id="S3.SS1.p2.3.m3.3a"><mrow id="S3.SS1.p2.3.m3.3.3.3" xref="S3.SS1.p2.3.m3.3.3.4.cmml"><msub id="S3.SS1.p2.3.m3.1.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.1.1.2" xref="S3.SS1.p2.3.m3.1.1.1.1.2.cmml">F</mi><mn id="S3.SS1.p2.3.m3.1.1.1.1.3" xref="S3.SS1.p2.3.m3.1.1.1.1.3.cmml">4</mn></msub><mo id="S3.SS1.p2.3.m3.3.3.3.4" xref="S3.SS1.p2.3.m3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.3.m3.2.2.2.2" xref="S3.SS1.p2.3.m3.2.2.2.2.cmml"><mi id="S3.SS1.p2.3.m3.2.2.2.2.2" xref="S3.SS1.p2.3.m3.2.2.2.2.2.cmml">F</mi><mn id="S3.SS1.p2.3.m3.2.2.2.2.3" xref="S3.SS1.p2.3.m3.2.2.2.2.3.cmml">5</mn></msub><mo id="S3.SS1.p2.3.m3.3.3.3.5" xref="S3.SS1.p2.3.m3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.3.m3.3.3.3.3" xref="S3.SS1.p2.3.m3.3.3.3.3.cmml"><mi id="S3.SS1.p2.3.m3.3.3.3.3.2" xref="S3.SS1.p2.3.m3.3.3.3.3.2.cmml">F</mi><mn id="S3.SS1.p2.3.m3.3.3.3.3.3" xref="S3.SS1.p2.3.m3.3.3.3.3.3.cmml">6</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.3b"><list id="S3.SS1.p2.3.m3.3.3.4.cmml" xref="S3.SS1.p2.3.m3.3.3.3"><apply id="S3.SS1.p2.3.m3.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.1.1.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.1.1.3">4</cn></apply><apply id="S3.SS1.p2.3.m3.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.p2.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p2.3.m3.2.2.2.2.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.p2.3.m3.2.2.2.2.3">5</cn></apply><apply id="S3.SS1.p2.3.m3.3.3.3.3.cmml" xref="S3.SS1.p2.3.m3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.3.3.3.3.1.cmml" xref="S3.SS1.p2.3.m3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.3.m3.3.3.3.3.2.cmml" xref="S3.SS1.p2.3.m3.3.3.3.3.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.3.m3.3.3.3.3.3.cmml" xref="S3.SS1.p2.3.m3.3.3.3.3.3">6</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.3c">F_{4},F_{5},F_{6}</annotation></semantics></math>} to <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="F_{c}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">F</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">𝐹</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">F_{c}</annotation></semantics></math>. Their spatial resolutions are all aligned to <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="F_{4}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">F</mi><mn id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">𝐹</ci><cn type="integer" id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">F_{4}</annotation></semantics></math>. For stage <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">i</annotation></semantics></math>, <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="F_{i}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><msub id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">F</mi><mi id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">𝐹</ci><ci id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">F_{i}</annotation></semantics></math> is a set of individual features <math id="S3.SS1.p2.8.m8.1" class="ltx_Math" alttext="f_{p}" display="inline"><semantics id="S3.SS1.p2.8.m8.1a"><msub id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml"><mi id="S3.SS1.p2.8.m8.1.1.2" xref="S3.SS1.p2.8.m8.1.1.2.cmml">f</mi><mi id="S3.SS1.p2.8.m8.1.1.3" xref="S3.SS1.p2.8.m8.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><apply id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.p2.8.m8.1.1.2">𝑓</ci><ci id="S3.SS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.p2.8.m8.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">f_{p}</annotation></semantics></math>. <math id="S3.SS1.p2.9.m9.1" class="ltx_Math" alttext="p\in P_{i}" display="inline"><semantics id="S3.SS1.p2.9.m9.1a"><mrow id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml"><mi id="S3.SS1.p2.9.m9.1.1.2" xref="S3.SS1.p2.9.m9.1.1.2.cmml">p</mi><mo id="S3.SS1.p2.9.m9.1.1.1" xref="S3.SS1.p2.9.m9.1.1.1.cmml">∈</mo><msub id="S3.SS1.p2.9.m9.1.1.3" xref="S3.SS1.p2.9.m9.1.1.3.cmml"><mi id="S3.SS1.p2.9.m9.1.1.3.2" xref="S3.SS1.p2.9.m9.1.1.3.2.cmml">P</mi><mi id="S3.SS1.p2.9.m9.1.1.3.3" xref="S3.SS1.p2.9.m9.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><apply id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1"><in id="S3.SS1.p2.9.m9.1.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1.1"></in><ci id="S3.SS1.p2.9.m9.1.1.2.cmml" xref="S3.SS1.p2.9.m9.1.1.2">𝑝</ci><apply id="S3.SS1.p2.9.m9.1.1.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.9.m9.1.1.3.1.cmml" xref="S3.SS1.p2.9.m9.1.1.3">subscript</csymbol><ci id="S3.SS1.p2.9.m9.1.1.3.2.cmml" xref="S3.SS1.p2.9.m9.1.1.3.2">𝑃</ci><ci id="S3.SS1.p2.9.m9.1.1.3.3.cmml" xref="S3.SS1.p2.9.m9.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">p\in P_{i}</annotation></semantics></math> is a position in 3D space, with the coordinate (<math id="S3.SS1.p2.10.m10.1" class="ltx_Math" alttext="x_{p}" display="inline"><semantics id="S3.SS1.p2.10.m10.1a"><msub id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml"><mi id="S3.SS1.p2.10.m10.1.1.2" xref="S3.SS1.p2.10.m10.1.1.2.cmml">x</mi><mi id="S3.SS1.p2.10.m10.1.1.3" xref="S3.SS1.p2.10.m10.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><apply id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.p2.10.m10.1.1.2">𝑥</ci><ci id="S3.SS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.p2.10.m10.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">x_{p}</annotation></semantics></math>, <math id="S3.SS1.p2.11.m11.1" class="ltx_Math" alttext="y_{p}" display="inline"><semantics id="S3.SS1.p2.11.m11.1a"><msub id="S3.SS1.p2.11.m11.1.1" xref="S3.SS1.p2.11.m11.1.1.cmml"><mi id="S3.SS1.p2.11.m11.1.1.2" xref="S3.SS1.p2.11.m11.1.1.2.cmml">y</mi><mi id="S3.SS1.p2.11.m11.1.1.3" xref="S3.SS1.p2.11.m11.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.11.m11.1b"><apply id="S3.SS1.p2.11.m11.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.11.m11.1.1.1.cmml" xref="S3.SS1.p2.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.p2.11.m11.1.1.2.cmml" xref="S3.SS1.p2.11.m11.1.1.2">𝑦</ci><ci id="S3.SS1.p2.11.m11.1.1.3.cmml" xref="S3.SS1.p2.11.m11.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.11.m11.1c">y_{p}</annotation></semantics></math>, <math id="S3.SS1.p2.12.m12.1" class="ltx_Math" alttext="z_{p}" display="inline"><semantics id="S3.SS1.p2.12.m12.1a"><msub id="S3.SS1.p2.12.m12.1.1" xref="S3.SS1.p2.12.m12.1.1.cmml"><mi id="S3.SS1.p2.12.m12.1.1.2" xref="S3.SS1.p2.12.m12.1.1.2.cmml">z</mi><mi id="S3.SS1.p2.12.m12.1.1.3" xref="S3.SS1.p2.12.m12.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.12.m12.1b"><apply id="S3.SS1.p2.12.m12.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.12.m12.1.1.1.cmml" xref="S3.SS1.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS1.p2.12.m12.1.1.2.cmml" xref="S3.SS1.p2.12.m12.1.1.2">𝑧</ci><ci id="S3.SS1.p2.12.m12.1.1.3.cmml" xref="S3.SS1.p2.12.m12.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.12.m12.1c">z_{p}</annotation></semantics></math>). This process is shown in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2 Related Work ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. It is noteworthy that this simple sparse concatenation requires no other parameterized layers.
Sparse features <math id="S3.SS1.p2.13.m13.1" class="ltx_Math" alttext="F_{c}" display="inline"><semantics id="S3.SS1.p2.13.m13.1a"><msub id="S3.SS1.p2.13.m13.1.1" xref="S3.SS1.p2.13.m13.1.1.cmml"><mi id="S3.SS1.p2.13.m13.1.1.2" xref="S3.SS1.p2.13.m13.1.1.2.cmml">F</mi><mi id="S3.SS1.p2.13.m13.1.1.3" xref="S3.SS1.p2.13.m13.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.13.m13.1b"><apply id="S3.SS1.p2.13.m13.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.13.m13.1.1.1.cmml" xref="S3.SS1.p2.13.m13.1.1">subscript</csymbol><ci id="S3.SS1.p2.13.m13.1.1.2.cmml" xref="S3.SS1.p2.13.m13.1.1.2">𝐹</ci><ci id="S3.SS1.p2.13.m13.1.1.3.cmml" xref="S3.SS1.p2.13.m13.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.13.m13.1c">F_{c}</annotation></semantics></math> and their positions <math id="S3.SS1.p2.14.m14.1" class="ltx_Math" alttext="P_{c}" display="inline"><semantics id="S3.SS1.p2.14.m14.1a"><msub id="S3.SS1.p2.14.m14.1.1" xref="S3.SS1.p2.14.m14.1.1.cmml"><mi id="S3.SS1.p2.14.m14.1.1.2" xref="S3.SS1.p2.14.m14.1.1.2.cmml">P</mi><mi id="S3.SS1.p2.14.m14.1.1.3" xref="S3.SS1.p2.14.m14.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.14.m14.1b"><apply id="S3.SS1.p2.14.m14.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.14.m14.1.1.1.cmml" xref="S3.SS1.p2.14.m14.1.1">subscript</csymbol><ci id="S3.SS1.p2.14.m14.1.1.2.cmml" xref="S3.SS1.p2.14.m14.1.1.2">𝑃</ci><ci id="S3.SS1.p2.14.m14.1.1.3.cmml" xref="S3.SS1.p2.14.m14.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.14.m14.1c">P_{c}</annotation></semantics></math>
are obtained as</p>
<table id="S3.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle{F}_{c}=F_{4}\cup(F_{5}\cup F_{6}),\qquad" display="inline"><semantics id="S3.E1X.2.1.1.m1.1a"><mrow id="S3.E1X.2.1.1.m1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E1X.2.1.1.m1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.2.cmml">F</mi><mi id="S3.E1X.2.1.1.m1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.3.cmml">c</mi></msub><mo id="S3.E1X.2.1.1.m1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2.cmml">F</mi><mn id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3.cmml">4</mn></msub><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml">∪</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml">F</mi><mn id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml">5</mn></msub><mo id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">∪</mo><msub id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml">F</mi><mn id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml">6</mn></msub></mrow><mo stretchy="false" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E1X.2.1.1.m1.1.1.1.2" xref="S3.E1X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1X.2.1.1.m1.1b"><apply id="S3.E1X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1"><eq id="S3.E1X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.2"></eq><apply id="S3.E1X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.2">𝐹</ci><ci id="S3.E1X.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.3.3">𝑐</ci></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1"><union id="S3.E1X.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.2"></union><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.2">𝐹</ci><cn type="integer" id="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.3.3">4</cn></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1"><union id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.1"></union><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.2">𝐹</ci><cn type="integer" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.2.3">5</cn></apply><apply id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.2">𝐹</ci><cn type="integer" id="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1X.2.1.1.m1.1.1.1.1.1.1.1.1.3.3">6</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1X.2.1.1.m1.1c">\displaystyle{F}_{c}=F_{4}\cup(F_{5}\cup F_{6}),\qquad</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="4" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr id="S3.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xa.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle P_{6}^{\prime}=\{(x_{p}\times 2^{2},\,y_{p}\times 2^{2},\,z_{p}\times 2^{2})\,|\,p\in P_{6}\}" display="inline"><semantics id="S3.E1Xa.2.1.1.m1.2a"><mrow id="S3.E1Xa.2.1.1.m1.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.cmml"><msubsup id="S3.E1Xa.2.1.1.m1.2.2.4" xref="S3.E1Xa.2.1.1.m1.2.2.4.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.4.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.4.2.2.cmml">P</mi><mn id="S3.E1Xa.2.1.1.m1.2.2.4.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.4.2.3.cmml">6</mn><mo id="S3.E1Xa.2.1.1.m1.2.2.4.3" xref="S3.E1Xa.2.1.1.m1.2.2.4.3.cmml">′</mo></msubsup><mo id="S3.E1Xa.2.1.1.m1.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E1Xa.2.1.1.m1.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1Xa.2.1.1.m1.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.3.1.cmml">{</mo><mrow id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.4.cmml"><mo stretchy="false" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.4" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.4.cmml">(</mo><mrow id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3.cmml">p</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">×</mo><msup id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.cmml"><mn id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.2.cmml">2</mn><mn id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.3.cmml">2</mn></msup></mrow><mo rspace="0.337em" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.5" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.4.cmml">,</mo><mrow id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.cmml"><msub id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.2.cmml">y</mi><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml">p</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.1" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.1.cmml">×</mo><msup id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.cmml"><mn id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml">2</mn><mn id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml">2</mn></msup></mrow><mo rspace="0.337em" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.6" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.4.cmml">,</mo><mrow id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.cmml"><msub id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.cmml"><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.2.cmml">z</mi><mi id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.3.cmml">p</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.1" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.1.cmml">×</mo><msup id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.cmml"><mn id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.2" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.2.cmml">2</mn><mn id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.3" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.3.cmml">2</mn></msup></mrow><mo stretchy="false" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.7" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.4.cmml">)</mo></mrow><mo lspace="0.170em" rspace="0.170em" id="S3.E1Xa.2.1.1.m1.2.2.2.2.4" xref="S3.E1Xa.2.1.1.m1.2.2.2.3.1.cmml">|</mo><mrow id="S3.E1Xa.2.1.1.m1.2.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.cmml">p</mi><mo id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.1" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.1.cmml">∈</mo><msub id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.cmml"><mi id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.2" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.2.cmml">P</mi><mn id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.3" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.3.cmml">6</mn></msub></mrow><mo stretchy="false" id="S3.E1Xa.2.1.1.m1.2.2.2.2.5" xref="S3.E1Xa.2.1.1.m1.2.2.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1Xa.2.1.1.m1.2b"><apply id="S3.E1Xa.2.1.1.m1.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2"><eq id="S3.E1Xa.2.1.1.m1.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.3"></eq><apply id="S3.E1Xa.2.1.1.m1.2.2.4.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.4.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4">superscript</csymbol><apply id="S3.E1Xa.2.1.1.m1.2.2.4.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.4.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.2.2.4.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.2.2">𝑃</ci><cn type="integer" id="S3.E1Xa.2.1.1.m1.2.2.4.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.2.3">6</cn></apply><ci id="S3.E1Xa.2.1.1.m1.2.2.4.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.4.3">′</ci></apply><apply id="S3.E1Xa.2.1.1.m1.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2"><csymbol cd="latexml" id="S3.E1Xa.2.1.1.m1.2.2.2.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.3">conditional-set</csymbol><vector id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.4.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3"><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1"><times id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.1"></times><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3">𝑝</ci></apply><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3">superscript</csymbol><cn type="integer" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.2">2</cn><cn type="integer" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.1.1.3.3">2</cn></apply></apply><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2"><times id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.1"></times><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.2">𝑦</ci><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.2.3">𝑝</ci></apply><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3">superscript</csymbol><cn type="integer" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.2">2</cn><cn type="integer" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.2.2.3.3">2</cn></apply></apply><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3"><times id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.1"></times><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.2">𝑧</ci><ci id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.2.3">𝑝</ci></apply><apply id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3">superscript</csymbol><cn type="integer" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.2">2</cn><cn type="integer" id="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.1.1.1.1.1.3.3.3.3">2</cn></apply></apply></vector><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2"><in id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.1"></in><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.2">𝑝</ci><apply id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.2">𝑃</ci><cn type="integer" id="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.3.cmml" xref="S3.E1Xa.2.1.1.m1.2.2.2.2.2.3.3">6</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xa.2.1.1.m1.2c">\displaystyle P_{6}^{\prime}=\{(x_{p}\times 2^{2},\,y_{p}\times 2^{2},\,z_{p}\times 2^{2})\,|\,p\in P_{6}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S3.E1Xb" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xb.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle P_{5}^{\prime}=\{(x_{p}\times 2^{1},\,y_{p}\times 2^{1},\,z_{p}\times 2^{1})\,|\,p\in P_{5}\}" display="inline"><semantics id="S3.E1Xb.2.1.1.m1.2a"><mrow id="S3.E1Xb.2.1.1.m1.2.2" xref="S3.E1Xb.2.1.1.m1.2.2.cmml"><msubsup id="S3.E1Xb.2.1.1.m1.2.2.4" xref="S3.E1Xb.2.1.1.m1.2.2.4.cmml"><mi id="S3.E1Xb.2.1.1.m1.2.2.4.2.2" xref="S3.E1Xb.2.1.1.m1.2.2.4.2.2.cmml">P</mi><mn id="S3.E1Xb.2.1.1.m1.2.2.4.2.3" xref="S3.E1Xb.2.1.1.m1.2.2.4.2.3.cmml">5</mn><mo id="S3.E1Xb.2.1.1.m1.2.2.4.3" xref="S3.E1Xb.2.1.1.m1.2.2.4.3.cmml">′</mo></msubsup><mo id="S3.E1Xb.2.1.1.m1.2.2.3" xref="S3.E1Xb.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E1Xb.2.1.1.m1.2.2.2.2" xref="S3.E1Xb.2.1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E1Xb.2.1.1.m1.2.2.2.2.3" xref="S3.E1Xb.2.1.1.m1.2.2.2.3.1.cmml">{</mo><mrow id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.4.cmml"><mo stretchy="false" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.4" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.4.cmml">(</mo><mrow id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.3.cmml">p</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">×</mo><msup id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.cmml"><mn id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2.cmml">2</mn><mn id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3.cmml">1</mn></msup></mrow><mo rspace="0.337em" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.5" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.4.cmml">,</mo><mrow id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.cmml"><msub id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.2.cmml">y</mi><mi id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml">p</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.1" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.1.cmml">×</mo><msup id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.cmml"><mn id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml">2</mn><mn id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml">1</mn></msup></mrow><mo rspace="0.337em" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.6" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.4.cmml">,</mo><mrow id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.cmml"><msub id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.cmml"><mi id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.2.cmml">z</mi><mi id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.3.cmml">p</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.1" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.1.cmml">×</mo><msup id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.cmml"><mn id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.2" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.2.cmml">2</mn><mn id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.3" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.3.cmml">1</mn></msup></mrow><mo stretchy="false" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.7" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.4.cmml">)</mo></mrow><mo lspace="0.170em" rspace="0.170em" id="S3.E1Xb.2.1.1.m1.2.2.2.2.4" xref="S3.E1Xb.2.1.1.m1.2.2.2.3.1.cmml">|</mo><mrow id="S3.E1Xb.2.1.1.m1.2.2.2.2.2" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.cmml"><mi id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.2" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.2.cmml">p</mi><mo id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.1" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.1.cmml">∈</mo><msub id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.cmml"><mi id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.2" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.2.cmml">P</mi><mn id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.3" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.3.cmml">5</mn></msub></mrow><mo stretchy="false" id="S3.E1Xb.2.1.1.m1.2.2.2.2.5" xref="S3.E1Xb.2.1.1.m1.2.2.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1Xb.2.1.1.m1.2b"><apply id="S3.E1Xb.2.1.1.m1.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.2.2"><eq id="S3.E1Xb.2.1.1.m1.2.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.3"></eq><apply id="S3.E1Xb.2.1.1.m1.2.2.4.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.2.2.4.1.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4">superscript</csymbol><apply id="S3.E1Xb.2.1.1.m1.2.2.4.2.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.2.2.4.2.1.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4">subscript</csymbol><ci id="S3.E1Xb.2.1.1.m1.2.2.4.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4.2.2">𝑃</ci><cn type="integer" id="S3.E1Xb.2.1.1.m1.2.2.4.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4.2.3">5</cn></apply><ci id="S3.E1Xb.2.1.1.m1.2.2.4.3.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.4.3">′</ci></apply><apply id="S3.E1Xb.2.1.1.m1.2.2.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2"><csymbol cd="latexml" id="S3.E1Xb.2.1.1.m1.2.2.2.3.1.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.3">conditional-set</csymbol><vector id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.4.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3"><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1"><times id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.1"></times><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.2.3">𝑝</ci></apply><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3">superscript</csymbol><cn type="integer" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2">2</cn><cn type="integer" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2"><times id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.1"></times><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.2">𝑦</ci><ci id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.2.3">𝑝</ci></apply><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3">superscript</csymbol><cn type="integer" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.2">2</cn><cn type="integer" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3"><times id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.1"></times><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.2">𝑧</ci><ci id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.2.3">𝑝</ci></apply><apply id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3">superscript</csymbol><cn type="integer" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.2">2</cn><cn type="integer" id="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1Xb.2.1.1.m1.1.1.1.1.1.3.3.3.3">1</cn></apply></apply></vector><apply id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2"><in id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.1.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.1"></in><ci id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.2">𝑝</ci><apply id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.2">𝑃</ci><cn type="integer" id="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.3.cmml" xref="S3.E1Xb.2.1.1.m1.2.2.2.2.2.3.3">5</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xb.2.1.1.m1.2c">\displaystyle P_{5}^{\prime}=\{(x_{p}\times 2^{1},\,y_{p}\times 2^{1},\,z_{p}\times 2^{1})\,|\,p\in P_{5}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
<tr id="S3.E1Xc" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E1Xc.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle{P}_{c}=P_{4}\cup(P_{5}^{\prime}\cup P_{6}^{\prime}).\qquad" display="inline"><semantics id="S3.E1Xc.2.1.1.m1.1a"><mrow id="S3.E1Xc.2.1.1.m1.1.1.1" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E1Xc.2.1.1.m1.1.1.1.1" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.cmml"><msub id="S3.E1Xc.2.1.1.m1.1.1.1.1.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3.cmml"><mi id="S3.E1Xc.2.1.1.m1.1.1.1.1.3.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3.2.cmml">P</mi><mi id="S3.E1Xc.2.1.1.m1.1.1.1.1.3.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3.3.cmml">c</mi></msub><mo id="S3.E1Xc.2.1.1.m1.1.1.1.1.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E1Xc.2.1.1.m1.1.1.1.1.1" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.cmml"><msub id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.2.cmml">P</mi><mn id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.3.cmml">4</mn></msub><mo id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.2.cmml">∪</mo><mrow id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">P</mi><mn id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml">5</mn><mo id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml">∪</mo><msubsup id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">P</mi><mn id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.3.cmml">6</mn><mo id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml">′</mo></msubsup></mrow><mo stretchy="false" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E1Xc.2.1.1.m1.1.1.1.2" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.cmml">.</mo><mspace width="2.167em" id="S3.E1Xc.2.1.1.m1.1.1.1.3" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.cmml"></mspace></mrow><annotation-xml encoding="MathML-Content" id="S3.E1Xc.2.1.1.m1.1b"><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1"><eq id="S3.E1Xc.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.2"></eq><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1Xc.2.1.1.m1.1.1.1.1.3.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.3.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3.2">𝑃</ci><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.3.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.3.3">𝑐</ci></apply><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1"><union id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.2"></union><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.2">𝑃</ci><cn type="integer" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.3.3">4</cn></apply><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1"><union id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.1"></union><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.2">𝑃</ci><cn type="integer" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.2.3">5</cn></apply><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.2.3">′</ci></apply><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.2">𝑃</ci><cn type="integer" id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.3">6</cn></apply><ci id="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1Xc.2.1.1.m1.1.1.1.1.1.1.1.1.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1Xc.2.1.1.m1.1c">\displaystyle{P}_{c}=P_{4}\cup(P_{5}^{\prime}\cup P_{6}^{\prime}).\qquad</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">We visualize the effective receptive fields (ERFs) in Fig. <a href="#S3.F5" title="Figure 5 ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. With additional down-sampling layers, ERFs are larger and the predicted box is more accurate.
It is effective enough and costs little extra computation, as in Tab. <a href="#S3.T2" title="Table 2 ‣ 3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Thus, we use this simple design as the backbone network.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2303.11301/assets/x6.png" id="S3.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="156" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.4.2" class="ltx_text" style="font-size:90%;">Spatially voxel pruning. In sparse CNN backbone, down-sampling layers commonly dilate all voxels to the kernel shape, before down-sampling. Different from these approaches, we only dilate selected voxels that have high feature magnitudes to maintain high efficiency.</span></figcaption>
</figure>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2303.11301/assets/x7.png" id="S3.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="112" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.4.2" class="ltx_text" style="font-size:90%;">Sparse max pooling layer. Similarly to submanifold sparse convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, it only operates on non-empty positions. It removes non-maximum voxels in local space.</span></figcaption>
</figure>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Sparse Height Compression</span>
3D object detectors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> compress 3D voxel features into dense 2D maps by converting sparse features to dense ones and then combining depth (along <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">z</annotation></semantics></math> axis) into the channel dimension. These operations cost footprint memory and computation.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.2" class="ltx_p">In VoxelNet, we find that 2D sparse features are efficient for prediction. Height compression in VoxelNeXt is fully sparse. We simply put all voxels onto the ground and sum up features in the same positions. It costs no more than 1ms. We find that prediction upon the compressed 2D sparse features cost less than using 3D ones, as shown in Tab. <a href="#S4.T5" title="Table 5 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.The compressed sparse features <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="\bar{F_{c}}" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mover accent="true" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><msub id="S3.SS1.p5.1.m1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.2.cmml"><mi id="S3.SS1.p5.1.m1.1.1.2.2" xref="S3.SS1.p5.1.m1.1.1.2.2.cmml">F</mi><mi id="S3.SS1.p5.1.m1.1.1.2.3" xref="S3.SS1.p5.1.m1.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS1.p5.1.m1.1.1.1" xref="S3.SS1.p5.1.m1.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><ci id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1.1">¯</ci><apply id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.2.1.cmml" xref="S3.SS1.p5.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.2.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2.2">𝐹</ci><ci id="S3.SS1.p5.1.m1.1.1.2.3.cmml" xref="S3.SS1.p5.1.m1.1.1.2.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">\bar{F_{c}}</annotation></semantics></math> and their positions <math id="S3.SS1.p5.2.m2.1" class="ltx_Math" alttext="\bar{P_{c}}" display="inline"><semantics id="S3.SS1.p5.2.m2.1a"><mover accent="true" id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml"><msub id="S3.SS1.p5.2.m2.1.1.2" xref="S3.SS1.p5.2.m2.1.1.2.cmml"><mi id="S3.SS1.p5.2.m2.1.1.2.2" xref="S3.SS1.p5.2.m2.1.1.2.2.cmml">P</mi><mi id="S3.SS1.p5.2.m2.1.1.2.3" xref="S3.SS1.p5.2.m2.1.1.2.3.cmml">c</mi></msub><mo id="S3.SS1.p5.2.m2.1.1.1" xref="S3.SS1.p5.2.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><apply id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1"><ci id="S3.SS1.p5.2.m2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1.1">¯</ci><apply id="S3.SS1.p5.2.m2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.2.1.cmml" xref="S3.SS1.p5.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.2.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2.2">𝑃</ci><ci id="S3.SS1.p5.2.m2.1.1.2.3.cmml" xref="S3.SS1.p5.2.m2.1.1.2.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">\bar{P_{c}}</annotation></semantics></math> are obtained as:</p>
<table id="S3.E2" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E2X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2X.2.1.1.m1.2" class="ltx_Math" alttext="\displaystyle\bar{P_{c}}=\{(x_{p},\,y_{p})\,|\,p\in P_{c}\}" display="inline"><semantics id="S3.E2X.2.1.1.m1.2a"><mrow id="S3.E2X.2.1.1.m1.2.2" xref="S3.E2X.2.1.1.m1.2.2.cmml"><mover accent="true" id="S3.E2X.2.1.1.m1.2.2.4" xref="S3.E2X.2.1.1.m1.2.2.4.cmml"><msub id="S3.E2X.2.1.1.m1.2.2.4.2" xref="S3.E2X.2.1.1.m1.2.2.4.2.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.4.2.2" xref="S3.E2X.2.1.1.m1.2.2.4.2.2.cmml">P</mi><mi id="S3.E2X.2.1.1.m1.2.2.4.2.3" xref="S3.E2X.2.1.1.m1.2.2.4.2.3.cmml">c</mi></msub><mo id="S3.E2X.2.1.1.m1.2.2.4.1" xref="S3.E2X.2.1.1.m1.2.2.4.1.cmml">¯</mo></mover><mo id="S3.E2X.2.1.1.m1.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.3.cmml">=</mo><mrow id="S3.E2X.2.1.1.m1.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E2X.2.1.1.m1.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.3.1.cmml">{</mo><mrow id="S3.E2X.2.1.1.m1.1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo rspace="0.337em" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.4" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml">,</mo><msub id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.cmml"><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.3" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.3.cmml">p</mi></msub><mo stretchy="false" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.5" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml">)</mo></mrow><mo lspace="0.170em" rspace="0.170em" id="S3.E2X.2.1.1.m1.2.2.2.2.4" xref="S3.E2X.2.1.1.m1.2.2.2.3.1.cmml">|</mo><mrow id="S3.E2X.2.1.1.m1.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2.cmml">p</mi><mo id="S3.E2X.2.1.1.m1.2.2.2.2.2.1" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.1.cmml">∈</mo><msub id="S3.E2X.2.1.1.m1.2.2.2.2.2.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3.cmml"><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.2" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3.2.cmml">P</mi><mi id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.3" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3.3.cmml">c</mi></msub></mrow><mo stretchy="false" id="S3.E2X.2.1.1.m1.2.2.2.2.5" xref="S3.E2X.2.1.1.m1.2.2.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2X.2.1.1.m1.2b"><apply id="S3.E2X.2.1.1.m1.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2"><eq id="S3.E2X.2.1.1.m1.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.3"></eq><apply id="S3.E2X.2.1.1.m1.2.2.4.cmml" xref="S3.E2X.2.1.1.m1.2.2.4"><ci id="S3.E2X.2.1.1.m1.2.2.4.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.1">¯</ci><apply id="S3.E2X.2.1.1.m1.2.2.4.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.2"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.4.2.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.2">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.2.2.4.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.2.2">𝑃</ci><ci id="S3.E2X.2.1.1.m1.2.2.4.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.4.2.3">𝑐</ci></apply></apply><apply id="S3.E2X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2"><csymbol cd="latexml" id="S3.E2X.2.1.1.m1.2.2.2.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.3">conditional-set</csymbol><interval closure="open" id="S3.E2X.2.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2"><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.1.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.1.1.1.1.1.2.2.3">𝑝</ci></apply></interval><apply id="S3.E2X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2"><in id="S3.E2X.2.1.1.m1.2.2.2.2.2.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.1"></in><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.2">𝑝</ci><apply id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3">subscript</csymbol><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3.2">𝑃</ci><ci id="S3.E2X.2.1.1.m1.2.2.2.2.2.3.3.cmml" xref="S3.E2X.2.1.1.m1.2.2.2.2.2.3.3">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2X.2.1.1.m1.2c">\displaystyle\bar{P_{c}}=\{(x_{p},\,y_{p})\,|\,p\in P_{c}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(2)</span></td>
</tr>
<tr id="S3.E2Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2Xa.2.1.1.m1.1" class="ltx_math_unparsed" alttext="\displaystyle\bar{F_{c}}=\{\sum_{p\in S_{\bar{p}}}f_{p},|\,\bar{p}\in\bar{P_{c}}\}" display="inline"><semantics id="S3.E2Xa.2.1.1.m1.1a"><mrow id="S3.E2Xa.2.1.1.m1.1b"><mover accent="true" id="S3.E2Xa.2.1.1.m1.1.1"><msub id="S3.E2Xa.2.1.1.m1.1.1.2"><mi id="S3.E2Xa.2.1.1.m1.1.1.2.2">F</mi><mi id="S3.E2Xa.2.1.1.m1.1.1.2.3">c</mi></msub><mo id="S3.E2Xa.2.1.1.m1.1.1.1">¯</mo></mover><mo id="S3.E2Xa.2.1.1.m1.1.2">=</mo><mrow id="S3.E2Xa.2.1.1.m1.1.3"><mo stretchy="false" id="S3.E2Xa.2.1.1.m1.1.3.1">{</mo><mstyle displaystyle="true" id="S3.E2Xa.2.1.1.m1.1.3.2"><munder id="S3.E2Xa.2.1.1.m1.1.3.2a"><mo movablelimits="false" id="S3.E2Xa.2.1.1.m1.1.3.2.2">∑</mo><mrow id="S3.E2Xa.2.1.1.m1.1.3.2.3"><mi id="S3.E2Xa.2.1.1.m1.1.3.2.3.2">p</mi><mo id="S3.E2Xa.2.1.1.m1.1.3.2.3.1">∈</mo><msub id="S3.E2Xa.2.1.1.m1.1.3.2.3.3"><mi id="S3.E2Xa.2.1.1.m1.1.3.2.3.3.2">S</mi><mover accent="true" id="S3.E2Xa.2.1.1.m1.1.3.2.3.3.3"><mi id="S3.E2Xa.2.1.1.m1.1.3.2.3.3.3.2">p</mi><mo id="S3.E2Xa.2.1.1.m1.1.3.2.3.3.3.1">¯</mo></mover></msub></mrow></munder></mstyle><msub id="S3.E2Xa.2.1.1.m1.1.3.3"><mi id="S3.E2Xa.2.1.1.m1.1.3.3.2">f</mi><mi id="S3.E2Xa.2.1.1.m1.1.3.3.3">p</mi></msub><mo id="S3.E2Xa.2.1.1.m1.1.3.4">,</mo><mo fence="false" rspace="0.337em" stretchy="false" id="S3.E2Xa.2.1.1.m1.1.3.5">|</mo><mover accent="true" id="S3.E2Xa.2.1.1.m1.1.3.6"><mi id="S3.E2Xa.2.1.1.m1.1.3.6.2">p</mi><mo id="S3.E2Xa.2.1.1.m1.1.3.6.1">¯</mo></mover><mo id="S3.E2Xa.2.1.1.m1.1.3.7">∈</mo><mover accent="true" id="S3.E2Xa.2.1.1.m1.1.3.8"><msub id="S3.E2Xa.2.1.1.m1.1.3.8.2"><mi id="S3.E2Xa.2.1.1.m1.1.3.8.2.2">P</mi><mi id="S3.E2Xa.2.1.1.m1.1.3.8.2.3">c</mi></msub><mo id="S3.E2Xa.2.1.1.m1.1.3.8.1">¯</mo></mover><mo stretchy="false" id="S3.E2Xa.2.1.1.m1.1.3.9">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E2Xa.2.1.1.m1.1c">\displaystyle\bar{F_{c}}=\{\sum_{p\in S_{\bar{p}}}f_{p},|\,\bar{p}\in\bar{P_{c}}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S3.SS1.p5.4" class="ltx_p">where <math id="S3.SS1.p5.3.m1.2" class="ltx_Math" alttext="S_{\bar{p}}=\{p\,|\,x_{p}=x_{\bar{p}},\,y_{p}=y_{\bar{p}},\,p\in P_{c}\}" display="inline"><semantics id="S3.SS1.p5.3.m1.2a"><mrow id="S3.SS1.p5.3.m1.2.2" xref="S3.SS1.p5.3.m1.2.2.cmml"><msub id="S3.SS1.p5.3.m1.2.2.3" xref="S3.SS1.p5.3.m1.2.2.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.3.2" xref="S3.SS1.p5.3.m1.2.2.3.2.cmml">S</mi><mover accent="true" id="S3.SS1.p5.3.m1.2.2.3.3" xref="S3.SS1.p5.3.m1.2.2.3.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.3.3.2" xref="S3.SS1.p5.3.m1.2.2.3.3.2.cmml">p</mi><mo id="S3.SS1.p5.3.m1.2.2.3.3.1" xref="S3.SS1.p5.3.m1.2.2.3.3.1.cmml">¯</mo></mover></msub><mo id="S3.SS1.p5.3.m1.2.2.2" xref="S3.SS1.p5.3.m1.2.2.2.cmml">=</mo><mrow id="S3.SS1.p5.3.m1.2.2.1.1" xref="S3.SS1.p5.3.m1.2.2.1.2.cmml"><mo stretchy="false" id="S3.SS1.p5.3.m1.2.2.1.1.2" xref="S3.SS1.p5.3.m1.2.2.1.2.1.cmml">{</mo><mi id="S3.SS1.p5.3.m1.1.1" xref="S3.SS1.p5.3.m1.1.1.cmml">p</mi><mo lspace="0.170em" rspace="0.170em" id="S3.SS1.p5.3.m1.2.2.1.1.3" xref="S3.SS1.p5.3.m1.2.2.1.2.1.cmml">|</mo><mrow id="S3.SS1.p5.3.m1.2.2.1.1.1.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.3.cmml"><mrow id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.cmml"><msub id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.1.cmml">=</mo><msub id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.2.cmml">x</mi><mover accent="true" id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.2.cmml">p</mi><mo id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.1.cmml">¯</mo></mover></msub></mrow><mo rspace="0.337em" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.3a.cmml">,</mo><mrow id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.3.cmml"><mrow id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.cmml"><msub id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.2.cmml">y</mi><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.1.cmml">=</mo><msub id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.2.cmml">y</mi><mover accent="true" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.2.cmml">p</mi><mo id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.1.cmml">¯</mo></mover></msub></mrow><mo rspace="0.337em" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.3a.cmml">,</mo><mrow id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.2.cmml">p</mi><mo id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.1" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.1.cmml">∈</mo><msub id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.cmml"><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.2" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.2.cmml">P</mi><mi id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.3" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.3.cmml">c</mi></msub></mrow></mrow></mrow><mo stretchy="false" id="S3.SS1.p5.3.m1.2.2.1.1.4" xref="S3.SS1.p5.3.m1.2.2.1.2.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m1.2b"><apply id="S3.SS1.p5.3.m1.2.2.cmml" xref="S3.SS1.p5.3.m1.2.2"><eq id="S3.SS1.p5.3.m1.2.2.2.cmml" xref="S3.SS1.p5.3.m1.2.2.2"></eq><apply id="S3.SS1.p5.3.m1.2.2.3.cmml" xref="S3.SS1.p5.3.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.3">subscript</csymbol><ci id="S3.SS1.p5.3.m1.2.2.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.3.2">𝑆</ci><apply id="S3.SS1.p5.3.m1.2.2.3.3.cmml" xref="S3.SS1.p5.3.m1.2.2.3.3"><ci id="S3.SS1.p5.3.m1.2.2.3.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.3.3.1">¯</ci><ci id="S3.SS1.p5.3.m1.2.2.3.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.3.3.2">𝑝</ci></apply></apply><apply id="S3.SS1.p5.3.m1.2.2.1.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1"><csymbol cd="latexml" id="S3.SS1.p5.3.m1.2.2.1.2.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.2">conditional-set</csymbol><ci id="S3.SS1.p5.3.m1.1.1.cmml" xref="S3.SS1.p5.3.m1.1.1">𝑝</ci><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.3a.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1"><eq id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.1"></eq><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.2.3">𝑝</ci></apply><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.2">𝑥</ci><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3"><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.1">¯</ci><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.1.1.3.3.2">𝑝</ci></apply></apply></apply><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.3a.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1"><eq id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.1"></eq><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2">subscript</csymbol><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.2">𝑦</ci><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.2.3">𝑝</ci></apply><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3">subscript</csymbol><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.2">𝑦</ci><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3"><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.1">¯</ci><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.1.1.3.3.2">𝑝</ci></apply></apply></apply><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2"><in id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.1"></in><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.2">𝑝</ci><apply id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.1.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3">subscript</csymbol><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.2.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.2">𝑃</ci><ci id="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.3.cmml" xref="S3.SS1.p5.3.m1.2.2.1.1.1.2.2.2.2.3.3">𝑐</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m1.2c">S_{\bar{p}}=\{p\,|\,x_{p}=x_{\bar{p}},\,y_{p}=y_{\bar{p}},\,p\in P_{c}\}</annotation></semantics></math>, containing voxels that are put onto the same 2D position <math id="S3.SS1.p5.4.m2.1" class="ltx_Math" alttext="\bar{p}" display="inline"><semantics id="S3.SS1.p5.4.m2.1a"><mover accent="true" id="S3.SS1.p5.4.m2.1.1" xref="S3.SS1.p5.4.m2.1.1.cmml"><mi id="S3.SS1.p5.4.m2.1.1.2" xref="S3.SS1.p5.4.m2.1.1.2.cmml">p</mi><mo id="S3.SS1.p5.4.m2.1.1.1" xref="S3.SS1.p5.4.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m2.1b"><apply id="S3.SS1.p5.4.m2.1.1.cmml" xref="S3.SS1.p5.4.m2.1.1"><ci id="S3.SS1.p5.4.m2.1.1.1.cmml" xref="S3.SS1.p5.4.m2.1.1.1">¯</ci><ci id="S3.SS1.p5.4.m2.1.1.2.cmml" xref="S3.SS1.p5.4.m2.1.1.2">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m2.1c">\bar{p}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Spatially Voxel Pruning</span>
Our network is completely based on voxels. It is common that 3D scenes contain a large number of background points that is redundant and have little benefit for prediction. We gradually prune irrelevant voxels along down-sampling layers. Following SPS-Conv <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, we suppress the dilation of voxels with small feature magnitudes, as shown in Fig. <a href="#S3.F6" title="Figure 6 ‣ 3.1 Sparse CNN Backbone Adaptation ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Taking the suppression ratio as 0.5, we only dilate the voxels whose feature magnitudes <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="|f_{p}|" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><mrow id="S3.SS1.p6.1.m1.1.1.1" xref="S3.SS1.p6.1.m1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p6.1.m1.1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.1.cmml">|</mo><msub id="S3.SS1.p6.1.m1.1.1.1.1" xref="S3.SS1.p6.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p6.1.m1.1.1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S3.SS1.p6.1.m1.1.1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.1.1.3.cmml">p</mi></msub><mo stretchy="false" id="S3.SS1.p6.1.m1.1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.1"><abs id="S3.SS1.p6.1.m1.1.1.2.1.cmml" xref="S3.SS1.p6.1.m1.1.1.1.2"></abs><apply id="S3.SS1.p6.1.m1.1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.2">𝑓</ci><ci id="S3.SS1.p6.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.3">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">|f_{p}|</annotation></semantics></math> (averaged on the channel dimension) rank top half of all voxels. The voxel pruning largely saves computation without compromising performance as indicated in Tab. <a href="#S3.T3" title="Table 3 ‣ 3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S3.F8" class="ltx_figure"><img src="/html/2303.11301/assets/x8.png" id="S3.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S3.F8.4.2" class="ltx_text" style="font-size:90%;">Visualization of voxel association. The predicted object centers are conventionally used for tracking. We additionally associate query voxels in case that the predicted centers are inaccurate.</span></figcaption>
</figure>
<figure id="S3.F9" class="ltx_figure"><img src="/html/2303.11301/assets/x9.png" id="S3.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="443" height="273" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.4.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S3.F9.5.2" class="ltx_text" style="font-size:90%;">Visualization on the predicted boxes and their query voxels. For the <span id="S3.F9.5.2.1" class="ltx_text ltx_font_italic">Car</span> objects, query voxels are inside and usually near the boundaries. For the pedestrian consisting of limited voxels, its query voxel is outside. More visualizations are in the appendix.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Sparse Prediction Head</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.4" class="ltx_p"><span id="S3.SS2.p1.4.1" class="ltx_text ltx_font_bold">Voxel Selection</span>
Figure <a href="#S2.F4" title="Figure 4 ‣ 2 Related Work ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the detailed framework of the VoxelNeXt model. Instead of relying on the dense feature map <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{M}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">𝐌</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝐌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathbf{M}</annotation></semantics></math>, we directly predict objects based on the sparse output of the 3D CNN backbone network <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{V}\in\mathbb{R}^{N\times F}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">𝐕</mi><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.2" xref="S3.SS2.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.2.m2.1.1.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.3.2" xref="S3.SS2.p1.2.m2.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.2.m2.1.1.3.3.1" xref="S3.SS2.p1.2.m2.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p1.2.m2.1.1.3.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.3.cmml">F</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><in id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></in><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝐕</ci><apply id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3"><times id="S3.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3.1"></times><ci id="S3.SS2.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3.2">𝑁</ci><ci id="S3.SS2.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3.3">𝐹</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathbf{V}\in\mathbb{R}^{N\times F}</annotation></semantics></math>. We first predict the scores of voxels for <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">K</annotation></semantics></math> classes, <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{s}\in\mathbb{R}^{N\times K}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mrow id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">𝐬</mi><mo id="S3.SS2.p1.4.m4.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml"><mi id="S3.SS2.p1.4.m4.1.1.3.2" xref="S3.SS2.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.4.m4.1.1.3.3" xref="S3.SS2.p1.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.p1.4.m4.1.1.3.3.2" xref="S3.SS2.p1.4.m4.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.4.m4.1.1.3.3.1" xref="S3.SS2.p1.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p1.4.m4.1.1.3.3.3" xref="S3.SS2.p1.4.m4.1.1.3.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><in id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1"></in><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">𝐬</ci><apply id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.3.1.cmml" xref="S3.SS2.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.3.2.cmml" xref="S3.SS2.p1.4.m4.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.4.m4.1.1.3.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3.3"><times id="S3.SS2.p1.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p1.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.p1.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p1.4.m4.1.1.3.3.2">𝑁</ci><ci id="S3.SS2.p1.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3.3.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathbf{s}\in\mathbb{R}^{N\times K}</annotation></semantics></math>. During training, we assign the voxel nearest to each annotated bounding box center as a positive sample. We use a focal loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> for supervision.
We note the fact that during inference <span id="S3.SS2.p1.4.2" class="ltx_text ltx_font_italic">query voxels are commonly not at the object center</span>.
They are even not necessarily inside the bounding boxes, <span id="S3.SS2.p1.4.3" class="ltx_text ltx_font_italic">e.g.</span>, for pedestrian in Fig. <a href="#S3.F9" title="Figure 9 ‣ 3.1 Sparse CNN Backbone Adaptation ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. We count the distribution of query voxels in Tab. <a href="#S4.T7" title="Table 7 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> on nuScenes validation set.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.14.3.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S3.T2.4.4.2" class="ltx_text" style="font-size:90%;">Results of a pilot study on nuScenes validation split, for the strides of fully sparse voxel-based prediction. Latency is evaluated on a single GPU. For <math id="S3.T2.3.3.1.m1.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S3.T2.3.3.1.m1.1b"><msub id="S3.T2.3.3.1.m1.1.1" xref="S3.T2.3.3.1.m1.1.1.cmml"><mi id="S3.T2.3.3.1.m1.1.1.2" xref="S3.T2.3.3.1.m1.1.1.2.cmml">D</mi><mn id="S3.T2.3.3.1.m1.1.1.3" xref="S3.T2.3.3.1.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.1.m1.1c"><apply id="S3.T2.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.3.3.1.m1.1.1.1.cmml" xref="S3.T2.3.3.1.m1.1.1">subscript</csymbol><ci id="S3.T2.3.3.1.m1.1.1.2.cmml" xref="S3.T2.3.3.1.m1.1.1.2">𝐷</ci><cn type="integer" id="S3.T2.3.3.1.m1.1.1.3.cmml" xref="S3.T2.3.3.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.1.m1.1d">D_{3}</annotation></semantics></math>, the arrows indicate the change based on CenterPoint. For others, the arrows indicate the change based on <math id="S3.T2.4.4.2.m2.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S3.T2.4.4.2.m2.1b"><msub id="S3.T2.4.4.2.m2.1.1" xref="S3.T2.4.4.2.m2.1.1.cmml"><mi id="S3.T2.4.4.2.m2.1.1.2" xref="S3.T2.4.4.2.m2.1.1.2.cmml">D</mi><mn id="S3.T2.4.4.2.m2.1.1.3" xref="S3.T2.4.4.2.m2.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.2.m2.1c"><apply id="S3.T2.4.4.2.m2.1.1.cmml" xref="S3.T2.4.4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.4.4.2.m2.1.1.1.cmml" xref="S3.T2.4.4.2.m2.1.1">subscript</csymbol><ci id="S3.T2.4.4.2.m2.1.1.2.cmml" xref="S3.T2.4.4.2.m2.1.1.2">𝐷</ci><cn type="integer" id="S3.T2.4.4.2.m2.1.1.3.cmml" xref="S3.T2.4.4.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.2.m2.1d">D_{3}</annotation></semantics></math>.</span></figcaption>
<div id="S3.T2.12.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:80pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-78.4pt,14.3pt) scale(0.734346492369161,0.734346492369161) ;">
<table id="S3.T2.12.12.8" class="ltx_tabular ltx_align_middle">
<tr id="S3.T2.12.12.8.9" class="ltx_tr">
<td id="S3.T2.12.12.8.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.12.12.8.9.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S3.T2.12.12.8.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T2.12.12.8.9.2.1" class="ltx_text ltx_font_italic">Strides</span></td>
<td id="S3.T2.12.12.8.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Latency</td>
<td id="S3.T2.12.12.8.9.4" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="S3.T2.12.12.8.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
<td id="S3.T2.12.12.8.9.6" class="ltx_td ltx_align_center ltx_border_t">Car</td>
<td id="S3.T2.12.12.8.9.7" class="ltx_td ltx_align_center ltx_border_t">Truck</td>
<td id="S3.T2.12.12.8.9.8" class="ltx_td ltx_align_center ltx_border_t">Bus</td>
<td id="S3.T2.12.12.8.9.9" class="ltx_td ltx_align_center ltx_border_t">Trailer</td>
<td id="S3.T2.12.12.8.9.10" class="ltx_td ltx_align_center ltx_border_t">C.V.</td>
<td id="S3.T2.12.12.8.9.11" class="ltx_td ltx_align_center ltx_border_t">Ped</td>
<td id="S3.T2.12.12.8.9.12" class="ltx_td ltx_align_center ltx_border_t">Mot</td>
<td id="S3.T2.12.12.8.9.13" class="ltx_td ltx_align_center ltx_border_t">Byc</td>
<td id="S3.T2.12.12.8.9.14" class="ltx_td ltx_align_center ltx_border_t">T.C.</td>
<td id="S3.T2.12.12.8.9.15" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Bar</td>
</tr>
<tr id="S3.T2.12.12.8.10" class="ltx_tr">
<td id="S3.T2.12.12.8.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CenterPoint</td>
<td id="S3.T2.12.12.8.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">{2, 4, 8}</td>
<td id="S3.T2.12.12.8.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96 ms</td>
<td id="S3.T2.12.12.8.10.4" class="ltx_td ltx_align_center ltx_border_t">55.6</td>
<td id="S3.T2.12.12.8.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.2</td>
<td id="S3.T2.12.12.8.10.6" class="ltx_td ltx_align_center ltx_border_t">83.5</td>
<td id="S3.T2.12.12.8.10.7" class="ltx_td ltx_align_center ltx_border_t">54.9</td>
<td id="S3.T2.12.12.8.10.8" class="ltx_td ltx_align_center ltx_border_t">67.5</td>
<td id="S3.T2.12.12.8.10.9" class="ltx_td ltx_align_center ltx_border_t">30.6</td>
<td id="S3.T2.12.12.8.10.10" class="ltx_td ltx_align_center ltx_border_t">16.3</td>
<td id="S3.T2.12.12.8.10.11" class="ltx_td ltx_align_center ltx_border_t">83.3</td>
<td id="S3.T2.12.12.8.10.12" class="ltx_td ltx_align_center ltx_border_t">52.7</td>
<td id="S3.T2.12.12.8.10.13" class="ltx_td ltx_align_center ltx_border_t">34.5</td>
<td id="S3.T2.12.12.8.10.14" class="ltx_td ltx_align_center ltx_border_t">65.6</td>
<td id="S3.T2.12.12.8.10.15" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.5</td>
</tr>
<tr id="S3.T2.6.6.2.2" class="ltx_tr">
<td id="S3.T2.5.5.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt"><math id="S3.T2.5.5.1.1.1.m1.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S3.T2.5.5.1.1.1.m1.1a"><msub id="S3.T2.5.5.1.1.1.m1.1.1" xref="S3.T2.5.5.1.1.1.m1.1.1.cmml"><mi id="S3.T2.5.5.1.1.1.m1.1.1.2" xref="S3.T2.5.5.1.1.1.m1.1.1.2.cmml">D</mi><mn id="S3.T2.5.5.1.1.1.m1.1.1.3" xref="S3.T2.5.5.1.1.1.m1.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.1.1.1.m1.1b"><apply id="S3.T2.5.5.1.1.1.m1.1.1.cmml" xref="S3.T2.5.5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.5.5.1.1.1.m1.1.1.1.cmml" xref="S3.T2.5.5.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.5.5.1.1.1.m1.1.1.2.cmml" xref="S3.T2.5.5.1.1.1.m1.1.1.2">𝐷</ci><cn type="integer" id="S3.T2.5.5.1.1.1.m1.1.1.3.cmml" xref="S3.T2.5.5.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.1.1.1.m1.1c">D_{3}</annotation></semantics></math></td>
<td id="S3.T2.6.6.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">{2, 4, 8}</td>
<td id="S3.T2.6.6.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">56 ms</td>
<td id="S3.T2.6.6.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">46.7<sub id="S3.T2.6.6.2.2.2.1" class="ltx_sub"><span id="S3.T2.6.6.2.2.2.1.1" class="ltx_text ltx_font_italic" style="color:#FF0000;">↓8.9</span></sub>
</td>
<td id="S3.T2.6.6.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">56.2</td>
<td id="S3.T2.6.6.2.2.6" class="ltx_td ltx_align_center ltx_border_tt">75.3</td>
<td id="S3.T2.6.6.2.2.7" class="ltx_td ltx_align_center ltx_border_tt">41.3</td>
<td id="S3.T2.6.6.2.2.8" class="ltx_td ltx_align_center ltx_border_tt">38.3</td>
<td id="S3.T2.6.6.2.2.9" class="ltx_td ltx_align_center ltx_border_tt">10.5</td>
<td id="S3.T2.6.6.2.2.10" class="ltx_td ltx_align_center ltx_border_tt">14.9</td>
<td id="S3.T2.6.6.2.2.11" class="ltx_td ltx_align_center ltx_border_tt">82.0</td>
<td id="S3.T2.6.6.2.2.12" class="ltx_td ltx_align_center ltx_border_tt">47.7</td>
<td id="S3.T2.6.6.2.2.13" class="ltx_td ltx_align_center ltx_border_tt">28.3</td>
<td id="S3.T2.6.6.2.2.14" class="ltx_td ltx_align_center ltx_border_tt">63.6</td>
<td id="S3.T2.6.6.2.2.15" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">64.2</td>
</tr>
<tr id="S3.T2.8.8.4.4" class="ltx_tr">
<td id="S3.T2.7.7.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><math id="S3.T2.7.7.3.3.1.m1.1" class="ltx_Math" alttext="D_{3}^{5\times 5\times 5}" display="inline"><semantics id="S3.T2.7.7.3.3.1.m1.1a"><msubsup id="S3.T2.7.7.3.3.1.m1.1.1" xref="S3.T2.7.7.3.3.1.m1.1.1.cmml"><mi id="S3.T2.7.7.3.3.1.m1.1.1.2.2" xref="S3.T2.7.7.3.3.1.m1.1.1.2.2.cmml">D</mi><mn id="S3.T2.7.7.3.3.1.m1.1.1.2.3" xref="S3.T2.7.7.3.3.1.m1.1.1.2.3.cmml">3</mn><mrow id="S3.T2.7.7.3.3.1.m1.1.1.3" xref="S3.T2.7.7.3.3.1.m1.1.1.3.cmml"><mn id="S3.T2.7.7.3.3.1.m1.1.1.3.2" xref="S3.T2.7.7.3.3.1.m1.1.1.3.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T2.7.7.3.3.1.m1.1.1.3.1" xref="S3.T2.7.7.3.3.1.m1.1.1.3.1.cmml">×</mo><mn id="S3.T2.7.7.3.3.1.m1.1.1.3.3" xref="S3.T2.7.7.3.3.1.m1.1.1.3.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S3.T2.7.7.3.3.1.m1.1.1.3.1a" xref="S3.T2.7.7.3.3.1.m1.1.1.3.1.cmml">×</mo><mn id="S3.T2.7.7.3.3.1.m1.1.1.3.4" xref="S3.T2.7.7.3.3.1.m1.1.1.3.4.cmml">5</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.T2.7.7.3.3.1.m1.1b"><apply id="S3.T2.7.7.3.3.1.m1.1.1.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.7.7.3.3.1.m1.1.1.1.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1">superscript</csymbol><apply id="S3.T2.7.7.3.3.1.m1.1.1.2.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.7.7.3.3.1.m1.1.1.2.1.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1">subscript</csymbol><ci id="S3.T2.7.7.3.3.1.m1.1.1.2.2.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.2.2">𝐷</ci><cn type="integer" id="S3.T2.7.7.3.3.1.m1.1.1.2.3.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.2.3">3</cn></apply><apply id="S3.T2.7.7.3.3.1.m1.1.1.3.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.3"><times id="S3.T2.7.7.3.3.1.m1.1.1.3.1.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.3.1"></times><cn type="integer" id="S3.T2.7.7.3.3.1.m1.1.1.3.2.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.3.2">5</cn><cn type="integer" id="S3.T2.7.7.3.3.1.m1.1.1.3.3.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.3.3">5</cn><cn type="integer" id="S3.T2.7.7.3.3.1.m1.1.1.3.4.cmml" xref="S3.T2.7.7.3.3.1.m1.1.1.3.4">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.7.3.3.1.m1.1c">D_{3}^{5\times 5\times 5}</annotation></semantics></math></td>
<td id="S3.T2.8.8.4.4.3" class="ltx_td ltx_align_center ltx_border_r">{2, 4, 8}</td>
<td id="S3.T2.8.8.4.4.4" class="ltx_td ltx_align_center ltx_border_r">225 ms</td>
<td id="S3.T2.8.8.4.4.2" class="ltx_td ltx_align_center">51.6<sub id="S3.T2.8.8.4.4.2.1" class="ltx_sub"><span id="S3.T2.8.8.4.4.2.1.1" class="ltx_text ltx_font_italic" style="color:#008000;">↑4.9</span></sub>
</td>
<td id="S3.T2.8.8.4.4.5" class="ltx_td ltx_align_center ltx_border_r">60.4</td>
<td id="S3.T2.8.8.4.4.6" class="ltx_td ltx_align_center">80.0</td>
<td id="S3.T2.8.8.4.4.7" class="ltx_td ltx_align_center">49.2</td>
<td id="S3.T2.8.8.4.4.8" class="ltx_td ltx_align_center">56.8</td>
<td id="S3.T2.8.8.4.4.9" class="ltx_td ltx_align_center">16.8</td>
<td id="S3.T2.8.8.4.4.10" class="ltx_td ltx_align_center">16.5</td>
<td id="S3.T2.8.8.4.4.11" class="ltx_td ltx_align_center">83.5</td>
<td id="S3.T2.8.8.4.4.12" class="ltx_td ltx_align_center">50.2</td>
<td id="S3.T2.8.8.4.4.13" class="ltx_td ltx_align_center">30.9</td>
<td id="S3.T2.8.8.4.4.14" class="ltx_td ltx_align_center">64.8</td>
<td id="S3.T2.8.8.4.4.15" class="ltx_td ltx_align_center ltx_border_r">67.7</td>
</tr>
<tr id="S3.T2.10.10.6.6" class="ltx_tr">
<td id="S3.T2.9.9.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><math id="S3.T2.9.9.5.5.1.m1.1" class="ltx_Math" alttext="D_{4}" display="inline"><semantics id="S3.T2.9.9.5.5.1.m1.1a"><msub id="S3.T2.9.9.5.5.1.m1.1.1" xref="S3.T2.9.9.5.5.1.m1.1.1.cmml"><mi id="S3.T2.9.9.5.5.1.m1.1.1.2" xref="S3.T2.9.9.5.5.1.m1.1.1.2.cmml">D</mi><mn id="S3.T2.9.9.5.5.1.m1.1.1.3" xref="S3.T2.9.9.5.5.1.m1.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.9.9.5.5.1.m1.1b"><apply id="S3.T2.9.9.5.5.1.m1.1.1.cmml" xref="S3.T2.9.9.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.9.9.5.5.1.m1.1.1.1.cmml" xref="S3.T2.9.9.5.5.1.m1.1.1">subscript</csymbol><ci id="S3.T2.9.9.5.5.1.m1.1.1.2.cmml" xref="S3.T2.9.9.5.5.1.m1.1.1.2">𝐷</ci><cn type="integer" id="S3.T2.9.9.5.5.1.m1.1.1.3.cmml" xref="S3.T2.9.9.5.5.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.9.5.5.1.m1.1c">D_{4}</annotation></semantics></math></td>
<td id="S3.T2.10.10.6.6.3" class="ltx_td ltx_align_center ltx_border_r">{2, 4, 8, 16}</td>
<td id="S3.T2.10.10.6.6.4" class="ltx_td ltx_align_center ltx_border_r">62 ms</td>
<td id="S3.T2.10.10.6.6.2" class="ltx_td ltx_align_center">52.3<sub id="S3.T2.10.10.6.6.2.1" class="ltx_sub"><span id="S3.T2.10.10.6.6.2.1.1" class="ltx_text ltx_font_italic" style="color:#008000;">↑5.6</span></sub>
</td>
<td id="S3.T2.10.10.6.6.5" class="ltx_td ltx_align_center ltx_border_r">61.2</td>
<td id="S3.T2.10.10.6.6.6" class="ltx_td ltx_align_center">80.0</td>
<td id="S3.T2.10.10.6.6.7" class="ltx_td ltx_align_center">50.0</td>
<td id="S3.T2.10.10.6.6.8" class="ltx_td ltx_align_center">61.2</td>
<td id="S3.T2.10.10.6.6.9" class="ltx_td ltx_align_center">23.1</td>
<td id="S3.T2.10.10.6.6.10" class="ltx_td ltx_align_center">16.9</td>
<td id="S3.T2.10.10.6.6.11" class="ltx_td ltx_align_center">82.5</td>
<td id="S3.T2.10.10.6.6.12" class="ltx_td ltx_align_center">49.0</td>
<td id="S3.T2.10.10.6.6.13" class="ltx_td ltx_align_center">31.8</td>
<td id="S3.T2.10.10.6.6.14" class="ltx_td ltx_align_center">63.9</td>
<td id="S3.T2.10.10.6.6.15" class="ltx_td ltx_align_center ltx_border_r">64.8</td>
</tr>
<tr id="S3.T2.12.12.8.8" class="ltx_tr">
<td id="S3.T2.11.11.7.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><math id="S3.T2.11.11.7.7.1.m1.1" class="ltx_Math" alttext="D_{5}" display="inline"><semantics id="S3.T2.11.11.7.7.1.m1.1a"><msub id="S3.T2.11.11.7.7.1.m1.1.1" xref="S3.T2.11.11.7.7.1.m1.1.1.cmml"><mi id="S3.T2.11.11.7.7.1.m1.1.1.2" xref="S3.T2.11.11.7.7.1.m1.1.1.2.cmml">D</mi><mn id="S3.T2.11.11.7.7.1.m1.1.1.3" xref="S3.T2.11.11.7.7.1.m1.1.1.3.cmml">5</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.11.11.7.7.1.m1.1b"><apply id="S3.T2.11.11.7.7.1.m1.1.1.cmml" xref="S3.T2.11.11.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.11.11.7.7.1.m1.1.1.1.cmml" xref="S3.T2.11.11.7.7.1.m1.1.1">subscript</csymbol><ci id="S3.T2.11.11.7.7.1.m1.1.1.2.cmml" xref="S3.T2.11.11.7.7.1.m1.1.1.2">𝐷</ci><cn type="integer" id="S3.T2.11.11.7.7.1.m1.1.1.3.cmml" xref="S3.T2.11.11.7.7.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.11.7.7.1.m1.1c">D_{5}</annotation></semantics></math></td>
<td id="S3.T2.12.12.8.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">{2, 4, 8, 16, 32}</td>
<td id="S3.T2.12.12.8.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">66 ms</td>
<td id="S3.T2.12.12.8.8.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S3.T2.12.12.8.8.2.1" class="ltx_text ltx_font_bold">56.5<sub id="S3.T2.12.12.8.8.2.1.1" class="ltx_sub"><span id="S3.T2.12.12.8.8.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic" style="color:#008000;">↑9.5</span></sub></span></td>
<td id="S3.T2.12.12.8.8.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T2.12.12.8.8.5.1" class="ltx_text ltx_font_bold">64.5</span></td>
<td id="S3.T2.12.12.8.8.6" class="ltx_td ltx_align_center ltx_border_b">83.0</td>
<td id="S3.T2.12.12.8.8.7" class="ltx_td ltx_align_center ltx_border_b">54.0</td>
<td id="S3.T2.12.12.8.8.8" class="ltx_td ltx_align_center ltx_border_b">67.4</td>
<td id="S3.T2.12.12.8.8.9" class="ltx_td ltx_align_center ltx_border_b">32.9</td>
<td id="S3.T2.12.12.8.8.10" class="ltx_td ltx_align_center ltx_border_b">20.0</td>
<td id="S3.T2.12.12.8.8.11" class="ltx_td ltx_align_center ltx_border_b">84.1</td>
<td id="S3.T2.12.12.8.8.12" class="ltx_td ltx_align_center ltx_border_b">52.7</td>
<td id="S3.T2.12.12.8.8.13" class="ltx_td ltx_align_center ltx_border_b">35.7</td>
<td id="S3.T2.12.12.8.8.14" class="ltx_td ltx_align_center ltx_border_b">66.6</td>
<td id="S3.T2.12.12.8.8.15" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">65.3</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S3.T3.3.2" class="ltx_text" style="font-size:90%;">Effects of spatial pruning ratios. A larger pruning ratio means that fewer voxels remain in the sparse CNN backbone.</span></figcaption>
<table id="S3.T3.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.4.1" class="ltx_tr">
<td id="S3.T3.4.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.4.1.1.1" class="ltx_text ltx_font_italic">Ratio</span></td>
<td id="S3.T3.4.1.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S3.T3.4.1.3" class="ltx_td ltx_align_center ltx_border_t">0.1</td>
<td id="S3.T3.4.1.4" class="ltx_td ltx_align_center ltx_border_t">0.3</td>
<td id="S3.T3.4.1.5" class="ltx_td ltx_align_center ltx_border_t">0.5</td>
<td id="S3.T3.4.1.6" class="ltx_td ltx_align_center ltx_border_t">0.7</td>
<td id="S3.T3.4.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.9</td>
</tr>
<tr id="S3.T3.4.2" class="ltx_tr">
<td id="S3.T3.4.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">FLOPs (G)</td>
<td id="S3.T3.4.2.2" class="ltx_td ltx_align_center ltx_border_t">83.8</td>
<td id="S3.T3.4.2.3" class="ltx_td ltx_align_center ltx_border_t">79.6</td>
<td id="S3.T3.4.2.4" class="ltx_td ltx_align_center ltx_border_t">60.1</td>
<td id="S3.T3.4.2.5" class="ltx_td ltx_align_center ltx_border_t">33.6</td>
<td id="S3.T3.4.2.6" class="ltx_td ltx_align_center ltx_border_t">19.8</td>
<td id="S3.T3.4.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7.6</td>
</tr>
<tr id="S3.T3.4.3" class="ltx_tr">
<td id="S3.T3.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">mAP</td>
<td id="S3.T3.4.3.2" class="ltx_td ltx_align_center">56.5</td>
<td id="S3.T3.4.3.3" class="ltx_td ltx_align_center">56.5</td>
<td id="S3.T3.4.3.4" class="ltx_td ltx_align_center">56.4</td>
<td id="S3.T3.4.3.5" class="ltx_td ltx_align_center">56.2</td>
<td id="S3.T3.4.3.6" class="ltx_td ltx_align_center">53.7</td>
<td id="S3.T3.4.3.7" class="ltx_td ltx_align_center ltx_border_r">45.1</td>
</tr>
<tr id="S3.T3.4.4" class="ltx_tr">
<td id="S3.T3.4.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">NDS</td>
<td id="S3.T3.4.4.2" class="ltx_td ltx_align_center ltx_border_b">64.5</td>
<td id="S3.T3.4.4.3" class="ltx_td ltx_align_center ltx_border_b">64.5</td>
<td id="S3.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_b">64.3</td>
<td id="S3.T3.4.4.5" class="ltx_td ltx_align_center ltx_border_b">64.3</td>
<td id="S3.T3.4.4.6" class="ltx_td ltx_align_center ltx_border_b">62.1</td>
<td id="S3.T3.4.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">56.0</td>
</tr>
</table>
</figure>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T4.2.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S3.T4.3.2" class="ltx_text" style="font-size:90%;">Effects of spatial pruning on various layers. We use it on the first 3 down-sampling layers by default.</span></figcaption>
<div id="S3.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:127.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(94.7pt,-27.9pt) scale(1.77520813517852,1.77520813517852) ;">
<table id="S3.T4.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.4.1.1" class="ltx_tr">
<td id="S3.T4.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.1.1.1.1" class="ltx_text ltx_font_italic">Stages</span></td>
<td id="S3.T4.4.1.1.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S3.T4.4.1.1.3" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S3.T4.4.1.1.4" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="S3.T4.4.1.1.5" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="S3.T4.4.1.1.6" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="S3.T4.4.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5</td>
</tr>
<tr id="S3.T4.4.1.2" class="ltx_tr">
<td id="S3.T4.4.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">FLOPs (G)</td>
<td id="S3.T4.4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">83.8</td>
<td id="S3.T4.4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">65.0</td>
<td id="S3.T4.4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">45.9</td>
<td id="S3.T4.4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">33.6</td>
<td id="S3.T4.4.1.2.6" class="ltx_td ltx_align_center ltx_border_t">29.1</td>
<td id="S3.T4.4.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.9</td>
</tr>
<tr id="S3.T4.4.1.3" class="ltx_tr">
<td id="S3.T4.4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">mAP</td>
<td id="S3.T4.4.1.3.2" class="ltx_td ltx_align_center">56.5</td>
<td id="S3.T4.4.1.3.3" class="ltx_td ltx_align_center">56.5</td>
<td id="S3.T4.4.1.3.4" class="ltx_td ltx_align_center">56.4</td>
<td id="S3.T4.4.1.3.5" class="ltx_td ltx_align_center">56.2</td>
<td id="S3.T4.4.1.3.6" class="ltx_td ltx_align_center">54.2</td>
<td id="S3.T4.4.1.3.7" class="ltx_td ltx_align_center ltx_border_r">53.7</td>
</tr>
<tr id="S3.T4.4.1.4" class="ltx_tr">
<td id="S3.T4.4.1.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">NDS</td>
<td id="S3.T4.4.1.4.2" class="ltx_td ltx_align_center ltx_border_b">64.5</td>
<td id="S3.T4.4.1.4.3" class="ltx_td ltx_align_center ltx_border_b">64.5</td>
<td id="S3.T4.4.1.4.4" class="ltx_td ltx_align_center ltx_border_b">64.4</td>
<td id="S3.T4.4.1.4.5" class="ltx_td ltx_align_center ltx_border_b">64.3</td>
<td id="S3.T4.4.1.4.6" class="ltx_td ltx_align_center ltx_border_b">62.5</td>
<td id="S3.T4.4.1.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">62.0</td>
</tr>
</table>
</span></div>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">During inference, we avoid NMS post-processing by using sparse max pooling, as features are sparse enough. Similar to submanifold sparse convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, it only operates on non-empty positions. This is based on the predicted scores <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{s}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">𝐬</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝐬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbf{s}</annotation></semantics></math> and conducted individually for each class. We adopt sparse max pooling to select voxels with spatially local maximums. The removed voxels will be excluded in box prediction, which saves the computation of head.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.8" class="ltx_p"><span id="S3.SS2.p3.8.1" class="ltx_text ltx_font_bold">Box Regression</span>
Bounding boxes are directly regressed from the positive or selected sparse voxel features <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{v}\in\mathbb{R}^{n\times F}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">𝐯</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p3.1.m1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.3.3.2" xref="S3.SS2.p3.1.m1.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.1.1.3.3.1" xref="S3.SS2.p3.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p3.1.m1.1.1.3.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.3.cmml">F</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><in id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></in><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝐯</ci><apply id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3"><times id="S3.SS2.p3.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3.2">𝑛</ci><ci id="S3.SS2.p3.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3.3">𝐹</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbf{v}\in\mathbb{R}^{n\times F}</annotation></semantics></math>. Following the protocol in CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, we regress the location <math id="S3.SS2.p3.2.m2.2" class="ltx_Math" alttext="(\Delta x,\Delta y)\in\mathbb{R}^{2}" display="inline"><semantics id="S3.SS2.p3.2.m2.2a"><mrow id="S3.SS2.p3.2.m2.2.2" xref="S3.SS2.p3.2.m2.2.2.cmml"><mrow id="S3.SS2.p3.2.m2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.p3.2.m2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">(</mo><mrow id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.1.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo id="S3.SS2.p3.2.m2.2.2.2.2.4" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">,</mo><mrow id="S3.SS2.p3.2.m2.2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS2.p3.2.m2.2.2.2.2.2.2" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.2.m2.2.2.2.2.2.1" xref="S3.SS2.p3.2.m2.2.2.2.2.2.1.cmml">​</mo><mi id="S3.SS2.p3.2.m2.2.2.2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.2.2.2.3.cmml">y</mi></mrow><mo stretchy="false" id="S3.SS2.p3.2.m2.2.2.2.2.5" xref="S3.SS2.p3.2.m2.2.2.2.3.cmml">)</mo></mrow><mo id="S3.SS2.p3.2.m2.2.2.3" xref="S3.SS2.p3.2.m2.2.2.3.cmml">∈</mo><msup id="S3.SS2.p3.2.m2.2.2.4" xref="S3.SS2.p3.2.m2.2.2.4.cmml"><mi id="S3.SS2.p3.2.m2.2.2.4.2" xref="S3.SS2.p3.2.m2.2.2.4.2.cmml">ℝ</mi><mn id="S3.SS2.p3.2.m2.2.2.4.3" xref="S3.SS2.p3.2.m2.2.2.4.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.2b"><apply id="S3.SS2.p3.2.m2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2"><in id="S3.SS2.p3.2.m2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.3"></in><interval closure="open" id="S3.SS2.p3.2.m2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2"><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1"><times id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.1"></times><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">Δ</ci><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">𝑥</ci></apply><apply id="S3.SS2.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2"><times id="S3.SS2.p3.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.1"></times><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.2">Δ</ci><ci id="S3.SS2.p3.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS2.p3.2.m2.2.2.2.2.2.3">𝑦</ci></apply></interval><apply id="S3.SS2.p3.2.m2.2.2.4.cmml" xref="S3.SS2.p3.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.2.2.4.1.cmml" xref="S3.SS2.p3.2.m2.2.2.4">superscript</csymbol><ci id="S3.SS2.p3.2.m2.2.2.4.2.cmml" xref="S3.SS2.p3.2.m2.2.2.4.2">ℝ</ci><cn type="integer" id="S3.SS2.p3.2.m2.2.2.4.3.cmml" xref="S3.SS2.p3.2.m2.2.2.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.2c">(\Delta x,\Delta y)\in\mathbb{R}^{2}</annotation></semantics></math>, height <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="h\in\mathbb{R}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mrow id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">h</mi><mo id="S3.SS2.p3.3.m3.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.cmml">∈</mo><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><in id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1"></in><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">ℎ</ci><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">h\in\mathbb{R}</annotation></semantics></math>, 3D size <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="s\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">s</mi><mo id="S3.SS2.p3.4.m4.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.p3.4.m4.1.1.3.2" xref="S3.SS2.p3.4.m4.1.1.3.2.cmml">ℝ</mi><mn id="S3.SS2.p3.4.m4.1.1.3.3" xref="S3.SS2.p3.4.m4.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><in id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1"></in><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝑠</ci><apply id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.p3.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.p3.4.m4.1.1.3.2">ℝ</ci><cn type="integer" id="S3.SS2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">s\in\mathbb{R}^{3}</annotation></semantics></math>, and rotation angle <math id="S3.SS2.p3.5.m5.4" class="ltx_Math" alttext="(sin(\alpha),cos(\alpha))\in\mathbb{R}^{2}" display="inline"><semantics id="S3.SS2.p3.5.m5.4a"><mrow id="S3.SS2.p3.5.m5.4.4" xref="S3.SS2.p3.5.m5.4.4.cmml"><mrow id="S3.SS2.p3.5.m5.4.4.2.2" xref="S3.SS2.p3.5.m5.4.4.2.3.cmml"><mo stretchy="false" id="S3.SS2.p3.5.m5.4.4.2.2.3" xref="S3.SS2.p3.5.m5.4.4.2.3.cmml">(</mo><mrow id="S3.SS2.p3.5.m5.3.3.1.1.1" xref="S3.SS2.p3.5.m5.3.3.1.1.1.cmml"><mi id="S3.SS2.p3.5.m5.3.3.1.1.1.2" xref="S3.SS2.p3.5.m5.3.3.1.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.3.3.1.1.1.1" xref="S3.SS2.p3.5.m5.3.3.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.5.m5.3.3.1.1.1.3" xref="S3.SS2.p3.5.m5.3.3.1.1.1.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.3.3.1.1.1.1a" xref="S3.SS2.p3.5.m5.3.3.1.1.1.1.cmml">​</mo><mi id="S3.SS2.p3.5.m5.3.3.1.1.1.4" xref="S3.SS2.p3.5.m5.3.3.1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.3.3.1.1.1.1b" xref="S3.SS2.p3.5.m5.3.3.1.1.1.1.cmml">​</mo><mrow id="S3.SS2.p3.5.m5.3.3.1.1.1.5.2" xref="S3.SS2.p3.5.m5.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.5.m5.3.3.1.1.1.5.2.1" xref="S3.SS2.p3.5.m5.3.3.1.1.1.cmml">(</mo><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">α</mi><mo stretchy="false" id="S3.SS2.p3.5.m5.3.3.1.1.1.5.2.2" xref="S3.SS2.p3.5.m5.3.3.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p3.5.m5.4.4.2.2.4" xref="S3.SS2.p3.5.m5.4.4.2.3.cmml">,</mo><mrow id="S3.SS2.p3.5.m5.4.4.2.2.2" xref="S3.SS2.p3.5.m5.4.4.2.2.2.cmml"><mi id="S3.SS2.p3.5.m5.4.4.2.2.2.2" xref="S3.SS2.p3.5.m5.4.4.2.2.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.4.4.2.2.2.1" xref="S3.SS2.p3.5.m5.4.4.2.2.2.1.cmml">​</mo><mi id="S3.SS2.p3.5.m5.4.4.2.2.2.3" xref="S3.SS2.p3.5.m5.4.4.2.2.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.4.4.2.2.2.1a" xref="S3.SS2.p3.5.m5.4.4.2.2.2.1.cmml">​</mo><mi id="S3.SS2.p3.5.m5.4.4.2.2.2.4" xref="S3.SS2.p3.5.m5.4.4.2.2.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.4.4.2.2.2.1b" xref="S3.SS2.p3.5.m5.4.4.2.2.2.1.cmml">​</mo><mrow id="S3.SS2.p3.5.m5.4.4.2.2.2.5.2" xref="S3.SS2.p3.5.m5.4.4.2.2.2.cmml"><mo stretchy="false" id="S3.SS2.p3.5.m5.4.4.2.2.2.5.2.1" xref="S3.SS2.p3.5.m5.4.4.2.2.2.cmml">(</mo><mi id="S3.SS2.p3.5.m5.2.2" xref="S3.SS2.p3.5.m5.2.2.cmml">α</mi><mo stretchy="false" id="S3.SS2.p3.5.m5.4.4.2.2.2.5.2.2" xref="S3.SS2.p3.5.m5.4.4.2.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.p3.5.m5.4.4.2.2.5" xref="S3.SS2.p3.5.m5.4.4.2.3.cmml">)</mo></mrow><mo id="S3.SS2.p3.5.m5.4.4.3" xref="S3.SS2.p3.5.m5.4.4.3.cmml">∈</mo><msup id="S3.SS2.p3.5.m5.4.4.4" xref="S3.SS2.p3.5.m5.4.4.4.cmml"><mi id="S3.SS2.p3.5.m5.4.4.4.2" xref="S3.SS2.p3.5.m5.4.4.4.2.cmml">ℝ</mi><mn id="S3.SS2.p3.5.m5.4.4.4.3" xref="S3.SS2.p3.5.m5.4.4.4.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.4b"><apply id="S3.SS2.p3.5.m5.4.4.cmml" xref="S3.SS2.p3.5.m5.4.4"><in id="S3.SS2.p3.5.m5.4.4.3.cmml" xref="S3.SS2.p3.5.m5.4.4.3"></in><interval closure="open" id="S3.SS2.p3.5.m5.4.4.2.3.cmml" xref="S3.SS2.p3.5.m5.4.4.2.2"><apply id="S3.SS2.p3.5.m5.3.3.1.1.1.cmml" xref="S3.SS2.p3.5.m5.3.3.1.1.1"><times id="S3.SS2.p3.5.m5.3.3.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.3.3.1.1.1.1"></times><ci id="S3.SS2.p3.5.m5.3.3.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.3.3.1.1.1.2">𝑠</ci><ci id="S3.SS2.p3.5.m5.3.3.1.1.1.3.cmml" xref="S3.SS2.p3.5.m5.3.3.1.1.1.3">𝑖</ci><ci id="S3.SS2.p3.5.m5.3.3.1.1.1.4.cmml" xref="S3.SS2.p3.5.m5.3.3.1.1.1.4">𝑛</ci><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">𝛼</ci></apply><apply id="S3.SS2.p3.5.m5.4.4.2.2.2.cmml" xref="S3.SS2.p3.5.m5.4.4.2.2.2"><times id="S3.SS2.p3.5.m5.4.4.2.2.2.1.cmml" xref="S3.SS2.p3.5.m5.4.4.2.2.2.1"></times><ci id="S3.SS2.p3.5.m5.4.4.2.2.2.2.cmml" xref="S3.SS2.p3.5.m5.4.4.2.2.2.2">𝑐</ci><ci id="S3.SS2.p3.5.m5.4.4.2.2.2.3.cmml" xref="S3.SS2.p3.5.m5.4.4.2.2.2.3">𝑜</ci><ci id="S3.SS2.p3.5.m5.4.4.2.2.2.4.cmml" xref="S3.SS2.p3.5.m5.4.4.2.2.2.4">𝑠</ci><ci id="S3.SS2.p3.5.m5.2.2.cmml" xref="S3.SS2.p3.5.m5.2.2">𝛼</ci></apply></interval><apply id="S3.SS2.p3.5.m5.4.4.4.cmml" xref="S3.SS2.p3.5.m5.4.4.4"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.4.4.4.1.cmml" xref="S3.SS2.p3.5.m5.4.4.4">superscript</csymbol><ci id="S3.SS2.p3.5.m5.4.4.4.2.cmml" xref="S3.SS2.p3.5.m5.4.4.4.2">ℝ</ci><cn type="integer" id="S3.SS2.p3.5.m5.4.4.4.3.cmml" xref="S3.SS2.p3.5.m5.4.4.4.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.4c">(sin(\alpha),cos(\alpha))\in\mathbb{R}^{2}</annotation></semantics></math>. For the nuScenes dataset or tracking, we regress the velocity <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="v\in\mathbb{R}^{2}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mrow id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">v</mi><mo id="S3.SS2.p3.6.m6.1.1.1" xref="S3.SS2.p3.6.m6.1.1.1.cmml">∈</mo><msup id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml"><mi id="S3.SS2.p3.6.m6.1.1.3.2" xref="S3.SS2.p3.6.m6.1.1.3.2.cmml">ℝ</mi><mn id="S3.SS2.p3.6.m6.1.1.3.3" xref="S3.SS2.p3.6.m6.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><in id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1.1"></in><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝑣</ci><apply id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.p3.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.p3.6.m6.1.1.3.2">ℝ</ci><cn type="integer" id="S3.SS2.p3.6.m6.1.1.3.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">v\in\mathbb{R}^{2}</annotation></semantics></math> by task definition. These predictions are supervised under the L1 loss function during training. For Waymo dataset, we also predict the IoU and train with IoU loss for performance enhancement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. We simply use fully connected layer or <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mn id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.7.m7.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.cmml">×</mo><mn id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><times id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1"></times><cn type="integer" id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">3</cn><cn type="integer" id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">3\times 3</annotation></semantics></math> submanifold sparse convolutional layers with kernel size 3 for prediction, without other complicate designs. We find that the <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><mrow id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mn id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.8.m8.1.1.1" xref="S3.SS2.p3.8.m8.1.1.1.cmml">×</mo><mn id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><times id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1.1"></times><cn type="integer" id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2">3</cn><cn type="integer" id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">3\times 3</annotation></semantics></math> sparse convolutions generate better results than fully connected layers, with limited burden, as in Tab. <a href="#S4.T6" title="Table 6 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>3D Tracking</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Our framework is naturally extended to 3D tracking. CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> tracks the predicted object centers via a two-dimensional velocity <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="v\in\mathbb{R}^{2}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">v</mi><mo id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mn id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><in id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></in><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝑣</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">ℝ</ci><cn type="integer" id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">v\in\mathbb{R}^{2}</annotation></semantics></math>, which is also supervised by L1 loss. We extend this design into VoxelNeXt. Our solution is to use <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">voxel association</span> to include more tracklets that match the positions of query voxels.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">As shown in Fig. <a href="#S3.F8" title="Figure 8 ‣ 3.1 Sparse CNN Backbone Adaptation ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we record the position of voxel that is used to predict each box. Similar to the center association, we compute the L2 distance for matching. The query positions are picked by tracking back their index to original input voxels, instead of stride-8 positions. The tracked voxels exist in input data, which has less bias than the predicted centers. Also, the query voxels between adjacent frames share similar relative positions to boxes. We empirically show that voxel association improves tracking in Tab. <a href="#S4.T11" title="Table 11 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.3.2" class="ltx_text" style="font-size:90%;">Ablations on 2D or 3D sparse CNN in VoxelNeXt. sparse height Compression is used to connect 3D backbone and 2D head.</span></figcaption>
<div id="S4.T5.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:114.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(80.8pt,-21.4pt) scale(1.59353785937386,1.59353785937386) ;">
<table id="S4.T5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.4.1.1" class="ltx_tr">
<td id="S4.T5.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T5.4.1.1.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S4.T5.4.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T5.4.1.1.2.1" class="ltx_text" style="font-size:90%;">Backbone</span></td>
<td id="S4.T5.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.4.1.1.3.1" class="ltx_text" style="font-size:90%;">Head</span></td>
<td id="S4.T5.4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Latency</td>
<td id="S4.T5.4.1.1.5" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="S4.T5.4.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
</tr>
<tr id="S4.T5.4.1.2" class="ltx_tr">
<td id="S4.T5.4.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">-</td>
<td id="S4.T5.4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">3D</td>
<td id="S4.T5.4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3D</td>
<td id="S4.T5.4.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92 ms</td>
<td id="S4.T5.4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">56.3</td>
<td id="S4.T5.4.1.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.4</td>
</tr>
<tr id="S4.T5.4.1.3" class="ltx_tr">
<td id="S4.T5.4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span id="S4.T5.4.1.3.1.1" class="ltx_text" style="font-size:90%;">VoxelNeXt</span></td>
<td id="S4.T5.4.1.3.2" class="ltx_td ltx_align_center">3D</td>
<td id="S4.T5.4.1.3.3" class="ltx_td ltx_align_center ltx_border_r">2D</td>
<td id="S4.T5.4.1.3.4" class="ltx_td ltx_align_center ltx_border_r">66 ms</td>
<td id="S4.T5.4.1.3.5" class="ltx_td ltx_align_center"><span id="S4.T5.4.1.3.5.1" class="ltx_text ltx_font_bold">56.2</span></td>
<td id="S4.T5.4.1.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.4.1.3.6.1" class="ltx_text ltx_font_bold">64.3</span></td>
</tr>
<tr id="S4.T5.4.1.4" class="ltx_tr">
<td id="S4.T5.4.1.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span id="S4.T5.4.1.4.1.1" class="ltx_text" style="font-size:90%;">VoxelNeXt-2D</span></td>
<td id="S4.T5.4.1.4.2" class="ltx_td ltx_align_center ltx_border_b">2D</td>
<td id="S4.T5.4.1.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">2D</td>
<td id="S4.T5.4.1.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T5.4.1.4.4.1" class="ltx_text ltx_font_bold">61 ms</span></td>
<td id="S4.T5.4.1.4.5" class="ltx_td ltx_align_center ltx_border_b">53.4</td>
<td id="S4.T5.4.1.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">62.6</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.6.2.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.2.2.1" class="ltx_text" style="font-size:90%;">Effects of the layer type in the sparse prediction head. <math id="S4.T6.2.2.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S4.T6.2.2.1.m1.1b"><mrow id="S4.T6.2.2.1.m1.1.1" xref="S4.T6.2.2.1.m1.1.1.cmml"><mn id="S4.T6.2.2.1.m1.1.1.2" xref="S4.T6.2.2.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T6.2.2.1.m1.1.1.1" xref="S4.T6.2.2.1.m1.1.1.1.cmml">×</mo><mn id="S4.T6.2.2.1.m1.1.1.3" xref="S4.T6.2.2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.1.m1.1c"><apply id="S4.T6.2.2.1.m1.1.1.cmml" xref="S4.T6.2.2.1.m1.1.1"><times id="S4.T6.2.2.1.m1.1.1.1.cmml" xref="S4.T6.2.2.1.m1.1.1.1"></times><cn type="integer" id="S4.T6.2.2.1.m1.1.1.2.cmml" xref="S4.T6.2.2.1.m1.1.1.2">1</cn><cn type="integer" id="S4.T6.2.2.1.m1.1.1.3.cmml" xref="S4.T6.2.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.1.m1.1d">1\times 1</annotation></semantics></math> submanifold sparse convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> is the fully connected.</span></figcaption>
<table id="S4.T6.4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T6.4.4.3" class="ltx_tr">
<td id="S4.T6.4.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Head kernel size</td>
<td id="S4.T6.4.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Head latency</td>
<td id="S4.T6.4.4.3.3" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="S4.T6.4.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
</tr>
<tr id="S4.T6.3.3.1" class="ltx_tr">
<td id="S4.T6.3.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<math id="S4.T6.3.3.1.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S4.T6.3.3.1.1.m1.1a"><mrow id="S4.T6.3.3.1.1.m1.1.1" xref="S4.T6.3.3.1.1.m1.1.1.cmml"><mn id="S4.T6.3.3.1.1.m1.1.1.2" xref="S4.T6.3.3.1.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T6.3.3.1.1.m1.1.1.1" xref="S4.T6.3.3.1.1.m1.1.1.1.cmml">×</mo><mn id="S4.T6.3.3.1.1.m1.1.1.3" xref="S4.T6.3.3.1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.1.1.m1.1b"><apply id="S4.T6.3.3.1.1.m1.1.1.cmml" xref="S4.T6.3.3.1.1.m1.1.1"><times id="S4.T6.3.3.1.1.m1.1.1.1.cmml" xref="S4.T6.3.3.1.1.m1.1.1.1"></times><cn type="integer" id="S4.T6.3.3.1.1.m1.1.1.2.cmml" xref="S4.T6.3.3.1.1.m1.1.1.2">1</cn><cn type="integer" id="S4.T6.3.3.1.1.m1.1.1.3.cmml" xref="S4.T6.3.3.1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.1.1.m1.1c">1\times 1</annotation></semantics></math> (FC)</td>
<td id="S4.T6.3.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30 ms</td>
<td id="S4.T6.3.3.1.3" class="ltx_td ltx_align_center ltx_border_t">56.2</td>
<td id="S4.T6.3.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.3</td>
</tr>
<tr id="S4.T6.4.4.2" class="ltx_tr">
<td id="S4.T6.4.4.2.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">
<math id="S4.T6.4.4.2.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.T6.4.4.2.1.m1.1a"><mrow id="S4.T6.4.4.2.1.m1.1.1" xref="S4.T6.4.4.2.1.m1.1.1.cmml"><mn id="S4.T6.4.4.2.1.m1.1.1.2" xref="S4.T6.4.4.2.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.T6.4.4.2.1.m1.1.1.1" xref="S4.T6.4.4.2.1.m1.1.1.1.cmml">×</mo><mn id="S4.T6.4.4.2.1.m1.1.1.3" xref="S4.T6.4.4.2.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.2.1.m1.1b"><apply id="S4.T6.4.4.2.1.m1.1.1.cmml" xref="S4.T6.4.4.2.1.m1.1.1"><times id="S4.T6.4.4.2.1.m1.1.1.1.cmml" xref="S4.T6.4.4.2.1.m1.1.1.1"></times><cn type="integer" id="S4.T6.4.4.2.1.m1.1.1.2.cmml" xref="S4.T6.4.4.2.1.m1.1.1.2">3</cn><cn type="integer" id="S4.T6.4.4.2.1.m1.1.1.3.cmml" xref="S4.T6.4.4.2.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.2.1.m1.1c">3\times 3</annotation></semantics></math> (SpConv)</td>
<td id="S4.T6.4.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">35 ms</td>
<td id="S4.T6.4.4.2.3" class="ltx_td ltx_align_center ltx_border_b">56.8</td>
<td id="S4.T6.4.4.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">64.5</td>
</tr>
</table>
</figure>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.7.2.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T7.2.2.1" class="ltx_text" style="font-size:90%;">Ratios of relative positions of query voxels to the boxes predicted from them. We only take high-quality predicted boxes (IoU with ground-truth boxes <math id="S4.T7.2.2.1.m1.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="S4.T7.2.2.1.m1.1b"><mo id="S4.T7.2.2.1.m1.1.1" xref="S4.T7.2.2.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.1.m1.1c"><gt id="S4.T7.2.2.1.m1.1.1.cmml" xref="S4.T7.2.2.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.1.m1.1d">&gt;</annotation></semantics></math> 0.7 and with matched predicted labels) into consideration. According to the relative positions to their predicted boxes, we split voxels into 3 types of <span id="S4.T7.2.2.1.1" class="ltx_text ltx_font_italic">near center</span>, <span id="S4.T7.2.2.1.2" class="ltx_text ltx_font_italic">near boundary</span>, and <span id="S4.T7.2.2.1.3" class="ltx_text ltx_font_italic">outside box</span>. Overall, most voxels are inside but not near center.</span></figcaption>
<div id="S4.T7.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:62pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-35.0pt,5.0pt) scale(0.861114796175471,0.861114796175471) ;">
<table id="S4.T7.8.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.8.1.1" class="ltx_tr">
<td id="S4.T7.8.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T7.8.1.1.1.1" class="ltx_text ltx_font_italic">Class</span></td>
<td id="S4.T7.8.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Mean</td>
<td id="S4.T7.8.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Car</td>
<td id="S4.T7.8.1.1.4" class="ltx_td ltx_align_center ltx_border_t">Truck</td>
<td id="S4.T7.8.1.1.5" class="ltx_td ltx_align_center ltx_border_t">Bus</td>
<td id="S4.T7.8.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Trailer</td>
<td id="S4.T7.8.1.1.7" class="ltx_td ltx_align_center ltx_border_t">C.V.</td>
<td id="S4.T7.8.1.1.8" class="ltx_td ltx_align_center ltx_border_t">Ped</td>
<td id="S4.T7.8.1.1.9" class="ltx_td ltx_align_center ltx_border_t">Mot</td>
<td id="S4.T7.8.1.1.10" class="ltx_td ltx_align_center ltx_border_t">Byc</td>
<td id="S4.T7.8.1.1.11" class="ltx_td ltx_align_center ltx_border_t">T.C.</td>
<td id="S4.T7.8.1.1.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Bar</td>
</tr>
<tr id="S4.T7.8.1.2" class="ltx_tr">
<td id="S4.T7.8.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Near center</td>
<td id="S4.T7.8.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9.9%</td>
<td id="S4.T7.8.1.2.3" class="ltx_td ltx_align_center ltx_border_t">10.3%</td>
<td id="S4.T7.8.1.2.4" class="ltx_td ltx_align_center ltx_border_t">5.6%</td>
<td id="S4.T7.8.1.2.5" class="ltx_td ltx_align_center ltx_border_t">15.2%</td>
<td id="S4.T7.8.1.2.6" class="ltx_td ltx_align_center ltx_border_t">1.2%</td>
<td id="S4.T7.8.1.2.7" class="ltx_td ltx_align_center ltx_border_t">16.3%</td>
<td id="S4.T7.8.1.2.8" class="ltx_td ltx_align_center ltx_border_t">12.5%</td>
<td id="S4.T7.8.1.2.9" class="ltx_td ltx_align_center ltx_border_t">19.6%</td>
<td id="S4.T7.8.1.2.10" class="ltx_td ltx_align_center ltx_border_t">13.1%</td>
<td id="S4.T7.8.1.2.11" class="ltx_td ltx_align_center ltx_border_t">10.8%</td>
<td id="S4.T7.8.1.2.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">17.8%</td>
</tr>
<tr id="S4.T7.8.1.3" class="ltx_tr">
<td id="S4.T7.8.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Near boundary</td>
<td id="S4.T7.8.1.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T7.8.1.3.2.1" class="ltx_text ltx_font_bold">72.8%</span></td>
<td id="S4.T7.8.1.3.3" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.3.3.1" class="ltx_text ltx_font_bold">84.3%</span></td>
<td id="S4.T7.8.1.3.4" class="ltx_td ltx_align_center">39.2%</td>
<td id="S4.T7.8.1.3.5" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.3.5.1" class="ltx_text ltx_font_bold">58.8%</span></td>
<td id="S4.T7.8.1.3.6" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.3.6.1" class="ltx_text ltx_font_bold">84.6%</span></td>
<td id="S4.T7.8.1.3.7" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.3.7.1" class="ltx_text ltx_font_bold">51.8%</span></td>
<td id="S4.T7.8.1.3.8" class="ltx_td ltx_align_center">42.3%</td>
<td id="S4.T7.8.1.3.9" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.3.9.1" class="ltx_text ltx_font_bold">66.5%</span></td>
<td id="S4.T7.8.1.3.10" class="ltx_td ltx_align_center"><span id="S4.T7.8.1.3.10.1" class="ltx_text ltx_font_bold">54.7%</span></td>
<td id="S4.T7.8.1.3.11" class="ltx_td ltx_align_center">39.7%</td>
<td id="S4.T7.8.1.3.12" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T7.8.1.3.12.1" class="ltx_text ltx_font_bold">58.7%</span></td>
</tr>
<tr id="S4.T7.8.1.4" class="ltx_tr">
<td id="S4.T7.8.1.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">Outside box</td>
<td id="S4.T7.8.1.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">17.3%</td>
<td id="S4.T7.8.1.4.3" class="ltx_td ltx_align_center ltx_border_b">5.4%</td>
<td id="S4.T7.8.1.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.8.1.4.4.1" class="ltx_text ltx_font_bold">55.3%</span></td>
<td id="S4.T7.8.1.4.5" class="ltx_td ltx_align_center ltx_border_b">26.0%</td>
<td id="S4.T7.8.1.4.6" class="ltx_td ltx_align_center ltx_border_b">14.2%</td>
<td id="S4.T7.8.1.4.7" class="ltx_td ltx_align_center ltx_border_b">31.9%</td>
<td id="S4.T7.8.1.4.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.8.1.4.8.1" class="ltx_text ltx_font_bold">45.2%</span></td>
<td id="S4.T7.8.1.4.9" class="ltx_td ltx_align_center ltx_border_b">13.9%</td>
<td id="S4.T7.8.1.4.10" class="ltx_td ltx_align_center ltx_border_b">32.2%</td>
<td id="S4.T7.8.1.4.11" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.8.1.4.11.1" class="ltx_text ltx_font_bold">49.6%</span></td>
<td id="S4.T7.8.1.4.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">23.5%</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T8.9.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="S4.T8.10.2" class="ltx_text" style="font-size:90%;">Comparison to the representative dense-head method Centerpoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. ATE, ASE, AOE, AVE, and AAE denote the errors of location, size, orientation, velocity, and attribute.</span></figcaption>
<div id="S4.T8.7.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(66.7pt,-16.0pt) scale(1.44446185641253,1.44446185641253) ;">
<table id="S4.T8.7.7.7" class="ltx_tabular ltx_align_middle">
<tr id="S4.T8.7.7.7.8" class="ltx_tr">
<td id="S4.T8.7.7.7.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T8.7.7.7.8.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S4.T8.7.7.7.8.2" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="S4.T8.7.7.7.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
<td id="S4.T8.7.7.7.8.4" class="ltx_td ltx_align_center ltx_border_t">ATE</td>
<td id="S4.T8.7.7.7.8.5" class="ltx_td ltx_align_center ltx_border_t">ASE</td>
<td id="S4.T8.7.7.7.8.6" class="ltx_td ltx_align_center ltx_border_t">AOE</td>
<td id="S4.T8.7.7.7.8.7" class="ltx_td ltx_align_center ltx_border_t">AVE</td>
<td id="S4.T8.7.7.7.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">AAE</td>
</tr>
<tr id="S4.T8.7.7.7.9" class="ltx_tr">
<td id="S4.T8.7.7.7.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CenterPoint</td>
<td id="S4.T8.7.7.7.9.2" class="ltx_td ltx_align_center ltx_border_t">55.6</td>
<td id="S4.T8.7.7.7.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.5</td>
<td id="S4.T8.7.7.7.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T8.7.7.7.9.4.1" class="ltx_text ltx_font_bold">29.7</span></td>
<td id="S4.T8.7.7.7.9.5" class="ltx_td ltx_align_center ltx_border_t">25.7</td>
<td id="S4.T8.7.7.7.9.6" class="ltx_td ltx_align_center ltx_border_t">44.5</td>
<td id="S4.T8.7.7.7.9.7" class="ltx_td ltx_align_center ltx_border_t">24.5</td>
<td id="S4.T8.7.7.7.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T8.7.7.7.9.8.1" class="ltx_text ltx_font_bold">18.8</span></td>
</tr>
<tr id="S4.T8.7.7.7.10" class="ltx_tr">
<td id="S4.T8.7.7.7.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" rowspan="2"><span id="S4.T8.7.7.7.10.1.1" class="ltx_text">VoxelNeXt</span></td>
<td id="S4.T8.7.7.7.10.2" class="ltx_td ltx_align_center"><span id="S4.T8.7.7.7.10.2.1" class="ltx_text ltx_font_bold">56.5</span></td>
<td id="S4.T8.7.7.7.10.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T8.7.7.7.10.3.1" class="ltx_text ltx_font_bold">64.5</span></td>
<td id="S4.T8.7.7.7.10.4" class="ltx_td ltx_align_center">29.9</td>
<td id="S4.T8.7.7.7.10.5" class="ltx_td ltx_align_center"><span id="S4.T8.7.7.7.10.5.1" class="ltx_text ltx_font_bold">25.4</span></td>
<td id="S4.T8.7.7.7.10.6" class="ltx_td ltx_align_center"><span id="S4.T8.7.7.7.10.6.1" class="ltx_text ltx_font_bold">39.6</span></td>
<td id="S4.T8.7.7.7.10.7" class="ltx_td ltx_align_center"><span id="S4.T8.7.7.7.10.7.1" class="ltx_text ltx_font_bold">23.2</span></td>
<td id="S4.T8.7.7.7.10.8" class="ltx_td ltx_align_center ltx_border_r">19.0</td>
</tr>
<tr id="S4.T8.7.7.7.7" class="ltx_tr">
<td id="S4.T8.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_b">
<math id="S4.T8.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T8.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T8.1.1.1.1.1.m1.1.1" xref="S4.T8.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.1.1.m1.1b"><ci id="S4.T8.1.1.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>0.9</td>
<td id="S4.T8.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<math id="S4.T8.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T8.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T8.2.2.2.2.2.m1.1.1" xref="S4.T8.2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.2.2.m1.1b"><ci id="S4.T8.2.2.2.2.2.m1.1.1.cmml" xref="S4.T8.2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math>1.0</td>
<td id="S4.T8.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_b">
<math id="S4.T8.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T8.3.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T8.3.3.3.3.3.m1.1.1" xref="S4.T8.3.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.3.3.m1.1b"><ci id="S4.T8.3.3.3.3.3.m1.1.1.cmml" xref="S4.T8.3.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>0.2</td>
<td id="S4.T8.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_b">
<math id="S4.T8.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.4.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T8.4.4.4.4.4.m1.1.1" xref="S4.T8.4.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.4.4.4.4.4.m1.1b"><ci id="S4.T8.4.4.4.4.4.m1.1.1.cmml" xref="S4.T8.4.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.4.4.4.4.m1.1c">\downarrow</annotation></semantics></math>0.3</td>
<td id="S4.T8.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_b">
<math id="S4.T8.5.5.5.5.5.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.5.5.5.5.5.m1.1a"><mo stretchy="false" id="S4.T8.5.5.5.5.5.m1.1.1" xref="S4.T8.5.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.5.5.5.5.5.m1.1b"><ci id="S4.T8.5.5.5.5.5.m1.1.1.cmml" xref="S4.T8.5.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.5.5.5.5.m1.1c">\downarrow</annotation></semantics></math><span id="S4.T8.5.5.5.5.5.1" class="ltx_text ltx_font_bold">4.9</span>
</td>
<td id="S4.T8.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_b">
<math id="S4.T8.6.6.6.6.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.6.6.6.6.6.m1.1a"><mo stretchy="false" id="S4.T8.6.6.6.6.6.m1.1.1" xref="S4.T8.6.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.6.6.6.6.6.m1.1b"><ci id="S4.T8.6.6.6.6.6.m1.1.1.cmml" xref="S4.T8.6.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.6.6.6.6.m1.1c">\downarrow</annotation></semantics></math>1.3</td>
<td id="S4.T8.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<math id="S4.T8.7.7.7.7.7.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T8.7.7.7.7.7.m1.1a"><mo stretchy="false" id="S4.T8.7.7.7.7.7.m1.1.1" xref="S4.T8.7.7.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.7.7.7.7.7.m1.1b"><ci id="S4.T8.7.7.7.7.7.m1.1.1.cmml" xref="S4.T8.7.7.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.7.7.7.7.m1.1c">\uparrow</annotation></semantics></math>0.2</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T9.2.1.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="S4.T9.3.2" class="ltx_text" style="font-size:90%;">Efficiency statistics on sparse CNN backbone. The computations of Stage 5&amp;6 are limited by their small voxel numbers.</span></figcaption>
<div id="S4.T9.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:158.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(93.5pt,-34.1pt) scale(1.7577179254914,1.7577179254914) ;">
<table id="S4.T9.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T9.4.1.1" class="ltx_tr">
<td id="S4.T9.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T9.4.1.1.1.1" class="ltx_text ltx_font_italic">Stage</span></td>
<td id="S4.T9.4.1.1.2" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.T9.4.1.1.3" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="S4.T9.4.1.1.4" class="ltx_td ltx_align_center ltx_border_t">3</td>
<td id="S4.T9.4.1.1.5" class="ltx_td ltx_align_center ltx_border_t">4</td>
<td id="S4.T9.4.1.1.6" class="ltx_td ltx_align_center ltx_border_t">5</td>
<td id="S4.T9.4.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6</td>
</tr>
<tr id="S4.T9.4.1.2" class="ltx_tr">
<td id="S4.T9.4.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Channel</td>
<td id="S4.T9.4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">16</td>
<td id="S4.T9.4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">32</td>
<td id="S4.T9.4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">64</td>
<td id="S4.T9.4.1.2.5" class="ltx_td ltx_align_center ltx_border_t">128</td>
<td id="S4.T9.4.1.2.6" class="ltx_td ltx_align_center ltx_border_t">128</td>
<td id="S4.T9.4.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</td>
</tr>
<tr id="S4.T9.4.1.3" class="ltx_tr">
<td id="S4.T9.4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Voxels (K)</td>
<td id="S4.T9.4.1.3.2" class="ltx_td ltx_align_center">82.6</td>
<td id="S4.T9.4.1.3.3" class="ltx_td ltx_align_center">46.7</td>
<td id="S4.T9.4.1.3.4" class="ltx_td ltx_align_center">18.2</td>
<td id="S4.T9.4.1.3.5" class="ltx_td ltx_align_center">6.4</td>
<td id="S4.T9.4.1.3.6" class="ltx_td ltx_align_center">3.0</td>
<td id="S4.T9.4.1.3.7" class="ltx_td ltx_align_center ltx_border_r">1.3</td>
</tr>
<tr id="S4.T9.4.1.4" class="ltx_tr">
<td id="S4.T9.4.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">FLOPs (G)</td>
<td id="S4.T9.4.1.4.2" class="ltx_td ltx_align_center">1.1</td>
<td id="S4.T9.4.1.4.3" class="ltx_td ltx_align_center">4.7</td>
<td id="S4.T9.4.1.4.4" class="ltx_td ltx_align_center">8.2</td>
<td id="S4.T9.4.1.4.5" class="ltx_td ltx_align_center">11.7</td>
<td id="S4.T9.4.1.4.6" class="ltx_td ltx_align_center">6.1</td>
<td id="S4.T9.4.1.4.7" class="ltx_td ltx_align_center ltx_border_r">2.8</td>
</tr>
<tr id="S4.T9.4.1.5" class="ltx_tr">
<td id="S4.T9.4.1.5.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">Latency (ms)</td>
<td id="S4.T9.4.1.5.2" class="ltx_td ltx_align_center ltx_border_b">4</td>
<td id="S4.T9.4.1.5.3" class="ltx_td ltx_align_center ltx_border_b">5</td>
<td id="S4.T9.4.1.5.4" class="ltx_td ltx_align_center ltx_border_b">6</td>
<td id="S4.T9.4.1.5.5" class="ltx_td ltx_align_center ltx_border_b">7</td>
<td id="S4.T9.4.1.5.6" class="ltx_td ltx_align_center ltx_border_b">6</td>
<td id="S4.T9.4.1.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">3</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T10.2.1.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="S4.T10.3.2" class="ltx_text" style="font-size:90%;">Effects of sparse max-pool and NMS post-processing. The max-pool follows the submanifold sparse convolution pattern.</span></figcaption>
<table id="S4.T10.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T10.4.1" class="ltx_tr">
<td id="S4.T10.4.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T10.4.1.1.1" class="ltx_text ltx_font_italic">Max-pool</span></td>
<td id="S4.T10.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T10.4.1.2.1" class="ltx_text ltx_font_italic">NMS</span></td>
<td id="S4.T10.4.1.3" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="S4.T10.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
</tr>
<tr id="S4.T10.4.2" class="ltx_tr">
<td id="S4.T10.4.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">✗</td>
<td id="S4.T10.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✗</td>
<td id="S4.T10.4.2.3" class="ltx_td ltx_align_center ltx_border_t">33.0</td>
<td id="S4.T10.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">51.0</td>
</tr>
<tr id="S4.T10.4.3" class="ltx_tr">
<td id="S4.T10.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">✗</td>
<td id="S4.T10.4.3.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="S4.T10.4.3.3" class="ltx_td ltx_align_center">56.0</td>
<td id="S4.T10.4.3.4" class="ltx_td ltx_align_center ltx_border_r">64.2</td>
</tr>
<tr id="S4.T10.4.4" class="ltx_tr">
<td id="S4.T10.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">✓</td>
<td id="S4.T10.4.4.2" class="ltx_td ltx_align_center ltx_border_r">✗</td>
<td id="S4.T10.4.4.3" class="ltx_td ltx_align_center">56.2</td>
<td id="S4.T10.4.4.4" class="ltx_td ltx_align_center ltx_border_r">64.3</td>
</tr>
<tr id="S4.T10.4.5" class="ltx_tr">
<td id="S4.T10.4.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">✓</td>
<td id="S4.T10.4.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">✓</td>
<td id="S4.T10.4.5.3" class="ltx_td ltx_align_center ltx_border_b">56.2</td>
<td id="S4.T10.4.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">63.3</td>
</tr>
</table>
</figure>
<figure id="S4.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T11.2.1.1" class="ltx_text" style="font-size:90%;">Table 11</span>: </span><span id="S4.T11.3.2" class="ltx_text" style="font-size:90%;">Voxel association on nuScenes tracking validation set.</span></figcaption>
<table id="S4.T11.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T11.4.1" class="ltx_tr">
<td id="S4.T11.4.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S4.T11.4.1.1.1" class="ltx_text"></span> <span id="S4.T11.4.1.1.2" class="ltx_text">
<span id="S4.T11.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T11.4.1.1.2.1.1" class="ltx_tr">
<span id="S4.T11.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T11.4.1.1.2.1.1.1.1" class="ltx_text ltx_font_italic">+ Voxel</span></span></span>
<span id="S4.T11.4.1.1.2.1.2" class="ltx_tr">
<span id="S4.T11.4.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T11.4.1.1.2.1.2.1.1" class="ltx_text ltx_font_italic">association</span></span></span>
</span></span><span id="S4.T11.4.1.1.3" class="ltx_text"></span></td>
<td id="S4.T11.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">AMOTA</td>
<td id="S4.T11.4.1.3" class="ltx_td ltx_align_center ltx_border_t">AMOTP</td>
<td id="S4.T11.4.1.4" class="ltx_td ltx_align_center ltx_border_t">MOTA</td>
<td id="S4.T11.4.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IDS</td>
</tr>
<tr id="S4.T11.4.2" class="ltx_tr">
<td id="S4.T11.4.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">✗</td>
<td id="S4.T11.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.1</td>
<td id="S4.T11.4.2.3" class="ltx_td ltx_align_center ltx_border_t">61.6</td>
<td id="S4.T11.4.2.4" class="ltx_td ltx_align_center ltx_border_t">59.3</td>
<td id="S4.T11.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">643</td>
</tr>
<tr id="S4.T11.4.3" class="ltx_tr">
<td id="S4.T11.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">✓</td>
<td id="S4.T11.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T11.4.3.2.1" class="ltx_text ltx_font_bold">70.2</span></td>
<td id="S4.T11.4.3.3" class="ltx_td ltx_align_center ltx_border_b">64.0</td>
<td id="S4.T11.4.3.4" class="ltx_td ltx_align_center ltx_border_b">61.5</td>
<td id="S4.T11.4.3.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">729</td>
</tr>
</table>
</figure>
<figure id="S4.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T12.9.2.1" class="ltx_text" style="font-size:90%;">Table 12</span>: </span><span id="S4.T12.2.2.1" class="ltx_text" style="font-size:90%;">Performance of 3D object detection methods on nuScenes test set. <sup id="S4.T12.2.2.1.1" class="ltx_sup"><span id="S4.T12.2.2.1.1.1" class="ltx_text ltx_font_italic">†</span></sup> means the method that uses double-flip testing. All models listed take LIDAR data as input without image fusion or any model ensemble.</span></figcaption>
<div id="S4.T12.6.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:194.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-84.7pt,37.9pt) scale(0.719107453800092,0.719107453800092) ;">
<table id="S4.T12.6.6.4" class="ltx_tabular ltx_align_middle">
<tr id="S4.T12.6.6.4.5" class="ltx_tr">
<td id="S4.T12.6.6.4.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T12.6.6.4.5.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S4.T12.6.6.4.5.2" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="S4.T12.6.6.4.5.3" class="ltx_td ltx_align_center ltx_border_t">NDS</td>
<td id="S4.T12.6.6.4.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Latency</td>
<td id="S4.T12.6.6.4.5.5" class="ltx_td ltx_align_center ltx_border_t">Car</td>
<td id="S4.T12.6.6.4.5.6" class="ltx_td ltx_align_center ltx_border_t">Truck</td>
<td id="S4.T12.6.6.4.5.7" class="ltx_td ltx_align_center ltx_border_t">Bus</td>
<td id="S4.T12.6.6.4.5.8" class="ltx_td ltx_align_center ltx_border_t">Trailer</td>
<td id="S4.T12.6.6.4.5.9" class="ltx_td ltx_align_center ltx_border_t">C.V.</td>
<td id="S4.T12.6.6.4.5.10" class="ltx_td ltx_align_center ltx_border_t">Ped</td>
<td id="S4.T12.6.6.4.5.11" class="ltx_td ltx_align_center ltx_border_t">Mot</td>
<td id="S4.T12.6.6.4.5.12" class="ltx_td ltx_align_center ltx_border_t">Byc</td>
<td id="S4.T12.6.6.4.5.13" class="ltx_td ltx_align_center ltx_border_t">T.C.</td>
<td id="S4.T12.6.6.4.5.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Bar</td>
</tr>
<tr id="S4.T12.6.6.4.6" class="ltx_tr">
<td id="S4.T12.6.6.4.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">PointPillars <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</td>
<td id="S4.T12.6.6.4.6.2" class="ltx_td ltx_align_center ltx_border_tt">30.5</td>
<td id="S4.T12.6.6.4.6.3" class="ltx_td ltx_align_center ltx_border_tt">45.3</td>
<td id="S4.T12.6.6.4.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">31 ms</td>
<td id="S4.T12.6.6.4.6.5" class="ltx_td ltx_align_center ltx_border_tt">68.4</td>
<td id="S4.T12.6.6.4.6.6" class="ltx_td ltx_align_center ltx_border_tt">23.0</td>
<td id="S4.T12.6.6.4.6.7" class="ltx_td ltx_align_center ltx_border_tt">28.2</td>
<td id="S4.T12.6.6.4.6.8" class="ltx_td ltx_align_center ltx_border_tt">23.4</td>
<td id="S4.T12.6.6.4.6.9" class="ltx_td ltx_align_center ltx_border_tt">4.1</td>
<td id="S4.T12.6.6.4.6.10" class="ltx_td ltx_align_center ltx_border_tt">59.7</td>
<td id="S4.T12.6.6.4.6.11" class="ltx_td ltx_align_center ltx_border_tt">27.4</td>
<td id="S4.T12.6.6.4.6.12" class="ltx_td ltx_align_center ltx_border_tt">1.1</td>
<td id="S4.T12.6.6.4.6.13" class="ltx_td ltx_align_center ltx_border_tt">30.8</td>
<td id="S4.T12.6.6.4.6.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">38.9</td>
</tr>
<tr id="S4.T12.6.6.4.7" class="ltx_tr">
<td id="S4.T12.6.6.4.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">3DSSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</td>
<td id="S4.T12.6.6.4.7.2" class="ltx_td ltx_align_center">42.6</td>
<td id="S4.T12.6.6.4.7.3" class="ltx_td ltx_align_center">56.4</td>
<td id="S4.T12.6.6.4.7.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T12.6.6.4.7.5" class="ltx_td ltx_align_center">81.2</td>
<td id="S4.T12.6.6.4.7.6" class="ltx_td ltx_align_center">47.2</td>
<td id="S4.T12.6.6.4.7.7" class="ltx_td ltx_align_center">61.4</td>
<td id="S4.T12.6.6.4.7.8" class="ltx_td ltx_align_center">30.5</td>
<td id="S4.T12.6.6.4.7.9" class="ltx_td ltx_align_center">12.6</td>
<td id="S4.T12.6.6.4.7.10" class="ltx_td ltx_align_center">70.2</td>
<td id="S4.T12.6.6.4.7.11" class="ltx_td ltx_align_center">36.0</td>
<td id="S4.T12.6.6.4.7.12" class="ltx_td ltx_align_center">8.6</td>
<td id="S4.T12.6.6.4.7.13" class="ltx_td ltx_align_center">31.1</td>
<td id="S4.T12.6.6.4.7.14" class="ltx_td ltx_align_center ltx_border_r">47.9</td>
</tr>
<tr id="S4.T12.6.6.4.8" class="ltx_tr">
<td id="S4.T12.6.6.4.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CBGS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>
</td>
<td id="S4.T12.6.6.4.8.2" class="ltx_td ltx_align_center">52.8</td>
<td id="S4.T12.6.6.4.8.3" class="ltx_td ltx_align_center">63.3</td>
<td id="S4.T12.6.6.4.8.4" class="ltx_td ltx_align_center ltx_border_r">80 ms</td>
<td id="S4.T12.6.6.4.8.5" class="ltx_td ltx_align_center">81.1</td>
<td id="S4.T12.6.6.4.8.6" class="ltx_td ltx_align_center">48.5</td>
<td id="S4.T12.6.6.4.8.7" class="ltx_td ltx_align_center">54.9</td>
<td id="S4.T12.6.6.4.8.8" class="ltx_td ltx_align_center">42.9</td>
<td id="S4.T12.6.6.4.8.9" class="ltx_td ltx_align_center">10.5</td>
<td id="S4.T12.6.6.4.8.10" class="ltx_td ltx_align_center">80.1</td>
<td id="S4.T12.6.6.4.8.11" class="ltx_td ltx_align_center">51.5</td>
<td id="S4.T12.6.6.4.8.12" class="ltx_td ltx_align_center">22.3</td>
<td id="S4.T12.6.6.4.8.13" class="ltx_td ltx_align_center">70.9</td>
<td id="S4.T12.6.6.4.8.14" class="ltx_td ltx_align_center ltx_border_r">65.7</td>
</tr>
<tr id="S4.T12.6.6.4.9" class="ltx_tr">
<td id="S4.T12.6.6.4.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T12.6.6.4.9.2" class="ltx_td ltx_align_center">58.0</td>
<td id="S4.T12.6.6.4.9.3" class="ltx_td ltx_align_center">65.5</td>
<td id="S4.T12.6.6.4.9.4" class="ltx_td ltx_align_center ltx_border_r">96 ms</td>
<td id="S4.T12.6.6.4.9.5" class="ltx_td ltx_align_center">84.6</td>
<td id="S4.T12.6.6.4.9.6" class="ltx_td ltx_align_center">51.0</td>
<td id="S4.T12.6.6.4.9.7" class="ltx_td ltx_align_center">60.2</td>
<td id="S4.T12.6.6.4.9.8" class="ltx_td ltx_align_center">53.2</td>
<td id="S4.T12.6.6.4.9.9" class="ltx_td ltx_align_center">17.5</td>
<td id="S4.T12.6.6.4.9.10" class="ltx_td ltx_align_center">83.4</td>
<td id="S4.T12.6.6.4.9.11" class="ltx_td ltx_align_center">53.7</td>
<td id="S4.T12.6.6.4.9.12" class="ltx_td ltx_align_center">28.7</td>
<td id="S4.T12.6.6.4.9.13" class="ltx_td ltx_align_center">76.7</td>
<td id="S4.T12.6.6.4.9.14" class="ltx_td ltx_align_center ltx_border_r">70.9</td>
</tr>
<tr id="S4.T12.6.6.4.10" class="ltx_tr">
<td id="S4.T12.6.6.4.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CVCNET <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
</td>
<td id="S4.T12.6.6.4.10.2" class="ltx_td ltx_align_center">58.2</td>
<td id="S4.T12.6.6.4.10.3" class="ltx_td ltx_align_center">66.6</td>
<td id="S4.T12.6.6.4.10.4" class="ltx_td ltx_align_center ltx_border_r">122 ms</td>
<td id="S4.T12.6.6.4.10.5" class="ltx_td ltx_align_center">82.6</td>
<td id="S4.T12.6.6.4.10.6" class="ltx_td ltx_align_center">49.5</td>
<td id="S4.T12.6.6.4.10.7" class="ltx_td ltx_align_center">59.4</td>
<td id="S4.T12.6.6.4.10.8" class="ltx_td ltx_align_center">51.1</td>
<td id="S4.T12.6.6.4.10.9" class="ltx_td ltx_align_center">16.2</td>
<td id="S4.T12.6.6.4.10.10" class="ltx_td ltx_align_center">83.0</td>
<td id="S4.T12.6.6.4.10.11" class="ltx_td ltx_align_center">61.8</td>
<td id="S4.T12.6.6.4.10.12" class="ltx_td ltx_align_center">38.8</td>
<td id="S4.T12.6.6.4.10.13" class="ltx_td ltx_align_center">69.7</td>
<td id="S4.T12.6.6.4.10.14" class="ltx_td ltx_align_center ltx_border_r">69.7</td>
</tr>
<tr id="S4.T12.6.6.4.11" class="ltx_tr">
<td id="S4.T12.6.6.4.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">HotSpotNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</td>
<td id="S4.T12.6.6.4.11.2" class="ltx_td ltx_align_center">59.3</td>
<td id="S4.T12.6.6.4.11.3" class="ltx_td ltx_align_center">66.0</td>
<td id="S4.T12.6.6.4.11.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T12.6.6.4.11.5" class="ltx_td ltx_align_center">83.1</td>
<td id="S4.T12.6.6.4.11.6" class="ltx_td ltx_align_center">50.9</td>
<td id="S4.T12.6.6.4.11.7" class="ltx_td ltx_align_center">56.4</td>
<td id="S4.T12.6.6.4.11.8" class="ltx_td ltx_align_center">53.3</td>
<td id="S4.T12.6.6.4.11.9" class="ltx_td ltx_align_center">23.0</td>
<td id="S4.T12.6.6.4.11.10" class="ltx_td ltx_align_center">81.3</td>
<td id="S4.T12.6.6.4.11.11" class="ltx_td ltx_align_center">63.5</td>
<td id="S4.T12.6.6.4.11.12" class="ltx_td ltx_align_center">36.6</td>
<td id="S4.T12.6.6.4.11.13" class="ltx_td ltx_align_center">73.0</td>
<td id="S4.T12.6.6.4.11.14" class="ltx_td ltx_align_center ltx_border_r">71.6</td>
</tr>
<tr id="S4.T12.6.6.4.12" class="ltx_tr">
<td id="S4.T12.6.6.4.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">AFDetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S4.T12.6.6.4.12.2" class="ltx_td ltx_align_center">62.4</td>
<td id="S4.T12.6.6.4.12.3" class="ltx_td ltx_align_center">68.5</td>
<td id="S4.T12.6.6.4.12.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T12.6.6.4.12.5" class="ltx_td ltx_align_center">86.3</td>
<td id="S4.T12.6.6.4.12.6" class="ltx_td ltx_align_center">54.2</td>
<td id="S4.T12.6.6.4.12.7" class="ltx_td ltx_align_center">62.5</td>
<td id="S4.T12.6.6.4.12.8" class="ltx_td ltx_align_center">58.9</td>
<td id="S4.T12.6.6.4.12.9" class="ltx_td ltx_align_center">26.7</td>
<td id="S4.T12.6.6.4.12.10" class="ltx_td ltx_align_center">85.8</td>
<td id="S4.T12.6.6.4.12.11" class="ltx_td ltx_align_center">63.8</td>
<td id="S4.T12.6.6.4.12.12" class="ltx_td ltx_align_center">34.3</td>
<td id="S4.T12.6.6.4.12.13" class="ltx_td ltx_align_center">80.1</td>
<td id="S4.T12.6.6.4.12.14" class="ltx_td ltx_align_center ltx_border_r">71.0</td>
</tr>
<tr id="S4.T12.6.6.4.13" class="ltx_tr">
<td id="S4.T12.6.6.4.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Focals Conv <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T12.6.6.4.13.2" class="ltx_td ltx_align_center">63.8</td>
<td id="S4.T12.6.6.4.13.3" class="ltx_td ltx_align_center">70.0</td>
<td id="S4.T12.6.6.4.13.4" class="ltx_td ltx_align_center ltx_border_r">138 ms</td>
<td id="S4.T12.6.6.4.13.5" class="ltx_td ltx_align_center">86.7</td>
<td id="S4.T12.6.6.4.13.6" class="ltx_td ltx_align_center">56.3</td>
<td id="S4.T12.6.6.4.13.7" class="ltx_td ltx_align_center">67.7</td>
<td id="S4.T12.6.6.4.13.8" class="ltx_td ltx_align_center">59.5</td>
<td id="S4.T12.6.6.4.13.9" class="ltx_td ltx_align_center">23.8</td>
<td id="S4.T12.6.6.4.13.10" class="ltx_td ltx_align_center">87.5</td>
<td id="S4.T12.6.6.4.13.11" class="ltx_td ltx_align_center">64.5</td>
<td id="S4.T12.6.6.4.13.12" class="ltx_td ltx_align_center">36.3</td>
<td id="S4.T12.6.6.4.13.13" class="ltx_td ltx_align_center">81.4</td>
<td id="S4.T12.6.6.4.13.14" class="ltx_td ltx_align_center ltx_border_r">74.1</td>
</tr>
<tr id="S4.T12.3.3.1.1" class="ltx_tr">
<td id="S4.T12.3.3.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">VISTA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite><sup id="S4.T12.3.3.1.1.1.1" class="ltx_sup"><span id="S4.T12.3.3.1.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
<td id="S4.T12.3.3.1.1.2" class="ltx_td ltx_align_center">63.0</td>
<td id="S4.T12.3.3.1.1.3" class="ltx_td ltx_align_center">69.8</td>
<td id="S4.T12.3.3.1.1.4" class="ltx_td ltx_align_center ltx_border_r">94 ms</td>
<td id="S4.T12.3.3.1.1.5" class="ltx_td ltx_align_center">84.4</td>
<td id="S4.T12.3.3.1.1.6" class="ltx_td ltx_align_center">55.1</td>
<td id="S4.T12.3.3.1.1.7" class="ltx_td ltx_align_center">63.7</td>
<td id="S4.T12.3.3.1.1.8" class="ltx_td ltx_align_center">54.2</td>
<td id="S4.T12.3.3.1.1.9" class="ltx_td ltx_align_center">25.1</td>
<td id="S4.T12.3.3.1.1.10" class="ltx_td ltx_align_center">82.8</td>
<td id="S4.T12.3.3.1.1.11" class="ltx_td ltx_align_center">70.0</td>
<td id="S4.T12.3.3.1.1.12" class="ltx_td ltx_align_center">45.4</td>
<td id="S4.T12.3.3.1.1.13" class="ltx_td ltx_align_center">78.5</td>
<td id="S4.T12.3.3.1.1.14" class="ltx_td ltx_align_center ltx_border_r">71.4</td>
</tr>
<tr id="S4.T12.4.4.2.2" class="ltx_tr">
<td id="S4.T12.4.4.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">UVTR-L <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite><sup id="S4.T12.4.4.2.2.1.1" class="ltx_sup"><span id="S4.T12.4.4.2.2.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
<td id="S4.T12.4.4.2.2.2" class="ltx_td ltx_align_center">63.9</td>
<td id="S4.T12.4.4.2.2.3" class="ltx_td ltx_align_center">69.7</td>
<td id="S4.T12.4.4.2.2.4" class="ltx_td ltx_align_center ltx_border_r">132 ms</td>
<td id="S4.T12.4.4.2.2.5" class="ltx_td ltx_align_center">86.3</td>
<td id="S4.T12.4.4.2.2.6" class="ltx_td ltx_align_center">52.2</td>
<td id="S4.T12.4.4.2.2.7" class="ltx_td ltx_align_center">62.8</td>
<td id="S4.T12.4.4.2.2.8" class="ltx_td ltx_align_center">59.7</td>
<td id="S4.T12.4.4.2.2.9" class="ltx_td ltx_align_center">33.7</td>
<td id="S4.T12.4.4.2.2.10" class="ltx_td ltx_align_center">84.5</td>
<td id="S4.T12.4.4.2.2.11" class="ltx_td ltx_align_center">68.8</td>
<td id="S4.T12.4.4.2.2.12" class="ltx_td ltx_align_center">41.1</td>
<td id="S4.T12.4.4.2.2.13" class="ltx_td ltx_align_center">74.7</td>
<td id="S4.T12.4.4.2.2.14" class="ltx_td ltx_align_center ltx_border_r">74.9</td>
</tr>
<tr id="S4.T12.5.5.3.3" class="ltx_tr">
<td id="S4.T12.5.5.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">PillarNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite><sup id="S4.T12.5.5.3.3.1.1" class="ltx_sup"><span id="S4.T12.5.5.3.3.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
<td id="S4.T12.5.5.3.3.2" class="ltx_td ltx_align_center">65.0</td>
<td id="S4.T12.5.5.3.3.3" class="ltx_td ltx_align_center">70.8</td>
<td id="S4.T12.5.5.3.3.4" class="ltx_td ltx_align_center ltx_border_r">78 ms</td>
<td id="S4.T12.5.5.3.3.5" class="ltx_td ltx_align_center">87.4</td>
<td id="S4.T12.5.5.3.3.6" class="ltx_td ltx_align_center">56.7</td>
<td id="S4.T12.5.5.3.3.7" class="ltx_td ltx_align_center">60.9</td>
<td id="S4.T12.5.5.3.3.8" class="ltx_td ltx_align_center">61.8</td>
<td id="S4.T12.5.5.3.3.9" class="ltx_td ltx_align_center">30.4</td>
<td id="S4.T12.5.5.3.3.10" class="ltx_td ltx_align_center">87.2</td>
<td id="S4.T12.5.5.3.3.11" class="ltx_td ltx_align_center">67.4</td>
<td id="S4.T12.5.5.3.3.12" class="ltx_td ltx_align_center">40.3</td>
<td id="S4.T12.5.5.3.3.13" class="ltx_td ltx_align_center">82.1</td>
<td id="S4.T12.5.5.3.3.14" class="ltx_td ltx_align_center ltx_border_r">76.0</td>
</tr>
<tr id="S4.T12.6.6.4.14" class="ltx_tr">
<td id="S4.T12.6.6.4.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">VoxelNeXt-2D</td>
<td id="S4.T12.6.6.4.14.2" class="ltx_td ltx_align_center ltx_border_tt">64.1</td>
<td id="S4.T12.6.6.4.14.3" class="ltx_td ltx_align_center ltx_border_tt">69.8</td>
<td id="S4.T12.6.6.4.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">61 ms</td>
<td id="S4.T12.6.6.4.14.5" class="ltx_td ltx_align_center ltx_border_tt">84.8</td>
<td id="S4.T12.6.6.4.14.6" class="ltx_td ltx_align_center ltx_border_tt">52.7</td>
<td id="S4.T12.6.6.4.14.7" class="ltx_td ltx_align_center ltx_border_tt">62.3</td>
<td id="S4.T12.6.6.4.14.8" class="ltx_td ltx_align_center ltx_border_tt">56.2</td>
<td id="S4.T12.6.6.4.14.9" class="ltx_td ltx_align_center ltx_border_tt">29.5</td>
<td id="S4.T12.6.6.4.14.10" class="ltx_td ltx_align_center ltx_border_tt">84.5</td>
<td id="S4.T12.6.6.4.14.11" class="ltx_td ltx_align_center ltx_border_tt">72.5</td>
<td id="S4.T12.6.6.4.14.12" class="ltx_td ltx_align_center ltx_border_tt">45.7</td>
<td id="S4.T12.6.6.4.14.13" class="ltx_td ltx_align_center ltx_border_tt">78.8</td>
<td id="S4.T12.6.6.4.14.14" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">73.7</td>
</tr>
<tr id="S4.T12.6.6.4.15" class="ltx_tr">
<td id="S4.T12.6.6.4.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">VoxelNeXt</td>
<td id="S4.T12.6.6.4.15.2" class="ltx_td ltx_align_center">64.5</td>
<td id="S4.T12.6.6.4.15.3" class="ltx_td ltx_align_center">70.0</td>
<td id="S4.T12.6.6.4.15.4" class="ltx_td ltx_align_center ltx_border_r">66 ms</td>
<td id="S4.T12.6.6.4.15.5" class="ltx_td ltx_align_center">84.6</td>
<td id="S4.T12.6.6.4.15.6" class="ltx_td ltx_align_center">53.0</td>
<td id="S4.T12.6.6.4.15.7" class="ltx_td ltx_align_center">64.7</td>
<td id="S4.T12.6.6.4.15.8" class="ltx_td ltx_align_center">55.8</td>
<td id="S4.T12.6.6.4.15.9" class="ltx_td ltx_align_center">28.7</td>
<td id="S4.T12.6.6.4.15.10" class="ltx_td ltx_align_center">85.8</td>
<td id="S4.T12.6.6.4.15.11" class="ltx_td ltx_align_center">73.2</td>
<td id="S4.T12.6.6.4.15.12" class="ltx_td ltx_align_center">45.7</td>
<td id="S4.T12.6.6.4.15.13" class="ltx_td ltx_align_center">79.0</td>
<td id="S4.T12.6.6.4.15.14" class="ltx_td ltx_align_center ltx_border_r">74.6</td>
</tr>
<tr id="S4.T12.6.6.4.4" class="ltx_tr">
<td id="S4.T12.6.6.4.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt<sup id="S4.T12.6.6.4.4.1.1" class="ltx_sup"><span id="S4.T12.6.6.4.4.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
<td id="S4.T12.6.6.4.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T12.6.6.4.4.2.1" class="ltx_text ltx_font_bold">66.2</span></td>
<td id="S4.T12.6.6.4.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T12.6.6.4.4.3.1" class="ltx_text ltx_font_bold">71.4</span></td>
<td id="S4.T12.6.6.4.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">-</td>
<td id="S4.T12.6.6.4.4.5" class="ltx_td ltx_align_center ltx_border_b">85.3</td>
<td id="S4.T12.6.6.4.4.6" class="ltx_td ltx_align_center ltx_border_b">55.7</td>
<td id="S4.T12.6.6.4.4.7" class="ltx_td ltx_align_center ltx_border_b">66.2</td>
<td id="S4.T12.6.6.4.4.8" class="ltx_td ltx_align_center ltx_border_b">57.2</td>
<td id="S4.T12.6.6.4.4.9" class="ltx_td ltx_align_center ltx_border_b">29.8</td>
<td id="S4.T12.6.6.4.4.10" class="ltx_td ltx_align_center ltx_border_b">86.5</td>
<td id="S4.T12.6.6.4.4.11" class="ltx_td ltx_align_center ltx_border_b">75.2</td>
<td id="S4.T12.6.6.4.4.12" class="ltx_td ltx_align_center ltx_border_b">48.8</td>
<td id="S4.T12.6.6.4.4.13" class="ltx_td ltx_align_center ltx_border_b">80.7</td>
<td id="S4.T12.6.6.4.4.14" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">76.1</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T13" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T13.6.2.1" class="ltx_text" style="font-size:90%;">Table 13</span>: </span><span id="S4.T13.2.2.1" class="ltx_text" style="font-size:90%;">Performance of nuScenes 3D tracking test split for LIDAR-only methods, without multi-modal extension. <sup id="S4.T13.2.2.1.1" class="ltx_sup"><span id="S4.T13.2.2.1.1.1" class="ltx_text ltx_font_italic">†</span></sup> is based on the double-flip 3D object detection results in Tab. <a href="#S4.T12" title="Table 12 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.</span></figcaption>
<div id="S4.T13.3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:239pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(53.5pt,-29.5pt) scale(1.32798439488471,1.32798439488471) ;">
<table id="S4.T13.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T13.3.3.1.2" class="ltx_tr">
<td id="S4.T13.3.3.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T13.3.3.1.2.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S4.T13.3.3.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">AMOTA</td>
<td id="S4.T13.3.3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">AMOTP</td>
<td id="S4.T13.3.3.1.2.4" class="ltx_td ltx_align_center ltx_border_t">MOTA</td>
<td id="S4.T13.3.3.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IDS</td>
</tr>
<tr id="S4.T13.3.3.1.3" class="ltx_tr">
<td id="S4.T13.3.3.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">AB3DMOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="S4.T13.3.3.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">15.1</td>
<td id="S4.T13.3.3.1.3.3" class="ltx_td ltx_align_center ltx_border_tt">150.1</td>
<td id="S4.T13.3.3.1.3.4" class="ltx_td ltx_align_center ltx_border_tt">15.4</td>
<td id="S4.T13.3.3.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">9027</td>
</tr>
<tr id="S4.T13.3.3.1.4" class="ltx_tr">
<td id="S4.T13.3.3.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T13.3.3.1.4.2" class="ltx_td ltx_align_center ltx_border_r">63.8</td>
<td id="S4.T13.3.3.1.4.3" class="ltx_td ltx_align_center">55.5</td>
<td id="S4.T13.3.3.1.4.4" class="ltx_td ltx_align_center">53.7</td>
<td id="S4.T13.3.3.1.4.5" class="ltx_td ltx_align_center ltx_border_r">760</td>
</tr>
<tr id="S4.T13.3.3.1.5" class="ltx_tr">
<td id="S4.T13.3.3.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CBMOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S4.T13.3.3.1.5.2" class="ltx_td ltx_align_center ltx_border_r">64.9</td>
<td id="S4.T13.3.3.1.5.3" class="ltx_td ltx_align_center">59.2</td>
<td id="S4.T13.3.3.1.5.4" class="ltx_td ltx_align_center">54.5</td>
<td id="S4.T13.3.3.1.5.5" class="ltx_td ltx_align_center ltx_border_r">557</td>
</tr>
<tr id="S4.T13.3.3.1.6" class="ltx_tr">
<td id="S4.T13.3.3.1.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">OGR3MOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>
</td>
<td id="S4.T13.3.3.1.6.2" class="ltx_td ltx_align_center ltx_border_r">65.6</td>
<td id="S4.T13.3.3.1.6.3" class="ltx_td ltx_align_center">62.0</td>
<td id="S4.T13.3.3.1.6.4" class="ltx_td ltx_align_center">55.4</td>
<td id="S4.T13.3.3.1.6.5" class="ltx_td ltx_align_center ltx_border_r">288</td>
</tr>
<tr id="S4.T13.3.3.1.7" class="ltx_tr">
<td id="S4.T13.3.3.1.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">SimpleTrack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
<td id="S4.T13.3.3.1.7.2" class="ltx_td ltx_align_center ltx_border_r">66.8</td>
<td id="S4.T13.3.3.1.7.3" class="ltx_td ltx_align_center">55.0</td>
<td id="S4.T13.3.3.1.7.4" class="ltx_td ltx_align_center">56.6</td>
<td id="S4.T13.3.3.1.7.5" class="ltx_td ltx_align_center ltx_border_r">575</td>
</tr>
<tr id="S4.T13.3.3.1.8" class="ltx_tr">
<td id="S4.T13.3.3.1.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">UVTR-L <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>
</td>
<td id="S4.T13.3.3.1.8.2" class="ltx_td ltx_align_center ltx_border_r">67.0</td>
<td id="S4.T13.3.3.1.8.3" class="ltx_td ltx_align_center">55.0</td>
<td id="S4.T13.3.3.1.8.4" class="ltx_td ltx_align_center">56.6</td>
<td id="S4.T13.3.3.1.8.5" class="ltx_td ltx_align_center ltx_border_r">774</td>
</tr>
<tr id="S4.T13.3.3.1.9" class="ltx_tr">
<td id="S4.T13.3.3.1.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">TransFusion-L <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
</td>
<td id="S4.T13.3.3.1.9.2" class="ltx_td ltx_align_center ltx_border_r">68.6</td>
<td id="S4.T13.3.3.1.9.3" class="ltx_td ltx_align_center">52.9</td>
<td id="S4.T13.3.3.1.9.4" class="ltx_td ltx_align_center">57.1</td>
<td id="S4.T13.3.3.1.9.5" class="ltx_td ltx_align_center ltx_border_r">893</td>
</tr>
<tr id="S4.T13.3.3.1.10" class="ltx_tr">
<td id="S4.T13.3.3.1.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt</td>
<td id="S4.T13.3.3.1.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T13.3.3.1.10.2.1" class="ltx_text ltx_font_bold">69.5</span></td>
<td id="S4.T13.3.3.1.10.3" class="ltx_td ltx_align_center ltx_border_t">56.8</td>
<td id="S4.T13.3.3.1.10.4" class="ltx_td ltx_align_center ltx_border_t">58.6</td>
<td id="S4.T13.3.3.1.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">785</td>
</tr>
<tr id="S4.T13.3.3.1.1" class="ltx_tr">
<td id="S4.T13.3.3.1.1.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt<sup id="S4.T13.3.3.1.1.1.1" class="ltx_sup"><span id="S4.T13.3.3.1.1.1.1.1" class="ltx_text ltx_font_italic">†</span></sup>
</td>
<td id="S4.T13.3.3.1.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T13.3.3.1.1.2.1" class="ltx_text ltx_font_bold">71.0</span></td>
<td id="S4.T13.3.3.1.1.3" class="ltx_td ltx_align_center ltx_border_b">51.1</td>
<td id="S4.T13.3.3.1.1.4" class="ltx_td ltx_align_center ltx_border_b">60.0</td>
<td id="S4.T13.3.3.1.1.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">654</td>
</tr>
</table>
</span></div>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Ablation Studies</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS1.p1.8" class="ltx_p"><span id="S4.SS1.p1.8.1" class="ltx_text ltx_font_bold">Additional Down-sampling Layers</span>
We ablate the effect of the down-sampling layers in VoxelNeXt.
We extend it to the variants <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="D_{s}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">D</mi><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝐷</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">D_{s}</annotation></semantics></math>. <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">s</annotation></semantics></math> denotes the number of down-sampling. For example, <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><msub id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">D</mi><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝐷</ci><cn type="integer" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">D_{3}</annotation></semantics></math> has the same network strides (3 times) to the base model. Our modification does not change the resolution for the detection head.
The results of these models are shown in Tab. <a href="#S3.T2" title="Table 2 ‣ 3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Without the dense head, <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">D</mi><mn id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝐷</ci><cn type="integer" id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">D_{3}</annotation></semantics></math> suffers from serious performance drop, especially on large objects of <span id="S4.SS1.p1.8.2" class="ltx_text ltx_font_italic">Truck</span> and <span id="S4.SS1.p1.8.3" class="ltx_text ltx_font_italic">Bus</span>. From <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="D_{3}" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><msub id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">D</mi><mn id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">𝐷</ci><cn type="integer" id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">D_{3}</annotation></semantics></math> to <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="D_{5}" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><msub id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml">D</mi><mn id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml">5</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2">𝐷</ci><cn type="integer" id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">D_{5}</annotation></semantics></math>, performance gradually increases. Additional down-sampling layers compensate for the receptive field. To verify this, we add one more variant, <math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="D_{3}^{5\times 5\times 5}" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><msubsup id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2.2" xref="S4.SS1.p1.7.m7.1.1.2.2.cmml">D</mi><mn id="S4.SS1.p1.7.m7.1.1.2.3" xref="S4.SS1.p1.7.m7.1.1.2.3.cmml">3</mn><mrow id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml"><mn id="S4.SS1.p1.7.m7.1.1.3.2" xref="S4.SS1.p1.7.m7.1.1.3.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.7.m7.1.1.3.1" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml">×</mo><mn id="S4.SS1.p1.7.m7.1.1.3.3" xref="S4.SS1.p1.7.m7.1.1.3.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.7.m7.1.1.3.1a" xref="S4.SS1.p1.7.m7.1.1.3.1.cmml">×</mo><mn id="S4.SS1.p1.7.m7.1.1.3.4" xref="S4.SS1.p1.7.m7.1.1.3.4.cmml">5</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">superscript</csymbol><apply id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.2.1.cmml" xref="S4.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.2.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2.2">𝐷</ci><cn type="integer" id="S4.SS1.p1.7.m7.1.1.2.3.cmml" xref="S4.SS1.p1.7.m7.1.1.2.3">3</cn></apply><apply id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3"><times id="S4.SS1.p1.7.m7.1.1.3.1.cmml" xref="S4.SS1.p1.7.m7.1.1.3.1"></times><cn type="integer" id="S4.SS1.p1.7.m7.1.1.3.2.cmml" xref="S4.SS1.p1.7.m7.1.1.3.2">5</cn><cn type="integer" id="S4.SS1.p1.7.m7.1.1.3.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3">5</cn><cn type="integer" id="S4.SS1.p1.7.m7.1.1.3.4.cmml" xref="S4.SS1.p1.7.m7.1.1.3.4">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">D_{3}^{5\times 5\times 5}</annotation></semantics></math>, which increases the kernel size of sparse convolutions in all stages to <math id="S4.SS1.p1.8.m8.1" class="ltx_Math" alttext="5\times 5\times 5" display="inline"><semantics id="S4.SS1.p1.8.m8.1a"><mrow id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml"><mn id="S4.SS1.p1.8.m8.1.1.2" xref="S4.SS1.p1.8.m8.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.8.m8.1.1.1" xref="S4.SS1.p1.8.m8.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.8.m8.1.1.3" xref="S4.SS1.p1.8.m8.1.1.3.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p1.8.m8.1.1.1a" xref="S4.SS1.p1.8.m8.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.8.m8.1.1.4" xref="S4.SS1.p1.8.m8.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><apply id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1"><times id="S4.SS1.p1.8.m8.1.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1.1"></times><cn type="integer" id="S4.SS1.p1.8.m8.1.1.2.cmml" xref="S4.SS1.p1.8.m8.1.1.2">5</cn><cn type="integer" id="S4.SS1.p1.8.m8.1.1.3.cmml" xref="S4.SS1.p1.8.m8.1.1.3">5</cn><cn type="integer" id="S4.SS1.p1.8.m8.1.1.4.cmml" xref="S4.SS1.p1.8.m8.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">5\times 5\times 5</annotation></semantics></math>. Large kernel improves the performance to some extend but degrades efficiency.
Thus, we use additional down-samplings as a simple solution.</p>
</div>
<figure id="S4.T14" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T14.2.1.1" class="ltx_text" style="font-size:90%;">Table 14</span>: </span><span id="S4.T14.3.2" class="ltx_text" style="font-size:90%;">Performance of nuScenes 3D tracking validation set. All methods listed are LIDAR-only, without multi-modal extension.</span></figcaption>
<div id="S4.T14.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:185.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(48.2pt,-20.6pt) scale(1.28549840107267,1.28549840107267) ;">
<table id="S4.T14.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T14.4.1.1" class="ltx_tr">
<td id="S4.T14.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T14.4.1.1.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S4.T14.4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">AMOTA</td>
<td id="S4.T14.4.1.1.3" class="ltx_td ltx_align_center ltx_border_t">AMOTP</td>
<td id="S4.T14.4.1.1.4" class="ltx_td ltx_align_center ltx_border_t">MOTA</td>
<td id="S4.T14.4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">IDS</td>
</tr>
<tr id="S4.T14.4.1.2" class="ltx_tr">
<td id="S4.T14.4.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">AB3DMOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>
</td>
<td id="S4.T14.4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">57.8</td>
<td id="S4.T14.4.1.2.3" class="ltx_td ltx_align_center ltx_border_tt">80.7</td>
<td id="S4.T14.4.1.2.4" class="ltx_td ltx_align_center ltx_border_tt">51.4</td>
<td id="S4.T14.4.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">1275</td>
</tr>
<tr id="S4.T14.4.1.3" class="ltx_tr">
<td id="S4.T14.4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">MPN-Baseline</td>
<td id="S4.T14.4.1.3.2" class="ltx_td ltx_align_center ltx_border_r">59.3</td>
<td id="S4.T14.4.1.3.3" class="ltx_td ltx_align_center">83.2</td>
<td id="S4.T14.4.1.3.4" class="ltx_td ltx_align_center">51.4</td>
<td id="S4.T14.4.1.3.5" class="ltx_td ltx_align_center ltx_border_r">1079</td>
</tr>
<tr id="S4.T14.4.1.4" class="ltx_tr">
<td id="S4.T14.4.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T14.4.1.4.2" class="ltx_td ltx_align_center ltx_border_r">66.5</td>
<td id="S4.T14.4.1.4.3" class="ltx_td ltx_align_center">56.7</td>
<td id="S4.T14.4.1.4.4" class="ltx_td ltx_align_center">56.2</td>
<td id="S4.T14.4.1.4.5" class="ltx_td ltx_align_center ltx_border_r">562</td>
</tr>
<tr id="S4.T14.4.1.5" class="ltx_tr">
<td id="S4.T14.4.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CBMOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>
</td>
<td id="S4.T14.4.1.5.2" class="ltx_td ltx_align_center ltx_border_r">67.5</td>
<td id="S4.T14.4.1.5.3" class="ltx_td ltx_align_center">59.1</td>
<td id="S4.T14.4.1.5.4" class="ltx_td ltx_align_center">58.3</td>
<td id="S4.T14.4.1.5.5" class="ltx_td ltx_align_center ltx_border_r">494</td>
</tr>
<tr id="S4.T14.4.1.6" class="ltx_tr">
<td id="S4.T14.4.1.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">OGR3MOT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</td>
<td id="S4.T14.4.1.6.2" class="ltx_td ltx_align_center ltx_border_r">69.3</td>
<td id="S4.T14.4.1.6.3" class="ltx_td ltx_align_center">62.7</td>
<td id="S4.T14.4.1.6.4" class="ltx_td ltx_align_center">60.2</td>
<td id="S4.T14.4.1.6.5" class="ltx_td ltx_align_center ltx_border_r">262</td>
</tr>
<tr id="S4.T14.4.1.7" class="ltx_tr">
<td id="S4.T14.4.1.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">SimpleTrack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
<td id="S4.T14.4.1.7.2" class="ltx_td ltx_align_center ltx_border_r">69.6</td>
<td id="S4.T14.4.1.7.3" class="ltx_td ltx_align_center">54.7</td>
<td id="S4.T14.4.1.7.4" class="ltx_td ltx_align_center">60.2</td>
<td id="S4.T14.4.1.7.5" class="ltx_td ltx_align_center ltx_border_r">405</td>
</tr>
<tr id="S4.T14.4.1.8" class="ltx_tr">
<td id="S4.T14.4.1.8.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt</td>
<td id="S4.T14.4.1.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T14.4.1.8.2.1" class="ltx_text ltx_font_bold">70.2</span></td>
<td id="S4.T14.4.1.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">64.0</td>
<td id="S4.T14.4.1.8.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">61.5</td>
<td id="S4.T14.4.1.8.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">729</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T15" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T15.4.1.1" class="ltx_text" style="font-size:90%;">Table 15</span>: </span><span id="S4.T15.5.2" class="ltx_text" style="font-size:90%;">Performance of 3D object detection results on the Waymo validation split.
Results with the instance-decreasing trick in the ground-truth sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> is in the appendix.
All models take single-frame data as input without test-time augmentations or ensemble.</span></figcaption>
<div id="S4.T15.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:280.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-103.5pt,66.9pt) scale(0.676769939439711,0.676769939439711) ;">
<table id="S4.T15.2.2.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T15.2.2.2.3" class="ltx_tr">
<td id="S4.T15.2.2.2.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T15.2.2.2.3.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="S4.T15.2.2.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">mAP/mAPH</td>
<td id="S4.T15.2.2.2.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Vehicle</td>
<td id="S4.T15.2.2.2.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Pedestrian</td>
<td id="S4.T15.2.2.2.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">Cyclist</td>
</tr>
<tr id="S4.T15.2.2.2.4" class="ltx_tr">
<td id="S4.T15.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S4.T15.2.2.2.4.2" class="ltx_td ltx_align_center">L1 AP/APH</td>
<td id="S4.T15.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_r">L2 AP/APH</td>
<td id="S4.T15.2.2.2.4.4" class="ltx_td ltx_align_center">L1 AP/APH</td>
<td id="S4.T15.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_r">L2 AP/APH</td>
<td id="S4.T15.2.2.2.4.6" class="ltx_td ltx_align_center">L1 AP/APH</td>
<td id="S4.T15.2.2.2.4.7" class="ltx_td ltx_align_center ltx_border_r">L2 AP/APH</td>
</tr>
<tr id="S4.T15.2.2.2.5" class="ltx_tr">
<td id="S4.T15.2.2.2.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">Pillar-OD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>
</td>
<td id="S4.T15.2.2.2.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S4.T15.2.2.2.5.3" class="ltx_td ltx_align_center ltx_border_tt">69.8 / -</td>
<td id="S4.T15.2.2.2.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">- / -</td>
<td id="S4.T15.2.2.2.5.5" class="ltx_td ltx_align_center ltx_border_tt">72.5 / -</td>
<td id="S4.T15.2.2.2.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td id="S4.T15.2.2.2.5.7" class="ltx_td ltx_align_center ltx_border_tt">-</td>
<td id="S4.T15.2.2.2.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
</tr>
<tr id="S4.T15.2.2.2.6" class="ltx_tr">
<td id="S4.T15.2.2.2.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">VoxSeT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S4.T15.2.2.2.6.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T15.2.2.2.6.3" class="ltx_td ltx_align_center">76.0 / -</td>
<td id="S4.T15.2.2.2.6.4" class="ltx_td ltx_align_center ltx_border_r">68.2 / -</td>
<td id="S4.T15.2.2.2.6.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T15.2.2.2.6.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T15.2.2.2.6.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T15.2.2.2.6.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S4.T15.2.2.2.7" class="ltx_tr">
<td id="S4.T15.2.2.2.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">VoTr-TSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
<td id="S4.T15.2.2.2.7.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T15.2.2.2.7.3" class="ltx_td ltx_align_center">74.9 / 74.3</td>
<td id="S4.T15.2.2.2.7.4" class="ltx_td ltx_align_center ltx_border_r">65.9 / 65.3</td>
<td id="S4.T15.2.2.2.7.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T15.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T15.2.2.2.7.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T15.2.2.2.7.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S4.T15.2.2.2.8" class="ltx_tr">
<td id="S4.T15.2.2.2.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">SECOND <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="S4.T15.2.2.2.8.2" class="ltx_td ltx_align_center ltx_border_r">61.0 / 57.2</td>
<td id="S4.T15.2.2.2.8.3" class="ltx_td ltx_align_center">72.3 / 71.7</td>
<td id="S4.T15.2.2.2.8.4" class="ltx_td ltx_align_center ltx_border_r">63.9 / 63.3</td>
<td id="S4.T15.2.2.2.8.5" class="ltx_td ltx_align_center">68.7 / 58.2</td>
<td id="S4.T15.2.2.2.8.6" class="ltx_td ltx_align_center ltx_border_r">60.7 / 51.3</td>
<td id="S4.T15.2.2.2.8.7" class="ltx_td ltx_align_center">60.6 / 59.3</td>
<td id="S4.T15.2.2.2.8.8" class="ltx_td ltx_align_center ltx_border_r">58.3 / 57.0</td>
</tr>
<tr id="S4.T15.2.2.2.9" class="ltx_tr">
<td id="S4.T15.2.2.2.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">M3METR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T15.2.2.2.9.2" class="ltx_td ltx_align_center ltx_border_r">61.8 / 58.7</td>
<td id="S4.T15.2.2.2.9.3" class="ltx_td ltx_align_center">75.7 / 75.1</td>
<td id="S4.T15.2.2.2.9.4" class="ltx_td ltx_align_center ltx_border_r">66.0 / 66.0</td>
<td id="S4.T15.2.2.2.9.5" class="ltx_td ltx_align_center">65.0 / 56.4</td>
<td id="S4.T15.2.2.2.9.6" class="ltx_td ltx_align_center ltx_border_r">56.0 / 48.4</td>
<td id="S4.T15.2.2.2.9.7" class="ltx_td ltx_align_center">65.4 / 64.2</td>
<td id="S4.T15.2.2.2.9.8" class="ltx_td ltx_align_center ltx_border_r">62.7 / 61.5</td>
</tr>
<tr id="S4.T15.2.2.2.10" class="ltx_tr">
<td id="S4.T15.2.2.2.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">IA-SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>
</td>
<td id="S4.T15.2.2.2.10.2" class="ltx_td ltx_align_center ltx_border_r">62.3 / 58.1</td>
<td id="S4.T15.2.2.2.10.3" class="ltx_td ltx_align_center">70.5 / 69.7</td>
<td id="S4.T15.2.2.2.10.4" class="ltx_td ltx_align_center ltx_border_r">61.6 / 61.0</td>
<td id="S4.T15.2.2.2.10.5" class="ltx_td ltx_align_center">69.4 / 58.5</td>
<td id="S4.T15.2.2.2.10.6" class="ltx_td ltx_align_center ltx_border_r">60.3 / 50.7</td>
<td id="S4.T15.2.2.2.10.7" class="ltx_td ltx_align_center">67.7 / 65.3</td>
<td id="S4.T15.2.2.2.10.8" class="ltx_td ltx_align_center ltx_border_r">65.0 / 62.7</td>
</tr>
<tr id="S4.T15.2.2.2.11" class="ltx_tr">
<td id="S4.T15.2.2.2.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">PointPillars <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</td>
<td id="S4.T15.2.2.2.11.2" class="ltx_td ltx_align_center ltx_border_r">62.8 / 57.8</td>
<td id="S4.T15.2.2.2.11.3" class="ltx_td ltx_align_center">72.1 / 71.5</td>
<td id="S4.T15.2.2.2.11.4" class="ltx_td ltx_align_center ltx_border_r">63.6 / 63.1</td>
<td id="S4.T15.2.2.2.11.5" class="ltx_td ltx_align_center">70.6 / 56.7</td>
<td id="S4.T15.2.2.2.11.6" class="ltx_td ltx_align_center ltx_border_r">62.8 / 50.3</td>
<td id="S4.T15.2.2.2.11.7" class="ltx_td ltx_align_center">64.4 / 62.3</td>
<td id="S4.T15.2.2.2.11.8" class="ltx_td ltx_align_center ltx_border_r">61.9 / 59.9</td>
</tr>
<tr id="S4.T15.2.2.2.12" class="ltx_tr">
<td id="S4.T15.2.2.2.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">RangeDet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S4.T15.2.2.2.12.2" class="ltx_td ltx_align_center ltx_border_r">65.0 / 63.2</td>
<td id="S4.T15.2.2.2.12.3" class="ltx_td ltx_align_center">72.9 / 72.3</td>
<td id="S4.T15.2.2.2.12.4" class="ltx_td ltx_align_center ltx_border_r">64.0 / 63.6</td>
<td id="S4.T15.2.2.2.12.5" class="ltx_td ltx_align_center">75.9 / 71.9</td>
<td id="S4.T15.2.2.2.12.6" class="ltx_td ltx_align_center ltx_border_r">67.6 / 63.9</td>
<td id="S4.T15.2.2.2.12.7" class="ltx_td ltx_align_center">65.7 / 64.4</td>
<td id="S4.T15.2.2.2.12.8" class="ltx_td ltx_align_center ltx_border_r">63.3 / 62.1</td>
</tr>
<tr id="S4.T15.2.2.2.13" class="ltx_tr">
<td id="S4.T15.2.2.2.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">3D-MAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>
</td>
<td id="S4.T15.2.2.2.13.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T15.2.2.2.13.3" class="ltx_td ltx_align_center">74.5 / 74.0</td>
<td id="S4.T15.2.2.2.13.4" class="ltx_td ltx_align_center ltx_border_r">67.6 / 67.1</td>
<td id="S4.T15.2.2.2.13.5" class="ltx_td ltx_align_center">71.7 / 67.7</td>
<td id="S4.T15.2.2.2.13.6" class="ltx_td ltx_align_center ltx_border_r">62.6 / 59.0</td>
<td id="S4.T15.2.2.2.13.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T15.2.2.2.13.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S4.T15.2.2.2.14" class="ltx_tr">
<td id="S4.T15.2.2.2.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">LIDAR-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>
</td>
<td id="S4.T15.2.2.2.14.2" class="ltx_td ltx_align_center ltx_border_r">65.8 / 61.3</td>
<td id="S4.T15.2.2.2.14.3" class="ltx_td ltx_align_center">76.0 / 75.5</td>
<td id="S4.T15.2.2.2.14.4" class="ltx_td ltx_align_center ltx_border_r">68.3 / 67.9</td>
<td id="S4.T15.2.2.2.14.5" class="ltx_td ltx_align_center">71.2 / 58.7</td>
<td id="S4.T15.2.2.2.14.6" class="ltx_td ltx_align_center ltx_border_r">63.1 / 51.7</td>
<td id="S4.T15.2.2.2.14.7" class="ltx_td ltx_align_center">68.6 / 66.9</td>
<td id="S4.T15.2.2.2.14.8" class="ltx_td ltx_align_center ltx_border_r">66.1 / 64.4</td>
</tr>
<tr id="S4.T15.2.2.2.15" class="ltx_tr">
<td id="S4.T15.2.2.2.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">PV-RCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
</td>
<td id="S4.T15.2.2.2.15.2" class="ltx_td ltx_align_center ltx_border_r">66.8 / 63.3</td>
<td id="S4.T15.2.2.2.15.3" class="ltx_td ltx_align_center">77.5 / 76.9</td>
<td id="S4.T15.2.2.2.15.4" class="ltx_td ltx_align_center ltx_border_r">69.0 / 68.4</td>
<td id="S4.T15.2.2.2.15.5" class="ltx_td ltx_align_center">75.0 / 65.6</td>
<td id="S4.T15.2.2.2.15.6" class="ltx_td ltx_align_center ltx_border_r">66.0 / 57.6</td>
<td id="S4.T15.2.2.2.15.7" class="ltx_td ltx_align_center">67.8 / 66.4</td>
<td id="S4.T15.2.2.2.15.8" class="ltx_td ltx_align_center ltx_border_r">65.4 / 64.0</td>
</tr>
<tr id="S4.T15.2.2.2.16" class="ltx_tr">
<td id="S4.T15.2.2.2.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">Part-A2-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
<td id="S4.T15.2.2.2.16.2" class="ltx_td ltx_align_center ltx_border_r">66.9 / 63.8</td>
<td id="S4.T15.2.2.2.16.3" class="ltx_td ltx_align_center">77.1 / 76.5</td>
<td id="S4.T15.2.2.2.16.4" class="ltx_td ltx_align_center ltx_border_r">68.5 / 68.0</td>
<td id="S4.T15.2.2.2.16.5" class="ltx_td ltx_align_center">75.2 / 66.9</td>
<td id="S4.T15.2.2.2.16.6" class="ltx_td ltx_align_center ltx_border_r">66.2 / 58.6</td>
<td id="S4.T15.2.2.2.16.7" class="ltx_td ltx_align_center">68.6 / 67.4</td>
<td id="S4.T15.2.2.2.16.8" class="ltx_td ltx_align_center ltx_border_r">66.1 / 64.9</td>
</tr>
<tr id="S4.T15.2.2.2.17" class="ltx_tr">
<td id="S4.T15.2.2.2.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">SST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T15.2.2.2.17.2" class="ltx_td ltx_align_center ltx_border_r">67.8 / 64.6</td>
<td id="S4.T15.2.2.2.17.3" class="ltx_td ltx_align_center">74.2 / 73.8</td>
<td id="S4.T15.2.2.2.17.4" class="ltx_td ltx_align_center ltx_border_r">65.5 / 65.1</td>
<td id="S4.T15.2.2.2.17.5" class="ltx_td ltx_align_center">78.7 / 69.6</td>
<td id="S4.T15.2.2.2.17.6" class="ltx_td ltx_align_center ltx_border_r">70.0 / 61.7</td>
<td id="S4.T15.2.2.2.17.7" class="ltx_td ltx_align_center">70.7 / 69.6</td>
<td id="S4.T15.2.2.2.17.8" class="ltx_td ltx_align_center ltx_border_r">68.0 / 66.9</td>
</tr>
<tr id="S4.T15.2.2.2.18" class="ltx_tr">
<td id="S4.T15.2.2.2.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">PV-RCNN++ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="S4.T15.2.2.2.18.2" class="ltx_td ltx_align_center ltx_border_r">68.4 / 64.9</td>
<td id="S4.T15.2.2.2.18.3" class="ltx_td ltx_align_center">78.8 / 78.2</td>
<td id="S4.T15.2.2.2.18.4" class="ltx_td ltx_align_center ltx_border_r">70.3 / 69.7</td>
<td id="S4.T15.2.2.2.18.5" class="ltx_td ltx_align_center">76.7 / 67.2</td>
<td id="S4.T15.2.2.2.18.6" class="ltx_td ltx_align_center ltx_border_r">68.5 / 59.7</td>
<td id="S4.T15.2.2.2.18.7" class="ltx_td ltx_align_center">69.0 / 67.6</td>
<td id="S4.T15.2.2.2.18.8" class="ltx_td ltx_align_center ltx_border_r">66.5 / 65.2</td>
</tr>
<tr id="S4.T15.2.2.2.19" class="ltx_tr">
<td id="S4.T15.2.2.2.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T15.2.2.2.19.2" class="ltx_td ltx_align_center ltx_border_r">69.8 / 67.6</td>
<td id="S4.T15.2.2.2.19.3" class="ltx_td ltx_align_center">76.6 / 76.0</td>
<td id="S4.T15.2.2.2.19.4" class="ltx_td ltx_align_center ltx_border_r">68.9 / 68.4</td>
<td id="S4.T15.2.2.2.19.5" class="ltx_td ltx_align_center">79.0 / 73.4</td>
<td id="S4.T15.2.2.2.19.6" class="ltx_td ltx_align_center ltx_border_r">71.0 / 65.8</td>
<td id="S4.T15.2.2.2.19.7" class="ltx_td ltx_align_center">72.1 / 71.0</td>
<td id="S4.T15.2.2.2.19.8" class="ltx_td ltx_align_center ltx_border_r">69.5 / 68.5</td>
</tr>
<tr id="S4.T15.2.2.2.20" class="ltx_tr">
<td id="S4.T15.2.2.2.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">AFDetV2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</td>
<td id="S4.T15.2.2.2.20.2" class="ltx_td ltx_align_center ltx_border_r">71.0 / 68.8</td>
<td id="S4.T15.2.2.2.20.3" class="ltx_td ltx_align_center">77.6 / 77.1</td>
<td id="S4.T15.2.2.2.20.4" class="ltx_td ltx_align_center ltx_border_r">69.7 / 69.2</td>
<td id="S4.T15.2.2.2.20.5" class="ltx_td ltx_align_center">80.2 / 74.6</td>
<td id="S4.T15.2.2.2.20.6" class="ltx_td ltx_align_center ltx_border_r">72.2 / 67.0</td>
<td id="S4.T15.2.2.2.20.7" class="ltx_td ltx_align_center">73.7 / 72.7</td>
<td id="S4.T15.2.2.2.20.8" class="ltx_td ltx_align_center ltx_border_r">71.0 / 70.1</td>
</tr>
<tr id="S4.T15.2.2.2.21" class="ltx_tr">
<td id="S4.T15.2.2.2.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">PillarNet-34 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T15.2.2.2.21.2" class="ltx_td ltx_align_center ltx_border_r">71.0 / 68.5</td>
<td id="S4.T15.2.2.2.21.3" class="ltx_td ltx_align_center">79.1 / 78.6</td>
<td id="S4.T15.2.2.2.21.4" class="ltx_td ltx_align_center ltx_border_r">70.9 / 70.5</td>
<td id="S4.T15.2.2.2.21.5" class="ltx_td ltx_align_center">80.6 / 74.0</td>
<td id="S4.T15.2.2.2.21.6" class="ltx_td ltx_align_center ltx_border_r">72.3 / 66.2</td>
<td id="S4.T15.2.2.2.21.7" class="ltx_td ltx_align_center">72.3 / 71.2</td>
<td id="S4.T15.2.2.2.21.8" class="ltx_td ltx_align_center ltx_border_r">69.7 / 68.7</td>
</tr>
<tr id="S4.T15.2.2.2.22" class="ltx_tr">
<td id="S4.T15.2.2.2.22.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">SWFormer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</td>
<td id="S4.T15.2.2.2.22.2" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S4.T15.2.2.2.22.3" class="ltx_td ltx_align_center">77.8 / 77.3</td>
<td id="S4.T15.2.2.2.22.4" class="ltx_td ltx_align_center ltx_border_r">69.2 / 68.8</td>
<td id="S4.T15.2.2.2.22.5" class="ltx_td ltx_align_center">80.9 / 72.7</td>
<td id="S4.T15.2.2.2.22.6" class="ltx_td ltx_align_center ltx_border_r">72.5 / 64.9</td>
<td id="S4.T15.2.2.2.22.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T15.2.2.2.22.8" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S4.T15.1.1.1.1" class="ltx_tr">
<td id="S4.T15.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">FSD<sub id="S4.T15.1.1.1.1.1.1" class="ltx_sub"><span id="S4.T15.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">spconv</span></sub> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S4.T15.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">71.9 / 69.7</td>
<td id="S4.T15.1.1.1.1.3" class="ltx_td ltx_align_center">77.8 / 77.3</td>
<td id="S4.T15.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">68.9 / 68.5</td>
<td id="S4.T15.1.1.1.1.5" class="ltx_td ltx_align_center">81.9 / 76.4</td>
<td id="S4.T15.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r">73.2 / 68.0</td>
<td id="S4.T15.1.1.1.1.7" class="ltx_td ltx_align_center">76.5 / 75.2</td>
<td id="S4.T15.1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_r">73.8 / 72.5</td>
</tr>
<tr id="S4.T15.2.2.2.23" class="ltx_tr">
<td id="S4.T15.2.2.2.23.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt-2D</td>
<td id="S4.T15.2.2.2.23.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.9 / 68.2</td>
<td id="S4.T15.2.2.2.23.3" class="ltx_td ltx_align_center ltx_border_t">77.9 / 77.5</td>
<td id="S4.T15.2.2.2.23.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.7 / 69.2</td>
<td id="S4.T15.2.2.2.23.5" class="ltx_td ltx_align_center ltx_border_t">80.2 / 73.5</td>
<td id="S4.T15.2.2.2.23.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.2 / 65.9</td>
<td id="S4.T15.2.2.2.23.7" class="ltx_td ltx_align_center ltx_border_t">73.3 / 72.2</td>
<td id="S4.T15.2.2.2.23.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.7 / 69.6</td>
</tr>
<tr id="S4.T15.2.2.2.2" class="ltx_tr">
<td id="S4.T15.2.2.2.2.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt<sub id="S4.T15.2.2.2.2.1.1" class="ltx_sub"><span id="S4.T15.2.2.2.2.1.1.1" class="ltx_text ltx_font_italic">K3</span></sub>
</td>
<td id="S4.T15.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span id="S4.T15.2.2.2.2.2.1" class="ltx_text ltx_font_bold">72.2</span> / <span id="S4.T15.2.2.2.2.2.2" class="ltx_text ltx_font_bold">70.1</span>
</td>
<td id="S4.T15.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_b">78.2 / 77.7</td>
<td id="S4.T15.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">69.9 / 69.4</td>
<td id="S4.T15.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_b">81.5 / 76.3</td>
<td id="S4.T15.2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">73.5 / 68.6</td>
<td id="S4.T15.2.2.2.2.7" class="ltx_td ltx_align_center ltx_border_b">76.1 / 74.9</td>
<td id="S4.T15.2.2.2.2.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">73.3 / 72.2</td>
</tr>
</table>
</span></div>
</figure>
<figure id="S4.T16" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T16.3.1.1" class="ltx_text" style="font-size:90%;">Table 16</span>: </span><span id="S4.T16.4.2" class="ltx_text" style="font-size:90%;">Performance of 3D object detection results Argoverse2 dataset.</span></figcaption>
<div id="S4.T16.1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:43.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-232.2pt,23.3pt) scale(0.482889136258679,0.482889136258679) ;">
<table id="S4.T16.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T16.1.1.1.2" class="ltx_tr">
<td id="S4.T16.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Methods</td>
<td id="S4.T16.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">mAP</td>
<td id="S4.T16.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Veh.</td>
<td id="S4.T16.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Bus</td>
<td id="S4.T16.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Ped.</td>
<td id="S4.T16.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Stop.</td>
<td id="S4.T16.1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_t">Box.</td>
<td id="S4.T16.1.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t">Boll.</td>
<td id="S4.T16.1.1.1.2.9" class="ltx_td ltx_align_center ltx_border_t">C-B.</td>
<td id="S4.T16.1.1.1.2.10" class="ltx_td ltx_align_center ltx_border_t">M.-list</td>
<td id="S4.T16.1.1.1.2.11" class="ltx_td ltx_align_center ltx_border_t">MPC.</td>
<td id="S4.T16.1.1.1.2.12" class="ltx_td ltx_align_center ltx_border_t">M.-cycle</td>
<td id="S4.T16.1.1.1.2.13" class="ltx_td ltx_align_center ltx_border_t">Bicycle</td>
<td id="S4.T16.1.1.1.2.14" class="ltx_td ltx_align_center ltx_border_t">A-B.</td>
<td id="S4.T16.1.1.1.2.15" class="ltx_td ltx_align_center ltx_border_t">School.</td>
<td id="S4.T16.1.1.1.2.16" class="ltx_td ltx_align_center ltx_border_t">Truck.</td>
<td id="S4.T16.1.1.1.2.17" class="ltx_td ltx_align_center ltx_border_t">C-C.</td>
<td id="S4.T16.1.1.1.2.18" class="ltx_td ltx_align_center ltx_border_t">V-T.</td>
<td id="S4.T16.1.1.1.2.19" class="ltx_td ltx_align_center ltx_border_t">Sign</td>
<td id="S4.T16.1.1.1.2.20" class="ltx_td ltx_align_center ltx_border_t">Large.</td>
<td id="S4.T16.1.1.1.2.21" class="ltx_td ltx_align_center ltx_border_t">Str.</td>
<td id="S4.T16.1.1.1.2.22" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Bic.-list</td>
</tr>
<tr id="S4.T16.1.1.1.3" class="ltx_tr">
<td id="S4.T16.1.1.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T16.1.1.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.0</td>
<td id="S4.T16.1.1.1.3.3" class="ltx_td ltx_align_center ltx_border_t">67.6</td>
<td id="S4.T16.1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_t">38.9</td>
<td id="S4.T16.1.1.1.3.5" class="ltx_td ltx_align_center ltx_border_t">46.5</td>
<td id="S4.T16.1.1.1.3.6" class="ltx_td ltx_align_center ltx_border_t">16.9</td>
<td id="S4.T16.1.1.1.3.7" class="ltx_td ltx_align_center ltx_border_t">37.4</td>
<td id="S4.T16.1.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t">40.1</td>
<td id="S4.T16.1.1.1.3.9" class="ltx_td ltx_align_center ltx_border_t">32.2</td>
<td id="S4.T16.1.1.1.3.10" class="ltx_td ltx_align_center ltx_border_t">28.6</td>
<td id="S4.T16.1.1.1.3.11" class="ltx_td ltx_align_center ltx_border_t">27.4</td>
<td id="S4.T16.1.1.1.3.12" class="ltx_td ltx_align_center ltx_border_t">33.4</td>
<td id="S4.T16.1.1.1.3.13" class="ltx_td ltx_align_center ltx_border_t">24.5</td>
<td id="S4.T16.1.1.1.3.14" class="ltx_td ltx_align_center ltx_border_t">8.7</td>
<td id="S4.T16.1.1.1.3.15" class="ltx_td ltx_align_center ltx_border_t">25.8</td>
<td id="S4.T16.1.1.1.3.16" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T16.1.1.1.3.16.1" class="ltx_text ltx_font_bold">22.6</span></td>
<td id="S4.T16.1.1.1.3.17" class="ltx_td ltx_align_center ltx_border_t">29.5</td>
<td id="S4.T16.1.1.1.3.18" class="ltx_td ltx_align_center ltx_border_t">22.4</td>
<td id="S4.T16.1.1.1.3.19" class="ltx_td ltx_align_center ltx_border_t">6.3</td>
<td id="S4.T16.1.1.1.3.20" class="ltx_td ltx_align_center ltx_border_t">3.9</td>
<td id="S4.T16.1.1.1.3.21" class="ltx_td ltx_align_center ltx_border_t">0.5</td>
<td id="S4.T16.1.1.1.3.22" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.1</td>
</tr>
<tr id="S4.T16.1.1.1.4" class="ltx_tr">
<td id="S4.T16.1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">FSD</td>
<td id="S4.T16.1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_r">28.2</td>
<td id="S4.T16.1.1.1.4.3" class="ltx_td ltx_align_center">68.1</td>
<td id="S4.T16.1.1.1.4.4" class="ltx_td ltx_align_center"><span id="S4.T16.1.1.1.4.4.1" class="ltx_text ltx_font_bold">40.9</span></td>
<td id="S4.T16.1.1.1.4.5" class="ltx_td ltx_align_center">59.0</td>
<td id="S4.T16.1.1.1.4.6" class="ltx_td ltx_align_center">29.0</td>
<td id="S4.T16.1.1.1.4.7" class="ltx_td ltx_align_center">38.5</td>
<td id="S4.T16.1.1.1.4.8" class="ltx_td ltx_align_center">41.8</td>
<td id="S4.T16.1.1.1.4.9" class="ltx_td ltx_align_center">42.6</td>
<td id="S4.T16.1.1.1.4.10" class="ltx_td ltx_align_center">39.7</td>
<td id="S4.T16.1.1.1.4.11" class="ltx_td ltx_align_center">26.2</td>
<td id="S4.T16.1.1.1.4.12" class="ltx_td ltx_align_center"><span id="S4.T16.1.1.1.4.12.1" class="ltx_text ltx_font_bold">49.0</span></td>
<td id="S4.T16.1.1.1.4.13" class="ltx_td ltx_align_center">38.6</td>
<td id="S4.T16.1.1.1.4.14" class="ltx_td ltx_align_center"><span id="S4.T16.1.1.1.4.14.1" class="ltx_text ltx_font_bold">20.4</span></td>
<td id="S4.T16.1.1.1.4.15" class="ltx_td ltx_align_center"><span id="S4.T16.1.1.1.4.15.1" class="ltx_text ltx_font_bold">30.5</span></td>
<td id="S4.T16.1.1.1.4.16" class="ltx_td ltx_align_center">14.8</td>
<td id="S4.T16.1.1.1.4.17" class="ltx_td ltx_align_center">41.2</td>
<td id="S4.T16.1.1.1.4.18" class="ltx_td ltx_align_center"><span id="S4.T16.1.1.1.4.18.1" class="ltx_text ltx_font_bold">26.9</span></td>
<td id="S4.T16.1.1.1.4.19" class="ltx_td ltx_align_center">11.9</td>
<td id="S4.T16.1.1.1.4.20" class="ltx_td ltx_align_center">5.9</td>
<td id="S4.T16.1.1.1.4.21" class="ltx_td ltx_align_center">13.8</td>
<td id="S4.T16.1.1.1.4.22" class="ltx_td ltx_align_center ltx_border_r">33.4</td>
</tr>
<tr id="S4.T16.1.1.1.5" class="ltx_tr">
<td id="S4.T16.1.1.1.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt</td>
<td id="S4.T16.1.1.1.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.0</td>
<td id="S4.T16.1.1.1.5.3" class="ltx_td ltx_align_center ltx_border_t">71.7</td>
<td id="S4.T16.1.1.1.5.4" class="ltx_td ltx_align_center ltx_border_t">39.2</td>
<td id="S4.T16.1.1.1.5.5" class="ltx_td ltx_align_center ltx_border_t">63.1</td>
<td id="S4.T16.1.1.1.5.6" class="ltx_td ltx_align_center ltx_border_t">39.2</td>
<td id="S4.T16.1.1.1.5.7" class="ltx_td ltx_align_center ltx_border_t">40.0</td>
<td id="S4.T16.1.1.1.5.8" class="ltx_td ltx_align_center ltx_border_t">52.5</td>
<td id="S4.T16.1.1.1.5.9" class="ltx_td ltx_align_center ltx_border_t">63.7</td>
<td id="S4.T16.1.1.1.5.10" class="ltx_td ltx_align_center ltx_border_t">42.2</td>
<td id="S4.T16.1.1.1.5.11" class="ltx_td ltx_align_center ltx_border_t">34.9</td>
<td id="S4.T16.1.1.1.5.12" class="ltx_td ltx_align_center ltx_border_t">42.7</td>
<td id="S4.T16.1.1.1.5.13" class="ltx_td ltx_align_center ltx_border_t">40.1</td>
<td id="S4.T16.1.1.1.5.14" class="ltx_td ltx_align_center ltx_border_t">20.1</td>
<td id="S4.T16.1.1.1.5.15" class="ltx_td ltx_align_center ltx_border_t">25.2</td>
<td id="S4.T16.1.1.1.5.16" class="ltx_td ltx_align_center ltx_border_t">16.9</td>
<td id="S4.T16.1.1.1.5.17" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T16.1.1.1.5.17.1" class="ltx_text ltx_font_bold">45.7</span></td>
<td id="S4.T16.1.1.1.5.18" class="ltx_td ltx_align_center ltx_border_t">22.3</td>
<td id="S4.T16.1.1.1.5.19" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T16.1.1.1.5.19.1" class="ltx_text ltx_font_bold">15.8</span></td>
<td id="S4.T16.1.1.1.5.20" class="ltx_td ltx_align_center ltx_border_t">5.9</td>
<td id="S4.T16.1.1.1.5.21" class="ltx_td ltx_align_center ltx_border_t">9.8</td>
<td id="S4.T16.1.1.1.5.22" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T16.1.1.1.5.22.1" class="ltx_text ltx_font_bold">33.5</span></td>
</tr>
<tr id="S4.T16.1.1.1.1" class="ltx_tr">
<td id="S4.T16.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt<sub id="S4.T16.1.1.1.1.1.1" class="ltx_sub"><span id="S4.T16.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">K3</span></sub>
</td>
<td id="S4.T16.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T16.1.1.1.1.2.1" class="ltx_text ltx_font_bold">30.7</span></td>
<td id="S4.T16.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.3.1" class="ltx_text ltx_font_bold">72.7</span></td>
<td id="S4.T16.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_b">38.8</td>
<td id="S4.T16.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.5.1" class="ltx_text ltx_font_bold">63.2</span></td>
<td id="S4.T16.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.6.1" class="ltx_text ltx_font_bold">40.2</span></td>
<td id="S4.T16.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.7.1" class="ltx_text ltx_font_bold">40.1</span></td>
<td id="S4.T16.1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.8.1" class="ltx_text ltx_font_bold">53.9</span></td>
<td id="S4.T16.1.1.1.1.9" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.9.1" class="ltx_text ltx_font_bold">64.9</span></td>
<td id="S4.T16.1.1.1.1.10" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.10.1" class="ltx_text ltx_font_bold">44.7</span></td>
<td id="S4.T16.1.1.1.1.11" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.11.1" class="ltx_text ltx_font_bold">39.4</span></td>
<td id="S4.T16.1.1.1.1.12" class="ltx_td ltx_align_center ltx_border_b">42.4</td>
<td id="S4.T16.1.1.1.1.13" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.13.1" class="ltx_text ltx_font_bold">40.6</span></td>
<td id="S4.T16.1.1.1.1.14" class="ltx_td ltx_align_center ltx_border_b">20.1</td>
<td id="S4.T16.1.1.1.1.15" class="ltx_td ltx_align_center ltx_border_b">25.2</td>
<td id="S4.T16.1.1.1.1.16" class="ltx_td ltx_align_center ltx_border_b">19.9</td>
<td id="S4.T16.1.1.1.1.17" class="ltx_td ltx_align_center ltx_border_b">44.9</td>
<td id="S4.T16.1.1.1.1.18" class="ltx_td ltx_align_center ltx_border_b">20.9</td>
<td id="S4.T16.1.1.1.1.19" class="ltx_td ltx_align_center ltx_border_b">14.9</td>
<td id="S4.T16.1.1.1.1.20" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.20.1" class="ltx_text ltx_font_bold">6.8</span></td>
<td id="S4.T16.1.1.1.1.21" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T16.1.1.1.1.21.1" class="ltx_text ltx_font_bold">15.7</span></td>
<td id="S4.T16.1.1.1.1.22" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">32.4</td>
</tr>
</table>
</span></div>
</figure>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Spatially Voxel Pruning</span>
VoxelNeXt gradually drops redundant voxels according to feature magnitude. We ablate this setting in Tab. <a href="#S3.T3" title="Table 3 ‣ 3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We control the drop ratio from 0.1 to 0.9 with an interval of 0.2.
The performance hardly decays when the ratio is not greater than 0.5. Thus, we set the drop ratio to 0.5 as a default setting in our experiments. We also ablate the stages of voxel pruning in Tab. <a href="#S3.T4" title="Table 4 ‣ 3.2 Sparse Prediction Head ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We use it on the first 3 stages by default.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Sparse Height Compression</span>
We make ablations on the sparse CNN types of 2D and 3D, in the backbone and head of VoxelNeXt, in Tab. <a href="#S4.T5" title="Table 5 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The naive design is that both the backbone and head apply 3D sparse CNN, which results in high latency. With the sparse height compression, we combine the 3D backbone and 2D sparse prediction head. It achieves much better efficiency with decent performance. We use it as a default setting of VoxelNeXt. When we use 2D sparse CNN as the backbone network, it has the same layer number and double channels as the 3D one. It achieves the best efficiency, and yet suffers a bit of performance drop. We name it VoxelNeXt-2D for its high efficiency.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p id="S4.SS1.p4.2" class="ltx_p"><span id="S4.SS1.p4.2.1" class="ltx_text ltx_font_bold">Layer Type in Sparse Prediction Head</span>
We ablate the effect using fully-connected layers or submanifold sparse convolutions to predict boxes in the sparse head, as shown in Tab. <a href="#S4.T6" title="Table 6 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The fully-connected (FC) head has inferior performance to the <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mn id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p4.1.m1.1.1.1" xref="S4.SS1.p4.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p4.1.m1.1.1.3" xref="S4.SS1.p4.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><times id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1.1"></times><cn type="integer" id="S4.SS1.p4.1.m1.1.1.2.cmml" xref="S4.SS1.p4.1.m1.1.1.2">3</cn><cn type="integer" id="S4.SS1.p4.1.m1.1.1.3.cmml" xref="S4.SS1.p4.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">3\times 3</annotation></semantics></math> sparse convolution counterpart, but more efficient. We denote the latter with <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="K3" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mrow id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml"><mi id="S4.SS1.p4.2.m2.1.1.2" xref="S4.SS1.p4.2.m2.1.1.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S4.SS1.p4.2.m2.1.1.1" xref="S4.SS1.p4.2.m2.1.1.1.cmml">​</mo><mn id="S4.SS1.p4.2.m2.1.1.3" xref="S4.SS1.p4.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><apply id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1"><times id="S4.SS1.p4.2.m2.1.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1.1"></times><ci id="S4.SS1.p4.2.m2.1.1.2.cmml" xref="S4.SS1.p4.2.m2.1.1.2">𝐾</ci><cn type="integer" id="S4.SS1.p4.2.m2.1.1.3.cmml" xref="S4.SS1.p4.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">K3</annotation></semantics></math> in VoxelNeXt.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para ltx_noindent">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Relative Positions between Voxels and Predicted Boxes</span>
In VoxelNeXt, voxels for box prediction are not required to be inside the boxes, not to mention centers, as in Tab. <a href="#S4.T7" title="Table 7 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We count the relative of voxels that are inside the 3D bounding boxes they generate. We split voxels into 3 area types of <span id="S4.SS1.p5.1.2" class="ltx_text ltx_font_italic">near center</span>, <span id="S4.SS1.p5.1.3" class="ltx_text ltx_font_italic">near boundary</span>, and <span id="S4.SS1.p5.1.4" class="ltx_text ltx_font_italic">outside box</span>, according to their relative positions to boxes. On average, most boxes are predicted from voxels inside, maybe not near centers. Statistically, only a few boxes (less than 10% in total) are predicted based on the voxels near object centers. This finding shows that boundary voxels are also qualified for prediction, while object centers are not always necessary.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p">Another observation is that there are large gaps between the ratios of different classes. For <span id="S4.SS1.p6.1.1" class="ltx_text ltx_font_italic">Car</span> and <span id="S4.SS1.p6.1.2" class="ltx_text ltx_font_italic">Trailer</span>, most boxes are predicted on inside voxels. In contrast, for <span id="S4.SS1.p6.1.3" class="ltx_text ltx_font_italic">Truck</span>, <span id="S4.SS1.p6.1.4" class="ltx_text ltx_font_italic">Traffic Cone</span>, and <span id="S4.SS1.p6.1.5" class="ltx_text ltx_font_italic">Pedestrian</span>, about half of the boxes are predicted from outside voxels. We illustrate example pairs in Fig. <a href="#S3.F9" title="Figure 9 ‣ 3.1 Sparse CNN Backbone Adaptation ‣ 3 Fully Sparse Voxel-based Network ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. As objects in different classes vary in size and spatial sparsity, predicting upon voxels complies with data distribution, rather than proxies like anchors or centers.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para ltx_noindent">
<p id="S4.SS1.p7.1" class="ltx_p"><span id="S4.SS1.p7.1.1" class="ltx_text ltx_font_bold">Comparison to CenterPoint in Error Analysis</span>
We compare VoxelNeXt to the representative dense-head method
CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> in Tab. <a href="#S4.T8" title="Table 8 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. Training on 1/4 nuScenes training set and evaluating on the full validation split, VoxelNeXt achieves 0.9% mAP and 1.0% NDS improvement. In further analysis, CenterPoint and VoxelNeXt shares comparable errors in location, size, and velocity. However, there are large gaps in other error types, especially in orientation. Notably, VoxelNext has 4.9% less orientation error than CenterPoint. We suppose that this results from that sparse voxel features might be more sensitive to orientation difference.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para ltx_noindent">
<p id="S4.SS1.p8.1" class="ltx_p"><span id="S4.SS1.p8.1.1" class="ltx_text ltx_font_bold">Efficiency Statistics of Backbone</span>
We count the efficiency-related statistics of our sparse CNN backbone network in Tab. <a href="#S4.T9" title="Table 9 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. As features in the last 3 stages are summed up for height compression, they share the same channel number 128. Due to the high down-sampling ratios in Stages 5-6, their voxel numbers are much smaller compared to previous stages. Consequently, the computation cost introduced in Stages 5-6 is limited to 6.1G and 2.8G FLOPs in 6 and 3 ms. It is no more than <math id="S4.SS1.p8.1.m1.1" class="ltx_Math" alttext="1/3" display="inline"><semantics id="S4.SS1.p8.1.m1.1a"><mrow id="S4.SS1.p8.1.m1.1.1" xref="S4.SS1.p8.1.m1.1.1.cmml"><mn id="S4.SS1.p8.1.m1.1.1.2" xref="S4.SS1.p8.1.m1.1.1.2.cmml">1</mn><mo id="S4.SS1.p8.1.m1.1.1.1" xref="S4.SS1.p8.1.m1.1.1.1.cmml">/</mo><mn id="S4.SS1.p8.1.m1.1.1.3" xref="S4.SS1.p8.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.1.m1.1b"><apply id="S4.SS1.p8.1.m1.1.1.cmml" xref="S4.SS1.p8.1.m1.1.1"><divide id="S4.SS1.p8.1.m1.1.1.1.cmml" xref="S4.SS1.p8.1.m1.1.1.1"></divide><cn type="integer" id="S4.SS1.p8.1.m1.1.1.2.cmml" xref="S4.SS1.p8.1.m1.1.1.2">1</cn><cn type="integer" id="S4.SS1.p8.1.m1.1.1.3.cmml" xref="S4.SS1.p8.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.1.m1.1c">1/3</annotation></semantics></math> of the overall backbone network, and yet makes notable effects on performance enhancement.</p>
</div>
<div id="S4.SS1.p9" class="ltx_para ltx_noindent">
<p id="S4.SS1.p9.1" class="ltx_p"><span id="S4.SS1.p9.1.1" class="ltx_text ltx_font_bold">Sparse Max Pooling</span>
We ablate the effect of sparse max pooling and NMS in Tab. <a href="#S4.T10" title="Table 10 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. Compared to the commonly used NMS, max-pool presents comparable mAP, 56.0% v.s. 56.2%. VoxelNeXt is flexible to works either with NMS or sparse max pooling. Max-pool is an elegant solution and avoids some unnecessary computation on predictions.</p>
</div>
<div id="S4.SS1.p10" class="ltx_para ltx_noindent">
<p id="S4.SS1.p10.1" class="ltx_p"><span id="S4.SS1.p10.1.1" class="ltx_text ltx_font_bold">Voxel Association for 3D Tracking</span>
Tab. <a href="#S4.T11" title="Table 11 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows the ablation of 3D tracking on nuScenes validation. In addition to tracking predicted box centers, we also include the voxels that predict boxes for matching. Voxel association introduces notable improvement of 1.1% AMOTA.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Main Results</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">3D Object Detection</span>
In Tab. <a href="#S4.T12" title="Table 12 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, we evaluate our detection models on the test split and compare them with other LIDAR-based methods on nuScenes test set.
Results denoted as <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mo id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\dagger</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> are reported with the double-flip testing augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. Both lines of results are better than previous ones. We compare VoxelNeXt with other 3D object detectors on the Waymo validation split in Tab. <a href="#S4.T15" title="Table 15 ‣ 4.1 Ablation Studies ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> and on Argoverse2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> in Tab. <a href="#S4.T16" title="Table 16 ‣ 4.1 Ablation Studies ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a>. We present latency comparison in Tab. <a href="#S4.T12" title="Table 12 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> and Fig. <a href="#S2.F3" title="Figure 3 ‣ 2 Related Work ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
VoxelNeXt achieves leading performance among these methods with high efficiency.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.2" class="ltx_p"><span id="S4.SS2.p2.2.1" class="ltx_text ltx_font_bold">3D Multi-object Tracking</span>
In Tab. <a href="#S4.T13" title="Table 13 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> and Tab. <a href="#S4.T14" title="Table 14 ‣ 4.1 Ablation Studies ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>, we compare VoxelNeXt’s tracking performance with other methods in the nuScenes test and validation splits. VoxelNeXt achieves the best AMOTA among all LIDAR-based methods. In addition, when combined with the double-flip testing results in Tab. <a href="#S4.T12" title="Table 12 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, denoted as <sup id="S4.SS2.p2.2.2" class="ltx_sup"><span id="S4.SS2.p2.2.2.1" class="ltx_text ltx_font_italic">†</span></sup> in Tab. <a href="#S4.T13" title="Table 13 ‣ 4 Experiments ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>, VoxelNeXt further achieves 71.0% AMOTA and ranking 1<sup id="S4.SS2.p2.2.3" class="ltx_sup"><span id="S4.SS2.p2.2.3.1" class="ltx_text ltx_font_italic">st</span></sup> on the nuScenes 3D LIDAR tracking benchmark.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we have presented a fully sparse and voxel-based framework for 3D object detection and tracking. It is with simple techniques, run fast with no much extra cost, and works in an elegant manner without NMS post-processing. For the first time, we show that direct voxel-based prediction is feasible and effective. Thus rule-based schemes, <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, anchors or centers, and dense heads become unnecessary in ours. VoxelNeXt presents promising results on large-scale datasets, including nuScenes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, Waymo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, and Argoverse2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. With high efficiency, it achieves leading performance on 3D object detection and ranks 1<sub id="S5.p1.1.2" class="ltx_sub"><span id="S5.p1.1.2.1" class="ltx_text ltx_font_italic">st</span></sub> on nuScenes 3D tracking LIDAR benchmark.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Limitations</span>
A gap exists between theoretical FLOPs and actual inference speed.
VoxelNeXt has a much small 38.7G FLOPs, compared to 186.6G of CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. The actual latency reduction is clear but not so large as FLOPs in Tab. <a href="#S2.T1" title="Table 1 ‣ 2 Related Work ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, as it highly depends on implementation and devices.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Xuyang Bai, Zeyu Hu, Xinge Zhu, Qingqiu Huang, Yilun Chen, Hongbo Fu, and
Chiew-Lan Tai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Transfusion: Robust lidar-camera fusion for 3d object detection with
transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:90%;">, pages 1080–1089, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Nuri Benbarka, Jona Schröder, and Andreas Zell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Score refinement for confidence-based 3d multi-object tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IROS</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 8083–8090, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Holger Caesar, Varun Bankiti, Alex H. Lang, Sourabh Vora, Venice Erin Liong,
Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">nuscenes: A multimodal dataset for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 11618–11628, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Qi Chen, Lin Sun, Ernest Cheung, and Alan L. Yuille.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Every view counts: Cross-view consistency in 3d object detection with
hybrid-cylindrical-spherical voxelization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Qi Chen, Lin Sun, Zhixin Wang, Kui Jia, and Alan L. Yuille.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Object as hotspots: An anchor-free 3d object detection approach via
firing of hotspots.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, volume 12366, pages 68–84, 2020.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Yukang Chen, Yanwei Li, Xiangyu Zhang, Jian Sun, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Focal sparse convolutional networks for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 5418–5427, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Yukang Chen, Yanwei Li, Xiangyu Zhang, Jian Sun, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Focal sparse convolutional networks for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 5418–5427, 2022.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Yukang Chen, Jianhui Liu, Xiaojuan Qi, Xiangyu Zhang, Jian Sun, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Scaling up kernels in 3d cnns.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, abs/2206.10555, 2022.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Hsu-Kuang Chiu, Jie Li, Rares Ambrus, and Jeannette Bohg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Probabilistic 3d multi-modal, multi-object tracking for autonomous
driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICRA</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 14227–14233, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Ruihang Chu, Yukang Chen, Tao Kong, Lu Qi, and Lei Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Icm-3d: Instantiated category modeling for 3d instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 7(1):57–64, 2021.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Ruihang Chu, Xiaoqing Ye, Zhengzhe Liu, Xiao Tan, Xiaojuan Qi, Chi-Wing Fu, and
Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Twist: Two-way inter-label self-training for semi-supervised 3d
instance segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 1100–1109, 2022.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and
Houqiang Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Voxel R-CNN: towards high performance voxel-based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 1201–1209, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Shengheng Deng, Zhihao Liang, Lin Sun, and Kui Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">VISTA: boosting 3d object detection via dual cross-view spatial
attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 8438–8447, 2022.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Kaiwen Duan, Song Bai, Lingxi Xie, Honggang Qi, Qingming Huang, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Centernet: Keypoint triplets for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 6568–6577, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Lue Fan, Ziqi Pang, Tianyuan Zhang, Yu-Xiong Wang, Hang Zhao, Feng Wang,
Naiyan Wang, and Zhaoxiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Embracing single stride 3d object detector with sparse transformer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 8448–8458, 2022.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Lue Fan, Feng Wang, Naiyan Wang, and Zhaoxiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Fully sparse 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, abs/2207.10035, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Lue Fan, Xuan Xiong, Feng Wang, Naiyan Wang, and Zhaoxiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Rangedet: In defense of range view for lidar-based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 2898–2907, 2021.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Vision meets robotics: The KITTI dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Int. J. Robotics Res.</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 32(11):1231–1237, 2013.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Benjamin Graham, Martin Engelcke, and Laurens van der Maaten.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">3d semantic segmentation with submanifold sparse convolutional
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 9224–9232, 2018.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Tianrui Guan, Jun Wang, Shiyi Lan, Rohan Chandra, Zuxuan Wu, Larry Davis, and
Dinesh Manocha.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">M3DETR: multi-representation, multi-scale, mutual-relation 3d
object detection with transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">WACV</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 2293–2303, 2022.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Chenhang He, Ruihuang Li, Shuai Li, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Voxel set transformer: A set-to-set approach to 3d object detection
from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 8407–8417, 2022.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Yihan Hu, Zhuangzhuang Ding, Runzhou Ge, Wenxin Shao, Li Huang, Kun Li, and
Qiang Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Afdetv2: Rethinking the necessity of the second stage for object
detection from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 969–979, 2022.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Li Jiang, Shaoshuai Shi, Zhuotao Tian, Xin Lai, Shu Liu, Chi-Wing Fu, and Jiaya
Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Guided point contrastive learning for semi-supervised point cloud
semantic segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 6423–6432, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Diederik P. Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In Yoshua Bengio and Yann LeCun, editors, </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICLR</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Xin Lai, Yukang Chen, Fanbin Lu, Jianhui Liu, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Spherical transformer for lidar-based 3d recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Xin Lai, Jianhui Liu, Li Jiang, Liwei Wang, Hengshuang Zhao, Shu Liu, Xiaojuan
Qi, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Stratified transformer for 3d point cloud segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 8500–8509, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar
Beijbom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Pointpillars: Fast encoders for object detection from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, pages 12697–12705, 2019.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Yanwei Li, Yilun Chen, Xiaojuan Qi, Zeming Li, Jian Sun, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Unifying voxel-based representation with transformer for 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, abs/2206.00630, 2022.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Zhichao Li, Feng Wang, and Naiyan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Lidar R-CNN: an efficient and universal 3d object detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 7546–7555, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Tingting Liang, Hongwei Xie, Kaicheng Yu, Zhongyu Xia, Zhiwei Lin, Yongtao
Wang, Tao Tang, Bing Wang, and Zhi Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Bevfusion: A simple and robust lidar-camera fusion framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, abs/2205.13790, 2022.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He, and Piotr
Dollár.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Focal loss for dense object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">T-PAMI</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 42(2):318–327, 2020.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Jianhui Liu, Yukang Chen, Xiaoqing Ye, Zhuotao Tian, Xiao Tan, and Xiaojuan Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Spatial pruned sparse convolution for efficient 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Zhijian Liu, Haotian Tang, Alexander Amini, Xinyu Yang, Huizi Mao, Daniela Rus,
and Song Han.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Bevfusion: Multi-task multi-sensor fusion with unified bird’s-eye
view representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, abs/2205.13542, 2022.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Jiageng Mao, Minzhe Niu, Haoyue Bai, Xiaodan Liang, Hang Xu, and Chunjing Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Pyramid R-CNN: towards better performance and adaptability for 3d
object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang,
Hang Xu, and Chunjing Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Voxel transformer for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Ziqi Pang, Zhichao Li, and Naiyan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Simpletrack: Understanding and rethinking 3d multi-object tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, abs/2111.09621, 2021.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Charles R. Qi, Or Litany, Kaiming He, and Leonidas J. Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Deep hough voting for 3d object detection in point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages 9276–9285, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J. Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Pointnet++: Deep hierarchical feature learning on point sets in a
metric space.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages 5099–5108, 2017.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Faster R-CNN: towards real-time object detection with region
proposal networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 91–99, 2015.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Guangsheng Shi, Ruifeng Li, and Chao Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Pillarnet: Real-time and high-performance pillar-based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, abs/2205.07403, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and
Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">PV-RCNN: point-voxel feature set abstraction for 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, pages 10526–10535, 2020.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Li Jiang, Jiajun Deng, Zhe Wang, Chaoxu Guo, Jianping Shi,
Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">PV-RCNN++: point-voxel feature set abstraction with local vector
representation for 3d object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, abs/2102.00463, 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Pointrcnn: 3d object proposal generation and detection from point
cloud.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib43.5.3" class="ltx_text" style="font-size:90%;">, pages 770–779, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Shaoshuai Shi, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">From points to parts: 3d object detection from point cloud with
part-aware and part-aggregation network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">T-PAMI</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 43(8):2647–2664, 2021.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun and et. al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Scalability in perception for autonomous driving: Waymo open dataset.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, pages 2443–2451, 2020.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Mingxing Tan, Weiyue Wang, Chenxi Liu, Fei Xia, Zhaoqi Leng, and
Dragomir Anguelov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Swformer: Sparse window transformer for 3d object detection in point
clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib46.4.2" class="ltx_text" style="font-size:90%;">, abs/2210.07372, 2022.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Pei Sun, Weiyue Wang, Yuning Chai, Gamaleldin Elsayed, Alex Bewley, Xiao Zhang,
Cristian Sminchisescu, and Dragomir Anguelov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">RSN: range sparse net for efficient, accurate lidar 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, pages 5725–5734, 2021.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Dominic Zeng Wang and Ingmar Posner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Voting for voting in online point cloud object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Robotics: Science and Systems</span><span id="bib.bib48.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Jun Wang, Shiyi Lan, Mingfei Gao, and Larry S. Davis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Infofocus: 3d object detection for autonomous driving with dynamic
information modeling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib49.5.3" class="ltx_text" style="font-size:90%;">, volume 12355, pages 405–420, 2020.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Yue Wang, Alireza Fathi, Abhijit Kundu, David A. Ross, Caroline Pantofaru,
Thomas A. Funkhouser, and Justin M. Solomon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Pillar-based object detection for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Xinshuo Weng, Jianren Wang, David Held, and Kris Kitani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">3d multi-object tracking: A baseline and new evaluation metrics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IROS</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, pages 10359–10366, 2020.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Benjamin Wilson and et. al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Argoverse 2: Next generation datasets for self-driving perception and
forecasting.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Yan Yan, Yuxing Mao, and Bo Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">SECOND: sparsely embedded convolutional detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Sensors</span><span id="bib.bib53.4.2" class="ltx_text" style="font-size:90%;">, 18(10):3337, 2018.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Honghui Yang, Zili Liu, Xiaopei Wu, Wenxiao Wang, Wei Qian, Xiaofei He, and
Deng Cai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Graph r-cnn: Towards accurate 3d object detection with
semantic-decorated local graph.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib54.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib54.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Zetong Yang, Yanan Sun, Shu Liu, and Jiaya Jia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">3dssd: Point-based 3d single stage object detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib55.5.3" class="ltx_text" style="font-size:90%;">, pages 11037–11045, 2020.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Zetong Yang, Yin Zhou, Zhifeng Chen, and Jiquan Ngiam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">3d-man: 3d multi-frame attention network for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, pages 1863–1872, 2021.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Tianwei Yin, Xingyi Zhou, and Philipp Krähenbühl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Center-based 3d object detection and tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib57.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib57.5.3" class="ltx_text" style="font-size:90%;">, pages 11784–11793, 2021.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Jan-Nico Zaech, Dengxin Dai, Alexander Liniger, Martin Danelljan, and Luc Van
Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Learnable online graph representations for 3d multi-object tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib58.4.2" class="ltx_text" style="font-size:90%;">, abs/2104.11747, 2021.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
Yifan Zhang, Qingyong Hu, Guoquan Xu, Yanxin Ma, Jianwei Wan, and Yulan Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">Not all points are equal: Learning highly efficient point-based
detectors for 3d lidar point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib59.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib59.5.3" class="ltx_text" style="font-size:90%;">, pages 18931–18940, 2022.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Xingyi Zhou, Vladlen Koltun, and Philipp Krähenbühl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">Tracking objects as points.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib60.5.3" class="ltx_text" style="font-size:90%;">, volume 12349, pages 474–490, 2020.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
Yin Zhou and Oncel Tuzel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">Voxelnet: End-to-end learning for point cloud based 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib61.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib61.5.3" class="ltx_text" style="font-size:90%;">, pages 4490–4499, 2018.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Benjin Zhu, Zhengkai Jiang, Xiangxin Zhou, Zeming Li, and Gang Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">Class-balanced grouping and sampling for point cloud 3d object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">CoRR</span><span id="bib.bib62.4.2" class="ltx_text" style="font-size:90%;">, abs/1908.09492, 2019.
</span>
</span>
</li>
</ul>
</section>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

<div id="Ax1.p1" class="ltx_para">
<p id="Ax1.p1.1" class="ltx_p">In this appendix, we first introduce implementation details in Sec. <a href="#A1" title="Appendix A Implementation Details ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. We then include additional experimental results in Sec. <a href="#A2" title="Appendix B Experimental results ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. We also provide more visualizations and discussions in Sec. <a href="#A3" title="Appendix C Visualizations ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> and Sec. <a href="#A4" title="Appendix D Discussions ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p id="A1.p1.1" class="ltx_p"><span id="A1.p1.1.1" class="ltx_text ltx_font_bold">nuScenes</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> has 1,000 drive sequences, split into 700, 150, and 150 sequences for training, validation, and testing. nuScenes is collected by a 32-beam synced LIDAR and 6 cameras. The annotations include 10 classes. In the ablation study, detection models are trained on 1/4 training data and evaluated on the full validation set.</p>
</div>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.1" class="ltx_p"><span id="A1.p2.1.1" class="ltx_text ltx_font_bold">Waymo</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> is a large-scale public autonomous driving dataset, which contains 1,150 sequences in total, with 798 for training, and 202 for validation. It was collected by one long-range LiDAR sensor at 75 meters and four near-range sensors.</p>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.1" class="ltx_p"><span id="A1.p3.1.1" class="ltx_text ltx_font_bold">Argoverse2</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> has 1000 sequences, including 700 for training, 150 for validation. The perception range is 200 radius meters, covering area of 400m × 400m. We follow FSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> for data processing.</p>
</div>
<div id="A1.p4" class="ltx_para ltx_noindent">
<p id="A1.p4.1" class="ltx_p"><span id="A1.p4.1.1" class="ltx_text ltx_font_bold">Voxelization</span></p>
</div>
<div id="A1.p5" class="ltx_para">
<p id="A1.p5.1" class="ltx_p">For nuScenes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> dataset, point clouds are clipped in [-54m, 54m] for <span id="A1.p5.1.1" class="ltx_text ltx_font_italic">X</span> or <span id="A1.p5.1.2" class="ltx_text ltx_font_italic">Y</span> axis, and [-5m, 3m] for <span id="A1.p5.1.3" class="ltx_text ltx_font_italic">Z</span> axis. Voxel size is (0.075m, 0.075m, 0.2m) by default. For VoxelNeXt-2D, the voxel size along <span id="A1.p5.1.4" class="ltx_text ltx_font_italic">Z</span> axis is 8m.</p>
</div>
<div id="A1.p6" class="ltx_para">
<p id="A1.p6.1" class="ltx_p">For Waymo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> dataset, point clouds are clipped into [-75.2m, 75.2m] <span id="A1.p6.1.1" class="ltx_text ltx_font_italic">X</span> or <span id="A1.p6.1.2" class="ltx_text ltx_font_italic">Y</span> axis, and [-2m, 4m] for <span id="A1.p6.1.3" class="ltx_text ltx_font_italic">Z</span> axis. Voxel size is (0.1m, 0.1m, 0.15m) by default. For VoxelNeXt-2D, the voxel size along <span id="A1.p6.1.4" class="ltx_text ltx_font_italic">Z</span> axis is 6m.</p>
</div>
<div id="A1.p7" class="ltx_para">
<p id="A1.p7.1" class="ltx_p">For Argoverse2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> dataset, we use (0.1m, 0.1m, 0.2m) as voxel size. The perception range is [-200m, 200m] for <span id="A1.p7.1.1" class="ltx_text ltx_font_italic">X</span> or <span id="A1.p7.1.2" class="ltx_text ltx_font_italic">Y</span> axis. The range for <span id="A1.p7.1.3" class="ltx_text ltx_font_italic">Z</span> is [-20m, 20m].</p>
</div>
<div id="A1.p8" class="ltx_para ltx_noindent">
<p id="A1.p8.1" class="ltx_p"><span id="A1.p8.1.1" class="ltx_text ltx_font_bold">Data Augmentations</span></p>
</div>
<div id="A1.p9" class="ltx_para">
<p id="A1.p9.2" class="ltx_p">For nuScenes dataset, random flipping, global scaling, global rotation, GT sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, and translation augmentations are used. Flipping is randomly conducted along <span id="A1.p9.2.1" class="ltx_text ltx_font_italic">X</span> and <span id="A1.p9.2.2" class="ltx_text ltx_font_italic">Y</span> axes. Rotation angle is randomly picked between -45<sup id="A1.p9.2.3" class="ltx_sup"><span id="A1.p9.2.3.1" class="ltx_text ltx_font_italic">o</span></sup> and 45<sup id="A1.p9.2.4" class="ltx_sup"><span id="A1.p9.2.4.1" class="ltx_text ltx_font_italic">o</span></sup>. Global scaling is conducted by a factor sampled between 0.9 and 1.1. The translation noise factors are sampled between 0 and 0.5. Only for test submission models, GT sampling is removed in the last 5 training epochs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.</p>
</div>
<div id="A1.p10" class="ltx_para">
<p id="A1.p10.1" class="ltx_p">For Waymo dataset, data augmentations also include random flipping, global scaling, global rotation, and ground-truth (GT) sampling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. These settings are similar to those of nuScenes dataset and follow baseline methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.</p>
</div>
<div id="A1.p11" class="ltx_para">
<p id="A1.p11.1" class="ltx_p">For Argoverse2 dataset, we use similar data augmentation to nuScenes and Waymo, except that we do not use ground-truth sampling.</p>
</div>
<figure id="A1.F10" class="ltx_figure"><img src="/html/2303.11301/assets/x10.png" id="A1.F10.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.8.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A1.F10.9.2" class="ltx_text" style="font-size:90%;">The relative positions of query voxel to the predicted boxes, <span id="A1.F10.9.2.1" class="ltx_text ltx_font_italic">e.g.</span>, <span id="A1.F10.9.2.2" class="ltx_text ltx_font_italic">near center</span>, <span id="A1.F10.9.2.3" class="ltx_text ltx_font_italic">near boundary</span>, <span id="A1.F10.9.2.4" class="ltx_text ltx_font_italic">outside box</span>, corresponding to Tab. <span id="A1.F10.9.2.5" class="ltx_text" style="color:#FF0000;">7</span> in the paper.</span></figcaption>
</figure>
<div id="A1.p12" class="ltx_para ltx_noindent">
<p id="A1.p12.1" class="ltx_p"><span id="A1.p12.1.1" class="ltx_text ltx_font_bold">Training Hyper-parameters</span></p>
</div>
<div id="A1.p13" class="ltx_para">
<p id="A1.p13.1" class="ltx_p">For nuScenes dataset, models are trained for 20 epochs with batch size 16. They are optimized with Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Learning rate is initially 1e-3 and decays to 1e-4 in a cosine annealing. Weight decay is 0.01. Gradients are clipped by norm 35. These settings follow CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
<div id="A1.p14" class="ltx_para">
<p id="A1.p14.1" class="ltx_p">For Waymo dataset, models are trained for 12 epochs by default. Batch size is set as 16. Learning rate is initialized as 3e-3. They are also optimized with Adam <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="A1.p15" class="ltx_para">
<p id="A1.p15.1" class="ltx_p">For Argoverse2 dataset, we use similar settings to Waymo, except that only 6 epochs for training is enough.</p>
</div>
<figure id="A1.T17" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T17.3.1.1" class="ltx_text" style="font-size:90%;">Table 17</span>: </span><span id="A1.T17.4.2" class="ltx_text" style="font-size:90%;">Comparison on the nuScenes validation split. This table presents detailed performance for Tab. <span id="A1.T17.4.2.1" class="ltx_text" style="color:#FF0000;">1</span> in the paper.</span></figcaption>
<table id="A1.T17.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T17.5.1" class="ltx_tr">
<td id="A1.T17.5.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="A1.T17.5.1.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="A1.T17.5.1.2" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="A1.T17.5.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
<td id="A1.T17.5.1.4" class="ltx_td ltx_align_center ltx_border_t">Car</td>
<td id="A1.T17.5.1.5" class="ltx_td ltx_align_center ltx_border_t">Truck</td>
<td id="A1.T17.5.1.6" class="ltx_td ltx_align_center ltx_border_t">Bus</td>
<td id="A1.T17.5.1.7" class="ltx_td ltx_align_center ltx_border_t">Trailer</td>
<td id="A1.T17.5.1.8" class="ltx_td ltx_align_center ltx_border_t">C.V.</td>
<td id="A1.T17.5.1.9" class="ltx_td ltx_align_center ltx_border_t">Ped</td>
<td id="A1.T17.5.1.10" class="ltx_td ltx_align_center ltx_border_t">Mot</td>
<td id="A1.T17.5.1.11" class="ltx_td ltx_align_center ltx_border_t">Byc</td>
<td id="A1.T17.5.1.12" class="ltx_td ltx_align_center ltx_border_t">T.C.</td>
<td id="A1.T17.5.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Bar</td>
</tr>
<tr id="A1.T17.5.2" class="ltx_tr">
<td id="A1.T17.5.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">SECOND <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="A1.T17.5.2.2" class="ltx_td ltx_align_center ltx_border_t">50.6</td>
<td id="A1.T17.5.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.3</td>
<td id="A1.T17.5.2.4" class="ltx_td ltx_align_center ltx_border_t">81.8</td>
<td id="A1.T17.5.2.5" class="ltx_td ltx_align_center ltx_border_t">51.7</td>
<td id="A1.T17.5.2.6" class="ltx_td ltx_align_center ltx_border_t">66.9</td>
<td id="A1.T17.5.2.7" class="ltx_td ltx_align_center ltx_border_t">37.3</td>
<td id="A1.T17.5.2.8" class="ltx_td ltx_align_center ltx_border_t">15.0</td>
<td id="A1.T17.5.2.9" class="ltx_td ltx_align_center ltx_border_t">77.7</td>
<td id="A1.T17.5.2.10" class="ltx_td ltx_align_center ltx_border_t">42.5</td>
<td id="A1.T17.5.2.11" class="ltx_td ltx_align_center ltx_border_t">17.5</td>
<td id="A1.T17.5.2.12" class="ltx_td ltx_align_center ltx_border_t">57.4</td>
<td id="A1.T17.5.2.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.2</td>
</tr>
<tr id="A1.T17.5.3" class="ltx_tr">
<td id="A1.T17.5.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r">CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="A1.T17.5.3.2" class="ltx_td ltx_align_center">58.6</td>
<td id="A1.T17.5.3.3" class="ltx_td ltx_align_center ltx_border_r">66.2</td>
<td id="A1.T17.5.3.4" class="ltx_td ltx_align_center">85.0</td>
<td id="A1.T17.5.3.5" class="ltx_td ltx_align_center">58.2</td>
<td id="A1.T17.5.3.6" class="ltx_td ltx_align_center">69.5</td>
<td id="A1.T17.5.3.7" class="ltx_td ltx_align_center">35.7</td>
<td id="A1.T17.5.3.8" class="ltx_td ltx_align_center">15.5</td>
<td id="A1.T17.5.3.9" class="ltx_td ltx_align_center">85.3</td>
<td id="A1.T17.5.3.10" class="ltx_td ltx_align_center">58.8</td>
<td id="A1.T17.5.3.11" class="ltx_td ltx_align_center">40.9</td>
<td id="A1.T17.5.3.12" class="ltx_td ltx_align_center">70.0</td>
<td id="A1.T17.5.3.13" class="ltx_td ltx_align_center ltx_border_r">67.1</td>
</tr>
<tr id="A1.T17.5.4" class="ltx_tr">
<td id="A1.T17.5.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt</td>
<td id="A1.T17.5.4.2" class="ltx_td ltx_align_center ltx_border_b">60.0</td>
<td id="A1.T17.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">67.1</td>
<td id="A1.T17.5.4.4" class="ltx_td ltx_align_center ltx_border_b">85.6</td>
<td id="A1.T17.5.4.5" class="ltx_td ltx_align_center ltx_border_b">58.4</td>
<td id="A1.T17.5.4.6" class="ltx_td ltx_align_center ltx_border_b">71.6</td>
<td id="A1.T17.5.4.7" class="ltx_td ltx_align_center ltx_border_b">38.6</td>
<td id="A1.T17.5.4.8" class="ltx_td ltx_align_center ltx_border_b">17.9</td>
<td id="A1.T17.5.4.9" class="ltx_td ltx_align_center ltx_border_b">85.4</td>
<td id="A1.T17.5.4.10" class="ltx_td ltx_align_center ltx_border_b">59.7</td>
<td id="A1.T17.5.4.11" class="ltx_td ltx_align_center ltx_border_b">43.4</td>
<td id="A1.T17.5.4.12" class="ltx_td ltx_align_center ltx_border_b">70.8</td>
<td id="A1.T17.5.4.13" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">68.1</td>
</tr>
</table>
</figure>
<figure id="A1.T18" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T18.2.1.1" class="ltx_text" style="font-size:90%;">Table 18</span>: </span><span id="A1.T18.3.2" class="ltx_text" style="font-size:90%;">Effects of the feature levels for prediction.</span></figcaption>
<table id="A1.T18.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T18.4.1" class="ltx_tr">
<td id="A1.T18.4.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Head resolution</td>
<td id="A1.T18.4.1.2" class="ltx_td ltx_align_center ltx_border_t">mAP</td>
<td id="A1.T18.4.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">NDS</td>
</tr>
<tr id="A1.T18.4.2" class="ltx_tr">
<td id="A1.T18.4.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">8</td>
<td id="A1.T18.4.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T18.4.2.2.1" class="ltx_text ltx_font_bold">56.2</span></td>
<td id="A1.T18.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T18.4.2.3.1" class="ltx_text ltx_font_bold">64.3</span></td>
</tr>
<tr id="A1.T18.4.3" class="ltx_tr">
<td id="A1.T18.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">16</td>
<td id="A1.T18.4.3.2" class="ltx_td ltx_align_center">52.5</td>
<td id="A1.T18.4.3.3" class="ltx_td ltx_align_center ltx_border_r">60.7</td>
</tr>
<tr id="A1.T18.4.4" class="ltx_tr">
<td id="A1.T18.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">32</td>
<td id="A1.T18.4.4.2" class="ltx_td ltx_align_center">49.0</td>
<td id="A1.T18.4.4.3" class="ltx_td ltx_align_center ltx_border_r">57.9</td>
</tr>
<tr id="A1.T18.4.5" class="ltx_tr">
<td id="A1.T18.4.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">{8, 16, 32}</td>
<td id="A1.T18.4.5.2" class="ltx_td ltx_align_center">55.7</td>
<td id="A1.T18.4.5.3" class="ltx_td ltx_align_center ltx_border_r">63.7</td>
</tr>
<tr id="A1.T18.4.6" class="ltx_tr">
<td id="A1.T18.4.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r">{2, 4, 8, 16, 32}</td>
<td id="A1.T18.4.6.2" class="ltx_td ltx_align_center ltx_border_b">53.9</td>
<td id="A1.T18.4.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">62.2</td>
</tr>
</table>
</figure>
<figure id="A1.T19" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T19.2.1.1" class="ltx_text" style="font-size:90%;">Table 19</span>: </span><span id="A1.T19.3.2" class="ltx_text" style="font-size:90%;">Gap between VoxelNeXt-2D and VoxelNet. mAP on nuScenes validation with different amounts of training data.</span></figcaption>
<table id="A1.T19.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T19.4.1" class="ltx_tr">
<td id="A1.T19.4.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="A1.T19.4.1.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="A1.T19.4.1.2" class="ltx_td ltx_align_center ltx_border_t">1/4</td>
<td id="A1.T19.4.1.3" class="ltx_td ltx_align_center ltx_border_t">1/2</td>
<td id="A1.T19.4.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">full</td>
</tr>
<tr id="A1.T19.4.2" class="ltx_tr">
<td id="A1.T19.4.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt-2D</td>
<td id="A1.T19.4.2.2" class="ltx_td ltx_align_center ltx_border_t">53.4</td>
<td id="A1.T19.4.2.3" class="ltx_td ltx_align_center ltx_border_t">56.0</td>
<td id="A1.T19.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.7</td>
</tr>
<tr id="A1.T19.4.3" class="ltx_tr">
<td id="A1.T19.4.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt</td>
<td id="A1.T19.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">56.2</td>
<td id="A1.T19.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">58.2</td>
<td id="A1.T19.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">60.0</td>
</tr>
</table>
</figure>
<figure id="A1.F11" class="ltx_figure"><img src="/html/2303.11301/assets/x11.png" id="A1.F11.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="77" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.3.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="A1.F11.4.2" class="ltx_text" style="font-size:90%;">Detections of adjacent frames. We visualize predicted boxes and the corresponding query voxels, which are enlarged as red squares. This figure is best viewed by zoom-in.</span></figcaption>
</figure>
<div id="A1.p16" class="ltx_para ltx_noindent">
<p id="A1.p16.1" class="ltx_p"><span id="A1.p16.1.1" class="ltx_text ltx_font_bold">Network Structures</span></p>
</div>
<div id="A1.p17" class="ltx_para">
<p id="A1.p17.1" class="ltx_p">We develop our VoxelNeXt network upon the widely-used residual sparse convolutional block <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. We use 2D sparse convolutions in its variant of VoxelNeXt-2D. For voxel selection and box regression, we use fully-connected layer or kernel-size-3 submanifold sparse convolutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> for prediction. The former convolution has 128 channels in VoxelNeXt-2D and 64 in 3D networks. Training schedules and hyper-parameters follow prior works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
<div id="A1.p18" class="ltx_para">
<p id="A1.p18.1" class="ltx_p">The backbone network of VoxelNeXt has 6 stages. The channels for these stages are {16, 32, 64, 128, 128, 128} by default. There are 2 residual submanifold sparse convolutional blocks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> in each stage. The sparse head predicts outputs by <math id="A1.p18.1.m1.1" class="ltx_Math" alttext="3\times 3" display="inline"><semantics id="A1.p18.1.m1.1a"><mrow id="A1.p18.1.m1.1.1" xref="A1.p18.1.m1.1.1.cmml"><mn id="A1.p18.1.m1.1.1.2" xref="A1.p18.1.m1.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="A1.p18.1.m1.1.1.1" xref="A1.p18.1.m1.1.1.1.cmml">×</mo><mn id="A1.p18.1.m1.1.1.3" xref="A1.p18.1.m1.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p18.1.m1.1b"><apply id="A1.p18.1.m1.1.1.cmml" xref="A1.p18.1.m1.1.1"><times id="A1.p18.1.m1.1.1.1.cmml" xref="A1.p18.1.m1.1.1.1"></times><cn type="integer" id="A1.p18.1.m1.1.1.2.cmml" xref="A1.p18.1.m1.1.1.2">3</cn><cn type="integer" id="A1.p18.1.m1.1.1.3.cmml" xref="A1.p18.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p18.1.m1.1c">3\times 3</annotation></semantics></math> submainfold sparse convolutions. Following CenterPoint <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, the prediction layers are only shared among similar classes on nuScenes and Argoverse2 and shared among all classes on Waymo. The kernel sizes for the sparse max pooling layer varies in different heads, because the size of objects varies in different classes.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental results</h2>

<div id="A2.p1" class="ltx_para ltx_noindent">
<p id="A2.p1.1" class="ltx_p"><span id="A2.p1.1.1" class="ltx_text ltx_font_bold">Performance on nuScenes Validation </span>
We provide the performance of VoxelNeXt on nuScenes <span id="A2.p1.1.2" class="ltx_text ltx_font_italic">val</span> in Tab. A - <a href="#A1.T17" title="Table 17 ‣ Appendix A Implementation Details ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>.</p>
</div>
<div id="A2.p2" class="ltx_para ltx_noindent">
<p id="A2.p2.1" class="ltx_p"><span id="A2.p2.1.1" class="ltx_text ltx_font_bold">Gaps between VoxelNeXt and VoxelNeXt-2D </span>
We analyze the gaps between VoxelNeXt and VoxelNeXt-2D on different amounts of training data in Tab. A - <a href="#A1.T19" title="Table 19 ‣ Appendix A Implementation Details ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a>. These models are trained on 1/4, 1/2, and full nuScenes training set, respectively, and evaluated on the full validation set. It shows that The gap is large on the 1/4 training data, while the gaps gradually narrow as the data amount grows. Overall, the 3D network can obtain much better performance than its 2D counterpart at a small amount of data. Meanwhile, VoxelNeXt-2D has potential on large data amount.</p>
</div>
<div id="A2.p3" class="ltx_para ltx_noindent">
<p id="A2.p3.1" class="ltx_p"><span id="A2.p3.1.1" class="ltx_text ltx_font_bold">Resolution of Sparse Head</span>
We make an ablation study on the resolution of prediction head in Tab. A - <a href="#A1.T18" title="Table 18 ‣ Appendix A Implementation Details ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a>. The performance decreases as the head resolution increases from the default setting of 8 to 32. In addition, we also evaluate the multi-head design of {8, 16, 32} and {2, 4, 8, 16, 32}, where results are combined from the multiple heads with various resolutions. These multi-head models present no better results than the single-resolution 8 network.</p>
</div>
<figure id="A2.T20" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A2.T20.6.2.1" class="ltx_text" style="font-size:90%;">Table 20</span>: </span><span id="A2.T20.2.2.1" class="ltx_text" style="font-size:90%;">Results on Vehicle detection on Waymo. <sup id="A2.T20.2.2.1.1" class="ltx_sup">∗</sup> means decreasing the number of pasted instances in the ground-truth sampling augmentation and increase training epochs by 6 epochs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</span></figcaption>
<table id="A2.T20.3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A2.T20.3.3.2" class="ltx_tr">
<td id="A2.T20.3.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="A2.T20.3.3.2.1.1" class="ltx_text ltx_font_italic">Method</span></td>
<td id="A2.T20.3.3.2.2" class="ltx_td ltx_align_left ltx_border_t">L1 AP/APH</td>
<td id="A2.T20.3.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">L2 AP/APH</td>
</tr>
<tr id="A2.T20.3.3.3" class="ltx_tr">
<td id="A2.T20.3.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">VoxelNeXt</td>
<td id="A2.T20.3.3.3.2" class="ltx_td ltx_align_left ltx_border_t">78.2 / 77.7</td>
<td id="A2.T20.3.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">69.9 / 69.4</td>
</tr>
<tr id="A2.T20.3.3.1" class="ltx_tr">
<td id="A2.T20.3.3.1.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r">VoxelNeXt<sup id="A2.T20.3.3.1.1.1" class="ltx_sup">∗</sup>
</td>
<td id="A2.T20.3.3.1.2" class="ltx_td ltx_align_left ltx_border_b">79.1 / 79.0</td>
<td id="A2.T20.3.3.1.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">70.8 / 70.5</td>
</tr>
</table>
</figure>
<div id="A2.p4" class="ltx_para ltx_noindent">
<p id="A2.p4.1" class="ltx_p"><span id="A2.p4.1.1" class="ltx_text ltx_font_bold">Performance on Waymo vehicle detection </span>
In Tab. A - <a href="#A2.T20" title="Table 20 ‣ Appendix B Experimental results ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">20</span></a>, we follow FSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to decrease the number of pasted instances in the ground-truth sampling augmentation and increase training epochs by 6 epochs. This trick leads to better results upon VoxelNeXt on the Waymo object detection.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Visualizations</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We visualize the results of adjacent frames in Fig. A - <a href="#A1.F11" title="Figure 11 ‣ Appendix A Implementation Details ‣ VoxelNeXt: Fully Sparse VoxelNet for 3D Object Detection and Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. The corresponding query voxels are depicted as red squares.</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Discussions</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p id="A4.p1.1" class="ltx_p"><span id="A4.p1.1.1" class="ltx_text ltx_font_bold">Point-based Detectors </span>
Point-based 3D object detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> are fully sparse by their very nature. Point R-CNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> is a pioneer work and presents decent performance on KITTI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Methods of SSD series <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, including 3DSSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, inherit the point-based tradition and accelerate the methods with simplified pipelines. VoteNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> is based on center voting and studies indoor 3D object detection. However, point-based detectors are usually used in scenes with limited points. The neighborhood query operation is still unaffordable in large-scale benchmarks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, which are dominated by voxel-based detectors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
<div id="A4.p2" class="ltx_para ltx_noindent">
<p id="A4.p2.1" class="ltx_p"><span id="A4.p2.1.1" class="ltx_text ltx_font_bold">Boarder Impacts </span>
VoxelNeXt replies on 3D data and its spatially sparse distribution. It might reflect biases in data collection, including the ones of negative societal impacts.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.11300" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.11301" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.11301">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.11301" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.11302" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 19:22:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
