<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2203.01449] Object Pose Estimation using Mid-level Visual Representations</title><meta property="og:description" content="This work proposes a novel pose estimation model for object categories that can be effectively transferred to previously unseen environments.
The deep convolutional network models (CNN) for pose estimation are typicall…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Object Pose Estimation using Mid-level Visual Representations">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Object Pose Estimation using Mid-level Visual Representations">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2203.01449">

<!--Generated on Mon Mar 11 07:16:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">Object Pose Estimation using Mid-level Visual Representations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Negar Nejatishahidin<sup id="id3.3.id1" class="ltx_sup"><span id="id3.3.id1.1" class="ltx_text ltx_font_italic">∗</span></sup>, Pooya Fayyazsanavi<sup id="id4.4.id2" class="ltx_sup"><span id="id4.4.id2.1" class="ltx_text ltx_font_italic">∗</span></sup>, Jana Košecka
</span><span class="ltx_author_notes">These authors contributed equally to this work. George Mason University, e-mail:nnejatis,pfayyazs,kosecka@gmu.edu</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p">This work proposes a novel pose estimation model for object categories that can be effectively transferred to previously unseen environments.
The deep convolutional network models (CNN) for pose estimation are typically trained and evaluated on datasets specifically curated for object detection, pose estimation, or 3D reconstruction, which requires large amounts of training data. In this work, we propose a model for pose estimation that can be trained with small amount of data and is built on the top of generic mid-level
representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite> (e.g. surface normal estimation and
re-shading). These representations are trained on a large dataset without requiring pose and object annotations. Later on, the predictions are refined with a small CNN neural network that exploits object masks and silhouette retrieval. The presented approach achieves superior performance on the Pix3D dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite> and shows nearly 35% improvement over the existing models when only 25% of the training data is available. We show that the approach is favorable when it comes to generalization and transfer to novel environments. Towards this end, we introduce a new pose estimation benchmark for commonly encountered furniture categories on challenging Active Vision Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>]</cite> and evaluated the models trained on the Pix3D dataset.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Detecting objects and their 3D poses are an integral part of spatial 3D perception relevant to
semantic simultaneous localization and mapping approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">22</a>]</cite> and target-driven navigation.
The state of the art deep learning approaches have marked notable advancements by training
pose estimation models on large datasets with standard ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">6</a>]</cite> backbone, requiring a large amount of training data and costly pose annotations. The resulting models did not generalize well to the the same instance in different environments.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/Inputs.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="269" height="220" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text" style="font-size:90%;">Active Vision Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>]</cite> pose estimation benchmark challenges; many objects are highly occluded (e.g. the first two rows), large lighting variations, glassy objects (the third row), and truncated viewpoints (last row). These challenges affect both computation of mid-level representations and pose estimation.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The proposed approach uses RGB images only and estimates the pose from a single view. The premise of the approach is to develop a method that can benefit from the availability of 3D CAD models, can be seamlessly integrated with the state-of-the-art object detection models, and will generalize well to novel environments. Instead of training the entire model end-to-end from pixels to pose predictions, we train a lightweight convolutional neural network on the top of generic mid-level representation features (<span id="S1.p2.1.1" class="ltx_text ltx_font_italic">e.g.</span> normal estimation and re-shading features) that have been pre-trained in indoor environments. The initial predictions of the model are further refined using object masks and silhouette retrieval. The appeal of using mid-level representations features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">23</a>]</cite> for this task is their re-usability and effectiveness for training visuomotor policies for exploration, navigation to target, as well as local planning and ability to transfer well to novel environments.
In summary, the contributions of the proposed approach are summarized as follows:
</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Novel object pose estimation model build on the top of generic mid-level representation feature maps <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite> (surface normals, and re-shading feature maps) that have been shown to be effective for other perceptual tasks.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Effective refinement stage aided by object detection masks and silhouette retrieval achieving superior performance on the state-of-the-art Pix3D dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Competitive performance in low training data regime achieving 35% improvement over the existing models when there’s only 25% of training data is available.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">New pose estimation benchmark for commonly encountered furniture categories on Active Vision Dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>]</cite> and zero-shot pose estimation baseline for these real-world scans of indoor environments captured by the robot.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps"> Related work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There is a large body of work on 3D object pose estimation.
The existing techniques vary depending on the sensing modality, focus on the object instances or categories, and availability of 3D models. With the success of deep convolutional neural networks (DCNN) for object recognition and detection, many works focused on estimating the pose (azimuth and elevation or full 6D pose) of object categories, separately or jointly with the object detection DCNNs by adding another branch to the network.
In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">16</a>]</cite> a 3D pose regressor is learned for each object category, while in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite> a discrete-continuous formulation for the pose prediction is introduced, with the input being the cropped object bounding boxes. Authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx32" title="" class="ltx_ref">32</a>]</cite> decouple the pose estimation task into multiple components such as predicting pixel-wise object labels, estimating the object’s center and distance from the camera to recover the translation, and estimating the rotation, while <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">20</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">11</a>]</cite> both extend the SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">15</a>]</cite> object detector to predict azimuth and elevation or the 6-DoF pose respectively. These methods learn the pose estimation and recognition directly from image pixels, and require a large number of training examples with pose annotations that are challenging to obtain for many categories. This is the case also for keypoint-based methods, which typically work better in the presence of occlusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">19</a>, <a href="#bib.bibx10" title="" class="ltx_ref">10</a>]</cite>.
Notable progress has been made in pose estimation for object instances from images, where 3D textured instance models were available during the training stage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">9</a>]</cite>.
Authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">12</a>]</cite> exploit non-textured models where given the predicted pose and shape, the object is rendered and compared to 2D instance segmentation and trained end-to-end on the small number of categories. These approaches require 3D pose annotations in images during training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">30</a>, <a href="#bib.bibx8" title="" class="ltx_ref">8</a>]</cite>. Approaches that resort to keypoint based representations and use CAD models require annotations of 3D keypoints on textured CAD models.
Authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">14</a>]</cite> generate a synthetic dataset provides additional supervision during training. They learn to predict the 2D image locations of the projected vertices or projections of object’s 3D bounding box  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">27</a>]</cite> before a PnP algorithm estimates the pose.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">At last, there are approaches that use point clouds or depth data to tackle the pose estimation problem. Examples of these include methods that exploit effective 3D shape representations of 3D objects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx28" title="" class="ltx_ref">28</a>]</cite>, methods that learn how to align the sparse point clouds with the CAD models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">2</a>]</cite> or deep voting based methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">25</a>]</cite> that use point clouds both in training and testing. These works utilize repositories of 3D shape models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">31</a>, <a href="#bib.bibx3" title="" class="ltx_ref">3</a>]</cite> and/or video or 3D datasets with pose annotations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">4</a>, <a href="#bib.bibx24" title="" class="ltx_ref">24</a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Our work is most closely related to the approach proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite>, where 2.5D sketches are learned as intermediate representations for 3D reconstruction and pose prediction. There the authors introduced a new benchmark for pose estimation with instance (instead of category) level annotations and adopted the 2.5D sketch representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">29</a>]</cite> as intermediate object representations for prediction of 3D structure and object pose.
We take a departure from this training paradigm and show that effective pose estimation can be built on the top of feature maps that are part of generic perceptual skill set, also referred to as <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">mid-level representations</span>. The <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">mid-level representations</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">23</a>]</cite> have been shown in previous works as useful priors for learning visuomotor policies. This work demonstrates their effectiveness for pose estimation task.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/network_arc.png" id="S2.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="232" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.4.2" class="ltx_text" style="font-size:90%;">Network Architecture. First stage: up-sampled and fused mid-level feature maps (not the actual normal and re-shading images) are used to predict azimuth and elevation. Second stage: The object mask and mid-level features are compared with the top three object D-masks corresponding to most likely pose hypotheses from the first stage.</span></figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Approach</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this work, we present a novel pose estimation approach using RGB images only. Our work is inspired by approaches that learn 2.5D sketches comprised of surface normal, depth map, and object silhouette as intermediate representations for 3D reconstruction and pose estimation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">29</a>, <a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite>. Pix3D dataset comprised of several furniture categories, with instance-level pose and keypoint annotations along with depth, normal, and silhouette that are required for supervision of training the intermediate representations.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The effectiveness and often the superior performance of the models trained in an end-to-end or on a single dataset usually comes with the generalization and domain adaptation challenges when applied in novel environments.
The fundamental question when it comes to building computer vision systems for robot perception is whether the existence of perceptual priors or representations learned through a set of proxy tasks (<span id="S3.p2.1.1" class="ltx_text ltx_font_italic">e.g.</span> depth estimation, edge detection) can be useful for different downstream tasks. Since a robot’s visual perception requires tackling multiple tasks, the ability to share the representations/features that pertain to a particular class of environments is appealing. In this work, we propose to exploit generic mid-level representations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite> and show their effectiveness for down-stream object pose estimation task.
The feature maps and models associated with mid-level representations are learned separately using a large number of images of indoor scenes with the proxy task supervision (<span id="S3.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span> re-shading and normal estimation) and are frozen in our approach.
<br class="ltx_break">Our model consists of two stages. In the first stage, the initial pose predictions are made with up-sampled mid-level representations features to generate predictions for discretized candidate poses. For the top three pose candidates<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><math id="footnote1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="footnote1.m1.1b"><mrow id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml"><mn id="footnote1.m1.1.1.2" xref="footnote1.m1.1.1.2.cmml">90</mn><mo id="footnote1.m1.1.1.1" xref="footnote1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><apply id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1"><csymbol cd="latexml" id="footnote1.m1.1.1.1.cmml" xref="footnote1.m1.1.1.1">percent</csymbol><cn type="integer" id="footnote1.m1.1.1.2.cmml" xref="footnote1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">90\%</annotation></semantics></math> of the time, the correct pose label is included in the top three pose candidates, which is optimized based on our experiments.</span></span></span>, we retrieve their discretized pose masks (Rendered D-Masks) and train a small neural network that takes the mid-level features representations gated (multiplied) by the object masks and learn to predict the correct pose of the retrieved mask. In this work, we will focus only on commonly encountered furniture categories and estimation of azimuth and elevation.
In the following, we will describe the two stages in more detail.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Mid-Level Visual Representations</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The inputs to our model are the feature maps of mid-level representations trained separately
in indoor environments on visual proxy tasks in indoor environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite>. Out of 25 available networks for different tasks, we found surface normal and re-shading features most effective for the pose classification model, see Figure <a href="#S3.F3" title="Figure 3 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We determined the most useful feature maps experimentally by testing their informative combinations and report results in the experiments section <a href="#S5.SS3.SSS2" title="V-C2 Mid-level representations features input ‣ V-C Pose Evaluation ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-C</span>2</span></a> in Table <a href="#S5.T2" title="TABLE II ‣ V-C1 Baseline vs. Ours ‣ V-C Pose Evaluation ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.
These feature maps provide encoding of the input image, while the network weights are frozen, forming an input to our pose estimation model. We concatenate the <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="16\times 16\times 8" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mn id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.1.m1.1.1.1a" xref="S3.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS1.p1.1.m1.1.1.4" xref="S3.SS1.p1.1.m1.1.1.4.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><times id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">16</cn><cn type="integer" id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">16</cn><cn type="integer" id="S3.SS1.p1.1.m1.1.1.4.cmml" xref="S3.SS1.p1.1.m1.1.1.4">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">16\times 16\times 8</annotation></semantics></math> feature maps from models trained on surface normal and re-shading tasks. Based on our experiments, using the actual predicted normal and re-shading images, same as pix3D <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite>, reduces the performance of the model.
In the first phase of the model the feature maps are followed by additional convolution layers
to get initial azimuth and elevation predictions, see Figure <a href="#S2.F2" title="Figure 2 ‣ II Related work ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (left). The predictions are further refined in the second stage using predicted object masks.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/features-and-masks.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="269" height="286" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">Visualization of mid-level representations and masks on the Pix3D dataset.</span></figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/AVD_label.png" id="S3.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="185" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.4.2" class="ltx_text" style="font-size:90%;">The pose labelling pipeline for main object categories in AVD. Using (a) RGB and depth images of each scene, we reconstructed the (b) dense 3D point-cloud of each scene. (c) The 3D bounding boxes of objects inside these point clouds are annotated using the LabelCloud tool. (f) Poses are generated using the PNP algorithm between (d) the corners projected on the image plane and (e) corners in object coordinate frame. In total, we have labeled 6337 objects pose and 3D bounding box.</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Masks and Discretized-Masks</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The second stage of our model aims to refine the predictions by using the predicted
object masks, mid-level representations features, and rendered masks from CAD models.
Since the state-of-the-art mask prediction models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">7</a>, <a href="#bib.bibx18" title="" class="ltx_ref">18</a>]</cite> are not accurate enough to be solely effective, we generate masks rendered from different viewpoints of the CAD models of the training set and use them to further refine the predictions of the model from the first stage. We called these masks, Discretized-mask (D-mask). The 45 masks from different viewpoints, 9 different azimuths and 5 different elevations (<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="9\times 5" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">9</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><times id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">9</cn><cn type="integer" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">9\times 5</annotation></semantics></math>) are stored per instance. In addition, for each image, we used the mask output of the state-of-the-art object detector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">5</a>]</cite>, we call it predicted-mask, see Figure <a href="#S3.F3" title="Figure 3 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Model</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.3" class="ltx_p">Figure <a href="#S2.F2" title="Figure 2 ‣ II Related work ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows different stages of the approach. In the first stage, the model proposes its top candidates as the probable pose classes. The input to the model is only the surface normals and re-shading feature maps generated from mid-level visual representations, each map is <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="16\times 16\times 8" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mn id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.1.m1.1.1.1a" xref="S3.SS3.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.1.m1.1.1.4" xref="S3.SS3.p1.1.m1.1.1.4.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><times id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">16</cn><cn type="integer" id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">16</cn><cn type="integer" id="S3.SS3.p1.1.m1.1.1.4.cmml" xref="S3.SS3.p1.1.m1.1.1.4">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">16\times 16\times 8</annotation></semantics></math>. We concatenate the features to get the input representation (<math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="16\times 16\times 16" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mn id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.2.m2.1.1.1a" xref="S3.SS3.p1.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.2.m2.1.1.4" xref="S3.SS3.p1.2.m2.1.1.4.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><times id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"></times><cn type="integer" id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">16</cn><cn type="integer" id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">16</cn><cn type="integer" id="S3.SS3.p1.2.m2.1.1.4.cmml" xref="S3.SS3.p1.2.m2.1.1.4">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">16\times 16\times 16</annotation></semantics></math>) and up-sample the concatenated features to the size of <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="128\times 128\times 8" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mn id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p1.3.m3.1.1.1a" xref="S3.SS3.p1.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS3.p1.3.m3.1.1.4" xref="S3.SS3.p1.3.m3.1.1.4.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><times id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1"></times><cn type="integer" id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">128</cn><cn type="integer" id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">128</cn><cn type="integer" id="S3.SS3.p1.3.m3.1.1.4.cmml" xref="S3.SS3.p1.3.m3.1.1.4">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">128\times 128\times 8</annotation></semantics></math>. The up-sampled features are then passed to a convolutional layer. For the classification purpose, we use three fully connected layers, batch normalization, and ReLU, along with the dropout to get the final embedding before Softmax classification. Azimuth and Elevation are estimated separately from the last fully connected layer.
In the second stage, the up-sampled feature maps are masked out using the ’predicted-mask’. The top three pose candidates and their D-masks are stacked with the features one at a time.
These channels are followed by convolution layers along with batch normalization and three fully connected layers before the binary classification. The model in the second phase learns to determine whether the selected D-mask matches the features and the predicted-mask. Since our method uses only RGB images, in the testing stage, we need to retrieve correct CAD model to use it’s D-masks. As a CAD model retrieval pipeline, we used the predicted-mask of the test image and compare with all the predicted-masks of the training data. For this stage, we found out that a simple Template Matching is sufficient to find the most similar CAD model for the pose estimation task, but more elaborate silhouette matching techniques, such as Chamfer matching can be used in practice. Although the CAD model retrieval part is time consuming, it is guided by the knowledge of object category provided by object detector and for many indoor setting applications, this needs to be done once for each object.
</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Active Vision Dataset Pose Labeling</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The AVD dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>]</cite> is a public dataset for active robotic vision tasks. It is comprised of dense scans of real indoor environments and has a total of 17 scenes.
Each object is viewed from multiple viewpoints while the robot traverses the environment making it suitable for pose estimation. The pose estimation challenges include occluded objects, truncated images, dark objects, reflections, shiny objects, glass, lighting variations, and novel object instances. Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows examples of these challenges.
To train and evaluate pose estimation on AVD we
first provide pose annotation for the main object categories of <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">sofa, table, desk, bed</span>, and <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">chair</span>.
We first get the dense 3D dense point-cloud of each scene using each scene RGB and depth images and annotate the 3D bounding boxes for objects using
LabelCloud tool <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">21</a>]</cite>, the example is in Figure <a href="#S3.F4" title="Figure 4 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>c.
We then project corners of 3D bounding-boxes in world coordinate are projected back to the image plane using the transformation matrix from world to camera, Figure <a href="#S3.F4" title="Figure 4 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>d, base on the following equation:</p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.1" class="ltx_Math" alttext="{\bf X_{w}}=[R_{c}^{w}|T_{c}^{w}]{\bf X_{c}}" display="block"><semantics id="S4.Ex1.m1.1a"><mrow id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml"><msub id="S4.Ex1.m1.1.1.3" xref="S4.Ex1.m1.1.1.3.cmml"><mi id="S4.Ex1.m1.1.1.3.2" xref="S4.Ex1.m1.1.1.3.2.cmml">𝐗</mi><mi id="S4.Ex1.m1.1.1.3.3" xref="S4.Ex1.m1.1.1.3.3.cmml">𝐰</mi></msub><mo id="S4.Ex1.m1.1.1.2" xref="S4.Ex1.m1.1.1.2.cmml">=</mo><mrow id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.Ex1.m1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.cmml"><msubsup id="S4.Ex1.m1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.1.1.2.cmml"><mi id="S4.Ex1.m1.1.1.1.1.1.1.2.2.2" xref="S4.Ex1.m1.1.1.1.1.1.1.2.2.2.cmml">R</mi><mi id="S4.Ex1.m1.1.1.1.1.1.1.2.2.3" xref="S4.Ex1.m1.1.1.1.1.1.1.2.2.3.cmml">c</mi><mi id="S4.Ex1.m1.1.1.1.1.1.1.2.3" xref="S4.Ex1.m1.1.1.1.1.1.1.2.3.cmml">w</mi></msubsup><mo fence="false" id="S4.Ex1.m1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.cmml">|</mo><msubsup id="S4.Ex1.m1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.Ex1.m1.1.1.1.1.1.1.3.2.2" xref="S4.Ex1.m1.1.1.1.1.1.1.3.2.2.cmml">T</mi><mi id="S4.Ex1.m1.1.1.1.1.1.1.3.2.3" xref="S4.Ex1.m1.1.1.1.1.1.1.3.2.3.cmml">c</mi><mi id="S4.Ex1.m1.1.1.1.1.1.1.3.3" xref="S4.Ex1.m1.1.1.1.1.1.1.3.3.cmml">w</mi></msubsup></mrow><mo stretchy="false" id="S4.Ex1.m1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.2.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.2.cmml">​</mo><msub id="S4.Ex1.m1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.3.cmml"><mi id="S4.Ex1.m1.1.1.1.3.2" xref="S4.Ex1.m1.1.1.1.3.2.cmml">𝐗</mi><mi id="S4.Ex1.m1.1.1.1.3.3" xref="S4.Ex1.m1.1.1.1.3.3.cmml">𝐜</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1"><eq id="S4.Ex1.m1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.2"></eq><apply id="S4.Ex1.m1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.3.2">𝐗</ci><ci id="S4.Ex1.m1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.3.3">𝐰</ci></apply><apply id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1"><times id="S4.Ex1.m1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.2"></times><apply id="S4.Ex1.m1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S4.Ex1.m1.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.Ex1.m1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S4.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.Ex1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2.2.2">𝑅</ci><ci id="S4.Ex1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2.2.3">𝑐</ci></apply><ci id="S4.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.2.3">𝑤</ci></apply><apply id="S4.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S4.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3.2.2">𝑇</ci><ci id="S4.Ex1.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3.2.3">𝑐</ci></apply><ci id="S4.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.3.3">𝑤</ci></apply></apply></apply><apply id="S4.Ex1.m1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.3.1.cmml" xref="S4.Ex1.m1.1.1.1.3">subscript</csymbol><ci id="S4.Ex1.m1.1.1.1.3.2.cmml" xref="S4.Ex1.m1.1.1.1.3.2">𝐗</ci><ci id="S4.Ex1.m1.1.1.1.3.3.cmml" xref="S4.Ex1.m1.1.1.1.3.3">𝐜</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">{\bf X_{w}}=[R_{c}^{w}|T_{c}^{w}]{\bf X_{c}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/a_cam_poses.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="243" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;">The image shows the dense RGB-D sampling from each home in the AVD dataset. The red dots are the locations of the camera, and the blue arrows around each dot are the 12 camera orientations.</span></figcaption>
</figure>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.15" class="ltx_p">considering that, <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="R_{c}^{w}={R_{w}^{c}}^{T}" display="inline"><semantics id="S4.p2.1.m1.1a"><mrow id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><msubsup id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml"><mi id="S4.p2.1.m1.1.1.2.2.2" xref="S4.p2.1.m1.1.1.2.2.2.cmml">R</mi><mi id="S4.p2.1.m1.1.1.2.2.3" xref="S4.p2.1.m1.1.1.2.2.3.cmml">c</mi><mi id="S4.p2.1.m1.1.1.2.3" xref="S4.p2.1.m1.1.1.2.3.cmml">w</mi></msubsup><mo id="S4.p2.1.m1.1.1.1" xref="S4.p2.1.m1.1.1.1.cmml">=</mo><mmultiscripts id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml"><mi id="S4.p2.1.m1.1.1.3.2.2.2" xref="S4.p2.1.m1.1.1.3.2.2.2.cmml">R</mi><mi id="S4.p2.1.m1.1.1.3.2.2.3" xref="S4.p2.1.m1.1.1.3.2.2.3.cmml">w</mi><mi id="S4.p2.1.m1.1.1.3.2.3" xref="S4.p2.1.m1.1.1.3.2.3.cmml">c</mi><mrow id="S4.p2.1.m1.1.1.3a" xref="S4.p2.1.m1.1.1.3.cmml"></mrow><mi id="S4.p2.1.m1.1.1.3.3" xref="S4.p2.1.m1.1.1.3.3.cmml">T</mi></mmultiscripts></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><eq id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1"></eq><apply id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.2.1.cmml" xref="S4.p2.1.m1.1.1.2">superscript</csymbol><apply id="S4.p2.1.m1.1.1.2.2.cmml" xref="S4.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.2.2.1.cmml" xref="S4.p2.1.m1.1.1.2">subscript</csymbol><ci id="S4.p2.1.m1.1.1.2.2.2.cmml" xref="S4.p2.1.m1.1.1.2.2.2">𝑅</ci><ci id="S4.p2.1.m1.1.1.2.2.3.cmml" xref="S4.p2.1.m1.1.1.2.2.3">𝑐</ci></apply><ci id="S4.p2.1.m1.1.1.2.3.cmml" xref="S4.p2.1.m1.1.1.2.3">𝑤</ci></apply><apply id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.3.1.cmml" xref="S4.p2.1.m1.1.1.3">superscript</csymbol><apply id="S4.p2.1.m1.1.1.3.2.cmml" xref="S4.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.3.2.1.cmml" xref="S4.p2.1.m1.1.1.3">superscript</csymbol><apply id="S4.p2.1.m1.1.1.3.2.2.cmml" xref="S4.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.3.2.2.1.cmml" xref="S4.p2.1.m1.1.1.3">subscript</csymbol><ci id="S4.p2.1.m1.1.1.3.2.2.2.cmml" xref="S4.p2.1.m1.1.1.3.2.2.2">𝑅</ci><ci id="S4.p2.1.m1.1.1.3.2.2.3.cmml" xref="S4.p2.1.m1.1.1.3.2.2.3">𝑤</ci></apply><ci id="S4.p2.1.m1.1.1.3.2.3.cmml" xref="S4.p2.1.m1.1.1.3.2.3">𝑐</ci></apply><ci id="S4.p2.1.m1.1.1.3.3.cmml" xref="S4.p2.1.m1.1.1.3.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">R_{c}^{w}={R_{w}^{c}}^{T}</annotation></semantics></math>, and <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="T_{c}^{w}={-R_{w}^{c}}^{T}T_{w}^{c}" display="inline"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><msubsup id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml"><mi id="S4.p2.2.m2.1.1.2.2.2" xref="S4.p2.2.m2.1.1.2.2.2.cmml">T</mi><mi id="S4.p2.2.m2.1.1.2.2.3" xref="S4.p2.2.m2.1.1.2.2.3.cmml">c</mi><mi id="S4.p2.2.m2.1.1.2.3" xref="S4.p2.2.m2.1.1.2.3.cmml">w</mi></msubsup><mo id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml"><mo id="S4.p2.2.m2.1.1.3a" xref="S4.p2.2.m2.1.1.3.cmml">−</mo><mrow id="S4.p2.2.m2.1.1.3.2" xref="S4.p2.2.m2.1.1.3.2.cmml"><mmultiscripts id="S4.p2.2.m2.1.1.3.2.2" xref="S4.p2.2.m2.1.1.3.2.2.cmml"><mi id="S4.p2.2.m2.1.1.3.2.2.2.2.2" xref="S4.p2.2.m2.1.1.3.2.2.2.2.2.cmml">R</mi><mi id="S4.p2.2.m2.1.1.3.2.2.2.2.3" xref="S4.p2.2.m2.1.1.3.2.2.2.2.3.cmml">w</mi><mi id="S4.p2.2.m2.1.1.3.2.2.2.3" xref="S4.p2.2.m2.1.1.3.2.2.2.3.cmml">c</mi><mrow id="S4.p2.2.m2.1.1.3.2.2a" xref="S4.p2.2.m2.1.1.3.2.2.cmml"></mrow><mi id="S4.p2.2.m2.1.1.3.2.2.3" xref="S4.p2.2.m2.1.1.3.2.2.3.cmml">T</mi></mmultiscripts><mo lspace="0em" rspace="0em" id="S4.p2.2.m2.1.1.3.2.1" xref="S4.p2.2.m2.1.1.3.2.1.cmml">​</mo><msubsup id="S4.p2.2.m2.1.1.3.2.3" xref="S4.p2.2.m2.1.1.3.2.3.cmml"><mi id="S4.p2.2.m2.1.1.3.2.3.2.2" xref="S4.p2.2.m2.1.1.3.2.3.2.2.cmml">T</mi><mi id="S4.p2.2.m2.1.1.3.2.3.2.3" xref="S4.p2.2.m2.1.1.3.2.3.2.3.cmml">w</mi><mi id="S4.p2.2.m2.1.1.3.2.3.3" xref="S4.p2.2.m2.1.1.3.2.3.3.cmml">c</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><eq id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1"></eq><apply id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.2.1.cmml" xref="S4.p2.2.m2.1.1.2">superscript</csymbol><apply id="S4.p2.2.m2.1.1.2.2.cmml" xref="S4.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.2.2.1.cmml" xref="S4.p2.2.m2.1.1.2">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.2.2.cmml" xref="S4.p2.2.m2.1.1.2.2.2">𝑇</ci><ci id="S4.p2.2.m2.1.1.2.2.3.cmml" xref="S4.p2.2.m2.1.1.2.2.3">𝑐</ci></apply><ci id="S4.p2.2.m2.1.1.2.3.cmml" xref="S4.p2.2.m2.1.1.2.3">𝑤</ci></apply><apply id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3"><minus id="S4.p2.2.m2.1.1.3.1.cmml" xref="S4.p2.2.m2.1.1.3"></minus><apply id="S4.p2.2.m2.1.1.3.2.cmml" xref="S4.p2.2.m2.1.1.3.2"><times id="S4.p2.2.m2.1.1.3.2.1.cmml" xref="S4.p2.2.m2.1.1.3.2.1"></times><apply id="S4.p2.2.m2.1.1.3.2.2.cmml" xref="S4.p2.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.3.2.2.1.cmml" xref="S4.p2.2.m2.1.1.3.2.2">superscript</csymbol><apply id="S4.p2.2.m2.1.1.3.2.2.2.cmml" xref="S4.p2.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.3.2.2.2.1.cmml" xref="S4.p2.2.m2.1.1.3.2.2">superscript</csymbol><apply id="S4.p2.2.m2.1.1.3.2.2.2.2.cmml" xref="S4.p2.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.3.2.2.2.2.1.cmml" xref="S4.p2.2.m2.1.1.3.2.2">subscript</csymbol><ci id="S4.p2.2.m2.1.1.3.2.2.2.2.2.cmml" xref="S4.p2.2.m2.1.1.3.2.2.2.2.2">𝑅</ci><ci id="S4.p2.2.m2.1.1.3.2.2.2.2.3.cmml" xref="S4.p2.2.m2.1.1.3.2.2.2.2.3">𝑤</ci></apply><ci id="S4.p2.2.m2.1.1.3.2.2.2.3.cmml" xref="S4.p2.2.m2.1.1.3.2.2.2.3">𝑐</ci></apply><ci id="S4.p2.2.m2.1.1.3.2.2.3.cmml" xref="S4.p2.2.m2.1.1.3.2.2.3">𝑇</ci></apply><apply id="S4.p2.2.m2.1.1.3.2.3.cmml" xref="S4.p2.2.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.3.2.3.1.cmml" xref="S4.p2.2.m2.1.1.3.2.3">superscript</csymbol><apply id="S4.p2.2.m2.1.1.3.2.3.2.cmml" xref="S4.p2.2.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.3.2.3.2.1.cmml" xref="S4.p2.2.m2.1.1.3.2.3">subscript</csymbol><ci id="S4.p2.2.m2.1.1.3.2.3.2.2.cmml" xref="S4.p2.2.m2.1.1.3.2.3.2.2">𝑇</ci><ci id="S4.p2.2.m2.1.1.3.2.3.2.3.cmml" xref="S4.p2.2.m2.1.1.3.2.3.2.3">𝑤</ci></apply><ci id="S4.p2.2.m2.1.1.3.2.3.3.cmml" xref="S4.p2.2.m2.1.1.3.2.3.3">𝑐</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">T_{c}^{w}={-R_{w}^{c}}^{T}T_{w}^{c}</annotation></semantics></math>, <math id="S4.p2.3.m3.3" class="ltx_Math" alttext="{\bf X_{c}}=[X_{c},Y_{c},Z_{c}]^{T}" display="inline"><semantics id="S4.p2.3.m3.3a"><mrow id="S4.p2.3.m3.3.3" xref="S4.p2.3.m3.3.3.cmml"><msub id="S4.p2.3.m3.3.3.5" xref="S4.p2.3.m3.3.3.5.cmml"><mi id="S4.p2.3.m3.3.3.5.2" xref="S4.p2.3.m3.3.3.5.2.cmml">𝐗</mi><mi id="S4.p2.3.m3.3.3.5.3" xref="S4.p2.3.m3.3.3.5.3.cmml">𝐜</mi></msub><mo id="S4.p2.3.m3.3.3.4" xref="S4.p2.3.m3.3.3.4.cmml">=</mo><msup id="S4.p2.3.m3.3.3.3" xref="S4.p2.3.m3.3.3.3.cmml"><mrow id="S4.p2.3.m3.3.3.3.3.3" xref="S4.p2.3.m3.3.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.3.m3.3.3.3.3.3.4" xref="S4.p2.3.m3.3.3.3.3.4.cmml">[</mo><msub id="S4.p2.3.m3.1.1.1.1.1.1" xref="S4.p2.3.m3.1.1.1.1.1.1.cmml"><mi id="S4.p2.3.m3.1.1.1.1.1.1.2" xref="S4.p2.3.m3.1.1.1.1.1.1.2.cmml">X</mi><mi id="S4.p2.3.m3.1.1.1.1.1.1.3" xref="S4.p2.3.m3.1.1.1.1.1.1.3.cmml">c</mi></msub><mo id="S4.p2.3.m3.3.3.3.3.3.5" xref="S4.p2.3.m3.3.3.3.3.4.cmml">,</mo><msub id="S4.p2.3.m3.2.2.2.2.2.2" xref="S4.p2.3.m3.2.2.2.2.2.2.cmml"><mi id="S4.p2.3.m3.2.2.2.2.2.2.2" xref="S4.p2.3.m3.2.2.2.2.2.2.2.cmml">Y</mi><mi id="S4.p2.3.m3.2.2.2.2.2.2.3" xref="S4.p2.3.m3.2.2.2.2.2.2.3.cmml">c</mi></msub><mo id="S4.p2.3.m3.3.3.3.3.3.6" xref="S4.p2.3.m3.3.3.3.3.4.cmml">,</mo><msub id="S4.p2.3.m3.3.3.3.3.3.3" xref="S4.p2.3.m3.3.3.3.3.3.3.cmml"><mi id="S4.p2.3.m3.3.3.3.3.3.3.2" xref="S4.p2.3.m3.3.3.3.3.3.3.2.cmml">Z</mi><mi id="S4.p2.3.m3.3.3.3.3.3.3.3" xref="S4.p2.3.m3.3.3.3.3.3.3.3.cmml">c</mi></msub><mo stretchy="false" id="S4.p2.3.m3.3.3.3.3.3.7" xref="S4.p2.3.m3.3.3.3.3.4.cmml">]</mo></mrow><mi id="S4.p2.3.m3.3.3.3.5" xref="S4.p2.3.m3.3.3.3.5.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.3b"><apply id="S4.p2.3.m3.3.3.cmml" xref="S4.p2.3.m3.3.3"><eq id="S4.p2.3.m3.3.3.4.cmml" xref="S4.p2.3.m3.3.3.4"></eq><apply id="S4.p2.3.m3.3.3.5.cmml" xref="S4.p2.3.m3.3.3.5"><csymbol cd="ambiguous" id="S4.p2.3.m3.3.3.5.1.cmml" xref="S4.p2.3.m3.3.3.5">subscript</csymbol><ci id="S4.p2.3.m3.3.3.5.2.cmml" xref="S4.p2.3.m3.3.3.5.2">𝐗</ci><ci id="S4.p2.3.m3.3.3.5.3.cmml" xref="S4.p2.3.m3.3.3.5.3">𝐜</ci></apply><apply id="S4.p2.3.m3.3.3.3.cmml" xref="S4.p2.3.m3.3.3.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.3.3.3.4.cmml" xref="S4.p2.3.m3.3.3.3">superscript</csymbol><list id="S4.p2.3.m3.3.3.3.3.4.cmml" xref="S4.p2.3.m3.3.3.3.3.3"><apply id="S4.p2.3.m3.1.1.1.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.1.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1.1.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.1.1.1.1.2.cmml" xref="S4.p2.3.m3.1.1.1.1.1.1.2">𝑋</ci><ci id="S4.p2.3.m3.1.1.1.1.1.1.3.cmml" xref="S4.p2.3.m3.1.1.1.1.1.1.3">𝑐</ci></apply><apply id="S4.p2.3.m3.2.2.2.2.2.2.cmml" xref="S4.p2.3.m3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.3.m3.2.2.2.2.2.2.1.cmml" xref="S4.p2.3.m3.2.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.3.m3.2.2.2.2.2.2.2.cmml" xref="S4.p2.3.m3.2.2.2.2.2.2.2">𝑌</ci><ci id="S4.p2.3.m3.2.2.2.2.2.2.3.cmml" xref="S4.p2.3.m3.2.2.2.2.2.2.3">𝑐</ci></apply><apply id="S4.p2.3.m3.3.3.3.3.3.3.cmml" xref="S4.p2.3.m3.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.3.3.3.3.3.3.1.cmml" xref="S4.p2.3.m3.3.3.3.3.3.3">subscript</csymbol><ci id="S4.p2.3.m3.3.3.3.3.3.3.2.cmml" xref="S4.p2.3.m3.3.3.3.3.3.3.2">𝑍</ci><ci id="S4.p2.3.m3.3.3.3.3.3.3.3.cmml" xref="S4.p2.3.m3.3.3.3.3.3.3.3">𝑐</ci></apply></list><ci id="S4.p2.3.m3.3.3.3.5.cmml" xref="S4.p2.3.m3.3.3.3.5">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.3c">{\bf X_{c}}=[X_{c},Y_{c},Z_{c}]^{T}</annotation></semantics></math> is a point in the camera coordinate frame and <math id="S4.p2.4.m4.3" class="ltx_Math" alttext="{\bf X_{w}}=[X_{w},Y_{w},Z_{w}]^{T}" display="inline"><semantics id="S4.p2.4.m4.3a"><mrow id="S4.p2.4.m4.3.3" xref="S4.p2.4.m4.3.3.cmml"><msub id="S4.p2.4.m4.3.3.5" xref="S4.p2.4.m4.3.3.5.cmml"><mi id="S4.p2.4.m4.3.3.5.2" xref="S4.p2.4.m4.3.3.5.2.cmml">𝐗</mi><mi id="S4.p2.4.m4.3.3.5.3" xref="S4.p2.4.m4.3.3.5.3.cmml">𝐰</mi></msub><mo id="S4.p2.4.m4.3.3.4" xref="S4.p2.4.m4.3.3.4.cmml">=</mo><msup id="S4.p2.4.m4.3.3.3" xref="S4.p2.4.m4.3.3.3.cmml"><mrow id="S4.p2.4.m4.3.3.3.3.3" xref="S4.p2.4.m4.3.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.4.m4.3.3.3.3.3.4" xref="S4.p2.4.m4.3.3.3.3.4.cmml">[</mo><msub id="S4.p2.4.m4.1.1.1.1.1.1" xref="S4.p2.4.m4.1.1.1.1.1.1.cmml"><mi id="S4.p2.4.m4.1.1.1.1.1.1.2" xref="S4.p2.4.m4.1.1.1.1.1.1.2.cmml">X</mi><mi id="S4.p2.4.m4.1.1.1.1.1.1.3" xref="S4.p2.4.m4.1.1.1.1.1.1.3.cmml">w</mi></msub><mo id="S4.p2.4.m4.3.3.3.3.3.5" xref="S4.p2.4.m4.3.3.3.3.4.cmml">,</mo><msub id="S4.p2.4.m4.2.2.2.2.2.2" xref="S4.p2.4.m4.2.2.2.2.2.2.cmml"><mi id="S4.p2.4.m4.2.2.2.2.2.2.2" xref="S4.p2.4.m4.2.2.2.2.2.2.2.cmml">Y</mi><mi id="S4.p2.4.m4.2.2.2.2.2.2.3" xref="S4.p2.4.m4.2.2.2.2.2.2.3.cmml">w</mi></msub><mo id="S4.p2.4.m4.3.3.3.3.3.6" xref="S4.p2.4.m4.3.3.3.3.4.cmml">,</mo><msub id="S4.p2.4.m4.3.3.3.3.3.3" xref="S4.p2.4.m4.3.3.3.3.3.3.cmml"><mi id="S4.p2.4.m4.3.3.3.3.3.3.2" xref="S4.p2.4.m4.3.3.3.3.3.3.2.cmml">Z</mi><mi id="S4.p2.4.m4.3.3.3.3.3.3.3" xref="S4.p2.4.m4.3.3.3.3.3.3.3.cmml">w</mi></msub><mo stretchy="false" id="S4.p2.4.m4.3.3.3.3.3.7" xref="S4.p2.4.m4.3.3.3.3.4.cmml">]</mo></mrow><mi id="S4.p2.4.m4.3.3.3.5" xref="S4.p2.4.m4.3.3.3.5.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.3b"><apply id="S4.p2.4.m4.3.3.cmml" xref="S4.p2.4.m4.3.3"><eq id="S4.p2.4.m4.3.3.4.cmml" xref="S4.p2.4.m4.3.3.4"></eq><apply id="S4.p2.4.m4.3.3.5.cmml" xref="S4.p2.4.m4.3.3.5"><csymbol cd="ambiguous" id="S4.p2.4.m4.3.3.5.1.cmml" xref="S4.p2.4.m4.3.3.5">subscript</csymbol><ci id="S4.p2.4.m4.3.3.5.2.cmml" xref="S4.p2.4.m4.3.3.5.2">𝐗</ci><ci id="S4.p2.4.m4.3.3.5.3.cmml" xref="S4.p2.4.m4.3.3.5.3">𝐰</ci></apply><apply id="S4.p2.4.m4.3.3.3.cmml" xref="S4.p2.4.m4.3.3.3"><csymbol cd="ambiguous" id="S4.p2.4.m4.3.3.3.4.cmml" xref="S4.p2.4.m4.3.3.3">superscript</csymbol><list id="S4.p2.4.m4.3.3.3.3.4.cmml" xref="S4.p2.4.m4.3.3.3.3.3"><apply id="S4.p2.4.m4.1.1.1.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.4.m4.1.1.1.1.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1.1.1.1">subscript</csymbol><ci id="S4.p2.4.m4.1.1.1.1.1.1.2.cmml" xref="S4.p2.4.m4.1.1.1.1.1.1.2">𝑋</ci><ci id="S4.p2.4.m4.1.1.1.1.1.1.3.cmml" xref="S4.p2.4.m4.1.1.1.1.1.1.3">𝑤</ci></apply><apply id="S4.p2.4.m4.2.2.2.2.2.2.cmml" xref="S4.p2.4.m4.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.4.m4.2.2.2.2.2.2.1.cmml" xref="S4.p2.4.m4.2.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.4.m4.2.2.2.2.2.2.2.cmml" xref="S4.p2.4.m4.2.2.2.2.2.2.2">𝑌</ci><ci id="S4.p2.4.m4.2.2.2.2.2.2.3.cmml" xref="S4.p2.4.m4.2.2.2.2.2.2.3">𝑤</ci></apply><apply id="S4.p2.4.m4.3.3.3.3.3.3.cmml" xref="S4.p2.4.m4.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.p2.4.m4.3.3.3.3.3.3.1.cmml" xref="S4.p2.4.m4.3.3.3.3.3.3">subscript</csymbol><ci id="S4.p2.4.m4.3.3.3.3.3.3.2.cmml" xref="S4.p2.4.m4.3.3.3.3.3.3.2">𝑍</ci><ci id="S4.p2.4.m4.3.3.3.3.3.3.3.cmml" xref="S4.p2.4.m4.3.3.3.3.3.3.3">𝑤</ci></apply></list><ci id="S4.p2.4.m4.3.3.3.5.cmml" xref="S4.p2.4.m4.3.3.3.5">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.3c">{\bf X_{w}}=[X_{w},Y_{w},Z_{w}]^{T}</annotation></semantics></math> is the point in the world coordinate frame. <math id="S4.p2.5.m5.1" class="ltx_Math" alttext="R_{w}^{c}" display="inline"><semantics id="S4.p2.5.m5.1a"><msubsup id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><mi id="S4.p2.5.m5.1.1.2.2" xref="S4.p2.5.m5.1.1.2.2.cmml">R</mi><mi id="S4.p2.5.m5.1.1.2.3" xref="S4.p2.5.m5.1.1.2.3.cmml">w</mi><mi id="S4.p2.5.m5.1.1.3" xref="S4.p2.5.m5.1.1.3.cmml">c</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1">superscript</csymbol><apply id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p2.5.m5.1.1.2.1.cmml" xref="S4.p2.5.m5.1.1">subscript</csymbol><ci id="S4.p2.5.m5.1.1.2.2.cmml" xref="S4.p2.5.m5.1.1.2.2">𝑅</ci><ci id="S4.p2.5.m5.1.1.2.3.cmml" xref="S4.p2.5.m5.1.1.2.3">𝑤</ci></apply><ci id="S4.p2.5.m5.1.1.3.cmml" xref="S4.p2.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">R_{w}^{c}</annotation></semantics></math> is the rotation matrix from the world to the camera and <math id="S4.p2.6.m6.1" class="ltx_Math" alttext="T_{w}^{c}" display="inline"><semantics id="S4.p2.6.m6.1a"><msubsup id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml"><mi id="S4.p2.6.m6.1.1.2.2" xref="S4.p2.6.m6.1.1.2.2.cmml">T</mi><mi id="S4.p2.6.m6.1.1.2.3" xref="S4.p2.6.m6.1.1.2.3.cmml">w</mi><mi id="S4.p2.6.m6.1.1.3" xref="S4.p2.6.m6.1.1.3.cmml">c</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><apply id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p2.6.m6.1.1.1.cmml" xref="S4.p2.6.m6.1.1">superscript</csymbol><apply id="S4.p2.6.m6.1.1.2.cmml" xref="S4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p2.6.m6.1.1.2.1.cmml" xref="S4.p2.6.m6.1.1">subscript</csymbol><ci id="S4.p2.6.m6.1.1.2.2.cmml" xref="S4.p2.6.m6.1.1.2.2">𝑇</ci><ci id="S4.p2.6.m6.1.1.2.3.cmml" xref="S4.p2.6.m6.1.1.2.3">𝑤</ci></apply><ci id="S4.p2.6.m6.1.1.3.cmml" xref="S4.p2.6.m6.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">T_{w}^{c}</annotation></semantics></math> is the translation between them. The camera intrinsic parameters matrix <math id="S4.p2.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.p2.7.m7.1a"><mi id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.1b"><ci id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.1c">K</annotation></semantics></math> is also known. See Figure <a href="#S3.F4" title="Figure 4 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>b for an example of dense point-cloud reconstruction.
To get the pose of an object in camera coordinate frame we used PnP algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">13</a>]</cite> between the points in 2D image frame and correspondences in the object coordinate frame. The 3D bounding box can be defined by it’s center <math id="S4.p2.8.m8.3" class="ltx_Math" alttext="c=[c_{x},c_{y},c_{x}]" display="inline"><semantics id="S4.p2.8.m8.3a"><mrow id="S4.p2.8.m8.3.3" xref="S4.p2.8.m8.3.3.cmml"><mi id="S4.p2.8.m8.3.3.5" xref="S4.p2.8.m8.3.3.5.cmml">c</mi><mo id="S4.p2.8.m8.3.3.4" xref="S4.p2.8.m8.3.3.4.cmml">=</mo><mrow id="S4.p2.8.m8.3.3.3.3" xref="S4.p2.8.m8.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.8.m8.3.3.3.3.4" xref="S4.p2.8.m8.3.3.3.4.cmml">[</mo><msub id="S4.p2.8.m8.1.1.1.1.1" xref="S4.p2.8.m8.1.1.1.1.1.cmml"><mi id="S4.p2.8.m8.1.1.1.1.1.2" xref="S4.p2.8.m8.1.1.1.1.1.2.cmml">c</mi><mi id="S4.p2.8.m8.1.1.1.1.1.3" xref="S4.p2.8.m8.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S4.p2.8.m8.3.3.3.3.5" xref="S4.p2.8.m8.3.3.3.4.cmml">,</mo><msub id="S4.p2.8.m8.2.2.2.2.2" xref="S4.p2.8.m8.2.2.2.2.2.cmml"><mi id="S4.p2.8.m8.2.2.2.2.2.2" xref="S4.p2.8.m8.2.2.2.2.2.2.cmml">c</mi><mi id="S4.p2.8.m8.2.2.2.2.2.3" xref="S4.p2.8.m8.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S4.p2.8.m8.3.3.3.3.6" xref="S4.p2.8.m8.3.3.3.4.cmml">,</mo><msub id="S4.p2.8.m8.3.3.3.3.3" xref="S4.p2.8.m8.3.3.3.3.3.cmml"><mi id="S4.p2.8.m8.3.3.3.3.3.2" xref="S4.p2.8.m8.3.3.3.3.3.2.cmml">c</mi><mi id="S4.p2.8.m8.3.3.3.3.3.3" xref="S4.p2.8.m8.3.3.3.3.3.3.cmml">x</mi></msub><mo stretchy="false" id="S4.p2.8.m8.3.3.3.3.7" xref="S4.p2.8.m8.3.3.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.8.m8.3b"><apply id="S4.p2.8.m8.3.3.cmml" xref="S4.p2.8.m8.3.3"><eq id="S4.p2.8.m8.3.3.4.cmml" xref="S4.p2.8.m8.3.3.4"></eq><ci id="S4.p2.8.m8.3.3.5.cmml" xref="S4.p2.8.m8.3.3.5">𝑐</ci><list id="S4.p2.8.m8.3.3.3.4.cmml" xref="S4.p2.8.m8.3.3.3.3"><apply id="S4.p2.8.m8.1.1.1.1.1.cmml" xref="S4.p2.8.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.8.m8.1.1.1.1.1.1.cmml" xref="S4.p2.8.m8.1.1.1.1.1">subscript</csymbol><ci id="S4.p2.8.m8.1.1.1.1.1.2.cmml" xref="S4.p2.8.m8.1.1.1.1.1.2">𝑐</ci><ci id="S4.p2.8.m8.1.1.1.1.1.3.cmml" xref="S4.p2.8.m8.1.1.1.1.1.3">𝑥</ci></apply><apply id="S4.p2.8.m8.2.2.2.2.2.cmml" xref="S4.p2.8.m8.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.8.m8.2.2.2.2.2.1.cmml" xref="S4.p2.8.m8.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.8.m8.2.2.2.2.2.2.cmml" xref="S4.p2.8.m8.2.2.2.2.2.2">𝑐</ci><ci id="S4.p2.8.m8.2.2.2.2.2.3.cmml" xref="S4.p2.8.m8.2.2.2.2.2.3">𝑦</ci></apply><apply id="S4.p2.8.m8.3.3.3.3.3.cmml" xref="S4.p2.8.m8.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.p2.8.m8.3.3.3.3.3.1.cmml" xref="S4.p2.8.m8.3.3.3.3.3">subscript</csymbol><ci id="S4.p2.8.m8.3.3.3.3.3.2.cmml" xref="S4.p2.8.m8.3.3.3.3.3.2">𝑐</ci><ci id="S4.p2.8.m8.3.3.3.3.3.3.cmml" xref="S4.p2.8.m8.3.3.3.3.3.3">𝑥</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m8.3c">c=[c_{x},c_{y},c_{x}]</annotation></semantics></math> which in object coordinate is <math id="S4.p2.9.m9.3" class="ltx_Math" alttext="[0,0,0]" display="inline"><semantics id="S4.p2.9.m9.3a"><mrow id="S4.p2.9.m9.3.4.2" xref="S4.p2.9.m9.3.4.1.cmml"><mo stretchy="false" id="S4.p2.9.m9.3.4.2.1" xref="S4.p2.9.m9.3.4.1.cmml">[</mo><mn id="S4.p2.9.m9.1.1" xref="S4.p2.9.m9.1.1.cmml">0</mn><mo id="S4.p2.9.m9.3.4.2.2" xref="S4.p2.9.m9.3.4.1.cmml">,</mo><mn id="S4.p2.9.m9.2.2" xref="S4.p2.9.m9.2.2.cmml">0</mn><mo id="S4.p2.9.m9.3.4.2.3" xref="S4.p2.9.m9.3.4.1.cmml">,</mo><mn id="S4.p2.9.m9.3.3" xref="S4.p2.9.m9.3.3.cmml">0</mn><mo stretchy="false" id="S4.p2.9.m9.3.4.2.4" xref="S4.p2.9.m9.3.4.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.9.m9.3b"><list id="S4.p2.9.m9.3.4.1.cmml" xref="S4.p2.9.m9.3.4.2"><cn type="integer" id="S4.p2.9.m9.1.1.cmml" xref="S4.p2.9.m9.1.1">0</cn><cn type="integer" id="S4.p2.9.m9.2.2.cmml" xref="S4.p2.9.m9.2.2">0</cn><cn type="integer" id="S4.p2.9.m9.3.3.cmml" xref="S4.p2.9.m9.3.3">0</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.9.m9.3c">[0,0,0]</annotation></semantics></math>, it’s orientation <math id="S4.p2.10.m10.3" class="ltx_Math" alttext="R(\theta,\phi,\alpha)" display="inline"><semantics id="S4.p2.10.m10.3a"><mrow id="S4.p2.10.m10.3.4" xref="S4.p2.10.m10.3.4.cmml"><mi id="S4.p2.10.m10.3.4.2" xref="S4.p2.10.m10.3.4.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S4.p2.10.m10.3.4.1" xref="S4.p2.10.m10.3.4.1.cmml">​</mo><mrow id="S4.p2.10.m10.3.4.3.2" xref="S4.p2.10.m10.3.4.3.1.cmml"><mo stretchy="false" id="S4.p2.10.m10.3.4.3.2.1" xref="S4.p2.10.m10.3.4.3.1.cmml">(</mo><mi id="S4.p2.10.m10.1.1" xref="S4.p2.10.m10.1.1.cmml">θ</mi><mo id="S4.p2.10.m10.3.4.3.2.2" xref="S4.p2.10.m10.3.4.3.1.cmml">,</mo><mi id="S4.p2.10.m10.2.2" xref="S4.p2.10.m10.2.2.cmml">ϕ</mi><mo id="S4.p2.10.m10.3.4.3.2.3" xref="S4.p2.10.m10.3.4.3.1.cmml">,</mo><mi id="S4.p2.10.m10.3.3" xref="S4.p2.10.m10.3.3.cmml">α</mi><mo stretchy="false" id="S4.p2.10.m10.3.4.3.2.4" xref="S4.p2.10.m10.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.10.m10.3b"><apply id="S4.p2.10.m10.3.4.cmml" xref="S4.p2.10.m10.3.4"><times id="S4.p2.10.m10.3.4.1.cmml" xref="S4.p2.10.m10.3.4.1"></times><ci id="S4.p2.10.m10.3.4.2.cmml" xref="S4.p2.10.m10.3.4.2">𝑅</ci><vector id="S4.p2.10.m10.3.4.3.1.cmml" xref="S4.p2.10.m10.3.4.3.2"><ci id="S4.p2.10.m10.1.1.cmml" xref="S4.p2.10.m10.1.1">𝜃</ci><ci id="S4.p2.10.m10.2.2.cmml" xref="S4.p2.10.m10.2.2">italic-ϕ</ci><ci id="S4.p2.10.m10.3.3.cmml" xref="S4.p2.10.m10.3.3">𝛼</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.10.m10.3c">R(\theta,\phi,\alpha)</annotation></semantics></math>, and it’s dimensions <math id="S4.p2.11.m11.3" class="ltx_Math" alttext="D=[d_{x},d_{y},d_{z}]" display="inline"><semantics id="S4.p2.11.m11.3a"><mrow id="S4.p2.11.m11.3.3" xref="S4.p2.11.m11.3.3.cmml"><mi id="S4.p2.11.m11.3.3.5" xref="S4.p2.11.m11.3.3.5.cmml">D</mi><mo id="S4.p2.11.m11.3.3.4" xref="S4.p2.11.m11.3.3.4.cmml">=</mo><mrow id="S4.p2.11.m11.3.3.3.3" xref="S4.p2.11.m11.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.11.m11.3.3.3.3.4" xref="S4.p2.11.m11.3.3.3.4.cmml">[</mo><msub id="S4.p2.11.m11.1.1.1.1.1" xref="S4.p2.11.m11.1.1.1.1.1.cmml"><mi id="S4.p2.11.m11.1.1.1.1.1.2" xref="S4.p2.11.m11.1.1.1.1.1.2.cmml">d</mi><mi id="S4.p2.11.m11.1.1.1.1.1.3" xref="S4.p2.11.m11.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S4.p2.11.m11.3.3.3.3.5" xref="S4.p2.11.m11.3.3.3.4.cmml">,</mo><msub id="S4.p2.11.m11.2.2.2.2.2" xref="S4.p2.11.m11.2.2.2.2.2.cmml"><mi id="S4.p2.11.m11.2.2.2.2.2.2" xref="S4.p2.11.m11.2.2.2.2.2.2.cmml">d</mi><mi id="S4.p2.11.m11.2.2.2.2.2.3" xref="S4.p2.11.m11.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S4.p2.11.m11.3.3.3.3.6" xref="S4.p2.11.m11.3.3.3.4.cmml">,</mo><msub id="S4.p2.11.m11.3.3.3.3.3" xref="S4.p2.11.m11.3.3.3.3.3.cmml"><mi id="S4.p2.11.m11.3.3.3.3.3.2" xref="S4.p2.11.m11.3.3.3.3.3.2.cmml">d</mi><mi id="S4.p2.11.m11.3.3.3.3.3.3" xref="S4.p2.11.m11.3.3.3.3.3.3.cmml">z</mi></msub><mo stretchy="false" id="S4.p2.11.m11.3.3.3.3.7" xref="S4.p2.11.m11.3.3.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.11.m11.3b"><apply id="S4.p2.11.m11.3.3.cmml" xref="S4.p2.11.m11.3.3"><eq id="S4.p2.11.m11.3.3.4.cmml" xref="S4.p2.11.m11.3.3.4"></eq><ci id="S4.p2.11.m11.3.3.5.cmml" xref="S4.p2.11.m11.3.3.5">𝐷</ci><list id="S4.p2.11.m11.3.3.3.4.cmml" xref="S4.p2.11.m11.3.3.3.3"><apply id="S4.p2.11.m11.1.1.1.1.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.1.1.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.1.1.2.cmml" xref="S4.p2.11.m11.1.1.1.1.1.2">𝑑</ci><ci id="S4.p2.11.m11.1.1.1.1.1.3.cmml" xref="S4.p2.11.m11.1.1.1.1.1.3">𝑥</ci></apply><apply id="S4.p2.11.m11.2.2.2.2.2.cmml" xref="S4.p2.11.m11.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.2.2.2.2.2.1.cmml" xref="S4.p2.11.m11.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.11.m11.2.2.2.2.2.2.cmml" xref="S4.p2.11.m11.2.2.2.2.2.2">𝑑</ci><ci id="S4.p2.11.m11.2.2.2.2.2.3.cmml" xref="S4.p2.11.m11.2.2.2.2.2.3">𝑦</ci></apply><apply id="S4.p2.11.m11.3.3.3.3.3.cmml" xref="S4.p2.11.m11.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.p2.11.m11.3.3.3.3.3.1.cmml" xref="S4.p2.11.m11.3.3.3.3.3">subscript</csymbol><ci id="S4.p2.11.m11.3.3.3.3.3.2.cmml" xref="S4.p2.11.m11.3.3.3.3.3.2">𝑑</ci><ci id="S4.p2.11.m11.3.3.3.3.3.3.cmml" xref="S4.p2.11.m11.3.3.3.3.3.3">𝑧</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.11.m11.3c">D=[d_{x},d_{y},d_{z}]</annotation></semantics></math> which is annotated in second step. Therefore, the corners in object coordinate are <math id="S4.p2.12.m12.3" class="ltx_Math" alttext="{\bf X}_{1}^{b}=[d_{x}/2,d_{y}/2,d_{z}/2]^{T}" display="inline"><semantics id="S4.p2.12.m12.3a"><mrow id="S4.p2.12.m12.3.3" xref="S4.p2.12.m12.3.3.cmml"><msubsup id="S4.p2.12.m12.3.3.5" xref="S4.p2.12.m12.3.3.5.cmml"><mi id="S4.p2.12.m12.3.3.5.2.2" xref="S4.p2.12.m12.3.3.5.2.2.cmml">𝐗</mi><mn id="S4.p2.12.m12.3.3.5.2.3" xref="S4.p2.12.m12.3.3.5.2.3.cmml">1</mn><mi id="S4.p2.12.m12.3.3.5.3" xref="S4.p2.12.m12.3.3.5.3.cmml">b</mi></msubsup><mo id="S4.p2.12.m12.3.3.4" xref="S4.p2.12.m12.3.3.4.cmml">=</mo><msup id="S4.p2.12.m12.3.3.3" xref="S4.p2.12.m12.3.3.3.cmml"><mrow id="S4.p2.12.m12.3.3.3.3.3" xref="S4.p2.12.m12.3.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.12.m12.3.3.3.3.3.4" xref="S4.p2.12.m12.3.3.3.3.4.cmml">[</mo><mrow id="S4.p2.12.m12.1.1.1.1.1.1" xref="S4.p2.12.m12.1.1.1.1.1.1.cmml"><msub id="S4.p2.12.m12.1.1.1.1.1.1.2" xref="S4.p2.12.m12.1.1.1.1.1.1.2.cmml"><mi id="S4.p2.12.m12.1.1.1.1.1.1.2.2" xref="S4.p2.12.m12.1.1.1.1.1.1.2.2.cmml">d</mi><mi id="S4.p2.12.m12.1.1.1.1.1.1.2.3" xref="S4.p2.12.m12.1.1.1.1.1.1.2.3.cmml">x</mi></msub><mo id="S4.p2.12.m12.1.1.1.1.1.1.1" xref="S4.p2.12.m12.1.1.1.1.1.1.1.cmml">/</mo><mn id="S4.p2.12.m12.1.1.1.1.1.1.3" xref="S4.p2.12.m12.1.1.1.1.1.1.3.cmml">2</mn></mrow><mo id="S4.p2.12.m12.3.3.3.3.3.5" xref="S4.p2.12.m12.3.3.3.3.4.cmml">,</mo><mrow id="S4.p2.12.m12.2.2.2.2.2.2" xref="S4.p2.12.m12.2.2.2.2.2.2.cmml"><msub id="S4.p2.12.m12.2.2.2.2.2.2.2" xref="S4.p2.12.m12.2.2.2.2.2.2.2.cmml"><mi id="S4.p2.12.m12.2.2.2.2.2.2.2.2" xref="S4.p2.12.m12.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="S4.p2.12.m12.2.2.2.2.2.2.2.3" xref="S4.p2.12.m12.2.2.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S4.p2.12.m12.2.2.2.2.2.2.1" xref="S4.p2.12.m12.2.2.2.2.2.2.1.cmml">/</mo><mn id="S4.p2.12.m12.2.2.2.2.2.2.3" xref="S4.p2.12.m12.2.2.2.2.2.2.3.cmml">2</mn></mrow><mo id="S4.p2.12.m12.3.3.3.3.3.6" xref="S4.p2.12.m12.3.3.3.3.4.cmml">,</mo><mrow id="S4.p2.12.m12.3.3.3.3.3.3" xref="S4.p2.12.m12.3.3.3.3.3.3.cmml"><msub id="S4.p2.12.m12.3.3.3.3.3.3.2" xref="S4.p2.12.m12.3.3.3.3.3.3.2.cmml"><mi id="S4.p2.12.m12.3.3.3.3.3.3.2.2" xref="S4.p2.12.m12.3.3.3.3.3.3.2.2.cmml">d</mi><mi id="S4.p2.12.m12.3.3.3.3.3.3.2.3" xref="S4.p2.12.m12.3.3.3.3.3.3.2.3.cmml">z</mi></msub><mo id="S4.p2.12.m12.3.3.3.3.3.3.1" xref="S4.p2.12.m12.3.3.3.3.3.3.1.cmml">/</mo><mn id="S4.p2.12.m12.3.3.3.3.3.3.3" xref="S4.p2.12.m12.3.3.3.3.3.3.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.p2.12.m12.3.3.3.3.3.7" xref="S4.p2.12.m12.3.3.3.3.4.cmml">]</mo></mrow><mi id="S4.p2.12.m12.3.3.3.5" xref="S4.p2.12.m12.3.3.3.5.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.12.m12.3b"><apply id="S4.p2.12.m12.3.3.cmml" xref="S4.p2.12.m12.3.3"><eq id="S4.p2.12.m12.3.3.4.cmml" xref="S4.p2.12.m12.3.3.4"></eq><apply id="S4.p2.12.m12.3.3.5.cmml" xref="S4.p2.12.m12.3.3.5"><csymbol cd="ambiguous" id="S4.p2.12.m12.3.3.5.1.cmml" xref="S4.p2.12.m12.3.3.5">superscript</csymbol><apply id="S4.p2.12.m12.3.3.5.2.cmml" xref="S4.p2.12.m12.3.3.5"><csymbol cd="ambiguous" id="S4.p2.12.m12.3.3.5.2.1.cmml" xref="S4.p2.12.m12.3.3.5">subscript</csymbol><ci id="S4.p2.12.m12.3.3.5.2.2.cmml" xref="S4.p2.12.m12.3.3.5.2.2">𝐗</ci><cn type="integer" id="S4.p2.12.m12.3.3.5.2.3.cmml" xref="S4.p2.12.m12.3.3.5.2.3">1</cn></apply><ci id="S4.p2.12.m12.3.3.5.3.cmml" xref="S4.p2.12.m12.3.3.5.3">𝑏</ci></apply><apply id="S4.p2.12.m12.3.3.3.cmml" xref="S4.p2.12.m12.3.3.3"><csymbol cd="ambiguous" id="S4.p2.12.m12.3.3.3.4.cmml" xref="S4.p2.12.m12.3.3.3">superscript</csymbol><list id="S4.p2.12.m12.3.3.3.3.4.cmml" xref="S4.p2.12.m12.3.3.3.3.3"><apply id="S4.p2.12.m12.1.1.1.1.1.1.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1"><divide id="S4.p2.12.m12.1.1.1.1.1.1.1.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1.1"></divide><apply id="S4.p2.12.m12.1.1.1.1.1.1.2.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.p2.12.m12.1.1.1.1.1.1.2.1.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.p2.12.m12.1.1.1.1.1.1.2.2.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1.2.2">𝑑</ci><ci id="S4.p2.12.m12.1.1.1.1.1.1.2.3.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1.2.3">𝑥</ci></apply><cn type="integer" id="S4.p2.12.m12.1.1.1.1.1.1.3.cmml" xref="S4.p2.12.m12.1.1.1.1.1.1.3">2</cn></apply><apply id="S4.p2.12.m12.2.2.2.2.2.2.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2"><divide id="S4.p2.12.m12.2.2.2.2.2.2.1.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2.1"></divide><apply id="S4.p2.12.m12.2.2.2.2.2.2.2.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.12.m12.2.2.2.2.2.2.2.1.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.12.m12.2.2.2.2.2.2.2.2.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2.2.2">𝑑</ci><ci id="S4.p2.12.m12.2.2.2.2.2.2.2.3.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2.2.3">𝑦</ci></apply><cn type="integer" id="S4.p2.12.m12.2.2.2.2.2.2.3.cmml" xref="S4.p2.12.m12.2.2.2.2.2.2.3">2</cn></apply><apply id="S4.p2.12.m12.3.3.3.3.3.3.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3"><divide id="S4.p2.12.m12.3.3.3.3.3.3.1.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3.1"></divide><apply id="S4.p2.12.m12.3.3.3.3.3.3.2.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3.2"><csymbol cd="ambiguous" id="S4.p2.12.m12.3.3.3.3.3.3.2.1.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3.2">subscript</csymbol><ci id="S4.p2.12.m12.3.3.3.3.3.3.2.2.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3.2.2">𝑑</ci><ci id="S4.p2.12.m12.3.3.3.3.3.3.2.3.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3.2.3">𝑧</ci></apply><cn type="integer" id="S4.p2.12.m12.3.3.3.3.3.3.3.cmml" xref="S4.p2.12.m12.3.3.3.3.3.3.3">2</cn></apply></list><ci id="S4.p2.12.m12.3.3.3.5.cmml" xref="S4.p2.12.m12.3.3.3.5">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.12.m12.3c">{\bf X}_{1}^{b}=[d_{x}/2,d_{y}/2,d_{z}/2]^{T}</annotation></semantics></math>, <math id="S4.p2.13.m13.3" class="ltx_Math" alttext="{\bf X}_{2}^{b}=[-d_{x}/2,d_{y}/2,d_{z}/2]^{T}" display="inline"><semantics id="S4.p2.13.m13.3a"><mrow id="S4.p2.13.m13.3.3" xref="S4.p2.13.m13.3.3.cmml"><msubsup id="S4.p2.13.m13.3.3.5" xref="S4.p2.13.m13.3.3.5.cmml"><mi id="S4.p2.13.m13.3.3.5.2.2" xref="S4.p2.13.m13.3.3.5.2.2.cmml">𝐗</mi><mn id="S4.p2.13.m13.3.3.5.2.3" xref="S4.p2.13.m13.3.3.5.2.3.cmml">2</mn><mi id="S4.p2.13.m13.3.3.5.3" xref="S4.p2.13.m13.3.3.5.3.cmml">b</mi></msubsup><mo id="S4.p2.13.m13.3.3.4" xref="S4.p2.13.m13.3.3.4.cmml">=</mo><msup id="S4.p2.13.m13.3.3.3" xref="S4.p2.13.m13.3.3.3.cmml"><mrow id="S4.p2.13.m13.3.3.3.3.3" xref="S4.p2.13.m13.3.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.13.m13.3.3.3.3.3.4" xref="S4.p2.13.m13.3.3.3.3.4.cmml">[</mo><mrow id="S4.p2.13.m13.1.1.1.1.1.1" xref="S4.p2.13.m13.1.1.1.1.1.1.cmml"><mo id="S4.p2.13.m13.1.1.1.1.1.1a" xref="S4.p2.13.m13.1.1.1.1.1.1.cmml">−</mo><mrow id="S4.p2.13.m13.1.1.1.1.1.1.2" xref="S4.p2.13.m13.1.1.1.1.1.1.2.cmml"><msub id="S4.p2.13.m13.1.1.1.1.1.1.2.2" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2.cmml"><mi id="S4.p2.13.m13.1.1.1.1.1.1.2.2.2" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2.2.cmml">d</mi><mi id="S4.p2.13.m13.1.1.1.1.1.1.2.2.3" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2.3.cmml">x</mi></msub><mo id="S4.p2.13.m13.1.1.1.1.1.1.2.1" xref="S4.p2.13.m13.1.1.1.1.1.1.2.1.cmml">/</mo><mn id="S4.p2.13.m13.1.1.1.1.1.1.2.3" xref="S4.p2.13.m13.1.1.1.1.1.1.2.3.cmml">2</mn></mrow></mrow><mo id="S4.p2.13.m13.3.3.3.3.3.5" xref="S4.p2.13.m13.3.3.3.3.4.cmml">,</mo><mrow id="S4.p2.13.m13.2.2.2.2.2.2" xref="S4.p2.13.m13.2.2.2.2.2.2.cmml"><msub id="S4.p2.13.m13.2.2.2.2.2.2.2" xref="S4.p2.13.m13.2.2.2.2.2.2.2.cmml"><mi id="S4.p2.13.m13.2.2.2.2.2.2.2.2" xref="S4.p2.13.m13.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="S4.p2.13.m13.2.2.2.2.2.2.2.3" xref="S4.p2.13.m13.2.2.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S4.p2.13.m13.2.2.2.2.2.2.1" xref="S4.p2.13.m13.2.2.2.2.2.2.1.cmml">/</mo><mn id="S4.p2.13.m13.2.2.2.2.2.2.3" xref="S4.p2.13.m13.2.2.2.2.2.2.3.cmml">2</mn></mrow><mo id="S4.p2.13.m13.3.3.3.3.3.6" xref="S4.p2.13.m13.3.3.3.3.4.cmml">,</mo><mrow id="S4.p2.13.m13.3.3.3.3.3.3" xref="S4.p2.13.m13.3.3.3.3.3.3.cmml"><msub id="S4.p2.13.m13.3.3.3.3.3.3.2" xref="S4.p2.13.m13.3.3.3.3.3.3.2.cmml"><mi id="S4.p2.13.m13.3.3.3.3.3.3.2.2" xref="S4.p2.13.m13.3.3.3.3.3.3.2.2.cmml">d</mi><mi id="S4.p2.13.m13.3.3.3.3.3.3.2.3" xref="S4.p2.13.m13.3.3.3.3.3.3.2.3.cmml">z</mi></msub><mo id="S4.p2.13.m13.3.3.3.3.3.3.1" xref="S4.p2.13.m13.3.3.3.3.3.3.1.cmml">/</mo><mn id="S4.p2.13.m13.3.3.3.3.3.3.3" xref="S4.p2.13.m13.3.3.3.3.3.3.3.cmml">2</mn></mrow><mo stretchy="false" id="S4.p2.13.m13.3.3.3.3.3.7" xref="S4.p2.13.m13.3.3.3.3.4.cmml">]</mo></mrow><mi id="S4.p2.13.m13.3.3.3.5" xref="S4.p2.13.m13.3.3.3.5.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.13.m13.3b"><apply id="S4.p2.13.m13.3.3.cmml" xref="S4.p2.13.m13.3.3"><eq id="S4.p2.13.m13.3.3.4.cmml" xref="S4.p2.13.m13.3.3.4"></eq><apply id="S4.p2.13.m13.3.3.5.cmml" xref="S4.p2.13.m13.3.3.5"><csymbol cd="ambiguous" id="S4.p2.13.m13.3.3.5.1.cmml" xref="S4.p2.13.m13.3.3.5">superscript</csymbol><apply id="S4.p2.13.m13.3.3.5.2.cmml" xref="S4.p2.13.m13.3.3.5"><csymbol cd="ambiguous" id="S4.p2.13.m13.3.3.5.2.1.cmml" xref="S4.p2.13.m13.3.3.5">subscript</csymbol><ci id="S4.p2.13.m13.3.3.5.2.2.cmml" xref="S4.p2.13.m13.3.3.5.2.2">𝐗</ci><cn type="integer" id="S4.p2.13.m13.3.3.5.2.3.cmml" xref="S4.p2.13.m13.3.3.5.2.3">2</cn></apply><ci id="S4.p2.13.m13.3.3.5.3.cmml" xref="S4.p2.13.m13.3.3.5.3">𝑏</ci></apply><apply id="S4.p2.13.m13.3.3.3.cmml" xref="S4.p2.13.m13.3.3.3"><csymbol cd="ambiguous" id="S4.p2.13.m13.3.3.3.4.cmml" xref="S4.p2.13.m13.3.3.3">superscript</csymbol><list id="S4.p2.13.m13.3.3.3.3.4.cmml" xref="S4.p2.13.m13.3.3.3.3.3"><apply id="S4.p2.13.m13.1.1.1.1.1.1.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1"><minus id="S4.p2.13.m13.1.1.1.1.1.1.1.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1"></minus><apply id="S4.p2.13.m13.1.1.1.1.1.1.2.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2"><divide id="S4.p2.13.m13.1.1.1.1.1.1.2.1.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2.1"></divide><apply id="S4.p2.13.m13.1.1.1.1.1.1.2.2.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.p2.13.m13.1.1.1.1.1.1.2.2.1.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.p2.13.m13.1.1.1.1.1.1.2.2.2.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2.2">𝑑</ci><ci id="S4.p2.13.m13.1.1.1.1.1.1.2.2.3.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2.2.3">𝑥</ci></apply><cn type="integer" id="S4.p2.13.m13.1.1.1.1.1.1.2.3.cmml" xref="S4.p2.13.m13.1.1.1.1.1.1.2.3">2</cn></apply></apply><apply id="S4.p2.13.m13.2.2.2.2.2.2.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2"><divide id="S4.p2.13.m13.2.2.2.2.2.2.1.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2.1"></divide><apply id="S4.p2.13.m13.2.2.2.2.2.2.2.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.13.m13.2.2.2.2.2.2.2.1.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.13.m13.2.2.2.2.2.2.2.2.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2.2.2">𝑑</ci><ci id="S4.p2.13.m13.2.2.2.2.2.2.2.3.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2.2.3">𝑦</ci></apply><cn type="integer" id="S4.p2.13.m13.2.2.2.2.2.2.3.cmml" xref="S4.p2.13.m13.2.2.2.2.2.2.3">2</cn></apply><apply id="S4.p2.13.m13.3.3.3.3.3.3.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3"><divide id="S4.p2.13.m13.3.3.3.3.3.3.1.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3.1"></divide><apply id="S4.p2.13.m13.3.3.3.3.3.3.2.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3.2"><csymbol cd="ambiguous" id="S4.p2.13.m13.3.3.3.3.3.3.2.1.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3.2">subscript</csymbol><ci id="S4.p2.13.m13.3.3.3.3.3.3.2.2.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3.2.2">𝑑</ci><ci id="S4.p2.13.m13.3.3.3.3.3.3.2.3.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3.2.3">𝑧</ci></apply><cn type="integer" id="S4.p2.13.m13.3.3.3.3.3.3.3.cmml" xref="S4.p2.13.m13.3.3.3.3.3.3.3">2</cn></apply></list><ci id="S4.p2.13.m13.3.3.3.5.cmml" xref="S4.p2.13.m13.3.3.3.5">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.13.m13.3c">{\bf X}_{2}^{b}=[-d_{x}/2,d_{y}/2,d_{z}/2]^{T}</annotation></semantics></math>, <math id="S4.p2.14.m14.1" class="ltx_Math" alttext="..." display="inline"><semantics id="S4.p2.14.m14.1a"><mi mathvariant="normal" id="S4.p2.14.m14.1.1" xref="S4.p2.14.m14.1.1.cmml">…</mi><annotation-xml encoding="MathML-Content" id="S4.p2.14.m14.1b"><ci id="S4.p2.14.m14.1.1.cmml" xref="S4.p2.14.m14.1.1">…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.14.m14.1c">...</annotation></semantics></math>, <math id="S4.p2.15.m15.3" class="ltx_Math" alttext="{\bf X}_{8}^{b}=[-d_{x}/2,-d_{y}/2,-d_{z}/2]^{T}" display="inline"><semantics id="S4.p2.15.m15.3a"><mrow id="S4.p2.15.m15.3.3" xref="S4.p2.15.m15.3.3.cmml"><msubsup id="S4.p2.15.m15.3.3.5" xref="S4.p2.15.m15.3.3.5.cmml"><mi id="S4.p2.15.m15.3.3.5.2.2" xref="S4.p2.15.m15.3.3.5.2.2.cmml">𝐗</mi><mn id="S4.p2.15.m15.3.3.5.2.3" xref="S4.p2.15.m15.3.3.5.2.3.cmml">8</mn><mi id="S4.p2.15.m15.3.3.5.3" xref="S4.p2.15.m15.3.3.5.3.cmml">b</mi></msubsup><mo id="S4.p2.15.m15.3.3.4" xref="S4.p2.15.m15.3.3.4.cmml">=</mo><msup id="S4.p2.15.m15.3.3.3" xref="S4.p2.15.m15.3.3.3.cmml"><mrow id="S4.p2.15.m15.3.3.3.3.3" xref="S4.p2.15.m15.3.3.3.3.4.cmml"><mo stretchy="false" id="S4.p2.15.m15.3.3.3.3.3.4" xref="S4.p2.15.m15.3.3.3.3.4.cmml">[</mo><mrow id="S4.p2.15.m15.1.1.1.1.1.1" xref="S4.p2.15.m15.1.1.1.1.1.1.cmml"><mo id="S4.p2.15.m15.1.1.1.1.1.1a" xref="S4.p2.15.m15.1.1.1.1.1.1.cmml">−</mo><mrow id="S4.p2.15.m15.1.1.1.1.1.1.2" xref="S4.p2.15.m15.1.1.1.1.1.1.2.cmml"><msub id="S4.p2.15.m15.1.1.1.1.1.1.2.2" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2.cmml"><mi id="S4.p2.15.m15.1.1.1.1.1.1.2.2.2" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2.2.cmml">d</mi><mi id="S4.p2.15.m15.1.1.1.1.1.1.2.2.3" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2.3.cmml">x</mi></msub><mo id="S4.p2.15.m15.1.1.1.1.1.1.2.1" xref="S4.p2.15.m15.1.1.1.1.1.1.2.1.cmml">/</mo><mn id="S4.p2.15.m15.1.1.1.1.1.1.2.3" xref="S4.p2.15.m15.1.1.1.1.1.1.2.3.cmml">2</mn></mrow></mrow><mo id="S4.p2.15.m15.3.3.3.3.3.5" xref="S4.p2.15.m15.3.3.3.3.4.cmml">,</mo><mrow id="S4.p2.15.m15.2.2.2.2.2.2" xref="S4.p2.15.m15.2.2.2.2.2.2.cmml"><mo id="S4.p2.15.m15.2.2.2.2.2.2a" xref="S4.p2.15.m15.2.2.2.2.2.2.cmml">−</mo><mrow id="S4.p2.15.m15.2.2.2.2.2.2.2" xref="S4.p2.15.m15.2.2.2.2.2.2.2.cmml"><msub id="S4.p2.15.m15.2.2.2.2.2.2.2.2" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2.cmml"><mi id="S4.p2.15.m15.2.2.2.2.2.2.2.2.2" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="S4.p2.15.m15.2.2.2.2.2.2.2.2.3" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S4.p2.15.m15.2.2.2.2.2.2.2.1" xref="S4.p2.15.m15.2.2.2.2.2.2.2.1.cmml">/</mo><mn id="S4.p2.15.m15.2.2.2.2.2.2.2.3" xref="S4.p2.15.m15.2.2.2.2.2.2.2.3.cmml">2</mn></mrow></mrow><mo id="S4.p2.15.m15.3.3.3.3.3.6" xref="S4.p2.15.m15.3.3.3.3.4.cmml">,</mo><mrow id="S4.p2.15.m15.3.3.3.3.3.3" xref="S4.p2.15.m15.3.3.3.3.3.3.cmml"><mo id="S4.p2.15.m15.3.3.3.3.3.3a" xref="S4.p2.15.m15.3.3.3.3.3.3.cmml">−</mo><mrow id="S4.p2.15.m15.3.3.3.3.3.3.2" xref="S4.p2.15.m15.3.3.3.3.3.3.2.cmml"><msub id="S4.p2.15.m15.3.3.3.3.3.3.2.2" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2.cmml"><mi id="S4.p2.15.m15.3.3.3.3.3.3.2.2.2" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2.2.cmml">d</mi><mi id="S4.p2.15.m15.3.3.3.3.3.3.2.2.3" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2.3.cmml">z</mi></msub><mo id="S4.p2.15.m15.3.3.3.3.3.3.2.1" xref="S4.p2.15.m15.3.3.3.3.3.3.2.1.cmml">/</mo><mn id="S4.p2.15.m15.3.3.3.3.3.3.2.3" xref="S4.p2.15.m15.3.3.3.3.3.3.2.3.cmml">2</mn></mrow></mrow><mo stretchy="false" id="S4.p2.15.m15.3.3.3.3.3.7" xref="S4.p2.15.m15.3.3.3.3.4.cmml">]</mo></mrow><mi id="S4.p2.15.m15.3.3.3.5" xref="S4.p2.15.m15.3.3.3.5.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.15.m15.3b"><apply id="S4.p2.15.m15.3.3.cmml" xref="S4.p2.15.m15.3.3"><eq id="S4.p2.15.m15.3.3.4.cmml" xref="S4.p2.15.m15.3.3.4"></eq><apply id="S4.p2.15.m15.3.3.5.cmml" xref="S4.p2.15.m15.3.3.5"><csymbol cd="ambiguous" id="S4.p2.15.m15.3.3.5.1.cmml" xref="S4.p2.15.m15.3.3.5">superscript</csymbol><apply id="S4.p2.15.m15.3.3.5.2.cmml" xref="S4.p2.15.m15.3.3.5"><csymbol cd="ambiguous" id="S4.p2.15.m15.3.3.5.2.1.cmml" xref="S4.p2.15.m15.3.3.5">subscript</csymbol><ci id="S4.p2.15.m15.3.3.5.2.2.cmml" xref="S4.p2.15.m15.3.3.5.2.2">𝐗</ci><cn type="integer" id="S4.p2.15.m15.3.3.5.2.3.cmml" xref="S4.p2.15.m15.3.3.5.2.3">8</cn></apply><ci id="S4.p2.15.m15.3.3.5.3.cmml" xref="S4.p2.15.m15.3.3.5.3">𝑏</ci></apply><apply id="S4.p2.15.m15.3.3.3.cmml" xref="S4.p2.15.m15.3.3.3"><csymbol cd="ambiguous" id="S4.p2.15.m15.3.3.3.4.cmml" xref="S4.p2.15.m15.3.3.3">superscript</csymbol><list id="S4.p2.15.m15.3.3.3.3.4.cmml" xref="S4.p2.15.m15.3.3.3.3.3"><apply id="S4.p2.15.m15.1.1.1.1.1.1.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1"><minus id="S4.p2.15.m15.1.1.1.1.1.1.1.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1"></minus><apply id="S4.p2.15.m15.1.1.1.1.1.1.2.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2"><divide id="S4.p2.15.m15.1.1.1.1.1.1.2.1.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2.1"></divide><apply id="S4.p2.15.m15.1.1.1.1.1.1.2.2.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.p2.15.m15.1.1.1.1.1.1.2.2.1.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.p2.15.m15.1.1.1.1.1.1.2.2.2.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2.2">𝑑</ci><ci id="S4.p2.15.m15.1.1.1.1.1.1.2.2.3.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2.2.3">𝑥</ci></apply><cn type="integer" id="S4.p2.15.m15.1.1.1.1.1.1.2.3.cmml" xref="S4.p2.15.m15.1.1.1.1.1.1.2.3">2</cn></apply></apply><apply id="S4.p2.15.m15.2.2.2.2.2.2.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2"><minus id="S4.p2.15.m15.2.2.2.2.2.2.1.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2"></minus><apply id="S4.p2.15.m15.2.2.2.2.2.2.2.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2"><divide id="S4.p2.15.m15.2.2.2.2.2.2.2.1.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2.1"></divide><apply id="S4.p2.15.m15.2.2.2.2.2.2.2.2.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.p2.15.m15.2.2.2.2.2.2.2.2.1.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S4.p2.15.m15.2.2.2.2.2.2.2.2.2.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2.2">𝑑</ci><ci id="S4.p2.15.m15.2.2.2.2.2.2.2.2.3.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2.2.3">𝑦</ci></apply><cn type="integer" id="S4.p2.15.m15.2.2.2.2.2.2.2.3.cmml" xref="S4.p2.15.m15.2.2.2.2.2.2.2.3">2</cn></apply></apply><apply id="S4.p2.15.m15.3.3.3.3.3.3.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3"><minus id="S4.p2.15.m15.3.3.3.3.3.3.1.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3"></minus><apply id="S4.p2.15.m15.3.3.3.3.3.3.2.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2"><divide id="S4.p2.15.m15.3.3.3.3.3.3.2.1.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2.1"></divide><apply id="S4.p2.15.m15.3.3.3.3.3.3.2.2.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2"><csymbol cd="ambiguous" id="S4.p2.15.m15.3.3.3.3.3.3.2.2.1.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2">subscript</csymbol><ci id="S4.p2.15.m15.3.3.3.3.3.3.2.2.2.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2.2">𝑑</ci><ci id="S4.p2.15.m15.3.3.3.3.3.3.2.2.3.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2.2.3">𝑧</ci></apply><cn type="integer" id="S4.p2.15.m15.3.3.3.3.3.3.2.3.cmml" xref="S4.p2.15.m15.3.3.3.3.3.3.2.3">2</cn></apply></apply></list><ci id="S4.p2.15.m15.3.3.3.5.cmml" xref="S4.p2.15.m15.3.3.3.5">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.15.m15.3c">{\bf X}_{8}^{b}=[-d_{x}/2,-d_{y}/2,-d_{z}/2]^{T}</annotation></semantics></math>. The example object coordinate space is shown in Figure <a href="#S3.F4" title="Figure 4 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>e.
In the last step, the PnP algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">13</a>]</cite> is used to estimate rotation and translation of the object’s 3D bounding-box from correspondences between the 2D image points and 3D points in the object coordinate frame. The result is shown in Figure <a href="#S3.F4" title="Figure 4 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:562.4pt;height:103.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.8pt,2.7pt) scale(0.95,0.95) ;">
<table id="S4.T1.6.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.6.1.1.1" class="ltx_tr">
<th id="S4.T1.6.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T1.6.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">bed</th>
<th id="S4.T1.6.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">chair</th>
<th id="S4.T1.6.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">desk</th>
<th id="S4.T1.6.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">table</th>
<th id="S4.T1.6.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">sofa</th>
<th id="S4.T1.6.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">wardrobe</th>
<th id="S4.T1.6.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">bookcase</th>
<th id="S4.T1.6.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">misc</th>
<th id="S4.T1.6.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">tool</th>
<th id="S4.T1.6.1.1.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">mean Azimuth</th>
<th id="S4.T1.6.1.1.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">mean Elevation</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.6.1.2.1" class="ltx_tr">
<td id="S4.T1.6.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt ltx_border_t">Baseline</td>
<td id="S4.T1.6.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">65.73</td>
<td id="S4.T1.6.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">50.73</td>
<td id="S4.T1.6.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">41.56</td>
<td id="S4.T1.6.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">51.08</td>
<td id="S4.T1.6.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">78.55</td>
<td id="S4.T1.6.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">77.78</td>
<td id="S4.T1.6.1.2.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">65.82</td>
<td id="S4.T1.6.1.2.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">20.00</td>
<td id="S4.T1.6.1.2.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">18.18</td>
<td id="S4.T1.6.1.2.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">56.72</td>
<td id="S4.T1.6.1.2.1.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">69.45</td>
</tr>
<tr id="S4.T1.6.1.3.2" class="ltx_tr">
<td id="S4.T1.6.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">ResNet_baseline</td>
<td id="S4.T1.6.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.08</td>
<td id="S4.T1.6.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.95</td>
<td id="S4.T1.6.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.65</td>
<td id="S4.T1.6.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">51.80</td>
<td id="S4.T1.6.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">81.20</td>
<td id="S4.T1.6.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.22</td>
<td id="S4.T1.6.1.3.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.09</td>
<td id="S4.T1.6.1.3.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.00</td>
<td id="S4.T1.6.1.3.2.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.27</td>
<td id="S4.T1.6.1.3.2.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.78</td>
<td id="S4.T1.6.1.3.2.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.25</td>
</tr>
<tr id="S4.T1.6.1.4.3" class="ltx_tr">
<td id="S4.T1.6.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Mousavian et al.</td>
<td id="S4.T1.6.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.83</td>
<td id="S4.T1.6.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.99</td>
<td id="S4.T1.6.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">51.30</td>
<td id="S4.T1.6.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.59</td>
<td id="S4.T1.6.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.96</td>
<td id="S4.T1.6.1.4.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.93</td>
<td id="S4.T1.6.1.4.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.35</td>
<td id="S4.T1.6.1.4.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.00</td>
<td id="S4.T1.6.1.4.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">18.18</td>
<td id="S4.T1.6.1.4.3.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.87</td>
<td id="S4.T1.6.1.4.3.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.81</td>
</tr>
<tr id="S4.T1.6.1.5.4" class="ltx_tr">
<td id="S4.T1.6.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Ours_phase1</td>
<td id="S4.T1.6.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.12</td>
<td id="S4.T1.6.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.61</td>
<td id="S4.T1.6.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.1.5.4.4.1" class="ltx_text ltx_font_bold">62.34</span></td>
<td id="S4.T1.6.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.43</td>
<td id="S4.T1.6.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.1.5.4.6.1" class="ltx_text ltx_font_bold">88.19</span></td>
<td id="S4.T1.6.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.1.5.4.7.1" class="ltx_text ltx_font_bold">94.44</span></td>
<td id="S4.T1.6.1.5.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.1.5.4.8.1" class="ltx_text ltx_font_bold">84.81</span></td>
<td id="S4.T1.6.1.5.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.1.5.4.9.1" class="ltx_text ltx_font_bold">40.00</span></td>
<td id="S4.T1.6.1.5.4.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.27</td>
<td id="S4.T1.6.1.5.4.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.21</td>
<td id="S4.T1.6.1.5.4.12" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.6.1.5.4.12.1" class="ltx_text ltx_font_bold">76.08</span></td>
</tr>
<tr id="S4.T1.6.1.6.5" class="ltx_tr">
<td id="S4.T1.6.1.6.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Ours</td>
<td id="S4.T1.6.1.6.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.6.1.6.5.2.1" class="ltx_text ltx_font_bold">77.93</span></td>
<td id="S4.T1.6.1.6.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.6.1.6.5.3.1" class="ltx_text ltx_font_bold">74.55</span></td>
<td id="S4.T1.6.1.6.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">59.09</td>
<td id="S4.T1.6.1.6.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.6.1.6.5.5.1" class="ltx_text ltx_font_bold">61.39</span></td>
<td id="S4.T1.6.1.6.5.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">85.06</td>
<td id="S4.T1.6.1.6.5.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">90.74</td>
<td id="S4.T1.6.1.6.5.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">83.54</td>
<td id="S4.T1.6.1.6.5.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">30.00</td>
<td id="S4.T1.6.1.6.5.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.6.1.6.5.10.1" class="ltx_text ltx_font_bold">36.36</span></td>
<td id="S4.T1.6.1.6.5.11" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.6.1.6.5.11.1" class="ltx_text ltx_font_bold">73.56</span></td>
<td id="S4.T1.6.1.6.5.12" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.6.1.6.5.12.1" class="ltx_text ltx_font_bold">76.08</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.7.3.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S4.T1.4.2" class="ltx_text" style="font-size:90%;">The azimuth classification accuracy for <math id="S4.T1.3.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S4.T1.3.1.m1.1b"><mn id="S4.T1.3.1.m1.1.1" xref="S4.T1.3.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.m1.1c"><cn type="integer" id="S4.T1.3.1.m1.1.1.cmml" xref="S4.T1.3.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.m1.1d">9</annotation></semantics></math> bins with <math id="S4.T1.4.2.m2.1" class="ltx_Math" alttext="2.5^{\circ}" display="inline"><semantics id="S4.T1.4.2.m2.1b"><msup id="S4.T1.4.2.m2.1.1" xref="S4.T1.4.2.m2.1.1.cmml"><mn id="S4.T1.4.2.m2.1.1.2" xref="S4.T1.4.2.m2.1.1.2.cmml">2.5</mn><mo id="S4.T1.4.2.m2.1.1.3" xref="S4.T1.4.2.m2.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.m2.1c"><apply id="S4.T1.4.2.m2.1.1.cmml" xref="S4.T1.4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.T1.4.2.m2.1.1.1.cmml" xref="S4.T1.4.2.m2.1.1">superscript</csymbol><cn type="float" id="S4.T1.4.2.m2.1.1.2.cmml" xref="S4.T1.4.2.m2.1.1.2">2.5</cn><compose id="S4.T1.4.2.m2.1.1.3.cmml" xref="S4.T1.4.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.m2.1d">2.5^{\circ}</annotation></semantics></math> overlap. Models are all trained category agnostic. </span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We train and evaluate the proposed pose estimation approach on the Pix3D dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite> comparing it to the state-of-the-art approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>, <a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite> and some baseline methods. We then directly evaluate it without any additional training or fine-tuning on the challenging AVD dataset<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">1</a>]</cite> to see the generalizability of the approach. Code is also available at <a target="_blank" href="https://github.com/N-NEJATISHAHIDIN/Pose_from_Mid-level" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/N-NEJATISHAHIDIN/Pose_from_Mid-level</a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Training</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.6" class="ltx_p">We use frozen mid-level-representation features as the input to our model,
and set the learning rate to <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="float" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">0.001</annotation></semantics></math> with a step size of <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn type="integer" id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">3</annotation></semantics></math>. All the models are trained for <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><mn id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><cn type="integer" id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">10</annotation></semantics></math> epochs with early stopping. The first phase is trained with <span id="S5.SS1.p1.6.1" class="ltx_text ltx_font_italic">cross-entropy</span> loss, where azimuth <math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><mi id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><ci id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">\theta</annotation></semantics></math> and elevation <math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><mi id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><ci id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">\phi</annotation></semantics></math> are the logits over the number of bins with
<math id="S5.SS1.p1.6.m6.2" class="ltx_Math" alttext="L_{\theta,\phi}=L_{\theta}+L_{\phi}" display="inline"><semantics id="S5.SS1.p1.6.m6.2a"><mrow id="S5.SS1.p1.6.m6.2.3" xref="S5.SS1.p1.6.m6.2.3.cmml"><msub id="S5.SS1.p1.6.m6.2.3.2" xref="S5.SS1.p1.6.m6.2.3.2.cmml"><mi id="S5.SS1.p1.6.m6.2.3.2.2" xref="S5.SS1.p1.6.m6.2.3.2.2.cmml">L</mi><mrow id="S5.SS1.p1.6.m6.2.2.2.4" xref="S5.SS1.p1.6.m6.2.2.2.3.cmml"><mi id="S5.SS1.p1.6.m6.1.1.1.1" xref="S5.SS1.p1.6.m6.1.1.1.1.cmml">θ</mi><mo id="S5.SS1.p1.6.m6.2.2.2.4.1" xref="S5.SS1.p1.6.m6.2.2.2.3.cmml">,</mo><mi id="S5.SS1.p1.6.m6.2.2.2.2" xref="S5.SS1.p1.6.m6.2.2.2.2.cmml">ϕ</mi></mrow></msub><mo id="S5.SS1.p1.6.m6.2.3.1" xref="S5.SS1.p1.6.m6.2.3.1.cmml">=</mo><mrow id="S5.SS1.p1.6.m6.2.3.3" xref="S5.SS1.p1.6.m6.2.3.3.cmml"><msub id="S5.SS1.p1.6.m6.2.3.3.2" xref="S5.SS1.p1.6.m6.2.3.3.2.cmml"><mi id="S5.SS1.p1.6.m6.2.3.3.2.2" xref="S5.SS1.p1.6.m6.2.3.3.2.2.cmml">L</mi><mi id="S5.SS1.p1.6.m6.2.3.3.2.3" xref="S5.SS1.p1.6.m6.2.3.3.2.3.cmml">θ</mi></msub><mo id="S5.SS1.p1.6.m6.2.3.3.1" xref="S5.SS1.p1.6.m6.2.3.3.1.cmml">+</mo><msub id="S5.SS1.p1.6.m6.2.3.3.3" xref="S5.SS1.p1.6.m6.2.3.3.3.cmml"><mi id="S5.SS1.p1.6.m6.2.3.3.3.2" xref="S5.SS1.p1.6.m6.2.3.3.3.2.cmml">L</mi><mi id="S5.SS1.p1.6.m6.2.3.3.3.3" xref="S5.SS1.p1.6.m6.2.3.3.3.3.cmml">ϕ</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.2b"><apply id="S5.SS1.p1.6.m6.2.3.cmml" xref="S5.SS1.p1.6.m6.2.3"><eq id="S5.SS1.p1.6.m6.2.3.1.cmml" xref="S5.SS1.p1.6.m6.2.3.1"></eq><apply id="S5.SS1.p1.6.m6.2.3.2.cmml" xref="S5.SS1.p1.6.m6.2.3.2"><csymbol cd="ambiguous" id="S5.SS1.p1.6.m6.2.3.2.1.cmml" xref="S5.SS1.p1.6.m6.2.3.2">subscript</csymbol><ci id="S5.SS1.p1.6.m6.2.3.2.2.cmml" xref="S5.SS1.p1.6.m6.2.3.2.2">𝐿</ci><list id="S5.SS1.p1.6.m6.2.2.2.3.cmml" xref="S5.SS1.p1.6.m6.2.2.2.4"><ci id="S5.SS1.p1.6.m6.1.1.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1.1.1">𝜃</ci><ci id="S5.SS1.p1.6.m6.2.2.2.2.cmml" xref="S5.SS1.p1.6.m6.2.2.2.2">italic-ϕ</ci></list></apply><apply id="S5.SS1.p1.6.m6.2.3.3.cmml" xref="S5.SS1.p1.6.m6.2.3.3"><plus id="S5.SS1.p1.6.m6.2.3.3.1.cmml" xref="S5.SS1.p1.6.m6.2.3.3.1"></plus><apply id="S5.SS1.p1.6.m6.2.3.3.2.cmml" xref="S5.SS1.p1.6.m6.2.3.3.2"><csymbol cd="ambiguous" id="S5.SS1.p1.6.m6.2.3.3.2.1.cmml" xref="S5.SS1.p1.6.m6.2.3.3.2">subscript</csymbol><ci id="S5.SS1.p1.6.m6.2.3.3.2.2.cmml" xref="S5.SS1.p1.6.m6.2.3.3.2.2">𝐿</ci><ci id="S5.SS1.p1.6.m6.2.3.3.2.3.cmml" xref="S5.SS1.p1.6.m6.2.3.3.2.3">𝜃</ci></apply><apply id="S5.SS1.p1.6.m6.2.3.3.3.cmml" xref="S5.SS1.p1.6.m6.2.3.3.3"><csymbol cd="ambiguous" id="S5.SS1.p1.6.m6.2.3.3.3.1.cmml" xref="S5.SS1.p1.6.m6.2.3.3.3">subscript</csymbol><ci id="S5.SS1.p1.6.m6.2.3.3.3.2.cmml" xref="S5.SS1.p1.6.m6.2.3.3.3.2">𝐿</ci><ci id="S5.SS1.p1.6.m6.2.3.3.3.3.cmml" xref="S5.SS1.p1.6.m6.2.3.3.3.3">italic-ϕ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.2c">L_{\theta,\phi}=L_{\theta}+L_{\phi}</annotation></semantics></math>
The second phase is trained with binary cross entropy loss (BCE) between the target and the output logits.</p>
<table id="S5.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.Ex2.m1.5" class="ltx_Math" alttext="L_{mask}=-\frac{1}{n}\sum_{i=0}^{n}y_{i}^{*}\cdot\log\left(y_{i}\right)+\left(1-y_{i}^{*}\right)\cdot\log\left(1-{y}_{i}\right)" display="block"><semantics id="S5.Ex2.m1.5a"><mrow id="S5.Ex2.m1.5.5" xref="S5.Ex2.m1.5.5.cmml"><msub id="S5.Ex2.m1.5.5.5" xref="S5.Ex2.m1.5.5.5.cmml"><mi id="S5.Ex2.m1.5.5.5.2" xref="S5.Ex2.m1.5.5.5.2.cmml">L</mi><mrow id="S5.Ex2.m1.5.5.5.3" xref="S5.Ex2.m1.5.5.5.3.cmml"><mi id="S5.Ex2.m1.5.5.5.3.2" xref="S5.Ex2.m1.5.5.5.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.5.5.5.3.1" xref="S5.Ex2.m1.5.5.5.3.1.cmml">​</mo><mi id="S5.Ex2.m1.5.5.5.3.3" xref="S5.Ex2.m1.5.5.5.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.5.5.5.3.1a" xref="S5.Ex2.m1.5.5.5.3.1.cmml">​</mo><mi id="S5.Ex2.m1.5.5.5.3.4" xref="S5.Ex2.m1.5.5.5.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.5.5.5.3.1b" xref="S5.Ex2.m1.5.5.5.3.1.cmml">​</mo><mi id="S5.Ex2.m1.5.5.5.3.5" xref="S5.Ex2.m1.5.5.5.3.5.cmml">k</mi></mrow></msub><mo id="S5.Ex2.m1.5.5.4" xref="S5.Ex2.m1.5.5.4.cmml">=</mo><mrow id="S5.Ex2.m1.5.5.3" xref="S5.Ex2.m1.5.5.3.cmml"><mrow id="S5.Ex2.m1.3.3.1.1" xref="S5.Ex2.m1.3.3.1.1.cmml"><mo id="S5.Ex2.m1.3.3.1.1a" xref="S5.Ex2.m1.3.3.1.1.cmml">−</mo><mrow id="S5.Ex2.m1.3.3.1.1.1" xref="S5.Ex2.m1.3.3.1.1.1.cmml"><mfrac id="S5.Ex2.m1.3.3.1.1.1.3" xref="S5.Ex2.m1.3.3.1.1.1.3.cmml"><mn id="S5.Ex2.m1.3.3.1.1.1.3.2" xref="S5.Ex2.m1.3.3.1.1.1.3.2.cmml">1</mn><mi id="S5.Ex2.m1.3.3.1.1.1.3.3" xref="S5.Ex2.m1.3.3.1.1.1.3.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S5.Ex2.m1.3.3.1.1.1.2" xref="S5.Ex2.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="S5.Ex2.m1.3.3.1.1.1.1" xref="S5.Ex2.m1.3.3.1.1.1.1.cmml"><munderover id="S5.Ex2.m1.3.3.1.1.1.1.2" xref="S5.Ex2.m1.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" id="S5.Ex2.m1.3.3.1.1.1.1.2.2.2" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.cmml"><mi id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.2" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.1" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.3" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.3.cmml">0</mn></mrow><mi id="S5.Ex2.m1.3.3.1.1.1.1.2.3" xref="S5.Ex2.m1.3.3.1.1.1.1.2.3.cmml">n</mi></munderover><mrow id="S5.Ex2.m1.3.3.1.1.1.1.1" xref="S5.Ex2.m1.3.3.1.1.1.1.1.cmml"><msubsup id="S5.Ex2.m1.3.3.1.1.1.1.1.3" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.2" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.2.cmml">y</mi><mi id="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.3" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.3.cmml">i</mi><mo id="S5.Ex2.m1.3.3.1.1.1.1.1.3.3" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.3.cmml">∗</mo></msubsup><mo lspace="0.222em" rspace="0.222em" id="S5.Ex2.m1.3.3.1.1.1.1.1.2" xref="S5.Ex2.m1.3.3.1.1.1.1.1.2.cmml">⋅</mo><mrow id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml"><mi id="S5.Ex2.m1.1.1" xref="S5.Ex2.m1.1.1.cmml">log</mi><mo id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1a" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml">⁡</mo><mrow id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml"><mo id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml">(</mo><msub id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml"><mi id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml">y</mi><mi id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S5.Ex2.m1.5.5.3.4" xref="S5.Ex2.m1.5.5.3.4.cmml">+</mo><mrow id="S5.Ex2.m1.5.5.3.3" xref="S5.Ex2.m1.5.5.3.3.cmml"><mrow id="S5.Ex2.m1.4.4.2.2.1.1" xref="S5.Ex2.m1.4.4.2.2.1.1.1.cmml"><mo id="S5.Ex2.m1.4.4.2.2.1.1.2" xref="S5.Ex2.m1.4.4.2.2.1.1.1.cmml">(</mo><mrow id="S5.Ex2.m1.4.4.2.2.1.1.1" xref="S5.Ex2.m1.4.4.2.2.1.1.1.cmml"><mn id="S5.Ex2.m1.4.4.2.2.1.1.1.2" xref="S5.Ex2.m1.4.4.2.2.1.1.1.2.cmml">1</mn><mo id="S5.Ex2.m1.4.4.2.2.1.1.1.1" xref="S5.Ex2.m1.4.4.2.2.1.1.1.1.cmml">−</mo><msubsup id="S5.Ex2.m1.4.4.2.2.1.1.1.3" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.cmml"><mi id="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.2" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.2.cmml">y</mi><mi id="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.3" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.3.cmml">i</mi><mo id="S5.Ex2.m1.4.4.2.2.1.1.1.3.3" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.3.cmml">∗</mo></msubsup></mrow><mo rspace="0.055em" id="S5.Ex2.m1.4.4.2.2.1.1.3" xref="S5.Ex2.m1.4.4.2.2.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S5.Ex2.m1.5.5.3.3.3" xref="S5.Ex2.m1.5.5.3.3.3.cmml">⋅</mo><mrow id="S5.Ex2.m1.5.5.3.3.2.1" xref="S5.Ex2.m1.5.5.3.3.2.2.cmml"><mi id="S5.Ex2.m1.2.2" xref="S5.Ex2.m1.2.2.cmml">log</mi><mo id="S5.Ex2.m1.5.5.3.3.2.1a" xref="S5.Ex2.m1.5.5.3.3.2.2.cmml">⁡</mo><mrow id="S5.Ex2.m1.5.5.3.3.2.1.1" xref="S5.Ex2.m1.5.5.3.3.2.2.cmml"><mo id="S5.Ex2.m1.5.5.3.3.2.1.1.2" xref="S5.Ex2.m1.5.5.3.3.2.2.cmml">(</mo><mrow id="S5.Ex2.m1.5.5.3.3.2.1.1.1" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.cmml"><mn id="S5.Ex2.m1.5.5.3.3.2.1.1.1.2" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.2.cmml">1</mn><mo id="S5.Ex2.m1.5.5.3.3.2.1.1.1.1" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.1.cmml">−</mo><msub id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.cmml"><mi id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.2" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.2.cmml">y</mi><mi id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.3" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="S5.Ex2.m1.5.5.3.3.2.1.1.3" xref="S5.Ex2.m1.5.5.3.3.2.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex2.m1.5b"><apply id="S5.Ex2.m1.5.5.cmml" xref="S5.Ex2.m1.5.5"><eq id="S5.Ex2.m1.5.5.4.cmml" xref="S5.Ex2.m1.5.5.4"></eq><apply id="S5.Ex2.m1.5.5.5.cmml" xref="S5.Ex2.m1.5.5.5"><csymbol cd="ambiguous" id="S5.Ex2.m1.5.5.5.1.cmml" xref="S5.Ex2.m1.5.5.5">subscript</csymbol><ci id="S5.Ex2.m1.5.5.5.2.cmml" xref="S5.Ex2.m1.5.5.5.2">𝐿</ci><apply id="S5.Ex2.m1.5.5.5.3.cmml" xref="S5.Ex2.m1.5.5.5.3"><times id="S5.Ex2.m1.5.5.5.3.1.cmml" xref="S5.Ex2.m1.5.5.5.3.1"></times><ci id="S5.Ex2.m1.5.5.5.3.2.cmml" xref="S5.Ex2.m1.5.5.5.3.2">𝑚</ci><ci id="S5.Ex2.m1.5.5.5.3.3.cmml" xref="S5.Ex2.m1.5.5.5.3.3">𝑎</ci><ci id="S5.Ex2.m1.5.5.5.3.4.cmml" xref="S5.Ex2.m1.5.5.5.3.4">𝑠</ci><ci id="S5.Ex2.m1.5.5.5.3.5.cmml" xref="S5.Ex2.m1.5.5.5.3.5">𝑘</ci></apply></apply><apply id="S5.Ex2.m1.5.5.3.cmml" xref="S5.Ex2.m1.5.5.3"><plus id="S5.Ex2.m1.5.5.3.4.cmml" xref="S5.Ex2.m1.5.5.3.4"></plus><apply id="S5.Ex2.m1.3.3.1.1.cmml" xref="S5.Ex2.m1.3.3.1.1"><minus id="S5.Ex2.m1.3.3.1.1.2.cmml" xref="S5.Ex2.m1.3.3.1.1"></minus><apply id="S5.Ex2.m1.3.3.1.1.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1"><times id="S5.Ex2.m1.3.3.1.1.1.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.2"></times><apply id="S5.Ex2.m1.3.3.1.1.1.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.3"><divide id="S5.Ex2.m1.3.3.1.1.1.3.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.3"></divide><cn type="integer" id="S5.Ex2.m1.3.3.1.1.1.3.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.3.2">1</cn><ci id="S5.Ex2.m1.3.3.1.1.1.3.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.3.3">𝑛</ci></apply><apply id="S5.Ex2.m1.3.3.1.1.1.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1"><apply id="S5.Ex2.m1.3.3.1.1.1.1.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.Ex2.m1.3.3.1.1.1.1.2.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2">superscript</csymbol><apply id="S5.Ex2.m1.3.3.1.1.1.1.2.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.Ex2.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S5.Ex2.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.2"></sum><apply id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3"><eq id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.1"></eq><ci id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2.2.3.3">0</cn></apply></apply><ci id="S5.Ex2.m1.3.3.1.1.1.1.2.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.Ex2.m1.3.3.1.1.1.1.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1"><ci id="S5.Ex2.m1.3.3.1.1.1.1.1.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.2">⋅</ci><apply id="S5.Ex2.m1.3.3.1.1.1.1.1.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex2.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3">superscript</csymbol><apply id="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.2">𝑦</ci><ci id="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.2.3">𝑖</ci></apply><times id="S5.Ex2.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.3.3"></times></apply><apply id="S5.Ex2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1"><log id="S5.Ex2.m1.1.1.cmml" xref="S5.Ex2.m1.1.1"></log><apply id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.2">𝑦</ci><ci id="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.Ex2.m1.3.3.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></apply></apply><apply id="S5.Ex2.m1.5.5.3.3.cmml" xref="S5.Ex2.m1.5.5.3.3"><ci id="S5.Ex2.m1.5.5.3.3.3.cmml" xref="S5.Ex2.m1.5.5.3.3.3">⋅</ci><apply id="S5.Ex2.m1.4.4.2.2.1.1.1.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1"><minus id="S5.Ex2.m1.4.4.2.2.1.1.1.1.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.1"></minus><cn type="integer" id="S5.Ex2.m1.4.4.2.2.1.1.1.2.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.2">1</cn><apply id="S5.Ex2.m1.4.4.2.2.1.1.1.3.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex2.m1.4.4.2.2.1.1.1.3.1.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3">superscript</csymbol><apply id="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.1.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3">subscript</csymbol><ci id="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.2.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.2">𝑦</ci><ci id="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.3.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.2.3">𝑖</ci></apply><times id="S5.Ex2.m1.4.4.2.2.1.1.1.3.3.cmml" xref="S5.Ex2.m1.4.4.2.2.1.1.1.3.3"></times></apply></apply><apply id="S5.Ex2.m1.5.5.3.3.2.2.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1"><log id="S5.Ex2.m1.2.2.cmml" xref="S5.Ex2.m1.2.2"></log><apply id="S5.Ex2.m1.5.5.3.3.2.1.1.1.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1"><minus id="S5.Ex2.m1.5.5.3.3.2.1.1.1.1.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.1"></minus><cn type="integer" id="S5.Ex2.m1.5.5.3.3.2.1.1.1.2.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.2">1</cn><apply id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.1.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3">subscript</csymbol><ci id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.2.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.2">𝑦</ci><ci id="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.3.cmml" xref="S5.Ex2.m1.5.5.3.3.2.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex2.m1.5c">L_{mask}=-\frac{1}{n}\sum_{i=0}^{n}y_{i}^{*}\cdot\log\left(y_{i}\right)+\left(1-y_{i}^{*}\right)\cdot\log\left(1-{y}_{i}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S5.SS1.p1.9" class="ltx_p">where <math id="S5.SS1.p1.7.m1.1" class="ltx_Math" alttext="y_{i}^{*}=1" display="inline"><semantics id="S5.SS1.p1.7.m1.1a"><mrow id="S5.SS1.p1.7.m1.1.1" xref="S5.SS1.p1.7.m1.1.1.cmml"><msubsup id="S5.SS1.p1.7.m1.1.1.2" xref="S5.SS1.p1.7.m1.1.1.2.cmml"><mi id="S5.SS1.p1.7.m1.1.1.2.2.2" xref="S5.SS1.p1.7.m1.1.1.2.2.2.cmml">y</mi><mi id="S5.SS1.p1.7.m1.1.1.2.2.3" xref="S5.SS1.p1.7.m1.1.1.2.2.3.cmml">i</mi><mo id="S5.SS1.p1.7.m1.1.1.2.3" xref="S5.SS1.p1.7.m1.1.1.2.3.cmml">∗</mo></msubsup><mo id="S5.SS1.p1.7.m1.1.1.1" xref="S5.SS1.p1.7.m1.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.7.m1.1.1.3" xref="S5.SS1.p1.7.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m1.1b"><apply id="S5.SS1.p1.7.m1.1.1.cmml" xref="S5.SS1.p1.7.m1.1.1"><eq id="S5.SS1.p1.7.m1.1.1.1.cmml" xref="S5.SS1.p1.7.m1.1.1.1"></eq><apply id="S5.SS1.p1.7.m1.1.1.2.cmml" xref="S5.SS1.p1.7.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p1.7.m1.1.1.2.1.cmml" xref="S5.SS1.p1.7.m1.1.1.2">superscript</csymbol><apply id="S5.SS1.p1.7.m1.1.1.2.2.cmml" xref="S5.SS1.p1.7.m1.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p1.7.m1.1.1.2.2.1.cmml" xref="S5.SS1.p1.7.m1.1.1.2">subscript</csymbol><ci id="S5.SS1.p1.7.m1.1.1.2.2.2.cmml" xref="S5.SS1.p1.7.m1.1.1.2.2.2">𝑦</ci><ci id="S5.SS1.p1.7.m1.1.1.2.2.3.cmml" xref="S5.SS1.p1.7.m1.1.1.2.2.3">𝑖</ci></apply><times id="S5.SS1.p1.7.m1.1.1.2.3.cmml" xref="S5.SS1.p1.7.m1.1.1.2.3"></times></apply><cn type="integer" id="S5.SS1.p1.7.m1.1.1.3.cmml" xref="S5.SS1.p1.7.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m1.1c">y_{i}^{*}=1</annotation></semantics></math> when the chosen
D-mask is from the ground truth bin.
Since Pix3D does not provide a train/test split, we use widely adopted Mesh R-CNN split S1. Split S1 randomly allocates <math id="S5.SS1.p1.8.m2.1" class="ltx_Math" alttext="7539" display="inline"><semantics id="S5.SS1.p1.8.m2.1a"><mn id="S5.SS1.p1.8.m2.1.1" xref="S5.SS1.p1.8.m2.1.1.cmml">7539</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.8.m2.1b"><cn type="integer" id="S5.SS1.p1.8.m2.1.1.cmml" xref="S5.SS1.p1.8.m2.1.1">7539</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.8.m2.1c">7539</annotation></semantics></math> images for training and <math id="S5.SS1.p1.9.m3.1" class="ltx_Math" alttext="2530" display="inline"><semantics id="S5.SS1.p1.9.m3.1a"><mn id="S5.SS1.p1.9.m3.1.1" xref="S5.SS1.p1.9.m3.1.1.cmml">2530</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.9.m3.1b"><cn type="integer" id="S5.SS1.p1.9.m3.1.1.cmml" xref="S5.SS1.p1.9.m3.1.1">2530</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.9.m3.1c">2530</annotation></semantics></math> for testing. The model is trained in the category agnostic level,
<span id="S5.SS1.p1.9.1" class="ltx_text ltx_font_italic">i.e.</span> we have only a single model for all categories.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Testing</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.5" class="ltx_p">For every test image, we find the nearest CAD model using template matching from OpenCV. To find the nearest CAD model, we use the predicted-mask of the image and compare it with the training predicted-masks of the images from the same category. To be more robust and scale-invariant, we compare each mask at different scales. See sample results are in Figure <a href="#S5.F6" title="Figure 6 ‣ V-B Testing ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
As discussed in Section <a href="#S3.SS3" title="III-C Model ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>, we use the top three pose candidate bins from stage one along with their probability. At testing time, we run binary classification between each of the top three candidate poses D-masks and the predicted_mask from the image. If the predicted_mask and D_mask are in the same bin, stage two output is a positive match. In case of more than one positive output, we choose the bin which maximizes the <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="\max_{\forall i\in C_{pose}}{\hat{Y}_{i}P_{phase1}({i})}" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.2" xref="S5.SS2.p1.1.m1.1.2.cmml"><mrow id="S5.SS2.p1.1.m1.1.2.2" xref="S5.SS2.p1.1.m1.1.2.2.cmml"><msub id="S5.SS2.p1.1.m1.1.2.2.1" xref="S5.SS2.p1.1.m1.1.2.2.1.cmml"><mi id="S5.SS2.p1.1.m1.1.2.2.1.2" xref="S5.SS2.p1.1.m1.1.2.2.1.2.cmml">max</mi><mrow id="S5.SS2.p1.1.m1.1.2.2.1.3" xref="S5.SS2.p1.1.m1.1.2.2.1.3.cmml"><mrow id="S5.SS2.p1.1.m1.1.2.2.1.3.2" xref="S5.SS2.p1.1.m1.1.2.2.1.3.2.cmml"><mo rspace="0.167em" id="S5.SS2.p1.1.m1.1.2.2.1.3.2.1" xref="S5.SS2.p1.1.m1.1.2.2.1.3.2.1.cmml">∀</mo><mi id="S5.SS2.p1.1.m1.1.2.2.1.3.2.2" xref="S5.SS2.p1.1.m1.1.2.2.1.3.2.2.cmml">i</mi></mrow><mo id="S5.SS2.p1.1.m1.1.2.2.1.3.1" xref="S5.SS2.p1.1.m1.1.2.2.1.3.1.cmml">∈</mo><msub id="S5.SS2.p1.1.m1.1.2.2.1.3.3" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.cmml"><mi id="S5.SS2.p1.1.m1.1.2.2.1.3.3.2" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.2.cmml">C</mi><mrow id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.cmml"><mi id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.2" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.3" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1a" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.4" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1b" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.5" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.5.cmml">e</mi></mrow></msub></mrow></msub><mo lspace="0.167em" id="S5.SS2.p1.1.m1.1.2.2a" xref="S5.SS2.p1.1.m1.1.2.2.cmml">⁡</mo><mrow id="S5.SS2.p1.1.m1.1.2.2.2" xref="S5.SS2.p1.1.m1.1.2.2.2.cmml"><msub id="S5.SS2.p1.1.m1.1.2.2.2.2" xref="S5.SS2.p1.1.m1.1.2.2.2.2.cmml"><mover accent="true" id="S5.SS2.p1.1.m1.1.2.2.2.2.2" xref="S5.SS2.p1.1.m1.1.2.2.2.2.2.cmml"><mi id="S5.SS2.p1.1.m1.1.2.2.2.2.2.2" xref="S5.SS2.p1.1.m1.1.2.2.2.2.2.2.cmml">Y</mi><mo id="S5.SS2.p1.1.m1.1.2.2.2.2.2.1" xref="S5.SS2.p1.1.m1.1.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S5.SS2.p1.1.m1.1.2.2.2.2.3" xref="S5.SS2.p1.1.m1.1.2.2.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.2.1" xref="S5.SS2.p1.1.m1.1.2.2.2.1.cmml">​</mo><msub id="S5.SS2.p1.1.m1.1.2.2.2.3" xref="S5.SS2.p1.1.m1.1.2.2.2.3.cmml"><mi id="S5.SS2.p1.1.m1.1.2.2.2.3.2" xref="S5.SS2.p1.1.m1.1.2.2.2.3.2.cmml">P</mi><mrow id="S5.SS2.p1.1.m1.1.2.2.2.3.3" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.cmml"><mi id="S5.SS2.p1.1.m1.1.2.2.2.3.3.2" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.2.3.3.1" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.2.3.3.3" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.2.3.3.1a" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.2.3.3.4" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.2.3.3.1b" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.2.3.3.5" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.2.3.3.1c" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.1.cmml">​</mo><mi id="S5.SS2.p1.1.m1.1.2.2.2.3.3.6" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.2.2.3.3.1d" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.1.cmml">​</mo><mn id="S5.SS2.p1.1.m1.1.2.2.2.3.3.7" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.7.cmml">1</mn></mrow></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S5.SS2.p1.1.m1.1.2.1" xref="S5.SS2.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S5.SS2.p1.1.m1.1.2.3.2" xref="S5.SS2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S5.SS2.p1.1.m1.1.2.3.2.1" xref="S5.SS2.p1.1.m1.1.2.cmml">(</mo><mi id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S5.SS2.p1.1.m1.1.2.3.2.2" xref="S5.SS2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.2"><times id="S5.SS2.p1.1.m1.1.2.1.cmml" xref="S5.SS2.p1.1.m1.1.2.1"></times><apply id="S5.SS2.p1.1.m1.1.2.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2"><apply id="S5.SS2.p1.1.m1.1.2.2.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.2.2.1.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1">subscript</csymbol><max id="S5.SS2.p1.1.m1.1.2.2.1.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.2"></max><apply id="S5.SS2.p1.1.m1.1.2.2.1.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3"><in id="S5.SS2.p1.1.m1.1.2.2.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.1"></in><apply id="S5.SS2.p1.1.m1.1.2.2.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.2"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.2.2.1.3.2.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.2.1">for-all</csymbol><ci id="S5.SS2.p1.1.m1.1.2.2.1.3.2.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.2.2">𝑖</ci></apply><apply id="S5.SS2.p1.1.m1.1.2.2.1.3.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.2.2.1.3.3.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.2.2.1.3.3.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.2">𝐶</ci><apply id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3"><times id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.1"></times><ci id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.2">𝑝</ci><ci id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.3">𝑜</ci><ci id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.4.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.4">𝑠</ci><ci id="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.5.cmml" xref="S5.SS2.p1.1.m1.1.2.2.1.3.3.3.5">𝑒</ci></apply></apply></apply></apply><apply id="S5.SS2.p1.1.m1.1.2.2.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2"><times id="S5.SS2.p1.1.m1.1.2.2.2.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.1"></times><apply id="S5.SS2.p1.1.m1.1.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.2.2.2.2.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.2">subscript</csymbol><apply id="S5.SS2.p1.1.m1.1.2.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.2.2"><ci id="S5.SS2.p1.1.m1.1.2.2.2.2.2.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.2.2.1">^</ci><ci id="S5.SS2.p1.1.m1.1.2.2.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.2.2.2">𝑌</ci></apply><ci id="S5.SS2.p1.1.m1.1.2.2.2.2.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.2.3">𝑖</ci></apply><apply id="S5.SS2.p1.1.m1.1.2.2.2.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.2.2.2.3.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.2.2.2.3.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.2">𝑃</ci><apply id="S5.SS2.p1.1.m1.1.2.2.2.3.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3"><times id="S5.SS2.p1.1.m1.1.2.2.2.3.3.1.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.1"></times><ci id="S5.SS2.p1.1.m1.1.2.2.2.3.3.2.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.2">𝑝</ci><ci id="S5.SS2.p1.1.m1.1.2.2.2.3.3.3.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.3">ℎ</ci><ci id="S5.SS2.p1.1.m1.1.2.2.2.3.3.4.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.4">𝑎</ci><ci id="S5.SS2.p1.1.m1.1.2.2.2.3.3.5.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.5">𝑠</ci><ci id="S5.SS2.p1.1.m1.1.2.2.2.3.3.6.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.6">𝑒</ci><cn type="integer" id="S5.SS2.p1.1.m1.1.2.2.2.3.3.7.cmml" xref="S5.SS2.p1.1.m1.1.2.2.2.3.3.7">1</cn></apply></apply></apply></apply><ci id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\max_{\forall i\in C_{pose}}{\hat{Y}_{i}P_{phase1}({i})}</annotation></semantics></math>, where <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="C_{pose}" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><msub id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">C</mi><mrow id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml"><mi id="S5.SS2.p1.2.m2.1.1.3.2" xref="S5.SS2.p1.2.m2.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.2.m2.1.1.3.1" xref="S5.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.p1.2.m2.1.1.3.3" xref="S5.SS2.p1.2.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.2.m2.1.1.3.1a" xref="S5.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.p1.2.m2.1.1.3.4" xref="S5.SS2.p1.2.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.2.m2.1.1.3.1b" xref="S5.SS2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S5.SS2.p1.2.m2.1.1.3.5" xref="S5.SS2.p1.2.m2.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">𝐶</ci><apply id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3"><times id="S5.SS2.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2.p1.2.m2.1.1.3.1"></times><ci id="S5.SS2.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2.p1.2.m2.1.1.3.2">𝑝</ci><ci id="S5.SS2.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3.3">𝑜</ci><ci id="S5.SS2.p1.2.m2.1.1.3.4.cmml" xref="S5.SS2.p1.2.m2.1.1.3.4">𝑠</ci><ci id="S5.SS2.p1.2.m2.1.1.3.5.cmml" xref="S5.SS2.p1.2.m2.1.1.3.5">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">C_{pose}</annotation></semantics></math> is the set of three candidate poses from phase one, the <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="\hat{Y}_{i}" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><msub id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mover accent="true" id="S5.SS2.p1.3.m3.1.1.2" xref="S5.SS2.p1.3.m3.1.1.2.cmml"><mi id="S5.SS2.p1.3.m3.1.1.2.2" xref="S5.SS2.p1.3.m3.1.1.2.2.cmml">Y</mi><mo id="S5.SS2.p1.3.m3.1.1.2.1" xref="S5.SS2.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="S5.SS2.p1.3.m3.1.1.3" xref="S5.SS2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">subscript</csymbol><apply id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2"><ci id="S5.SS2.p1.3.m3.1.1.2.1.cmml" xref="S5.SS2.p1.3.m3.1.1.2.1">^</ci><ci id="S5.SS2.p1.3.m3.1.1.2.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2.2">𝑌</ci></apply><ci id="S5.SS2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">\hat{Y}_{i}</annotation></semantics></math> is the binary classification result for bin <math id="S5.SS2.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S5.SS2.p1.4.m4.1a"><mi id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><ci id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">i</annotation></semantics></math> from phase2, and <math id="S5.SS2.p1.5.m5.1" class="ltx_Math" alttext="P_{phase1}({i})" display="inline"><semantics id="S5.SS2.p1.5.m5.1a"><mrow id="S5.SS2.p1.5.m5.1.2" xref="S5.SS2.p1.5.m5.1.2.cmml"><msub id="S5.SS2.p1.5.m5.1.2.2" xref="S5.SS2.p1.5.m5.1.2.2.cmml"><mi id="S5.SS2.p1.5.m5.1.2.2.2" xref="S5.SS2.p1.5.m5.1.2.2.2.cmml">P</mi><mrow id="S5.SS2.p1.5.m5.1.2.2.3" xref="S5.SS2.p1.5.m5.1.2.2.3.cmml"><mi id="S5.SS2.p1.5.m5.1.2.2.3.2" xref="S5.SS2.p1.5.m5.1.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.5.m5.1.2.2.3.1" xref="S5.SS2.p1.5.m5.1.2.2.3.1.cmml">​</mo><mi id="S5.SS2.p1.5.m5.1.2.2.3.3" xref="S5.SS2.p1.5.m5.1.2.2.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.5.m5.1.2.2.3.1a" xref="S5.SS2.p1.5.m5.1.2.2.3.1.cmml">​</mo><mi id="S5.SS2.p1.5.m5.1.2.2.3.4" xref="S5.SS2.p1.5.m5.1.2.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.5.m5.1.2.2.3.1b" xref="S5.SS2.p1.5.m5.1.2.2.3.1.cmml">​</mo><mi id="S5.SS2.p1.5.m5.1.2.2.3.5" xref="S5.SS2.p1.5.m5.1.2.2.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.5.m5.1.2.2.3.1c" xref="S5.SS2.p1.5.m5.1.2.2.3.1.cmml">​</mo><mi id="S5.SS2.p1.5.m5.1.2.2.3.6" xref="S5.SS2.p1.5.m5.1.2.2.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2.p1.5.m5.1.2.2.3.1d" xref="S5.SS2.p1.5.m5.1.2.2.3.1.cmml">​</mo><mn id="S5.SS2.p1.5.m5.1.2.2.3.7" xref="S5.SS2.p1.5.m5.1.2.2.3.7.cmml">1</mn></mrow></msub><mo lspace="0em" rspace="0em" id="S5.SS2.p1.5.m5.1.2.1" xref="S5.SS2.p1.5.m5.1.2.1.cmml">​</mo><mrow id="S5.SS2.p1.5.m5.1.2.3.2" xref="S5.SS2.p1.5.m5.1.2.cmml"><mo stretchy="false" id="S5.SS2.p1.5.m5.1.2.3.2.1" xref="S5.SS2.p1.5.m5.1.2.cmml">(</mo><mi id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml">i</mi><mo stretchy="false" id="S5.SS2.p1.5.m5.1.2.3.2.2" xref="S5.SS2.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.2.cmml" xref="S5.SS2.p1.5.m5.1.2"><times id="S5.SS2.p1.5.m5.1.2.1.cmml" xref="S5.SS2.p1.5.m5.1.2.1"></times><apply id="S5.SS2.p1.5.m5.1.2.2.cmml" xref="S5.SS2.p1.5.m5.1.2.2"><csymbol cd="ambiguous" id="S5.SS2.p1.5.m5.1.2.2.1.cmml" xref="S5.SS2.p1.5.m5.1.2.2">subscript</csymbol><ci id="S5.SS2.p1.5.m5.1.2.2.2.cmml" xref="S5.SS2.p1.5.m5.1.2.2.2">𝑃</ci><apply id="S5.SS2.p1.5.m5.1.2.2.3.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3"><times id="S5.SS2.p1.5.m5.1.2.2.3.1.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.1"></times><ci id="S5.SS2.p1.5.m5.1.2.2.3.2.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.2">𝑝</ci><ci id="S5.SS2.p1.5.m5.1.2.2.3.3.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.3">ℎ</ci><ci id="S5.SS2.p1.5.m5.1.2.2.3.4.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.4">𝑎</ci><ci id="S5.SS2.p1.5.m5.1.2.2.3.5.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.5">𝑠</ci><ci id="S5.SS2.p1.5.m5.1.2.2.3.6.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.6">𝑒</ci><cn type="integer" id="S5.SS2.p1.5.m5.1.2.2.3.7.cmml" xref="S5.SS2.p1.5.m5.1.2.2.3.7">1</cn></apply></apply><ci id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">P_{phase1}({i})</annotation></semantics></math> is the output probability of the bin from phase1.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/Shape_retv.png" id="S5.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="256" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S5.F6.4.2" class="ltx_text" style="font-size:90%;">Shape Retrieval on Pix3D. Template matching compares the predicted-mask of the query image with other predicted-masks in the training data of the same category.</span></figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Pose Evaluation</span>
</h3>

<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS1.5.1.1" class="ltx_text">V-C</span>1 </span>Baseline vs. Ours</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p id="S5.SS3.SSS1.p1.1" class="ltx_p">To establish the importance of mid-level representations, we performed an ablation experiment in which the same network architecture is used but trained entirely from scratch. We called this network Baseline. Our second baseline, ResNet_baseline, uses ResNet backbone features instead of the features of the mid-level representation. The results for phase one and Our whole model are shown in Table <a href="#S4.T1" title="TABLE I ‣ IV Active Vision Dataset Pose Labeling ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. The backbone from mid-level features in our model is frozen.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<div id="S5.T2.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:237.1pt;height:136.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-6.2pt,3.6pt) scale(0.95,0.95) ;">
<table id="S5.T2.6.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.6.1.1.1" class="ltx_tr">
<th id="S5.T2.6.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S5.T2.6.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Azimuth</th>
<th id="S5.T2.6.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Elevation</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.6.1.2.1" class="ltx_tr">
<td id="S5.T2.6.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Normal</td>
<td id="S5.T2.6.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">68.37</td>
<td id="S5.T2.6.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">74.47</td>
</tr>
<tr id="S5.T2.6.1.3.2" class="ltx_tr">
<td id="S5.T2.6.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Normal+ 2D key-points</td>
<td id="S5.T2.6.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.77</td>
<td id="S5.T2.6.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.38</td>
</tr>
<tr id="S5.T2.6.1.4.3" class="ltx_tr">
<td id="S5.T2.6.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Normal+edge_occlusion</td>
<td id="S5.T2.6.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.52</td>
<td id="S5.T2.6.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.91</td>
</tr>
<tr id="S5.T2.6.1.5.4" class="ltx_tr">
<td id="S5.T2.6.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Normal+ depth_euclidean</td>
<td id="S5.T2.6.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.24</td>
<td id="S5.T2.6.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.6.1.5.4.3.1" class="ltx_text ltx_font_bold">76.36</span></td>
</tr>
<tr id="S5.T2.6.1.6.5" class="ltx_tr">
<td id="S5.T2.6.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Normal+ segment_unsup25d</td>
<td id="S5.T2.6.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.40</td>
<td id="S5.T2.6.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">74.42</td>
</tr>
<tr id="S5.T2.6.1.7.6" class="ltx_tr">
<td id="S5.T2.6.1.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Normal+ 3D key points</td>
<td id="S5.T2.6.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.03</td>
<td id="S5.T2.6.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.6.1.7.6.3.1" class="ltx_text ltx_font_bold">76.36</span></td>
</tr>
<tr id="S5.T2.6.1.8.7" class="ltx_tr">
<td id="S5.T2.6.1.8.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Normal+reshading</td>
<td id="S5.T2.6.1.8.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S5.T2.6.1.8.7.2.1" class="ltx_text ltx_font_bold">72.21</span></td>
<td id="S5.T2.6.1.8.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">76.08</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.7.3.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S5.T2.4.2" class="ltx_text" style="font-size:90%;">The choice of mid-level features and the effect on pose classification task with <math id="S5.T2.3.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S5.T2.3.1.m1.1b"><mn id="S5.T2.3.1.m1.1.1" xref="S5.T2.3.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S5.T2.3.1.m1.1c"><cn type="integer" id="S5.T2.3.1.m1.1.1.cmml" xref="S5.T2.3.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.1.m1.1d">9</annotation></semantics></math> bins with <math id="S5.T2.4.2.m2.1" class="ltx_Math" alttext="2.5^{\circ}" display="inline"><semantics id="S5.T2.4.2.m2.1b"><msup id="S5.T2.4.2.m2.1.1" xref="S5.T2.4.2.m2.1.1.cmml"><mn id="S5.T2.4.2.m2.1.1.2" xref="S5.T2.4.2.m2.1.1.2.cmml">2.5</mn><mo id="S5.T2.4.2.m2.1.1.3" xref="S5.T2.4.2.m2.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.4.2.m2.1c"><apply id="S5.T2.4.2.m2.1.1.cmml" xref="S5.T2.4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.T2.4.2.m2.1.1.1.cmml" xref="S5.T2.4.2.m2.1.1">superscript</csymbol><cn type="float" id="S5.T2.4.2.m2.1.1.2.cmml" xref="S5.T2.4.2.m2.1.1.2">2.5</cn><compose id="S5.T2.4.2.m2.1.1.3.cmml" xref="S5.T2.4.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.2.m2.1d">2.5^{\circ}</annotation></semantics></math> overlap.</span></figcaption>
</figure>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS2.5.1.1" class="ltx_text">V-C</span>2 </span>Mid-level representations features input</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p id="S5.SS3.SSS2.p1.4" class="ltx_p">The <math id="S5.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="16\times 8" display="inline"><semantics id="S5.SS3.SSS2.p1.1.m1.1a"><mrow id="S5.SS3.SSS2.p1.1.m1.1.1" xref="S5.SS3.SSS2.p1.1.m1.1.1.cmml"><mn id="S5.SS3.SSS2.p1.1.m1.1.1.2" xref="S5.SS3.SSS2.p1.1.m1.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS3.SSS2.p1.1.m1.1.1.1" xref="S5.SS3.SSS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS3.SSS2.p1.1.m1.1.1.3" xref="S5.SS3.SSS2.p1.1.m1.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p1.1.m1.1b"><apply id="S5.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.1"><times id="S5.SS3.SSS2.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS3.SSS2.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.1.2">16</cn><cn type="integer" id="S5.SS3.SSS2.p1.1.m1.1.1.3.cmml" xref="S5.SS3.SSS2.p1.1.m1.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p1.1.m1.1c">16\times 8</annotation></semantics></math> feature maps of mid-level representations are used as our model input.
Inspired by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">29</a>, <a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite> we use the surface normals that have been shown to be beneficial for the pose estimation. From other <math id="S5.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="24" display="inline"><semantics id="S5.SS3.SSS2.p1.2.m2.1a"><mn id="S5.SS3.SSS2.p1.2.m2.1.1" xref="S5.SS3.SSS2.p1.2.m2.1.1.cmml">24</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p1.2.m2.1b"><cn type="integer" id="S5.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS2.p1.2.m2.1.1">24</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p1.2.m2.1c">24</annotation></semantics></math> models introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">33</a>]</cite>, the re-shading feature map benefits our model most as shown in our experiments in Table <a href="#S5.T2" title="TABLE II ‣ V-C1 Baseline vs. Ours ‣ V-C Pose Evaluation ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Figure <a href="#S3.F3" title="Figure 3 ‣ III-A Mid-Level Visual Representations ‣ III Approach ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows sample inputs. We also tried the combinations of <math id="S5.SS3.SSS2.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.SS3.SSS2.p1.3.m3.1a"><mn id="S5.SS3.SSS2.p1.3.m3.1.1" xref="S5.SS3.SSS2.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p1.3.m3.1b"><cn type="integer" id="S5.SS3.SSS2.p1.3.m3.1.1.cmml" xref="S5.SS3.SSS2.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p1.3.m3.1c">3</annotation></semantics></math> feature maps, but they did not improve the model by more than a few <math id="S5.SS3.SSS2.p1.4.m4.1" class="ltx_Math" alttext="0.1\%" display="inline"><semantics id="S5.SS3.SSS2.p1.4.m4.1a"><mrow id="S5.SS3.SSS2.p1.4.m4.1.1" xref="S5.SS3.SSS2.p1.4.m4.1.1.cmml"><mn id="S5.SS3.SSS2.p1.4.m4.1.1.2" xref="S5.SS3.SSS2.p1.4.m4.1.1.2.cmml">0.1</mn><mo id="S5.SS3.SSS2.p1.4.m4.1.1.1" xref="S5.SS3.SSS2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p1.4.m4.1b"><apply id="S5.SS3.SSS2.p1.4.m4.1.1.cmml" xref="S5.SS3.SSS2.p1.4.m4.1.1"><csymbol cd="latexml" id="S5.SS3.SSS2.p1.4.m4.1.1.1.cmml" xref="S5.SS3.SSS2.p1.4.m4.1.1.1">percent</csymbol><cn type="float" id="S5.SS3.SSS2.p1.4.m4.1.1.2.cmml" xref="S5.SS3.SSS2.p1.4.m4.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p1.4.m4.1c">0.1\%</annotation></semantics></math>.</p>
</div>
<div id="S5.SS3.SSS2.p2" class="ltx_para">
<p id="S5.SS3.SSS2.p2.7" class="ltx_p">The second stage of the approach completely relies on the D-Masks. With the even number of bins, the symmetric objects have the same D-masks for multiple orientations. This fact encourages us to use the odd number of bins. Based on our experiments, it’s difficult for models to distinguish the pose of the object if it’s close to the bin’s borders, hence overlapping bins are used as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite>.
To make the results comparable to other pose classification models, we defined <math id="S5.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="9" display="inline"><semantics id="S5.SS3.SSS2.p2.1.m1.1a"><mn id="S5.SS3.SSS2.p2.1.m1.1.1" xref="S5.SS3.SSS2.p2.1.m1.1.1.cmml">9</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.1.m1.1b"><cn type="integer" id="S5.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S5.SS3.SSS2.p2.1.m1.1.1">9</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.1.m1.1c">9</annotation></semantics></math> bins with <math id="S5.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="2.5" display="inline"><semantics id="S5.SS3.SSS2.p2.2.m2.1a"><mn id="S5.SS3.SSS2.p2.2.m2.1.1" xref="S5.SS3.SSS2.p2.2.m2.1.1.cmml">2.5</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.2.m2.1b"><cn type="float" id="S5.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S5.SS3.SSS2.p2.2.m2.1.1">2.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.2.m2.1c">2.5</annotation></semantics></math> degree overlap on each side; which is comparable to <math id="S5.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S5.SS3.SSS2.p2.3.m3.1a"><mn id="S5.SS3.SSS2.p2.3.m3.1.1" xref="S5.SS3.SSS2.p2.3.m3.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.3.m3.1b"><cn type="integer" id="S5.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S5.SS3.SSS2.p2.3.m3.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.3.m3.1c">8</annotation></semantics></math> bins. Since the range of each bin in both is <math id="S5.SS3.SSS2.p2.4.m4.1" class="ltx_Math" alttext="45" display="inline"><semantics id="S5.SS3.SSS2.p2.4.m4.1a"><mn id="S5.SS3.SSS2.p2.4.m4.1.1" xref="S5.SS3.SSS2.p2.4.m4.1.1.cmml">45</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.4.m4.1b"><cn type="integer" id="S5.SS3.SSS2.p2.4.m4.1.1.cmml" xref="S5.SS3.SSS2.p2.4.m4.1.1">45</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.4.m4.1c">45</annotation></semantics></math> degree; Similarly, the <math id="S5.SS3.SSS2.p2.5.m5.3" class="ltx_Math" alttext="5,13,25" display="inline"><semantics id="S5.SS3.SSS2.p2.5.m5.3a"><mrow id="S5.SS3.SSS2.p2.5.m5.3.4.2" xref="S5.SS3.SSS2.p2.5.m5.3.4.1.cmml"><mn id="S5.SS3.SSS2.p2.5.m5.1.1" xref="S5.SS3.SSS2.p2.5.m5.1.1.cmml">5</mn><mo id="S5.SS3.SSS2.p2.5.m5.3.4.2.1" xref="S5.SS3.SSS2.p2.5.m5.3.4.1.cmml">,</mo><mn id="S5.SS3.SSS2.p2.5.m5.2.2" xref="S5.SS3.SSS2.p2.5.m5.2.2.cmml">13</mn><mo id="S5.SS3.SSS2.p2.5.m5.3.4.2.2" xref="S5.SS3.SSS2.p2.5.m5.3.4.1.cmml">,</mo><mn id="S5.SS3.SSS2.p2.5.m5.3.3" xref="S5.SS3.SSS2.p2.5.m5.3.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.5.m5.3b"><list id="S5.SS3.SSS2.p2.5.m5.3.4.1.cmml" xref="S5.SS3.SSS2.p2.5.m5.3.4.2"><cn type="integer" id="S5.SS3.SSS2.p2.5.m5.1.1.cmml" xref="S5.SS3.SSS2.p2.5.m5.1.1">5</cn><cn type="integer" id="S5.SS3.SSS2.p2.5.m5.2.2.cmml" xref="S5.SS3.SSS2.p2.5.m5.2.2">13</cn><cn type="integer" id="S5.SS3.SSS2.p2.5.m5.3.3.cmml" xref="S5.SS3.SSS2.p2.5.m5.3.3">25</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.5.m5.3c">5,13,25</annotation></semantics></math> bins with <math id="S5.SS3.SSS2.p2.6.m6.3" class="ltx_Math" alttext="9,1.15,0.3" display="inline"><semantics id="S5.SS3.SSS2.p2.6.m6.3a"><mrow id="S5.SS3.SSS2.p2.6.m6.3.4.2" xref="S5.SS3.SSS2.p2.6.m6.3.4.1.cmml"><mn id="S5.SS3.SSS2.p2.6.m6.1.1" xref="S5.SS3.SSS2.p2.6.m6.1.1.cmml">9</mn><mo id="S5.SS3.SSS2.p2.6.m6.3.4.2.1" xref="S5.SS3.SSS2.p2.6.m6.3.4.1.cmml">,</mo><mn id="S5.SS3.SSS2.p2.6.m6.2.2" xref="S5.SS3.SSS2.p2.6.m6.2.2.cmml">1.15</mn><mo id="S5.SS3.SSS2.p2.6.m6.3.4.2.2" xref="S5.SS3.SSS2.p2.6.m6.3.4.1.cmml">,</mo><mn id="S5.SS3.SSS2.p2.6.m6.3.3" xref="S5.SS3.SSS2.p2.6.m6.3.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.6.m6.3b"><list id="S5.SS3.SSS2.p2.6.m6.3.4.1.cmml" xref="S5.SS3.SSS2.p2.6.m6.3.4.2"><cn type="integer" id="S5.SS3.SSS2.p2.6.m6.1.1.cmml" xref="S5.SS3.SSS2.p2.6.m6.1.1">9</cn><cn type="float" id="S5.SS3.SSS2.p2.6.m6.2.2.cmml" xref="S5.SS3.SSS2.p2.6.m6.2.2">1.15</cn><cn type="float" id="S5.SS3.SSS2.p2.6.m6.3.3.cmml" xref="S5.SS3.SSS2.p2.6.m6.3.3">0.3</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.6.m6.3c">9,1.15,0.3</annotation></semantics></math>, degree overlap on each side is comparable with <math id="S5.SS3.SSS2.p2.7.m7.3" class="ltx_Math" alttext="4,12,24" display="inline"><semantics id="S5.SS3.SSS2.p2.7.m7.3a"><mrow id="S5.SS3.SSS2.p2.7.m7.3.4.2" xref="S5.SS3.SSS2.p2.7.m7.3.4.1.cmml"><mn id="S5.SS3.SSS2.p2.7.m7.1.1" xref="S5.SS3.SSS2.p2.7.m7.1.1.cmml">4</mn><mo id="S5.SS3.SSS2.p2.7.m7.3.4.2.1" xref="S5.SS3.SSS2.p2.7.m7.3.4.1.cmml">,</mo><mn id="S5.SS3.SSS2.p2.7.m7.2.2" xref="S5.SS3.SSS2.p2.7.m7.2.2.cmml">12</mn><mo id="S5.SS3.SSS2.p2.7.m7.3.4.2.2" xref="S5.SS3.SSS2.p2.7.m7.3.4.1.cmml">,</mo><mn id="S5.SS3.SSS2.p2.7.m7.3.3" xref="S5.SS3.SSS2.p2.7.m7.3.3.cmml">24</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS2.p2.7.m7.3b"><list id="S5.SS3.SSS2.p2.7.m7.3.4.1.cmml" xref="S5.SS3.SSS2.p2.7.m7.3.4.2"><cn type="integer" id="S5.SS3.SSS2.p2.7.m7.1.1.cmml" xref="S5.SS3.SSS2.p2.7.m7.1.1">4</cn><cn type="integer" id="S5.SS3.SSS2.p2.7.m7.2.2.cmml" xref="S5.SS3.SSS2.p2.7.m7.2.2">12</cn><cn type="integer" id="S5.SS3.SSS2.p2.7.m7.3.3.cmml" xref="S5.SS3.SSS2.p2.7.m7.3.3">24</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS2.p2.7.m7.3c">4,12,24</annotation></semantics></math> bins. Table <a href="#S5.T4" title="TABLE IV ‣ V-C4 Low Data Regime for training ‣ V-C Pose Evaluation ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> shows the model performance for the different number of bins.</p>
</div>
</section>
<section id="S5.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS3.5.1.1" class="ltx_text">V-C</span>3 </span>Comparison with Available Models</h4>

<div id="S5.SS3.SSS3.p1" class="ltx_para">
<p id="S5.SS3.SSS3.p1.1" class="ltx_p">In comparison Mousavian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">17</a>]</cite>, our model outperforms by a large margin, which shows the importance of generalizability of the mid-level features for the pose estimation task, Table <a href="#S4.T1" title="TABLE I ‣ IV Active Vision Dataset Pose Labeling ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. The model is also compared with the Pix3D dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite> on the chair category. The Pix3D trained reconstruction and pose estimation together only for the untruncated and unoccluded chairs. It is stated that the reconstruction branch helps to improve the pose classification accuracy. Compared to Pix3D, our model is trained category agnostic way, with no need for supervision on the mid-level features. On the contrary, Pix3D needs supervision for normal, depth, and silhouette images and is trained per category. The results are shown in Table <a href="#S5.T3" title="TABLE III ‣ V-C4 Low Data Regime for training ‣ V-C Pose Evaluation ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> for the chair category.</p>
</div>
</section>
<section id="S5.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS4.5.1.1" class="ltx_text">V-C</span>4 </span>Low Data Regime for training</h4>

<div id="S5.SS3.SSS4.p1" class="ltx_para">
<p id="S5.SS3.SSS4.p1.1" class="ltx_p">Training Models for pose estimation tasks from scratch require thousands of samples for each category with the pose annotation. Some approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">26</a>]</cite> also require the surface normal, silhouette, or depth supervision. The labeling process is costly and time-consuming. The proposed model outperforms other models by a large margin when using a fraction of training examples. Figure <a href="#S5.F7" title="Figure 7 ‣ V-C4 Low Data Regime for training ‣ V-C Pose Evaluation ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows some quantitative results.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/less_data.png" id="S5.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S5.F7.4.2" class="ltx_text" style="font-size:90%;">The accuracy results with training on different percentages of the training data. Achieving 35% improvement over the existing models when there’s only 25% of training data is available.</span></figcaption>
</figure>
<figure id="S5.T3" class="ltx_table">
<div id="S5.T3.9" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:244.7pt;height:47.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.7pt,3.2pt) scale(0.88,0.88) ;">
<table id="S5.T3.9.9" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.3.3.3" class="ltx_tr">
<th id="S5.T3.3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"># bins</th>
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S5.T3.1.1.1.1.m1.2" class="ltx_Math" alttext="(4)/(5+9^{\circ})" display="inline"><semantics id="S5.T3.1.1.1.1.m1.2a"><mrow id="S5.T3.1.1.1.1.m1.2.2" xref="S5.T3.1.1.1.1.m1.2.2.cmml"><mrow id="S5.T3.1.1.1.1.m1.2.2.3.2" xref="S5.T3.1.1.1.1.m1.2.2.cmml"><mo stretchy="false" id="S5.T3.1.1.1.1.m1.2.2.3.2.1" xref="S5.T3.1.1.1.1.m1.2.2.cmml">(</mo><mn id="S5.T3.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.m1.1.1.cmml">4</mn><mo stretchy="false" id="S5.T3.1.1.1.1.m1.2.2.3.2.2" xref="S5.T3.1.1.1.1.m1.2.2.cmml">)</mo></mrow><mo id="S5.T3.1.1.1.1.m1.2.2.2" xref="S5.T3.1.1.1.1.m1.2.2.2.cmml">/</mo><mrow id="S5.T3.1.1.1.1.m1.2.2.1.1" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S5.T3.1.1.1.1.m1.2.2.1.1.2" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.cmml">(</mo><mrow id="S5.T3.1.1.1.1.m1.2.2.1.1.1" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.cmml"><mn id="S5.T3.1.1.1.1.m1.2.2.1.1.1.2" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.2.cmml">5</mn><mo id="S5.T3.1.1.1.1.m1.2.2.1.1.1.1" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.1.cmml">+</mo><msup id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.cmml"><mn id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.2" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.2.cmml">9</mn><mo id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.3" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.3.cmml">∘</mo></msup></mrow><mo stretchy="false" id="S5.T3.1.1.1.1.m1.2.2.1.1.3" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.m1.2b"><apply id="S5.T3.1.1.1.1.m1.2.2.cmml" xref="S5.T3.1.1.1.1.m1.2.2"><divide id="S5.T3.1.1.1.1.m1.2.2.2.cmml" xref="S5.T3.1.1.1.1.m1.2.2.2"></divide><cn type="integer" id="S5.T3.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1">4</cn><apply id="S5.T3.1.1.1.1.m1.2.2.1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1"><plus id="S5.T3.1.1.1.1.m1.2.2.1.1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.1"></plus><cn type="integer" id="S5.T3.1.1.1.1.m1.2.2.1.1.1.2.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.2">5</cn><apply id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.1.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3">superscript</csymbol><cn type="integer" id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.2.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.2">9</cn><compose id="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.3.cmml" xref="S5.T3.1.1.1.1.m1.2.2.1.1.1.3.3"></compose></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.m1.2c">(4)/(5+9^{\circ})</annotation></semantics></math></th>
<th id="S5.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S5.T3.2.2.2.2.m1.2" class="ltx_Math" alttext="(8)/(9+2.5^{\circ})" display="inline"><semantics id="S5.T3.2.2.2.2.m1.2a"><mrow id="S5.T3.2.2.2.2.m1.2.2" xref="S5.T3.2.2.2.2.m1.2.2.cmml"><mrow id="S5.T3.2.2.2.2.m1.2.2.3.2" xref="S5.T3.2.2.2.2.m1.2.2.cmml"><mo stretchy="false" id="S5.T3.2.2.2.2.m1.2.2.3.2.1" xref="S5.T3.2.2.2.2.m1.2.2.cmml">(</mo><mn id="S5.T3.2.2.2.2.m1.1.1" xref="S5.T3.2.2.2.2.m1.1.1.cmml">8</mn><mo stretchy="false" id="S5.T3.2.2.2.2.m1.2.2.3.2.2" xref="S5.T3.2.2.2.2.m1.2.2.cmml">)</mo></mrow><mo id="S5.T3.2.2.2.2.m1.2.2.2" xref="S5.T3.2.2.2.2.m1.2.2.2.cmml">/</mo><mrow id="S5.T3.2.2.2.2.m1.2.2.1.1" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S5.T3.2.2.2.2.m1.2.2.1.1.2" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.cmml">(</mo><mrow id="S5.T3.2.2.2.2.m1.2.2.1.1.1" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.cmml"><mn id="S5.T3.2.2.2.2.m1.2.2.1.1.1.2" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.2.cmml">9</mn><mo id="S5.T3.2.2.2.2.m1.2.2.1.1.1.1" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.1.cmml">+</mo><msup id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.cmml"><mn id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.2" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.2.cmml">2.5</mn><mo id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.3" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.3.cmml">∘</mo></msup></mrow><mo stretchy="false" id="S5.T3.2.2.2.2.m1.2.2.1.1.3" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.m1.2b"><apply id="S5.T3.2.2.2.2.m1.2.2.cmml" xref="S5.T3.2.2.2.2.m1.2.2"><divide id="S5.T3.2.2.2.2.m1.2.2.2.cmml" xref="S5.T3.2.2.2.2.m1.2.2.2"></divide><cn type="integer" id="S5.T3.2.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.1.1">8</cn><apply id="S5.T3.2.2.2.2.m1.2.2.1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1"><plus id="S5.T3.2.2.2.2.m1.2.2.1.1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.1"></plus><cn type="integer" id="S5.T3.2.2.2.2.m1.2.2.1.1.1.2.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.2">9</cn><apply id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.1.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3">superscript</csymbol><cn type="float" id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.2.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.2">2.5</cn><compose id="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.3.cmml" xref="S5.T3.2.2.2.2.m1.2.2.1.1.1.3.3"></compose></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.m1.2c">(8)/(9+2.5^{\circ})</annotation></semantics></math></th>
<th id="S5.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><math id="S5.T3.3.3.3.3.m1.2" class="ltx_Math" alttext="(12)/(13+1.5^{\circ})" display="inline"><semantics id="S5.T3.3.3.3.3.m1.2a"><mrow id="S5.T3.3.3.3.3.m1.2.2" xref="S5.T3.3.3.3.3.m1.2.2.cmml"><mrow id="S5.T3.3.3.3.3.m1.2.2.3.2" xref="S5.T3.3.3.3.3.m1.2.2.cmml"><mo stretchy="false" id="S5.T3.3.3.3.3.m1.2.2.3.2.1" xref="S5.T3.3.3.3.3.m1.2.2.cmml">(</mo><mn id="S5.T3.3.3.3.3.m1.1.1" xref="S5.T3.3.3.3.3.m1.1.1.cmml">12</mn><mo stretchy="false" id="S5.T3.3.3.3.3.m1.2.2.3.2.2" xref="S5.T3.3.3.3.3.m1.2.2.cmml">)</mo></mrow><mo id="S5.T3.3.3.3.3.m1.2.2.2" xref="S5.T3.3.3.3.3.m1.2.2.2.cmml">/</mo><mrow id="S5.T3.3.3.3.3.m1.2.2.1.1" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.cmml"><mo stretchy="false" id="S5.T3.3.3.3.3.m1.2.2.1.1.2" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.cmml">(</mo><mrow id="S5.T3.3.3.3.3.m1.2.2.1.1.1" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.cmml"><mn id="S5.T3.3.3.3.3.m1.2.2.1.1.1.2" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.2.cmml">13</mn><mo id="S5.T3.3.3.3.3.m1.2.2.1.1.1.1" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.1.cmml">+</mo><msup id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.cmml"><mn id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.2" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.2.cmml">1.5</mn><mo id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.3" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.3.cmml">∘</mo></msup></mrow><mo stretchy="false" id="S5.T3.3.3.3.3.m1.2.2.1.1.3" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.m1.2b"><apply id="S5.T3.3.3.3.3.m1.2.2.cmml" xref="S5.T3.3.3.3.3.m1.2.2"><divide id="S5.T3.3.3.3.3.m1.2.2.2.cmml" xref="S5.T3.3.3.3.3.m1.2.2.2"></divide><cn type="integer" id="S5.T3.3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.3.m1.1.1">12</cn><apply id="S5.T3.3.3.3.3.m1.2.2.1.1.1.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1"><plus id="S5.T3.3.3.3.3.m1.2.2.1.1.1.1.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.1"></plus><cn type="integer" id="S5.T3.3.3.3.3.m1.2.2.1.1.1.2.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.2">13</cn><apply id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.1.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3">superscript</csymbol><cn type="float" id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.2.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.2">1.5</cn><compose id="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.3.cmml" xref="S5.T3.3.3.3.3.m1.2.2.1.1.1.3.3"></compose></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.m1.2c">(12)/(13+1.5^{\circ})</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.6.6.6" class="ltx_tr">
<th id="S5.T3.6.6.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt">Pix3D</th>
<td id="S5.T3.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S5.T3.4.4.4.1.m1.1" class="ltx_Math" alttext="76.00" display="inline"><semantics id="S5.T3.4.4.4.1.m1.1a"><mn id="S5.T3.4.4.4.1.m1.1.1" xref="S5.T3.4.4.4.1.m1.1.1.cmml">76.00</mn><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.1.m1.1b"><cn type="float" id="S5.T3.4.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.4.1.m1.1.1">76.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.1.m1.1c">76.00</annotation></semantics></math></td>
<td id="S5.T3.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S5.T3.5.5.5.2.m1.1" class="ltx_Math" alttext="73.00" display="inline"><semantics id="S5.T3.5.5.5.2.m1.1a"><mn id="S5.T3.5.5.5.2.m1.1.1" xref="S5.T3.5.5.5.2.m1.1.1.cmml">73.00</mn><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.2.m1.1b"><cn type="float" id="S5.T3.5.5.5.2.m1.1.1.cmml" xref="S5.T3.5.5.5.2.m1.1.1">73.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.5.2.m1.1c">73.00</annotation></semantics></math></td>
<td id="S5.T3.6.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><math id="S5.T3.6.6.6.3.m1.1" class="ltx_Math" alttext="61.00" display="inline"><semantics id="S5.T3.6.6.6.3.m1.1a"><mn id="S5.T3.6.6.6.3.m1.1.1" xref="S5.T3.6.6.6.3.m1.1.1.cmml">61.00</mn><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.6.3.m1.1b"><cn type="float" id="S5.T3.6.6.6.3.m1.1.1.cmml" xref="S5.T3.6.6.6.3.m1.1.1">61.00</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.6.3.m1.1c">61.00</annotation></semantics></math></td>
</tr>
<tr id="S5.T3.9.9.9" class="ltx_tr">
<th id="S5.T3.9.9.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">ours</th>
<td id="S5.T3.7.7.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.7.7.7.1.m1.1" class="ltx_Math" alttext="76.61" display="inline"><semantics id="S5.T3.7.7.7.1.m1.1a"><mn id="S5.T3.7.7.7.1.m1.1.1" xref="S5.T3.7.7.7.1.m1.1.1.cmml">76.61</mn><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.7.1.m1.1b"><cn type="float" id="S5.T3.7.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1">76.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.7.1.m1.1c">76.61</annotation></semantics></math></td>
<td id="S5.T3.8.8.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.8.8.8.2.m1.1" class="ltx_Math" alttext="74.55" display="inline"><semantics id="S5.T3.8.8.8.2.m1.1a"><mn id="S5.T3.8.8.8.2.m1.1.1" xref="S5.T3.8.8.8.2.m1.1.1.cmml">74.55</mn><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.8.2.m1.1b"><cn type="float" id="S5.T3.8.8.8.2.m1.1.1.cmml" xref="S5.T3.8.8.8.2.m1.1.1">74.55</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.8.2.m1.1c">74.55</annotation></semantics></math></td>
<td id="S5.T3.9.9.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><math id="S5.T3.9.9.9.3.m1.1" class="ltx_Math" alttext="61.70" display="inline"><semantics id="S5.T3.9.9.9.3.m1.1a"><mn id="S5.T3.9.9.9.3.m1.1.1" xref="S5.T3.9.9.9.3.m1.1.1.cmml">61.70</mn><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.9.3.m1.1b"><cn type="float" id="S5.T3.9.9.9.3.m1.1.1.cmml" xref="S5.T3.9.9.9.3.m1.1.1">61.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.9.3.m1.1c">61.70</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.11.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S5.T3.12.2" class="ltx_text" style="font-size:90%;">The comparison of our model with the Pix3D model. Results are only for the chair category for different number of bins.</span></figcaption>
</figure>
<figure id="S5.T4" class="ltx_table">
<div id="S5.T4.12" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:257.4pt;height:47.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-17.5pt,3.2pt) scale(0.88,0.88) ;">
<table id="S5.T4.12.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T4.12.12.13.1" class="ltx_tr">
<th id="S5.T4.12.12.13.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S5.T4.12.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3">Azimuth</th>
<th id="S5.T4.12.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3">Elevation</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T4.6.6.6" class="ltx_tr">
<th id="S5.T4.6.6.6.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"># bins</th>
<td id="S5.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="5+9^{\circ}" display="inline"><semantics id="S5.T4.1.1.1.1.m1.1a"><mrow id="S5.T4.1.1.1.1.m1.1.1" xref="S5.T4.1.1.1.1.m1.1.1.cmml"><mn id="S5.T4.1.1.1.1.m1.1.1.2" xref="S5.T4.1.1.1.1.m1.1.1.2.cmml">5</mn><mo id="S5.T4.1.1.1.1.m1.1.1.1" xref="S5.T4.1.1.1.1.m1.1.1.1.cmml">+</mo><msup id="S5.T4.1.1.1.1.m1.1.1.3" xref="S5.T4.1.1.1.1.m1.1.1.3.cmml"><mn id="S5.T4.1.1.1.1.m1.1.1.3.2" xref="S5.T4.1.1.1.1.m1.1.1.3.2.cmml">9</mn><mo id="S5.T4.1.1.1.1.m1.1.1.3.3" xref="S5.T4.1.1.1.1.m1.1.1.3.3.cmml">∘</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><apply id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1"><plus id="S5.T4.1.1.1.1.m1.1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1.1"></plus><cn type="integer" id="S5.T4.1.1.1.1.m1.1.1.2.cmml" xref="S5.T4.1.1.1.1.m1.1.1.2">5</cn><apply id="S5.T4.1.1.1.1.m1.1.1.3.cmml" xref="S5.T4.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T4.1.1.1.1.m1.1.1.3.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.T4.1.1.1.1.m1.1.1.3.2.cmml" xref="S5.T4.1.1.1.1.m1.1.1.3.2">9</cn><compose id="S5.T4.1.1.1.1.m1.1.1.3.3.cmml" xref="S5.T4.1.1.1.1.m1.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">5+9^{\circ}</annotation></semantics></math></td>
<td id="S5.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.2.2.2.2.m1.1" class="ltx_Math" alttext="9+2.5^{\circ}" display="inline"><semantics id="S5.T4.2.2.2.2.m1.1a"><mrow id="S5.T4.2.2.2.2.m1.1.1" xref="S5.T4.2.2.2.2.m1.1.1.cmml"><mn id="S5.T4.2.2.2.2.m1.1.1.2" xref="S5.T4.2.2.2.2.m1.1.1.2.cmml">9</mn><mo id="S5.T4.2.2.2.2.m1.1.1.1" xref="S5.T4.2.2.2.2.m1.1.1.1.cmml">+</mo><msup id="S5.T4.2.2.2.2.m1.1.1.3" xref="S5.T4.2.2.2.2.m1.1.1.3.cmml"><mn id="S5.T4.2.2.2.2.m1.1.1.3.2" xref="S5.T4.2.2.2.2.m1.1.1.3.2.cmml">2.5</mn><mo id="S5.T4.2.2.2.2.m1.1.1.3.3" xref="S5.T4.2.2.2.2.m1.1.1.3.3.cmml">∘</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.2.m1.1b"><apply id="S5.T4.2.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.2.m1.1.1"><plus id="S5.T4.2.2.2.2.m1.1.1.1.cmml" xref="S5.T4.2.2.2.2.m1.1.1.1"></plus><cn type="integer" id="S5.T4.2.2.2.2.m1.1.1.2.cmml" xref="S5.T4.2.2.2.2.m1.1.1.2">9</cn><apply id="S5.T4.2.2.2.2.m1.1.1.3.cmml" xref="S5.T4.2.2.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T4.2.2.2.2.m1.1.1.3.1.cmml" xref="S5.T4.2.2.2.2.m1.1.1.3">superscript</csymbol><cn type="float" id="S5.T4.2.2.2.2.m1.1.1.3.2.cmml" xref="S5.T4.2.2.2.2.m1.1.1.3.2">2.5</cn><compose id="S5.T4.2.2.2.2.m1.1.1.3.3.cmml" xref="S5.T4.2.2.2.2.m1.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.2.m1.1c">9+2.5^{\circ}</annotation></semantics></math></td>
<td id="S5.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.3.3.3.3.m1.1" class="ltx_Math" alttext="13+1.5^{\circ}" display="inline"><semantics id="S5.T4.3.3.3.3.m1.1a"><mrow id="S5.T4.3.3.3.3.m1.1.1" xref="S5.T4.3.3.3.3.m1.1.1.cmml"><mn id="S5.T4.3.3.3.3.m1.1.1.2" xref="S5.T4.3.3.3.3.m1.1.1.2.cmml">13</mn><mo id="S5.T4.3.3.3.3.m1.1.1.1" xref="S5.T4.3.3.3.3.m1.1.1.1.cmml">+</mo><msup id="S5.T4.3.3.3.3.m1.1.1.3" xref="S5.T4.3.3.3.3.m1.1.1.3.cmml"><mn id="S5.T4.3.3.3.3.m1.1.1.3.2" xref="S5.T4.3.3.3.3.m1.1.1.3.2.cmml">1.5</mn><mo id="S5.T4.3.3.3.3.m1.1.1.3.3" xref="S5.T4.3.3.3.3.m1.1.1.3.3.cmml">∘</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.3.m1.1b"><apply id="S5.T4.3.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.3.m1.1.1"><plus id="S5.T4.3.3.3.3.m1.1.1.1.cmml" xref="S5.T4.3.3.3.3.m1.1.1.1"></plus><cn type="integer" id="S5.T4.3.3.3.3.m1.1.1.2.cmml" xref="S5.T4.3.3.3.3.m1.1.1.2">13</cn><apply id="S5.T4.3.3.3.3.m1.1.1.3.cmml" xref="S5.T4.3.3.3.3.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T4.3.3.3.3.m1.1.1.3.1.cmml" xref="S5.T4.3.3.3.3.m1.1.1.3">superscript</csymbol><cn type="float" id="S5.T4.3.3.3.3.m1.1.1.3.2.cmml" xref="S5.T4.3.3.3.3.m1.1.1.3.2">1.5</cn><compose id="S5.T4.3.3.3.3.m1.1.1.3.3.cmml" xref="S5.T4.3.3.3.3.m1.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.3.m1.1c">13+1.5^{\circ}</annotation></semantics></math></td>
<td id="S5.T4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.4.4.4.4.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S5.T4.4.4.4.4.m1.1a"><mn id="S5.T4.4.4.4.4.m1.1.1" xref="S5.T4.4.4.4.4.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.4.m1.1b"><cn type="integer" id="S5.T4.4.4.4.4.m1.1.1.cmml" xref="S5.T4.4.4.4.4.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.4.m1.1c">3</annotation></semantics></math></td>
<td id="S5.T4.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.5.5.5.5.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.T4.5.5.5.5.m1.1a"><mn id="S5.T4.5.5.5.5.m1.1.1" xref="S5.T4.5.5.5.5.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.5.5.m1.1b"><cn type="integer" id="S5.T4.5.5.5.5.m1.1.1.cmml" xref="S5.T4.5.5.5.5.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.5.5.m1.1c">5</annotation></semantics></math></td>
<td id="S5.T4.6.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.6.6.6.6.m1.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S5.T4.6.6.6.6.m1.1a"><mn id="S5.T4.6.6.6.6.m1.1.1" xref="S5.T4.6.6.6.6.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.6.6.m1.1b"><cn type="integer" id="S5.T4.6.6.6.6.m1.1.1.cmml" xref="S5.T4.6.6.6.6.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.6.6.m1.1c">7</annotation></semantics></math></td>
</tr>
<tr id="S5.T4.12.12.12" class="ltx_tr">
<th id="S5.T4.12.12.12.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_tt">ours</th>
<td id="S5.T4.7.7.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><math id="S5.T4.7.7.7.1.m1.1" class="ltx_Math" alttext="77.54" display="inline"><semantics id="S5.T4.7.7.7.1.m1.1a"><mn id="S5.T4.7.7.7.1.m1.1.1" xref="S5.T4.7.7.7.1.m1.1.1.cmml">77.54</mn><annotation-xml encoding="MathML-Content" id="S5.T4.7.7.7.1.m1.1b"><cn type="float" id="S5.T4.7.7.7.1.m1.1.1.cmml" xref="S5.T4.7.7.7.1.m1.1.1">77.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.7.7.1.m1.1c">77.54</annotation></semantics></math></td>
<td id="S5.T4.8.8.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><math id="S5.T4.8.8.8.2.m1.1" class="ltx_Math" alttext="73.56" display="inline"><semantics id="S5.T4.8.8.8.2.m1.1a"><mn id="S5.T4.8.8.8.2.m1.1.1" xref="S5.T4.8.8.8.2.m1.1.1.cmml">73.56</mn><annotation-xml encoding="MathML-Content" id="S5.T4.8.8.8.2.m1.1b"><cn type="float" id="S5.T4.8.8.8.2.m1.1.1.cmml" xref="S5.T4.8.8.8.2.m1.1.1">73.56</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.8.8.2.m1.1c">73.56</annotation></semantics></math></td>
<td id="S5.T4.9.9.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><math id="S5.T4.9.9.9.3.m1.1" class="ltx_Math" alttext="64.82" display="inline"><semantics id="S5.T4.9.9.9.3.m1.1a"><mn id="S5.T4.9.9.9.3.m1.1.1" xref="S5.T4.9.9.9.3.m1.1.1.cmml">64.82</mn><annotation-xml encoding="MathML-Content" id="S5.T4.9.9.9.3.m1.1b"><cn type="float" id="S5.T4.9.9.9.3.m1.1.1.cmml" xref="S5.T4.9.9.9.3.m1.1.1">64.82</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.9.9.9.3.m1.1c">64.82</annotation></semantics></math></td>
<td id="S5.T4.10.10.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><math id="S5.T4.10.10.10.4.m1.1" class="ltx_Math" alttext="85.37" display="inline"><semantics id="S5.T4.10.10.10.4.m1.1a"><mn id="S5.T4.10.10.10.4.m1.1.1" xref="S5.T4.10.10.10.4.m1.1.1.cmml">85.37</mn><annotation-xml encoding="MathML-Content" id="S5.T4.10.10.10.4.m1.1b"><cn type="float" id="S5.T4.10.10.10.4.m1.1.1.cmml" xref="S5.T4.10.10.10.4.m1.1.1">85.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.10.10.10.4.m1.1c">85.37</annotation></semantics></math></td>
<td id="S5.T4.11.11.11.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><math id="S5.T4.11.11.11.5.m1.1" class="ltx_Math" alttext="76.08" display="inline"><semantics id="S5.T4.11.11.11.5.m1.1a"><mn id="S5.T4.11.11.11.5.m1.1.1" xref="S5.T4.11.11.11.5.m1.1.1.cmml">76.08</mn><annotation-xml encoding="MathML-Content" id="S5.T4.11.11.11.5.m1.1b"><cn type="float" id="S5.T4.11.11.11.5.m1.1.1.cmml" xref="S5.T4.11.11.11.5.m1.1.1">76.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.11.11.11.5.m1.1c">76.08</annotation></semantics></math></td>
<td id="S5.T4.12.12.12.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><math id="S5.T4.12.12.12.6.m1.1" class="ltx_Math" alttext="66.36" display="inline"><semantics id="S5.T4.12.12.12.6.m1.1a"><mn id="S5.T4.12.12.12.6.m1.1.1" xref="S5.T4.12.12.12.6.m1.1.1.cmml">66.36</mn><annotation-xml encoding="MathML-Content" id="S5.T4.12.12.12.6.m1.1b"><cn type="float" id="S5.T4.12.12.12.6.m1.1.1.cmml" xref="S5.T4.12.12.12.6.m1.1.1">66.36</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.12.12.12.6.m1.1c">66.36</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.14.1.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S5.T4.15.2" class="ltx_text" style="font-size:90%;">The average accuracy of the azimuth and elevation for the different number of bins.</span></figcaption>
</figure>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">AVD experiments</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">As mentioned earlier, the AVD dataset is a challenging dataset for pose estimation task; most of the images are either truncated or heavily occluded. The generated normal and re-shading features for these images are less accurate in comparison to the Pix3D, see Figure <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The fact that AVD has been densely sampled from different views, generates object poses that are less probable in the Pix3D, such as the back of the sofa. Figure <a href="#S4.F5" title="Figure 5 ‣ IV Active Vision Dataset Pose Labeling ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> is the map of two homes with the location and orientation of the camera. Since the predicted masks for AVD are of lower quality because of the mentioned challenges, we report the results for the Our_phase1 model. The model was trained on Pix3D and tested on AVD. We also evaluated the ResNet_baseline model performance on AVD to better show the generalizability of our model. Table <a href="#S5.T5" title="TABLE V ‣ V-D AVD experiments ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> shows the results. The proposed Ours_phase1 outperforms the other model with <math id="S5.SS4.p1.1.m1.1" class="ltx_Math" alttext="10.56\%" display="inline"><semantics id="S5.SS4.p1.1.m1.1a"><mrow id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mn id="S5.SS4.p1.1.m1.1.1.2" xref="S5.SS4.p1.1.m1.1.1.2.cmml">10.56</mn><mo id="S5.SS4.p1.1.m1.1.1.1" xref="S5.SS4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.SS4.p1.1.m1.1.1.2.cmml" xref="S5.SS4.p1.1.m1.1.1.2">10.56</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">10.56\%</annotation></semantics></math>. This shows the effectiveness and generalizability of mid-level features. In comparison to Pix3D, our model’s failures include objects in rare poses or cases of heavily occluded objects. Figure <a href="#S5.F8" title="Figure 8 ‣ V-D AVD experiments ‣ V Experiments ‣ Object Pose Estimation using Mid-level Visual Representations" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows some of the results on the AVD dataset.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2203.01449/assets/imgs/Picture1.jpg" id="S5.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="445" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S5.F8.4.2" class="ltx_text" style="font-size:90%;">Results on the challenging AVD dataset. This model is capable of estimating pose without any training on AVD data.</span></figcaption>
</figure>
<figure id="S5.T5" class="ltx_table">
<div id="S5.T5.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:304.9pt;height:68.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-8.0pt,1.8pt) scale(0.95,0.95) ;">
<table id="S5.T5.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.4.1.1.1" class="ltx_tr">
<th id="S5.T5.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Category</th>
<th id="S5.T5.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">bed</th>
<th id="S5.T5.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">chair</th>
<th id="S5.T5.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">desk</th>
<th id="S5.T5.4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">table</th>
<th id="S5.T5.4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">sofa</th>
<th id="S5.T5.4.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">mean</th>
</tr>
<tr id="S5.T5.4.1.2.2" class="ltx_tr">
<th id="S5.T5.4.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Total # samples</th>
<th id="S5.T5.4.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">338</th>
<th id="S5.T5.4.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">2026</th>
<th id="S5.T5.4.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">313</th>
<th id="S5.T5.4.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">1435</th>
<th id="S5.T5.4.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">2225</th>
<th id="S5.T5.4.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">6337</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.4.1.3.1" class="ltx_tr">
<td id="S5.T5.4.1.3.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">ResNet_baseline (%)</td>
<td id="S5.T5.4.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">13.31</td>
<td id="S5.T5.4.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">41.06</td>
<td id="S5.T5.4.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">25.88</td>
<td id="S5.T5.4.1.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">22.43</td>
<td id="S5.T5.4.1.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">44.04</td>
<td id="S5.T5.4.1.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">35.66</td>
</tr>
<tr id="S5.T5.4.1.4.2" class="ltx_tr">
<td id="S5.T5.4.1.4.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Ours_phase1 (%)</td>
<td id="S5.T5.4.1.4.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">23.08</td>
<td id="S5.T5.4.1.4.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">46.54</td>
<td id="S5.T5.4.1.4.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">45.04</td>
<td id="S5.T5.4.1.4.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">29.97</td>
<td id="S5.T5.4.1.4.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">60.43</td>
<td id="S5.T5.4.1.4.2.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">46.22</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.5.2.1" class="ltx_text" style="font-size:90%;">TABLE V</span>: </span><span id="S5.T5.2.1" class="ltx_text" style="font-size:90%;">Per category accuracy of two models on AVD dataset. The results are for 9 bins with <math id="S5.T5.2.1.m1.1" class="ltx_Math" alttext="2.5^{\circ}" display="inline"><semantics id="S5.T5.2.1.m1.1b"><msup id="S5.T5.2.1.m1.1.1" xref="S5.T5.2.1.m1.1.1.cmml"><mn id="S5.T5.2.1.m1.1.1.2" xref="S5.T5.2.1.m1.1.1.2.cmml">2.5</mn><mo id="S5.T5.2.1.m1.1.1.3" xref="S5.T5.2.1.m1.1.1.3.cmml">∘</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T5.2.1.m1.1c"><apply id="S5.T5.2.1.m1.1.1.cmml" xref="S5.T5.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T5.2.1.m1.1.1.1.cmml" xref="S5.T5.2.1.m1.1.1">superscript</csymbol><cn type="float" id="S5.T5.2.1.m1.1.1.2.cmml" xref="S5.T5.2.1.m1.1.1.2">2.5</cn><compose id="S5.T5.2.1.m1.1.1.3.cmml" xref="S5.T5.2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.1.m1.1d">2.5^{\circ}</annotation></semantics></math> overlap. </span></figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We present a novel object pose estimation approach built on the top of generic mid-level representations trained on computer vision proxy tasks
of surface normal estimation and reshading. The first stage is competitive with the state-of-the-art approaches that are trained on the Pix3D dataset. The second refinement via learned retrieval stage achieves superior performance compared to the state-of-the-art.
We also introduce a new pose estimation benchmark on the Active Vision Dataset and establish several new pose estimation baselines. We currently formulate the problem as classification and estimate only discretized azimuth and elevation angles. We plan to address the full 6 DOF pose estimation in the future. The performance of our approach is notably affected by the quality of the object masks, which deteriorates with challenging viewpoints and occlusions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">Phil Ammirato et al.
</span>
<span class="ltx_bibblock">“A dataset for developing and benchmarking active vision”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx1.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2017, pp. 1378–1385
</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">A. Avetisyan et al.
</span>
<span class="ltx_bibblock">“Scan2CAD: Learning CAD Model Alignment in RGBD Scans”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2019
</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">Angel X. Chang et al.
</span>
<span class="ltx_bibblock">“ShapeNet: An Information-Rich 3D Model Repository” cite arxiv:1512.03012, 2015
</span>
<span class="ltx_bibblock">URL: <a target="_blank" href="http://arxiv.org/abs/1512.03012" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1512.03012</a>
</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">Andreas Geiger, Philip Lenz and Raquel Urtasun
</span>
<span class="ltx_bibblock">“Are we ready for autonomous driving? the KITT vision benchmark suite”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx4.1.1" class="ltx_emph ltx_font_italic">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</em>, 2012, pp. 3354–3361
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">Georgia Gkioxari, Jitendra Malik and Justin Johnson
</span>
<span class="ltx_bibblock">“Mesh R-CNN”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx5.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2019, pp. 9784–9794
</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">Kaiming He, X. Zhang, Shaoqing Ren and Jian Sun
</span>
<span class="ltx_bibblock">“Deep Residual Learning for Image Recognition”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx6.1.1" class="ltx_emph ltx_font_italic">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2016, pp. 770–778
</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">Kaiming He, Georgia Gkioxari, Piotr Dollár and Ross B. Girshick
</span>
<span class="ltx_bibblock">“Mask R-CNN”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx7.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em> <span id="bib.bibx7.2.2" class="ltx_text ltx_font_bold">42</span>, 2020, pp. 386–397
</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">Stefan Hinterstoisser et al.
</span>
<span class="ltx_bibblock">“Model based training, detection and pose estimation of texture-less 3d objects in heavily cluttered scenes”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx8.1.1" class="ltx_emph ltx_font_italic">Asian conference on computer vision</em>, 2012, pp. 548–562
</span>
<span class="ltx_bibblock">Springer
</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">Tomás Hodan et al.
</span>
<span class="ltx_bibblock">“BOP: Benchmark for 6D Object Pose Estimation”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx9.1.1" class="ltx_emph ltx_font_italic">ArXiv</em> <span id="bib.bibx9.2.2" class="ltx_text ltx_font_bold">abs/1808.08319</span>, 2018
</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">Moos Hueting et al.
</span>
<span class="ltx_bibblock">“SeeThrough: finding chairs in heavily occluded indoor scene images”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx10.1.1" class="ltx_emph ltx_font_italic">CoRR abs/1710.10473</em>, 2017
</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">Wadim Kehl et al.
</span>
<span class="ltx_bibblock">“SSD-6D: Making RGB-based 3D detection and 6D pose estimation great again”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Computer Vision (ICCV 2017), Venice, Italy</em>, 2017, pp. 22–29
</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">Abhijit Kundu, Yin Li and James M Rehg
</span>
<span class="ltx_bibblock">“3D-RCNN: Instance-Level 3D Object Reconstruction via Render-and-Compare”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2018, pp. 3559–3568
</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">Vincent Lepetit, Francesc Moreno-Noguer and P. Fua
</span>
<span class="ltx_bibblock">“EPnP: An Accurate O(n) Solution to the PnP Problem”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx13.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em> <span id="bib.bibx13.2.2" class="ltx_text ltx_font_bold">81</span>, 2008, pp. 155–166
</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">Chi Li et al.
</span>
<span class="ltx_bibblock">“Deep supervision with shape concepts for occlusion-aware 3d object parsing”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2017
</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">Wei Liu et al.
</span>
<span class="ltx_bibblock">“SSD: Single shot multibox detector”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx15.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>, 2016, pp. 21–37
</span>
<span class="ltx_bibblock">Springer
</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">Siddharth Mahendran, Haider Ali and René Vidal
</span>
<span class="ltx_bibblock">“3D pose regression using convolutional neural networks”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx16.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Computer Vision</em> <span id="bib.bibx16.2.2" class="ltx_text ltx_font_bold">1</span>, 2017, pp. 4
</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">Arsalan Mousavian, Dragomir Anguelov, John Flynn and Jana Košecká
</span>
<span class="ltx_bibblock">“3d bounding box estimation using deep learning and geometry”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx17.1.1" class="ltx_emph ltx_font_italic">Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on</em>, 2017, pp. 5632–5640
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">Yinyu Nie et al.
</span>
<span class="ltx_bibblock">“Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes From a Single Image”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx18.1.1" class="ltx_emph ltx_font_italic">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020, pp. 52–61
</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">Georgios Pavlakos et al.
</span>
<span class="ltx_bibblock">“6-dof object pose from semantic keypoints”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx19.1.1" class="ltx_emph ltx_font_italic">Robotics and Automation (ICRA), 2017 IEEE International Conference on</em>, 2017, pp. 2011–2018
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">Patrick Poirson et al.
</span>
<span class="ltx_bibblock">“Fast single shot detection and pose estimation”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx20.1.1" class="ltx_emph ltx_font_italic">3D Vision (3DV), 2016 Fourth International Conference on</em>, 2016, pp. 676–684
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">Christoph Sager, Patrick Zschech and Niklas Kühl
</span>
<span class="ltx_bibblock">“labelCloud: A Lightweight Domain-Independent Labeling Tool for 3D Object Detection in Point Clouds”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx21.1.1" class="ltx_emph ltx_font_italic">ArXiv</em> <span id="bib.bibx21.2.2" class="ltx_text ltx_font_bold">abs/2103.04970</span>, 2021
</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">R.F. Salas-Moreno et al.
</span>
<span class="ltx_bibblock">“SLAM++: Simultaneous localisation and mapping at the level of objects”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2013
</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">Alexander Sax et al.
</span>
<span class="ltx_bibblock">“Mid-Level Visual Representations Improve Generalization and Sample Efficiency for Learning Visuomotor Policies.”, 2018
</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">S. Song, S. Lichtenberg and J. Xiao
</span>
<span class="ltx_bibblock">“SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2015
</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">Shuran Song and Jianxiong Xiao
</span>
<span class="ltx_bibblock">“Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images”, 2016
</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">Xingyuan Sun et al.
</span>
<span class="ltx_bibblock">“Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx26.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2018
</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">Bugra Tekin, Sudipta N Sinha and Pascal Fua
</span>
<span class="ltx_bibblock">“Real-Time Seamless Single Shot 6D Object Pose Prediction”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2018, pp. 292–301
</span>
</li>
<li id="bib.bibx28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">He Wang, Jingwei Huang Srinath Sridhar, Shuran Song Julien Valentin and Leonidas J. Guibas
</span>
<span class="ltx_bibblock">“Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2019
</span>
</li>
<li id="bib.bibx29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">Jiajun Wu et al.
</span>
<span class="ltx_bibblock">“MarrNet: 3D Shape Reconstruction via 2.5D Sketches”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx29.1.1" class="ltx_emph ltx_font_italic">Advances In Neural Information Processing Systems</em>, 2017
</span>
</li>
<li id="bib.bibx30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">Yu Xiang, Roozbeh Mottaghi and Silvio Savarese
</span>
<span class="ltx_bibblock">“Beyond pascal: A benchmark for 3d object detection in the wild”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx30.1.1" class="ltx_emph ltx_font_italic">Applications of Computer Vision (WACV), 2014 IEEE Winter Conference on</em>, 2014, pp. 75–82
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
<li id="bib.bibx31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">Yu Xiang et al.
</span>
<span class="ltx_bibblock">“ObjectNet3D: A Large Scale Database for 3D Object Recognition”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx31.1.1" class="ltx_emph ltx_font_italic">European Conference Computer Vision (ECCV)</em>, 2016
</span>
</li>
<li id="bib.bibx32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">Yu Xiang, Tanner Schmidt, Venkatraman Narayanan and Dieter Fox
</span>
<span class="ltx_bibblock">“Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.00199</em>, 2017
</span>
</li>
<li id="bib.bibx33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">Amir R. Zamir et al.
</span>
<span class="ltx_bibblock">“Taskonomy: Disentangling Task Transfer Learning”
</span>
<span class="ltx_bibblock">In <em id="bib.bibx33.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2018
</span>
<span class="ltx_bibblock">IEEE
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2203.01448" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2203.01449" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2203.01449">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2203.01449" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2203.01450" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 07:16:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
