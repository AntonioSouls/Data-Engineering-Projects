<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2005.10353] WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose</title><meta property="og:description" content="We present an end-to-end head-pose estimation network designed to predict Euler angles through the full range head yaws from a single RGB image. Existing methods perform well for frontal views but few target head pose â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2005.10353">

<!--Generated on Sat Mar  9 07:22:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\addauthor</span>
<p id="p1.2" class="ltx_p">Yijun Zhouyijun.zhou1@huawei.com1
<span id="p1.2.1" class="ltx_ERROR undefined">\addauthor</span>James Gregsonjames.gregson@huawei.com1
<span id="p1.2.2" class="ltx_ERROR undefined">\addinstitution</span>
IC Lab, Huawei Technologies Canada
<br class="ltx_break">
WHENet</p>
</div>
<h1 class="ltx_title ltx_title_document">WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">We present an end-to-end head-pose estimation network designed to predict Euler angles through the full range head yaws from a single RGB image. Existing methods perform well for frontal views but few target head pose from all viewpoints. This has applications in autonomous driving and retail. Our network builds on multi-loss approaches with changes to loss functions and training strategies adapted to wide range estimation. Additionally, we extract ground truth labelling of anterior views from a current panoptic dataset for the first time. The resulting Wide Headpose Estimation Network (WHENet) is the first fine-grained modern method applicable to the full-range of head yaws (hence wide) yet also meets or beats state-of-the-art methods for frontal head pose estimation. Our network is compact and efficient for mobile devices and applications. Code will be available at: <a target="_blank" href="https://github.com/Ascend-Research/HeadPoseEstimation-WHENet" title="" class="ltx_ref ltx_href">https://github.com/Ascend-Research/HeadPoseEstimation-WHENet</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Head pose estimation (HPE) is the task of estimating the orientation of heads from images or video (see FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) and has seen considerable research. Applications of HPE are wide-ranging and include (but are not limited to) virtual &amp; augmented-realityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx25" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2010)</a>]</cite>, driver assistance, markerless motion captureÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">deÂ FariasÂ Macedo etÂ al.(2013)deÂ FariasÂ Macedo, ApolinÃ¡rio, and dos
SantosÂ Souza</a>]</cite> or as an integral component of gaze-estimationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2008)</a>]</cite> since gaze and head pose are tightly linkedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">Langton etÂ al.(2004)Langton, Honeyman, and
Tessler</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The importance of HPE is well described inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2008)</a>]</cite>. They describe wide-ranging social interactions such as <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">mutual gaze</span>, <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">driver-pedestrian</span> &amp; <span id="S1.p2.1.3" class="ltx_text ltx_font_italic">driver-driver</span> interaction. It is also important in providing visual cues for the targets of conversation, to indicate appropriate times for speaker/listener role switches as well as to indicate agreementÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2008)</a>]</cite>. For systems to interact with people naturally, it is important to be sensitive to head pose.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Most HPE methods target frontal to profile poses since applications are plentiful, the face is feature-rich and training datasets are widely available. However, covering full range is useful in many areas including driver assistanceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">Murphy-Chutorian etÂ al.(2007)Murphy-Chutorian, Doshi, and
Trivedi</a>]</cite>, motion-capture and to generate attention maps for advertising and retailÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx37" title="" class="ltx_ref">Siriteerakul(2012)</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2005.10353/assets/x1.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="531" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The WHENet full-range head pose estimation network (center) refinesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> by combining an EfficientNet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">Tan and Le(2019)</a>]</cite> backbone with classification and regression losses on each of pitch, yaw and roll. A new <span id="S1.F1.2.1" class="ltx_text ltx_font_italic">wrapped-loss</span> stabilizes the network at large yaws. Training this network using anterior views repurposed fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite> (lower-left) via a novel reprocessing procedure allows WHENet to predict head poses from anterior view as well as heads featuring heavy occlusions, fashion accessories and adverse lighting (right) with a mobile-friendly model. In spite of this, WHENet is as accurate or more accurate than existing state-of-the-art methods that are constrained to frontal or profile views. Some images are fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>&amp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx41" title="" class="ltx_ref">Vu etÂ al.(2015)Vu, Osokin, and Laptev</a>]</cite></figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Furthermore, though methods such asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>, <a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite> perform well, they may be prohibitively large networks for mobile and embedded platforms. This is especially important in autonomous driving where many subsystems must operate concurrently.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Based on these criteria, we developed the Wide Headpose Estimation Network (WHENet) which extends head-pose estimation to the full range of yaws (hence <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">wide</span>) using a mobile-friendly architecture. In doing so, we make the following contributions:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We introduce a <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">wrapped loss</span> that significantly improves yaw accuracy for anterior views in full-range HPE.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We detail an automated labeling process for the CMU Panoptic DatasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite> allowing it to be used for training and validation data in full-range HPE.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We extend our modified network (WHENet) to the full range of yaws where it achieves state-of-the-art performance for full-range HPE  and within 1.8% of state-of-the-art for narrow range HPE despite being trained for another task.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.2" class="ltx_p">We demonstrate that simple modifications to HopeNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> can achieve <math id="S1.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="29\%" display="inline"><semantics id="S1.I1.i4.p1.1.m1.1a"><mrow id="S1.I1.i4.p1.1.m1.1.1" xref="S1.I1.i4.p1.1.m1.1.1.cmml"><mn id="S1.I1.i4.p1.1.m1.1.1.2" xref="S1.I1.i4.p1.1.m1.1.1.2.cmml">29</mn><mo id="S1.I1.i4.p1.1.m1.1.1.1" xref="S1.I1.i4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i4.p1.1.m1.1b"><apply id="S1.I1.i4.p1.1.m1.1.1.cmml" xref="S1.I1.i4.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i4.p1.1.m1.1.1.1.cmml" xref="S1.I1.i4.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.I1.i4.p1.1.m1.1.1.2.cmml" xref="S1.I1.i4.p1.1.m1.1.1.2">29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i4.p1.1.m1.1c">29\%</annotation></semantics></math> improvement over the original network and <math id="S1.I1.i4.p1.2.m2.1" class="ltx_Math" alttext="5-13\%" display="inline"><semantics id="S1.I1.i4.p1.2.m2.1a"><mrow id="S1.I1.i4.p1.2.m2.1.1" xref="S1.I1.i4.p1.2.m2.1.1.cmml"><mn id="S1.I1.i4.p1.2.m2.1.1.2" xref="S1.I1.i4.p1.2.m2.1.1.2.cmml">5</mn><mo id="S1.I1.i4.p1.2.m2.1.1.1" xref="S1.I1.i4.p1.2.m2.1.1.1.cmml">âˆ’</mo><mrow id="S1.I1.i4.p1.2.m2.1.1.3" xref="S1.I1.i4.p1.2.m2.1.1.3.cmml"><mn id="S1.I1.i4.p1.2.m2.1.1.3.2" xref="S1.I1.i4.p1.2.m2.1.1.3.2.cmml">13</mn><mo id="S1.I1.i4.p1.2.m2.1.1.3.1" xref="S1.I1.i4.p1.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i4.p1.2.m2.1b"><apply id="S1.I1.i4.p1.2.m2.1.1.cmml" xref="S1.I1.i4.p1.2.m2.1.1"><minus id="S1.I1.i4.p1.2.m2.1.1.1.cmml" xref="S1.I1.i4.p1.2.m2.1.1.1"></minus><cn type="integer" id="S1.I1.i4.p1.2.m2.1.1.2.cmml" xref="S1.I1.i4.p1.2.m2.1.1.2">5</cn><apply id="S1.I1.i4.p1.2.m2.1.1.3.cmml" xref="S1.I1.i4.p1.2.m2.1.1.3"><csymbol cd="latexml" id="S1.I1.i4.p1.2.m2.1.1.3.1.cmml" xref="S1.I1.i4.p1.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S1.I1.i4.p1.2.m2.1.1.3.2.cmml" xref="S1.I1.i4.p1.2.m2.1.1.3.2">13</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i4.p1.2.m2.1c">5-13\%</annotation></semantics></math> improvement over the current state-of-the-art FSANetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite> for narrow range HPE from RGB images in the AFLW2000Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> and BIWIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite> datasets.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background &amp; Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Head pose estimation has been actively researched over the past 25 years. Approaches up to 2008 are well surveyed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2008)</a>]</cite> and much of our discussion on early methods follows their work. Due to the breadth of research activity and our target application of HPE from monocular RGB images, we exclude multi-view or active sensing methods from this review.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Classical methods</span> include template matching and cascaded detectors. Template matching compares input images with a set of labeled templates and assign a pose based on nearby matchesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx36" title="" class="ltx_ref">Sherrah etÂ al.(1999)Sherrah, Gong, and Ong</a>, <a href="#bib.bibx27" title="" class="ltx_ref">Ng and Gong(2002)</a>]</cite>. They can have difficulty differentiating between identity and pose similarityÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2008)</a>]</cite>. Cascaded detectors train distinct detectors that also localize heads for each (discretized) pose. Challenges include prediction resolution and resolving when multiple detectors fireÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Murphy-Chutorian and Trivedi(2008)</a>]</cite>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Geometric &amp; deformable models</span> are similar methodologies. Geometric models use features, e.g. facial keypoints, from the input images and analytically determine the matching head pose using a static templateÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Burger etÂ al.(2014)Burger, Rothbucher, and Diepold</a>]</cite>. The majority of their complexity lies in detecting the features, which is itself a well studied problem, see e.g.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx39" title="" class="ltx_ref">Sun etÂ al.(2013)Sun, Wang, and Tang</a>, <a href="#bib.bibx16" title="" class="ltx_ref">Herpers etÂ al.(1996)Herpers, Michaelis, Lichtenauer, and
Sommer</a>]</cite> and surveyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx42" title="" class="ltx_ref">Wang etÂ al.(2018)Wang, Gao, Tao, Yang, and Li</a>]</cite>. Deformable models are similar but allow the template to deform to match subject-specific head features. Pose or other information is obtained from the deformed modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx49" title="" class="ltx_ref">Yu etÂ al.(2013)Yu, Huang, Zhang, Yan, and Metaxas</a>, <a href="#bib.bibx8" title="" class="ltx_ref">Cai etÂ al.(2010)Cai, Gallup, Zhang, and Zhang</a>, <a href="#bib.bibx46" title="" class="ltx_ref">Yang and Zhang(2002)</a>, <a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Regression &amp; classification methods</span> serve as supersets or components of most other methods. Regression methods use or fit a mathematical model to directly predict pose based on labeled training data. The formulation of the regressor is wide-ranging and includes principle component analysisÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx52" title="" class="ltx_ref">Zhu and Fujimura(2004)</a>, <a href="#bib.bibx38" title="" class="ltx_ref">Srinivasan and Boyer(2002)</a>]</cite> and neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>, <a href="#bib.bibx23" title="" class="ltx_ref">Mukherjee and Robertson(2015)</a>]</cite> among others. In contrast, classification methods predict pose from a discretized set of poses. Prediction resolution tends to be lower, generally less than 10-12 discrete poses. Methods include decision trees &amp; random forestsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">Benfold and Reid(2008)</a>, <a href="#bib.bibx11" title="" class="ltx_ref">Fanelli etÂ al.(2011)Fanelli, Gall, and VanÂ Gool</a>]</cite>, multi-task learningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx44" title="" class="ltx_ref">Yan etÂ al.(2013)Yan, Ricci, Subramanian, Lanz, and Sebe</a>, <a href="#bib.bibx45" title="" class="ltx_ref">Yan etÂ al.(2015)Yan, Ricci, Subramanian, Liu, Lanz, and
Sebe</a>]</cite> and neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>, <a href="#bib.bibx23" title="" class="ltx_ref">Mukherjee and Robertson(2015)</a>]</cite>. Our networks are most similar to the multi-loss framework inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> which uses classification and regression objectives. Other works employ soft stage-wise regressionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx47" title="" class="ltx_ref">Yang etÂ al.(2018)Yang, Huang, Lin, Hsiu, and Chuang</a>, <a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite> by training with both classification and regression objectives at multiple scales.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Multi-tasks methods</span> combines the head pose estimation problem with other facial analysis problems. Studies<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">Chen etÂ al.(2014)Chen, Ren, Wei, Cao, and Sun</a>, <a href="#bib.bibx50" title="" class="ltx_ref">Zhu and Ramanan(2012)</a>, <a href="#bib.bibx29" title="" class="ltx_ref">Ranjan etÂ al.(2017a)Ranjan, Patel, and
Chellappa</a>, <a href="#bib.bibx30" title="" class="ltx_ref">Ranjan etÂ al.(2017b)Ranjan, Sankaranarayanan, Castillo,
and Chellappa</a>]</cite> show that learning related tasks at the same time can achieve better performance than training tasks individually. For instance, inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">Ranjan etÂ al.(2017a)Ranjan, Patel, and
Chellappa</a>, <a href="#bib.bibx30" title="" class="ltx_ref">Ranjan etÂ al.(2017b)Ranjan, Sankaranarayanan, Castillo,
and Chellappa</a>]</cite> face detection and pose regression are trained jointly.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p"><span id="S2.p6.1.1" class="ltx_text ltx_font_bold">Full-range methods</span> are much less common than narrow-range since most existing datasets for HPE focus on frontal to profile views. Recent methods includeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">Raza etÂ al.(2018)Raza, Chen, Rehman, Wang, and
Bao</a>, <a href="#bib.bibx15" title="" class="ltx_ref">Heo etÂ al.(2019)Heo, Nam, and Ko</a>, <a href="#bib.bibx32" title="" class="ltx_ref">Rehder etÂ al.(2014)Rehder, Kloeden, and Stiller</a>]</cite> which classify poses into coarsely-grained bins/classes to determine yaw. Unlike our method, pitch and roll are not predicted inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">Raza etÂ al.(2018)Raza, Chen, Rehman, Wang, and
Bao</a>, <a href="#bib.bibx15" title="" class="ltx_ref">Heo etÂ al.(2019)Heo, Nam, and Ko</a>, <a href="#bib.bibx32" title="" class="ltx_ref">Rehder etÂ al.(2014)Rehder, Kloeden, and Stiller</a>]</cite>.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p"><span id="S2.p7.1.1" class="ltx_text ltx_font_bold">Datasets</span> for facial pose include BIWIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite>, AFLW2000<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> and 300W-LPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>. Both AFLW2000 and 300W-LP use a morphable model fit to faces under large pose variation and report Euler angles. 300W-LP generates additional synthetic views to enlarge the dataset. More recently, the UMD Faces<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">Bansal etÂ al.(2017)Bansal, Nanduri, Castillo, Ranjan, and
Chellappa</a>]</cite> and Pandora<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">Borghi etÂ al.(2017)Borghi, Venturelli, Vezzani, and
Cucchiara</a>]</cite> datasets provide a range of data labels, including head pose. A disadvantage for our application is that they do not cover the full-range of head poses but only frontal-to-profile views.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">Very important to our method is the CMU Panoptic DatasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite>. It captures subjects from an abundance of calibrated cameras covering a full-hemisphere and provides facial landmarks in 3D. Using this data, we are able to estimate head pose from near-frontal views and use this pose to label non-frontal viewpoints. By doing so, we cover the full range of camera-relative poses, allowing our method to be trained with anterior views. This is discussed further in SectionÂ <a href="#S4" title="4 Datasets &amp; Training â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a></p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Our Method</h2>

<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2005.10353/assets/images/full_range_images_2.png" id="S3.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="228" height="90" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2005.10353/assets/images/wrapped_loss_figure_2.png" id="S3.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="228" height="99" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F2.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2005.10353/assets/images/dome_processing_2.png" id="S3.F2.3.g1" class="ltx_graphics ltx_img_square" width="102" height="102" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Head pose (a) is parameterized by pitch (red-axis), yaw (green-axis) and roll (blue-axis) angles in indicated directions.
Our proposed wrapped loss function (b-left) avoids over-penalizing predictions <math id="S3.F2.6.m1.1" class="ltx_Math" alttext="&gt;180^{\circ}" display="inline"><semantics id="S3.F2.6.m1.1b"><mrow id="S3.F2.6.m1.1.1" xref="S3.F2.6.m1.1.1.cmml"><mi id="S3.F2.6.m1.1.1.2" xref="S3.F2.6.m1.1.1.2.cmml"></mi><mo id="S3.F2.6.m1.1.1.1" xref="S3.F2.6.m1.1.1.1.cmml">&gt;</mo><msup id="S3.F2.6.m1.1.1.3" xref="S3.F2.6.m1.1.1.3.cmml"><mn id="S3.F2.6.m1.1.1.3.2" xref="S3.F2.6.m1.1.1.3.2.cmml">180</mn><mo id="S3.F2.6.m1.1.1.3.3" xref="S3.F2.6.m1.1.1.3.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.6.m1.1c"><apply id="S3.F2.6.m1.1.1.cmml" xref="S3.F2.6.m1.1.1"><gt id="S3.F2.6.m1.1.1.1.cmml" xref="S3.F2.6.m1.1.1.1"></gt><csymbol cd="latexml" id="S3.F2.6.m1.1.1.2.cmml" xref="S3.F2.6.m1.1.1.2">absent</csymbol><apply id="S3.F2.6.m1.1.1.3.cmml" xref="S3.F2.6.m1.1.1.3"><csymbol cd="ambiguous" id="S3.F2.6.m1.1.1.3.1.cmml" xref="S3.F2.6.m1.1.1.3">superscript</csymbol><cn type="integer" id="S3.F2.6.m1.1.1.3.2.cmml" xref="S3.F2.6.m1.1.1.3.2">180</cn><compose id="S3.F2.6.m1.1.1.3.3.cmml" xref="S3.F2.6.m1.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.6.m1.1d">&gt;180^{\circ}</annotation></semantics></math> from true where pose is similar but MSE produces extreme loss values. This improves predictions when subjects face away from camera (b-right) where networks trained with MSE have errors approaching <math id="S3.F2.7.m2.1" class="ltx_Math" alttext="180^{\circ}" display="inline"><semantics id="S3.F2.7.m2.1b"><msup id="S3.F2.7.m2.1.1" xref="S3.F2.7.m2.1.1.cmml"><mn id="S3.F2.7.m2.1.1.2" xref="S3.F2.7.m2.1.1.2.cmml">180</mn><mo id="S3.F2.7.m2.1.1.3" xref="S3.F2.7.m2.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S3.F2.7.m2.1c"><apply id="S3.F2.7.m2.1.1.cmml" xref="S3.F2.7.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.7.m2.1.1.1.cmml" xref="S3.F2.7.m2.1.1">superscript</csymbol><cn type="integer" id="S3.F2.7.m2.1.1.2.cmml" xref="S3.F2.7.m2.1.1.2">180</cn><compose id="S3.F2.7.m2.1.1.3.cmml" xref="S3.F2.7.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.7.m2.1d">180^{\circ}</annotation></semantics></math> for yaw. Note the x (red) axis should align with the left ear of subjects. In (c), we compute virtual camera extrinsics oriented to provide a frontal view along with true extrinsics to extract Euler angles from the CMU Panoptic datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite>. This allows us to automatically label tens of thousands of anterior view images for the full-range HPE task. We believe we are the first to do so.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our network design is derived from the multi-loss framework of Ruiz et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite>. They combine a convolutional backbone with separate fully-connected networks that classify each of pitch, yaw and roll into <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="3^{\circ}" display="inline"><semantics id="S3.p1.1.m1.1a"><msup id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mn id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">3</mn><mo id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">3</cn><compose id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">3^{\circ}</annotation></semantics></math> bins using softmax with a cross-entropy loss. A mean squared error (MSE) regression loss is also applied between the ground-truth labels and the expected value of the softmax output. The two losses are weighted to produce the final training objective for each angle.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">InÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite>, Ruiz <em id="S3.p2.1.1" class="ltx_emph ltx_font_italic">et al</em><span id="S3.p2.1.2" class="ltx_ERROR undefined">\bmvaOneDot</span>suggest that this combination of losses gives the resulting network robustness &amp; stability due to the softmax &amp; cross-entropy loss while still providing fine-grained supervision and output via the regression loss.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.5" class="ltx_p">We adopt this overall framework fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> but make substitutions for both loss functions in order to adapt the method to full-range. To our knowledge we are the first to do so. Yaw prediction is divided into 120 <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="3^{\circ}" display="inline"><semantics id="S3.p3.1.m1.1a"><msup id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mn id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">3</mn><mo id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">3</cn><compose id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">3^{\circ}</annotation></semantics></math> bins covering the full range of yaws <math id="S3.p3.2.m2.2" class="ltx_Math" alttext="(-180^{\circ},180^{\circ}]" display="inline"><semantics id="S3.p3.2.m2.2a"><mrow id="S3.p3.2.m2.2.2.2" xref="S3.p3.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.p3.2.m2.2.2.2.3" xref="S3.p3.2.m2.2.2.3.cmml">(</mo><mrow id="S3.p3.2.m2.1.1.1.1" xref="S3.p3.2.m2.1.1.1.1.cmml"><mo id="S3.p3.2.m2.1.1.1.1a" xref="S3.p3.2.m2.1.1.1.1.cmml">âˆ’</mo><msup id="S3.p3.2.m2.1.1.1.1.2" xref="S3.p3.2.m2.1.1.1.1.2.cmml"><mn id="S3.p3.2.m2.1.1.1.1.2.2" xref="S3.p3.2.m2.1.1.1.1.2.2.cmml">180</mn><mo id="S3.p3.2.m2.1.1.1.1.2.3" xref="S3.p3.2.m2.1.1.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><mo id="S3.p3.2.m2.2.2.2.4" xref="S3.p3.2.m2.2.2.3.cmml">,</mo><msup id="S3.p3.2.m2.2.2.2.2" xref="S3.p3.2.m2.2.2.2.2.cmml"><mn id="S3.p3.2.m2.2.2.2.2.2" xref="S3.p3.2.m2.2.2.2.2.2.cmml">180</mn><mo id="S3.p3.2.m2.2.2.2.2.3" xref="S3.p3.2.m2.2.2.2.2.3.cmml">âˆ˜</mo></msup><mo stretchy="false" id="S3.p3.2.m2.2.2.2.5" xref="S3.p3.2.m2.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.2b"><interval closure="open-closed" id="S3.p3.2.m2.2.2.3.cmml" xref="S3.p3.2.m2.2.2.2"><apply id="S3.p3.2.m2.1.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1.1"><minus id="S3.p3.2.m2.1.1.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1.1"></minus><apply id="S3.p3.2.m2.1.1.1.1.2.cmml" xref="S3.p3.2.m2.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.p3.2.m2.1.1.1.1.2.1.cmml" xref="S3.p3.2.m2.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S3.p3.2.m2.1.1.1.1.2.2.cmml" xref="S3.p3.2.m2.1.1.1.1.2.2">180</cn><compose id="S3.p3.2.m2.1.1.1.1.2.3.cmml" xref="S3.p3.2.m2.1.1.1.1.2.3"></compose></apply></apply><apply id="S3.p3.2.m2.2.2.2.2.cmml" xref="S3.p3.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p3.2.m2.2.2.2.2.1.cmml" xref="S3.p3.2.m2.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.p3.2.m2.2.2.2.2.2.cmml" xref="S3.p3.2.m2.2.2.2.2.2">180</cn><compose id="S3.p3.2.m2.2.2.2.2.3.cmml" xref="S3.p3.2.m2.2.2.2.2.3"></compose></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.2c">(-180^{\circ},180^{\circ}]</annotation></semantics></math>. Pitch and roll predictions are each made from 66 <math id="S3.p3.3.m3.1" class="ltx_Math" alttext="3^{\circ}" display="inline"><semantics id="S3.p3.3.m3.1a"><msup id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mn id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2.cmml">3</mn><mo id="S3.p3.3.m3.1.1.3" xref="S3.p3.3.m3.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1">superscript</csymbol><cn type="integer" id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">3</cn><compose id="S3.p3.3.m3.1.1.3.cmml" xref="S3.p3.3.m3.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">3^{\circ}</annotation></semantics></math> bins covering the range <math id="S3.p3.4.m4.2" class="ltx_Math" alttext="[-99^{\circ},99^{\circ}]" display="inline"><semantics id="S3.p3.4.m4.2a"><mrow id="S3.p3.4.m4.2.2.2" xref="S3.p3.4.m4.2.2.3.cmml"><mo stretchy="false" id="S3.p3.4.m4.2.2.2.3" xref="S3.p3.4.m4.2.2.3.cmml">[</mo><mrow id="S3.p3.4.m4.1.1.1.1" xref="S3.p3.4.m4.1.1.1.1.cmml"><mo id="S3.p3.4.m4.1.1.1.1a" xref="S3.p3.4.m4.1.1.1.1.cmml">âˆ’</mo><msup id="S3.p3.4.m4.1.1.1.1.2" xref="S3.p3.4.m4.1.1.1.1.2.cmml"><mn id="S3.p3.4.m4.1.1.1.1.2.2" xref="S3.p3.4.m4.1.1.1.1.2.2.cmml">99</mn><mo id="S3.p3.4.m4.1.1.1.1.2.3" xref="S3.p3.4.m4.1.1.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><mo id="S3.p3.4.m4.2.2.2.4" xref="S3.p3.4.m4.2.2.3.cmml">,</mo><msup id="S3.p3.4.m4.2.2.2.2" xref="S3.p3.4.m4.2.2.2.2.cmml"><mn id="S3.p3.4.m4.2.2.2.2.2" xref="S3.p3.4.m4.2.2.2.2.2.cmml">99</mn><mo id="S3.p3.4.m4.2.2.2.2.3" xref="S3.p3.4.m4.2.2.2.2.3.cmml">âˆ˜</mo></msup><mo stretchy="false" id="S3.p3.4.m4.2.2.2.5" xref="S3.p3.4.m4.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.2b"><interval closure="closed" id="S3.p3.4.m4.2.2.3.cmml" xref="S3.p3.4.m4.2.2.2"><apply id="S3.p3.4.m4.1.1.1.1.cmml" xref="S3.p3.4.m4.1.1.1.1"><minus id="S3.p3.4.m4.1.1.1.1.1.cmml" xref="S3.p3.4.m4.1.1.1.1"></minus><apply id="S3.p3.4.m4.1.1.1.1.2.cmml" xref="S3.p3.4.m4.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.p3.4.m4.1.1.1.1.2.1.cmml" xref="S3.p3.4.m4.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S3.p3.4.m4.1.1.1.1.2.2.cmml" xref="S3.p3.4.m4.1.1.1.1.2.2">99</cn><compose id="S3.p3.4.m4.1.1.1.1.2.3.cmml" xref="S3.p3.4.m4.1.1.1.1.2.3"></compose></apply></apply><apply id="S3.p3.4.m4.2.2.2.2.cmml" xref="S3.p3.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S3.p3.4.m4.2.2.2.2.1.cmml" xref="S3.p3.4.m4.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.p3.4.m4.2.2.2.2.2.cmml" xref="S3.p3.4.m4.2.2.2.2.2">99</cn><compose id="S3.p3.4.m4.2.2.2.2.3.cmml" xref="S3.p3.4.m4.2.2.2.2.3"></compose></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.2c">[-99^{\circ},99^{\circ}]</annotation></semantics></math>, although only the bins from <math id="S3.p3.5.m5.2" class="ltx_Math" alttext="[-90,90]" display="inline"><semantics id="S3.p3.5.m5.2a"><mrow id="S3.p3.5.m5.2.2.1" xref="S3.p3.5.m5.2.2.2.cmml"><mo stretchy="false" id="S3.p3.5.m5.2.2.1.2" xref="S3.p3.5.m5.2.2.2.cmml">[</mo><mrow id="S3.p3.5.m5.2.2.1.1" xref="S3.p3.5.m5.2.2.1.1.cmml"><mo id="S3.p3.5.m5.2.2.1.1a" xref="S3.p3.5.m5.2.2.1.1.cmml">âˆ’</mo><mn id="S3.p3.5.m5.2.2.1.1.2" xref="S3.p3.5.m5.2.2.1.1.2.cmml">90</mn></mrow><mo id="S3.p3.5.m5.2.2.1.3" xref="S3.p3.5.m5.2.2.2.cmml">,</mo><mn id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml">90</mn><mo stretchy="false" id="S3.p3.5.m5.2.2.1.4" xref="S3.p3.5.m5.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.2b"><interval closure="closed" id="S3.p3.5.m5.2.2.2.cmml" xref="S3.p3.5.m5.2.2.1"><apply id="S3.p3.5.m5.2.2.1.1.cmml" xref="S3.p3.5.m5.2.2.1.1"><minus id="S3.p3.5.m5.2.2.1.1.1.cmml" xref="S3.p3.5.m5.2.2.1.1"></minus><cn type="integer" id="S3.p3.5.m5.2.2.1.1.2.cmml" xref="S3.p3.5.m5.2.2.1.1.2">90</cn></apply><cn type="integer" id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1">90</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.2c">[-90,90]</annotation></semantics></math> are ultimately used. The regression and classification losses for each of pitch, yaw and roll are combined via:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\mathcal{L}=\alpha\mathcal{L}_{reg}+\beta\mathcal{L}_{cls}" display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">â„’</mi><mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2" xref="S3.E1.m1.1.1.3.2.2.cmml">Î±</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.2.1" xref="S3.E1.m1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.3.2.3.2.cmml">â„’</mi><mrow id="S3.E1.m1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.3.2.3.3.cmml"><mi id="S3.E1.m1.1.1.3.2.3.3.2" xref="S3.E1.m1.1.1.3.2.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.2.3.3.1" xref="S3.E1.m1.1.1.3.2.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.2.3.3.3" xref="S3.E1.m1.1.1.3.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.2.3.3.1a" xref="S3.E1.m1.1.1.3.2.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.2.3.3.4" xref="S3.E1.m1.1.1.3.2.3.3.4.cmml">g</mi></mrow></msub></mrow><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml">Î²</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.1" xref="S3.E1.m1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.3.3.3.2.cmml">â„’</mi><mrow id="S3.E1.m1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.3.3.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.3.3.2" xref="S3.E1.m1.1.1.3.3.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.3.1" xref="S3.E1.m1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.3.3" xref="S3.E1.m1.1.1.3.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.3.3.3.3.1a" xref="S3.E1.m1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.3.3.3.3.4" xref="S3.E1.m1.1.1.3.3.3.3.4.cmml">s</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"></eq><ci id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2">â„’</ci><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><plus id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><times id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2.1"></times><ci id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2">ğ›¼</ci><apply id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.3.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.3.2.3.2">â„’</ci><apply id="S3.E1.m1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.3.2.3.3"><times id="S3.E1.m1.1.1.3.2.3.3.1.cmml" xref="S3.E1.m1.1.1.3.2.3.3.1"></times><ci id="S3.E1.m1.1.1.3.2.3.3.2.cmml" xref="S3.E1.m1.1.1.3.2.3.3.2">ğ‘Ÿ</ci><ci id="S3.E1.m1.1.1.3.2.3.3.3.cmml" xref="S3.E1.m1.1.1.3.2.3.3.3">ğ‘’</ci><ci id="S3.E1.m1.1.1.3.2.3.3.4.cmml" xref="S3.E1.m1.1.1.3.2.3.3.4">ğ‘”</ci></apply></apply></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><times id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2">ğ›½</ci><apply id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.3.2">â„’</ci><apply id="S3.E1.m1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3.3"><times id="S3.E1.m1.1.1.3.3.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3.3.3.1"></times><ci id="S3.E1.m1.1.1.3.3.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.3.3.2">ğ‘</ci><ci id="S3.E1.m1.1.1.3.3.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3.3.3">ğ‘™</ci><ci id="S3.E1.m1.1.1.3.3.3.3.4.cmml" xref="S3.E1.m1.1.1.3.3.3.3.4">ğ‘ </ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\mathcal{L}=\alpha\mathcal{L}_{reg}+\beta\mathcal{L}_{cls}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p3.9" class="ltx_p">Here <math id="S3.p3.6.m1.1" class="ltx_Math" alttext="\mathcal{L}_{cls}" display="inline"><semantics id="S3.p3.6.m1.1a"><msub id="S3.p3.6.m1.1.1" xref="S3.p3.6.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p3.6.m1.1.1.2" xref="S3.p3.6.m1.1.1.2.cmml">â„’</mi><mrow id="S3.p3.6.m1.1.1.3" xref="S3.p3.6.m1.1.1.3.cmml"><mi id="S3.p3.6.m1.1.1.3.2" xref="S3.p3.6.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.p3.6.m1.1.1.3.1" xref="S3.p3.6.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p3.6.m1.1.1.3.3" xref="S3.p3.6.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.p3.6.m1.1.1.3.1a" xref="S3.p3.6.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p3.6.m1.1.1.3.4" xref="S3.p3.6.m1.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p3.6.m1.1b"><apply id="S3.p3.6.m1.1.1.cmml" xref="S3.p3.6.m1.1.1"><csymbol cd="ambiguous" id="S3.p3.6.m1.1.1.1.cmml" xref="S3.p3.6.m1.1.1">subscript</csymbol><ci id="S3.p3.6.m1.1.1.2.cmml" xref="S3.p3.6.m1.1.1.2">â„’</ci><apply id="S3.p3.6.m1.1.1.3.cmml" xref="S3.p3.6.m1.1.1.3"><times id="S3.p3.6.m1.1.1.3.1.cmml" xref="S3.p3.6.m1.1.1.3.1"></times><ci id="S3.p3.6.m1.1.1.3.2.cmml" xref="S3.p3.6.m1.1.1.3.2">ğ‘</ci><ci id="S3.p3.6.m1.1.1.3.3.cmml" xref="S3.p3.6.m1.1.1.3.3">ğ‘™</ci><ci id="S3.p3.6.m1.1.1.3.4.cmml" xref="S3.p3.6.m1.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.6.m1.1c">\mathcal{L}_{cls}</annotation></semantics></math> is the classification loss and <math id="S3.p3.7.m2.1" class="ltx_Math" alttext="\mathcal{L}_{reg}" display="inline"><semantics id="S3.p3.7.m2.1a"><msub id="S3.p3.7.m2.1.1" xref="S3.p3.7.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p3.7.m2.1.1.2" xref="S3.p3.7.m2.1.1.2.cmml">â„’</mi><mrow id="S3.p3.7.m2.1.1.3" xref="S3.p3.7.m2.1.1.3.cmml"><mi id="S3.p3.7.m2.1.1.3.2" xref="S3.p3.7.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.p3.7.m2.1.1.3.1" xref="S3.p3.7.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.p3.7.m2.1.1.3.3" xref="S3.p3.7.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.p3.7.m2.1.1.3.1a" xref="S3.p3.7.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.p3.7.m2.1.1.3.4" xref="S3.p3.7.m2.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p3.7.m2.1b"><apply id="S3.p3.7.m2.1.1.cmml" xref="S3.p3.7.m2.1.1"><csymbol cd="ambiguous" id="S3.p3.7.m2.1.1.1.cmml" xref="S3.p3.7.m2.1.1">subscript</csymbol><ci id="S3.p3.7.m2.1.1.2.cmml" xref="S3.p3.7.m2.1.1.2">â„’</ci><apply id="S3.p3.7.m2.1.1.3.cmml" xref="S3.p3.7.m2.1.1.3"><times id="S3.p3.7.m2.1.1.3.1.cmml" xref="S3.p3.7.m2.1.1.3.1"></times><ci id="S3.p3.7.m2.1.1.3.2.cmml" xref="S3.p3.7.m2.1.1.3.2">ğ‘Ÿ</ci><ci id="S3.p3.7.m2.1.1.3.3.cmml" xref="S3.p3.7.m2.1.1.3.3">ğ‘’</ci><ci id="S3.p3.7.m2.1.1.3.4.cmml" xref="S3.p3.7.m2.1.1.3.4">ğ‘”</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.7.m2.1c">\mathcal{L}_{reg}</annotation></semantics></math> is the regression loss while <math id="S3.p3.8.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.p3.8.m3.1a"><mi id="S3.p3.8.m3.1.1" xref="S3.p3.8.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S3.p3.8.m3.1b"><ci id="S3.p3.8.m3.1.1.cmml" xref="S3.p3.8.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.8.m3.1c">\alpha</annotation></semantics></math> and <math id="S3.p3.9.m4.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.p3.9.m4.1a"><mi id="S3.p3.9.m4.1.1" xref="S3.p3.9.m4.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S3.p3.9.m4.1b"><ci id="S3.p3.9.m4.1.1.cmml" xref="S3.p3.9.m4.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.9.m4.1c">\beta</annotation></semantics></math> trade off the influence of one with respect to the other.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">We tested different classification losses and chose a sigmoid activation with binary cross-entropy for <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{cls}" display="inline"><semantics id="S3.p4.1.m1.1a"><msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">â„’</mi><mrow id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml"><mi id="S3.p4.1.m1.1.1.3.2" xref="S3.p4.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.p4.1.m1.1.1.3.1" xref="S3.p4.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p4.1.m1.1.1.3.3" xref="S3.p4.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.p4.1.m1.1.1.3.1a" xref="S3.p4.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p4.1.m1.1.1.3.4" xref="S3.p4.1.m1.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">â„’</ci><apply id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3"><times id="S3.p4.1.m1.1.1.3.1.cmml" xref="S3.p4.1.m1.1.1.3.1"></times><ci id="S3.p4.1.m1.1.1.3.2.cmml" xref="S3.p4.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.p4.1.m1.1.1.3.3.cmml" xref="S3.p4.1.m1.1.1.3.3">ğ‘™</ci><ci id="S3.p4.1.m1.1.1.3.4.cmml" xref="S3.p4.1.m1.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\mathcal{L}_{cls}</annotation></semantics></math>. This differs fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> and shows marginally improved accuracy for the full-range task but is mentioned primarily for reproducibility.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.6" class="ltx_p">As inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> we predict output angles from the bin logits by applying softmax to obtain bin probabilities and take an expectation of the result for each of yaw, pitch and roll:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\theta_{pred}=3\sum_{i=1}^{N}p_{i}\left(i-\frac{1+N}{2}\right)" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msub id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml">Î¸</mi><mrow id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.3.3.2" xref="S3.E2.m1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.1" xref="S3.E2.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.3.3.3" xref="S3.E2.m1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.1a" xref="S3.E2.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.3.3.4" xref="S3.E2.m1.1.1.3.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.3.3.1b" xref="S3.E2.m1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.1.1.3.3.5" xref="S3.E2.m1.1.1.3.3.5.cmml">d</mi></mrow></msub><mo id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><mn id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><munderover id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E2.m1.1.1.1.1.2.2.3.1" xref="S3.E2.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E2.m1.1.1.1.1.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml">i</mi><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mfrac id="S3.E2.m1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">1</mn><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.1.cmml">+</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.3.cmml">N</mi></mrow><mn id="S3.E2.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.3.cmml">2</mn></mfrac></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"></eq><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2">ğœƒ</ci><apply id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3"><times id="S3.E2.m1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.3.3.1"></times><ci id="S3.E2.m1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.3.3.2">ğ‘</ci><ci id="S3.E2.m1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.3.3.3">ğ‘Ÿ</ci><ci id="S3.E2.m1.1.1.3.3.4.cmml" xref="S3.E2.m1.1.1.3.3.4">ğ‘’</ci><ci id="S3.E2.m1.1.1.3.3.5.cmml" xref="S3.E2.m1.1.1.3.3.5">ğ‘‘</ci></apply></apply><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><cn type="integer" id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3">3</cn><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E2.m1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3"><eq id="S3.E2.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E2.m1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3.3">ğ‘–</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"><minus id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1"></minus><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.2">ğ‘–</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3"><divide id="S3.E2.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3"></divide><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2"><plus id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.1"></plus><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.2">1</cn><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.2.3">ğ‘</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.3.3">2</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\theta_{pred}=3\sum_{i=1}^{N}p_{i}\left(i-\frac{1+N}{2}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.p5.5" class="ltx_p">Here <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.p5.1.m1.1a"><msub id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml"><mi id="S3.p5.1.m1.1.1.2" xref="S3.p5.1.m1.1.1.2.cmml">p</mi><mi id="S3.p5.1.m1.1.1.3" xref="S3.p5.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><apply id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p5.1.m1.1.1.1.cmml" xref="S3.p5.1.m1.1.1">subscript</csymbol><ci id="S3.p5.1.m1.1.1.2.cmml" xref="S3.p5.1.m1.1.1.2">ğ‘</ci><ci id="S3.p5.1.m1.1.1.3.cmml" xref="S3.p5.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">p_{i}</annotation></semantics></math> is the probability of the iâ€™th bin, <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p5.2.m2.1a"><mn id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><cn type="integer" id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">3</annotation></semantics></math> is the bin width in degrees and <math id="S3.p5.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p5.3.m3.1a"><mi id="S3.p5.3.m3.1.1" xref="S3.p5.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p5.3.m3.1b"><ci id="S3.p5.3.m3.1.1.cmml" xref="S3.p5.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.3.m3.1c">N</annotation></semantics></math> is the bin-count of either <math id="S3.p5.4.m4.1" class="ltx_Math" alttext="120" display="inline"><semantics id="S3.p5.4.m4.1a"><mn id="S3.p5.4.m4.1.1" xref="S3.p5.4.m4.1.1.cmml">120</mn><annotation-xml encoding="MathML-Content" id="S3.p5.4.m4.1b"><cn type="integer" id="S3.p5.4.m4.1.1.cmml" xref="S3.p5.4.m4.1.1">120</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.4.m4.1c">120</annotation></semantics></math> (yaw) or <math id="S3.p5.5.m5.1" class="ltx_Math" alttext="66" display="inline"><semantics id="S3.p5.5.m5.1a"><mn id="S3.p5.5.m5.1.1" xref="S3.p5.5.m5.1.1.cmml">66</mn><annotation-xml encoding="MathML-Content" id="S3.p5.5.m5.1b"><cn type="integer" id="S3.p5.5.m5.1.1.cmml" xref="S3.p5.5.m5.1.1">66</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.5.m5.1c">66</annotation></semantics></math> (pitch and roll). The subtracted term shifts bin indices to bin centres.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.2" class="ltx_p">InÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite>, a mean squared error (MSE) loss was used for regression which was sufficient for the limited range of yaws that were targeted. However, on the full-range task, this loss leads to erratic behaviour for subjects with absolute yaws exceeding <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="150^{\circ}" display="inline"><semantics id="S3.p6.1.m1.1a"><msup id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml"><mn id="S3.p6.1.m1.1.1.2" xref="S3.p6.1.m1.1.1.2.cmml">150</mn><mo id="S3.p6.1.m1.1.1.3" xref="S3.p6.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><apply id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p6.1.m1.1.1.1.cmml" xref="S3.p6.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.p6.1.m1.1.1.2.cmml" xref="S3.p6.1.m1.1.1.2">150</cn><compose id="S3.p6.1.m1.1.1.3.cmml" xref="S3.p6.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">150^{\circ}</annotation></semantics></math>. This is illustrated in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and is due to <math id="S3.p6.2.m2.1" class="ltx_Math" alttext="\pm 180^{\circ}" display="inline"><semantics id="S3.p6.2.m2.1a"><mrow id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml"><mo id="S3.p6.2.m2.1.1a" xref="S3.p6.2.m2.1.1.cmml">Â±</mo><msup id="S3.p6.2.m2.1.1.2" xref="S3.p6.2.m2.1.1.2.cmml"><mn id="S3.p6.2.m2.1.1.2.2" xref="S3.p6.2.m2.1.1.2.2.cmml">180</mn><mo id="S3.p6.2.m2.1.1.2.3" xref="S3.p6.2.m2.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.1b"><apply id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1"><csymbol cd="latexml" id="S3.p6.2.m2.1.1.1.cmml" xref="S3.p6.2.m2.1.1">plus-or-minus</csymbol><apply id="S3.p6.2.m2.1.1.2.cmml" xref="S3.p6.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p6.2.m2.1.1.2.1.cmml" xref="S3.p6.2.m2.1.1.2">superscript</csymbol><cn type="integer" id="S3.p6.2.m2.1.1.2.2.cmml" xref="S3.p6.2.m2.1.1.2.2">180</cn><compose id="S3.p6.2.m2.1.1.2.3.cmml" xref="S3.p6.2.m2.1.1.2.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.1c">\pm 180^{\circ}</annotation></semantics></math> having wildly different angles for the same pose.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p">To prevent this, we define a <span id="S3.p7.1.1" class="ltx_text ltx_font_italic">wrapped loss</span> (see FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) that avoids this behavior. Rather than penalizing angle directly, it penalizes the minimal rotation angle that is needed to align each yaw prediction with its corresponding dataset annotation:</p>
</div>
<div id="S3.p8" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.9" class="ltx_Math" alttext="\mathcal{L}_{wrap}(\theta_{pred},\theta_{true})=\frac{1}{N_{batch}}\sum_{i}^{N_{batch}}\min[|\theta^{(i)}_{pred}-\theta^{(i)}_{true}|^{2},(360-|\theta^{(i)}_{pred}-\theta^{(i)}_{true}|)^{2}]" display="block"><semantics id="S3.E3.m1.9a"><mrow id="S3.E3.m1.9.9" xref="S3.E3.m1.9.9.cmml"><mrow id="S3.E3.m1.7.7.2" xref="S3.E3.m1.7.7.2.cmml"><msub id="S3.E3.m1.7.7.2.4" xref="S3.E3.m1.7.7.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.7.2.4.2" xref="S3.E3.m1.7.7.2.4.2.cmml">â„’</mi><mrow id="S3.E3.m1.7.7.2.4.3" xref="S3.E3.m1.7.7.2.4.3.cmml"><mi id="S3.E3.m1.7.7.2.4.3.2" xref="S3.E3.m1.7.7.2.4.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.4.3.1" xref="S3.E3.m1.7.7.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.7.7.2.4.3.3" xref="S3.E3.m1.7.7.2.4.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.4.3.1a" xref="S3.E3.m1.7.7.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.7.7.2.4.3.4" xref="S3.E3.m1.7.7.2.4.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.4.3.1b" xref="S3.E3.m1.7.7.2.4.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.7.7.2.4.3.5" xref="S3.E3.m1.7.7.2.4.3.5.cmml">p</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.3" xref="S3.E3.m1.7.7.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.7.7.2.2.2" xref="S3.E3.m1.7.7.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.7.7.2.2.2.3" xref="S3.E3.m1.7.7.2.2.3.cmml">(</mo><msub id="S3.E3.m1.6.6.1.1.1.1" xref="S3.E3.m1.6.6.1.1.1.1.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.2" xref="S3.E3.m1.6.6.1.1.1.1.2.cmml">Î¸</mi><mrow id="S3.E3.m1.6.6.1.1.1.1.3" xref="S3.E3.m1.6.6.1.1.1.1.3.cmml"><mi id="S3.E3.m1.6.6.1.1.1.1.3.2" xref="S3.E3.m1.6.6.1.1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.6.6.1.1.1.1.3.1" xref="S3.E3.m1.6.6.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.6.6.1.1.1.1.3.3" xref="S3.E3.m1.6.6.1.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.6.6.1.1.1.1.3.1a" xref="S3.E3.m1.6.6.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.6.6.1.1.1.1.3.4" xref="S3.E3.m1.6.6.1.1.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.6.6.1.1.1.1.3.1b" xref="S3.E3.m1.6.6.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.6.6.1.1.1.1.3.5" xref="S3.E3.m1.6.6.1.1.1.1.3.5.cmml">d</mi></mrow></msub><mo id="S3.E3.m1.7.7.2.2.2.4" xref="S3.E3.m1.7.7.2.2.3.cmml">,</mo><msub id="S3.E3.m1.7.7.2.2.2.2" xref="S3.E3.m1.7.7.2.2.2.2.cmml"><mi id="S3.E3.m1.7.7.2.2.2.2.2" xref="S3.E3.m1.7.7.2.2.2.2.2.cmml">Î¸</mi><mrow id="S3.E3.m1.7.7.2.2.2.2.3" xref="S3.E3.m1.7.7.2.2.2.2.3.cmml"><mi id="S3.E3.m1.7.7.2.2.2.2.3.2" xref="S3.E3.m1.7.7.2.2.2.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.2.2.2.3.1" xref="S3.E3.m1.7.7.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.7.7.2.2.2.2.3.3" xref="S3.E3.m1.7.7.2.2.2.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.2.2.2.3.1a" xref="S3.E3.m1.7.7.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.7.7.2.2.2.2.3.4" xref="S3.E3.m1.7.7.2.2.2.2.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.7.7.2.2.2.2.3.1b" xref="S3.E3.m1.7.7.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.7.7.2.2.2.2.3.5" xref="S3.E3.m1.7.7.2.2.2.2.3.5.cmml">e</mi></mrow></msub><mo stretchy="false" id="S3.E3.m1.7.7.2.2.2.5" xref="S3.E3.m1.7.7.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.9.9.5" xref="S3.E3.m1.9.9.5.cmml">=</mo><mrow id="S3.E3.m1.9.9.4" xref="S3.E3.m1.9.9.4.cmml"><mfrac id="S3.E3.m1.9.9.4.4" xref="S3.E3.m1.9.9.4.4.cmml"><mn id="S3.E3.m1.9.9.4.4.2" xref="S3.E3.m1.9.9.4.4.2.cmml">1</mn><msub id="S3.E3.m1.9.9.4.4.3" xref="S3.E3.m1.9.9.4.4.3.cmml"><mi id="S3.E3.m1.9.9.4.4.3.2" xref="S3.E3.m1.9.9.4.4.3.2.cmml">N</mi><mrow id="S3.E3.m1.9.9.4.4.3.3" xref="S3.E3.m1.9.9.4.4.3.3.cmml"><mi id="S3.E3.m1.9.9.4.4.3.3.2" xref="S3.E3.m1.9.9.4.4.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.4.3.3.1" xref="S3.E3.m1.9.9.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.4.3.3.3" xref="S3.E3.m1.9.9.4.4.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.4.3.3.1a" xref="S3.E3.m1.9.9.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.4.3.3.4" xref="S3.E3.m1.9.9.4.4.3.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.4.3.3.1b" xref="S3.E3.m1.9.9.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.4.3.3.5" xref="S3.E3.m1.9.9.4.4.3.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.4.3.3.1c" xref="S3.E3.m1.9.9.4.4.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.4.3.3.6" xref="S3.E3.m1.9.9.4.4.3.3.6.cmml">h</mi></mrow></msub></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.3" xref="S3.E3.m1.9.9.4.3.cmml">â€‹</mo><mrow id="S3.E3.m1.9.9.4.2" xref="S3.E3.m1.9.9.4.2.cmml"><munderover id="S3.E3.m1.9.9.4.2.3" xref="S3.E3.m1.9.9.4.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.9.9.4.2.3.2.2" xref="S3.E3.m1.9.9.4.2.3.2.2.cmml">âˆ‘</mo><mi id="S3.E3.m1.9.9.4.2.3.2.3" xref="S3.E3.m1.9.9.4.2.3.2.3.cmml">i</mi><msub id="S3.E3.m1.9.9.4.2.3.3" xref="S3.E3.m1.9.9.4.2.3.3.cmml"><mi id="S3.E3.m1.9.9.4.2.3.3.2" xref="S3.E3.m1.9.9.4.2.3.3.2.cmml">N</mi><mrow id="S3.E3.m1.9.9.4.2.3.3.3" xref="S3.E3.m1.9.9.4.2.3.3.3.cmml"><mi id="S3.E3.m1.9.9.4.2.3.3.3.2" xref="S3.E3.m1.9.9.4.2.3.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.3.3.3.1" xref="S3.E3.m1.9.9.4.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.3.3.3.3" xref="S3.E3.m1.9.9.4.2.3.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.3.3.3.1a" xref="S3.E3.m1.9.9.4.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.3.3.3.4" xref="S3.E3.m1.9.9.4.2.3.3.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.3.3.3.1b" xref="S3.E3.m1.9.9.4.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.3.3.3.5" xref="S3.E3.m1.9.9.4.2.3.3.3.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.3.3.3.1c" xref="S3.E3.m1.9.9.4.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.3.3.3.6" xref="S3.E3.m1.9.9.4.2.3.3.3.6.cmml">h</mi></mrow></msub></munderover><mrow id="S3.E3.m1.9.9.4.2.2.2" xref="S3.E3.m1.9.9.4.2.2.3.cmml"><mi id="S3.E3.m1.5.5" xref="S3.E3.m1.5.5.cmml">min</mi><mo id="S3.E3.m1.9.9.4.2.2.2a" xref="S3.E3.m1.9.9.4.2.2.3.cmml">â¡</mo><mrow id="S3.E3.m1.9.9.4.2.2.2.2" xref="S3.E3.m1.9.9.4.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.9.9.4.2.2.2.2.3" xref="S3.E3.m1.9.9.4.2.2.3.cmml">[</mo><msup id="S3.E3.m1.8.8.3.1.1.1.1.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.cmml"><msubsup id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.2.2.cmml">Î¸</mi><mrow id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1a" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.4" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1b" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.5" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.5.cmml">d</mi></mrow><mrow id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.3.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml">i</mi><mo stretchy="false" id="S3.E3.m1.1.1.1.3.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.2.2.cmml">Î¸</mi><mrow id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1a" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.4" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1b" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.5" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.5.cmml">e</mi></mrow><mrow id="S3.E3.m1.2.2.1.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.3.1" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml">i</mi><mo stretchy="false" id="S3.E3.m1.2.2.1.3.2" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></msubsup></mrow><mo stretchy="false" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mn id="S3.E3.m1.8.8.3.1.1.1.1.1.3" xref="S3.E3.m1.8.8.3.1.1.1.1.1.3.cmml">2</mn></msup><mo id="S3.E3.m1.9.9.4.2.2.2.2.4" xref="S3.E3.m1.9.9.4.2.2.3.cmml">,</mo><msup id="S3.E3.m1.9.9.4.2.2.2.2.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.cmml"><mrow id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.cmml"><mn id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.3.cmml">360</mn><mo id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.cmml"><msubsup id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.2.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.2.2.cmml">Î¸</mi><mrow id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1a" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.4" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1b" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.5" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.5.cmml">d</mi></mrow><mrow id="S3.E3.m1.3.3.1.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.3.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml">i</mi><mo stretchy="false" id="S3.E3.m1.3.3.1.3.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.cmml">)</mo></mrow></msubsup><mo id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.2.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.2.2.cmml">Î¸</mi><mrow id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1a" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.4" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1b" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.5" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.5.cmml">e</mi></mrow><mrow id="S3.E3.m1.4.4.1.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.3.1" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.cmml">(</mo><mi id="S3.E3.m1.4.4.1.1" xref="S3.E3.m1.4.4.1.1.cmml">i</mi><mo stretchy="false" id="S3.E3.m1.4.4.1.3.2" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.cmml">)</mo></mrow></msubsup></mrow><mo stretchy="false" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.2.1.cmml">|</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.cmml">)</mo></mrow><mn id="S3.E3.m1.9.9.4.2.2.2.2.2.3" xref="S3.E3.m1.9.9.4.2.2.2.2.2.3.cmml">2</mn></msup><mo stretchy="false" id="S3.E3.m1.9.9.4.2.2.2.2.5" xref="S3.E3.m1.9.9.4.2.2.3.cmml">]</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.9b"><apply id="S3.E3.m1.9.9.cmml" xref="S3.E3.m1.9.9"><eq id="S3.E3.m1.9.9.5.cmml" xref="S3.E3.m1.9.9.5"></eq><apply id="S3.E3.m1.7.7.2.cmml" xref="S3.E3.m1.7.7.2"><times id="S3.E3.m1.7.7.2.3.cmml" xref="S3.E3.m1.7.7.2.3"></times><apply id="S3.E3.m1.7.7.2.4.cmml" xref="S3.E3.m1.7.7.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.7.7.2.4.1.cmml" xref="S3.E3.m1.7.7.2.4">subscript</csymbol><ci id="S3.E3.m1.7.7.2.4.2.cmml" xref="S3.E3.m1.7.7.2.4.2">â„’</ci><apply id="S3.E3.m1.7.7.2.4.3.cmml" xref="S3.E3.m1.7.7.2.4.3"><times id="S3.E3.m1.7.7.2.4.3.1.cmml" xref="S3.E3.m1.7.7.2.4.3.1"></times><ci id="S3.E3.m1.7.7.2.4.3.2.cmml" xref="S3.E3.m1.7.7.2.4.3.2">ğ‘¤</ci><ci id="S3.E3.m1.7.7.2.4.3.3.cmml" xref="S3.E3.m1.7.7.2.4.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.7.7.2.4.3.4.cmml" xref="S3.E3.m1.7.7.2.4.3.4">ğ‘</ci><ci id="S3.E3.m1.7.7.2.4.3.5.cmml" xref="S3.E3.m1.7.7.2.4.3.5">ğ‘</ci></apply></apply><interval closure="open" id="S3.E3.m1.7.7.2.2.3.cmml" xref="S3.E3.m1.7.7.2.2.2"><apply id="S3.E3.m1.6.6.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.6.6.1.1.1.1.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.6.6.1.1.1.1.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.2">ğœƒ</ci><apply id="S3.E3.m1.6.6.1.1.1.1.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3"><times id="S3.E3.m1.6.6.1.1.1.1.3.1.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.1"></times><ci id="S3.E3.m1.6.6.1.1.1.1.3.2.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E3.m1.6.6.1.1.1.1.3.3.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.6.6.1.1.1.1.3.4.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.4">ğ‘’</ci><ci id="S3.E3.m1.6.6.1.1.1.1.3.5.cmml" xref="S3.E3.m1.6.6.1.1.1.1.3.5">ğ‘‘</ci></apply></apply><apply id="S3.E3.m1.7.7.2.2.2.2.cmml" xref="S3.E3.m1.7.7.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.7.7.2.2.2.2.1.cmml" xref="S3.E3.m1.7.7.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.7.7.2.2.2.2.2.cmml" xref="S3.E3.m1.7.7.2.2.2.2.2">ğœƒ</ci><apply id="S3.E3.m1.7.7.2.2.2.2.3.cmml" xref="S3.E3.m1.7.7.2.2.2.2.3"><times id="S3.E3.m1.7.7.2.2.2.2.3.1.cmml" xref="S3.E3.m1.7.7.2.2.2.2.3.1"></times><ci id="S3.E3.m1.7.7.2.2.2.2.3.2.cmml" xref="S3.E3.m1.7.7.2.2.2.2.3.2">ğ‘¡</ci><ci id="S3.E3.m1.7.7.2.2.2.2.3.3.cmml" xref="S3.E3.m1.7.7.2.2.2.2.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.7.7.2.2.2.2.3.4.cmml" xref="S3.E3.m1.7.7.2.2.2.2.3.4">ğ‘¢</ci><ci id="S3.E3.m1.7.7.2.2.2.2.3.5.cmml" xref="S3.E3.m1.7.7.2.2.2.2.3.5">ğ‘’</ci></apply></apply></interval></apply><apply id="S3.E3.m1.9.9.4.cmml" xref="S3.E3.m1.9.9.4"><times id="S3.E3.m1.9.9.4.3.cmml" xref="S3.E3.m1.9.9.4.3"></times><apply id="S3.E3.m1.9.9.4.4.cmml" xref="S3.E3.m1.9.9.4.4"><divide id="S3.E3.m1.9.9.4.4.1.cmml" xref="S3.E3.m1.9.9.4.4"></divide><cn type="integer" id="S3.E3.m1.9.9.4.4.2.cmml" xref="S3.E3.m1.9.9.4.4.2">1</cn><apply id="S3.E3.m1.9.9.4.4.3.cmml" xref="S3.E3.m1.9.9.4.4.3"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.4.3.1.cmml" xref="S3.E3.m1.9.9.4.4.3">subscript</csymbol><ci id="S3.E3.m1.9.9.4.4.3.2.cmml" xref="S3.E3.m1.9.9.4.4.3.2">ğ‘</ci><apply id="S3.E3.m1.9.9.4.4.3.3.cmml" xref="S3.E3.m1.9.9.4.4.3.3"><times id="S3.E3.m1.9.9.4.4.3.3.1.cmml" xref="S3.E3.m1.9.9.4.4.3.3.1"></times><ci id="S3.E3.m1.9.9.4.4.3.3.2.cmml" xref="S3.E3.m1.9.9.4.4.3.3.2">ğ‘</ci><ci id="S3.E3.m1.9.9.4.4.3.3.3.cmml" xref="S3.E3.m1.9.9.4.4.3.3.3">ğ‘</ci><ci id="S3.E3.m1.9.9.4.4.3.3.4.cmml" xref="S3.E3.m1.9.9.4.4.3.3.4">ğ‘¡</ci><ci id="S3.E3.m1.9.9.4.4.3.3.5.cmml" xref="S3.E3.m1.9.9.4.4.3.3.5">ğ‘</ci><ci id="S3.E3.m1.9.9.4.4.3.3.6.cmml" xref="S3.E3.m1.9.9.4.4.3.3.6">â„</ci></apply></apply></apply><apply id="S3.E3.m1.9.9.4.2.cmml" xref="S3.E3.m1.9.9.4.2"><apply id="S3.E3.m1.9.9.4.2.3.cmml" xref="S3.E3.m1.9.9.4.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.3.1.cmml" xref="S3.E3.m1.9.9.4.2.3">superscript</csymbol><apply id="S3.E3.m1.9.9.4.2.3.2.cmml" xref="S3.E3.m1.9.9.4.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.3.2.1.cmml" xref="S3.E3.m1.9.9.4.2.3">subscript</csymbol><sum id="S3.E3.m1.9.9.4.2.3.2.2.cmml" xref="S3.E3.m1.9.9.4.2.3.2.2"></sum><ci id="S3.E3.m1.9.9.4.2.3.2.3.cmml" xref="S3.E3.m1.9.9.4.2.3.2.3">ğ‘–</ci></apply><apply id="S3.E3.m1.9.9.4.2.3.3.cmml" xref="S3.E3.m1.9.9.4.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.3.3.1.cmml" xref="S3.E3.m1.9.9.4.2.3.3">subscript</csymbol><ci id="S3.E3.m1.9.9.4.2.3.3.2.cmml" xref="S3.E3.m1.9.9.4.2.3.3.2">ğ‘</ci><apply id="S3.E3.m1.9.9.4.2.3.3.3.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3"><times id="S3.E3.m1.9.9.4.2.3.3.3.1.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3.1"></times><ci id="S3.E3.m1.9.9.4.2.3.3.3.2.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3.2">ğ‘</ci><ci id="S3.E3.m1.9.9.4.2.3.3.3.3.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3.3">ğ‘</ci><ci id="S3.E3.m1.9.9.4.2.3.3.3.4.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3.4">ğ‘¡</ci><ci id="S3.E3.m1.9.9.4.2.3.3.3.5.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3.5">ğ‘</ci><ci id="S3.E3.m1.9.9.4.2.3.3.3.6.cmml" xref="S3.E3.m1.9.9.4.2.3.3.3.6">â„</ci></apply></apply></apply><apply id="S3.E3.m1.9.9.4.2.2.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2"><min id="S3.E3.m1.5.5.cmml" xref="S3.E3.m1.5.5"></min><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.3.1.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1"><abs id="S3.E3.m1.8.8.3.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.2"></abs><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.2.2">ğœƒ</ci><ci id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1">ğ‘–</ci></apply><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3"><times id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.4">ğ‘’</ci><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.5.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.2.3.5">ğ‘‘</ci></apply></apply><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.2.2">ğœƒ</ci><ci id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1.1">ğ‘–</ci></apply><apply id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3"><times id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.2">ğ‘¡</ci><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.4">ğ‘¢</ci><ci id="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.5.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.1.1.1.3.3.5">ğ‘’</ci></apply></apply></apply></apply><cn type="integer" id="S3.E3.m1.8.8.3.1.1.1.1.1.3.cmml" xref="S3.E3.m1.8.8.3.1.1.1.1.1.3">2</cn></apply><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.2.2.2.2.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2">superscript</csymbol><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1"><minus id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.2"></minus><cn type="integer" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.3">360</cn><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1"><abs id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.2.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.2"></abs><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1"><minus id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.1"></minus><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.2.2">ğœƒ</ci><ci id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1.1">ğ‘–</ci></apply><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3"><times id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.4">ğ‘’</ci><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.5.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.2.3.5">ğ‘‘</ci></apply></apply><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.2.2">ğœƒ</ci><ci id="S3.E3.m1.4.4.1.1.cmml" xref="S3.E3.m1.4.4.1.1">ğ‘–</ci></apply><apply id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3"><times id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.2">ğ‘¡</ci><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.4">ğ‘¢</ci><ci id="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.5.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.1.1.1.1.1.1.3.3.5">ğ‘’</ci></apply></apply></apply></apply></apply><cn type="integer" id="S3.E3.m1.9.9.4.2.2.2.2.2.3.cmml" xref="S3.E3.m1.9.9.4.2.2.2.2.2.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.9c">\mathcal{L}_{wrap}(\theta_{pred},\theta_{true})=\frac{1}{N_{batch}}\sum_{i}^{N_{batch}}\min[|\theta^{(i)}_{pred}-\theta^{(i)}_{true}|^{2},(360-|\theta^{(i)}_{pred}-\theta^{(i)}_{true}|)^{2}]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.p8.5" class="ltx_p">The loss function <math id="S3.p8.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{wrap}" display="inline"><semantics id="S3.p8.1.m1.1a"><msub id="S3.p8.1.m1.1.1" xref="S3.p8.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p8.1.m1.1.1.2" xref="S3.p8.1.m1.1.1.2.cmml">â„’</mi><mrow id="S3.p8.1.m1.1.1.3" xref="S3.p8.1.m1.1.1.3.cmml"><mi id="S3.p8.1.m1.1.1.3.2" xref="S3.p8.1.m1.1.1.3.2.cmml">w</mi><mo lspace="0em" rspace="0em" id="S3.p8.1.m1.1.1.3.1" xref="S3.p8.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p8.1.m1.1.1.3.3" xref="S3.p8.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.p8.1.m1.1.1.3.1a" xref="S3.p8.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p8.1.m1.1.1.3.4" xref="S3.p8.1.m1.1.1.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.p8.1.m1.1.1.3.1b" xref="S3.p8.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.p8.1.m1.1.1.3.5" xref="S3.p8.1.m1.1.1.3.5.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.p8.1.m1.1b"><apply id="S3.p8.1.m1.1.1.cmml" xref="S3.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p8.1.m1.1.1.1.cmml" xref="S3.p8.1.m1.1.1">subscript</csymbol><ci id="S3.p8.1.m1.1.1.2.cmml" xref="S3.p8.1.m1.1.1.2">â„’</ci><apply id="S3.p8.1.m1.1.1.3.cmml" xref="S3.p8.1.m1.1.1.3"><times id="S3.p8.1.m1.1.1.3.1.cmml" xref="S3.p8.1.m1.1.1.3.1"></times><ci id="S3.p8.1.m1.1.1.3.2.cmml" xref="S3.p8.1.m1.1.1.3.2">ğ‘¤</ci><ci id="S3.p8.1.m1.1.1.3.3.cmml" xref="S3.p8.1.m1.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.p8.1.m1.1.1.3.4.cmml" xref="S3.p8.1.m1.1.1.3.4">ğ‘</ci><ci id="S3.p8.1.m1.1.1.3.5.cmml" xref="S3.p8.1.m1.1.1.3.5">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.1.m1.1c">\mathcal{L}_{wrap}</annotation></semantics></math> is plotted in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> for the target value <math id="S3.p8.2.m2.1" class="ltx_Math" alttext="\theta_{true}=150^{\circ}" display="inline"><semantics id="S3.p8.2.m2.1a"><mrow id="S3.p8.2.m2.1.1" xref="S3.p8.2.m2.1.1.cmml"><msub id="S3.p8.2.m2.1.1.2" xref="S3.p8.2.m2.1.1.2.cmml"><mi id="S3.p8.2.m2.1.1.2.2" xref="S3.p8.2.m2.1.1.2.2.cmml">Î¸</mi><mrow id="S3.p8.2.m2.1.1.2.3" xref="S3.p8.2.m2.1.1.2.3.cmml"><mi id="S3.p8.2.m2.1.1.2.3.2" xref="S3.p8.2.m2.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.p8.2.m2.1.1.2.3.1" xref="S3.p8.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.p8.2.m2.1.1.2.3.3" xref="S3.p8.2.m2.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.p8.2.m2.1.1.2.3.1a" xref="S3.p8.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.p8.2.m2.1.1.2.3.4" xref="S3.p8.2.m2.1.1.2.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.p8.2.m2.1.1.2.3.1b" xref="S3.p8.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.p8.2.m2.1.1.2.3.5" xref="S3.p8.2.m2.1.1.2.3.5.cmml">e</mi></mrow></msub><mo id="S3.p8.2.m2.1.1.1" xref="S3.p8.2.m2.1.1.1.cmml">=</mo><msup id="S3.p8.2.m2.1.1.3" xref="S3.p8.2.m2.1.1.3.cmml"><mn id="S3.p8.2.m2.1.1.3.2" xref="S3.p8.2.m2.1.1.3.2.cmml">150</mn><mo id="S3.p8.2.m2.1.1.3.3" xref="S3.p8.2.m2.1.1.3.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.2.m2.1b"><apply id="S3.p8.2.m2.1.1.cmml" xref="S3.p8.2.m2.1.1"><eq id="S3.p8.2.m2.1.1.1.cmml" xref="S3.p8.2.m2.1.1.1"></eq><apply id="S3.p8.2.m2.1.1.2.cmml" xref="S3.p8.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p8.2.m2.1.1.2.1.cmml" xref="S3.p8.2.m2.1.1.2">subscript</csymbol><ci id="S3.p8.2.m2.1.1.2.2.cmml" xref="S3.p8.2.m2.1.1.2.2">ğœƒ</ci><apply id="S3.p8.2.m2.1.1.2.3.cmml" xref="S3.p8.2.m2.1.1.2.3"><times id="S3.p8.2.m2.1.1.2.3.1.cmml" xref="S3.p8.2.m2.1.1.2.3.1"></times><ci id="S3.p8.2.m2.1.1.2.3.2.cmml" xref="S3.p8.2.m2.1.1.2.3.2">ğ‘¡</ci><ci id="S3.p8.2.m2.1.1.2.3.3.cmml" xref="S3.p8.2.m2.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S3.p8.2.m2.1.1.2.3.4.cmml" xref="S3.p8.2.m2.1.1.2.3.4">ğ‘¢</ci><ci id="S3.p8.2.m2.1.1.2.3.5.cmml" xref="S3.p8.2.m2.1.1.2.3.5">ğ‘’</ci></apply></apply><apply id="S3.p8.2.m2.1.1.3.cmml" xref="S3.p8.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p8.2.m2.1.1.3.1.cmml" xref="S3.p8.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="S3.p8.2.m2.1.1.3.2.cmml" xref="S3.p8.2.m2.1.1.3.2">150</cn><compose id="S3.p8.2.m2.1.1.3.3.cmml" xref="S3.p8.2.m2.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.2.m2.1c">\theta_{true}=150^{\circ}</annotation></semantics></math> and compared with an MSE loss. In the range <math id="S3.p8.3.m3.2" class="ltx_Math" alttext="(-30,180]" display="inline"><semantics id="S3.p8.3.m3.2a"><mrow id="S3.p8.3.m3.2.2.1" xref="S3.p8.3.m3.2.2.2.cmml"><mo stretchy="false" id="S3.p8.3.m3.2.2.1.2" xref="S3.p8.3.m3.2.2.2.cmml">(</mo><mrow id="S3.p8.3.m3.2.2.1.1" xref="S3.p8.3.m3.2.2.1.1.cmml"><mo id="S3.p8.3.m3.2.2.1.1a" xref="S3.p8.3.m3.2.2.1.1.cmml">âˆ’</mo><mn id="S3.p8.3.m3.2.2.1.1.2" xref="S3.p8.3.m3.2.2.1.1.2.cmml">30</mn></mrow><mo id="S3.p8.3.m3.2.2.1.3" xref="S3.p8.3.m3.2.2.2.cmml">,</mo><mn id="S3.p8.3.m3.1.1" xref="S3.p8.3.m3.1.1.cmml">180</mn><mo stretchy="false" id="S3.p8.3.m3.2.2.1.4" xref="S3.p8.3.m3.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.3.m3.2b"><interval closure="open-closed" id="S3.p8.3.m3.2.2.2.cmml" xref="S3.p8.3.m3.2.2.1"><apply id="S3.p8.3.m3.2.2.1.1.cmml" xref="S3.p8.3.m3.2.2.1.1"><minus id="S3.p8.3.m3.2.2.1.1.1.cmml" xref="S3.p8.3.m3.2.2.1.1"></minus><cn type="integer" id="S3.p8.3.m3.2.2.1.1.2.cmml" xref="S3.p8.3.m3.2.2.1.1.2">30</cn></apply><cn type="integer" id="S3.p8.3.m3.1.1.cmml" xref="S3.p8.3.m3.1.1">180</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.3.m3.2c">(-30,180]</annotation></semantics></math> the two are identical but diverge for angles <math id="S3.p8.4.m4.1" class="ltx_Math" alttext="&lt;-30^{\circ}" display="inline"><semantics id="S3.p8.4.m4.1a"><mrow id="S3.p8.4.m4.1.1" xref="S3.p8.4.m4.1.1.cmml"><mi id="S3.p8.4.m4.1.1.2" xref="S3.p8.4.m4.1.1.2.cmml"></mi><mo id="S3.p8.4.m4.1.1.1" xref="S3.p8.4.m4.1.1.1.cmml">&lt;</mo><mrow id="S3.p8.4.m4.1.1.3" xref="S3.p8.4.m4.1.1.3.cmml"><mo id="S3.p8.4.m4.1.1.3a" xref="S3.p8.4.m4.1.1.3.cmml">âˆ’</mo><msup id="S3.p8.4.m4.1.1.3.2" xref="S3.p8.4.m4.1.1.3.2.cmml"><mn id="S3.p8.4.m4.1.1.3.2.2" xref="S3.p8.4.m4.1.1.3.2.2.cmml">30</mn><mo id="S3.p8.4.m4.1.1.3.2.3" xref="S3.p8.4.m4.1.1.3.2.3.cmml">âˆ˜</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.4.m4.1b"><apply id="S3.p8.4.m4.1.1.cmml" xref="S3.p8.4.m4.1.1"><lt id="S3.p8.4.m4.1.1.1.cmml" xref="S3.p8.4.m4.1.1.1"></lt><csymbol cd="latexml" id="S3.p8.4.m4.1.1.2.cmml" xref="S3.p8.4.m4.1.1.2">absent</csymbol><apply id="S3.p8.4.m4.1.1.3.cmml" xref="S3.p8.4.m4.1.1.3"><minus id="S3.p8.4.m4.1.1.3.1.cmml" xref="S3.p8.4.m4.1.1.3"></minus><apply id="S3.p8.4.m4.1.1.3.2.cmml" xref="S3.p8.4.m4.1.1.3.2"><csymbol cd="ambiguous" id="S3.p8.4.m4.1.1.3.2.1.cmml" xref="S3.p8.4.m4.1.1.3.2">superscript</csymbol><cn type="integer" id="S3.p8.4.m4.1.1.3.2.2.cmml" xref="S3.p8.4.m4.1.1.3.2.2">30</cn><compose id="S3.p8.4.m4.1.1.3.2.3.cmml" xref="S3.p8.4.m4.1.1.3.2.3"></compose></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.4.m4.1c">&lt;-30^{\circ}</annotation></semantics></math>. As they diverge MSE increases rapidly but the wrapped loss decreases as poses become more similar. The wrapped loss is smooth &amp; differentiable everywhere except at a cusp <math id="S3.p8.5.m5.1" class="ltx_Math" alttext="180^{\circ}" display="inline"><semantics id="S3.p8.5.m5.1a"><msup id="S3.p8.5.m5.1.1" xref="S3.p8.5.m5.1.1.cmml"><mn id="S3.p8.5.m5.1.1.2" xref="S3.p8.5.m5.1.1.2.cmml">180</mn><mo id="S3.p8.5.m5.1.1.3" xref="S3.p8.5.m5.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p8.5.m5.1b"><apply id="S3.p8.5.m5.1.1.cmml" xref="S3.p8.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p8.5.m5.1.1.1.cmml" xref="S3.p8.5.m5.1.1">superscript</csymbol><cn type="integer" id="S3.p8.5.m5.1.1.2.cmml" xref="S3.p8.5.m5.1.1.2">180</cn><compose id="S3.p8.5.m5.1.1.3.cmml" xref="S3.p8.5.m5.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.5.m5.1c">180^{\circ}</annotation></semantics></math> from the ground-truth yaw. This does make training the network more difficult, we suspect this is due to the cusp occurring at maximal errors in yaw.</p>
</div>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.1" class="ltx_p">The wrapped loss is key to the methodâ€™s performance in anterior views, demonstrated empirically in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. A MSE trained network predicts entirely incorrect head poses while our predictions are consistent with the images. FigureÂ <a href="#S5.F3" title="Figure 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> plots errors as a function of angles and shows average errors at large yaw are decreased by more than 50%.</p>
</div>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx29" title="" class="ltx_ref">Ranjan etÂ al.(2017a)Ranjan, Patel, and
Chellappa</a>, <a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> AlexNet and ResNet50 were used as backbones. These are quite large networks for a highly specialized task such as HPE. Since a focus of our method is to be mobile-friendly, we instead opted for a lighter backbone: EfficientNet-B0<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">Tan and Le(2019)</a>]</cite>. EfficientNet-B0 is the baseline model of the EfficientNet family that incorporates Inverted Residual Blocks (from MobileNetV2<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx34" title="" class="ltx_ref">Sandler etÂ al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
Chen</a>]</cite>) to reduce the number of parameters while adding skip connections.</p>
</div>
<div id="S3.p11" class="ltx_para">
<p id="S3.p11.1" class="ltx_p">This model size reduction is important on low-power embedded devices where head pose estimation may be only one component of a larger system. We have successfully ported a preliminary implementation to a low-power embedded platform where we see inference speeds approaching 60fps</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Datasets &amp; Training</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Currently, major datasets for HPE are 300W-LP<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>, AFLW2000<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> and BIWI<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite>. Both AFLW2000 &amp; 300W-LP use 3D Dense Face Alignment (3DDFA) to fit a morphable 3D model to 2D input images and provide accurate head poses as ground-truth. 300W-LP additionally generates synthetic views, greatly expanding the number of images.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The BIWI dataset is composed of video sequences collected by a Kinect. Subjects moved their heads trying to span all possible angles observed from a frontal position. Pose annotations were created from the depth information.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We follow the convention ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> by reserving AFLW2000Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> and BIWIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite> for testing, while using 300W-LPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> for training.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Unfortunately, none of datasets mentioned above provide examples with (absolute) yaws larger than <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="100^{\circ}" display="inline"><semantics id="S4.p4.1.m1.1a"><msup id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mn id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">100</mn><mo id="S4.p4.1.m1.1.1.3" xref="S4.p4.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">100</cn><compose id="S4.p4.1.m1.1.1.3.cmml" xref="S4.p4.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">100^{\circ}</annotation></semantics></math>. To overcome this, we generated a new dataset combining 300W-LP with data from the CMU Panoptic DatasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite>. The CMU Panoptic Dataset captured video of subjects performing tasks in a dome from approximately 30 HD cameras.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">The panoptic dataset includes 3D facial landmarks and calibrated camera extrinsics and intrinsics but does not include head pose information. We use the landmarks and camera calibrations to locate and crop images of subjectsâ€™ heads and to compute the corresponding camera-relative head pose Euler angles. We believe we are the first to use this dataset in this context.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows a frame from the dataset. The panoptic dataset has very little background variation and so cannot be used to train networks alone since networks do not learn features to differentiate subjects from general backgrounds. This is the motivation to combine it with 300W-LP, which is used for yaws in <math id="S4.p6.1.m1.2" class="ltx_Math" alttext="(-99^{\circ},99^{\circ})" display="inline"><semantics id="S4.p6.1.m1.2a"><mrow id="S4.p6.1.m1.2.2.2" xref="S4.p6.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.p6.1.m1.2.2.2.3" xref="S4.p6.1.m1.2.2.3.cmml">(</mo><mrow id="S4.p6.1.m1.1.1.1.1" xref="S4.p6.1.m1.1.1.1.1.cmml"><mo id="S4.p6.1.m1.1.1.1.1a" xref="S4.p6.1.m1.1.1.1.1.cmml">âˆ’</mo><msup id="S4.p6.1.m1.1.1.1.1.2" xref="S4.p6.1.m1.1.1.1.1.2.cmml"><mn id="S4.p6.1.m1.1.1.1.1.2.2" xref="S4.p6.1.m1.1.1.1.1.2.2.cmml">99</mn><mo id="S4.p6.1.m1.1.1.1.1.2.3" xref="S4.p6.1.m1.1.1.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><mo id="S4.p6.1.m1.2.2.2.4" xref="S4.p6.1.m1.2.2.3.cmml">,</mo><msup id="S4.p6.1.m1.2.2.2.2" xref="S4.p6.1.m1.2.2.2.2.cmml"><mn id="S4.p6.1.m1.2.2.2.2.2" xref="S4.p6.1.m1.2.2.2.2.2.cmml">99</mn><mo id="S4.p6.1.m1.2.2.2.2.3" xref="S4.p6.1.m1.2.2.2.2.3.cmml">âˆ˜</mo></msup><mo stretchy="false" id="S4.p6.1.m1.2.2.2.5" xref="S4.p6.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.2b"><interval closure="open" id="S4.p6.1.m1.2.2.3.cmml" xref="S4.p6.1.m1.2.2.2"><apply id="S4.p6.1.m1.1.1.1.1.cmml" xref="S4.p6.1.m1.1.1.1.1"><minus id="S4.p6.1.m1.1.1.1.1.1.cmml" xref="S4.p6.1.m1.1.1.1.1"></minus><apply id="S4.p6.1.m1.1.1.1.1.2.cmml" xref="S4.p6.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.p6.1.m1.1.1.1.1.2.1.cmml" xref="S4.p6.1.m1.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S4.p6.1.m1.1.1.1.1.2.2.cmml" xref="S4.p6.1.m1.1.1.1.1.2.2">99</cn><compose id="S4.p6.1.m1.1.1.1.1.2.3.cmml" xref="S4.p6.1.m1.1.1.1.1.2.3"></compose></apply></apply><apply id="S4.p6.1.m1.2.2.2.2.cmml" xref="S4.p6.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.p6.1.m1.2.2.2.2.1.cmml" xref="S4.p6.1.m1.2.2.2.2">superscript</csymbol><cn type="integer" id="S4.p6.1.m1.2.2.2.2.2.cmml" xref="S4.p6.1.m1.2.2.2.2.2">99</cn><compose id="S4.p6.1.m1.2.2.2.2.3.cmml" xref="S4.p6.1.m1.2.2.2.2.3"></compose></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.2c">(-99^{\circ},99^{\circ})</annotation></semantics></math> while the panoptic dataset provides data mostly outside this range.</p>
</div>
<div id="S4.p7" class="ltx_para">
<p id="S4.p7.12" class="ltx_p"><span id="S4.p7.12.1" class="ltx_text ltx_font_bold">Processing the CMU Panoptic Dataset.</span> To compute camera-relative head pose Euler angles from the panoptic dataset we use the following procedure, depicted graphically in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We first define a set of reference 3D facial landmarks (<math id="S4.p7.1.m1.1" class="ltx_Math" alttext="x_{ref}" display="inline"><semantics id="S4.p7.1.m1.1a"><msub id="S4.p7.1.m1.1.1" xref="S4.p7.1.m1.1.1.cmml"><mi id="S4.p7.1.m1.1.1.2" xref="S4.p7.1.m1.1.1.2.cmml">x</mi><mrow id="S4.p7.1.m1.1.1.3" xref="S4.p7.1.m1.1.1.3.cmml"><mi id="S4.p7.1.m1.1.1.3.2" xref="S4.p7.1.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.1.m1.1.1.3.1" xref="S4.p7.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.1.m1.1.1.3.3" xref="S4.p7.1.m1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.1.m1.1.1.3.1a" xref="S4.p7.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.1.m1.1.1.3.4" xref="S4.p7.1.m1.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.1.m1.1b"><apply id="S4.p7.1.m1.1.1.cmml" xref="S4.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p7.1.m1.1.1.1.cmml" xref="S4.p7.1.m1.1.1">subscript</csymbol><ci id="S4.p7.1.m1.1.1.2.cmml" xref="S4.p7.1.m1.1.1.2">ğ‘¥</ci><apply id="S4.p7.1.m1.1.1.3.cmml" xref="S4.p7.1.m1.1.1.3"><times id="S4.p7.1.m1.1.1.3.1.cmml" xref="S4.p7.1.m1.1.1.3.1"></times><ci id="S4.p7.1.m1.1.1.3.2.cmml" xref="S4.p7.1.m1.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.1.m1.1.1.3.3.cmml" xref="S4.p7.1.m1.1.1.3.3">ğ‘’</ci><ci id="S4.p7.1.m1.1.1.3.4.cmml" xref="S4.p7.1.m1.1.1.3.4">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.1.m1.1c">x_{ref}</annotation></semantics></math>) matching the panoptic dataset facial keypoints annotations using a generic head model, except for the noisy jawline keypoints. A reference camera with intrinsics &amp; extrinsics (<math id="S4.p7.2.m2.1" class="ltx_Math" alttext="K_{ref}" display="inline"><semantics id="S4.p7.2.m2.1a"><msub id="S4.p7.2.m2.1.1" xref="S4.p7.2.m2.1.1.cmml"><mi id="S4.p7.2.m2.1.1.2" xref="S4.p7.2.m2.1.1.2.cmml">K</mi><mrow id="S4.p7.2.m2.1.1.3" xref="S4.p7.2.m2.1.1.3.cmml"><mi id="S4.p7.2.m2.1.1.3.2" xref="S4.p7.2.m2.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.2.m2.1.1.3.1" xref="S4.p7.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.2.m2.1.1.3.3" xref="S4.p7.2.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.2.m2.1.1.3.1a" xref="S4.p7.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.2.m2.1.1.3.4" xref="S4.p7.2.m2.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.2.m2.1b"><apply id="S4.p7.2.m2.1.1.cmml" xref="S4.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p7.2.m2.1.1.1.cmml" xref="S4.p7.2.m2.1.1">subscript</csymbol><ci id="S4.p7.2.m2.1.1.2.cmml" xref="S4.p7.2.m2.1.1.2">ğ¾</ci><apply id="S4.p7.2.m2.1.1.3.cmml" xref="S4.p7.2.m2.1.1.3"><times id="S4.p7.2.m2.1.1.3.1.cmml" xref="S4.p7.2.m2.1.1.3.1"></times><ci id="S4.p7.2.m2.1.1.3.2.cmml" xref="S4.p7.2.m2.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.2.m2.1.1.3.3.cmml" xref="S4.p7.2.m2.1.1.3.3">ğ‘’</ci><ci id="S4.p7.2.m2.1.1.3.4.cmml" xref="S4.p7.2.m2.1.1.3.4">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.2.m2.1c">K_{ref}</annotation></semantics></math>,<math id="S4.p7.3.m3.1" class="ltx_Math" alttext="E_{ref}" display="inline"><semantics id="S4.p7.3.m3.1a"><msub id="S4.p7.3.m3.1.1" xref="S4.p7.3.m3.1.1.cmml"><mi id="S4.p7.3.m3.1.1.2" xref="S4.p7.3.m3.1.1.2.cmml">E</mi><mrow id="S4.p7.3.m3.1.1.3" xref="S4.p7.3.m3.1.1.3.cmml"><mi id="S4.p7.3.m3.1.1.3.2" xref="S4.p7.3.m3.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.3.m3.1.1.3.1" xref="S4.p7.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.3.m3.1.1.3.3" xref="S4.p7.3.m3.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.3.m3.1.1.3.1a" xref="S4.p7.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.3.m3.1.1.3.4" xref="S4.p7.3.m3.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.3.m3.1b"><apply id="S4.p7.3.m3.1.1.cmml" xref="S4.p7.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p7.3.m3.1.1.1.cmml" xref="S4.p7.3.m3.1.1">subscript</csymbol><ci id="S4.p7.3.m3.1.1.2.cmml" xref="S4.p7.3.m3.1.1.2">ğ¸</ci><apply id="S4.p7.3.m3.1.1.3.cmml" xref="S4.p7.3.m3.1.1.3"><times id="S4.p7.3.m3.1.1.3.1.cmml" xref="S4.p7.3.m3.1.1.3.1"></times><ci id="S4.p7.3.m3.1.1.3.2.cmml" xref="S4.p7.3.m3.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.3.m3.1.1.3.3.cmml" xref="S4.p7.3.m3.1.1.3.3">ğ‘’</ci><ci id="S4.p7.3.m3.1.1.3.4.cmml" xref="S4.p7.3.m3.1.1.3.4">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.3.m3.1c">E_{ref}</annotation></semantics></math>) is then positioned to obtain a perfectly frontal view (yaw=pitch=roll=0) of <math id="S4.p7.4.m4.1" class="ltx_Math" alttext="x_{ref}" display="inline"><semantics id="S4.p7.4.m4.1a"><msub id="S4.p7.4.m4.1.1" xref="S4.p7.4.m4.1.1.cmml"><mi id="S4.p7.4.m4.1.1.2" xref="S4.p7.4.m4.1.1.2.cmml">x</mi><mrow id="S4.p7.4.m4.1.1.3" xref="S4.p7.4.m4.1.1.3.cmml"><mi id="S4.p7.4.m4.1.1.3.2" xref="S4.p7.4.m4.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.4.m4.1.1.3.1" xref="S4.p7.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.4.m4.1.1.3.3" xref="S4.p7.4.m4.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.4.m4.1.1.3.1a" xref="S4.p7.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.4.m4.1.1.3.4" xref="S4.p7.4.m4.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.4.m4.1b"><apply id="S4.p7.4.m4.1.1.cmml" xref="S4.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p7.4.m4.1.1.1.cmml" xref="S4.p7.4.m4.1.1">subscript</csymbol><ci id="S4.p7.4.m4.1.1.2.cmml" xref="S4.p7.4.m4.1.1.2">ğ‘¥</ci><apply id="S4.p7.4.m4.1.1.3.cmml" xref="S4.p7.4.m4.1.1.3"><times id="S4.p7.4.m4.1.1.3.1.cmml" xref="S4.p7.4.m4.1.1.3.1"></times><ci id="S4.p7.4.m4.1.1.3.2.cmml" xref="S4.p7.4.m4.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.4.m4.1.1.3.3.cmml" xref="S4.p7.4.m4.1.1.3.3">ğ‘’</ci><ci id="S4.p7.4.m4.1.1.3.4.cmml" xref="S4.p7.4.m4.1.1.3.4">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.4.m4.1c">x_{ref}</annotation></semantics></math>. For each subject in each frame, we estimate the rigid transformation <math id="S4.p7.5.m5.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.p7.5.m5.1a"><mi id="S4.p7.5.m5.1.1" xref="S4.p7.5.m5.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.p7.5.m5.1b"><ci id="S4.p7.5.m5.1.1.cmml" xref="S4.p7.5.m5.1.1">ğ‘…</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.5.m5.1c">R</annotation></semantics></math> between <math id="S4.p7.6.m6.1" class="ltx_Math" alttext="x_{ref}" display="inline"><semantics id="S4.p7.6.m6.1a"><msub id="S4.p7.6.m6.1.1" xref="S4.p7.6.m6.1.1.cmml"><mi id="S4.p7.6.m6.1.1.2" xref="S4.p7.6.m6.1.1.2.cmml">x</mi><mrow id="S4.p7.6.m6.1.1.3" xref="S4.p7.6.m6.1.1.3.cmml"><mi id="S4.p7.6.m6.1.1.3.2" xref="S4.p7.6.m6.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.6.m6.1.1.3.1" xref="S4.p7.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.6.m6.1.1.3.3" xref="S4.p7.6.m6.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.6.m6.1.1.3.1a" xref="S4.p7.6.m6.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.6.m6.1.1.3.4" xref="S4.p7.6.m6.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.6.m6.1b"><apply id="S4.p7.6.m6.1.1.cmml" xref="S4.p7.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p7.6.m6.1.1.1.cmml" xref="S4.p7.6.m6.1.1">subscript</csymbol><ci id="S4.p7.6.m6.1.1.2.cmml" xref="S4.p7.6.m6.1.1.2">ğ‘¥</ci><apply id="S4.p7.6.m6.1.1.3.cmml" xref="S4.p7.6.m6.1.1.3"><times id="S4.p7.6.m6.1.1.3.1.cmml" xref="S4.p7.6.m6.1.1.3.1"></times><ci id="S4.p7.6.m6.1.1.3.2.cmml" xref="S4.p7.6.m6.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.6.m6.1.1.3.3.cmml" xref="S4.p7.6.m6.1.1.3.3">ğ‘’</ci><ci id="S4.p7.6.m6.1.1.3.4.cmml" xref="S4.p7.6.m6.1.1.3.4">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.6.m6.1c">x_{ref}</annotation></semantics></math> and the true keypoints <math id="S4.p7.7.m7.1" class="ltx_Math" alttext="x_{real}" display="inline"><semantics id="S4.p7.7.m7.1a"><msub id="S4.p7.7.m7.1.1" xref="S4.p7.7.m7.1.1.cmml"><mi id="S4.p7.7.m7.1.1.2" xref="S4.p7.7.m7.1.1.2.cmml">x</mi><mrow id="S4.p7.7.m7.1.1.3" xref="S4.p7.7.m7.1.1.3.cmml"><mi id="S4.p7.7.m7.1.1.3.2" xref="S4.p7.7.m7.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.7.m7.1.1.3.1" xref="S4.p7.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.7.m7.1.1.3.3" xref="S4.p7.7.m7.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.7.m7.1.1.3.1a" xref="S4.p7.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.7.m7.1.1.3.4" xref="S4.p7.7.m7.1.1.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p7.7.m7.1.1.3.1b" xref="S4.p7.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.7.m7.1.1.3.5" xref="S4.p7.7.m7.1.1.3.5.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.7.m7.1b"><apply id="S4.p7.7.m7.1.1.cmml" xref="S4.p7.7.m7.1.1"><csymbol cd="ambiguous" id="S4.p7.7.m7.1.1.1.cmml" xref="S4.p7.7.m7.1.1">subscript</csymbol><ci id="S4.p7.7.m7.1.1.2.cmml" xref="S4.p7.7.m7.1.1.2">ğ‘¥</ci><apply id="S4.p7.7.m7.1.1.3.cmml" xref="S4.p7.7.m7.1.1.3"><times id="S4.p7.7.m7.1.1.3.1.cmml" xref="S4.p7.7.m7.1.1.3.1"></times><ci id="S4.p7.7.m7.1.1.3.2.cmml" xref="S4.p7.7.m7.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.7.m7.1.1.3.3.cmml" xref="S4.p7.7.m7.1.1.3.3">ğ‘’</ci><ci id="S4.p7.7.m7.1.1.3.4.cmml" xref="S4.p7.7.m7.1.1.3.4">ğ‘</ci><ci id="S4.p7.7.m7.1.1.3.5.cmml" xref="S4.p7.7.m7.1.1.3.5">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.7.m7.1c">x_{real}</annotation></semantics></math> provided by the panoptic dataset usingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">Horn etÂ al.(1988)Horn, Hilden, and Negahdaripour</a>]</cite>. We then construct new extrinsics for a virtual camera <math id="S4.p7.8.m8.1" class="ltx_Math" alttext="E_{virt}=E_{ref}R^{-1}" display="inline"><semantics id="S4.p7.8.m8.1a"><mrow id="S4.p7.8.m8.1.1" xref="S4.p7.8.m8.1.1.cmml"><msub id="S4.p7.8.m8.1.1.2" xref="S4.p7.8.m8.1.1.2.cmml"><mi id="S4.p7.8.m8.1.1.2.2" xref="S4.p7.8.m8.1.1.2.2.cmml">E</mi><mrow id="S4.p7.8.m8.1.1.2.3" xref="S4.p7.8.m8.1.1.2.3.cmml"><mi id="S4.p7.8.m8.1.1.2.3.2" xref="S4.p7.8.m8.1.1.2.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.p7.8.m8.1.1.2.3.1" xref="S4.p7.8.m8.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.p7.8.m8.1.1.2.3.3" xref="S4.p7.8.m8.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.p7.8.m8.1.1.2.3.1a" xref="S4.p7.8.m8.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.p7.8.m8.1.1.2.3.4" xref="S4.p7.8.m8.1.1.2.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.8.m8.1.1.2.3.1b" xref="S4.p7.8.m8.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.p7.8.m8.1.1.2.3.5" xref="S4.p7.8.m8.1.1.2.3.5.cmml">t</mi></mrow></msub><mo id="S4.p7.8.m8.1.1.1" xref="S4.p7.8.m8.1.1.1.cmml">=</mo><mrow id="S4.p7.8.m8.1.1.3" xref="S4.p7.8.m8.1.1.3.cmml"><msub id="S4.p7.8.m8.1.1.3.2" xref="S4.p7.8.m8.1.1.3.2.cmml"><mi id="S4.p7.8.m8.1.1.3.2.2" xref="S4.p7.8.m8.1.1.3.2.2.cmml">E</mi><mrow id="S4.p7.8.m8.1.1.3.2.3" xref="S4.p7.8.m8.1.1.3.2.3.cmml"><mi id="S4.p7.8.m8.1.1.3.2.3.2" xref="S4.p7.8.m8.1.1.3.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.8.m8.1.1.3.2.3.1" xref="S4.p7.8.m8.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.8.m8.1.1.3.2.3.3" xref="S4.p7.8.m8.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.8.m8.1.1.3.2.3.1a" xref="S4.p7.8.m8.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.8.m8.1.1.3.2.3.4" xref="S4.p7.8.m8.1.1.3.2.3.4.cmml">f</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.p7.8.m8.1.1.3.1" xref="S4.p7.8.m8.1.1.3.1.cmml">â€‹</mo><msup id="S4.p7.8.m8.1.1.3.3" xref="S4.p7.8.m8.1.1.3.3.cmml"><mi id="S4.p7.8.m8.1.1.3.3.2" xref="S4.p7.8.m8.1.1.3.3.2.cmml">R</mi><mrow id="S4.p7.8.m8.1.1.3.3.3" xref="S4.p7.8.m8.1.1.3.3.3.cmml"><mo id="S4.p7.8.m8.1.1.3.3.3a" xref="S4.p7.8.m8.1.1.3.3.3.cmml">âˆ’</mo><mn id="S4.p7.8.m8.1.1.3.3.3.2" xref="S4.p7.8.m8.1.1.3.3.3.2.cmml">1</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p7.8.m8.1b"><apply id="S4.p7.8.m8.1.1.cmml" xref="S4.p7.8.m8.1.1"><eq id="S4.p7.8.m8.1.1.1.cmml" xref="S4.p7.8.m8.1.1.1"></eq><apply id="S4.p7.8.m8.1.1.2.cmml" xref="S4.p7.8.m8.1.1.2"><csymbol cd="ambiguous" id="S4.p7.8.m8.1.1.2.1.cmml" xref="S4.p7.8.m8.1.1.2">subscript</csymbol><ci id="S4.p7.8.m8.1.1.2.2.cmml" xref="S4.p7.8.m8.1.1.2.2">ğ¸</ci><apply id="S4.p7.8.m8.1.1.2.3.cmml" xref="S4.p7.8.m8.1.1.2.3"><times id="S4.p7.8.m8.1.1.2.3.1.cmml" xref="S4.p7.8.m8.1.1.2.3.1"></times><ci id="S4.p7.8.m8.1.1.2.3.2.cmml" xref="S4.p7.8.m8.1.1.2.3.2">ğ‘£</ci><ci id="S4.p7.8.m8.1.1.2.3.3.cmml" xref="S4.p7.8.m8.1.1.2.3.3">ğ‘–</ci><ci id="S4.p7.8.m8.1.1.2.3.4.cmml" xref="S4.p7.8.m8.1.1.2.3.4">ğ‘Ÿ</ci><ci id="S4.p7.8.m8.1.1.2.3.5.cmml" xref="S4.p7.8.m8.1.1.2.3.5">ğ‘¡</ci></apply></apply><apply id="S4.p7.8.m8.1.1.3.cmml" xref="S4.p7.8.m8.1.1.3"><times id="S4.p7.8.m8.1.1.3.1.cmml" xref="S4.p7.8.m8.1.1.3.1"></times><apply id="S4.p7.8.m8.1.1.3.2.cmml" xref="S4.p7.8.m8.1.1.3.2"><csymbol cd="ambiguous" id="S4.p7.8.m8.1.1.3.2.1.cmml" xref="S4.p7.8.m8.1.1.3.2">subscript</csymbol><ci id="S4.p7.8.m8.1.1.3.2.2.cmml" xref="S4.p7.8.m8.1.1.3.2.2">ğ¸</ci><apply id="S4.p7.8.m8.1.1.3.2.3.cmml" xref="S4.p7.8.m8.1.1.3.2.3"><times id="S4.p7.8.m8.1.1.3.2.3.1.cmml" xref="S4.p7.8.m8.1.1.3.2.3.1"></times><ci id="S4.p7.8.m8.1.1.3.2.3.2.cmml" xref="S4.p7.8.m8.1.1.3.2.3.2">ğ‘Ÿ</ci><ci id="S4.p7.8.m8.1.1.3.2.3.3.cmml" xref="S4.p7.8.m8.1.1.3.2.3.3">ğ‘’</ci><ci id="S4.p7.8.m8.1.1.3.2.3.4.cmml" xref="S4.p7.8.m8.1.1.3.2.3.4">ğ‘“</ci></apply></apply><apply id="S4.p7.8.m8.1.1.3.3.cmml" xref="S4.p7.8.m8.1.1.3.3"><csymbol cd="ambiguous" id="S4.p7.8.m8.1.1.3.3.1.cmml" xref="S4.p7.8.m8.1.1.3.3">superscript</csymbol><ci id="S4.p7.8.m8.1.1.3.3.2.cmml" xref="S4.p7.8.m8.1.1.3.3.2">ğ‘…</ci><apply id="S4.p7.8.m8.1.1.3.3.3.cmml" xref="S4.p7.8.m8.1.1.3.3.3"><minus id="S4.p7.8.m8.1.1.3.3.3.1.cmml" xref="S4.p7.8.m8.1.1.3.3.3"></minus><cn type="integer" id="S4.p7.8.m8.1.1.3.3.3.2.cmml" xref="S4.p7.8.m8.1.1.3.3.3.2">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.8.m8.1c">E_{virt}=E_{ref}R^{-1}</annotation></semantics></math>. This provides a (nominally) frontal view of the subject as they are positioned within the dome. Using the known real camera extrinsics <math id="S4.p7.9.m9.1" class="ltx_Math" alttext="E_{real}" display="inline"><semantics id="S4.p7.9.m9.1a"><msub id="S4.p7.9.m9.1.1" xref="S4.p7.9.m9.1.1.cmml"><mi id="S4.p7.9.m9.1.1.2" xref="S4.p7.9.m9.1.1.2.cmml">E</mi><mrow id="S4.p7.9.m9.1.1.3" xref="S4.p7.9.m9.1.1.3.cmml"><mi id="S4.p7.9.m9.1.1.3.2" xref="S4.p7.9.m9.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.9.m9.1.1.3.1" xref="S4.p7.9.m9.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.9.m9.1.1.3.3" xref="S4.p7.9.m9.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.9.m9.1.1.3.1a" xref="S4.p7.9.m9.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.9.m9.1.1.3.4" xref="S4.p7.9.m9.1.1.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p7.9.m9.1.1.3.1b" xref="S4.p7.9.m9.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.9.m9.1.1.3.5" xref="S4.p7.9.m9.1.1.3.5.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.9.m9.1b"><apply id="S4.p7.9.m9.1.1.cmml" xref="S4.p7.9.m9.1.1"><csymbol cd="ambiguous" id="S4.p7.9.m9.1.1.1.cmml" xref="S4.p7.9.m9.1.1">subscript</csymbol><ci id="S4.p7.9.m9.1.1.2.cmml" xref="S4.p7.9.m9.1.1.2">ğ¸</ci><apply id="S4.p7.9.m9.1.1.3.cmml" xref="S4.p7.9.m9.1.1.3"><times id="S4.p7.9.m9.1.1.3.1.cmml" xref="S4.p7.9.m9.1.1.3.1"></times><ci id="S4.p7.9.m9.1.1.3.2.cmml" xref="S4.p7.9.m9.1.1.3.2">ğ‘Ÿ</ci><ci id="S4.p7.9.m9.1.1.3.3.cmml" xref="S4.p7.9.m9.1.1.3.3">ğ‘’</ci><ci id="S4.p7.9.m9.1.1.3.4.cmml" xref="S4.p7.9.m9.1.1.3.4">ğ‘</ci><ci id="S4.p7.9.m9.1.1.3.5.cmml" xref="S4.p7.9.m9.1.1.3.5">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.9.m9.1c">E_{real}</annotation></semantics></math> from the panoptic dataset and <math id="S4.p7.10.m10.1" class="ltx_Math" alttext="E_{virt}" display="inline"><semantics id="S4.p7.10.m10.1a"><msub id="S4.p7.10.m10.1.1" xref="S4.p7.10.m10.1.1.cmml"><mi id="S4.p7.10.m10.1.1.2" xref="S4.p7.10.m10.1.1.2.cmml">E</mi><mrow id="S4.p7.10.m10.1.1.3" xref="S4.p7.10.m10.1.1.3.cmml"><mi id="S4.p7.10.m10.1.1.3.2" xref="S4.p7.10.m10.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.p7.10.m10.1.1.3.1" xref="S4.p7.10.m10.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.10.m10.1.1.3.3" xref="S4.p7.10.m10.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.p7.10.m10.1.1.3.1a" xref="S4.p7.10.m10.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.10.m10.1.1.3.4" xref="S4.p7.10.m10.1.1.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.10.m10.1.1.3.1b" xref="S4.p7.10.m10.1.1.3.1.cmml">â€‹</mo><mi id="S4.p7.10.m10.1.1.3.5" xref="S4.p7.10.m10.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p7.10.m10.1b"><apply id="S4.p7.10.m10.1.1.cmml" xref="S4.p7.10.m10.1.1"><csymbol cd="ambiguous" id="S4.p7.10.m10.1.1.1.cmml" xref="S4.p7.10.m10.1.1">subscript</csymbol><ci id="S4.p7.10.m10.1.1.2.cmml" xref="S4.p7.10.m10.1.1.2">ğ¸</ci><apply id="S4.p7.10.m10.1.1.3.cmml" xref="S4.p7.10.m10.1.1.3"><times id="S4.p7.10.m10.1.1.3.1.cmml" xref="S4.p7.10.m10.1.1.3.1"></times><ci id="S4.p7.10.m10.1.1.3.2.cmml" xref="S4.p7.10.m10.1.1.3.2">ğ‘£</ci><ci id="S4.p7.10.m10.1.1.3.3.cmml" xref="S4.p7.10.m10.1.1.3.3">ğ‘–</ci><ci id="S4.p7.10.m10.1.1.3.4.cmml" xref="S4.p7.10.m10.1.1.3.4">ğ‘Ÿ</ci><ci id="S4.p7.10.m10.1.1.3.5.cmml" xref="S4.p7.10.m10.1.1.3.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.10.m10.1c">E_{virt}</annotation></semantics></math>, we recover the rigid transformation <math id="S4.p7.11.m11.1" class="ltx_Math" alttext="T=E_{real}E_{virt}^{-1}" display="inline"><semantics id="S4.p7.11.m11.1a"><mrow id="S4.p7.11.m11.1.1" xref="S4.p7.11.m11.1.1.cmml"><mi id="S4.p7.11.m11.1.1.2" xref="S4.p7.11.m11.1.1.2.cmml">T</mi><mo id="S4.p7.11.m11.1.1.1" xref="S4.p7.11.m11.1.1.1.cmml">=</mo><mrow id="S4.p7.11.m11.1.1.3" xref="S4.p7.11.m11.1.1.3.cmml"><msub id="S4.p7.11.m11.1.1.3.2" xref="S4.p7.11.m11.1.1.3.2.cmml"><mi id="S4.p7.11.m11.1.1.3.2.2" xref="S4.p7.11.m11.1.1.3.2.2.cmml">E</mi><mrow id="S4.p7.11.m11.1.1.3.2.3" xref="S4.p7.11.m11.1.1.3.2.3.cmml"><mi id="S4.p7.11.m11.1.1.3.2.3.2" xref="S4.p7.11.m11.1.1.3.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.2.3.1" xref="S4.p7.11.m11.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.11.m11.1.1.3.2.3.3" xref="S4.p7.11.m11.1.1.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.2.3.1a" xref="S4.p7.11.m11.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.11.m11.1.1.3.2.3.4" xref="S4.p7.11.m11.1.1.3.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.2.3.1b" xref="S4.p7.11.m11.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.11.m11.1.1.3.2.3.5" xref="S4.p7.11.m11.1.1.3.2.3.5.cmml">l</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.1" xref="S4.p7.11.m11.1.1.3.1.cmml">â€‹</mo><msubsup id="S4.p7.11.m11.1.1.3.3" xref="S4.p7.11.m11.1.1.3.3.cmml"><mi id="S4.p7.11.m11.1.1.3.3.2.2" xref="S4.p7.11.m11.1.1.3.3.2.2.cmml">E</mi><mrow id="S4.p7.11.m11.1.1.3.3.2.3" xref="S4.p7.11.m11.1.1.3.3.2.3.cmml"><mi id="S4.p7.11.m11.1.1.3.3.2.3.2" xref="S4.p7.11.m11.1.1.3.3.2.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.3.2.3.1" xref="S4.p7.11.m11.1.1.3.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.11.m11.1.1.3.3.2.3.3" xref="S4.p7.11.m11.1.1.3.3.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.3.2.3.1a" xref="S4.p7.11.m11.1.1.3.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.11.m11.1.1.3.3.2.3.4" xref="S4.p7.11.m11.1.1.3.3.2.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.p7.11.m11.1.1.3.3.2.3.1b" xref="S4.p7.11.m11.1.1.3.3.2.3.1.cmml">â€‹</mo><mi id="S4.p7.11.m11.1.1.3.3.2.3.5" xref="S4.p7.11.m11.1.1.3.3.2.3.5.cmml">t</mi></mrow><mrow id="S4.p7.11.m11.1.1.3.3.3" xref="S4.p7.11.m11.1.1.3.3.3.cmml"><mo id="S4.p7.11.m11.1.1.3.3.3a" xref="S4.p7.11.m11.1.1.3.3.3.cmml">âˆ’</mo><mn id="S4.p7.11.m11.1.1.3.3.3.2" xref="S4.p7.11.m11.1.1.3.3.3.2.cmml">1</mn></mrow></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p7.11.m11.1b"><apply id="S4.p7.11.m11.1.1.cmml" xref="S4.p7.11.m11.1.1"><eq id="S4.p7.11.m11.1.1.1.cmml" xref="S4.p7.11.m11.1.1.1"></eq><ci id="S4.p7.11.m11.1.1.2.cmml" xref="S4.p7.11.m11.1.1.2">ğ‘‡</ci><apply id="S4.p7.11.m11.1.1.3.cmml" xref="S4.p7.11.m11.1.1.3"><times id="S4.p7.11.m11.1.1.3.1.cmml" xref="S4.p7.11.m11.1.1.3.1"></times><apply id="S4.p7.11.m11.1.1.3.2.cmml" xref="S4.p7.11.m11.1.1.3.2"><csymbol cd="ambiguous" id="S4.p7.11.m11.1.1.3.2.1.cmml" xref="S4.p7.11.m11.1.1.3.2">subscript</csymbol><ci id="S4.p7.11.m11.1.1.3.2.2.cmml" xref="S4.p7.11.m11.1.1.3.2.2">ğ¸</ci><apply id="S4.p7.11.m11.1.1.3.2.3.cmml" xref="S4.p7.11.m11.1.1.3.2.3"><times id="S4.p7.11.m11.1.1.3.2.3.1.cmml" xref="S4.p7.11.m11.1.1.3.2.3.1"></times><ci id="S4.p7.11.m11.1.1.3.2.3.2.cmml" xref="S4.p7.11.m11.1.1.3.2.3.2">ğ‘Ÿ</ci><ci id="S4.p7.11.m11.1.1.3.2.3.3.cmml" xref="S4.p7.11.m11.1.1.3.2.3.3">ğ‘’</ci><ci id="S4.p7.11.m11.1.1.3.2.3.4.cmml" xref="S4.p7.11.m11.1.1.3.2.3.4">ğ‘</ci><ci id="S4.p7.11.m11.1.1.3.2.3.5.cmml" xref="S4.p7.11.m11.1.1.3.2.3.5">ğ‘™</ci></apply></apply><apply id="S4.p7.11.m11.1.1.3.3.cmml" xref="S4.p7.11.m11.1.1.3.3"><csymbol cd="ambiguous" id="S4.p7.11.m11.1.1.3.3.1.cmml" xref="S4.p7.11.m11.1.1.3.3">superscript</csymbol><apply id="S4.p7.11.m11.1.1.3.3.2.cmml" xref="S4.p7.11.m11.1.1.3.3"><csymbol cd="ambiguous" id="S4.p7.11.m11.1.1.3.3.2.1.cmml" xref="S4.p7.11.m11.1.1.3.3">subscript</csymbol><ci id="S4.p7.11.m11.1.1.3.3.2.2.cmml" xref="S4.p7.11.m11.1.1.3.3.2.2">ğ¸</ci><apply id="S4.p7.11.m11.1.1.3.3.2.3.cmml" xref="S4.p7.11.m11.1.1.3.3.2.3"><times id="S4.p7.11.m11.1.1.3.3.2.3.1.cmml" xref="S4.p7.11.m11.1.1.3.3.2.3.1"></times><ci id="S4.p7.11.m11.1.1.3.3.2.3.2.cmml" xref="S4.p7.11.m11.1.1.3.3.2.3.2">ğ‘£</ci><ci id="S4.p7.11.m11.1.1.3.3.2.3.3.cmml" xref="S4.p7.11.m11.1.1.3.3.2.3.3">ğ‘–</ci><ci id="S4.p7.11.m11.1.1.3.3.2.3.4.cmml" xref="S4.p7.11.m11.1.1.3.3.2.3.4">ğ‘Ÿ</ci><ci id="S4.p7.11.m11.1.1.3.3.2.3.5.cmml" xref="S4.p7.11.m11.1.1.3.3.2.3.5">ğ‘¡</ci></apply></apply><apply id="S4.p7.11.m11.1.1.3.3.3.cmml" xref="S4.p7.11.m11.1.1.3.3.3"><minus id="S4.p7.11.m11.1.1.3.3.3.1.cmml" xref="S4.p7.11.m11.1.1.3.3.3"></minus><cn type="integer" id="S4.p7.11.m11.1.1.3.3.3.2.cmml" xref="S4.p7.11.m11.1.1.3.3.3.2">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.11.m11.1c">T=E_{real}E_{virt}^{-1}</annotation></semantics></math> between the virtual camera extrinsics and each real camera. Finally we extract Euler angles in pitch-yaw-roll (x-y-z) order from <math id="S4.p7.12.m12.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.p7.12.m12.1a"><mi id="S4.p7.12.m12.1.1" xref="S4.p7.12.m12.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.p7.12.m12.1b"><ci id="S4.p7.12.m12.1.1.cmml" xref="S4.p7.12.m12.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.12.m12.1c">T</annotation></semantics></math>, mirroring yaw and roll in order to match the rotation convention from the datasets. There is a translation component to the rigid transform but it is not needed to determine the head orientation with respect to the camera optical axes.</p>
</div>
<div id="S4.p8" class="ltx_para">
<p id="S4.p8.1" class="ltx_p">Using the synthetic reference and virtual camera in this process ensures that we have a consistent and automatic method for labeling. It also considerably reduces noise compared to manually selecting a frontal camera and annotating corresponding Euler angles.</p>
</div>
<div id="S4.p9" class="ltx_para">
<p id="S4.p9.1" class="ltx_p">To crop images, we define a spherical set of points around the subjectâ€™s head as a <span id="S4.p9.1.1" class="ltx_text ltx_font_italic">helmet</span> and project these into each view to determine a cropping region. Inspired by Ming et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite>, we leave a margin from the head bounding box so the network can learn to distinguish foreground and background. We followed the method of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite>, using K = 0.5 for data from 300W-LP and adjust the helmet radius to 21cm for CMU data.</p>
</div>
<div id="S4.p10" class="ltx_para">
<p id="S4.p10.1" class="ltx_p"><span id="S4.p10.1.1" class="ltx_text ltx_font_bold">Training</span> of WHENet is devided into two stages. We first train a narrow range model, WHENet-V with prediction range between <math id="S4.p10.1.m1.2" class="ltx_Math" alttext="[-99^{\circ},99^{\circ}]" display="inline"><semantics id="S4.p10.1.m1.2a"><mrow id="S4.p10.1.m1.2.2.2" xref="S4.p10.1.m1.2.2.3.cmml"><mo stretchy="false" id="S4.p10.1.m1.2.2.2.3" xref="S4.p10.1.m1.2.2.3.cmml">[</mo><mrow id="S4.p10.1.m1.1.1.1.1" xref="S4.p10.1.m1.1.1.1.1.cmml"><mo id="S4.p10.1.m1.1.1.1.1a" xref="S4.p10.1.m1.1.1.1.1.cmml">âˆ’</mo><msup id="S4.p10.1.m1.1.1.1.1.2" xref="S4.p10.1.m1.1.1.1.1.2.cmml"><mn id="S4.p10.1.m1.1.1.1.1.2.2" xref="S4.p10.1.m1.1.1.1.1.2.2.cmml">99</mn><mo id="S4.p10.1.m1.1.1.1.1.2.3" xref="S4.p10.1.m1.1.1.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><mo id="S4.p10.1.m1.2.2.2.4" xref="S4.p10.1.m1.2.2.3.cmml">,</mo><msup id="S4.p10.1.m1.2.2.2.2" xref="S4.p10.1.m1.2.2.2.2.cmml"><mn id="S4.p10.1.m1.2.2.2.2.2" xref="S4.p10.1.m1.2.2.2.2.2.cmml">99</mn><mo id="S4.p10.1.m1.2.2.2.2.3" xref="S4.p10.1.m1.2.2.2.2.3.cmml">âˆ˜</mo></msup><mo stretchy="false" id="S4.p10.1.m1.2.2.2.5" xref="S4.p10.1.m1.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p10.1.m1.2b"><interval closure="closed" id="S4.p10.1.m1.2.2.3.cmml" xref="S4.p10.1.m1.2.2.2"><apply id="S4.p10.1.m1.1.1.1.1.cmml" xref="S4.p10.1.m1.1.1.1.1"><minus id="S4.p10.1.m1.1.1.1.1.1.cmml" xref="S4.p10.1.m1.1.1.1.1"></minus><apply id="S4.p10.1.m1.1.1.1.1.2.cmml" xref="S4.p10.1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.p10.1.m1.1.1.1.1.2.1.cmml" xref="S4.p10.1.m1.1.1.1.1.2">superscript</csymbol><cn type="integer" id="S4.p10.1.m1.1.1.1.1.2.2.cmml" xref="S4.p10.1.m1.1.1.1.1.2.2">99</cn><compose id="S4.p10.1.m1.1.1.1.1.2.3.cmml" xref="S4.p10.1.m1.1.1.1.1.2.3"></compose></apply></apply><apply id="S4.p10.1.m1.2.2.2.2.cmml" xref="S4.p10.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.p10.1.m1.2.2.2.2.1.cmml" xref="S4.p10.1.m1.2.2.2.2">superscript</csymbol><cn type="integer" id="S4.p10.1.m1.2.2.2.2.2.cmml" xref="S4.p10.1.m1.2.2.2.2.2">99</cn><compose id="S4.p10.1.m1.2.2.2.2.3.cmml" xref="S4.p10.1.m1.2.2.2.2.3"></compose></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p10.1.m1.2c">[-99^{\circ},99^{\circ}]</annotation></semantics></math> for yaw, pitch and roll. We train this narrow range network on the 300W-LPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> dataset using an ADAM optimizer with learning rate 1e-5. Full-range WHENet with 120 yaw bins is then trained starting from the WHENet-V weights using our full-rage data set combining 300W-LP and CMU Panoptic Dataset data. We use the same optimizer and learning rate for this step. This two-stage approach helps the full-range network converge better and learn more useful features since the CMU data has little background variation. During training, images are randomly downsampled by up to 15X to improve robustness.</p>
</div>
<div id="S4.p11" class="ltx_para">
<p id="S4.p11.1" class="ltx_p">Training data from 300W-LP and the panoptic dataset is used in nearly equal amounts, with the former providing narrow range samples and the latter primarily handling wide range. A small amount of panoptic data is also used to level a dip in the histogram of narrow range images near yaw=0.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results &amp; Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.5" class="ltx_p">For wide range results in this section, we define the Absolute Wrapped Error (AWE) as <math id="S5.p1.1.m1.3" class="ltx_Math" alttext="{AWE}=\min\left(|\theta_{pred}-\theta_{true}|,360-|\theta_{pred}-\theta_{true}|\right)" display="inline"><semantics id="S5.p1.1.m1.3a"><mrow id="S5.p1.1.m1.3.3" xref="S5.p1.1.m1.3.3.cmml"><mrow id="S5.p1.1.m1.3.3.4" xref="S5.p1.1.m1.3.3.4.cmml"><mi id="S5.p1.1.m1.3.3.4.2" xref="S5.p1.1.m1.3.3.4.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.4.1" xref="S5.p1.1.m1.3.3.4.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.4.3" xref="S5.p1.1.m1.3.3.4.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.4.1a" xref="S5.p1.1.m1.3.3.4.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.4.4" xref="S5.p1.1.m1.3.3.4.4.cmml">E</mi></mrow><mo id="S5.p1.1.m1.3.3.3" xref="S5.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S5.p1.1.m1.3.3.2.2" xref="S5.p1.1.m1.3.3.2.3.cmml"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">min</mi><mo id="S5.p1.1.m1.3.3.2.2a" xref="S5.p1.1.m1.3.3.2.3.cmml">â¡</mo><mrow id="S5.p1.1.m1.3.3.2.2.2" xref="S5.p1.1.m1.3.3.2.3.cmml"><mo id="S5.p1.1.m1.3.3.2.2.2.3" xref="S5.p1.1.m1.3.3.2.3.cmml">(</mo><mrow id="S5.p1.1.m1.2.2.1.1.1.1.1" xref="S5.p1.1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S5.p1.1.m1.2.2.1.1.1.1.1.2" xref="S5.p1.1.m1.2.2.1.1.1.1.2.1.cmml">|</mo><mrow id="S5.p1.1.m1.2.2.1.1.1.1.1.1" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.cmml"><msub id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.2" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.2.cmml">Î¸</mi><mrow id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.cmml"><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.2" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.3" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1a" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.4" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1b" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.5" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo id="S5.p1.1.m1.2.2.1.1.1.1.1.1.1" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.2" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.2.cmml">Î¸</mi><mrow id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.cmml"><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.2" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.3" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1a" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.4" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1b" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.5" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.5.cmml">e</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p1.1.m1.2.2.1.1.1.1.1.3" xref="S5.p1.1.m1.2.2.1.1.1.1.2.1.cmml">|</mo></mrow><mo id="S5.p1.1.m1.3.3.2.2.2.4" xref="S5.p1.1.m1.3.3.2.3.cmml">,</mo><mrow id="S5.p1.1.m1.3.3.2.2.2.2" xref="S5.p1.1.m1.3.3.2.2.2.2.cmml"><mn id="S5.p1.1.m1.3.3.2.2.2.2.3" xref="S5.p1.1.m1.3.3.2.2.2.2.3.cmml">360</mn><mo id="S5.p1.1.m1.3.3.2.2.2.2.2" xref="S5.p1.1.m1.3.3.2.2.2.2.2.cmml">âˆ’</mo><mrow id="S5.p1.1.m1.3.3.2.2.2.2.1.1" xref="S5.p1.1.m1.3.3.2.2.2.2.1.2.cmml"><mo stretchy="false" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.2" xref="S5.p1.1.m1.3.3.2.2.2.2.1.2.1.cmml">|</mo><mrow id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.cmml"><msub id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.cmml"><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.2" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.2.cmml">Î¸</mi><mrow id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.cmml"><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.2" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.3" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1a" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.4" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1b" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.5" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.1" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.1.cmml">âˆ’</mo><msub id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.cmml"><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.2" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.2.cmml">Î¸</mi><mrow id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.cmml"><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.2" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.3" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1a" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.4" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1b" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.5" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.5.cmml">e</mi></mrow></msub></mrow><mo stretchy="false" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.3" xref="S5.p1.1.m1.3.3.2.2.2.2.1.2.1.cmml">|</mo></mrow></mrow><mo id="S5.p1.1.m1.3.3.2.2.2.5" xref="S5.p1.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.3b"><apply id="S5.p1.1.m1.3.3.cmml" xref="S5.p1.1.m1.3.3"><eq id="S5.p1.1.m1.3.3.3.cmml" xref="S5.p1.1.m1.3.3.3"></eq><apply id="S5.p1.1.m1.3.3.4.cmml" xref="S5.p1.1.m1.3.3.4"><times id="S5.p1.1.m1.3.3.4.1.cmml" xref="S5.p1.1.m1.3.3.4.1"></times><ci id="S5.p1.1.m1.3.3.4.2.cmml" xref="S5.p1.1.m1.3.3.4.2">ğ´</ci><ci id="S5.p1.1.m1.3.3.4.3.cmml" xref="S5.p1.1.m1.3.3.4.3">ğ‘Š</ci><ci id="S5.p1.1.m1.3.3.4.4.cmml" xref="S5.p1.1.m1.3.3.4.4">ğ¸</ci></apply><apply id="S5.p1.1.m1.3.3.2.3.cmml" xref="S5.p1.1.m1.3.3.2.2"><min id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"></min><apply id="S5.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1"><abs id="S5.p1.1.m1.2.2.1.1.1.1.2.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.2"></abs><apply id="S5.p1.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1"><minus id="S5.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.1"></minus><apply id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.2">ğœƒ</ci><apply id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3"><times id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.1"></times><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.2.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.3.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.4.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.4">ğ‘’</ci><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.5.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.2.3.5">ğ‘‘</ci></apply></apply><apply id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.2">ğœƒ</ci><apply id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3"><times id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.1"></times><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.2">ğ‘¡</ci><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.3">ğ‘Ÿ</ci><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.4.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.4">ğ‘¢</ci><ci id="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.5.cmml" xref="S5.p1.1.m1.2.2.1.1.1.1.1.1.3.3.5">ğ‘’</ci></apply></apply></apply></apply><apply id="S5.p1.1.m1.3.3.2.2.2.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2"><minus id="S5.p1.1.m1.3.3.2.2.2.2.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.2"></minus><cn type="integer" id="S5.p1.1.m1.3.3.2.2.2.2.3.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.3">360</cn><apply id="S5.p1.1.m1.3.3.2.2.2.2.1.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1"><abs id="S5.p1.1.m1.3.3.2.2.2.2.1.2.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.2"></abs><apply id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1"><minus id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.1"></minus><apply id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2">subscript</csymbol><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.2">ğœƒ</ci><apply id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3"><times id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.1"></times><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.2">ğ‘</ci><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.3.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.4.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.4">ğ‘’</ci><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.5.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.2.3.5">ğ‘‘</ci></apply></apply><apply id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3">subscript</csymbol><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.2">ğœƒ</ci><apply id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3"><times id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.1"></times><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.2.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.2">ğ‘¡</ci><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.3.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.3">ğ‘Ÿ</ci><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.4.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.4">ğ‘¢</ci><ci id="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.5.cmml" xref="S5.p1.1.m1.3.3.2.2.2.2.1.1.1.3.3.5">ğ‘’</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.3c">{AWE}=\min\left(|\theta_{pred}-\theta_{true}|,360-|\theta_{pred}-\theta_{true}|\right)</annotation></semantics></math> which properly handles wrapping of yaws. We also define Mean AWE (MAWE) as the arithmetic mean of AWE. For results below, we are using <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p1.2.m2.1a"><mi id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><ci id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">\alpha</annotation></semantics></math> = 1, <math id="S5.p1.3.m3.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="S5.p1.3.m3.1a"><mrow id="S5.p1.3.m3.1.1" xref="S5.p1.3.m3.1.1.cmml"><mi id="S5.p1.3.m3.1.1.2" xref="S5.p1.3.m3.1.1.2.cmml">Î²</mi><mo id="S5.p1.3.m3.1.1.1" xref="S5.p1.3.m3.1.1.1.cmml">=</mo><mn id="S5.p1.3.m3.1.1.3" xref="S5.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.3.m3.1b"><apply id="S5.p1.3.m3.1.1.cmml" xref="S5.p1.3.m3.1.1"><eq id="S5.p1.3.m3.1.1.1.cmml" xref="S5.p1.3.m3.1.1.1"></eq><ci id="S5.p1.3.m3.1.1.2.cmml" xref="S5.p1.3.m3.1.1.2">ğ›½</ci><cn type="integer" id="S5.p1.3.m3.1.1.3.cmml" xref="S5.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.3.m3.1c">\beta=1</annotation></semantics></math> for WHENet and <math id="S5.p1.4.m4.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="S5.p1.4.m4.1a"><mrow id="S5.p1.4.m4.1.1" xref="S5.p1.4.m4.1.1.cmml"><mi id="S5.p1.4.m4.1.1.2" xref="S5.p1.4.m4.1.1.2.cmml">Î±</mi><mo id="S5.p1.4.m4.1.1.1" xref="S5.p1.4.m4.1.1.1.cmml">=</mo><mn id="S5.p1.4.m4.1.1.3" xref="S5.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.4.m4.1b"><apply id="S5.p1.4.m4.1.1.cmml" xref="S5.p1.4.m4.1.1"><eq id="S5.p1.4.m4.1.1.1.cmml" xref="S5.p1.4.m4.1.1.1"></eq><ci id="S5.p1.4.m4.1.1.2.cmml" xref="S5.p1.4.m4.1.1.2">ğ›¼</ci><cn type="float" id="S5.p1.4.m4.1.1.3.cmml" xref="S5.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.4.m4.1c">\alpha=0.5</annotation></semantics></math>, <math id="S5.p1.5.m5.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="S5.p1.5.m5.1a"><mrow id="S5.p1.5.m5.1.1" xref="S5.p1.5.m5.1.1.cmml"><mi id="S5.p1.5.m5.1.1.2" xref="S5.p1.5.m5.1.1.2.cmml">Î²</mi><mo id="S5.p1.5.m5.1.1.1" xref="S5.p1.5.m5.1.1.1.cmml">=</mo><mn id="S5.p1.5.m5.1.1.3" xref="S5.p1.5.m5.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.5.m5.1b"><apply id="S5.p1.5.m5.1.1.cmml" xref="S5.p1.5.m5.1.1"><eq id="S5.p1.5.m5.1.1.1.cmml" xref="S5.p1.5.m5.1.1.1"></eq><ci id="S5.p1.5.m5.1.1.2.cmml" xref="S5.p1.5.m5.1.1.2">ğ›½</ci><cn type="integer" id="S5.p1.5.m5.1.1.3.cmml" xref="S5.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.5.m5.1c">\beta=2</annotation></semantics></math> for WHENet-V based on our ablations. Hyperparameter details can be found in our supplementary.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">TableÂ <a href="#S5.T1" title="Table 1 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes key results from WHENet and WHENet-V. We compare with eight narrow &amp; two full-range methods and report, where applicable/available, the output range, number of parameters, mean average errors on BIWIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite>, AFLW-2000Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>, an average of both (to indicate generalization) and reported full-range MAE if applicable. WHENet &amp; WHENet-V are trained on 300W-LPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> or our combined dataset and are not trained on the AFLW2000 or BIWI datasets, as is standard practice. We begin with a discussion of the full-range network WHENet, as this is our primary application.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of results: â€˜Aggr. MAEâ€™: average of BIWI and AFLW2000 overall results. â€˜Full MWAEâ€™: full-range results. <span id="S5.T1.8.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">first/only</span><span id="S5.T1.9.2" class="ltx_text ltx_font_bold">, second, -: not reported</span></figcaption>
<table id="S5.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.5.6.1" class="ltx_tr">
<th id="S5.T1.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Method</th>
<td id="S5.T1.5.6.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Full</td>
<td id="S5.T1.5.6.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Params</td>
<td id="S5.T1.5.6.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">BIWI</td>
<td id="S5.T1.5.6.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">AFLW2k</td>
<td id="S5.T1.5.6.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Avg.</td>
<td id="S5.T1.5.6.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Full</td>
</tr>
<tr id="S5.T1.5.5" class="ltx_tr">
<th id="S5.T1.5.5.6" class="ltx_td ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;"></th>
<td id="S5.T1.5.5.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Range</td>
<td id="S5.T1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">(<math id="S5.T1.1.1.1.m1.1" class="ltx_Math" alttext="\times 10^{6}" display="inline"><semantics id="S5.T1.1.1.1.m1.1a"><mrow id="S5.T1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.m1.1.1.cmml"><mi id="S5.T1.1.1.1.m1.1.1.2" xref="S5.T1.1.1.1.m1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0.222em" id="S5.T1.1.1.1.m1.1.1.1" xref="S5.T1.1.1.1.m1.1.1.1.cmml">Ã—</mo><msup id="S5.T1.1.1.1.m1.1.1.3" xref="S5.T1.1.1.1.m1.1.1.3.cmml"><mn id="S5.T1.1.1.1.m1.1.1.3.2" xref="S5.T1.1.1.1.m1.1.1.3.2.cmml">10</mn><mn id="S5.T1.1.1.1.m1.1.1.3.3" xref="S5.T1.1.1.1.m1.1.1.3.3.cmml">6</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.m1.1b"><apply id="S5.T1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1"><times id="S5.T1.1.1.1.m1.1.1.1.cmml" xref="S5.T1.1.1.1.m1.1.1.1"></times><csymbol cd="latexml" id="S5.T1.1.1.1.m1.1.1.2.cmml" xref="S5.T1.1.1.1.m1.1.1.2">absent</csymbol><apply id="S5.T1.1.1.1.m1.1.1.3.cmml" xref="S5.T1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.T1.1.1.1.m1.1.1.3.1.cmml" xref="S5.T1.1.1.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.T1.1.1.1.m1.1.1.3.2.cmml" xref="S5.T1.1.1.1.m1.1.1.3.2">10</cn><cn type="integer" id="S5.T1.1.1.1.m1.1.1.3.3.cmml" xref="S5.T1.1.1.1.m1.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.m1.1c">\times 10^{6}</annotation></semantics></math>)</td>
<td id="S5.T1.2.2.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">MAE<sup id="S5.T1.2.2.2.1" class="ltx_sup">âˆ˜</sup>
</td>
<td id="S5.T1.3.3.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">MAE<sup id="S5.T1.3.3.3.1" class="ltx_sup">âˆ˜</sup>
</td>
<td id="S5.T1.4.4.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">MAE<sup id="S5.T1.4.4.4.1" class="ltx_sup">âˆ˜</sup>
</td>
<td id="S5.T1.5.5.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">MAWE<sup id="S5.T1.5.5.5.1" class="ltx_sup">âˆ˜</sup>
</td>
</tr>
<tr id="S5.T1.5.7.2" class="ltx_tr">
<th id="S5.T1.5.7.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">KEPLERÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">Kumar etÂ al.(2017)Kumar, Alavi, and Chellappa</a>]</cite>
</th>
<td id="S5.T1.5.7.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.7.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.7.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">13.852</td>
<td id="S5.T1.5.7.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.7.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.7.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.8.3" class="ltx_tr">
<th id="S5.T1.5.8.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Dlib (68 points)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Kazemi and Sullivan(2014)</a>]</cite>
</th>
<td id="S5.T1.5.8.3.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.8.3.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.8.3.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">12.249</td>
<td id="S5.T1.5.8.3.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">15.777</td>
<td id="S5.T1.5.8.3.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">14.013</td>
<td id="S5.T1.5.8.3.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.9.4" class="ltx_tr">
<th id="S5.T1.5.9.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">FAN (12 points)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">Bulat and Tzimiropoulos(2017)</a>]</cite>
</th>
<td id="S5.T1.5.9.4.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.9.4.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">6-24</td>
<td id="S5.T1.5.9.4.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">7.882</td>
<td id="S5.T1.5.9.4.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">9.116</td>
<td id="S5.T1.5.9.4.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">8.499</td>
<td id="S5.T1.5.9.4.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.10.5" class="ltx_tr">
<th id="S5.T1.5.10.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3DDFAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>
</th>
<td id="S5.T1.5.10.5.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.10.5.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.10.5.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">19.07</td>
<td id="S5.T1.5.10.5.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">7.393</td>
<td id="S5.T1.5.10.5.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">13.231</td>
<td id="S5.T1.5.10.5.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.11.6" class="ltx_tr">
<th id="S5.T1.5.11.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Shao <em id="S5.T1.5.11.6.1.1" class="ltx_emph ltx_font_italic">et al</em><span id="S5.T1.5.11.6.1.2" class="ltx_ERROR undefined">\bmvaOneDot</span>(K=0.5)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite>
</th>
<td id="S5.T1.5.11.6.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.11.6.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">24.6</td>
<td id="S5.T1.5.11.6.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">5.999</td>
<td id="S5.T1.5.11.6.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">5.478</td>
<td id="S5.T1.5.11.6.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">5.875</td>
<td id="S5.T1.5.11.6.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.12.7" class="ltx_tr">
<th id="S5.T1.5.12.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">HopenetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite>
</th>
<td id="S5.T1.5.12.7.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.12.7.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">23.9</td>
<td id="S5.T1.5.12.7.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">4.895</td>
<td id="S5.T1.5.12.7.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">6.155</td>
<td id="S5.T1.5.12.7.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">5.525</td>
<td id="S5.T1.5.12.7.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.13.8" class="ltx_tr">
<th id="S5.T1.5.13.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">SSR-Net-MDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx47" title="" class="ltx_ref">Yang etÂ al.(2018)Yang, Huang, Lin, Hsiu, and Chuang</a>]</cite>
</th>
<td id="S5.T1.5.13.8.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.13.8.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.13.8.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">0.2</span></td>
<td id="S5.T1.5.13.8.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">4.650</td>
<td id="S5.T1.5.13.8.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">6.010</td>
<td id="S5.T1.5.13.8.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">5.330</td>
<td id="S5.T1.5.13.8.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.14.9" class="ltx_tr">
<th id="S5.T1.5.14.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">FSA-Caps-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite>
</th>
<td id="S5.T1.5.14.9.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.14.9.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.14.9.3.1" class="ltx_text ltx_font_bold">1.2</span></td>
<td id="S5.T1.5.14.9.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">4.000</td>
<td id="S5.T1.5.14.9.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.14.9.5.1" class="ltx_text ltx_font_bold">5.070</span></td>
<td id="S5.T1.5.14.9.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.14.9.6.1" class="ltx_text ltx_font_bold">4.535</span></td>
<td id="S5.T1.5.14.9.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.15.10" class="ltx_tr">
<th id="S5.T1.5.15.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Rehder et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx32" title="" class="ltx_ref">Rehder etÂ al.(2014)Rehder, Kloeden, and Stiller</a>]</cite>
</th>
<td id="S5.T1.5.15.10.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Yaw</td>
<td id="S5.T1.5.15.10.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.15.10.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.15.10.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.15.10.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.15.10.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">19.0</td>
</tr>
<tr id="S5.T1.5.16.11" class="ltx_tr">
<th id="S5.T1.5.16.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Raza et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">Raza etÂ al.(2018)Raza, Chen, Rehman, Wang, and
Bao</a>]</cite>
</th>
<td id="S5.T1.5.16.11.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Yaw</td>
<td id="S5.T1.5.16.11.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.16.11.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.16.11.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.16.11.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S5.T1.5.16.11.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.16.11.7.1" class="ltx_text ltx_font_bold">11.25</span></td>
</tr>
<tr id="S5.T1.5.17.12" class="ltx_tr">
<th id="S5.T1.5.17.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">WHENet-V</th>
<td id="S5.T1.5.17.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">N</td>
<td id="S5.T1.5.17.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">4.4</td>
<td id="S5.T1.5.17.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.17.12.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">3.475</span></td>
<td id="S5.T1.5.17.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.17.12.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.834</span></td>
<td id="S5.T1.5.17.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.17.12.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.155</span></td>
<td id="S5.T1.5.17.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
</tr>
<tr id="S5.T1.5.18.13" class="ltx_tr">
<th id="S5.T1.5.18.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">WHENet</th>
<td id="S5.T1.5.18.13.2" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Y</td>
<td id="S5.T1.5.18.13.3" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">4.4</td>
<td id="S5.T1.5.18.13.4" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.18.13.4.1" class="ltx_text ltx_font_bold">3.814</span></td>
<td id="S5.T1.5.18.13.5" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">5.424</td>
<td id="S5.T1.5.18.13.6" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">4.619</td>
<td id="S5.T1.5.18.13.7" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S5.T1.5.18.13.7.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">7.655</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Full-range WHENet results and comparisons</span> are shown in TableÂ <a href="#S5.T1" title="Table 1 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Of the three full-range methods compared, WHENet is the only method to also predict pitch and roll. Comparisons are difficult to perform objectively since both Raza et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">Raza etÂ al.(2018)Raza, Chen, Rehman, Wang, and
Bao</a>]</cite> and Rehder et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx32" title="" class="ltx_ref">Rehder etÂ al.(2014)Rehder, Kloeden, and Stiller</a>]</cite> predict yaws only (no pitch and roll) and do so on non-public datasets. ForÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx31" title="" class="ltx_ref">Raza etÂ al.(2018)Raza, Chen, Rehman, Wang, and
Bao</a>]</cite>, MAE was not reported, so we report the lowest possible errors given a uniform distribution of yaws with their bin-widths (i.e. the result if their method performed perfectly). WHENet still shows a 31% improvements, although these results should be treated as qualitative given lack of consistent testing data. This latter point is something we attempt to address in this work by making our dataset processing code for the CMU Panoptic DatasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite> public.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Additionally, excluding WHENet-V, full-range WHENet has the lowest average errors on BIWI, second-lowest errors on AFLW2000 and has second lowest average overall errors, missing first place by 0.084<sup id="S5.p4.1.1" class="ltx_sup">âˆ˜</sup> (1.8%) to FSANetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite>. This is significant since full-range WHENet was not trained specifically for the narrow range task, yet is still state-of-the-art or very competitve with FSANetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite>, a significantly more complex network. In handling full-range inputs, WHENet is significantly more capable than FSANet, yet sacrifices remarkably little accuracy.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows pose predictions generated using WHENet to track a subject rotating through a full revolution of yaw. WHENet produces coherent predictions throughout, even when the face is completely absent. A key to achieving this is our wrapped loss function, which significantly improves anterior views. Without the wrapped loss predictions are erratic and often nearly 180<sup id="S5.p5.1.1" class="ltx_sup">âˆ˜</sup> from the true pose as shown in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Our Method â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. This improvement is enabled by our annotation process for the CMU panoptic datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite> which allows us to automatically generate labelings for tens of thousands of anterior views to tackle this challenge.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.3" class="ltx_p"><span id="S5.p6.3.1" class="ltx_text ltx_font_bold">Narrow range results and comparisons</span> are listed in TablesÂ <a href="#S5.T2" title="Table 2 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Dlib<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Kazemi and Sullivan(2014)</a>]</cite>, KEPLER<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">Kumar etÂ al.(2017)Kumar, Alavi, and Chellappa</a>]</cite> and FAN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">Bulat and Tzimiropoulos(2017)</a>]</cite> are all landmark based methods. 3DDFA<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite> uses CNN to fit a 3D dense model to a RGB image. Hopenet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> and FSANet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite> are two landmark-free methods both of which explore the possbility of treating a continuous problem (head pose) into different classes/stages. As showed in TablesÂ <a href="#S5.T2" title="Table 2 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, WHENet-V achieves state-of-the-art accuracy on both BIWIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite> and AFLW2000Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>, and outperforms the previous state-of-the-art FSANetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite> by <math id="S5.p6.1.m1.1" class="ltx_Math" alttext="0.52^{\circ}" display="inline"><semantics id="S5.p6.1.m1.1a"><msup id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml"><mn id="S5.p6.1.m1.1.1.2" xref="S5.p6.1.m1.1.1.2.cmml">0.52</mn><mo id="S5.p6.1.m1.1.1.3" xref="S5.p6.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><apply id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.1.cmml" xref="S5.p6.1.m1.1.1">superscript</csymbol><cn type="float" id="S5.p6.1.m1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.2">0.52</cn><compose id="S5.p6.1.m1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">0.52^{\circ}</annotation></semantics></math> (13.1%) and <math id="S5.p6.2.m2.1" class="ltx_Math" alttext="0.24^{\circ}" display="inline"><semantics id="S5.p6.2.m2.1a"><msup id="S5.p6.2.m2.1.1" xref="S5.p6.2.m2.1.1.cmml"><mn id="S5.p6.2.m2.1.1.2" xref="S5.p6.2.m2.1.1.2.cmml">0.24</mn><mo id="S5.p6.2.m2.1.1.3" xref="S5.p6.2.m2.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.p6.2.m2.1b"><apply id="S5.p6.2.m2.1.1.cmml" xref="S5.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p6.2.m2.1.1.1.cmml" xref="S5.p6.2.m2.1.1">superscript</csymbol><cn type="float" id="S5.p6.2.m2.1.1.2.cmml" xref="S5.p6.2.m2.1.1.2">0.24</cn><compose id="S5.p6.2.m2.1.1.3.cmml" xref="S5.p6.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.2.m2.1c">0.24^{\circ}</annotation></semantics></math> (4.7%) respectively, leading to an aggregate improvement of 0.38<sup id="S5.p6.3.2" class="ltx_sup">âˆ˜</sup> (8.4%) on the two datasets overall. It also achieve first place in every metric. Interestingly, WHENet-V shows a 29% and 21% improvement over HopeNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> on these datasets, despite of having a very similar network architecture.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison with state-of-the-art on BIWI<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool</a>]</cite>(left) and AFLW2000<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>(right) dataset. Best (bold underlined) and second best (bold) results are highlighted.</figcaption>
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" colspan="4">BIWI</td>
<td id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_t" colspan="4">AFLW2000</td>
</tr>
<tr id="S5.T2.1.2.2" class="ltx_tr">
<th id="S5.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Method</th>
<td id="S5.T2.1.2.2.2" class="ltx_td ltx_align_left ltx_border_t">Yaw</td>
<td id="S5.T2.1.2.2.3" class="ltx_td ltx_align_left ltx_border_t">Pitch</td>
<td id="S5.T2.1.2.2.4" class="ltx_td ltx_align_left ltx_border_t">Roll</td>
<td id="S5.T2.1.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MAE</td>
<td id="S5.T2.1.2.2.6" class="ltx_td ltx_align_left ltx_border_t">Yaw</td>
<td id="S5.T2.1.2.2.7" class="ltx_td ltx_align_left ltx_border_t">Pitch</td>
<td id="S5.T2.1.2.2.8" class="ltx_td ltx_align_left ltx_border_t">Roll</td>
<td id="S5.T2.1.2.2.9" class="ltx_td ltx_align_left ltx_border_t">MAE</td>
</tr>
<tr id="S5.T2.1.3.3" class="ltx_tr">
<th id="S5.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">KEPLERÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">Kumar etÂ al.(2017)Kumar, Alavi, and Chellappa</a>]</cite>
</th>
<td id="S5.T2.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t">8.80</td>
<td id="S5.T2.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">17.3</td>
<td id="S5.T2.1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">16.2</td>
<td id="S5.T2.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13.9</td>
<td id="S5.T2.1.3.3.6" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="S5.T2.1.3.3.7" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="S5.T2.1.3.3.8" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="S5.T2.1.3.3.9" class="ltx_td ltx_align_left ltx_border_t">-</td>
</tr>
<tr id="S5.T2.1.4.4" class="ltx_tr">
<th id="S5.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Dlib (68 points)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Kazemi and Sullivan(2014)</a>]</cite>
</th>
<td id="S5.T2.1.4.4.2" class="ltx_td ltx_align_left">16.8</td>
<td id="S5.T2.1.4.4.3" class="ltx_td ltx_align_left">13.8</td>
<td id="S5.T2.1.4.4.4" class="ltx_td ltx_align_left">6.19</td>
<td id="S5.T2.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r">12.2</td>
<td id="S5.T2.1.4.4.6" class="ltx_td ltx_align_left">23.1</td>
<td id="S5.T2.1.4.4.7" class="ltx_td ltx_align_left">13.6</td>
<td id="S5.T2.1.4.4.8" class="ltx_td ltx_align_left">10.5</td>
<td id="S5.T2.1.4.4.9" class="ltx_td ltx_align_left">15.8</td>
</tr>
<tr id="S5.T2.1.5.5" class="ltx_tr">
<th id="S5.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">FAN (12 points)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">Bulat and Tzimiropoulos(2017)</a>]</cite>
</th>
<td id="S5.T2.1.5.5.2" class="ltx_td ltx_align_left">-</td>
<td id="S5.T2.1.5.5.3" class="ltx_td ltx_align_left">-</td>
<td id="S5.T2.1.5.5.4" class="ltx_td ltx_align_left">-</td>
<td id="S5.T2.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r">-</td>
<td id="S5.T2.1.5.5.6" class="ltx_td ltx_align_left">8.53</td>
<td id="S5.T2.1.5.5.7" class="ltx_td ltx_align_left">7.48</td>
<td id="S5.T2.1.5.5.8" class="ltx_td ltx_align_left">7.63</td>
<td id="S5.T2.1.5.5.9" class="ltx_td ltx_align_left">7.88</td>
</tr>
<tr id="S5.T2.1.6.6" class="ltx_tr">
<th id="S5.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">3DDFAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite>
</th>
<td id="S5.T2.1.6.6.2" class="ltx_td ltx_align_left">36.20</td>
<td id="S5.T2.1.6.6.3" class="ltx_td ltx_align_left">12.30</td>
<td id="S5.T2.1.6.6.4" class="ltx_td ltx_align_left">8.78</td>
<td id="S5.T2.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r">19.10</td>
<td id="S5.T2.1.6.6.6" class="ltx_td ltx_align_left">5.40</td>
<td id="S5.T2.1.6.6.7" class="ltx_td ltx_align_left">8.53</td>
<td id="S5.T2.1.6.6.8" class="ltx_td ltx_align_left">8.25</td>
<td id="S5.T2.1.6.6.9" class="ltx_td ltx_align_left">7.39</td>
</tr>
<tr id="S5.T2.1.7.7" class="ltx_tr">
<th id="S5.T2.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Hopenet(a = 1)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite>
</th>
<td id="S5.T2.1.7.7.2" class="ltx_td ltx_align_left">4.81</td>
<td id="S5.T2.1.7.7.3" class="ltx_td ltx_align_left">6.61</td>
<td id="S5.T2.1.7.7.4" class="ltx_td ltx_align_left">3.27</td>
<td id="S5.T2.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r">4.90</td>
<td id="S5.T2.1.7.7.6" class="ltx_td ltx_align_left">6.92</td>
<td id="S5.T2.1.7.7.7" class="ltx_td ltx_align_left">6.64</td>
<td id="S5.T2.1.7.7.8" class="ltx_td ltx_align_left">5.67</td>
<td id="S5.T2.1.7.7.9" class="ltx_td ltx_align_left">6.41</td>
</tr>
<tr id="S5.T2.1.8.8" class="ltx_tr">
<th id="S5.T2.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Hopenet(a = 2)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite>
</th>
<td id="S5.T2.1.8.8.2" class="ltx_td ltx_align_left">5.12</td>
<td id="S5.T2.1.8.8.3" class="ltx_td ltx_align_left">6.98</td>
<td id="S5.T2.1.8.8.4" class="ltx_td ltx_align_left">3.39</td>
<td id="S5.T2.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r">5.12</td>
<td id="S5.T2.1.8.8.6" class="ltx_td ltx_align_left">6.47</td>
<td id="S5.T2.1.8.8.7" class="ltx_td ltx_align_left">6.56</td>
<td id="S5.T2.1.8.8.8" class="ltx_td ltx_align_left">5.44</td>
<td id="S5.T2.1.8.8.9" class="ltx_td ltx_align_left">6.16</td>
</tr>
<tr id="S5.T2.1.9.9" class="ltx_tr">
<th id="S5.T2.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Shao <em id="S5.T2.1.9.9.1.1" class="ltx_emph ltx_font_italic">et al</em><span id="S5.T2.1.9.9.1.2" class="ltx_ERROR undefined">\bmvaOneDot</span>(K=0.5)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite>
</th>
<td id="S5.T2.1.9.9.2" class="ltx_td ltx_align_left">4.59</td>
<td id="S5.T2.1.9.9.3" class="ltx_td ltx_align_left">7.25</td>
<td id="S5.T2.1.9.9.4" class="ltx_td ltx_align_left">6.15</td>
<td id="S5.T2.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r">6.00</td>
<td id="S5.T2.1.9.9.6" class="ltx_td ltx_align_left">5.07</td>
<td id="S5.T2.1.9.9.7" class="ltx_td ltx_align_left">6.37</td>
<td id="S5.T2.1.9.9.8" class="ltx_td ltx_align_left">4.99</td>
<td id="S5.T2.1.9.9.9" class="ltx_td ltx_align_left">5.48</td>
</tr>
<tr id="S5.T2.1.10.10" class="ltx_tr">
<th id="S5.T2.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">SSR-Net-MD Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx47" title="" class="ltx_ref">Yang etÂ al.(2018)Yang, Huang, Lin, Hsiu, and Chuang</a>]</cite>
</th>
<td id="S5.T2.1.10.10.2" class="ltx_td ltx_align_left">4.49</td>
<td id="S5.T2.1.10.10.3" class="ltx_td ltx_align_left">6.31</td>
<td id="S5.T2.1.10.10.4" class="ltx_td ltx_align_left">3.61</td>
<td id="S5.T2.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r">4.65</td>
<td id="S5.T2.1.10.10.6" class="ltx_td ltx_align_left">5.14</td>
<td id="S5.T2.1.10.10.7" class="ltx_td ltx_align_left">7.09</td>
<td id="S5.T2.1.10.10.8" class="ltx_td ltx_align_left">5.89</td>
<td id="S5.T2.1.10.10.9" class="ltx_td ltx_align_left">6.01</td>
</tr>
<tr id="S5.T2.1.11.11" class="ltx_tr">
<th id="S5.T2.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">FSA-Caps-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite>
</th>
<td id="S5.T2.1.11.11.2" class="ltx_td ltx_align_left">4.27</td>
<td id="S5.T2.1.11.11.3" class="ltx_td ltx_align_left">4.96</td>
<td id="S5.T2.1.11.11.4" class="ltx_td ltx_align_left"><span id="S5.T2.1.11.11.4.1" class="ltx_text ltx_font_bold">2.76</span></td>
<td id="S5.T2.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r">4.00</td>
<td id="S5.T2.1.11.11.6" class="ltx_td ltx_align_left"><span id="S5.T2.1.11.11.6.1" class="ltx_text ltx_font_bold">4.50</span></td>
<td id="S5.T2.1.11.11.7" class="ltx_td ltx_align_left"><span id="S5.T2.1.11.11.7.1" class="ltx_text ltx_font_bold">6.08</span></td>
<td id="S5.T2.1.11.11.8" class="ltx_td ltx_align_left"><span id="S5.T2.1.11.11.8.1" class="ltx_text ltx_font_bold">4.64</span></td>
<td id="S5.T2.1.11.11.9" class="ltx_td ltx_align_left"><span id="S5.T2.1.11.11.9.1" class="ltx_text ltx_font_bold">5.07</span></td>
</tr>
<tr id="S5.T2.1.12.12" class="ltx_tr">
<th id="S5.T2.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">WHENet-V</th>
<td id="S5.T2.1.12.12.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.2.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">3.60</span></td>
<td id="S5.T2.1.12.12.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.10</span></td>
<td id="S5.T2.1.12.12.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">2.73</span></td>
<td id="S5.T2.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T2.1.12.12.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">3.48</span></td>
<td id="S5.T2.1.12.12.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.44</span></td>
<td id="S5.T2.1.12.12.7" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.7.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">5.75</span></td>
<td id="S5.T2.1.12.12.8" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.8.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.31</span></td>
<td id="S5.T2.1.12.12.9" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.1.12.12.9.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.83</span></td>
</tr>
<tr id="S5.T2.1.13.13" class="ltx_tr">
<th id="S5.T2.1.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">WHENet</th>
<td id="S5.T2.1.13.13.2" class="ltx_td ltx_align_left"><span id="S5.T2.1.13.13.2.1" class="ltx_text ltx_font_bold">3.99</span></td>
<td id="S5.T2.1.13.13.3" class="ltx_td ltx_align_left"><span id="S5.T2.1.13.13.3.1" class="ltx_text ltx_font_bold">4.39</span></td>
<td id="S5.T2.1.13.13.4" class="ltx_td ltx_align_left">3.06</td>
<td id="S5.T2.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r"><span id="S5.T2.1.13.13.5.1" class="ltx_text ltx_font_bold">3.81</span></td>
<td id="S5.T2.1.13.13.6" class="ltx_td ltx_align_left">5.11</td>
<td id="S5.T2.1.13.13.7" class="ltx_td ltx_align_left">6.24</td>
<td id="S5.T2.1.13.13.8" class="ltx_td ltx_align_left">4.92</td>
<td id="S5.T2.1.13.13.9" class="ltx_td ltx_align_left">5.42</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.F3" class="ltx_figure">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Histogram of the errors on our hybrid dataset for WHENet and WHENet (MSE), errors at high yaw are signficantly reduced with our proposed wrapped loss.</figcaption><img src="/html/2005.10353/assets/images/combine_hist_b1a1.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="184" alt="Refer to caption">
</figure>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p"><span id="S5.p7.1.1" class="ltx_text ltx_font_bold">Ablation studies</span> for the change of backbone and loss functions are shown in FigureÂ <a href="#S5.F3" title="Figure 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and TableÂ <a href="#S5.T3" title="Table 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. FigureÂ <a href="#S5.F3" title="Figure 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> plots the mean errors at different angle intervals between wrapped regression loss (WHENet) and MSE loss (WHENet MSE).The mean error in yaw for extreme poses (close to -180/180 degrees) reaches 35 degrees when using MSE loss. By introducing the wrapped loss, errors for these angles are reduced by more than 50% and are more consistent with those from medium or low yaws. High pitch and roll errors are typical in HPE methods as yaws approach <math id="S5.p7.1.m1.1" class="ltx_Math" alttext="\pm 90^{\circ}" display="inline"><semantics id="S5.p7.1.m1.1a"><mrow id="S5.p7.1.m1.1.1" xref="S5.p7.1.m1.1.1.cmml"><mo id="S5.p7.1.m1.1.1a" xref="S5.p7.1.m1.1.1.cmml">Â±</mo><msup id="S5.p7.1.m1.1.1.2" xref="S5.p7.1.m1.1.1.2.cmml"><mn id="S5.p7.1.m1.1.1.2.2" xref="S5.p7.1.m1.1.1.2.2.cmml">90</mn><mo id="S5.p7.1.m1.1.1.2.3" xref="S5.p7.1.m1.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p7.1.m1.1b"><apply id="S5.p7.1.m1.1.1.cmml" xref="S5.p7.1.m1.1.1"><csymbol cd="latexml" id="S5.p7.1.m1.1.1.1.cmml" xref="S5.p7.1.m1.1.1">plus-or-minus</csymbol><apply id="S5.p7.1.m1.1.1.2.cmml" xref="S5.p7.1.m1.1.1.2"><csymbol cd="ambiguous" id="S5.p7.1.m1.1.1.2.1.cmml" xref="S5.p7.1.m1.1.1.2">superscript</csymbol><cn type="integer" id="S5.p7.1.m1.1.1.2.2.cmml" xref="S5.p7.1.m1.1.1.2.2">90</cn><compose id="S5.p7.1.m1.1.1.2.3.cmml" xref="S5.p7.1.m1.1.1.2.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.1.m1.1c">\pm 90^{\circ}</annotation></semantics></math> as seen inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite>, we believe due to gimbal lock in the data labeling. Additionally, a quantitative result comparison can be found in Table <a href="#S5.T3" title="Table 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. WHENet CE uses cross-entropy loss for classification and wrapped regression loss for regression. WHENet MSE uses the binary cross-entropy loss for classification and MSE loss for regression. WHENet uses binary cross-entropy loss for classification and wrapped regression loss for regression. We can see in the wide-range dataset (combine), WHENet has superior performance in yaw which confirms our observations in FigureÂ <a href="#S5.F3" title="Figure 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Although WHENet sacrifices some performance in the narrow range testing compared with other two loss settings, our main focus is in the wide-range predictions where we see significantly improved errors at large yaws. We believe performance could be improved by adapting the template keypoints used in annotating the CMU dataset to each subject rather than using a fixed template but leave this to future work.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Result comparison of different loss settings. Combine indicates our combined dataset of CMU panoptic and 300W-LP</figcaption>
<div id="S5.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:386.6pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-48.3pt,9.0pt) scale(0.8,0.8) ;">
<table id="S5.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.1.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="S5.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="4">Combine</th>
<th id="S5.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_t" colspan="4">BIWI</th>
<th id="S5.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_t" colspan="4">AFLW2000</th>
</tr>
<tr id="S5.T3.1.1.2.2" class="ltx_tr">
<th id="S5.T3.1.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t"></th>
<th id="S5.T3.1.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Yaw</th>
<th id="S5.T3.1.1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Pitch</th>
<th id="S5.T3.1.1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Roll</th>
<th id="S5.T3.1.1.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MWAE</th>
<th id="S5.T3.1.1.2.2.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Yaw</th>
<th id="S5.T3.1.1.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Pitch</th>
<th id="S5.T3.1.1.2.2.8" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Roll</th>
<th id="S5.T3.1.1.2.2.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">MAE</th>
<th id="S5.T3.1.1.2.2.10" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Yaw</th>
<th id="S5.T3.1.1.2.2.11" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Pitch</th>
<th id="S5.T3.1.1.2.2.12" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Roll</th>
<th id="S5.T3.1.1.2.2.13" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">MAE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.3.1" class="ltx_tr">
<th id="S5.T3.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">WHENet CE</th>
<td id="S5.T3.1.1.3.1.2" class="ltx_td ltx_align_left ltx_border_t">8.75</td>
<td id="S5.T3.1.1.3.1.3" class="ltx_td ltx_align_left ltx_border_t">7.65</td>
<td id="S5.T3.1.1.3.1.4" class="ltx_td ltx_align_left ltx_border_t">6.74</td>
<td id="S5.T3.1.1.3.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7.71</td>
<td id="S5.T3.1.1.3.1.6" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.3.1.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">3.51</span></td>
<td id="S5.T3.1.1.3.1.7" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.3.1.7.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.13</span></td>
<td id="S5.T3.1.1.3.1.8" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.3.1.8.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">3.04</span></td>
<td id="S5.T3.1.1.3.1.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T3.1.1.3.1.9.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">3.56</span></td>
<td id="S5.T3.1.1.3.1.10" class="ltx_td ltx_align_left ltx_border_t">5.50</td>
<td id="S5.T3.1.1.3.1.11" class="ltx_td ltx_align_left ltx_border_t">6.36</td>
<td id="S5.T3.1.1.3.1.12" class="ltx_td ltx_align_left ltx_border_t">4.94</td>
<td id="S5.T3.1.1.3.1.13" class="ltx_td ltx_align_left ltx_border_t">5.60</td>
</tr>
<tr id="S5.T3.1.1.4.2" class="ltx_tr">
<th id="S5.T3.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">WHENet MSE</th>
<td id="S5.T3.1.1.4.2.2" class="ltx_td ltx_align_left">9.69</td>
<td id="S5.T3.1.1.4.2.3" class="ltx_td ltx_align_left"><span id="S5.T3.1.1.4.2.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">7.15</span></td>
<td id="S5.T3.1.1.4.2.4" class="ltx_td ltx_align_left"><span id="S5.T3.1.1.4.2.4.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">6.19</span></td>
<td id="S5.T3.1.1.4.2.5" class="ltx_td ltx_align_left ltx_border_r">7.68</td>
<td id="S5.T3.1.1.4.2.6" class="ltx_td ltx_align_left">3.79</td>
<td id="S5.T3.1.1.4.2.7" class="ltx_td ltx_align_left">4.82</td>
<td id="S5.T3.1.1.4.2.8" class="ltx_td ltx_align_left">3.21</td>
<td id="S5.T3.1.1.4.2.9" class="ltx_td ltx_align_left ltx_border_r">3.94</td>
<td id="S5.T3.1.1.4.2.10" class="ltx_td ltx_align_left"><span id="S5.T3.1.1.4.2.10.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">5.03</span></td>
<td id="S5.T3.1.1.4.2.11" class="ltx_td ltx_align_left">6.41</td>
<td id="S5.T3.1.1.4.2.12" class="ltx_td ltx_align_left">5.16</td>
<td id="S5.T3.1.1.4.2.13" class="ltx_td ltx_align_left">5.53</td>
</tr>
<tr id="S5.T3.1.1.5.3" class="ltx_tr">
<th id="S5.T3.1.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">WHENet</th>
<td id="S5.T3.1.1.5.3.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.5.3.2.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">8.51</span></td>
<td id="S5.T3.1.1.5.3.3" class="ltx_td ltx_align_left ltx_border_t">7.67</td>
<td id="S5.T3.1.1.5.3.4" class="ltx_td ltx_align_left ltx_border_t">6.78</td>
<td id="S5.T3.1.1.5.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S5.T3.1.1.5.3.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">7.66</span></td>
<td id="S5.T3.1.1.5.3.6" class="ltx_td ltx_align_left ltx_border_t">3.99</td>
<td id="S5.T3.1.1.5.3.7" class="ltx_td ltx_align_left ltx_border_t">4.39</td>
<td id="S5.T3.1.1.5.3.8" class="ltx_td ltx_align_left ltx_border_t">3.06</td>
<td id="S5.T3.1.1.5.3.9" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.81</td>
<td id="S5.T3.1.1.5.3.10" class="ltx_td ltx_align_left ltx_border_t">5.11</td>
<td id="S5.T3.1.1.5.3.11" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.5.3.11.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">6.24</span></td>
<td id="S5.T3.1.1.5.3.12" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.5.3.12.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">4.92</span></td>
<td id="S5.T3.1.1.5.3.13" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.1.1.5.3.13.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">5.42</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.p8" class="ltx_para">
<p id="S5.p8.2" class="ltx_p">The supplement provides additional ablation studies on the metaparameters <math id="S5.p8.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.p8.1.m1.1a"><mi id="S5.p8.1.m1.1.1" xref="S5.p8.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S5.p8.1.m1.1b"><ci id="S5.p8.1.m1.1.1.cmml" xref="S5.p8.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p8.1.m1.1c">\alpha</annotation></semantics></math> and <math id="S5.p8.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.p8.2.m2.1a"><mi id="S5.p8.2.m2.1.1" xref="S5.p8.2.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S5.p8.2.m2.1b"><ci id="S5.p8.2.m2.1.1.cmml" xref="S5.p8.2.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p8.2.m2.1c">\beta</annotation></semantics></math> as well the effects of resolution and relative comparison to video and depth-based methods that are outside our target application.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions and future work</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper we have presented WHENet, a new method for HPE that can estimate head poses in the full 360 degree range of yaws. This is achieved by careful choice of our wrapped loss function as well as by developing an automated labeling method for the CMU Panoptic DatasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.</a>]</cite>. We believe we are the first to adapt this dataset to the specific task of head-pose estimation. WHENet meets or exceeds the performance of state-of-the-art methods tuned for the specific task of frontal-to-profile HPE in spite of being trained for the full range of yaws. We are not aware of competing methods with similar capabilities and accuracy.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">In the future, we would like to extend upon this work by reducing network size even further. Reducing input image resolution has the potential to lower memory usage as well as allow shallower networks with fewer features. This could yield even further improvements in speed and size of network.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Another interesting avenue is modifying the representation of head pose. Euler angles are minimal and interpretable but have the drawback of gimbal lock. The pitch-yaw-roll rotation ordering of existing datasets such as AFLW2000 and BIWI emphasize this effect at yaws near <math id="S6.p3.1.m1.1" class="ltx_Math" alttext="\pm 90^{\circ}" display="inline"><semantics id="S6.p3.1.m1.1a"><mrow id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml"><mo id="S6.p3.1.m1.1.1a" xref="S6.p3.1.m1.1.1.cmml">Â±</mo><msup id="S6.p3.1.m1.1.1.2" xref="S6.p3.1.m1.1.1.2.cmml"><mn id="S6.p3.1.m1.1.1.2.2" xref="S6.p3.1.m1.1.1.2.2.cmml">90</mn><mo id="S6.p3.1.m1.1.1.2.3" xref="S6.p3.1.m1.1.1.2.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><apply id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1"><csymbol cd="latexml" id="S6.p3.1.m1.1.1.1.cmml" xref="S6.p3.1.m1.1.1">plus-or-minus</csymbol><apply id="S6.p3.1.m1.1.1.2.cmml" xref="S6.p3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S6.p3.1.m1.1.1.2.1.cmml" xref="S6.p3.1.m1.1.1.2">superscript</csymbol><cn type="integer" id="S6.p3.1.m1.1.1.2.2.cmml" xref="S6.p3.1.m1.1.1.2.2">90</cn><compose id="S6.p3.1.m1.1.1.2.3.cmml" xref="S6.p3.1.m1.1.1.2.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">\pm 90^{\circ}</annotation></semantics></math> where pitch and roll effectively counteract each other. We believe this leads to the relatively high pitch and roll errors near profile poses seen in FigureÂ <a href="#S5.F3" title="Figure 3 â€£ 5 Results &amp; Discussion â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> which can also be seen in methods such as Shao et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani</a>]</cite>. Relabeling data to yaw-pitch-roll order might reduce this. Similarly other rotation representations such as axis-angle, exponential map or quaternions may help, though adapting the architecture to alternative rotation representations is likely non-trivial due to the classification networks.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgment</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We thank Shao Hua Chen and Tanmana Sadhu for their insightful discussions. We also thank Zhan Xu, Peng Deng, Rui Ma, Ruochen Wen, Qiang Wang and other colleagues in Huawei Technologies for their support in the project as well as the anonymous reviewers whose comments helped to improve the paper.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Abtahi etÂ al.(2014)Abtahi, Omidyeganeh, Shirmohammadi, and
Hariri]</span>
<span class="ltx_bibblock">
Shabnam Abtahi, Mona Omidyeganeh, Shervin Shirmohammadi, and Behnoosh Hariri.

</span>
<span class="ltx_bibblock">Yawdd: A yawning detection dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th ACM Multimedia Systems Conference</em>,
pages 24â€“28. ACM, 2014.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Bansal etÂ al.(2017)Bansal, Nanduri, Castillo, Ranjan, and
Chellappa]</span>
<span class="ltx_bibblock">
Ankan Bansal, Anirudh Nanduri, CarlosÂ D Castillo, Rajeev Ranjan, and Rama
Chellappa.

</span>
<span class="ltx_bibblock">Umdfaces: An annotated face dataset for training deep networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx2.1.1" class="ltx_emph ltx_font_italic">2017 IEEE International Joint Conference on Biometrics
(IJCB)</em>, pages 464â€“473. IEEE, 2017.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Benfold and Reid(2008)]</span>
<span class="ltx_bibblock">
Ben Benfold and IanÂ D Reid.

</span>
<span class="ltx_bibblock">Colour invariant head pose classification in low resolution video.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx3.1.1" class="ltx_emph ltx_font_italic">BMVC</em>, pages 1â€“10, 2008.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Borghi etÂ al.(2017)Borghi, Venturelli, Vezzani, and
Cucchiara]</span>
<span class="ltx_bibblock">
Guido Borghi, Marco Venturelli, Roberto Vezzani, and Rita Cucchiara.

</span>
<span class="ltx_bibblock">Poseidon: Face-from-depth for driver pose estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx4.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, pages 5494â€“5503. IEEE, 2017.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Borghi etÂ al.(2018)Borghi, Fabbri, Vezzani, Cucchiara,
etÂ al.]</span>
<span class="ltx_bibblock">
Guido Borghi, Matteo Fabbri, Roberto Vezzani, Rita Cucchiara, etÂ al.

</span>
<span class="ltx_bibblock">Face-from-depth for head pose estimation on depth images.

</span>
<span class="ltx_bibblock"><em id="bib.bibx5.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 2018.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Bulat and Tzimiropoulos(2017)]</span>
<span class="ltx_bibblock">
Adrian Bulat and Georgios Tzimiropoulos.

</span>
<span class="ltx_bibblock">How far are we from solving the 2d &amp; 3d face alignment problem?(and
a dataset of 230,000 3d facial landmarks).

</span>
<span class="ltx_bibblock">In <em id="bib.bibx6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</em>, pages 1021â€“1030, 2017.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Burger etÂ al.(2014)Burger, Rothbucher, and Diepold]</span>
<span class="ltx_bibblock">
Patrick Burger, Martin Rothbucher, and Klaus Diepold.

</span>
<span class="ltx_bibblock">Self-initializing head pose estimation with a 2d monocular usb
camera.

</span>
<span class="ltx_bibblock">Technical report, Lehrstuhl fÃ¼r Datenverarbeitung, 2014.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Cai etÂ al.(2010)Cai, Gallup, Zhang, and Zhang]</span>
<span class="ltx_bibblock">
Qin Cai, David Gallup, Cha Zhang, and Zhengyou Zhang.

</span>
<span class="ltx_bibblock">3d deformable face tracking with a commodity depth camera.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx8.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>, pages 229â€“242.
Springer, 2010.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Chen etÂ al.(2014)Chen, Ren, Wei, Cao, and Sun]</span>
<span class="ltx_bibblock">
Dong Chen, Shaoqing Ren, Yichen Wei, Xudong Cao, and Jian Sun.

</span>
<span class="ltx_bibblock">Joint cascade face detection and alignment.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx9.1.1" class="ltx_emph ltx_font_italic">European conference on computer vision</em>, pages 109â€“122.
Springer, 2014.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[deÂ FariasÂ Macedo etÂ al.(2013)deÂ FariasÂ Macedo, ApolinÃ¡rio, and dos
SantosÂ Souza]</span>
<span class="ltx_bibblock">
MÃ¡rcioÂ Cerqueira deÂ FariasÂ Macedo, AntÃ´nioÂ Lopes ApolinÃ¡rio, and
AntonioÂ Carlos dos SantosÂ Souza.

</span>
<span class="ltx_bibblock">A robust real-time face tracking using head pose estimation for a
markerless ar system.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx10.1.1" class="ltx_emph ltx_font_italic">2013 XV Symposium on Virtual and Augmented Reality</em>, pages
224â€“227. IEEE, 2013.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Fanelli etÂ al.(2011)Fanelli, Gall, and VanÂ Gool]</span>
<span class="ltx_bibblock">
Gabriele Fanelli, Juergen Gall, and Luc VanÂ Gool.

</span>
<span class="ltx_bibblock">Real time head pose estimation with random regression forests.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx11.1.1" class="ltx_emph ltx_font_italic">CVPR 2011</em>, pages 617â€“624. IEEE, 2011.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Fanelli etÂ al.(2013)Fanelli, Dantone, Gall, Fossati, and
VanÂ Gool]</span>
<span class="ltx_bibblock">
Gabriele Fanelli, Matthias Dantone, Juergen Gall, Andrea Fossati, and Luc
VanÂ Gool.

</span>
<span class="ltx_bibblock">Random forests for real time 3d face analysis.

</span>
<span class="ltx_bibblock"><em id="bib.bibx12.1.1" class="ltx_emph ltx_font_italic">Int. J. Comput. Vision</em>, 101(3):437â€“458,
February 2013.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Geiger etÂ al.(2013)Geiger, Lenz, Stiller, and
Urtasun]</span>
<span class="ltx_bibblock">
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun.

</span>
<span class="ltx_bibblock">Vision meets robotics: The kitti dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bibx13.1.1" class="ltx_emph ltx_font_italic">The International Journal of Robotics Research</em>, 32(11):1231â€“1237, 2013.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Gu etÂ al.(2017)Gu, Yang, DeÂ Mello, and Kautz]</span>
<span class="ltx_bibblock">
Jinwei Gu, Xiaodong Yang, Shalini DeÂ Mello, and Jan Kautz.

</span>
<span class="ltx_bibblock">Dynamic facial analysis: From bayesian filtering to recurrent neural
network.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 1548â€“1557, 2017.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Heo etÂ al.(2019)Heo, Nam, and Ko]</span>
<span class="ltx_bibblock">
DuYeong Heo, JaeÂ Yeal Nam, and ByoungÂ Chul Ko.

</span>
<span class="ltx_bibblock">Estimation of pedestrian pose orientation using soft target training
based on teacherâ€“student framework.

</span>
<span class="ltx_bibblock"><em id="bib.bibx15.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, 19(5):1147, 2019.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Herpers etÂ al.(1996)Herpers, Michaelis, Lichtenauer, and
Sommer]</span>
<span class="ltx_bibblock">
Rainer Herpers, Markus Michaelis, K-H Lichtenauer, and Gerald Sommer.

</span>
<span class="ltx_bibblock">Edge and keypoint detection in facial regions.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Second International Conference on
Automatic Face and Gesture Recognition</em>, pages 212â€“217. IEEE, 1996.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Horn etÂ al.(1988)Horn, Hilden, and Negahdaripour]</span>
<span class="ltx_bibblock">
BertholdÂ KP Horn, HughÂ M Hilden, and Shahriar Negahdaripour.

</span>
<span class="ltx_bibblock">Closed-form solution of absolute orientation using orthonormal
matrices.

</span>
<span class="ltx_bibblock"><em id="bib.bibx17.1.1" class="ltx_emph ltx_font_italic">JOSA A</em>, 5(7):1127â€“1135, 1988.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Joo etÂ al.(2017)Joo, Simon, Li, Liu, Tan, Gui, Banerjee, Godisart,
Nabbe, Matthews, etÂ al.]</span>
<span class="ltx_bibblock">
Hanbyul Joo, Tomas Simon, Xulong Li, Hao Liu, Lei Tan, Lin Gui, Sean Banerjee,
Timothy Godisart, Bart Nabbe, Iain Matthews, etÂ al.

</span>
<span class="ltx_bibblock">Panoptic studio: A massively multiview system for social interaction
capture.

</span>
<span class="ltx_bibblock"><em id="bib.bibx18.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 41(1):190â€“204, 2017.

</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Kazemi and Sullivan(2014)]</span>
<span class="ltx_bibblock">
Vahid Kazemi and Josephine Sullivan.

</span>
<span class="ltx_bibblock">One millisecond face alignment with an ensemble of regression trees.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 1867â€“1874, 2014.

</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Kumar etÂ al.(2017)Kumar, Alavi, and Chellappa]</span>
<span class="ltx_bibblock">
Amit Kumar, Azadeh Alavi, and Rama Chellappa.

</span>
<span class="ltx_bibblock">Kepler: Keypoint and pose estimation of unconstrained faces by
learning efficient h-cnn regressors.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx20.1.1" class="ltx_emph ltx_font_italic">2017 12th IEEE International Conference on Automatic Face &amp;
Gesture Recognition (FG 2017)</em>, pages 258â€“265. IEEE, 2017.

</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Langton etÂ al.(2004)Langton, Honeyman, and
Tessler]</span>
<span class="ltx_bibblock">
StephenÂ RH Langton, Helen Honeyman, and Emma Tessler.

</span>
<span class="ltx_bibblock">The influence of head contour and nose angle on the perception of
eye-gaze direction.

</span>
<span class="ltx_bibblock"><em id="bib.bibx21.1.1" class="ltx_emph ltx_font_italic">Perception &amp; psychophysics</em>, 66(5):752â€“771, 2004.

</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Martin etÂ al.(2014)Martin, Van DeÂ Camp, and
Stiefelhagen]</span>
<span class="ltx_bibblock">
Manuel Martin, Florian Van DeÂ Camp, and Rainer Stiefelhagen.

</span>
<span class="ltx_bibblock">Real time head model creation and head pose estimation on consumer
depth cameras.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx22.1.1" class="ltx_emph ltx_font_italic">2014 2nd International Conference on 3D Vision</em>, volumeÂ 1,
pages 641â€“648. IEEE, 2014.

</span>
</li>
<li id="bib.bibx23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Mukherjee and Robertson(2015)]</span>
<span class="ltx_bibblock">
SankhaÂ S Mukherjee and NeilÂ Martin Robertson.

</span>
<span class="ltx_bibblock">Deep head pose: Gaze-direction estimation in multimodal video.

</span>
<span class="ltx_bibblock"><em id="bib.bibx23.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Multimedia</em>, 17(11):2094â€“2107, 2015.

</span>
</li>
<li id="bib.bibx24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Murphy-Chutorian and Trivedi(2008)]</span>
<span class="ltx_bibblock">
Erik Murphy-Chutorian and MohanÂ Manubhai Trivedi.

</span>
<span class="ltx_bibblock">Head pose estimation in computer vision: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bibx24.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 31(4):607â€“626, 2008.

</span>
</li>
<li id="bib.bibx25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Murphy-Chutorian and Trivedi(2010)]</span>
<span class="ltx_bibblock">
Erik Murphy-Chutorian and MohanÂ Manubhai Trivedi.

</span>
<span class="ltx_bibblock">Head pose estimation and augmented reality tracking: An integrated
system and evaluation for monitoring driver awareness.

</span>
<span class="ltx_bibblock"><em id="bib.bibx25.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on intelligent transportation systems</em>,
11(2):300â€“311, 2010.

</span>
</li>
<li id="bib.bibx26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Murphy-Chutorian etÂ al.(2007)Murphy-Chutorian, Doshi, and
Trivedi]</span>
<span class="ltx_bibblock">
Erik Murphy-Chutorian, Anup Doshi, and MohanÂ Manubhai Trivedi.

</span>
<span class="ltx_bibblock">Head pose estimation for driver assistance systems: A robust
algorithm and experimental evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx26.1.1" class="ltx_emph ltx_font_italic">2007 IEEE Intelligent Transportation Systems Conference</em>,
pages 709â€“714. IEEE, 2007.

</span>
</li>
<li id="bib.bibx27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ng and Gong(2002)]</span>
<span class="ltx_bibblock">
Jeffrey Ng and Shaogang Gong.

</span>
<span class="ltx_bibblock">Composite support vector machines for detection of faces across views
and pose estimation.

</span>
<span class="ltx_bibblock"><em id="bib.bibx27.1.1" class="ltx_emph ltx_font_italic">Image and Vision Computing</em>, 20(5-6):359â€“368, 2002.

</span>
</li>
<li id="bib.bibx28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Osokin(2018)]</span>
<span class="ltx_bibblock">
Daniil Osokin.

</span>
<span class="ltx_bibblock">Real-time 2d multi-person pose estimation on cpu: Lightweight
openpose.

</span>
<span class="ltx_bibblock"><em id="bib.bibx28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.12004</em>, 2018.

</span>
</li>
<li id="bib.bibx29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ranjan etÂ al.(2017a)Ranjan, Patel, and
Chellappa]</span>
<span class="ltx_bibblock">
Rajeev Ranjan, VishalÂ M Patel, and Rama Chellappa.

</span>
<span class="ltx_bibblock">Hyperface: A deep multi-task learning framework for face detection,
landmark localization, pose estimation, and gender recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bibx29.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 41(1):121â€“135, 2017a.

</span>
</li>
<li id="bib.bibx30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ranjan etÂ al.(2017b)Ranjan, Sankaranarayanan, Castillo,
and Chellappa]</span>
<span class="ltx_bibblock">
Rajeev Ranjan, Swami Sankaranarayanan, CarlosÂ D Castillo, and Rama Chellappa.

</span>
<span class="ltx_bibblock">An all-in-one convolutional neural network for face analysis.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx30.1.1" class="ltx_emph ltx_font_italic">2017 12th IEEE International Conference on Automatic Face &amp;
Gesture Recognition (FG 2017)</em>, pages 17â€“24. IEEE, 2017b.

</span>
</li>
<li id="bib.bibx31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Raza etÂ al.(2018)Raza, Chen, Rehman, Wang, and
Bao]</span>
<span class="ltx_bibblock">
Mudassar Raza, Zonghai Chen, Saeed-Ur Rehman, Peng Wang, and Peng Bao.

</span>
<span class="ltx_bibblock">Appearance based pedestriansâ€™ head pose and body orientation
estimation using deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bibx31.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, 272:647â€“659, 2018.

</span>
</li>
<li id="bib.bibx32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Rehder etÂ al.(2014)Rehder, Kloeden, and Stiller]</span>
<span class="ltx_bibblock">
Eike Rehder, Horst Kloeden, and Christoph Stiller.

</span>
<span class="ltx_bibblock">Head detection and orientation estimation for pedestrian safety.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx32.1.1" class="ltx_emph ltx_font_italic">17th International IEEE Conference on Intelligent
Transportation Systems (ITSC)</em>, pages 2292â€“2297. IEEE, 2014.

</span>
</li>
<li id="bib.bibx33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg]</span>
<span class="ltx_bibblock">
Nataniel Ruiz, Eunji Chong, and JamesÂ M Rehg.

</span>
<span class="ltx_bibblock">Fine-grained head pose estimation without keypoints.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition Workshops</em>, pages 2074â€“2083, 2018.

</span>
</li>
<li id="bib.bibx34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Sandler etÂ al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
Chen]</span>
<span class="ltx_bibblock">
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh
Chen.

</span>
<span class="ltx_bibblock">Mobilenetv2: Inverted residuals and linear bottlenecks.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, pages 4510â€“4520, 2018.

</span>
</li>
<li id="bib.bibx35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Shao etÂ al.(2019)Shao, Sun, Ozay, and Okatani]</span>
<span class="ltx_bibblock">
Mingzhen Shao, Zhun Sun, Mete Ozay, and Takayuki Okatani.

</span>
<span class="ltx_bibblock">Improving head pose estimation with a combined loss and bounding box
margin adjustment.

</span>
<span class="ltx_bibblock"><em id="bib.bibx35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.08609</em>, 2019.

</span>
</li>
<li id="bib.bibx36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Sherrah etÂ al.(1999)Sherrah, Gong, and Ong]</span>
<span class="ltx_bibblock">
Jamie Sherrah, Shaogang Gong, and Eng-Jon Ong.

</span>
<span class="ltx_bibblock">Understanding pose discrimination in similarity space.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx36.1.1" class="ltx_emph ltx_font_italic">BMVC</em>, pages 1â€“10, 1999.

</span>
</li>
<li id="bib.bibx37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Siriteerakul(2012)]</span>
<span class="ltx_bibblock">
Teera Siriteerakul.

</span>
<span class="ltx_bibblock">Advance in head pose estimation from low resolution images: A review.

</span>
<span class="ltx_bibblock"><em id="bib.bibx37.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Science Issues</em>, 9(2):1, 2012.

</span>
</li>
<li id="bib.bibx38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Srinivasan and Boyer(2002)]</span>
<span class="ltx_bibblock">
Sujith Srinivasan and KimÂ L Boyer.

</span>
<span class="ltx_bibblock">Head pose estimation using view based eigenspaces.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx38.1.1" class="ltx_emph ltx_font_italic">Object recognition supported by user interaction for service
robots</em>, volumeÂ 4, pages 302â€“305. IEEE, 2002.

</span>
</li>
<li id="bib.bibx39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Sun etÂ al.(2013)Sun, Wang, and Tang]</span>
<span class="ltx_bibblock">
YiÂ Sun, Xiaogang Wang, and Xiaoou Tang.

</span>
<span class="ltx_bibblock">Deep convolutional network cascade for facial point detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 3476â€“3483, 2013.

</span>
</li>
<li id="bib.bibx40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Tan and Le(2019)]</span>
<span class="ltx_bibblock">
Mingxing Tan and QuocÂ V Le.

</span>
<span class="ltx_bibblock">Efficientnet: Rethinking model scaling for convolutional neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bibx40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.11946</em>, 2019.

</span>
</li>
<li id="bib.bibx41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Vu etÂ al.(2015)Vu, Osokin, and Laptev]</span>
<span class="ltx_bibblock">
Tuan-Hung Vu, Anton Osokin, and Ivan Laptev.

</span>
<span class="ltx_bibblock">Context-aware cnns for person head detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</em>, pages 2893â€“2901, 2015.

</span>
</li>
<li id="bib.bibx42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Wang etÂ al.(2018)Wang, Gao, Tao, Yang, and Li]</span>
<span class="ltx_bibblock">
Nannan Wang, Xinbo Gao, Dacheng Tao, Heng Yang, and Xuelong Li.

</span>
<span class="ltx_bibblock">Facial feature point detection: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bibx42.1.1" class="ltx_emph ltx_font_italic">Neurocomputing</em>, 275:50â€“65, 2018.

</span>
</li>
<li id="bib.bibx43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Wu etÂ al.(2017)Wu, Zheng, Zhao, Li, Yan, Liang, Wang, Zhou, Lin, Fu,
etÂ al.]</span>
<span class="ltx_bibblock">
Jiahong Wu, HeÂ Zheng, BoÂ Zhao, Yixin Li, Baoming Yan, Rui Liang, Wenjia Wang,
Shipei Zhou, Guosen Lin, Yanwei Fu, etÂ al.

</span>
<span class="ltx_bibblock">Ai challenger: a large-scale dataset for going deeper in image
understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bibx43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.06475</em>, 2017.

</span>
</li>
<li id="bib.bibx44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yan etÂ al.(2013)Yan, Ricci, Subramanian, Lanz, and Sebe]</span>
<span class="ltx_bibblock">
Yan Yan, Elisa Ricci, Ramanathan Subramanian, Oswald Lanz, and Nicu Sebe.

</span>
<span class="ltx_bibblock">No matter where you are: Flexible graph-guided multi-task learning
for multi-view head pose classification under target motion.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 1177â€“1184, 2013.

</span>
</li>
<li id="bib.bibx45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yan etÂ al.(2015)Yan, Ricci, Subramanian, Liu, Lanz, and
Sebe]</span>
<span class="ltx_bibblock">
Yan Yan, Elisa Ricci, Ramanathan Subramanian, Gaowen Liu, Oswald Lanz, and Nicu
Sebe.

</span>
<span class="ltx_bibblock">A multi-task learning framework for head pose estimation under target
motion.

</span>
<span class="ltx_bibblock"><em id="bib.bibx45.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 38(6):1070â€“1083, 2015.

</span>
</li>
<li id="bib.bibx46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yang and Zhang(2002)]</span>
<span class="ltx_bibblock">
Ruigang Yang and Zhengyou Zhang.

</span>
<span class="ltx_bibblock">Model-based head pose tracking with stereovision.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx46.1.1" class="ltx_emph ltx_font_italic">Proceedings of Fifth IEEE International Conference on
Automatic Face Gesture Recognition</em>, pages 255â€“260. IEEE, 2002.

</span>
</li>
<li id="bib.bibx47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yang etÂ al.(2018)Yang, Huang, Lin, Hsiu, and Chuang]</span>
<span class="ltx_bibblock">
Tsun-Yi Yang, Yi-Hsuan Huang, Yen-Yu Lin, Pi-Cheng Hsiu, and Yung-Yu Chuang.

</span>
<span class="ltx_bibblock">Ssr-net: A compact soft stagewise regression network for age
estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx47.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>, volumeÂ 5, pageÂ 7, 2018.

</span>
</li>
<li id="bib.bibx48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang]</span>
<span class="ltx_bibblock">
Tsun-Yi Yang, Yi-Ting Chen, Yen-Yu Lin, and Yung-Yu Chuang.

</span>
<span class="ltx_bibblock">Fsa-net: Learning fine-grained structure aggregation for head pose
estimation from a single image.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</em>, pages 1087â€“1096, 2019.

</span>
</li>
<li id="bib.bibx49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Yu etÂ al.(2013)Yu, Huang, Zhang, Yan, and Metaxas]</span>
<span class="ltx_bibblock">
Xiang Yu, Junzhou Huang, Shaoting Zhang, Wang Yan, and DimitrisÂ N Metaxas.

</span>
<span class="ltx_bibblock">Pose-free facial landmark fitting via optimized part mixtures and
cascaded deformable shape model.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</em>, pages 1944â€“1951, 2013.

</span>
</li>
<li id="bib.bibx50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Zhu and Ramanan(2012)]</span>
<span class="ltx_bibblock">
Xiangxin Zhu and Deva Ramanan.

</span>
<span class="ltx_bibblock">Face detection, pose estimation, and landmark localization in the
wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx50.1.1" class="ltx_emph ltx_font_italic">2012 IEEE conference on computer vision and pattern
recognition</em>, pages 2879â€“2886. IEEE, 2012.

</span>
</li>
<li id="bib.bibx51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li]</span>
<span class="ltx_bibblock">
Xiangyu Zhu, Zhen Lei, Xiaoming Liu, Hailin Shi, and StanÂ Z Li.

</span>
<span class="ltx_bibblock">Face alignment across large poses: A 3d solution.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 146â€“155, 2016.

</span>
</li>
<li id="bib.bibx52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[Zhu and Fujimura(2004)]</span>
<span class="ltx_bibblock">
Youding Zhu and Kikuo Fujimura.

</span>
<span class="ltx_bibblock">Head pose estimation for driver monitoring.

</span>
<span class="ltx_bibblock">In <em id="bib.bibx52.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Vehicles Symposium, 2004</em>, pages 501â€“506.
IEEE, 2004.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Hyperparameter Studies</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.6" class="ltx_p">TablesÂ <a href="#A1.T4" title="Table 4 â€£ Appendix A Hyperparameter Studies â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, <a href="#A1.T5" title="Table 5 â€£ Appendix A Hyperparameter Studies â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, <a href="#A1.T6" title="Table 6 â€£ Appendix A Hyperparameter Studies â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, <a href="#A1.T7" title="Table 7 â€£ Appendix A Hyperparameter Studies â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and <a href="#A1.T8" title="Table 8 â€£ Appendix A Hyperparameter Studies â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> show ablation studies of mean average error for the <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.p1.1.m1.1a"><mi id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><ci id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">\beta</annotation></semantics></math> and <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">\alpha</annotation></semantics></math> metaparameters of WHENet-V and WHENet, tested on the AFLW2000, BIWI datasets and our combined dataset. From this, we selected the best overall performance as <math id="A1.p1.3.m3.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="A1.p1.3.m3.1a"><mrow id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mi id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">Î²</mi><mo id="A1.p1.3.m3.1.1.1" xref="A1.p1.3.m3.1.1.1.cmml">=</mo><mn id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><eq id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1.1"></eq><ci id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">ğ›½</ci><cn type="integer" id="A1.p1.3.m3.1.1.3.cmml" xref="A1.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">\beta=2</annotation></semantics></math> and <math id="A1.p1.4.m4.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.p1.4.m4.1a"><mrow id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml"><mi id="A1.p1.4.m4.1.1.2" xref="A1.p1.4.m4.1.1.2.cmml">Î±</mi><mo id="A1.p1.4.m4.1.1.1" xref="A1.p1.4.m4.1.1.1.cmml">=</mo><mn id="A1.p1.4.m4.1.1.3" xref="A1.p1.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><apply id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1"><eq id="A1.p1.4.m4.1.1.1.cmml" xref="A1.p1.4.m4.1.1.1"></eq><ci id="A1.p1.4.m4.1.1.2.cmml" xref="A1.p1.4.m4.1.1.2">ğ›¼</ci><cn type="float" id="A1.p1.4.m4.1.1.3.cmml" xref="A1.p1.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">\alpha=0.5</annotation></semantics></math> for WHENet-V, <math id="A1.p1.5.m5.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="A1.p1.5.m5.1a"><mrow id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml"><mi id="A1.p1.5.m5.1.1.2" xref="A1.p1.5.m5.1.1.2.cmml">Î²</mi><mo id="A1.p1.5.m5.1.1.1" xref="A1.p1.5.m5.1.1.1.cmml">=</mo><mn id="A1.p1.5.m5.1.1.3" xref="A1.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><apply id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1"><eq id="A1.p1.5.m5.1.1.1.cmml" xref="A1.p1.5.m5.1.1.1"></eq><ci id="A1.p1.5.m5.1.1.2.cmml" xref="A1.p1.5.m5.1.1.2">ğ›½</ci><cn type="integer" id="A1.p1.5.m5.1.1.3.cmml" xref="A1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">\beta=1</annotation></semantics></math> and <math id="A1.p1.6.m6.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="A1.p1.6.m6.1a"><mrow id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml"><mi id="A1.p1.6.m6.1.1.2" xref="A1.p1.6.m6.1.1.2.cmml">Î±</mi><mo id="A1.p1.6.m6.1.1.1" xref="A1.p1.6.m6.1.1.1.cmml">=</mo><mn id="A1.p1.6.m6.1.1.3" xref="A1.p1.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><apply id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1"><eq id="A1.p1.6.m6.1.1.1.cmml" xref="A1.p1.6.m6.1.1.1"></eq><ci id="A1.p1.6.m6.1.1.2.cmml" xref="A1.p1.6.m6.1.1.2">ğ›¼</ci><cn type="integer" id="A1.p1.6.m6.1.1.3.cmml" xref="A1.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">\alpha=1</annotation></semantics></math> for WHENe, although performance is not overly sensitive to these choices.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>WHENet-V MAE vs. <math id="A1.T4.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T4.3.m1.1b"><mi id="A1.T4.3.m1.1.1" xref="A1.T4.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A1.T4.3.m1.1c"><ci id="A1.T4.3.m1.1.1.cmml" xref="A1.T4.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.3.m1.1d">\alpha</annotation></semantics></math> and <math id="A1.T4.4.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.T4.4.m2.1b"><mi id="A1.T4.4.m2.1.1" xref="A1.T4.4.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.T4.4.m2.1c"><ci id="A1.T4.4.m2.1.1.cmml" xref="A1.T4.4.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.4.m2.1d">\beta</annotation></semantics></math> on AFLW2000</figcaption>
<table id="A1.T4.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T4.7.3" class="ltx_tr">
<th id="A1.T4.7.3.4" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="A1.T4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T4.5.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.T4.5.1.1.m1.1a"><mrow id="A1.T4.5.1.1.m1.1.1" xref="A1.T4.5.1.1.m1.1.1.cmml"><mi id="A1.T4.5.1.1.m1.1.1.2" xref="A1.T4.5.1.1.m1.1.1.2.cmml">Î±</mi><mo id="A1.T4.5.1.1.m1.1.1.1" xref="A1.T4.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A1.T4.5.1.1.m1.1.1.3" xref="A1.T4.5.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T4.5.1.1.m1.1b"><apply id="A1.T4.5.1.1.m1.1.1.cmml" xref="A1.T4.5.1.1.m1.1.1"><eq id="A1.T4.5.1.1.m1.1.1.1.cmml" xref="A1.T4.5.1.1.m1.1.1.1"></eq><ci id="A1.T4.5.1.1.m1.1.1.2.cmml" xref="A1.T4.5.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="A1.T4.5.1.1.m1.1.1.3.cmml" xref="A1.T4.5.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.5.1.1.m1.1c">\alpha=0.5</annotation></semantics></math></th>
<th id="A1.T4.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T4.6.2.2.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="A1.T4.6.2.2.m1.1a"><mrow id="A1.T4.6.2.2.m1.1.1" xref="A1.T4.6.2.2.m1.1.1.cmml"><mi id="A1.T4.6.2.2.m1.1.1.2" xref="A1.T4.6.2.2.m1.1.1.2.cmml">Î±</mi><mo id="A1.T4.6.2.2.m1.1.1.1" xref="A1.T4.6.2.2.m1.1.1.1.cmml">=</mo><mn id="A1.T4.6.2.2.m1.1.1.3" xref="A1.T4.6.2.2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T4.6.2.2.m1.1b"><apply id="A1.T4.6.2.2.m1.1.1.cmml" xref="A1.T4.6.2.2.m1.1.1"><eq id="A1.T4.6.2.2.m1.1.1.1.cmml" xref="A1.T4.6.2.2.m1.1.1.1"></eq><ci id="A1.T4.6.2.2.m1.1.1.2.cmml" xref="A1.T4.6.2.2.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T4.6.2.2.m1.1.1.3.cmml" xref="A1.T4.6.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.6.2.2.m1.1c">\alpha=1</annotation></semantics></math></th>
<th id="A1.T4.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T4.7.3.3.m1.1" class="ltx_Math" alttext="\alpha=2" display="inline"><semantics id="A1.T4.7.3.3.m1.1a"><mrow id="A1.T4.7.3.3.m1.1.1" xref="A1.T4.7.3.3.m1.1.1.cmml"><mi id="A1.T4.7.3.3.m1.1.1.2" xref="A1.T4.7.3.3.m1.1.1.2.cmml">Î±</mi><mo id="A1.T4.7.3.3.m1.1.1.1" xref="A1.T4.7.3.3.m1.1.1.1.cmml">=</mo><mn id="A1.T4.7.3.3.m1.1.1.3" xref="A1.T4.7.3.3.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T4.7.3.3.m1.1b"><apply id="A1.T4.7.3.3.m1.1.1.cmml" xref="A1.T4.7.3.3.m1.1.1"><eq id="A1.T4.7.3.3.m1.1.1.1.cmml" xref="A1.T4.7.3.3.m1.1.1.1"></eq><ci id="A1.T4.7.3.3.m1.1.1.2.cmml" xref="A1.T4.7.3.3.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T4.7.3.3.m1.1.1.3.cmml" xref="A1.T4.7.3.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.7.3.3.m1.1c">\alpha=2</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T4.8.4" class="ltx_tr">
<th id="A1.T4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="A1.T4.8.4.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="A1.T4.8.4.1.m1.1a"><mrow id="A1.T4.8.4.1.m1.1.1" xref="A1.T4.8.4.1.m1.1.1.cmml"><mi id="A1.T4.8.4.1.m1.1.1.2" xref="A1.T4.8.4.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T4.8.4.1.m1.1.1.1" xref="A1.T4.8.4.1.m1.1.1.1.cmml">=</mo><mn id="A1.T4.8.4.1.m1.1.1.3" xref="A1.T4.8.4.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T4.8.4.1.m1.1b"><apply id="A1.T4.8.4.1.m1.1.1.cmml" xref="A1.T4.8.4.1.m1.1.1"><eq id="A1.T4.8.4.1.m1.1.1.1.cmml" xref="A1.T4.8.4.1.m1.1.1.1"></eq><ci id="A1.T4.8.4.1.m1.1.1.2.cmml" xref="A1.T4.8.4.1.m1.1.1.2">ğ›½</ci><cn type="float" id="A1.T4.8.4.1.m1.1.1.3.cmml" xref="A1.T4.8.4.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.8.4.1.m1.1c">\beta=0.5</annotation></semantics></math></th>
<td id="A1.T4.8.4.2" class="ltx_td ltx_align_center ltx_border_t">4.984</td>
<td id="A1.T4.8.4.3" class="ltx_td ltx_align_center ltx_border_t">4.966</td>
<td id="A1.T4.8.4.4" class="ltx_td ltx_align_center ltx_border_t">5.113</td>
</tr>
<tr id="A1.T4.9.5" class="ltx_tr">
<th id="A1.T4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T4.9.5.1.m1.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="A1.T4.9.5.1.m1.1a"><mrow id="A1.T4.9.5.1.m1.1.1" xref="A1.T4.9.5.1.m1.1.1.cmml"><mi id="A1.T4.9.5.1.m1.1.1.2" xref="A1.T4.9.5.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T4.9.5.1.m1.1.1.1" xref="A1.T4.9.5.1.m1.1.1.1.cmml">=</mo><mn id="A1.T4.9.5.1.m1.1.1.3" xref="A1.T4.9.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T4.9.5.1.m1.1b"><apply id="A1.T4.9.5.1.m1.1.1.cmml" xref="A1.T4.9.5.1.m1.1.1"><eq id="A1.T4.9.5.1.m1.1.1.1.cmml" xref="A1.T4.9.5.1.m1.1.1.1"></eq><ci id="A1.T4.9.5.1.m1.1.1.2.cmml" xref="A1.T4.9.5.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T4.9.5.1.m1.1.1.3.cmml" xref="A1.T4.9.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.9.5.1.m1.1c">\beta=1</annotation></semantics></math></th>
<td id="A1.T4.9.5.2" class="ltx_td ltx_align_center">4.946</td>
<td id="A1.T4.9.5.3" class="ltx_td ltx_align_center">5.146</td>
<td id="A1.T4.9.5.4" class="ltx_td ltx_align_center">4.904</td>
</tr>
<tr id="A1.T4.10.6" class="ltx_tr">
<th id="A1.T4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T4.10.6.1.m1.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="A1.T4.10.6.1.m1.1a"><mrow id="A1.T4.10.6.1.m1.1.1" xref="A1.T4.10.6.1.m1.1.1.cmml"><mi id="A1.T4.10.6.1.m1.1.1.2" xref="A1.T4.10.6.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T4.10.6.1.m1.1.1.1" xref="A1.T4.10.6.1.m1.1.1.1.cmml">=</mo><mn id="A1.T4.10.6.1.m1.1.1.3" xref="A1.T4.10.6.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T4.10.6.1.m1.1b"><apply id="A1.T4.10.6.1.m1.1.1.cmml" xref="A1.T4.10.6.1.m1.1.1"><eq id="A1.T4.10.6.1.m1.1.1.1.cmml" xref="A1.T4.10.6.1.m1.1.1.1"></eq><ci id="A1.T4.10.6.1.m1.1.1.2.cmml" xref="A1.T4.10.6.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T4.10.6.1.m1.1.1.3.cmml" xref="A1.T4.10.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.10.6.1.m1.1c">\beta=2</annotation></semantics></math></th>
<td id="A1.T4.10.6.2" class="ltx_td ltx_align_center">4.834</td>
<td id="A1.T4.10.6.3" class="ltx_td ltx_align_center">4.953</td>
<td id="A1.T4.10.6.4" class="ltx_td ltx_align_center">5.189</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>WHENet-V MAE vs. <math id="A1.T5.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T5.3.m1.1b"><mi id="A1.T5.3.m1.1.1" xref="A1.T5.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A1.T5.3.m1.1c"><ci id="A1.T5.3.m1.1.1.cmml" xref="A1.T5.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.3.m1.1d">\alpha</annotation></semantics></math> and <math id="A1.T5.4.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.T5.4.m2.1b"><mi id="A1.T5.4.m2.1.1" xref="A1.T5.4.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.T5.4.m2.1c"><ci id="A1.T5.4.m2.1.1.cmml" xref="A1.T5.4.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.4.m2.1d">\beta</annotation></semantics></math> on BIWI</figcaption>
<table id="A1.T5.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T5.7.3" class="ltx_tr">
<th id="A1.T5.7.3.4" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="A1.T5.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T5.5.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.T5.5.1.1.m1.1a"><mrow id="A1.T5.5.1.1.m1.1.1" xref="A1.T5.5.1.1.m1.1.1.cmml"><mi id="A1.T5.5.1.1.m1.1.1.2" xref="A1.T5.5.1.1.m1.1.1.2.cmml">Î±</mi><mo id="A1.T5.5.1.1.m1.1.1.1" xref="A1.T5.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A1.T5.5.1.1.m1.1.1.3" xref="A1.T5.5.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.5.1.1.m1.1b"><apply id="A1.T5.5.1.1.m1.1.1.cmml" xref="A1.T5.5.1.1.m1.1.1"><eq id="A1.T5.5.1.1.m1.1.1.1.cmml" xref="A1.T5.5.1.1.m1.1.1.1"></eq><ci id="A1.T5.5.1.1.m1.1.1.2.cmml" xref="A1.T5.5.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="A1.T5.5.1.1.m1.1.1.3.cmml" xref="A1.T5.5.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.5.1.1.m1.1c">\alpha=0.5</annotation></semantics></math></th>
<th id="A1.T5.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T5.6.2.2.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="A1.T5.6.2.2.m1.1a"><mrow id="A1.T5.6.2.2.m1.1.1" xref="A1.T5.6.2.2.m1.1.1.cmml"><mi id="A1.T5.6.2.2.m1.1.1.2" xref="A1.T5.6.2.2.m1.1.1.2.cmml">Î±</mi><mo id="A1.T5.6.2.2.m1.1.1.1" xref="A1.T5.6.2.2.m1.1.1.1.cmml">=</mo><mn id="A1.T5.6.2.2.m1.1.1.3" xref="A1.T5.6.2.2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.6.2.2.m1.1b"><apply id="A1.T5.6.2.2.m1.1.1.cmml" xref="A1.T5.6.2.2.m1.1.1"><eq id="A1.T5.6.2.2.m1.1.1.1.cmml" xref="A1.T5.6.2.2.m1.1.1.1"></eq><ci id="A1.T5.6.2.2.m1.1.1.2.cmml" xref="A1.T5.6.2.2.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T5.6.2.2.m1.1.1.3.cmml" xref="A1.T5.6.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.6.2.2.m1.1c">\alpha=1</annotation></semantics></math></th>
<th id="A1.T5.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T5.7.3.3.m1.1" class="ltx_Math" alttext="\alpha=2" display="inline"><semantics id="A1.T5.7.3.3.m1.1a"><mrow id="A1.T5.7.3.3.m1.1.1" xref="A1.T5.7.3.3.m1.1.1.cmml"><mi id="A1.T5.7.3.3.m1.1.1.2" xref="A1.T5.7.3.3.m1.1.1.2.cmml">Î±</mi><mo id="A1.T5.7.3.3.m1.1.1.1" xref="A1.T5.7.3.3.m1.1.1.1.cmml">=</mo><mn id="A1.T5.7.3.3.m1.1.1.3" xref="A1.T5.7.3.3.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.7.3.3.m1.1b"><apply id="A1.T5.7.3.3.m1.1.1.cmml" xref="A1.T5.7.3.3.m1.1.1"><eq id="A1.T5.7.3.3.m1.1.1.1.cmml" xref="A1.T5.7.3.3.m1.1.1.1"></eq><ci id="A1.T5.7.3.3.m1.1.1.2.cmml" xref="A1.T5.7.3.3.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T5.7.3.3.m1.1.1.3.cmml" xref="A1.T5.7.3.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.7.3.3.m1.1c">\alpha=2</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T5.8.4" class="ltx_tr">
<th id="A1.T5.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="A1.T5.8.4.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="A1.T5.8.4.1.m1.1a"><mrow id="A1.T5.8.4.1.m1.1.1" xref="A1.T5.8.4.1.m1.1.1.cmml"><mi id="A1.T5.8.4.1.m1.1.1.2" xref="A1.T5.8.4.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T5.8.4.1.m1.1.1.1" xref="A1.T5.8.4.1.m1.1.1.1.cmml">=</mo><mn id="A1.T5.8.4.1.m1.1.1.3" xref="A1.T5.8.4.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.8.4.1.m1.1b"><apply id="A1.T5.8.4.1.m1.1.1.cmml" xref="A1.T5.8.4.1.m1.1.1"><eq id="A1.T5.8.4.1.m1.1.1.1.cmml" xref="A1.T5.8.4.1.m1.1.1.1"></eq><ci id="A1.T5.8.4.1.m1.1.1.2.cmml" xref="A1.T5.8.4.1.m1.1.1.2">ğ›½</ci><cn type="float" id="A1.T5.8.4.1.m1.1.1.3.cmml" xref="A1.T5.8.4.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.8.4.1.m1.1c">\beta=0.5</annotation></semantics></math></th>
<td id="A1.T5.8.4.2" class="ltx_td ltx_align_center ltx_border_t">3.531</td>
<td id="A1.T5.8.4.3" class="ltx_td ltx_align_center ltx_border_t">3.501</td>
<td id="A1.T5.8.4.4" class="ltx_td ltx_align_center ltx_border_t">3.554</td>
</tr>
<tr id="A1.T5.9.5" class="ltx_tr">
<th id="A1.T5.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T5.9.5.1.m1.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="A1.T5.9.5.1.m1.1a"><mrow id="A1.T5.9.5.1.m1.1.1" xref="A1.T5.9.5.1.m1.1.1.cmml"><mi id="A1.T5.9.5.1.m1.1.1.2" xref="A1.T5.9.5.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T5.9.5.1.m1.1.1.1" xref="A1.T5.9.5.1.m1.1.1.1.cmml">=</mo><mn id="A1.T5.9.5.1.m1.1.1.3" xref="A1.T5.9.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.9.5.1.m1.1b"><apply id="A1.T5.9.5.1.m1.1.1.cmml" xref="A1.T5.9.5.1.m1.1.1"><eq id="A1.T5.9.5.1.m1.1.1.1.cmml" xref="A1.T5.9.5.1.m1.1.1.1"></eq><ci id="A1.T5.9.5.1.m1.1.1.2.cmml" xref="A1.T5.9.5.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T5.9.5.1.m1.1.1.3.cmml" xref="A1.T5.9.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.9.5.1.m1.1c">\beta=1</annotation></semantics></math></th>
<td id="A1.T5.9.5.2" class="ltx_td ltx_align_center">3.551</td>
<td id="A1.T5.9.5.3" class="ltx_td ltx_align_center">3.676</td>
<td id="A1.T5.9.5.4" class="ltx_td ltx_align_center">3.626</td>
</tr>
<tr id="A1.T5.10.6" class="ltx_tr">
<th id="A1.T5.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T5.10.6.1.m1.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="A1.T5.10.6.1.m1.1a"><mrow id="A1.T5.10.6.1.m1.1.1" xref="A1.T5.10.6.1.m1.1.1.cmml"><mi id="A1.T5.10.6.1.m1.1.1.2" xref="A1.T5.10.6.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T5.10.6.1.m1.1.1.1" xref="A1.T5.10.6.1.m1.1.1.1.cmml">=</mo><mn id="A1.T5.10.6.1.m1.1.1.3" xref="A1.T5.10.6.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T5.10.6.1.m1.1b"><apply id="A1.T5.10.6.1.m1.1.1.cmml" xref="A1.T5.10.6.1.m1.1.1"><eq id="A1.T5.10.6.1.m1.1.1.1.cmml" xref="A1.T5.10.6.1.m1.1.1.1"></eq><ci id="A1.T5.10.6.1.m1.1.1.2.cmml" xref="A1.T5.10.6.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T5.10.6.1.m1.1.1.3.cmml" xref="A1.T5.10.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.10.6.1.m1.1c">\beta=2</annotation></semantics></math></th>
<td id="A1.T5.10.6.2" class="ltx_td ltx_align_center">3.475</td>
<td id="A1.T5.10.6.3" class="ltx_td ltx_align_center">3.466</td>
<td id="A1.T5.10.6.4" class="ltx_td ltx_align_center">3.513</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>WHENet MAE vs. <math id="A1.T6.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T6.3.m1.1b"><mi id="A1.T6.3.m1.1.1" xref="A1.T6.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A1.T6.3.m1.1c"><ci id="A1.T6.3.m1.1.1.cmml" xref="A1.T6.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.3.m1.1d">\alpha</annotation></semantics></math> and <math id="A1.T6.4.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.T6.4.m2.1b"><mi id="A1.T6.4.m2.1.1" xref="A1.T6.4.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.T6.4.m2.1c"><ci id="A1.T6.4.m2.1.1.cmml" xref="A1.T6.4.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.4.m2.1d">\beta</annotation></semantics></math> on AFLW2000</figcaption>
<table id="A1.T6.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T6.7.3" class="ltx_tr">
<th id="A1.T6.7.3.4" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="A1.T6.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T6.5.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.T6.5.1.1.m1.1a"><mrow id="A1.T6.5.1.1.m1.1.1" xref="A1.T6.5.1.1.m1.1.1.cmml"><mi id="A1.T6.5.1.1.m1.1.1.2" xref="A1.T6.5.1.1.m1.1.1.2.cmml">Î±</mi><mo id="A1.T6.5.1.1.m1.1.1.1" xref="A1.T6.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A1.T6.5.1.1.m1.1.1.3" xref="A1.T6.5.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T6.5.1.1.m1.1b"><apply id="A1.T6.5.1.1.m1.1.1.cmml" xref="A1.T6.5.1.1.m1.1.1"><eq id="A1.T6.5.1.1.m1.1.1.1.cmml" xref="A1.T6.5.1.1.m1.1.1.1"></eq><ci id="A1.T6.5.1.1.m1.1.1.2.cmml" xref="A1.T6.5.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="A1.T6.5.1.1.m1.1.1.3.cmml" xref="A1.T6.5.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.5.1.1.m1.1c">\alpha=0.5</annotation></semantics></math></th>
<th id="A1.T6.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T6.6.2.2.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="A1.T6.6.2.2.m1.1a"><mrow id="A1.T6.6.2.2.m1.1.1" xref="A1.T6.6.2.2.m1.1.1.cmml"><mi id="A1.T6.6.2.2.m1.1.1.2" xref="A1.T6.6.2.2.m1.1.1.2.cmml">Î±</mi><mo id="A1.T6.6.2.2.m1.1.1.1" xref="A1.T6.6.2.2.m1.1.1.1.cmml">=</mo><mn id="A1.T6.6.2.2.m1.1.1.3" xref="A1.T6.6.2.2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T6.6.2.2.m1.1b"><apply id="A1.T6.6.2.2.m1.1.1.cmml" xref="A1.T6.6.2.2.m1.1.1"><eq id="A1.T6.6.2.2.m1.1.1.1.cmml" xref="A1.T6.6.2.2.m1.1.1.1"></eq><ci id="A1.T6.6.2.2.m1.1.1.2.cmml" xref="A1.T6.6.2.2.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T6.6.2.2.m1.1.1.3.cmml" xref="A1.T6.6.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.6.2.2.m1.1c">\alpha=1</annotation></semantics></math></th>
<th id="A1.T6.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T6.7.3.3.m1.1" class="ltx_Math" alttext="\alpha=2" display="inline"><semantics id="A1.T6.7.3.3.m1.1a"><mrow id="A1.T6.7.3.3.m1.1.1" xref="A1.T6.7.3.3.m1.1.1.cmml"><mi id="A1.T6.7.3.3.m1.1.1.2" xref="A1.T6.7.3.3.m1.1.1.2.cmml">Î±</mi><mo id="A1.T6.7.3.3.m1.1.1.1" xref="A1.T6.7.3.3.m1.1.1.1.cmml">=</mo><mn id="A1.T6.7.3.3.m1.1.1.3" xref="A1.T6.7.3.3.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T6.7.3.3.m1.1b"><apply id="A1.T6.7.3.3.m1.1.1.cmml" xref="A1.T6.7.3.3.m1.1.1"><eq id="A1.T6.7.3.3.m1.1.1.1.cmml" xref="A1.T6.7.3.3.m1.1.1.1"></eq><ci id="A1.T6.7.3.3.m1.1.1.2.cmml" xref="A1.T6.7.3.3.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T6.7.3.3.m1.1.1.3.cmml" xref="A1.T6.7.3.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.7.3.3.m1.1c">\alpha=2</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T6.8.4" class="ltx_tr">
<th id="A1.T6.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="A1.T6.8.4.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="A1.T6.8.4.1.m1.1a"><mrow id="A1.T6.8.4.1.m1.1.1" xref="A1.T6.8.4.1.m1.1.1.cmml"><mi id="A1.T6.8.4.1.m1.1.1.2" xref="A1.T6.8.4.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T6.8.4.1.m1.1.1.1" xref="A1.T6.8.4.1.m1.1.1.1.cmml">=</mo><mn id="A1.T6.8.4.1.m1.1.1.3" xref="A1.T6.8.4.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T6.8.4.1.m1.1b"><apply id="A1.T6.8.4.1.m1.1.1.cmml" xref="A1.T6.8.4.1.m1.1.1"><eq id="A1.T6.8.4.1.m1.1.1.1.cmml" xref="A1.T6.8.4.1.m1.1.1.1"></eq><ci id="A1.T6.8.4.1.m1.1.1.2.cmml" xref="A1.T6.8.4.1.m1.1.1.2">ğ›½</ci><cn type="float" id="A1.T6.8.4.1.m1.1.1.3.cmml" xref="A1.T6.8.4.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.8.4.1.m1.1c">\beta=0.5</annotation></semantics></math></th>
<td id="A1.T6.8.4.2" class="ltx_td ltx_align_center ltx_border_t">5.822</td>
<td id="A1.T6.8.4.3" class="ltx_td ltx_align_center ltx_border_t">5.624</td>
<td id="A1.T6.8.4.4" class="ltx_td ltx_align_center ltx_border_t">5.620</td>
</tr>
<tr id="A1.T6.9.5" class="ltx_tr">
<th id="A1.T6.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T6.9.5.1.m1.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="A1.T6.9.5.1.m1.1a"><mrow id="A1.T6.9.5.1.m1.1.1" xref="A1.T6.9.5.1.m1.1.1.cmml"><mi id="A1.T6.9.5.1.m1.1.1.2" xref="A1.T6.9.5.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T6.9.5.1.m1.1.1.1" xref="A1.T6.9.5.1.m1.1.1.1.cmml">=</mo><mn id="A1.T6.9.5.1.m1.1.1.3" xref="A1.T6.9.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T6.9.5.1.m1.1b"><apply id="A1.T6.9.5.1.m1.1.1.cmml" xref="A1.T6.9.5.1.m1.1.1"><eq id="A1.T6.9.5.1.m1.1.1.1.cmml" xref="A1.T6.9.5.1.m1.1.1.1"></eq><ci id="A1.T6.9.5.1.m1.1.1.2.cmml" xref="A1.T6.9.5.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T6.9.5.1.m1.1.1.3.cmml" xref="A1.T6.9.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.9.5.1.m1.1c">\beta=1</annotation></semantics></math></th>
<td id="A1.T6.9.5.2" class="ltx_td ltx_align_center">5.484</td>
<td id="A1.T6.9.5.3" class="ltx_td ltx_align_center">5.424</td>
<td id="A1.T6.9.5.4" class="ltx_td ltx_align_center">5.529</td>
</tr>
<tr id="A1.T6.10.6" class="ltx_tr">
<th id="A1.T6.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T6.10.6.1.m1.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="A1.T6.10.6.1.m1.1a"><mrow id="A1.T6.10.6.1.m1.1.1" xref="A1.T6.10.6.1.m1.1.1.cmml"><mi id="A1.T6.10.6.1.m1.1.1.2" xref="A1.T6.10.6.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T6.10.6.1.m1.1.1.1" xref="A1.T6.10.6.1.m1.1.1.1.cmml">=</mo><mn id="A1.T6.10.6.1.m1.1.1.3" xref="A1.T6.10.6.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T6.10.6.1.m1.1b"><apply id="A1.T6.10.6.1.m1.1.1.cmml" xref="A1.T6.10.6.1.m1.1.1"><eq id="A1.T6.10.6.1.m1.1.1.1.cmml" xref="A1.T6.10.6.1.m1.1.1.1"></eq><ci id="A1.T6.10.6.1.m1.1.1.2.cmml" xref="A1.T6.10.6.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T6.10.6.1.m1.1.1.3.cmml" xref="A1.T6.10.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.10.6.1.m1.1c">\beta=2</annotation></semantics></math></th>
<td id="A1.T6.10.6.2" class="ltx_td ltx_align_center">5.658</td>
<td id="A1.T6.10.6.3" class="ltx_td ltx_align_center">5.414</td>
<td id="A1.T6.10.6.4" class="ltx_td ltx_align_center">5.509</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>WHENet MAE vs. <math id="A1.T7.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T7.3.m1.1b"><mi id="A1.T7.3.m1.1.1" xref="A1.T7.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A1.T7.3.m1.1c"><ci id="A1.T7.3.m1.1.1.cmml" xref="A1.T7.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.3.m1.1d">\alpha</annotation></semantics></math> and <math id="A1.T7.4.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.T7.4.m2.1b"><mi id="A1.T7.4.m2.1.1" xref="A1.T7.4.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.T7.4.m2.1c"><ci id="A1.T7.4.m2.1.1.cmml" xref="A1.T7.4.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.4.m2.1d">\beta</annotation></semantics></math> on BIWI</figcaption>
<table id="A1.T7.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T7.7.3" class="ltx_tr">
<th id="A1.T7.7.3.4" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="A1.T7.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T7.5.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.T7.5.1.1.m1.1a"><mrow id="A1.T7.5.1.1.m1.1.1" xref="A1.T7.5.1.1.m1.1.1.cmml"><mi id="A1.T7.5.1.1.m1.1.1.2" xref="A1.T7.5.1.1.m1.1.1.2.cmml">Î±</mi><mo id="A1.T7.5.1.1.m1.1.1.1" xref="A1.T7.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A1.T7.5.1.1.m1.1.1.3" xref="A1.T7.5.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.5.1.1.m1.1b"><apply id="A1.T7.5.1.1.m1.1.1.cmml" xref="A1.T7.5.1.1.m1.1.1"><eq id="A1.T7.5.1.1.m1.1.1.1.cmml" xref="A1.T7.5.1.1.m1.1.1.1"></eq><ci id="A1.T7.5.1.1.m1.1.1.2.cmml" xref="A1.T7.5.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="A1.T7.5.1.1.m1.1.1.3.cmml" xref="A1.T7.5.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.5.1.1.m1.1c">\alpha=0.5</annotation></semantics></math></th>
<th id="A1.T7.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T7.6.2.2.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="A1.T7.6.2.2.m1.1a"><mrow id="A1.T7.6.2.2.m1.1.1" xref="A1.T7.6.2.2.m1.1.1.cmml"><mi id="A1.T7.6.2.2.m1.1.1.2" xref="A1.T7.6.2.2.m1.1.1.2.cmml">Î±</mi><mo id="A1.T7.6.2.2.m1.1.1.1" xref="A1.T7.6.2.2.m1.1.1.1.cmml">=</mo><mn id="A1.T7.6.2.2.m1.1.1.3" xref="A1.T7.6.2.2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.6.2.2.m1.1b"><apply id="A1.T7.6.2.2.m1.1.1.cmml" xref="A1.T7.6.2.2.m1.1.1"><eq id="A1.T7.6.2.2.m1.1.1.1.cmml" xref="A1.T7.6.2.2.m1.1.1.1"></eq><ci id="A1.T7.6.2.2.m1.1.1.2.cmml" xref="A1.T7.6.2.2.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T7.6.2.2.m1.1.1.3.cmml" xref="A1.T7.6.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.6.2.2.m1.1c">\alpha=1</annotation></semantics></math></th>
<th id="A1.T7.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T7.7.3.3.m1.1" class="ltx_Math" alttext="\alpha=2" display="inline"><semantics id="A1.T7.7.3.3.m1.1a"><mrow id="A1.T7.7.3.3.m1.1.1" xref="A1.T7.7.3.3.m1.1.1.cmml"><mi id="A1.T7.7.3.3.m1.1.1.2" xref="A1.T7.7.3.3.m1.1.1.2.cmml">Î±</mi><mo id="A1.T7.7.3.3.m1.1.1.1" xref="A1.T7.7.3.3.m1.1.1.1.cmml">=</mo><mn id="A1.T7.7.3.3.m1.1.1.3" xref="A1.T7.7.3.3.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.7.3.3.m1.1b"><apply id="A1.T7.7.3.3.m1.1.1.cmml" xref="A1.T7.7.3.3.m1.1.1"><eq id="A1.T7.7.3.3.m1.1.1.1.cmml" xref="A1.T7.7.3.3.m1.1.1.1"></eq><ci id="A1.T7.7.3.3.m1.1.1.2.cmml" xref="A1.T7.7.3.3.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T7.7.3.3.m1.1.1.3.cmml" xref="A1.T7.7.3.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.7.3.3.m1.1c">\alpha=2</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T7.8.4" class="ltx_tr">
<th id="A1.T7.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="A1.T7.8.4.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="A1.T7.8.4.1.m1.1a"><mrow id="A1.T7.8.4.1.m1.1.1" xref="A1.T7.8.4.1.m1.1.1.cmml"><mi id="A1.T7.8.4.1.m1.1.1.2" xref="A1.T7.8.4.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T7.8.4.1.m1.1.1.1" xref="A1.T7.8.4.1.m1.1.1.1.cmml">=</mo><mn id="A1.T7.8.4.1.m1.1.1.3" xref="A1.T7.8.4.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.8.4.1.m1.1b"><apply id="A1.T7.8.4.1.m1.1.1.cmml" xref="A1.T7.8.4.1.m1.1.1"><eq id="A1.T7.8.4.1.m1.1.1.1.cmml" xref="A1.T7.8.4.1.m1.1.1.1"></eq><ci id="A1.T7.8.4.1.m1.1.1.2.cmml" xref="A1.T7.8.4.1.m1.1.1.2">ğ›½</ci><cn type="float" id="A1.T7.8.4.1.m1.1.1.3.cmml" xref="A1.T7.8.4.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.8.4.1.m1.1c">\beta=0.5</annotation></semantics></math></th>
<td id="A1.T7.8.4.2" class="ltx_td ltx_align_center ltx_border_t">3.823</td>
<td id="A1.T7.8.4.3" class="ltx_td ltx_align_center ltx_border_t">3.855</td>
<td id="A1.T7.8.4.4" class="ltx_td ltx_align_center ltx_border_t">3.880</td>
</tr>
<tr id="A1.T7.9.5" class="ltx_tr">
<th id="A1.T7.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T7.9.5.1.m1.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="A1.T7.9.5.1.m1.1a"><mrow id="A1.T7.9.5.1.m1.1.1" xref="A1.T7.9.5.1.m1.1.1.cmml"><mi id="A1.T7.9.5.1.m1.1.1.2" xref="A1.T7.9.5.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T7.9.5.1.m1.1.1.1" xref="A1.T7.9.5.1.m1.1.1.1.cmml">=</mo><mn id="A1.T7.9.5.1.m1.1.1.3" xref="A1.T7.9.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.9.5.1.m1.1b"><apply id="A1.T7.9.5.1.m1.1.1.cmml" xref="A1.T7.9.5.1.m1.1.1"><eq id="A1.T7.9.5.1.m1.1.1.1.cmml" xref="A1.T7.9.5.1.m1.1.1.1"></eq><ci id="A1.T7.9.5.1.m1.1.1.2.cmml" xref="A1.T7.9.5.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T7.9.5.1.m1.1.1.3.cmml" xref="A1.T7.9.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.9.5.1.m1.1c">\beta=1</annotation></semantics></math></th>
<td id="A1.T7.9.5.2" class="ltx_td ltx_align_center">3.843</td>
<td id="A1.T7.9.5.3" class="ltx_td ltx_align_center">3.814</td>
<td id="A1.T7.9.5.4" class="ltx_td ltx_align_center">3.786</td>
</tr>
<tr id="A1.T7.10.6" class="ltx_tr">
<th id="A1.T7.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T7.10.6.1.m1.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="A1.T7.10.6.1.m1.1a"><mrow id="A1.T7.10.6.1.m1.1.1" xref="A1.T7.10.6.1.m1.1.1.cmml"><mi id="A1.T7.10.6.1.m1.1.1.2" xref="A1.T7.10.6.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T7.10.6.1.m1.1.1.1" xref="A1.T7.10.6.1.m1.1.1.1.cmml">=</mo><mn id="A1.T7.10.6.1.m1.1.1.3" xref="A1.T7.10.6.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T7.10.6.1.m1.1b"><apply id="A1.T7.10.6.1.m1.1.1.cmml" xref="A1.T7.10.6.1.m1.1.1"><eq id="A1.T7.10.6.1.m1.1.1.1.cmml" xref="A1.T7.10.6.1.m1.1.1.1"></eq><ci id="A1.T7.10.6.1.m1.1.1.2.cmml" xref="A1.T7.10.6.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T7.10.6.1.m1.1.1.3.cmml" xref="A1.T7.10.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.10.6.1.m1.1c">\beta=2</annotation></semantics></math></th>
<td id="A1.T7.10.6.2" class="ltx_td ltx_align_center">3.710</td>
<td id="A1.T7.10.6.3" class="ltx_td ltx_align_center">4.064</td>
<td id="A1.T7.10.6.4" class="ltx_td ltx_align_center">3.935</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>WHENet MAE vs. <math id="A1.T8.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.T8.3.m1.1b"><mi id="A1.T8.3.m1.1.1" xref="A1.T8.3.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="A1.T8.3.m1.1c"><ci id="A1.T8.3.m1.1.1.cmml" xref="A1.T8.3.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.3.m1.1d">\alpha</annotation></semantics></math> and <math id="A1.T8.4.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="A1.T8.4.m2.1b"><mi id="A1.T8.4.m2.1.1" xref="A1.T8.4.m2.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="A1.T8.4.m2.1c"><ci id="A1.T8.4.m2.1.1.cmml" xref="A1.T8.4.m2.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.4.m2.1d">\beta</annotation></semantics></math> on our combined dataset</figcaption>
<table id="A1.T8.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T8.7.3" class="ltx_tr">
<th id="A1.T8.7.3.4" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="A1.T8.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T8.5.1.1.m1.1" class="ltx_Math" alttext="\alpha=0.5" display="inline"><semantics id="A1.T8.5.1.1.m1.1a"><mrow id="A1.T8.5.1.1.m1.1.1" xref="A1.T8.5.1.1.m1.1.1.cmml"><mi id="A1.T8.5.1.1.m1.1.1.2" xref="A1.T8.5.1.1.m1.1.1.2.cmml">Î±</mi><mo id="A1.T8.5.1.1.m1.1.1.1" xref="A1.T8.5.1.1.m1.1.1.1.cmml">=</mo><mn id="A1.T8.5.1.1.m1.1.1.3" xref="A1.T8.5.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T8.5.1.1.m1.1b"><apply id="A1.T8.5.1.1.m1.1.1.cmml" xref="A1.T8.5.1.1.m1.1.1"><eq id="A1.T8.5.1.1.m1.1.1.1.cmml" xref="A1.T8.5.1.1.m1.1.1.1"></eq><ci id="A1.T8.5.1.1.m1.1.1.2.cmml" xref="A1.T8.5.1.1.m1.1.1.2">ğ›¼</ci><cn type="float" id="A1.T8.5.1.1.m1.1.1.3.cmml" xref="A1.T8.5.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.5.1.1.m1.1c">\alpha=0.5</annotation></semantics></math></th>
<th id="A1.T8.6.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T8.6.2.2.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="A1.T8.6.2.2.m1.1a"><mrow id="A1.T8.6.2.2.m1.1.1" xref="A1.T8.6.2.2.m1.1.1.cmml"><mi id="A1.T8.6.2.2.m1.1.1.2" xref="A1.T8.6.2.2.m1.1.1.2.cmml">Î±</mi><mo id="A1.T8.6.2.2.m1.1.1.1" xref="A1.T8.6.2.2.m1.1.1.1.cmml">=</mo><mn id="A1.T8.6.2.2.m1.1.1.3" xref="A1.T8.6.2.2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T8.6.2.2.m1.1b"><apply id="A1.T8.6.2.2.m1.1.1.cmml" xref="A1.T8.6.2.2.m1.1.1"><eq id="A1.T8.6.2.2.m1.1.1.1.cmml" xref="A1.T8.6.2.2.m1.1.1.1"></eq><ci id="A1.T8.6.2.2.m1.1.1.2.cmml" xref="A1.T8.6.2.2.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T8.6.2.2.m1.1.1.3.cmml" xref="A1.T8.6.2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.6.2.2.m1.1c">\alpha=1</annotation></semantics></math></th>
<th id="A1.T8.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="A1.T8.7.3.3.m1.1" class="ltx_Math" alttext="\alpha=2" display="inline"><semantics id="A1.T8.7.3.3.m1.1a"><mrow id="A1.T8.7.3.3.m1.1.1" xref="A1.T8.7.3.3.m1.1.1.cmml"><mi id="A1.T8.7.3.3.m1.1.1.2" xref="A1.T8.7.3.3.m1.1.1.2.cmml">Î±</mi><mo id="A1.T8.7.3.3.m1.1.1.1" xref="A1.T8.7.3.3.m1.1.1.1.cmml">=</mo><mn id="A1.T8.7.3.3.m1.1.1.3" xref="A1.T8.7.3.3.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T8.7.3.3.m1.1b"><apply id="A1.T8.7.3.3.m1.1.1.cmml" xref="A1.T8.7.3.3.m1.1.1"><eq id="A1.T8.7.3.3.m1.1.1.1.cmml" xref="A1.T8.7.3.3.m1.1.1.1"></eq><ci id="A1.T8.7.3.3.m1.1.1.2.cmml" xref="A1.T8.7.3.3.m1.1.1.2">ğ›¼</ci><cn type="integer" id="A1.T8.7.3.3.m1.1.1.3.cmml" xref="A1.T8.7.3.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.7.3.3.m1.1c">\alpha=2</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T8.8.4" class="ltx_tr">
<th id="A1.T8.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="A1.T8.8.4.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="A1.T8.8.4.1.m1.1a"><mrow id="A1.T8.8.4.1.m1.1.1" xref="A1.T8.8.4.1.m1.1.1.cmml"><mi id="A1.T8.8.4.1.m1.1.1.2" xref="A1.T8.8.4.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T8.8.4.1.m1.1.1.1" xref="A1.T8.8.4.1.m1.1.1.1.cmml">=</mo><mn id="A1.T8.8.4.1.m1.1.1.3" xref="A1.T8.8.4.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T8.8.4.1.m1.1b"><apply id="A1.T8.8.4.1.m1.1.1.cmml" xref="A1.T8.8.4.1.m1.1.1"><eq id="A1.T8.8.4.1.m1.1.1.1.cmml" xref="A1.T8.8.4.1.m1.1.1.1"></eq><ci id="A1.T8.8.4.1.m1.1.1.2.cmml" xref="A1.T8.8.4.1.m1.1.1.2">ğ›½</ci><cn type="float" id="A1.T8.8.4.1.m1.1.1.3.cmml" xref="A1.T8.8.4.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.8.4.1.m1.1c">\beta=0.5</annotation></semantics></math></th>
<td id="A1.T8.8.4.2" class="ltx_td ltx_align_center ltx_border_t">8.009</td>
<td id="A1.T8.8.4.3" class="ltx_td ltx_align_center ltx_border_t">8.287</td>
<td id="A1.T8.8.4.4" class="ltx_td ltx_align_center ltx_border_t">7.394</td>
</tr>
<tr id="A1.T8.9.5" class="ltx_tr">
<th id="A1.T8.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T8.9.5.1.m1.1" class="ltx_Math" alttext="\beta=1" display="inline"><semantics id="A1.T8.9.5.1.m1.1a"><mrow id="A1.T8.9.5.1.m1.1.1" xref="A1.T8.9.5.1.m1.1.1.cmml"><mi id="A1.T8.9.5.1.m1.1.1.2" xref="A1.T8.9.5.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T8.9.5.1.m1.1.1.1" xref="A1.T8.9.5.1.m1.1.1.1.cmml">=</mo><mn id="A1.T8.9.5.1.m1.1.1.3" xref="A1.T8.9.5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T8.9.5.1.m1.1b"><apply id="A1.T8.9.5.1.m1.1.1.cmml" xref="A1.T8.9.5.1.m1.1.1"><eq id="A1.T8.9.5.1.m1.1.1.1.cmml" xref="A1.T8.9.5.1.m1.1.1.1"></eq><ci id="A1.T8.9.5.1.m1.1.1.2.cmml" xref="A1.T8.9.5.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T8.9.5.1.m1.1.1.3.cmml" xref="A1.T8.9.5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.9.5.1.m1.1c">\beta=1</annotation></semantics></math></th>
<td id="A1.T8.9.5.2" class="ltx_td ltx_align_center">7.331</td>
<td id="A1.T8.9.5.3" class="ltx_td ltx_align_center">7.655</td>
<td id="A1.T8.9.5.4" class="ltx_td ltx_align_center">7.879</td>
</tr>
<tr id="A1.T8.10.6" class="ltx_tr">
<th id="A1.T8.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><math id="A1.T8.10.6.1.m1.1" class="ltx_Math" alttext="\beta=2" display="inline"><semantics id="A1.T8.10.6.1.m1.1a"><mrow id="A1.T8.10.6.1.m1.1.1" xref="A1.T8.10.6.1.m1.1.1.cmml"><mi id="A1.T8.10.6.1.m1.1.1.2" xref="A1.T8.10.6.1.m1.1.1.2.cmml">Î²</mi><mo id="A1.T8.10.6.1.m1.1.1.1" xref="A1.T8.10.6.1.m1.1.1.1.cmml">=</mo><mn id="A1.T8.10.6.1.m1.1.1.3" xref="A1.T8.10.6.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.T8.10.6.1.m1.1b"><apply id="A1.T8.10.6.1.m1.1.1.cmml" xref="A1.T8.10.6.1.m1.1.1"><eq id="A1.T8.10.6.1.m1.1.1.1.cmml" xref="A1.T8.10.6.1.m1.1.1.1"></eq><ci id="A1.T8.10.6.1.m1.1.1.2.cmml" xref="A1.T8.10.6.1.m1.1.1.2">ğ›½</ci><cn type="integer" id="A1.T8.10.6.1.m1.1.1.3.cmml" xref="A1.T8.10.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.10.6.1.m1.1c">\beta=2</annotation></semantics></math></th>
<td id="A1.T8.10.6.2" class="ltx_td ltx_align_center">7.878</td>
<td id="A1.T8.10.6.3" class="ltx_td ltx_align_center">7.457</td>
<td id="A1.T8.10.6.4" class="ltx_td ltx_align_center">7.694</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Comparison results on BIWI dataset with different modality methods. WHENet and WHENet-V are trained on 300W-LP and our combined dataset. The rest of the methods are trained on BIWI where they split the BIWI dataset into testing and training.</figcaption>
<table id="A1.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T9.1.1.1" class="ltx_tr">
<td id="A1.T9.1.1.1.1" class="ltx_td ltx_border_t"></td>
<td id="A1.T9.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">Yaw</td>
<td id="A1.T9.1.1.1.3" class="ltx_td ltx_align_left ltx_border_t">Pitch</td>
<td id="A1.T9.1.1.1.4" class="ltx_td ltx_align_left ltx_border_t">Roll</td>
<td id="A1.T9.1.1.1.5" class="ltx_td ltx_align_left ltx_border_t">MAE</td>
</tr>
<tr id="A1.T9.1.2.2" class="ltx_tr">
<td id="A1.T9.1.2.2.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="A1.T9.1.2.2.1.1" class="ltx_text ltx_font_bold">RGB-based</span></td>
</tr>
<tr id="A1.T9.1.3.3" class="ltx_tr">
<td id="A1.T9.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t">DeepHeadPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">Mukherjee and Robertson(2015)</a>]</cite>
</td>
<td id="A1.T9.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t">5.67</td>
<td id="A1.T9.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">5.18</td>
<td id="A1.T9.1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="A1.T9.1.3.3.5" class="ltx_td ltx_align_left ltx_border_t">-</td>
</tr>
<tr id="A1.T9.1.4.4" class="ltx_tr">
<td id="A1.T9.1.4.4.1" class="ltx_td ltx_align_left">SSR-Net-MDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx47" title="" class="ltx_ref">Yang etÂ al.(2018)Yang, Huang, Lin, Hsiu, and Chuang</a>]</cite>
</td>
<td id="A1.T9.1.4.4.2" class="ltx_td ltx_align_left">4.24</td>
<td id="A1.T9.1.4.4.3" class="ltx_td ltx_align_left">4.35</td>
<td id="A1.T9.1.4.4.4" class="ltx_td ltx_align_left">4.19</td>
<td id="A1.T9.1.4.4.5" class="ltx_td ltx_align_left">4.26</td>
</tr>
<tr id="A1.T9.1.5.5" class="ltx_tr">
<td id="A1.T9.1.5.5.1" class="ltx_td ltx_align_left">VGG16Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">Gu etÂ al.(2017)Gu, Yang, DeÂ Mello, and Kautz</a>]</cite>
</td>
<td id="A1.T9.1.5.5.2" class="ltx_td ltx_align_left">3.91</td>
<td id="A1.T9.1.5.5.3" class="ltx_td ltx_align_left">4.03</td>
<td id="A1.T9.1.5.5.4" class="ltx_td ltx_align_left">3.03</td>
<td id="A1.T9.1.5.5.5" class="ltx_td ltx_align_left">3.66</td>
</tr>
<tr id="A1.T9.1.6.6" class="ltx_tr">
<td id="A1.T9.1.6.6.1" class="ltx_td ltx_align_left">FSA-Caps-FusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite>
</td>
<td id="A1.T9.1.6.6.2" class="ltx_td ltx_align_left">2.89</td>
<td id="A1.T9.1.6.6.3" class="ltx_td ltx_align_left">4.29</td>
<td id="A1.T9.1.6.6.4" class="ltx_td ltx_align_left">3.60</td>
<td id="A1.T9.1.6.6.5" class="ltx_td ltx_align_left">3.60</td>
</tr>
<tr id="A1.T9.1.7.7" class="ltx_tr">
<td id="A1.T9.1.7.7.1" class="ltx_td ltx_align_left">WHENet-V</td>
<td id="A1.T9.1.7.7.2" class="ltx_td ltx_align_left">3.60</td>
<td id="A1.T9.1.7.7.3" class="ltx_td ltx_align_left">4.10</td>
<td id="A1.T9.1.7.7.4" class="ltx_td ltx_align_left">2.73</td>
<td id="A1.T9.1.7.7.5" class="ltx_td ltx_align_left">3.47</td>
</tr>
<tr id="A1.T9.1.8.8" class="ltx_tr">
<td id="A1.T9.1.8.8.1" class="ltx_td ltx_align_left">WHENet</td>
<td id="A1.T9.1.8.8.2" class="ltx_td ltx_align_left">3.99</td>
<td id="A1.T9.1.8.8.3" class="ltx_td ltx_align_left">4.39</td>
<td id="A1.T9.1.8.8.4" class="ltx_td ltx_align_left">3.06</td>
<td id="A1.T9.1.8.8.5" class="ltx_td ltx_align_left">3.81</td>
</tr>
<tr id="A1.T9.1.9.9" class="ltx_tr">
<td id="A1.T9.1.9.9.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="A1.T9.1.9.9.1.1" class="ltx_text ltx_font_bold">RGB+Depth</span></td>
</tr>
<tr id="A1.T9.1.10.10" class="ltx_tr">
<td id="A1.T9.1.10.10.1" class="ltx_td ltx_align_left ltx_border_t">DeepHeadPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx23" title="" class="ltx_ref">Mukherjee and Robertson(2015)</a>]</cite>
</td>
<td id="A1.T9.1.10.10.2" class="ltx_td ltx_align_left ltx_border_t">5.32</td>
<td id="A1.T9.1.10.10.3" class="ltx_td ltx_align_left ltx_border_t">4.76</td>
<td id="A1.T9.1.10.10.4" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="A1.T9.1.10.10.5" class="ltx_td ltx_align_left ltx_border_t">-</td>
</tr>
<tr id="A1.T9.1.11.11" class="ltx_tr">
<td id="A1.T9.1.11.11.1" class="ltx_td ltx_align_left">MartinÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">Martin etÂ al.(2014)Martin, Van DeÂ Camp, and
Stiefelhagen</a>]</cite>
</td>
<td id="A1.T9.1.11.11.2" class="ltx_td ltx_align_left">3.6</td>
<td id="A1.T9.1.11.11.3" class="ltx_td ltx_align_left">2.5</td>
<td id="A1.T9.1.11.11.4" class="ltx_td ltx_align_left">2.6</td>
<td id="A1.T9.1.11.11.5" class="ltx_td ltx_align_left">2.9</td>
</tr>
<tr id="A1.T9.1.12.12" class="ltx_tr">
<td id="A1.T9.1.12.12.1" class="ltx_td ltx_align_left">POSEidon+Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">Borghi etÂ al.(2018)Borghi, Fabbri, Vezzani, Cucchiara,
etÂ al.</a>]</cite>
</td>
<td id="A1.T9.1.12.12.2" class="ltx_td ltx_align_left">1.7</td>
<td id="A1.T9.1.12.12.3" class="ltx_td ltx_align_left">1.6</td>
<td id="A1.T9.1.12.12.4" class="ltx_td ltx_align_left">1.7</td>
<td id="A1.T9.1.12.12.5" class="ltx_td ltx_align_left">1.6</td>
</tr>
<tr id="A1.T9.1.13.13" class="ltx_tr">
<td id="A1.T9.1.13.13.1" class="ltx_td ltx_align_left ltx_border_t" colspan="5"><span id="A1.T9.1.13.13.1.1" class="ltx_text ltx_font_bold">RGB+Time</span></td>
</tr>
<tr id="A1.T9.1.14.14" class="ltx_tr">
<td id="A1.T9.1.14.14.1" class="ltx_td ltx_align_left ltx_border_t">VGG16+RNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">Gu etÂ al.(2017)Gu, Yang, DeÂ Mello, and Kautz</a>]</cite>
</td>
<td id="A1.T9.1.14.14.2" class="ltx_td ltx_align_left ltx_border_t">3.14</td>
<td id="A1.T9.1.14.14.3" class="ltx_td ltx_align_left ltx_border_t">3.48</td>
<td id="A1.T9.1.14.14.4" class="ltx_td ltx_align_left ltx_border_t">2.6</td>
<td id="A1.T9.1.14.14.5" class="ltx_td ltx_align_left ltx_border_t">3.07</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Robustness</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">A key objective of WHENet is to be robust to adverse imaging conditions as well as occlusions and accessories such as eyewear and hats. Much of the robustness of WHENet can be derived from using a similar network architecture as HopenetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> which also performs well due to the CNN architecture.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">FigureÂ <a href="#A2.F4" title="Figure 4 â€£ Appendix B Robustness â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows a selection of occluded face images where the subject tried to maintain consistent head pose while blocking areas of their face. The angular predictions are quite stable with angles varying by only <math id="A2.p2.1.m1.1" class="ltx_Math" alttext="7^{\circ}" display="inline"><semantics id="A2.p2.1.m1.1a"><msup id="A2.p2.1.m1.1.1" xref="A2.p2.1.m1.1.1.cmml"><mn id="A2.p2.1.m1.1.1.2" xref="A2.p2.1.m1.1.1.2.cmml">7</mn><mo id="A2.p2.1.m1.1.1.3" xref="A2.p2.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.1b"><apply id="A2.p2.1.m1.1.1.cmml" xref="A2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p2.1.m1.1.1.1.cmml" xref="A2.p2.1.m1.1.1">superscript</csymbol><cn type="integer" id="A2.p2.1.m1.1.1.2.cmml" xref="A2.p2.1.m1.1.1.2">7</cn><compose id="A2.p2.1.m1.1.1.3.cmml" xref="A2.p2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.1c">7^{\circ}</annotation></semantics></math> in spite of siginificant occlusions of features (some underlying variation of pose is expected due to subject motion). This suggests the method is learning high-level features rather than specific localized details.</p>
</div>
<figure id="A2.F4" class="ltx_figure"><img src="/html/2005.10353/assets/images/occlusion.png" id="A2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="105" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Head pose estimation with occlusion. Subjects asked to remain still while covering different regions of their face. Predicted deviations are within <math id="A2.F4.2.m1.1" class="ltx_Math" alttext="7^{\circ}" display="inline"><semantics id="A2.F4.2.m1.1b"><msup id="A2.F4.2.m1.1.1" xref="A2.F4.2.m1.1.1.cmml"><mn id="A2.F4.2.m1.1.1.2" xref="A2.F4.2.m1.1.1.2.cmml">7</mn><mo id="A2.F4.2.m1.1.1.3" xref="A2.F4.2.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="A2.F4.2.m1.1c"><apply id="A2.F4.2.m1.1.1.cmml" xref="A2.F4.2.m1.1.1"><csymbol cd="ambiguous" id="A2.F4.2.m1.1.1.1.cmml" xref="A2.F4.2.m1.1.1">superscript</csymbol><cn type="integer" id="A2.F4.2.m1.1.1.2.cmml" xref="A2.F4.2.m1.1.1.2">7</cn><compose id="A2.F4.2.m1.1.1.3.cmml" xref="A2.F4.2.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F4.2.m1.1d">7^{\circ}</annotation></semantics></math> of the unoccluded view (left). Some amount of deviation is expected due to slight subject motions.</figcaption>
</figure>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">We also evaluted the effect of resolution. FigureÂ <a href="#A2.F5" title="Figure 5 â€£ Appendix B Robustness â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates qualitatively that prediction accuracy is not seriously degraded by aggressive downsampling of up to 16X.</p>
</div>
<figure id="A2.F5" class="ltx_figure"><img src="/html/2005.10353/assets/images/resolution_example.png" id="A2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="359" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Downsampling factor vs. yaw, pitch &amp; roll. Ground-truth values were 47.6, 22.0, 18.8. Images were downsampled by indicated amount and then resized to their original size using nearest-neighbor interpolation before being supplied to WHENet. Head pose predictions remain relatively stable event when images are aggressively downsampled by up to 16X. Original image fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx51" title="" class="ltx_ref">Zhu etÂ al.(2016)Zhu, Lei, Liu, Shi, and Li</a>]</cite></figcaption>
</figure>
<div id="A2.p4" class="ltx_para">
<p id="A2.p4.1" class="ltx_p">We carried out this test in aggregate on the AFLW2000 dataset. The results are shown in FigureÂ <a href="#A2.F6" title="Figure 6 â€£ Appendix B Robustness â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and compared to HopenetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> and FSANetÂ Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite>. We list the smallest reported errors for Hopenet among the four training strategies inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> and thank the authors for providing this data.</p>
</div>
<figure id="A2.F6" class="ltx_figure"><img src="/html/2005.10353/assets/images/resolution_study_2.png" id="A2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="329" height="177" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Effect of downsampling factor on MAE. WHENet (orange) shows consistent improvement over the already impressive HopenetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite> and FSANetÂ Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx48" title="" class="ltx_ref">Yang etÂ al.(2019)Yang, Chen, Lin, and Chuang</a>]</cite> performance (grey and black). For Hopenet we plot the minimum (best) value at each downsampling factor among all training strategies reported inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Ruiz etÂ al.(2018)Ruiz, Chong, and Rehg</a>]</cite></figcaption>
</figure>
<div id="A2.p5" class="ltx_para">
<p id="A2.p5.1" class="ltx_p">In summation, full-range WHENet targets a task that is outside the scope of the existing state-of-the-art using a faster and significantly smaller network. In spite of this, it meets or beats state-of-the-art performance for the restricted case of HPE for frontal-to-profile views when evaluated on two datasets that were not used during training.</p>
</div>
<figure id="A2.F7" class="ltx_figure"><img src="/html/2005.10353/assets/images/openpose_results.png" id="A2.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="226" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>WHENet applied to head crops generated from keypoint predictions fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx28" title="" class="ltx_ref">Osokin(2018)</a>]</cite>, keypoints shown as dots, illustrating how HPE can be integrated with full-body pose estimation methods. Images fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx43" title="" class="ltx_ref">Wu etÂ al.(2017)Wu, Zheng, Zhao, Li, Yan, Liang, Wang, Zhou, Lin, Fu,
etÂ al.</a>]</cite></figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Applications</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Here we show qualitative examples of WHENet applied to several applications that demonstrate how HPE can integrate with real-world systems and how our training strategy allows the method to generalize to low-resolution and low-quality data that was not present during training.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">FigureÂ <a href="#A2.F7" title="Figure 7 â€£ Appendix B Robustness â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows using a pose detector based on Lightweight OpenPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx28" title="" class="ltx_ref">Osokin(2018)</a>]</cite> code to detect pose keypoints while using WHENet to predict head pose. Frequently pose-estimations do not estimate sufficient keypoints for accurate HPE but by incorporating a full-range HPE method such as WHENet, such limitations may be overcome. This could be used, for example, in sports broadcasting or by coaching staff to estimate participants fields of views and situational awareness when analyzing plays.</p>
</div>
<div id="A3.p3" class="ltx_para">
<p id="A3.p3.1" class="ltx_p">FigureÂ <a href="#A3.F8" title="Figure 8 â€£ Appendix C Applications â€£ WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> depicts a hypothetical driver-attention module where drivers are considered attentive with camera-relative yaws <math id="A3.p3.1.m1.1" class="ltx_Math" alttext="&lt;30^{\circ}" display="inline"><semantics id="A3.p3.1.m1.1a"><mrow id="A3.p3.1.m1.1.1" xref="A3.p3.1.m1.1.1.cmml"><mi id="A3.p3.1.m1.1.1.2" xref="A3.p3.1.m1.1.1.2.cmml"></mi><mo id="A3.p3.1.m1.1.1.1" xref="A3.p3.1.m1.1.1.1.cmml">&lt;</mo><msup id="A3.p3.1.m1.1.1.3" xref="A3.p3.1.m1.1.1.3.cmml"><mn id="A3.p3.1.m1.1.1.3.2" xref="A3.p3.1.m1.1.1.3.2.cmml">30</mn><mo id="A3.p3.1.m1.1.1.3.3" xref="A3.p3.1.m1.1.1.3.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="A3.p3.1.m1.1b"><apply id="A3.p3.1.m1.1.1.cmml" xref="A3.p3.1.m1.1.1"><lt id="A3.p3.1.m1.1.1.1.cmml" xref="A3.p3.1.m1.1.1.1"></lt><csymbol cd="latexml" id="A3.p3.1.m1.1.1.2.cmml" xref="A3.p3.1.m1.1.1.2">absent</csymbol><apply id="A3.p3.1.m1.1.1.3.cmml" xref="A3.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="A3.p3.1.m1.1.1.3.1.cmml" xref="A3.p3.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="A3.p3.1.m1.1.1.3.2.cmml" xref="A3.p3.1.m1.1.1.3.2">30</cn><compose id="A3.p3.1.m1.1.1.3.3.cmml" xref="A3.p3.1.m1.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p3.1.m1.1c">&lt;30^{\circ}</annotation></semantics></math> and inattentive otherwise. The extension to full-range could extend this to predicting blind spots during other activities such as reversing without requiring additional hardware.</p>
</div>
<figure id="A3.F8" class="ltx_figure"><img src="/html/2005.10353/assets/images/ad_results_2.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Applications to autonomous driving and driver assistance. Left: Green boxes indicate yaws <math id="A3.F8.3.m1.1" class="ltx_Math" alttext="&lt;\pm 45^{\circ}" display="inline"><semantics id="A3.F8.3.m1.1b"><mrow id="A3.F8.3.m1.1.1" xref="A3.F8.3.m1.1.1.cmml"><mi id="A3.F8.3.m1.1.1.2" xref="A3.F8.3.m1.1.1.2.cmml"></mi><mo id="A3.F8.3.m1.1.1.1" xref="A3.F8.3.m1.1.1.1.cmml">&lt;</mo><mrow id="A3.F8.3.m1.1.1.3" xref="A3.F8.3.m1.1.1.3.cmml"><mo id="A3.F8.3.m1.1.1.3b" xref="A3.F8.3.m1.1.1.3.cmml">Â±</mo><msup id="A3.F8.3.m1.1.1.3.2" xref="A3.F8.3.m1.1.1.3.2.cmml"><mn id="A3.F8.3.m1.1.1.3.2.2" xref="A3.F8.3.m1.1.1.3.2.2.cmml">45</mn><mo id="A3.F8.3.m1.1.1.3.2.3" xref="A3.F8.3.m1.1.1.3.2.3.cmml">âˆ˜</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.F8.3.m1.1c"><apply id="A3.F8.3.m1.1.1.cmml" xref="A3.F8.3.m1.1.1"><lt id="A3.F8.3.m1.1.1.1.cmml" xref="A3.F8.3.m1.1.1.1"></lt><csymbol cd="latexml" id="A3.F8.3.m1.1.1.2.cmml" xref="A3.F8.3.m1.1.1.2">absent</csymbol><apply id="A3.F8.3.m1.1.1.3.cmml" xref="A3.F8.3.m1.1.1.3"><csymbol cd="latexml" id="A3.F8.3.m1.1.1.3.1.cmml" xref="A3.F8.3.m1.1.1.3">plus-or-minus</csymbol><apply id="A3.F8.3.m1.1.1.3.2.cmml" xref="A3.F8.3.m1.1.1.3.2"><csymbol cd="ambiguous" id="A3.F8.3.m1.1.1.3.2.1.cmml" xref="A3.F8.3.m1.1.1.3.2">superscript</csymbol><cn type="integer" id="A3.F8.3.m1.1.1.3.2.2.cmml" xref="A3.F8.3.m1.1.1.3.2.2">45</cn><compose id="A3.F8.3.m1.1.1.3.2.3.cmml" xref="A3.F8.3.m1.1.1.3.2.3"></compose></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F8.3.m1.1d">&lt;\pm 45^{\circ}</annotation></semantics></math> and potential awareness of vehicle, red boxes indicate probable inattention. This example highlights the need for efficient and low-resolution approaches to HPE with 6 total low-resolution detections. Here low-quality pose-estimates yield poor cropping regions but WHENet successfully generalizes despite having no comparable training data. Images fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">Geiger etÂ al.(2013)Geiger, Lenz, Stiller, and
Urtasun</a>]</cite>. Right: WHENet is used to monitor driver attention, marking the driver as inattentive (red) when yaw exceeds <math id="A3.F8.4.m2.1" class="ltx_Math" alttext="30^{\circ}" display="inline"><semantics id="A3.F8.4.m2.1b"><msup id="A3.F8.4.m2.1.1" xref="A3.F8.4.m2.1.1.cmml"><mn id="A3.F8.4.m2.1.1.2" xref="A3.F8.4.m2.1.1.2.cmml">30</mn><mo id="A3.F8.4.m2.1.1.3" xref="A3.F8.4.m2.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="A3.F8.4.m2.1c"><apply id="A3.F8.4.m2.1.1.cmml" xref="A3.F8.4.m2.1.1"><csymbol cd="ambiguous" id="A3.F8.4.m2.1.1.1.cmml" xref="A3.F8.4.m2.1.1">superscript</csymbol><cn type="integer" id="A3.F8.4.m2.1.1.2.cmml" xref="A3.F8.4.m2.1.1.2">30</cn><compose id="A3.F8.4.m2.1.1.3.cmml" xref="A3.F8.4.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F8.4.m2.1d">30^{\circ}</annotation></semantics></math> and attentive (green) otherwise. Images fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">Abtahi etÂ al.(2014)Abtahi, Omidyeganeh, Shirmohammadi, and
Hariri</a>]</cite></figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2005.10352" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2005.10353" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2005.10353">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2005.10353" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2005.10354" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  9 07:22:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
