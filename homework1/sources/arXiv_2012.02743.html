<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2012.02743] SMPLy Benchmarking 3D Human Pose Estimation in the Wild</title><meta property="og:description" content="Predicting 3D human pose from images has seen great recent improvements. Novel approaches that can even predict both pose and shape from a single input image have been introduced, often relying on a parametric model ofâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SMPLy Benchmarking 3D Human Pose Estimation in the Wild">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SMPLy Benchmarking 3D Human Pose Estimation in the Wild">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2012.02743">

<!--Generated on Thu Mar  7 02:55:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SMPLy Benchmarking 3D Human Pose Estimation in the Wild</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vincent Leroy<sup id="id3.2.id1" class="ltx_sup"><span id="id3.2.id1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Philippe Weinzaepfel<sup id="id4.2.id1" class="ltx_sup"><span id="id4.2.id1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Romain BrÃ©gier
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hadrien Combaluzier Â Â Â Â Â Â Â Â Â  GrÃ©gory Rogez 
<br class="ltx_break">NAVER LABS Europe
<br class="ltx_break"><span id="id5.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">firstname.lastname@naverlabs.com</span>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span> <sup id="footnotex1.1" class="ltx_sup"><span id="footnotex1.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> indicates equal contribution.</span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Predicting 3D human pose from images has seen great recent improvements. Novel approaches that can even predict both pose and shape from a single input image have been introduced, often relying on a parametric model of the human body such as SMPL. While qualitative results for such methods are often shown for images captured in-the-wild, a proper benchmark in such conditions is still missing, as it is cumbersome to obtain ground-truth 3D poses elsewhere than in a motion capture room.
This paper presents a pipeline to easily produce and validate such a dataset with accurate ground-truth, with which we benchmark recent 3D human pose estimation methods in-the-wild.
We make use of the recently introduced Mannequin Challenge dataset which contains in-the-wild videos of people frozen in action like statues and leverage the fact that people are static and the camera moving to accurately fit the SMPL model on the sequences.
A total of 24,428 frames with registered body models are then selected from 567 scenes at almost no cost, using only online RGB videos.
We benchmark state-of-the-art SMPL-based human pose estimation methods on this dataset.
Our results highlight that challenges remain, in particular for difficult poses or for scenes where the persons are partially truncated or occluded.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup> <sup id="footnote1.1" class="ltx_sup"><span id="footnote1.1.1" class="ltx_text ltx_font_italic">âˆ—</span></sup> indicates equal contribution.</span></span></span>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Human pose estimation is an important computer vision problem with many possible applications in robotics, virtual/augmented reality or human-computer interactions.
Primarily driven by the availability (or absence) of training data, the problem has been originally tackled either as 2D pose estimation in-the-wildÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> or 3D pose estimation in either syntheticÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> or constrained scenariosÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p1.1.2" class="ltx_text"></span> using Motion Capture (MoCap) rooms.
Recently, some works have managed to predict 3D poses for in-the-wild images, and impressively, various approaches can even predict the 3D human shape from a single image.
Most of these methods rely on a parametric model of the human body such as SMPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and estimate the parameters that control pose and shape deformations of the modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.
A few recent works make direct predictions of the human 3D shape without any parametric representationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.
The task of human 3D pose and shape estimation is mostly evaluated on datasets captured in a constrained environmentÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and only qualitative results are usually shown for a few images captured in the wild.
Even if some efforts have been made to produce outdoor evaluation datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, one can argue that the accuracy of the ground truth is not sufficient or that the variety in terms of scenes, subjects, and backgrounds is not large enough to properly benchmark state-of-the-art methods.
Therefore, it is difficult to understand what the current state of 3D human pose estimation is, in particular in-the-wild, and what challenges still need to be addressed.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2012.02743/assets/Figures/multiview_skelfull.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="419" height="236" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span> 3D pose from multiview â€œfrozenâ€ people in-the-wild. We build 3D keypoints locations as well as visibility information (occluded joints in dark) with a dense SMPL based approach, based on both 2D and 3D information. Additional examples from various points of view can be found in the supplementary material.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To answer these questions, we present a new dataset of images captured in-the-wild associated with accurate ground-truth body poses.
Some approaches were proposed to annotate images with the SMPL model constraining its optimization with 2D pose detections combined with manual curationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, Inertial Measurement Units (IMUs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> or using multiple viewsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
One way to easily obtain many views of a person in a certain in-the-wild pose is to capture a video turning around that person while he/she stays still.
The Mannequin Challenge datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, recently introduced to predict the depth of humans in an image, shows in-the-wild videos of people, often several persons, frozen in action like mannequins and captured from a moving camera.
We propose to use this dataset and leverage the static posture of the people with the motion of the camera to apply structure-from-motion techniques and accurately fit the SMPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> model on the resulting point cloud.
More concretely, our pipeline includes the following steps:
(a) the human instances are tracked and segmented over the frames to find individual instances,
(b) we run a structure-from-motion reconstruction to obtain a 3D point cloud and clean it using the human segmentations,
(c) we use DensePoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> to obtain correspondences between pixels and SMPL surface, and fit SMPL with the constraint of the pose being constant over frames while minimizing the DensePose reconstruction error.
After curating the resulting data and checking the quality of our body model registrations with both automatic and manual procedures, we selected for our dataset a total of 742 human subjects in 567 different scenes. We generate in total 24,428 crops around the detected subjects at each frame.
To validate the quality of our reconstruction pipeline, we captured a set of RGB-D sequences and compared the reconstructions produced by our pipeline to the depth data, obtaining a negligible difference.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">As a second contribution, we benchmark recent methods that predict SMPL parameters in imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> or videosÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
We find that the best method regarding 3D pose estimation is VIBEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> which benefits from leveraging temporal information compared to the other ones that predict SMPL parameters from a static image.
Interestingly, when evaluating the 2D reprojection error of the body joints, HMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> outperforms more recent approaches. This can be explained by the fact that HMR was trained on more in-the-wild datasets with 2D annotations.
Despite impressive results, all state-of-the-art methods tend to catastrophically fail when humans are either occluded by objects in the scene in close-up or truncated by image boundaries. The presented benchmark helps understanding such failure cases and we believe it is of great importance to improve robustness of future works.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">After reviewing related benchmarks in SectionÂ <a href="#S2" title="2 Related Benchmarks â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we present our method to reconstruct static people in SectionÂ <a href="#S3" title="3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and validate it in SectionÂ <a href="#S4" title="4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
SectionÂ <a href="#S5" title="5 The SMPL Mannequin Benchmark â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> then summarizes our SMPL Mannequin Benchmark dataset while we benchmark state-of-the-art methods in SectionÂ <a href="#S6" title="6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Benchmarks</h2>

<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison with recent datasets used for evaluation.</figcaption>
<div id="S2.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:175.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.4pt,5.0pt) scale(0.945856330935951,0.945856330935951) ;">
<table id="S2.T1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Dataset</td>
<td id="S2.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.1.2.1" class="ltx_text"></span> <span id="S2.T1.1.1.1.2.2" class="ltx_text">
<span id="S2.T1.1.1.1.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.2.2.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">#</span></span>
<span id="S2.T1.1.1.1.2.2.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Frames</span></span>
</span></span><span id="S2.T1.1.1.1.2.3" class="ltx_text"></span></td>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.1.3.1" class="ltx_text"></span> <span id="S2.T1.1.1.1.3.2" class="ltx_text">
<span id="S2.T1.1.1.1.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.3.2.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">#</span></span>
<span id="S2.T1.1.1.1.3.2.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Scenes</span></span>
</span></span><span id="S2.T1.1.1.1.3.3" class="ltx_text"></span></td>
<td id="S2.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.1.4.1" class="ltx_text"></span> <span id="S2.T1.1.1.1.4.2" class="ltx_text">
<span id="S2.T1.1.1.1.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.4.2.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">#</span></span>
<span id="S2.T1.1.1.1.4.2.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Subjects</span></span>
</span></span><span id="S2.T1.1.1.1.4.3" class="ltx_text"></span></td>
<td id="S2.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.1.5.1" class="ltx_text"></span> <span id="S2.T1.1.1.1.5.2" class="ltx_text">
<span id="S2.T1.1.1.1.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.5.2.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">In-</span></span>
<span id="S2.T1.1.1.1.5.2.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">the-</span></span>
<span id="S2.T1.1.1.1.5.2.1.3" class="ltx_tr">
<span id="S2.T1.1.1.1.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">wild</span></span>
</span></span><span id="S2.T1.1.1.1.5.3" class="ltx_text"></span></td>
<td id="S2.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">
<span id="S2.T1.1.1.1.6.1" class="ltx_text"></span> <span id="S2.T1.1.1.1.6.2" class="ltx_text">
<span id="S2.T1.1.1.1.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S2.T1.1.1.1.6.2.1.1" class="ltx_tr">
<span id="S2.T1.1.1.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">Max #</span></span>
<span id="S2.T1.1.1.1.6.2.1.2" class="ltx_tr">
<span id="S2.T1.1.1.1.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">subjects</span></span>
<span id="S2.T1.1.1.1.6.2.1.3" class="ltx_tr">
<span id="S2.T1.1.1.1.6.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">per frame</span></span>
</span></span><span id="S2.T1.1.1.1.6.3" class="ltx_text"></span></td>
<td id="S2.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3D GT</td>
<td id="S2.T1.1.1.1.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">GT Source</td>
</tr>
<tr id="S2.T1.1.1.2" class="ltx_tr">
<td id="S2.T1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Human3.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S2.T1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">3.6M</td>
<td id="S2.T1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="S2.T1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td id="S2.T1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S2.T1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="S2.T1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">keypoints</td>
<td id="S2.T1.1.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">marker-based</td>
</tr>
<tr id="S2.T1.1.1.3" class="ltx_tr">
<td id="S2.T1.1.1.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">PanopticÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>
</td>
<td id="S2.T1.1.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1.5M</td>
<td id="S2.T1.1.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="S2.T1.1.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Â 40</td>
<td id="S2.T1.1.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">-</td>
<td id="S2.T1.1.1.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">8</td>
<td id="S2.T1.1.1.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">keypoints</td>
<td id="S2.T1.1.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">multi-views</td>
</tr>
<tr id="S2.T1.1.1.4" class="ltx_tr">
<td id="S2.T1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">MARCOnIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S2.T1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">6190</td>
<td id="S2.T1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">7</td>
<td id="S2.T1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Â 10</td>
<td id="S2.T1.1.1.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">âœ“</td>
<td id="S2.T1.1.1.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td id="S2.T1.1.1.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">keypoints</td>
<td id="S2.T1.1.1.4.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">multi-views</td>
</tr>
<tr id="S2.T1.1.1.5" class="ltx_tr">
<td id="S2.T1.1.1.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">MuPoTSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</td>
<td id="S2.T1.1.1.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">8000</td>
<td id="S2.T1.1.1.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">20</td>
<td id="S2.T1.1.1.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3</td>
<td id="S2.T1.1.1.5.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">âœ“</td>
<td id="S2.T1.1.1.5.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3</td>
<td id="S2.T1.1.1.5.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">keypoints</td>
<td id="S2.T1.1.1.5.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">multi-views</td>
</tr>
<tr id="S2.T1.1.1.6" class="ltx_tr">
<td id="S2.T1.1.1.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
<td id="S2.T1.1.1.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">51,000</td>
<td id="S2.T1.1.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">60</td>
<td id="S2.T1.1.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">7</td>
<td id="S2.T1.1.1.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">âœ“</td>
<td id="S2.T1.1.1.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td id="S2.T1.1.1.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">SMPL</td>
<td id="S2.T1.1.1.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1view + IMUs</td>
</tr>
<tr id="S2.T1.1.1.7" class="ltx_tr">
<td id="S2.T1.1.1.7.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">UP-3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S2.T1.1.1.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">8515</td>
<td id="S2.T1.1.1.7.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">8515</td>
<td id="S2.T1.1.1.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">8515</td>
<td id="S2.T1.1.1.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">âœ“</td>
<td id="S2.T1.1.1.7.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="S2.T1.1.1.7.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">SMPL</td>
<td id="S2.T1.1.1.7.8" class="ltx_td ltx_align_center" style="padding-left:2.0pt;padding-right:2.0pt;">1view + annot.</td>
</tr>
<tr id="S2.T1.1.1.8" class="ltx_tr">
<td id="S2.T1.1.1.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;"><span id="S2.T1.1.1.8.1.1" class="ltx_text ltx_font_bold">Ours</span></td>
<td id="S2.T1.1.1.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">24,428</td>
<td id="S2.T1.1.1.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">567</td>
<td id="S2.T1.1.1.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">742</td>
<td id="S2.T1.1.1.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">âœ“</td>
<td id="S2.T1.1.1.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">5</td>
<td id="S2.T1.1.1.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">SMPL</td>
<td id="S2.T1.1.1.8.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">video + static</td>
</tr>
</table>
</span></div>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Several datasets have been employed to evaluate 3D human pose estimation methods.
These include datasets captured in controlled environments such as HumanEvaÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> or Human3.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, semi-synthetic datasets such as MPI-INF-3DHPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> or MuCo-3DHPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and, finally, in-the-wild datasets like MARCOnIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, MuPoTSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, UP-3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, or 3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Datasets captured in controlled environments can rely on marker-based MoCap systems to obtain very accurate ground-truth informationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
Another way to produce ground-truth data is to employ a marker-less multiview MoCap systemÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
This technique can also be employed outdoors as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> but this implies setting-up multiple cameras in the scene of interest while making sure that the subjects are fully visible in several views.
In practice, this limits the possible scenes where data can be captured and the quality of the ground-truth 3D poses highly depends on the number of cameras deployed.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">All these datasets provide ground-truth for body 3D keypoints. Closer to ours are datasets that take a step further and provide the full 3D shape of the persons.
This is the case of 3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> where an optimization pipeline was employed to fit the SMPL model using 2D pose detections associated to motion data coming from IMUs attached to the persons.
However, the known limitations of IMUs (set-up, initial alignment, accumulated errors) make the process hardly scalable.
Another example is UP-3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> where the SMPL model was fitted to the images using single-view 2D pose detections and results were manually curated. In our case, we also optimize the parameters of the SMPL model but we use multiple views constraints of the persons in the same poses ensuring an accurate 3D pose.
Our pipeline allows to generate ground-truth for partially occluded people and multi-person scenes. Importantly, it only requires a single camera to generate the data, making our method easily scalable and allowing us to build a more varied dataset with more subjects and scenes compared to other in-the-wild datasets, as indicated in TableÂ <a href="#S2.T1" title="Table 1 â€£ 2 Related Benchmarks â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Reconstructing static human poses in videos</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To overcome the depth ambiguity inherent to monocular pose estimation methods, we propose to enrich the 3D pose estimation formulation with additional multi-view geometry constraints. In particular, we combine dense constraints arising from the 2D detections in the images in a fashion similar to that inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, with 3D point clouds reconstructed from the images, likeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
We build our benchmark upon the Mannequin Challenge datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> which consists of video sequences of people mimicking mannequins captured with a single moving camera.
This section presents the pipeline that we use to robustly reconstruct static human poses in videos, see FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
It consists of three main steps:
(a) humans are segmented and tracked (SectionÂ <a href="#S3.SS1" title="3.1 Human instance segmentation and tracking â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>),
(b) the resulting tracks are used to clean the point cloud reconstruction (SectionÂ <a href="#S3.SS2" title="3.2 SfM and Point Cloud Cleaning â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>),
(c) SMPL models are fit to each human instance of a sequence with an optimization scheme (SectionÂ <a href="#S3.SS3" title="3.3 SMPL Optimization â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>) leveraging 3D information coming from the multi-view scenario.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2012.02743/assets/Figures/pipeline_flat.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="167" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> Our pipeline to reconstruct human pose in-the-wild. See text for details.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Human instance segmentation and tracking</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.6" class="ltx_p">We rely on DensePoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> to perform human segmentation in each frame, which additionally provides body part segmentation and dense UV coordinates that will be used later. For every human instance in an image, we try to associate it with instances in neighboring frames by warping all the pixels of the mask in the central frame to a neighboring frame according to the optical flow (computed with SelfFlowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>). Because such associations may be noisy, we remove non-maximum associations: at least <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="k_{1}=50\%" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2.2" xref="S3.SS1.p1.1.m1.1.1.2.2.cmml">k</mi><mn id="S3.SS1.p1.1.m1.1.1.2.3" xref="S3.SS1.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mn id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">50</mn><mo id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><eq id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></eq><apply id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.1.1.2.3">1</cn></apply><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">k_{1}=50\%</annotation></semantics></math> of the pixels of the source instance have to fall inside the associated instance in a neighboring frame for the connection to be considered valid.
Furthermore, we also check forward and backward compatibility: a connection is kept only if it is detected with the forward and the backward pass.
Finally, we obtain all the human tracks by keeping all connected human masks, ignoring clusters with less than <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="k_{2}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">k</mi><mn id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">k_{2}</annotation></semantics></math> nodes, <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="k_{2}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">k</mi><mn id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">k_{2}</annotation></semantics></math> being set to <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mn id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">20</mn><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="latexml" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">20\%</annotation></semantics></math> of the sequence length.
Because the inter-frame motion is rather limited, and thanks to restrictive values for the <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="k_{1}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">k</mi><mn id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">k_{1}</annotation></semantics></math> and <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="k_{2}" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">k</mi><mn id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">ğ‘˜</ci><cn type="integer" id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">k_{2}</annotation></semantics></math> thresholds, this tracking method performs well most of the time and discards a track when information is ambiguous.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>SfM and Point Cloud Cleaning</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.3" class="ltx_p">Our goal is to use 3D knowledge of the scene to better constrain the estimation of the pose, which is an active trendÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
Similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, we perform Structure-from-Motion (SfM) on each sequence using COLMAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
These reconstructions contain 3D points of humans, but also on the surrounding environment which needs to be pruned.
To this aim, we count 3D points that are visible and belong to a human according to the segmentations, and only keep them when they appear more often than a given threshold. Additional details can be found in the supplementary material. This validity is estimated using three following heuristics: 
<br class="ltx_break"><math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mo id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\bullet</annotation></semantics></math> The 3D point has to reproject inside a human mask. 
<br class="ltx_break"><math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mo id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\bullet</annotation></semantics></math> It has to be visible, approximate visibility being computed using a low-resolution soft z-buffer. 
<br class="ltx_break"><math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mo id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">âˆ™</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">âˆ™</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\bullet</annotation></semantics></math> Visibility is reinforced using appearance: the point clouds are equipped with color information from the cameras that agreed on a particular point location, that we use to disambiguate the visibility when the point cloud is incomplete.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>SMPL Optimization</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.5" class="ltx_p">The segmented point clouds we obtain are often very noisy and incomplete due to motion blur and video compression artifacts.
Thus, we cannot fit SMPL using regular ICPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.
We consequently devise an optimization scheme that considers per-frame geometric and semantic information.
For every sequence, we are given a set of <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">N</annotation></semantics></math> images <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\{I_{n}\}_{n=1}^{N}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msubsup id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mrow id="S3.SS3.p1.2.m2.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.1.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.2.cmml">{</mo><msub id="S3.SS3.p1.2.m2.1.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S3.SS3.p1.2.m2.1.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS3.p1.2.m2.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.1.3.2.cmml">n</mi><mo id="S3.SS3.p1.2.m2.1.1.1.3.1" xref="S3.SS3.p1.2.m2.1.1.1.3.1.cmml">=</mo><mn id="S3.SS3.p1.2.m2.1.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><set id="S3.SS3.p1.2.m2.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1"><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2">ğ¼</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.3">ğ‘›</ci></apply></set><apply id="S3.SS3.p1.2.m2.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3"><eq id="S3.SS3.p1.2.m2.1.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.1"></eq><ci id="S3.SS3.p1.2.m2.1.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.2">ğ‘›</ci><cn type="integer" id="S3.SS3.p1.2.m2.1.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\{I_{n}\}_{n=1}^{N}</annotation></semantics></math>, and their projection operator <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\pi_{n}:\mathbb{R}^{3}\ \to\mathbb{R}^{2}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mrow id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><msub id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2.2" xref="S3.SS3.p1.3.m3.1.1.2.2.cmml">Ï€</mi><mi id="S3.SS3.p1.3.m3.1.1.2.3" xref="S3.SS3.p1.3.m3.1.1.2.3.cmml">n</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S3.SS3.p1.3.m3.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.cmml">:</mo><mrow id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml"><msup id="S3.SS3.p1.3.m3.1.1.3.2" xref="S3.SS3.p1.3.m3.1.1.3.2.cmml"><mi id="S3.SS3.p1.3.m3.1.1.3.2.2" xref="S3.SS3.p1.3.m3.1.1.3.2.2.cmml">â„</mi><mn id="S3.SS3.p1.3.m3.1.1.3.2.3" xref="S3.SS3.p1.3.m3.1.1.3.2.3.cmml">3</mn></msup><mo stretchy="false" id="S3.SS3.p1.3.m3.1.1.3.1" xref="S3.SS3.p1.3.m3.1.1.3.1.cmml">â†’</mo><msup id="S3.SS3.p1.3.m3.1.1.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS3.p1.3.m3.1.1.3.3.2" xref="S3.SS3.p1.3.m3.1.1.3.3.2.cmml">â„</mi><mn id="S3.SS3.p1.3.m3.1.1.3.3.3" xref="S3.SS3.p1.3.m3.1.1.3.3.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><ci id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1">:</ci><apply id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.2.1.cmml" xref="S3.SS3.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2.2">ğœ‹</ci><ci id="S3.SS3.p1.3.m3.1.1.2.3.cmml" xref="S3.SS3.p1.3.m3.1.1.2.3">ğ‘›</ci></apply><apply id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3"><ci id="S3.SS3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3.1">â†’</ci><apply id="S3.SS3.p1.3.m3.1.1.3.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.3.2.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2">superscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.3.2.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2.2">â„</ci><cn type="integer" id="S3.SS3.p1.3.m3.1.1.3.2.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.2.3">3</cn></apply><apply id="S3.SS3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3">superscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3.2">â„</ci><cn type="integer" id="S3.SS3.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\pi_{n}:\mathbb{R}^{3}\ \to\mathbb{R}^{2}</annotation></semantics></math>.
For each human instance, we aim at finding the SMPL model that best explains the observed frames in a sequence while accounting for the camera motion.
More formally, SMPLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> is a parametric human model that is a function of pose <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">\theta</annotation></semantics></math> and shape <math id="S3.SS3.p1.5.m5.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S3.SS3.p1.5.m5.1a"><mi id="S3.SS3.p1.5.m5.1.1" xref="S3.SS3.p1.5.m5.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.1b"><ci id="S3.SS3.p1.5.m5.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.1c">\beta</annotation></semantics></math> parameters.
To find the 3D pose in a sequence, we minimize an objective function (EquationÂ <a href="#S3.E1" title="In 3.3 SMPL Optimization â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) that is the sum of five error terms described in the upcoming paragraphs: a 3D data term accounting for the 3D reconstruction, a 2D reprojection error data term, two pose priors and a shape prior:</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\{\theta^{*},\beta^{*}\}=\operatorname*{argmin}_{\theta,\beta}E_{3D}+E_{2D}+E_{epose}+E_{mpose}+E_{shape}." display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1.2.2" xref="S3.E1.m1.3.3.1.1.2.3.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.2.2.3" xref="S3.E1.m1.3.3.1.1.2.3.cmml">{</mo><msup id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.cmml">Î¸</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.3.cmml">âˆ—</mo></msup><mo id="S3.E1.m1.3.3.1.1.2.2.4" xref="S3.E1.m1.3.3.1.1.2.3.cmml">,</mo><msup id="S3.E1.m1.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.2.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.2.cmml">Î²</mi><mo id="S3.E1.m1.3.3.1.1.2.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.2.3.cmml">âˆ—</mo></msup><mo stretchy="false" id="S3.E1.m1.3.3.1.1.2.2.5" xref="S3.E1.m1.3.3.1.1.2.3.cmml">}</mo></mrow><mo rspace="0.1389em" id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.4" xref="S3.E1.m1.3.3.1.1.4.cmml"><mrow id="S3.E1.m1.3.3.1.1.4.2" xref="S3.E1.m1.3.3.1.1.4.2.cmml"><munder id="S3.E1.m1.3.3.1.1.4.2.1" xref="S3.E1.m1.3.3.1.1.4.2.1.cmml"><mo lspace="0.1389em" rspace="0.167em" id="S3.E1.m1.3.3.1.1.4.2.1.2" xref="S3.E1.m1.3.3.1.1.4.2.1.2.cmml">argmin</mo><mrow id="S3.E1.m1.2.2.2.4" xref="S3.E1.m1.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml">Î¸</mi><mo id="S3.E1.m1.2.2.2.4.1" xref="S3.E1.m1.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">Î²</mi></mrow></munder><msub id="S3.E1.m1.3.3.1.1.4.2.2" xref="S3.E1.m1.3.3.1.1.4.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.4.2.2.2" xref="S3.E1.m1.3.3.1.1.4.2.2.2.cmml">E</mi><mrow id="S3.E1.m1.3.3.1.1.4.2.2.3" xref="S3.E1.m1.3.3.1.1.4.2.2.3.cmml"><mn id="S3.E1.m1.3.3.1.1.4.2.2.3.2" xref="S3.E1.m1.3.3.1.1.4.2.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.2.2.3.1" xref="S3.E1.m1.3.3.1.1.4.2.2.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.2.2.3.3" xref="S3.E1.m1.3.3.1.1.4.2.2.3.3.cmml">D</mi></mrow></msub></mrow><mo id="S3.E1.m1.3.3.1.1.4.1" xref="S3.E1.m1.3.3.1.1.4.1.cmml">+</mo><msub id="S3.E1.m1.3.3.1.1.4.3" xref="S3.E1.m1.3.3.1.1.4.3.cmml"><mi id="S3.E1.m1.3.3.1.1.4.3.2" xref="S3.E1.m1.3.3.1.1.4.3.2.cmml">E</mi><mrow id="S3.E1.m1.3.3.1.1.4.3.3" xref="S3.E1.m1.3.3.1.1.4.3.3.cmml"><mn id="S3.E1.m1.3.3.1.1.4.3.3.2" xref="S3.E1.m1.3.3.1.1.4.3.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.3.3.1" xref="S3.E1.m1.3.3.1.1.4.3.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.3.3.3" xref="S3.E1.m1.3.3.1.1.4.3.3.3.cmml">D</mi></mrow></msub><mo id="S3.E1.m1.3.3.1.1.4.1a" xref="S3.E1.m1.3.3.1.1.4.1.cmml">+</mo><msub id="S3.E1.m1.3.3.1.1.4.4" xref="S3.E1.m1.3.3.1.1.4.4.cmml"><mi id="S3.E1.m1.3.3.1.1.4.4.2" xref="S3.E1.m1.3.3.1.1.4.4.2.cmml">E</mi><mrow id="S3.E1.m1.3.3.1.1.4.4.3" xref="S3.E1.m1.3.3.1.1.4.4.3.cmml"><mi id="S3.E1.m1.3.3.1.1.4.4.3.2" xref="S3.E1.m1.3.3.1.1.4.4.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.4.3.1" xref="S3.E1.m1.3.3.1.1.4.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.4.3.3" xref="S3.E1.m1.3.3.1.1.4.4.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.4.3.1a" xref="S3.E1.m1.3.3.1.1.4.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.4.3.4" xref="S3.E1.m1.3.3.1.1.4.4.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.4.3.1b" xref="S3.E1.m1.3.3.1.1.4.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.4.3.5" xref="S3.E1.m1.3.3.1.1.4.4.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.4.3.1c" xref="S3.E1.m1.3.3.1.1.4.4.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.4.3.6" xref="S3.E1.m1.3.3.1.1.4.4.3.6.cmml">e</mi></mrow></msub><mo id="S3.E1.m1.3.3.1.1.4.1b" xref="S3.E1.m1.3.3.1.1.4.1.cmml">+</mo><msub id="S3.E1.m1.3.3.1.1.4.5" xref="S3.E1.m1.3.3.1.1.4.5.cmml"><mi id="S3.E1.m1.3.3.1.1.4.5.2" xref="S3.E1.m1.3.3.1.1.4.5.2.cmml">E</mi><mrow id="S3.E1.m1.3.3.1.1.4.5.3" xref="S3.E1.m1.3.3.1.1.4.5.3.cmml"><mi id="S3.E1.m1.3.3.1.1.4.5.3.2" xref="S3.E1.m1.3.3.1.1.4.5.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.5.3.1" xref="S3.E1.m1.3.3.1.1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.5.3.3" xref="S3.E1.m1.3.3.1.1.4.5.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.5.3.1a" xref="S3.E1.m1.3.3.1.1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.5.3.4" xref="S3.E1.m1.3.3.1.1.4.5.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.5.3.1b" xref="S3.E1.m1.3.3.1.1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.5.3.5" xref="S3.E1.m1.3.3.1.1.4.5.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.5.3.1c" xref="S3.E1.m1.3.3.1.1.4.5.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.5.3.6" xref="S3.E1.m1.3.3.1.1.4.5.3.6.cmml">e</mi></mrow></msub><mo id="S3.E1.m1.3.3.1.1.4.1c" xref="S3.E1.m1.3.3.1.1.4.1.cmml">+</mo><msub id="S3.E1.m1.3.3.1.1.4.6" xref="S3.E1.m1.3.3.1.1.4.6.cmml"><mi id="S3.E1.m1.3.3.1.1.4.6.2" xref="S3.E1.m1.3.3.1.1.4.6.2.cmml">E</mi><mrow id="S3.E1.m1.3.3.1.1.4.6.3" xref="S3.E1.m1.3.3.1.1.4.6.3.cmml"><mi id="S3.E1.m1.3.3.1.1.4.6.3.2" xref="S3.E1.m1.3.3.1.1.4.6.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.6.3.1" xref="S3.E1.m1.3.3.1.1.4.6.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.6.3.3" xref="S3.E1.m1.3.3.1.1.4.6.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.6.3.1a" xref="S3.E1.m1.3.3.1.1.4.6.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.6.3.4" xref="S3.E1.m1.3.3.1.1.4.6.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.6.3.1b" xref="S3.E1.m1.3.3.1.1.4.6.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.6.3.5" xref="S3.E1.m1.3.3.1.1.4.6.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.4.6.3.1c" xref="S3.E1.m1.3.3.1.1.4.6.3.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.4.6.3.6" xref="S3.E1.m1.3.3.1.1.4.6.3.6.cmml">e</mi></mrow></msub></mrow></mrow><mo lspace="0em" id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3"></eq><set id="S3.E1.m1.3.3.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2"><apply id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2">ğœƒ</ci><times id="S3.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3"></times></apply><apply id="S3.E1.m1.3.3.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2">superscript</csymbol><ci id="S3.E1.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.2">ğ›½</ci><times id="S3.E1.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2.3"></times></apply></set><apply id="S3.E1.m1.3.3.1.1.4.cmml" xref="S3.E1.m1.3.3.1.1.4"><plus id="S3.E1.m1.3.3.1.1.4.1.cmml" xref="S3.E1.m1.3.3.1.1.4.1"></plus><apply id="S3.E1.m1.3.3.1.1.4.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2"><apply id="S3.E1.m1.3.3.1.1.4.2.1.cmml" xref="S3.E1.m1.3.3.1.1.4.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.2.1.1.cmml" xref="S3.E1.m1.3.3.1.1.4.2.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.2.1.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2.1.2">argmin</ci><list id="S3.E1.m1.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">ğœƒ</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">ğ›½</ci></list></apply><apply id="S3.E1.m1.3.3.1.1.4.2.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2.2">ğ¸</ci><apply id="S3.E1.m1.3.3.1.1.4.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2.3"><times id="S3.E1.m1.3.3.1.1.4.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2.3.1"></times><cn type="integer" id="S3.E1.m1.3.3.1.1.4.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2.3.2">3</cn><ci id="S3.E1.m1.3.3.1.1.4.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.2.2.3.3">ğ·</ci></apply></apply></apply><apply id="S3.E1.m1.3.3.1.1.4.3.cmml" xref="S3.E1.m1.3.3.1.1.4.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.3">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.3.2">ğ¸</ci><apply id="S3.E1.m1.3.3.1.1.4.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.3.3"><times id="S3.E1.m1.3.3.1.1.4.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.3.3.1"></times><cn type="integer" id="S3.E1.m1.3.3.1.1.4.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.3.3.2">2</cn><ci id="S3.E1.m1.3.3.1.1.4.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.3.3.3">ğ·</ci></apply></apply><apply id="S3.E1.m1.3.3.1.1.4.4.cmml" xref="S3.E1.m1.3.3.1.1.4.4"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.4.1.cmml" xref="S3.E1.m1.3.3.1.1.4.4">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.4.2.cmml" xref="S3.E1.m1.3.3.1.1.4.4.2">ğ¸</ci><apply id="S3.E1.m1.3.3.1.1.4.4.3.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3"><times id="S3.E1.m1.3.3.1.1.4.4.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3.1"></times><ci id="S3.E1.m1.3.3.1.1.4.4.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3.2">ğ‘’</ci><ci id="S3.E1.m1.3.3.1.1.4.4.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3.3">ğ‘</ci><ci id="S3.E1.m1.3.3.1.1.4.4.3.4.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3.4">ğ‘œ</ci><ci id="S3.E1.m1.3.3.1.1.4.4.3.5.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3.5">ğ‘ </ci><ci id="S3.E1.m1.3.3.1.1.4.4.3.6.cmml" xref="S3.E1.m1.3.3.1.1.4.4.3.6">ğ‘’</ci></apply></apply><apply id="S3.E1.m1.3.3.1.1.4.5.cmml" xref="S3.E1.m1.3.3.1.1.4.5"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.5.1.cmml" xref="S3.E1.m1.3.3.1.1.4.5">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.5.2.cmml" xref="S3.E1.m1.3.3.1.1.4.5.2">ğ¸</ci><apply id="S3.E1.m1.3.3.1.1.4.5.3.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3"><times id="S3.E1.m1.3.3.1.1.4.5.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3.1"></times><ci id="S3.E1.m1.3.3.1.1.4.5.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3.2">ğ‘š</ci><ci id="S3.E1.m1.3.3.1.1.4.5.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3.3">ğ‘</ci><ci id="S3.E1.m1.3.3.1.1.4.5.3.4.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3.4">ğ‘œ</ci><ci id="S3.E1.m1.3.3.1.1.4.5.3.5.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3.5">ğ‘ </ci><ci id="S3.E1.m1.3.3.1.1.4.5.3.6.cmml" xref="S3.E1.m1.3.3.1.1.4.5.3.6">ğ‘’</ci></apply></apply><apply id="S3.E1.m1.3.3.1.1.4.6.cmml" xref="S3.E1.m1.3.3.1.1.4.6"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.4.6.1.cmml" xref="S3.E1.m1.3.3.1.1.4.6">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.4.6.2.cmml" xref="S3.E1.m1.3.3.1.1.4.6.2">ğ¸</ci><apply id="S3.E1.m1.3.3.1.1.4.6.3.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3"><times id="S3.E1.m1.3.3.1.1.4.6.3.1.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3.1"></times><ci id="S3.E1.m1.3.3.1.1.4.6.3.2.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3.2">ğ‘ </ci><ci id="S3.E1.m1.3.3.1.1.4.6.3.3.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3.3">â„</ci><ci id="S3.E1.m1.3.3.1.1.4.6.3.4.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3.4">ğ‘</ci><ci id="S3.E1.m1.3.3.1.1.4.6.3.5.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3.5">ğ‘</ci><ci id="S3.E1.m1.3.3.1.1.4.6.3.6.cmml" xref="S3.E1.m1.3.3.1.1.4.6.3.6">ğ‘’</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\{\theta^{*},\beta^{*}\}=\operatorname*{argmin}_{\theta,\beta}E_{3D}+E_{2D}+E_{epose}+E_{mpose}+E_{shape}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.6" class="ltx_p"><span id="S3.SS3.p3.6.1" class="ltx_text ltx_font_bold">3D Data term.</span>
DensePoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> provides body part segmentations and UV texture coordinates.
The 3D data term ensures that the vertices of the fitted SMPL model roughly match with the extracted UV coordinates in the images.
Let <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{V}^{r}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msup id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">ğ•</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ğ•</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathbf{V}^{r}</annotation></semantics></math> be the set of <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="3D" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mn id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p3.2.m2.1.1.1" xref="S3.SS3.p3.2.m2.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><times id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1"></times><cn type="integer" id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">3</cn><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">3D</annotation></semantics></math> points in the point clouds after cleaning, <em id="S3.SS3.p3.6.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S3.SS3.p3.6.3" class="ltx_text"></span>, all points are supposed to belong to the human instance.
For each clean 3D point <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="x_{r}\in\mathbf{V}^{r}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><msub id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2.2" xref="S3.SS3.p3.3.m3.1.1.2.2.cmml">x</mi><mi id="S3.SS3.p3.3.m3.1.1.2.3" xref="S3.SS3.p3.3.m3.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">ğ•</mi><mi id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">r</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><in id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></in><apply id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.2.1.cmml" xref="S3.SS3.p3.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2.2">ğ‘¥</ci><ci id="S3.SS3.p3.3.m3.1.1.2.3.cmml" xref="S3.SS3.p3.3.m3.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">ğ•</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">x_{r}\in\mathbf{V}^{r}</annotation></semantics></math>, we compute its pixel projection <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="\pi_{n}(x_{r})" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><mrow id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><msub id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml"><mi id="S3.SS3.p3.4.m4.1.1.3.2" xref="S3.SS3.p3.4.m4.1.1.3.2.cmml">Ï€</mi><mi id="S3.SS3.p3.4.m4.1.1.3.3" xref="S3.SS3.p3.4.m4.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.p3.4.m4.1.1.1.1" xref="S3.SS3.p3.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p3.4.m4.1.1.1.1.2" xref="S3.SS3.p3.4.m4.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p3.4.m4.1.1.1.1.1" xref="S3.SS3.p3.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.1.1.1.2" xref="S3.SS3.p3.4.m4.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p3.4.m4.1.1.1.1.1.3" xref="S3.SS3.p3.4.m4.1.1.1.1.1.3.cmml">r</mi></msub><mo stretchy="false" id="S3.SS3.p3.4.m4.1.1.1.1.3" xref="S3.SS3.p3.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><times id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2"></times><apply id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.3.1.cmml" xref="S3.SS3.p3.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.3.2.cmml" xref="S3.SS3.p3.4.m4.1.1.3.2">ğœ‹</ci><ci id="S3.SS3.p3.4.m4.1.1.3.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3.3">ğ‘›</ci></apply><apply id="S3.SS3.p3.4.m4.1.1.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p3.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.1.1.1.3">ğ‘Ÿ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">\pi_{n}(x_{r})</annotation></semantics></math> in the frame <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="I_{n}" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><msub id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml"><mi id="S3.SS3.p3.5.m5.1.1.2" xref="S3.SS3.p3.5.m5.1.1.2.cmml">I</mi><mi id="S3.SS3.p3.5.m5.1.1.3" xref="S3.SS3.p3.5.m5.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.1.2.cmml" xref="S3.SS3.p3.5.m5.1.1.2">ğ¼</ci><ci id="S3.SS3.p3.5.m5.1.1.3.cmml" xref="S3.SS3.p3.5.m5.1.1.3">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">I_{n}</annotation></semantics></math> of the sequence.
Given the DensePose pixel-to-vertex association, we recover the corresponding SMPL vertex coordinate <math id="S3.SS3.p3.6.m6.1" class="ltx_Math" alttext="x_{s}=DP(\pi_{n}(x_{r}))" display="inline"><semantics id="S3.SS3.p3.6.m6.1a"><mrow id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml"><msub id="S3.SS3.p3.6.m6.1.1.3" xref="S3.SS3.p3.6.m6.1.1.3.cmml"><mi id="S3.SS3.p3.6.m6.1.1.3.2" xref="S3.SS3.p3.6.m6.1.1.3.2.cmml">x</mi><mi id="S3.SS3.p3.6.m6.1.1.3.3" xref="S3.SS3.p3.6.m6.1.1.3.3.cmml">s</mi></msub><mo id="S3.SS3.p3.6.m6.1.1.2" xref="S3.SS3.p3.6.m6.1.1.2.cmml">=</mo><mrow id="S3.SS3.p3.6.m6.1.1.1" xref="S3.SS3.p3.6.m6.1.1.1.cmml"><mi id="S3.SS3.p3.6.m6.1.1.1.3" xref="S3.SS3.p3.6.m6.1.1.1.3.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.6.m6.1.1.1.2" xref="S3.SS3.p3.6.m6.1.1.1.2.cmml">â€‹</mo><mi id="S3.SS3.p3.6.m6.1.1.1.4" xref="S3.SS3.p3.6.m6.1.1.1.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.6.m6.1.1.1.2a" xref="S3.SS3.p3.6.m6.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.p3.6.m6.1.1.1.1.1" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p3.6.m6.1.1.1.1.1.2" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p3.6.m6.1.1.1.1.1.1" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.cmml"><msub id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.cmml"><mi id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.2" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.2.cmml">Ï€</mi><mi id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.3" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p3.6.m6.1.1.1.1.1.1.2" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.2" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.2" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.3.cmml">r</mi></msub><mo stretchy="false" id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS3.p3.6.m6.1.1.1.1.1.3" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><apply id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1"><eq id="S3.SS3.p3.6.m6.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.2"></eq><apply id="S3.SS3.p3.6.m6.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.3.1.cmml" xref="S3.SS3.p3.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.6.m6.1.1.3.2.cmml" xref="S3.SS3.p3.6.m6.1.1.3.2">ğ‘¥</ci><ci id="S3.SS3.p3.6.m6.1.1.3.3.cmml" xref="S3.SS3.p3.6.m6.1.1.3.3">ğ‘ </ci></apply><apply id="S3.SS3.p3.6.m6.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1"><times id="S3.SS3.p3.6.m6.1.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.1.2"></times><ci id="S3.SS3.p3.6.m6.1.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.1.3">ğ·</ci><ci id="S3.SS3.p3.6.m6.1.1.1.4.cmml" xref="S3.SS3.p3.6.m6.1.1.1.4">ğ‘ƒ</ci><apply id="S3.SS3.p3.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1"><times id="S3.SS3.p3.6.m6.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.2"></times><apply id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.2.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.2">ğœ‹</ci><ci id="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.3.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.3.3">ğ‘›</ci></apply><apply id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.6.m6.1.1.1.1.1.1.1.1.1.3">ğ‘Ÿ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">x_{s}=DP(\pi_{n}(x_{r}))</annotation></semantics></math> for this point.
The 3D data term is a cost on the Euclidean distance between SMPL points and target 3D points, summed over all frames and all 3D point clouds:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.3" class="ltx_Math" alttext="E_{3D}(\theta,\beta)=\sum_{n=1}^{N}\sum_{x_{r}\in\mathbb{V}^{r}_{n}}\omega^{3D}_{s}\rho(x_{r}-x_{s})," display="block"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1.3" xref="S3.E2.m1.3.3.1.1.3.cmml"><msub id="S3.E2.m1.3.3.1.1.3.2" xref="S3.E2.m1.3.3.1.1.3.2.cmml"><mi id="S3.E2.m1.3.3.1.1.3.2.2" xref="S3.E2.m1.3.3.1.1.3.2.2.cmml">E</mi><mrow id="S3.E2.m1.3.3.1.1.3.2.3" xref="S3.E2.m1.3.3.1.1.3.2.3.cmml"><mn id="S3.E2.m1.3.3.1.1.3.2.3.2" xref="S3.E2.m1.3.3.1.1.3.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.3.2.3.1" xref="S3.E2.m1.3.3.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.3.3.1.1.3.2.3.3" xref="S3.E2.m1.3.3.1.1.3.2.3.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.3.1" xref="S3.E2.m1.3.3.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E2.m1.3.3.1.1.3.3.2" xref="S3.E2.m1.3.3.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.1.1.3.3.2.1" xref="S3.E2.m1.3.3.1.1.3.3.1.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">Î¸</mi><mo id="S3.E2.m1.3.3.1.1.3.3.2.2" xref="S3.E2.m1.3.3.1.1.3.3.1.cmml">,</mo><mi id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">Î²</mi><mo stretchy="false" id="S3.E2.m1.3.3.1.1.3.3.2.3" xref="S3.E2.m1.3.3.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E2.m1.3.3.1.1.2" xref="S3.E2.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml"><munderover id="S3.E2.m1.3.3.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E2.m1.3.3.1.1.1.2.2.2" xref="S3.E2.m1.3.3.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.3.3.1.1.1.2.2.3" xref="S3.E2.m1.3.3.1.1.1.2.2.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.2.2.3.2" xref="S3.E2.m1.3.3.1.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E2.m1.3.3.1.1.1.2.2.3.1" xref="S3.E2.m1.3.3.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E2.m1.3.3.1.1.1.2.2.3.3" xref="S3.E2.m1.3.3.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.3.3.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.cmml"><munder id="S3.E2.m1.3.3.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E2.m1.3.3.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.2.3.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.2.3.2" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.2.3.2.2" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2.2.cmml">x</mi><mi id="S3.E2.m1.3.3.1.1.1.1.2.3.2.3" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2.3.cmml">r</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.2.3.1" xref="S3.E2.m1.3.3.1.1.1.1.2.3.1.cmml">âˆˆ</mo><msubsup id="S3.E2.m1.3.3.1.1.1.1.2.3.3" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.2" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.2.cmml">ğ•</mi><mi id="S3.E2.m1.3.3.1.1.1.1.2.3.3.3" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.3.cmml">n</mi><mi id="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.3" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.3.cmml">r</mi></msubsup></mrow></munder><mrow id="S3.E2.m1.3.3.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.cmml"><msubsup id="S3.E2.m1.3.3.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.3.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.2.cmml">Ï‰</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.3.cmml">s</mi><mrow id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.cmml"><mn id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.1" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.3.cmml">D</mi></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E2.m1.3.3.1.1.1.1.1.4" xref="S3.E2.m1.3.3.1.1.1.1.1.4.cmml">Ï</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.1.1.1.1.1.2a" xref="S3.E2.m1.3.3.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.3.cmml">r</mi></msub><mo id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml">s</mi></msub></mrow><mo stretchy="false" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.2"></eq><apply id="S3.E2.m1.3.3.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.3"><times id="S3.E2.m1.3.3.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3.1"></times><apply id="S3.E2.m1.3.3.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.3.2.1.cmml" xref="S3.E2.m1.3.3.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.3.2.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.2">ğ¸</ci><apply id="S3.E2.m1.3.3.1.1.3.2.3.cmml" xref="S3.E2.m1.3.3.1.1.3.2.3"><times id="S3.E2.m1.3.3.1.1.3.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3.2.3.1"></times><cn type="integer" id="S3.E2.m1.3.3.1.1.3.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.3.2.3.2">3</cn><ci id="S3.E2.m1.3.3.1.1.3.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.3.2.3.3">ğ·</ci></apply></apply><interval closure="open" id="S3.E2.m1.3.3.1.1.3.3.1.cmml" xref="S3.E2.m1.3.3.1.1.3.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğœƒ</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ğ›½</ci></interval></apply><apply id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"><apply id="S3.E2.m1.3.3.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.2">superscript</csymbol><apply id="S3.E2.m1.3.3.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.2.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S3.E2.m1.3.3.1.1.1.2.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2.2.2"></sum><apply id="S3.E2.m1.3.3.1.1.1.2.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.2.2.3"><eq id="S3.E2.m1.3.3.1.1.1.2.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.2.2.3.1"></eq><ci id="S3.E2.m1.3.3.1.1.1.2.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.2.2.3.2">ğ‘›</ci><cn type="integer" id="S3.E2.m1.3.3.1.1.1.2.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.3.3.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1"><apply id="S3.E2.m1.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S3.E2.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.2"></sum><apply id="S3.E2.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3"><in id="S3.E2.m1.3.3.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.1"></in><apply id="S3.E2.m1.3.3.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.2.3.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.2.3.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2.2">ğ‘¥</ci><ci id="S3.E2.m1.3.3.1.1.1.1.2.3.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.2.3">ğ‘Ÿ</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.2.3.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3">subscript</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3">superscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.2">ğ•</ci><ci id="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.2.3">ğ‘Ÿ</ci></apply><ci id="S3.E2.m1.3.3.1.1.1.1.2.3.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2.3.3.3">ğ‘›</ci></apply></apply></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1"><times id="S3.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.2"></times><apply id="S3.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E2.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.2">ğœ”</ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3"><times id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.1"></times><cn type="integer" id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.2">3</cn><ci id="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.2.3.3">ğ·</ci></apply></apply><ci id="S3.E2.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.3.3">ğ‘ </ci></apply><ci id="S3.E2.m1.3.3.1.1.1.1.1.4.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.4">ğœŒ</ci><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1"><minus id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.1.1.1.1.3.3">ğ‘ </ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">E_{3D}(\theta,\beta)=\sum_{n=1}^{N}\sum_{x_{r}\in\mathbb{V}^{r}_{n}}\omega^{3D}_{s}\rho(x_{r}-x_{s}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p3.9" class="ltx_p">with <math id="S3.SS3.p3.7.m1.1" class="ltx_Math" alttext="w^{3D}_{s}" display="inline"><semantics id="S3.SS3.p3.7.m1.1a"><msubsup id="S3.SS3.p3.7.m1.1.1" xref="S3.SS3.p3.7.m1.1.1.cmml"><mi id="S3.SS3.p3.7.m1.1.1.2.2" xref="S3.SS3.p3.7.m1.1.1.2.2.cmml">w</mi><mi id="S3.SS3.p3.7.m1.1.1.3" xref="S3.SS3.p3.7.m1.1.1.3.cmml">s</mi><mrow id="S3.SS3.p3.7.m1.1.1.2.3" xref="S3.SS3.p3.7.m1.1.1.2.3.cmml"><mn id="S3.SS3.p3.7.m1.1.1.2.3.2" xref="S3.SS3.p3.7.m1.1.1.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p3.7.m1.1.1.2.3.1" xref="S3.SS3.p3.7.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p3.7.m1.1.1.2.3.3" xref="S3.SS3.p3.7.m1.1.1.2.3.3.cmml">D</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m1.1b"><apply id="S3.SS3.p3.7.m1.1.1.cmml" xref="S3.SS3.p3.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m1.1.1.1.cmml" xref="S3.SS3.p3.7.m1.1.1">subscript</csymbol><apply id="S3.SS3.p3.7.m1.1.1.2.cmml" xref="S3.SS3.p3.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.7.m1.1.1.2.1.cmml" xref="S3.SS3.p3.7.m1.1.1">superscript</csymbol><ci id="S3.SS3.p3.7.m1.1.1.2.2.cmml" xref="S3.SS3.p3.7.m1.1.1.2.2">ğ‘¤</ci><apply id="S3.SS3.p3.7.m1.1.1.2.3.cmml" xref="S3.SS3.p3.7.m1.1.1.2.3"><times id="S3.SS3.p3.7.m1.1.1.2.3.1.cmml" xref="S3.SS3.p3.7.m1.1.1.2.3.1"></times><cn type="integer" id="S3.SS3.p3.7.m1.1.1.2.3.2.cmml" xref="S3.SS3.p3.7.m1.1.1.2.3.2">3</cn><ci id="S3.SS3.p3.7.m1.1.1.2.3.3.cmml" xref="S3.SS3.p3.7.m1.1.1.2.3.3">ğ·</ci></apply></apply><ci id="S3.SS3.p3.7.m1.1.1.3.cmml" xref="S3.SS3.p3.7.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m1.1c">w^{3D}_{s}</annotation></semantics></math> which weights the contribution of each point <math id="S3.SS3.p3.8.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS3.p3.8.m2.1a"><mi id="S3.SS3.p3.8.m2.1.1" xref="S3.SS3.p3.8.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m2.1b"><ci id="S3.SS3.p3.8.m2.1.1.cmml" xref="S3.SS3.p3.8.m2.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m2.1c">s</annotation></semantics></math> depending on the number of times it was associated and <math id="S3.SS3.p3.9.m3.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="S3.SS3.p3.9.m3.1a"><mi id="S3.SS3.p3.9.m3.1.1" xref="S3.SS3.p3.9.m3.1.1.cmml">Ï</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m3.1b"><ci id="S3.SS3.p3.9.m3.1.1.cmml" xref="S3.SS3.p3.9.m3.1.1">ğœŒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m3.1c">\rho</annotation></semantics></math> the Geman-McClure penalty functionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> that has shown robustness with noisy estimates.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.3" class="ltx_p"><span id="S3.SS3.p4.3.1" class="ltx_text ltx_font_bold">2D Data term.</span>
Because the 3D point cloud is not complete and often noisy, we devise a reprojection error loss based on DensePose UV coordinates.
These coordinates map vertices of the SMPL model to pixels in the image.
For every pixel in the mask <math id="S3.SS3.p4.1.m1.1" class="ltx_Math" alttext="p\in M" display="inline"><semantics id="S3.SS3.p4.1.m1.1a"><mrow id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">p</mi><mo id="S3.SS3.p4.1.m1.1.1.1" xref="S3.SS3.p4.1.m1.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><in id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1.1"></in><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">p\in M</annotation></semantics></math>, we project the associated <math id="S3.SS3.p4.2.m2.1" class="ltx_Math" alttext="3D" display="inline"><semantics id="S3.SS3.p4.2.m2.1a"><mrow id="S3.SS3.p4.2.m2.1.1" xref="S3.SS3.p4.2.m2.1.1.cmml"><mn id="S3.SS3.p4.2.m2.1.1.2" xref="S3.SS3.p4.2.m2.1.1.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p4.2.m2.1.1.1" xref="S3.SS3.p4.2.m2.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p4.2.m2.1.1.3" xref="S3.SS3.p4.2.m2.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.2.m2.1b"><apply id="S3.SS3.p4.2.m2.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1"><times id="S3.SS3.p4.2.m2.1.1.1.cmml" xref="S3.SS3.p4.2.m2.1.1.1"></times><cn type="integer" id="S3.SS3.p4.2.m2.1.1.2.cmml" xref="S3.SS3.p4.2.m2.1.1.2">3</cn><ci id="S3.SS3.p4.2.m2.1.1.3.cmml" xref="S3.SS3.p4.2.m2.1.1.3">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.2.m2.1c">3D</annotation></semantics></math> SMPL point and penalize the distance in the image plane, for every frame <math id="S3.SS3.p4.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p4.3.m3.1a"><mi id="S3.SS3.p4.3.m3.1.1" xref="S3.SS3.p4.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.3.m3.1b"><ci id="S3.SS3.p4.3.m3.1.1.cmml" xref="S3.SS3.p4.3.m3.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.3.m3.1c">n</annotation></semantics></math> of the track:</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.4" class="ltx_Math" alttext="E_{2D}(\theta,\beta)=\sum_{n=1}^{N}\sum_{p\in M}\omega^{2D}_{s}\rho(p-\pi_{n}(DP(p)))." display="block"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.4.1" xref="S3.E3.m1.4.4.1.1.cmml"><mrow id="S3.E3.m1.4.4.1.1" xref="S3.E3.m1.4.4.1.1.cmml"><mrow id="S3.E3.m1.4.4.1.1.3" xref="S3.E3.m1.4.4.1.1.3.cmml"><msub id="S3.E3.m1.4.4.1.1.3.2" xref="S3.E3.m1.4.4.1.1.3.2.cmml"><mi id="S3.E3.m1.4.4.1.1.3.2.2" xref="S3.E3.m1.4.4.1.1.3.2.2.cmml">E</mi><mrow id="S3.E3.m1.4.4.1.1.3.2.3" xref="S3.E3.m1.4.4.1.1.3.2.3.cmml"><mn id="S3.E3.m1.4.4.1.1.3.2.3.2" xref="S3.E3.m1.4.4.1.1.3.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.3.2.3.1" xref="S3.E3.m1.4.4.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.4.4.1.1.3.2.3.3" xref="S3.E3.m1.4.4.1.1.3.2.3.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.3.1" xref="S3.E3.m1.4.4.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.3.3.2" xref="S3.E3.m1.4.4.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.1.3.3.2.1" xref="S3.E3.m1.4.4.1.1.3.3.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">Î¸</mi><mo id="S3.E3.m1.4.4.1.1.3.3.2.2" xref="S3.E3.m1.4.4.1.1.3.3.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">Î²</mi><mo stretchy="false" id="S3.E3.m1.4.4.1.1.3.3.2.3" xref="S3.E3.m1.4.4.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E3.m1.4.4.1.1.2" xref="S3.E3.m1.4.4.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.4.4.1.1.1" xref="S3.E3.m1.4.4.1.1.1.cmml"><munderover id="S3.E3.m1.4.4.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E3.m1.4.4.1.1.1.2.2.2" xref="S3.E3.m1.4.4.1.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.4.4.1.1.1.2.2.3" xref="S3.E3.m1.4.4.1.1.1.2.2.3.cmml"><mi id="S3.E3.m1.4.4.1.1.1.2.2.3.2" xref="S3.E3.m1.4.4.1.1.1.2.2.3.2.cmml">n</mi><mo id="S3.E3.m1.4.4.1.1.1.2.2.3.1" xref="S3.E3.m1.4.4.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E3.m1.4.4.1.1.1.2.2.3.3" xref="S3.E3.m1.4.4.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.4.4.1.1.1.2.3" xref="S3.E3.m1.4.4.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E3.m1.4.4.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.cmml"><munder id="S3.E3.m1.4.4.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E3.m1.4.4.1.1.1.1.2.2" xref="S3.E3.m1.4.4.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.2.3" xref="S3.E3.m1.4.4.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.2.3.2" xref="S3.E3.m1.4.4.1.1.1.1.2.3.2.cmml">p</mi><mo id="S3.E3.m1.4.4.1.1.1.1.2.3.1" xref="S3.E3.m1.4.4.1.1.1.1.2.3.1.cmml">âˆˆ</mo><mi id="S3.E3.m1.4.4.1.1.1.1.2.3.3" xref="S3.E3.m1.4.4.1.1.1.1.2.3.3.cmml">M</mi></mrow></munder><mrow id="S3.E3.m1.4.4.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.cmml"><msubsup id="S3.E3.m1.4.4.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.3.2.2" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.2.cmml">Ï‰</mi><mi id="S3.E3.m1.4.4.1.1.1.1.1.3.3" xref="S3.E3.m1.4.4.1.1.1.1.1.3.3.cmml">s</mi><mrow id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.cmml"><mn id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.2" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.1" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.3" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.3.cmml">D</mi></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E3.m1.4.4.1.1.1.1.1.4" xref="S3.E3.m1.4.4.1.1.1.1.1.4.cmml">Ï</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.2a" xref="S3.E3.m1.4.4.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">p</mi><mo id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml">Ï€</mi><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.4.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.4.2.1" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml">p</mi><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.4.2.2" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.3" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E3.m1.4.4.1.2" xref="S3.E3.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.4.1.1.cmml" xref="S3.E3.m1.4.4.1"><eq id="S3.E3.m1.4.4.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.2"></eq><apply id="S3.E3.m1.4.4.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.3"><times id="S3.E3.m1.4.4.1.1.3.1.cmml" xref="S3.E3.m1.4.4.1.1.3.1"></times><apply id="S3.E3.m1.4.4.1.1.3.2.cmml" xref="S3.E3.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.3.2.1.cmml" xref="S3.E3.m1.4.4.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.3.2.2.cmml" xref="S3.E3.m1.4.4.1.1.3.2.2">ğ¸</ci><apply id="S3.E3.m1.4.4.1.1.3.2.3.cmml" xref="S3.E3.m1.4.4.1.1.3.2.3"><times id="S3.E3.m1.4.4.1.1.3.2.3.1.cmml" xref="S3.E3.m1.4.4.1.1.3.2.3.1"></times><cn type="integer" id="S3.E3.m1.4.4.1.1.3.2.3.2.cmml" xref="S3.E3.m1.4.4.1.1.3.2.3.2">2</cn><ci id="S3.E3.m1.4.4.1.1.3.2.3.3.cmml" xref="S3.E3.m1.4.4.1.1.3.2.3.3">ğ·</ci></apply></apply><interval closure="open" id="S3.E3.m1.4.4.1.1.3.3.1.cmml" xref="S3.E3.m1.4.4.1.1.3.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğœƒ</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">ğ›½</ci></interval></apply><apply id="S3.E3.m1.4.4.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1"><apply id="S3.E3.m1.4.4.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.2">superscript</csymbol><apply id="S3.E3.m1.4.4.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.2.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.4.4.1.1.1.2.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.2.2.2"></sum><apply id="S3.E3.m1.4.4.1.1.1.2.2.3.cmml" xref="S3.E3.m1.4.4.1.1.1.2.2.3"><eq id="S3.E3.m1.4.4.1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.4.4.1.1.1.2.2.3.1"></eq><ci id="S3.E3.m1.4.4.1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.4.4.1.1.1.2.2.3.2">ğ‘›</ci><cn type="integer" id="S3.E3.m1.4.4.1.1.1.2.2.3.3.cmml" xref="S3.E3.m1.4.4.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.4.4.1.1.1.2.3.cmml" xref="S3.E3.m1.4.4.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.E3.m1.4.4.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1"><apply id="S3.E3.m1.4.4.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.4.4.1.1.1.1.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.2"></sum><apply id="S3.E3.m1.4.4.1.1.1.1.2.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.3"><in id="S3.E3.m1.4.4.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.3.1"></in><ci id="S3.E3.m1.4.4.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.3.2">ğ‘</ci><ci id="S3.E3.m1.4.4.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.2.3.3">ğ‘€</ci></apply></apply><apply id="S3.E3.m1.4.4.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1"><times id="S3.E3.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.2"></times><apply id="S3.E3.m1.4.4.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3">subscript</csymbol><apply id="S3.E3.m1.4.4.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.3.2.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.4.4.1.1.1.1.1.3.2.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.2">ğœ”</ci><apply id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3"><times id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.1"></times><cn type="integer" id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.2">2</cn><ci id="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3.2.3.3">ğ·</ci></apply></apply><ci id="S3.E3.m1.4.4.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.3.3">ğ‘ </ci></apply><ci id="S3.E3.m1.4.4.1.1.1.1.1.4.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.4">ğœŒ</ci><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1"><minus id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.2"></minus><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.3">ğ‘</ci><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.2">ğœ‹</ci><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3">ğ‘›</ci></apply><apply id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ·</ci><ci id="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘ƒ</ci><ci id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.3.3">ğ‘</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">E_{2D}(\theta,\beta)=\sum_{n=1}^{N}\sum_{p\in M}\omega^{2D}_{s}\rho(p-\pi_{n}(DP(p))).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.2" class="ltx_p">Both weights <math id="S3.SS3.p6.1.m1.1" class="ltx_Math" alttext="w^{2D}_{s}" display="inline"><semantics id="S3.SS3.p6.1.m1.1a"><msubsup id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mi id="S3.SS3.p6.1.m1.1.1.2.2" xref="S3.SS3.p6.1.m1.1.1.2.2.cmml">w</mi><mi id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml">s</mi><mrow id="S3.SS3.p6.1.m1.1.1.2.3" xref="S3.SS3.p6.1.m1.1.1.2.3.cmml"><mn id="S3.SS3.p6.1.m1.1.1.2.3.2" xref="S3.SS3.p6.1.m1.1.1.2.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p6.1.m1.1.1.2.3.1" xref="S3.SS3.p6.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p6.1.m1.1.1.2.3.3" xref="S3.SS3.p6.1.m1.1.1.2.3.3.cmml">D</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">subscript</csymbol><apply id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.2.1.cmml" xref="S3.SS3.p6.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2.2">ğ‘¤</ci><apply id="S3.SS3.p6.1.m1.1.1.2.3.cmml" xref="S3.SS3.p6.1.m1.1.1.2.3"><times id="S3.SS3.p6.1.m1.1.1.2.3.1.cmml" xref="S3.SS3.p6.1.m1.1.1.2.3.1"></times><cn type="integer" id="S3.SS3.p6.1.m1.1.1.2.3.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2.3.2">2</cn><ci id="S3.SS3.p6.1.m1.1.1.2.3.3.cmml" xref="S3.SS3.p6.1.m1.1.1.2.3.3">ğ·</ci></apply></apply><ci id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">w^{2D}_{s}</annotation></semantics></math> and <math id="S3.SS3.p6.2.m2.1" class="ltx_Math" alttext="\omega^{3D}_{s}" display="inline"><semantics id="S3.SS3.p6.2.m2.1a"><msubsup id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml"><mi id="S3.SS3.p6.2.m2.1.1.2.2" xref="S3.SS3.p6.2.m2.1.1.2.2.cmml">Ï‰</mi><mi id="S3.SS3.p6.2.m2.1.1.3" xref="S3.SS3.p6.2.m2.1.1.3.cmml">s</mi><mrow id="S3.SS3.p6.2.m2.1.1.2.3" xref="S3.SS3.p6.2.m2.1.1.2.3.cmml"><mn id="S3.SS3.p6.2.m2.1.1.2.3.2" xref="S3.SS3.p6.2.m2.1.1.2.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p6.2.m2.1.1.2.3.1" xref="S3.SS3.p6.2.m2.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS3.p6.2.m2.1.1.2.3.3" xref="S3.SS3.p6.2.m2.1.1.2.3.3.cmml">D</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><apply id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.2.m2.1.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">subscript</csymbol><apply id="S3.SS3.p6.2.m2.1.1.2.cmml" xref="S3.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.2.m2.1.1.2.1.cmml" xref="S3.SS3.p6.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p6.2.m2.1.1.2.2.cmml" xref="S3.SS3.p6.2.m2.1.1.2.2">ğœ”</ci><apply id="S3.SS3.p6.2.m2.1.1.2.3.cmml" xref="S3.SS3.p6.2.m2.1.1.2.3"><times id="S3.SS3.p6.2.m2.1.1.2.3.1.cmml" xref="S3.SS3.p6.2.m2.1.1.2.3.1"></times><cn type="integer" id="S3.SS3.p6.2.m2.1.1.2.3.2.cmml" xref="S3.SS3.p6.2.m2.1.1.2.3.2">3</cn><ci id="S3.SS3.p6.2.m2.1.1.2.3.3.cmml" xref="S3.SS3.p6.2.m2.1.1.2.3.3">ğ·</ci></apply></apply><ci id="S3.SS3.p6.2.m2.1.1.3.cmml" xref="S3.SS3.p6.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">\omega^{3D}_{s}</annotation></semantics></math> mean that model points that were respectively not often observed nor associated will only marginally impact the optimization. These weights are respectively normalized by the total number of appearances or associations and both by the number of frames in the track.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">The remaining terms are used as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and briefly explained for completenessâ€™ sake:</p>
</div>
<div id="S3.SS3.p8" class="ltx_para ltx_noindent">
<p id="S3.SS3.p8.1" class="ltx_p"><span id="S3.SS3.p8.1.1" class="ltx_text ltx_font_bold">Exponential pose regularization.</span>
We use a pose prior penalizing elbows and knees that bend unnaturally in the form of an exponential penalty:</p>
</div>
<div id="S3.SS3.p9" class="ltx_para">
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="E_{epose}(\theta)=\sum_{i}\exp(\theta_{i})." display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1" xref="S3.E4.m1.3.3.1.1.cmml"><mrow id="S3.E4.m1.3.3.1.1.3" xref="S3.E4.m1.3.3.1.1.3.cmml"><msub id="S3.E4.m1.3.3.1.1.3.2" xref="S3.E4.m1.3.3.1.1.3.2.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.2" xref="S3.E4.m1.3.3.1.1.3.2.2.cmml">E</mi><mrow id="S3.E4.m1.3.3.1.1.3.2.3" xref="S3.E4.m1.3.3.1.1.3.2.3.cmml"><mi id="S3.E4.m1.3.3.1.1.3.2.3.2" xref="S3.E4.m1.3.3.1.1.3.2.3.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.1" xref="S3.E4.m1.3.3.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.3.2.3.3" xref="S3.E4.m1.3.3.1.1.3.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.1a" xref="S3.E4.m1.3.3.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.3.2.3.4" xref="S3.E4.m1.3.3.1.1.3.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.1b" xref="S3.E4.m1.3.3.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.3.2.3.5" xref="S3.E4.m1.3.3.1.1.3.2.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.2.3.1c" xref="S3.E4.m1.3.3.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.1.1.3.2.3.6" xref="S3.E4.m1.3.3.1.1.3.2.3.6.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.1.3.1" xref="S3.E4.m1.3.3.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E4.m1.3.3.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.3.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.3.2.1" xref="S3.E4.m1.3.3.1.1.3.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">Î¸</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.3.3.2.2" xref="S3.E4.m1.3.3.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E4.m1.3.3.1.1.2" xref="S3.E4.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.1.1.cmml"><munder id="S3.E4.m1.3.3.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E4.m1.3.3.1.1.1.2.2" xref="S3.E4.m1.3.3.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.E4.m1.3.3.1.1.1.2.3" xref="S3.E4.m1.3.3.1.1.1.2.3.cmml">i</mi></munder><mrow id="S3.E4.m1.3.3.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml"><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">exp</mi><mo id="S3.E4.m1.3.3.1.1.1.1.1a" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">â¡</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">(</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml">Î¸</mi><mi id="S3.E4.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.1.1.cmml" xref="S3.E4.m1.3.3.1"><eq id="S3.E4.m1.3.3.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.2"></eq><apply id="S3.E4.m1.3.3.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.3"><times id="S3.E4.m1.3.3.1.1.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.1"></times><apply id="S3.E4.m1.3.3.1.1.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.3.2.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.3.2.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.2">ğ¸</ci><apply id="S3.E4.m1.3.3.1.1.3.2.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3"><times id="S3.E4.m1.3.3.1.1.3.2.3.1.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.1"></times><ci id="S3.E4.m1.3.3.1.1.3.2.3.2.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.2">ğ‘’</ci><ci id="S3.E4.m1.3.3.1.1.3.2.3.3.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.3">ğ‘</ci><ci id="S3.E4.m1.3.3.1.1.3.2.3.4.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.4">ğ‘œ</ci><ci id="S3.E4.m1.3.3.1.1.3.2.3.5.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.5">ğ‘ </ci><ci id="S3.E4.m1.3.3.1.1.3.2.3.6.cmml" xref="S3.E4.m1.3.3.1.1.3.2.3.6">ğ‘’</ci></apply></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">ğœƒ</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1"><apply id="S3.E4.m1.3.3.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S3.E4.m1.3.3.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.2.2"></sum><ci id="S3.E4.m1.3.3.1.1.1.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1"><exp id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"></exp><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.2">ğœƒ</ci><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">E_{epose}(\theta)=\sum_{i}\exp(\theta_{i}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p10" class="ltx_para ltx_noindent">
<p id="S3.SS3.p10.1" class="ltx_p"><span id="S3.SS3.p10.1.1" class="ltx_text ltx_font_bold">Gaussian Mixture Model.</span>
We penalize non-plausible poses using the prior ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>:</p>
</div>
<div id="S3.SS3.p11" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.8" class="ltx_Math" alttext="E_{mpose}(\theta)=\min_{j}(-\log(g_{j}\mathcal{N}(\theta;\mu_{\theta,j},\Sigma_{\theta,j})))," display="block"><semantics id="S3.E5.m1.8a"><mrow id="S3.E5.m1.8.8.1" xref="S3.E5.m1.8.8.1.1.cmml"><mrow id="S3.E5.m1.8.8.1.1" xref="S3.E5.m1.8.8.1.1.cmml"><mrow id="S3.E5.m1.8.8.1.1.4" xref="S3.E5.m1.8.8.1.1.4.cmml"><msub id="S3.E5.m1.8.8.1.1.4.2" xref="S3.E5.m1.8.8.1.1.4.2.cmml"><mi id="S3.E5.m1.8.8.1.1.4.2.2" xref="S3.E5.m1.8.8.1.1.4.2.2.cmml">E</mi><mrow id="S3.E5.m1.8.8.1.1.4.2.3" xref="S3.E5.m1.8.8.1.1.4.2.3.cmml"><mi id="S3.E5.m1.8.8.1.1.4.2.3.2" xref="S3.E5.m1.8.8.1.1.4.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.4.2.3.1" xref="S3.E5.m1.8.8.1.1.4.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.8.8.1.1.4.2.3.3" xref="S3.E5.m1.8.8.1.1.4.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.4.2.3.1a" xref="S3.E5.m1.8.8.1.1.4.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.8.8.1.1.4.2.3.4" xref="S3.E5.m1.8.8.1.1.4.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.4.2.3.1b" xref="S3.E5.m1.8.8.1.1.4.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.8.8.1.1.4.2.3.5" xref="S3.E5.m1.8.8.1.1.4.2.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.4.2.3.1c" xref="S3.E5.m1.8.8.1.1.4.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.8.8.1.1.4.2.3.6" xref="S3.E5.m1.8.8.1.1.4.2.3.6.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.4.1" xref="S3.E5.m1.8.8.1.1.4.1.cmml">â€‹</mo><mrow id="S3.E5.m1.8.8.1.1.4.3.2" xref="S3.E5.m1.8.8.1.1.4.cmml"><mo stretchy="false" id="S3.E5.m1.8.8.1.1.4.3.2.1" xref="S3.E5.m1.8.8.1.1.4.cmml">(</mo><mi id="S3.E5.m1.5.5" xref="S3.E5.m1.5.5.cmml">Î¸</mi><mo stretchy="false" id="S3.E5.m1.8.8.1.1.4.3.2.2" xref="S3.E5.m1.8.8.1.1.4.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.8.8.1.1.3" xref="S3.E5.m1.8.8.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.8.8.1.1.2.2" xref="S3.E5.m1.8.8.1.1.2.3.cmml"><munder id="S3.E5.m1.8.8.1.1.1.1.1" xref="S3.E5.m1.8.8.1.1.1.1.1.cmml"><mi id="S3.E5.m1.8.8.1.1.1.1.1.2" xref="S3.E5.m1.8.8.1.1.1.1.1.2.cmml">min</mi><mi id="S3.E5.m1.8.8.1.1.1.1.1.3" xref="S3.E5.m1.8.8.1.1.1.1.1.3.cmml">j</mi></munder><mo id="S3.E5.m1.8.8.1.1.2.2a" xref="S3.E5.m1.8.8.1.1.2.3.cmml">â¡</mo><mrow id="S3.E5.m1.8.8.1.1.2.2.2" xref="S3.E5.m1.8.8.1.1.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.8.8.1.1.2.2.2.2" xref="S3.E5.m1.8.8.1.1.2.3.cmml">(</mo><mrow id="S3.E5.m1.8.8.1.1.2.2.2.1" xref="S3.E5.m1.8.8.1.1.2.2.2.1.cmml"><mo rspace="0.167em" id="S3.E5.m1.8.8.1.1.2.2.2.1a" xref="S3.E5.m1.8.8.1.1.2.2.2.1.cmml">âˆ’</mo><mrow id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.2.cmml"><mi id="S3.E5.m1.7.7" xref="S3.E5.m1.7.7.cmml">log</mi><mo id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1a" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.2.cmml">â¡</mo><mrow id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.2" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.2.cmml">(</mo><mrow id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.cmml"><msub id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.cmml"><mi id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.2" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.2.cmml">g</mi><mi id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.3" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.3" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.3.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.5" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.5.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.3a" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.3.cmml">â€‹</mo><mrow id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.3" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.3.cmml">(</mo><mi id="S3.E5.m1.6.6" xref="S3.E5.m1.6.6.cmml">Î¸</mi><mo id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.4" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.3.cmml">;</mo><msub id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.2.cmml">Î¼</mi><mrow id="S3.E5.m1.2.2.2.4" xref="S3.E5.m1.2.2.2.3.cmml"><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">Î¸</mi><mo id="S3.E5.m1.2.2.2.4.1" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><mi id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.5" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.cmml"><mi mathvariant="normal" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.2" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.2.cmml">Î£</mi><mrow id="S3.E5.m1.4.4.2.4" xref="S3.E5.m1.4.4.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml">Î¸</mi><mo id="S3.E5.m1.4.4.2.4.1" xref="S3.E5.m1.4.4.2.3.cmml">,</mo><mi id="S3.E5.m1.4.4.2.2" xref="S3.E5.m1.4.4.2.2.cmml">j</mi></mrow></msub><mo stretchy="false" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.6" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.3" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E5.m1.8.8.1.1.2.2.2.3" xref="S3.E5.m1.8.8.1.1.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.8.8.1.2" xref="S3.E5.m1.8.8.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.8b"><apply id="S3.E5.m1.8.8.1.1.cmml" xref="S3.E5.m1.8.8.1"><eq id="S3.E5.m1.8.8.1.1.3.cmml" xref="S3.E5.m1.8.8.1.1.3"></eq><apply id="S3.E5.m1.8.8.1.1.4.cmml" xref="S3.E5.m1.8.8.1.1.4"><times id="S3.E5.m1.8.8.1.1.4.1.cmml" xref="S3.E5.m1.8.8.1.1.4.1"></times><apply id="S3.E5.m1.8.8.1.1.4.2.cmml" xref="S3.E5.m1.8.8.1.1.4.2"><csymbol cd="ambiguous" id="S3.E5.m1.8.8.1.1.4.2.1.cmml" xref="S3.E5.m1.8.8.1.1.4.2">subscript</csymbol><ci id="S3.E5.m1.8.8.1.1.4.2.2.cmml" xref="S3.E5.m1.8.8.1.1.4.2.2">ğ¸</ci><apply id="S3.E5.m1.8.8.1.1.4.2.3.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3"><times id="S3.E5.m1.8.8.1.1.4.2.3.1.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3.1"></times><ci id="S3.E5.m1.8.8.1.1.4.2.3.2.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3.2">ğ‘š</ci><ci id="S3.E5.m1.8.8.1.1.4.2.3.3.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3.3">ğ‘</ci><ci id="S3.E5.m1.8.8.1.1.4.2.3.4.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3.4">ğ‘œ</ci><ci id="S3.E5.m1.8.8.1.1.4.2.3.5.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3.5">ğ‘ </ci><ci id="S3.E5.m1.8.8.1.1.4.2.3.6.cmml" xref="S3.E5.m1.8.8.1.1.4.2.3.6">ğ‘’</ci></apply></apply><ci id="S3.E5.m1.5.5.cmml" xref="S3.E5.m1.5.5">ğœƒ</ci></apply><apply id="S3.E5.m1.8.8.1.1.2.3.cmml" xref="S3.E5.m1.8.8.1.1.2.2"><apply id="S3.E5.m1.8.8.1.1.1.1.1.cmml" xref="S3.E5.m1.8.8.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.8.8.1.1.1.1.1.1.cmml" xref="S3.E5.m1.8.8.1.1.1.1.1">subscript</csymbol><min id="S3.E5.m1.8.8.1.1.1.1.1.2.cmml" xref="S3.E5.m1.8.8.1.1.1.1.1.2"></min><ci id="S3.E5.m1.8.8.1.1.1.1.1.3.cmml" xref="S3.E5.m1.8.8.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.E5.m1.8.8.1.1.2.2.2.1.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1"><minus id="S3.E5.m1.8.8.1.1.2.2.2.1.2.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1"></minus><apply id="S3.E5.m1.8.8.1.1.2.2.2.1.1.2.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1"><log id="S3.E5.m1.7.7.cmml" xref="S3.E5.m1.7.7"></log><apply id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1"><times id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.3"></times><apply id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.1.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.2.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.2">ğ‘”</ci><ci id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.3.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.4.3">ğ‘—</ci></apply><ci id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.5.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.5">ğ’©</ci><list id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2"><ci id="S3.E5.m1.6.6.cmml" xref="S3.E5.m1.6.6">ğœƒ</ci><apply id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.1.1.1.2">ğœ‡</ci><list id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.4"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">ğœƒ</ci><ci id="S3.E5.m1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.8.8.1.1.2.2.2.1.1.1.1.1.2.2.2.2">Î£</ci><list id="S3.E5.m1.4.4.2.3.cmml" xref="S3.E5.m1.4.4.2.4"><ci id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1">ğœƒ</ci><ci id="S3.E5.m1.4.4.2.2.cmml" xref="S3.E5.m1.4.4.2.2">ğ‘—</ci></list></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.8c">E_{mpose}(\theta)=\min_{j}(-\log(g_{j}\mathcal{N}(\theta;\mu_{\theta,j},\Sigma_{\theta,j}))),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p11.1" class="ltx_p">with <math id="S3.SS3.p11.1.m1.1" class="ltx_Math" alttext="g_{j}" display="inline"><semantics id="S3.SS3.p11.1.m1.1a"><msub id="S3.SS3.p11.1.m1.1.1" xref="S3.SS3.p11.1.m1.1.1.cmml"><mi id="S3.SS3.p11.1.m1.1.1.2" xref="S3.SS3.p11.1.m1.1.1.2.cmml">g</mi><mi id="S3.SS3.p11.1.m1.1.1.3" xref="S3.SS3.p11.1.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p11.1.m1.1b"><apply id="S3.SS3.p11.1.m1.1.1.cmml" xref="S3.SS3.p11.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p11.1.m1.1.1.1.cmml" xref="S3.SS3.p11.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p11.1.m1.1.1.2.cmml" xref="S3.SS3.p11.1.m1.1.1.2">ğ‘”</ci><ci id="S3.SS3.p11.1.m1.1.1.3.cmml" xref="S3.SS3.p11.1.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p11.1.m1.1c">g_{j}</annotation></semantics></math> the mixture model weights.</p>
</div>
<div id="S3.SS3.p12" class="ltx_para ltx_noindent">
<p id="S3.SS3.p12.1" class="ltx_p"><span id="S3.SS3.p12.1.1" class="ltx_text ltx_font_bold">Shape.</span>
We add a regularization term on possible body shapes based on Principal Component Analysis of the SMPL training set:</p>
</div>
<div id="S3.SS3.p13" class="ltx_para">
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.2" class="ltx_Math" alttext="E_{shape}(\beta)=\beta^{T}\Sigma_{\beta}^{-1}\beta," display="block"><semantics id="S3.E6.m1.2a"><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1" xref="S3.E6.m1.2.2.1.1.cmml"><mrow id="S3.E6.m1.2.2.1.1.2" xref="S3.E6.m1.2.2.1.1.2.cmml"><msub id="S3.E6.m1.2.2.1.1.2.2" xref="S3.E6.m1.2.2.1.1.2.2.cmml"><mi id="S3.E6.m1.2.2.1.1.2.2.2" xref="S3.E6.m1.2.2.1.1.2.2.2.cmml">E</mi><mrow id="S3.E6.m1.2.2.1.1.2.2.3" xref="S3.E6.m1.2.2.1.1.2.2.3.cmml"><mi id="S3.E6.m1.2.2.1.1.2.2.3.2" xref="S3.E6.m1.2.2.1.1.2.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.2.2.3.1" xref="S3.E6.m1.2.2.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.1.1.2.2.3.3" xref="S3.E6.m1.2.2.1.1.2.2.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.2.2.3.1a" xref="S3.E6.m1.2.2.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.1.1.2.2.3.4" xref="S3.E6.m1.2.2.1.1.2.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.2.2.3.1b" xref="S3.E6.m1.2.2.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.1.1.2.2.3.5" xref="S3.E6.m1.2.2.1.1.2.2.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.2.2.3.1c" xref="S3.E6.m1.2.2.1.1.2.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.1.1.2.2.3.6" xref="S3.E6.m1.2.2.1.1.2.2.3.6.cmml">e</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.2.1" xref="S3.E6.m1.2.2.1.1.2.1.cmml">â€‹</mo><mrow id="S3.E6.m1.2.2.1.1.2.3.2" xref="S3.E6.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.2.2.1.1.2.3.2.1" xref="S3.E6.m1.2.2.1.1.2.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">Î²</mi><mo stretchy="false" id="S3.E6.m1.2.2.1.1.2.3.2.2" xref="S3.E6.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.2.2.1.1.1" xref="S3.E6.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.2.2.1.1.3" xref="S3.E6.m1.2.2.1.1.3.cmml"><msup id="S3.E6.m1.2.2.1.1.3.2" xref="S3.E6.m1.2.2.1.1.3.2.cmml"><mi id="S3.E6.m1.2.2.1.1.3.2.2" xref="S3.E6.m1.2.2.1.1.3.2.2.cmml">Î²</mi><mi id="S3.E6.m1.2.2.1.1.3.2.3" xref="S3.E6.m1.2.2.1.1.3.2.3.cmml">T</mi></msup><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.3.1" xref="S3.E6.m1.2.2.1.1.3.1.cmml">â€‹</mo><msubsup id="S3.E6.m1.2.2.1.1.3.3" xref="S3.E6.m1.2.2.1.1.3.3.cmml"><mi mathvariant="normal" id="S3.E6.m1.2.2.1.1.3.3.2.2" xref="S3.E6.m1.2.2.1.1.3.3.2.2.cmml">Î£</mi><mi id="S3.E6.m1.2.2.1.1.3.3.2.3" xref="S3.E6.m1.2.2.1.1.3.3.2.3.cmml">Î²</mi><mrow id="S3.E6.m1.2.2.1.1.3.3.3" xref="S3.E6.m1.2.2.1.1.3.3.3.cmml"><mo id="S3.E6.m1.2.2.1.1.3.3.3a" xref="S3.E6.m1.2.2.1.1.3.3.3.cmml">âˆ’</mo><mn id="S3.E6.m1.2.2.1.1.3.3.3.2" xref="S3.E6.m1.2.2.1.1.3.3.3.2.cmml">1</mn></mrow></msubsup><mo lspace="0em" rspace="0em" id="S3.E6.m1.2.2.1.1.3.1a" xref="S3.E6.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.2.2.1.1.3.4" xref="S3.E6.m1.2.2.1.1.3.4.cmml">Î²</mi></mrow></mrow><mo id="S3.E6.m1.2.2.1.2" xref="S3.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.2b"><apply id="S3.E6.m1.2.2.1.1.cmml" xref="S3.E6.m1.2.2.1"><eq id="S3.E6.m1.2.2.1.1.1.cmml" xref="S3.E6.m1.2.2.1.1.1"></eq><apply id="S3.E6.m1.2.2.1.1.2.cmml" xref="S3.E6.m1.2.2.1.1.2"><times id="S3.E6.m1.2.2.1.1.2.1.cmml" xref="S3.E6.m1.2.2.1.1.2.1"></times><apply id="S3.E6.m1.2.2.1.1.2.2.cmml" xref="S3.E6.m1.2.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.2.2.1.cmml" xref="S3.E6.m1.2.2.1.1.2.2">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.2.2.2.cmml" xref="S3.E6.m1.2.2.1.1.2.2.2">ğ¸</ci><apply id="S3.E6.m1.2.2.1.1.2.2.3.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3"><times id="S3.E6.m1.2.2.1.1.2.2.3.1.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3.1"></times><ci id="S3.E6.m1.2.2.1.1.2.2.3.2.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3.2">ğ‘ </ci><ci id="S3.E6.m1.2.2.1.1.2.2.3.3.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3.3">â„</ci><ci id="S3.E6.m1.2.2.1.1.2.2.3.4.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3.4">ğ‘</ci><ci id="S3.E6.m1.2.2.1.1.2.2.3.5.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3.5">ğ‘</ci><ci id="S3.E6.m1.2.2.1.1.2.2.3.6.cmml" xref="S3.E6.m1.2.2.1.1.2.2.3.6">ğ‘’</ci></apply></apply><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">ğ›½</ci></apply><apply id="S3.E6.m1.2.2.1.1.3.cmml" xref="S3.E6.m1.2.2.1.1.3"><times id="S3.E6.m1.2.2.1.1.3.1.cmml" xref="S3.E6.m1.2.2.1.1.3.1"></times><apply id="S3.E6.m1.2.2.1.1.3.2.cmml" xref="S3.E6.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.3.2.1.cmml" xref="S3.E6.m1.2.2.1.1.3.2">superscript</csymbol><ci id="S3.E6.m1.2.2.1.1.3.2.2.cmml" xref="S3.E6.m1.2.2.1.1.3.2.2">ğ›½</ci><ci id="S3.E6.m1.2.2.1.1.3.2.3.cmml" xref="S3.E6.m1.2.2.1.1.3.2.3">ğ‘‡</ci></apply><apply id="S3.E6.m1.2.2.1.1.3.3.cmml" xref="S3.E6.m1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.3.3.1.cmml" xref="S3.E6.m1.2.2.1.1.3.3">superscript</csymbol><apply id="S3.E6.m1.2.2.1.1.3.3.2.cmml" xref="S3.E6.m1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.1.1.3.3.2.1.cmml" xref="S3.E6.m1.2.2.1.1.3.3">subscript</csymbol><ci id="S3.E6.m1.2.2.1.1.3.3.2.2.cmml" xref="S3.E6.m1.2.2.1.1.3.3.2.2">Î£</ci><ci id="S3.E6.m1.2.2.1.1.3.3.2.3.cmml" xref="S3.E6.m1.2.2.1.1.3.3.2.3">ğ›½</ci></apply><apply id="S3.E6.m1.2.2.1.1.3.3.3.cmml" xref="S3.E6.m1.2.2.1.1.3.3.3"><minus id="S3.E6.m1.2.2.1.1.3.3.3.1.cmml" xref="S3.E6.m1.2.2.1.1.3.3.3"></minus><cn type="integer" id="S3.E6.m1.2.2.1.1.3.3.3.2.cmml" xref="S3.E6.m1.2.2.1.1.3.3.3.2">1</cn></apply></apply><ci id="S3.E6.m1.2.2.1.1.3.4.cmml" xref="S3.E6.m1.2.2.1.1.3.4">ğ›½</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.2c">E_{shape}(\beta)=\beta^{T}\Sigma_{\beta}^{-1}\beta,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p13.1" class="ltx_p">where <math id="S3.SS3.p13.1.m1.1" class="ltx_Math" alttext="\Sigma_{\beta}^{-1}" display="inline"><semantics id="S3.SS3.p13.1.m1.1a"><msubsup id="S3.SS3.p13.1.m1.1.1" xref="S3.SS3.p13.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p13.1.m1.1.1.2.2" xref="S3.SS3.p13.1.m1.1.1.2.2.cmml">Î£</mi><mi id="S3.SS3.p13.1.m1.1.1.2.3" xref="S3.SS3.p13.1.m1.1.1.2.3.cmml">Î²</mi><mrow id="S3.SS3.p13.1.m1.1.1.3" xref="S3.SS3.p13.1.m1.1.1.3.cmml"><mo id="S3.SS3.p13.1.m1.1.1.3a" xref="S3.SS3.p13.1.m1.1.1.3.cmml">âˆ’</mo><mn id="S3.SS3.p13.1.m1.1.1.3.2" xref="S3.SS3.p13.1.m1.1.1.3.2.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.p13.1.m1.1b"><apply id="S3.SS3.p13.1.m1.1.1.cmml" xref="S3.SS3.p13.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p13.1.m1.1.1.1.cmml" xref="S3.SS3.p13.1.m1.1.1">superscript</csymbol><apply id="S3.SS3.p13.1.m1.1.1.2.cmml" xref="S3.SS3.p13.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p13.1.m1.1.1.2.1.cmml" xref="S3.SS3.p13.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p13.1.m1.1.1.2.2.cmml" xref="S3.SS3.p13.1.m1.1.1.2.2">Î£</ci><ci id="S3.SS3.p13.1.m1.1.1.2.3.cmml" xref="S3.SS3.p13.1.m1.1.1.2.3">ğ›½</ci></apply><apply id="S3.SS3.p13.1.m1.1.1.3.cmml" xref="S3.SS3.p13.1.m1.1.1.3"><minus id="S3.SS3.p13.1.m1.1.1.3.1.cmml" xref="S3.SS3.p13.1.m1.1.1.3"></minus><cn type="integer" id="S3.SS3.p13.1.m1.1.1.3.2.cmml" xref="S3.SS3.p13.1.m1.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p13.1.m1.1c">\Sigma_{\beta}^{-1}</annotation></semantics></math> is a diagonal matrix with the squared singular values estimated via Principal Component Analysis from the shapes in the SMPL training set.</p>
</div>
<div id="S3.SS3.p14" class="ltx_para">
<p id="S3.SS3.p14.1" class="ltx_p">It is worth mentioning that we also tried to constrain the problem using a 2D joints detector (OpenPose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>) and adding another 2D reprojection error term on the joints like Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Unfortunately, this did not yield enough robustness in our scenario. Because of the small variations in the the detected joint locations, the triangulated 3D points often fell far away from the real objective. We illustrate this in the supplementary material by showing that using a denser representation is less prone to errors and overall more robust to noise.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Post Processing</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The obtained poses can be quite noisy in some cases and the optimization often diverges for various reasons.
Such reasons could be that DensePose UV coordinates are not consistent along a sequence, tracking fails or 3D points are wrongly associated to model vertices.
To tackle these, we devised three post-processing steps in order to keep only successfully reconstructed humans from the sequences: reprojection check, visibility check and manual verification.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS4.p2.1" class="ltx_p"><span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_bold">Reprojection check.</span> This is a simple automatic reprojection error verification step.
Estimated poses are kept only if the residual reprojection error is below a restrictive threshold. This excludes most of the erroneous estimated poses of the dataset.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para ltx_noindent">
<p id="S3.SS4.p3.1" class="ltx_p"><span id="S3.SS4.p3.1.1" class="ltx_text ltx_font_bold">Visibility Check.</span> Many humans are not correctly observed in a sequence, <em id="S3.SS4.p3.1.2" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S3.SS4.p3.1.3" class="ltx_text"></span> only a single limb is visible. In order to discard such examples, we compute jointsâ€™ sequence-wise visibility: a joint is considered to be visible in the sequence if it reprojects inside a valid body part of DensePose <math id="S3.SS4.p3.1.m1.1" class="ltx_Math" alttext="80" display="inline"><semantics id="S3.SS4.p3.1.m1.1a"><mn id="S3.SS4.p3.1.m1.1.1" xref="S3.SS4.p3.1.m1.1.1.cmml">80</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p3.1.m1.1b"><cn type="integer" id="S3.SS4.p3.1.m1.1.1.cmml" xref="S3.SS4.p3.1.m1.1.1">80</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p3.1.m1.1c">80</annotation></semantics></math> percent of the time. We only keep models with at least half the torso and one limb visible. The selected models are equipped with this visibility information for evaluation.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para ltx_noindent">
<p id="S3.SS4.p4.2" class="ltx_p"><span id="S3.SS4.p4.2.1" class="ltx_text ltx_font_bold">Human Verification.</span> Finally, we perform a manual check.
A human annotator visualizes (a) the 3D SMPL model with its joints visibility along with the 3D reconstruction, and (b) the rendered model on a few images in the track.
This way, the annotator can discard samples that are inaccurate, either far from the reconstruction, with an invalid reprojection on the images or not corresponding to the reality.
This inspection takes less than a minute per instance. A single annotator can check more than <math id="S3.SS4.p4.1.m1.1" class="ltx_Math" alttext="600" display="inline"><semantics id="S3.SS4.p4.1.m1.1a"><mn id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.1b"><cn type="integer" id="S3.SS4.p4.1.m1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.1c">600</annotation></semantics></math> instances in <math id="S3.SS4.p4.2.m2.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S3.SS4.p4.2.m2.1a"><mn id="S3.SS4.p4.2.m2.1.1" xref="S3.SS4.p4.2.m2.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.2.m2.1b"><cn type="integer" id="S3.SS4.p4.2.m2.1.1.cmml" xref="S3.SS4.p4.2.m2.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.2.m2.1c">7</annotation></semantics></math> hours.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Validation of the method</h2>

<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2012.02743/assets/Figures/1582122481_464_color.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="180" height="135" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2012.02743/assets/Figures/dm_464.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="180" height="138" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2012.02743/assets/Figures/GT_render_464.png" id="S4.F3.sf3.g1" class="ltx_graphics ltx_img_landscape" width="180" height="135" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span> Example of captured validation sequence. <span id="S4.F3.4.1" class="ltx_text ltx_font_italic">Left:</span> RGB image. <span id="S4.F3.5.2" class="ltx_text ltx_font_italic">Middle:</span> Associated depth map. <span id="S4.F3.6.3" class="ltx_text ltx_font_italic">Right:</span> Estimated pose using RGB information only. More examples can be found in the supplementary material.</figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To evaluate the accuracy of the proposed pipeline, we captured a dataset using an off-the-shelf Ipad Pro 11Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, with a Structure depth sensorÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> attached to it, providing dense ground-truth 3D measurements of the scene.
Using this dataset, we (a) measure the robustness of our approach, (b) measure the distance between the surface of the reconstructed human poses and the ground-truth point clouds and (c) compare the results of our pipeline with the same optimization scheme applied to the ground-truth point clouds.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.4" class="ltx_p"><span id="S4.p2.4.1" class="ltx_text ltx_font_bold">Structure Sensor.</span> The active stereo depth sensor has an accuracy of <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="integer" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">1</annotation></semantics></math> percent @ <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="3.5m" display="inline"><semantics id="S4.p2.2.m2.1a"><mrow id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mn id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">3.5</mn><mo lspace="0em" rspace="0em" id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><times id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1"></times><cn type="float" id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">3.5</cn><ci id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">3.5m</annotation></semantics></math>. Depth and RGB acquisitions are synchronized and aligned using a procedure provided by the constructor. The images and depth maps are saved at <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="640\times 480" display="inline"><semantics id="S4.p2.3.m3.1a"><mrow id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mn id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">640</mn><mo lspace="0.222em" rspace="0.222em" id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">480</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><times id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1"></times><cn type="integer" id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">640</cn><cn type="integer" id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">480</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">640\times 480</annotation></semantics></math> px @ <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="24" display="inline"><semantics id="S4.p2.4.m4.1a"><mn id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">24</mn><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><cn type="integer" id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">24</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">24</annotation></semantics></math> fps.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.4" class="ltx_p"><span id="S4.p3.4.1" class="ltx_text ltx_font_bold">Acquisitions.</span> We reproduce acquisition conditions similar to the Mannequin Challenge dataset. We captured immobile humans in indoor scenes using the hand-held device, possibly containing multiple subjects in various poses, with natural noise such as motion blur, occlusions, sensor noise, <em id="S4.p3.4.2" class="ltx_emph ltx_font_italic">etc</em>.<span id="S4.p3.4.3" class="ltx_text"></span> We recorded <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="19" display="inline"><semantics id="S4.p3.1.m1.1a"><mn id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">19</mn><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><cn type="integer" id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">19</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">19</annotation></semantics></math> validation sequences of a few seconds each, resulting in <math id="S4.p3.2.m2.2" class="ltx_Math" alttext="3,624" display="inline"><semantics id="S4.p3.2.m2.2a"><mrow id="S4.p3.2.m2.2.3.2" xref="S4.p3.2.m2.2.3.1.cmml"><mn id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">3</mn><mo id="S4.p3.2.m2.2.3.2.1" xref="S4.p3.2.m2.2.3.1.cmml">,</mo><mn id="S4.p3.2.m2.2.2" xref="S4.p3.2.m2.2.2.cmml">624</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.2b"><list id="S4.p3.2.m2.2.3.1.cmml" xref="S4.p3.2.m2.2.3.2"><cn type="integer" id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">3</cn><cn type="integer" id="S4.p3.2.m2.2.2.cmml" xref="S4.p3.2.m2.2.2">624</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.2c">3,624</annotation></semantics></math> frames for <math id="S4.p3.3.m3.1" class="ltx_Math" alttext="29" display="inline"><semantics id="S4.p3.3.m3.1a"><mn id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">29</mn><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><cn type="integer" id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">29</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">29</annotation></semantics></math> human instances (<math id="S4.p3.4.m4.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.p3.4.m4.1a"><mn id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><cn type="integer" id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">8</annotation></semantics></math> different subjects).
We then use the RGB images to find the poses with our pipeline, see examples in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Validation metrics. First row is our pipeline using COLMAP, second row is replacing the latter with fused ground-truth depth maps in the optimization (values in <math id="S4.T2.2.m1.1" class="ltx_Math" alttext="cm" display="inline"><semantics id="S4.T2.2.m1.1b"><mrow id="S4.T2.2.m1.1.1" xref="S4.T2.2.m1.1.1.cmml"><mi id="S4.T2.2.m1.1.1.2" xref="S4.T2.2.m1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T2.2.m1.1.1.1" xref="S4.T2.2.m1.1.1.1.cmml">â€‹</mo><mi id="S4.T2.2.m1.1.1.3" xref="S4.T2.2.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.m1.1c"><apply id="S4.T2.2.m1.1.1.cmml" xref="S4.T2.2.m1.1.1"><times id="S4.T2.2.m1.1.1.1.cmml" xref="S4.T2.2.m1.1.1.1"></times><ci id="S4.T2.2.m1.1.1.2.cmml" xref="S4.T2.2.m1.1.1.2">ğ‘</ci><ci id="S4.T2.2.m1.1.1.3.cmml" xref="S4.T2.2.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.m1.1d">cm</annotation></semantics></math>).</figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T2.3.1" class="ltx_tr">
<td id="S4.T2.3.1.1" class="ltx_td ltx_border_r"></td>
<td id="S4.T2.3.1.2" class="ltx_td ltx_align_center ltx_border_r">SR</td>
<td id="S4.T2.3.1.3" class="ltx_td ltx_align_center ltx_border_r">mean AD</td>
<td id="S4.T2.3.1.4" class="ltx_td ltx_align_center ltx_border_r">median AD</td>
<td id="S4.T2.3.1.5" class="ltx_td ltx_align_center">MPJPE</td>
</tr>
<tr id="S4.T2.3.2" class="ltx_tr">
<td id="S4.T2.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">RGB</td>
<td id="S4.T2.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">55%</td>
<td id="S4.T2.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">6.2</td>
<td id="S4.T2.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">3.5</td>
<td id="S4.T2.3.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt" rowspan="2"><span id="S4.T2.3.2.5.1" class="ltx_text">3.1</span></td>
</tr>
<tr id="S4.T2.3.3" class="ltx_tr">
<td id="S4.T2.3.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Depth</td>
<td id="S4.T2.3.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">55%</td>
<td id="S4.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">5.0</td>
<td id="S4.T2.3.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2.2</td>
</tr>
</table>
</figure>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p id="S4.p4.3" class="ltx_p"><span id="S4.p4.3.1" class="ltx_text ltx_font_bold">Evaluation.</span>
Numerical results are reported in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
We first measure the <span id="S4.p4.3.2" class="ltx_text ltx_font_italic">robustness</span> of the method as success rate of the reconstruction (SR), <em id="S4.p4.3.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.p4.3.4" class="ltx_text"></span>, passing all of the post-processing verification checks.
The first row of TableÂ <a href="#S4.T2" title="Table 2 â€£ 4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that optimization correctly converges more than half the time when considering RGB sequences. We successfully recover <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="14" display="inline"><semantics id="S4.p4.1.m1.1a"><mn id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">14</mn><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><cn type="integer" id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">14</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">14</annotation></semantics></math> sequences, that is <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p4.2.m2.1a"><mn id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><cn type="integer" id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">16</annotation></semantics></math> human instances totaling <math id="S4.p4.3.m3.2" class="ltx_Math" alttext="2,500" display="inline"><semantics id="S4.p4.3.m3.2a"><mrow id="S4.p4.3.m3.2.3.2" xref="S4.p4.3.m3.2.3.1.cmml"><mn id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml">2</mn><mo id="S4.p4.3.m3.2.3.2.1" xref="S4.p4.3.m3.2.3.1.cmml">,</mo><mn id="S4.p4.3.m3.2.2" xref="S4.p4.3.m3.2.2.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.2b"><list id="S4.p4.3.m3.2.3.1.cmml" xref="S4.p4.3.m3.2.3.2"><cn type="integer" id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1">2</cn><cn type="integer" id="S4.p4.3.m3.2.2.cmml" xref="S4.p4.3.m3.2.2">500</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.2c">2,500</annotation></semantics></math> frames.
Interestingly, if we replace the COLMAP point cloud with the accumulated ground-truth depth maps, the method does not converge either (SR of 55% for depth also).
This shows that the failures are not due to the accuracy of the SfM reconstruction.
In practice, convergence mostly fails due to inconsistent human and body part segmentation.
Human segmentation impacts the tracking, and when the DensePose UV coordinates are not consistent along the sequence, optimal SMPL pose, shape and location are not well defined, leading to a strong divergence during the optimization step.
We conclude that our pipeline strongly depends on DensePose to provide accurate results.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.2" class="ltx_p">Next, we measure the <span id="S4.p5.2.1" class="ltx_text ltx_font_italic">overall accuracy</span> by averaging over a sequence the mean and median of absolute distances (AD) for each frame between the captured depth maps and a synthetic depth map obtained by rendering the SMPL model in the estimated pose.
We only focus here on successful pose estimations that were not automatically discarded.
We compute the absolute distance only for pixels where depths are defined in both images: because of parallax or hardware limitations, <span id="S4.p5.2.2" class="ltx_text ltx_font_italic">ground-truth</span> depth values are undefined for some pixels, as shown in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> (middle column).
TableÂ <a href="#S4.T2" title="Table 2 â€£ 4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows that we achieve a per-frame mean of <math id="S4.p5.1.m1.1" class="ltx_Math" alttext="6.2cm" display="inline"><semantics id="S4.p5.1.m1.1a"><mrow id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml"><mn id="S4.p5.1.m1.1.1.2" xref="S4.p5.1.m1.1.1.2.cmml">6.2</mn><mo lspace="0em" rspace="0em" id="S4.p5.1.m1.1.1.1" xref="S4.p5.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.p5.1.m1.1.1.3" xref="S4.p5.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.p5.1.m1.1.1.1a" xref="S4.p5.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.p5.1.m1.1.1.4" xref="S4.p5.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><apply id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1"><times id="S4.p5.1.m1.1.1.1.cmml" xref="S4.p5.1.m1.1.1.1"></times><cn type="float" id="S4.p5.1.m1.1.1.2.cmml" xref="S4.p5.1.m1.1.1.2">6.2</cn><ci id="S4.p5.1.m1.1.1.3.cmml" xref="S4.p5.1.m1.1.1.3">ğ‘</ci><ci id="S4.p5.1.m1.1.1.4.cmml" xref="S4.p5.1.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">6.2cm</annotation></semantics></math> and a per-frame median of <math id="S4.p5.2.m2.1" class="ltx_Math" alttext="3.5cm" display="inline"><semantics id="S4.p5.2.m2.1a"><mrow id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml"><mn id="S4.p5.2.m2.1.1.2" xref="S4.p5.2.m2.1.1.2.cmml">3.5</mn><mo lspace="0em" rspace="0em" id="S4.p5.2.m2.1.1.1" xref="S4.p5.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.p5.2.m2.1.1.3" xref="S4.p5.2.m2.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.p5.2.m2.1.1.1a" xref="S4.p5.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.p5.2.m2.1.1.4" xref="S4.p5.2.m2.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><apply id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1"><times id="S4.p5.2.m2.1.1.1.cmml" xref="S4.p5.2.m2.1.1.1"></times><cn type="float" id="S4.p5.2.m2.1.1.2.cmml" xref="S4.p5.2.m2.1.1.2">3.5</cn><ci id="S4.p5.2.m2.1.1.3.cmml" xref="S4.p5.2.m2.1.1.3">ğ‘</ci><ci id="S4.p5.2.m2.1.1.4.cmml" xref="S4.p5.2.m2.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">3.5cm</annotation></semantics></math> on average.
We additionally report the absolute distances between the depth maps and <span id="S4.p5.2.3" class="ltx_text ltx_font_italic">reference models</span>, computed by replacing the COLMAP point cloud with the ground-truth point cloud.
Because we are explicitly minimizing the metric in our optimization, the <span id="S4.p5.2.4" class="ltx_text ltx_font_italic">reference models</span> are naturally closer to the ground-truth. We will use these <span id="S4.p5.2.5" class="ltx_text ltx_font_italic">reference models</span> in the last validation step.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">Finally, we measure <span id="S4.p6.1.1" class="ltx_text ltx_font_italic">pose accuracy</span> as the distance between joints of the 3D pose of the reconstructed SMPL from RGB and depth data.
This evaluates the impact of the completeness and accuracy of COLMAPs reconstruction on our results.
We only consider instances where both optimizations converged, and we mask unseen joints using the per-frame visibility (SectionÂ <a href="#S3.SS4" title="3.4 Post Processing â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>).
The average MPJPE as defined in <a href="#S6.SS2" title="6.2 Metrics â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a> over all joints is reported in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4 Validation of the method â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> with <math id="S4.p6.1.m1.1" class="ltx_Math" alttext="3.1cm" display="inline"><semantics id="S4.p6.1.m1.1a"><mrow id="S4.p6.1.m1.1.1" xref="S4.p6.1.m1.1.1.cmml"><mn id="S4.p6.1.m1.1.1.2" xref="S4.p6.1.m1.1.1.2.cmml">3.1</mn><mo lspace="0em" rspace="0em" id="S4.p6.1.m1.1.1.1" xref="S4.p6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.p6.1.m1.1.1.3" xref="S4.p6.1.m1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.p6.1.m1.1.1.1a" xref="S4.p6.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.p6.1.m1.1.1.4" xref="S4.p6.1.m1.1.1.4.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.1b"><apply id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1"><times id="S4.p6.1.m1.1.1.1.cmml" xref="S4.p6.1.m1.1.1.1"></times><cn type="float" id="S4.p6.1.m1.1.1.2.cmml" xref="S4.p6.1.m1.1.1.2">3.1</cn><ci id="S4.p6.1.m1.1.1.3.cmml" xref="S4.p6.1.m1.1.1.3">ğ‘</ci><ci id="S4.p6.1.m1.1.1.4.cmml" xref="S4.p6.1.m1.1.1.4">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.1c">3.1cm</annotation></semantics></math>.
This validates that our RGB based pipeline achieves accurate reconstructions according to the depth sensor. Considering that the subjects are possibly wearing loose clothing, we would like to emphasis that the shape parameters are only used to better constrain the optimization, but cannot be considered as ground-truth.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>The SMPL Mannequin Benchmark</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.3" class="ltx_p">In total, we obtained <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="567" display="inline"><semantics id="S5.p1.1.m1.1a"><mn id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">567</mn><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><cn type="integer" id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">567</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">567</annotation></semantics></math> sequences with <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="742" display="inline"><semantics id="S5.p1.2.m2.1a"><mn id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">742</mn><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><cn type="integer" id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">742</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">742</annotation></semantics></math> different human instances, resulting in <math id="S5.p1.3.m3.2" class="ltx_Math" alttext="24,428" display="inline"><semantics id="S5.p1.3.m3.2a"><mrow id="S5.p1.3.m3.2.3.2" xref="S5.p1.3.m3.2.3.1.cmml"><mn id="S5.p1.3.m3.1.1" xref="S5.p1.3.m3.1.1.cmml">24</mn><mo id="S5.p1.3.m3.2.3.2.1" xref="S5.p1.3.m3.2.3.1.cmml">,</mo><mn id="S5.p1.3.m3.2.2" xref="S5.p1.3.m3.2.2.cmml">428</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.3.m3.2b"><list id="S5.p1.3.m3.2.3.1.cmml" xref="S5.p1.3.m3.2.3.2"><cn type="integer" id="S5.p1.3.m3.1.1.cmml" xref="S5.p1.3.m3.1.1">24</cn><cn type="integer" id="S5.p1.3.m3.2.2.cmml" xref="S5.p1.3.m3.2.2">428</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.3.m3.2c">24,428</annotation></semantics></math> image crops.
All these crops are equipped with joint visibility information from the post-processing step (sequence-wise and frame-wise), see SectionÂ <a href="#S3.SS4" title="3.4 Post Processing â€£ 3 Reconstructing static human poses in videos â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>.
Our in-the-wild dataset has a strong variability in terms of body poses, appearances and environment, and comprises indoor and outdoor scenes, with natural occlusions and close-ups.
Such natural occlusions with the environment or truncations can be seen in FigureÂ <a href="#S6.F6" title="Figure 6 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> (third and fourth columns).
Moreover, FigureÂ <a href="#S5.F4" title="Figure 4 â€£ 5 The SMPL Mannequin Benchmark â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows some random poses from our dataset to showcase the variability in poses and viewpoints.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Discussion.</span>
On one hand, one clear weakness of our pipeline comes from the fact that humans have to stay still during the acquisition. Inherently, we thus cannot capture people jumping or running but only mimes of such motions. On the other hand, compared to other in-the-wild 3D datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, we recover the poses of one to two orders of magnitude more different subjects in numerous natural environments, containing occlusions and close-ups, see TableÂ <a href="#S2.T1" title="Table 1 â€£ 2 Related Benchmarks â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Finally, our strategy does not require any particular setup and acquiring new sequences at almost no cost is a matter of seconds with any handheld RGB acquisition device such as smartphones, which are widespread.
We plan on continuing to increase the size of the dataset by acquiring and processing supplementary sequences. We make it available to the community at the following link: <a target="_blank" href="https://europe.naverlabs.com/research/computer-vision/mannequin-benchmark" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://europe.naverlabs.com/research/computer-vision/mannequin-benchmark</a>.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2012.02743/assets/Figures/db_variability_small.png" id="S5.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="77" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Illustration of pose/viewpoint variability in our SMPL Mannequin Benchmark. </figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Comparison of state-of-the-art methods</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we benchmark several SMPL-based pose estimation methods.
We describe them in SectionÂ <a href="#S6.SS1" title="6.1 Evaluated approaches â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a> before introducing the metrics used in our benchmarkÂ <a href="#S6.SS2" title="6.2 Metrics â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>.
Results are presented and discussed in SectionÂ <a href="#S6.SS3" title="6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Evaluated approaches</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">We compare the performance of several approaches whose code was available online, namely HMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, NBFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, SPINÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, DCTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, Texture PoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, GraphCMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and VIBEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
TableÂ <a href="#S6.T3" title="Table 3 â€£ 6.1 Evaluated approaches â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows an overview of their main features.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">In terms of training input, most methods take a single image crop, except NBF that uses a human body part segmentation map, VIBE that processes videos, and TexturePose whose losses are based on consistencies under different frames.
At test time, they all process a single image crop assuming <span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_italic">a single person</span>, except VIBE that processes videos.
For VIBEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, humans are detected and tracked across frames, and prediction is then made independently on each cropped image based on a per-frame method similar to SPIN, adding an adversarial loss on the SMPL motion. For a fair comparison, we directly give the ground-truth tracks to VIBE and denote the method by VIBE*.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Overview of evaluated methods.</figcaption>
<div id="S6.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:148.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.4pt,6.6pt) scale(0.917947721557852,0.917947721557852) ;">
<table id="S6.T3.3.3" class="ltx_tabular ltx_align_middle">
<tr id="S6.T3.3.3.4" class="ltx_tr">
<td id="S6.T3.3.3.4.1" class="ltx_td"></td>
<td id="S6.T3.3.3.4.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_r">HMR</td>
<td id="S6.T3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_r">NBF</td>
<td id="S6.T3.3.3.4.5" class="ltx_td ltx_align_center ltx_border_r">SPIN</td>
<td id="S6.T3.3.3.4.6" class="ltx_td ltx_align_center ltx_border_r">DCT</td>
<td id="S6.T3.3.3.4.7" class="ltx_td ltx_align_center ltx_border_r">Text.Pose</td>
<td id="S6.T3.3.3.4.8" class="ltx_td ltx_align_center ltx_border_r">GraphCMR</td>
<td id="S6.T3.3.3.4.9" class="ltx_td ltx_align_center">VIBE</td>
</tr>
<tr id="S6.T3.3.3.5" class="ltx_tr">
<td id="S6.T3.3.3.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" colspan="2">training input</td>
<td id="S6.T3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">image</td>
<td id="S6.T3.3.3.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">part. seg</td>
<td id="S6.T3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">image</td>
<td id="S6.T3.3.3.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">image</td>
<td id="S6.T3.3.3.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">image pair</td>
<td id="S6.T3.3.3.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">image</td>
<td id="S6.T3.3.3.5.8" class="ltx_td ltx_align_center ltx_border_tt">video</td>
</tr>
<tr id="S6.T3.3.3.6" class="ltx_tr">
<td id="S6.T3.3.3.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">SMPL angles</td>
<td id="S6.T3.3.3.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">axis-angle</td>
<td id="S6.T3.3.3.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">rot. matrix</td>
<td id="S6.T3.3.3.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6D rot</td>
<td id="S6.T3.3.3.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">rot. matrix</td>
<td id="S6.T3.3.3.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6D rot</td>
<td id="S6.T3.3.3.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">vertices</td>
<td id="S6.T3.3.3.6.8" class="ltx_td ltx_align_center ltx_border_t">6D rot</td>
</tr>
<tr id="S6.T3.3.3.7" class="ltx_tr">
<td id="S6.T3.3.3.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" rowspan="6">
<span id="S6.T3.3.3.7.1.1" class="ltx_inline-block ltx_parbox ltx_align_top" style="width:14.2pt;">
<span id="S6.T3.3.3.7.1.1.1" class="ltx_p">
<span id="S6.T3.3.3.7.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:24.1pt;vertical-align:-8.6pt;"><span class="ltx_transformed_inner" style="width:24.1pt;transform:translate(-8.56pt,0pt) rotate(-90deg) ;">
<span id="S6.T3.3.3.7.1.1.1.1.1" class="ltx_p">losses</span>
</span></span></span>
</span>
</td>
<td id="S6.T3.3.3.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2D joints</td>
<td id="S6.T3.3.3.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">L2</td>
<td id="S6.T3.3.3.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">L2</td>
<td id="S6.T3.3.3.7.5" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T3.3.3.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">L1</td>
<td id="S6.T3.3.3.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">L2</td>
<td id="S6.T3.3.3.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">L1</td>
<td id="S6.T3.3.3.7.9" class="ltx_td ltx_align_center ltx_border_t">L2</td>
</tr>
<tr id="S6.T3.3.3.8" class="ltx_tr">
<td id="S6.T3.3.3.8.1" class="ltx_td ltx_align_left ltx_border_r">3D joints</td>
<td id="S6.T3.3.3.8.2" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.8.3" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.8.4" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.8.5" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.8.6" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.8.7" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.8.8" class="ltx_td ltx_align_center">L2</td>
</tr>
<tr id="S6.T3.3.3.9" class="ltx_tr">
<td id="S6.T3.3.3.9.1" class="ltx_td ltx_align_left ltx_border_r">3D vertices</td>
<td id="S6.T3.3.3.9.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.9.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.9.4" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.9.5" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.9.6" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.9.7" class="ltx_td ltx_align_center ltx_border_r">L1</td>
<td id="S6.T3.3.3.9.8" class="ltx_td"></td>
</tr>
<tr id="S6.T3.3.3.10" class="ltx_tr">
<td id="S6.T3.3.3.10.1" class="ltx_td ltx_align_left ltx_border_r">texture</td>
<td id="S6.T3.3.3.10.2" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.10.3" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.10.4" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.10.5" class="ltx_td ltx_align_center ltx_border_r">L1</td>
<td id="S6.T3.3.3.10.6" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.10.7" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.10.8" class="ltx_td"></td>
</tr>
<tr id="S6.T3.3.3.11" class="ltx_tr">
<td id="S6.T3.3.3.11.1" class="ltx_td ltx_align_left ltx_border_r">SMPL</td>
<td id="S6.T3.3.3.11.2" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.11.3" class="ltx_td ltx_align_center ltx_border_r">L1</td>
<td id="S6.T3.3.3.11.4" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.11.5" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.11.6" class="ltx_td ltx_border_r"></td>
<td id="S6.T3.3.3.11.7" class="ltx_td ltx_align_center ltx_border_r">L2</td>
<td id="S6.T3.3.3.11.8" class="ltx_td"></td>
</tr>
<tr id="S6.T3.3.3.3" class="ltx_tr">
<td id="S6.T3.3.3.3.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">adversarial</td>
<td id="S6.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S6.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S6.T3.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S6.T3.1.1.1.1.m1.1.1" xref="S6.T3.1.1.1.1.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.1.m1.1b"><ci id="S6.T3.1.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.1.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S6.T3.3.3.3.5" class="ltx_td ltx_border_b ltx_border_r"></td>
<td id="S6.T3.3.3.3.6" class="ltx_td ltx_border_b ltx_border_r"></td>
<td id="S6.T3.3.3.3.7" class="ltx_td ltx_border_b ltx_border_r"></td>
<td id="S6.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><math id="S6.T3.2.2.2.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S6.T3.2.2.2.2.m1.1a"><mi mathvariant="normal" id="S6.T3.2.2.2.2.m1.1.1" xref="S6.T3.2.2.2.2.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.2.2.m1.1b"><ci id="S6.T3.2.2.2.2.m1.1.1.cmml" xref="S6.T3.2.2.2.2.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.2.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S6.T3.3.3.3.8" class="ltx_td ltx_border_b ltx_border_r"></td>
<td id="S6.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_b"><math id="S6.T3.3.3.3.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S6.T3.3.3.3.3.m1.1a"><mi mathvariant="normal" id="S6.T3.3.3.3.3.m1.1.1" xref="S6.T3.3.3.3.3.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S6.T3.3.3.3.3.m1.1b"><ci id="S6.T3.3.3.3.3.m1.1.1.cmml" xref="S6.T3.3.3.3.3.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.3.3.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
</table>
</span></div>
</figure>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">When predicting SMPL parameters, different methods use various representations for the angles in the SMPL pose, either axis-angleÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> (3 dimensions), rotation matricesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> (9 dimensions) or a 6D rotation representationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. GraphCMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> predicts a mesh from which a SMPL model can be fitted while other approaches directly predict SMPL parameters.</p>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p id="S6.SS1.p4.1" class="ltx_p">In terms of losses, most of them use a loss on the reprojection of the 2D joints (which can be used on any 2D pose estimation dataset like MPIIÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> or COCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>) and on the 3D joints when 3D ground-truth is available like on Human3.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> for instance. SPINÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> does not use such losses directly, but the method alternates between training a CNN to predict SMPL parameters and refining these parameters using a variant of SMPLifyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> which leverages such pose estimation.
Some methods use additional losses on SMPL parameters on data where it is available and/or on vertices from the corresponding mesh.
A few methods have leveraged texture correspondences like in DensePoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.
Finally, HMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> leverages an adversarial loss to ensure the realism of predicted poses. Such a strategy has been followed by TexturePose.
An adversarial loss is also used in VIBE, but at the video-level to ensure realistic motion of the SMPL model parameters.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Metrics</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">We evaluate metrics for the 3D poses as well as their 2D projections in images.
Since the aim is to predict physical joints of rather large volumes, keypoints for 3D pose have an uncertainty level of a few centimeters, that is a lower bound on the meaningful quantitative evaluation. Regardless of that, the results evidence limits of existing methods <em id="S6.SS2.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S6.SS2.p1.1.2" class="ltx_text"></span> showing natural cases where all methods completely fail.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para ltx_noindent">
<p id="S6.SS2.p2.1" class="ltx_p"><span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_bold">3D poses.</span>
Various approaches assume different virtual cameras. We thus consider metrics after setting the translational SMPL component to 0.
We extract the 3D coordinates of the 24 joints proposed in the SMPL definition and measure for each joint the average error over all instances where this joint is visible.
We finally report the mean per-joint position error (MPJPE) in millimeters by averaging these values over all joints.
MPJPE has the downside of penalizing methods with outliers. We thus also measure the <span id="S6.SS2.p2.1.2" class="ltx_text ltx_font_italic">PCK3D@X</span> (percentage of correct keypoints in 3D with a threshold of X mm) for every joint, <em id="S6.SS2.p2.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S6.SS2.p2.1.4" class="ltx_text"></span>, the percentages of cases where the joint is predicted with an error below X mm, and average this over all joints. To obtain a single numerical value, we report the AUC (Area Under the Curve) when plotting the PCK3D at various thresholds. In practice, we average the PCK3D@X for X varying from 1 to 500 mm with a step of 1 mm.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para ltx_noindent">
<p id="S6.SS2.p3.1" class="ltx_p"><span id="S6.SS2.p3.1.1" class="ltx_text ltx_font_bold">2D poses.</span>
We project the joints using the virtual cameras of each method into the images and get pixel coordinates for each joint.
We also project the ground-truth model and compute the error in pixels, which we normalize by dividing by a scale factor, to achieve invariance <em id="S6.SS2.p3.1.2" class="ltx_emph ltx_font_italic">w.r.t</em>.<span id="S6.SS2.p3.1.3" class="ltx_text"></span> camera distance to the subject.
This scale is obtained by drawing the radius of the sphere centered in joint 0 of the ground-truth of the size of the first bone, which measures roughly 11cm in 3D.
We finally report the normalized error the MPJPE, PCK2D@X with X between 0.05 and 2.00 with a step 0.05 and the AUC.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Results and discussion</h3>

<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Comparison of state-of-the-art methods using the MPJPE metric in 3D (top) and in 2D (bottom) for different sets of joints, as well as average MPJPE over the whole body (<span id="S6.T4.2.1" class="ltx_text ltx_font_bold">mean</span>). The column N shows the average number of such visible sets of joints in the dataset. â€˜PAâ€™ refers to results obtained after a Procrustes alignment with the ground-truth. For each row, the best method is shown in bold, while the second best is underlined.</figcaption>
<div id="S6.T4.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:396.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(20.0pt,-18.2pt) scale(1.10135999029547,1.10135999029547) ;">
<table id="S6.T4.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T4.3.1.1" class="ltx_tr">
<td id="S6.T4.3.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td id="S6.T4.3.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td id="S6.T4.3.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(njts)</td>
<td id="S6.T4.3.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">N</td>
<td id="S6.T4.3.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">MEAN</td>
<td id="S6.T4.3.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">HMR</td>
<td id="S6.T4.3.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">NBF</td>
<td id="S6.T4.3.1.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">SPIN</td>
<td id="S6.T4.3.1.1.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">DCT</td>
<td id="S6.T4.3.1.1.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">Text.Pose</td>
<td id="S6.T4.3.1.1.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">GraphCMR</td>
<td id="S6.T4.3.1.1.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">VIBE*</td>
</tr>
<tr id="S6.T4.3.1.2" class="ltx_tr">
<td id="S6.T4.3.1.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="9">
<span id="S6.T4.3.1.2.1.1" class="ltx_inline-block ltx_parbox ltx_align_top" style="width:14.2pt;">
<span id="S6.T4.3.1.2.1.1.1" class="ltx_p">
<span id="S6.T4.3.1.2.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:10.0pt;height:40.4pt;vertical-align:-17.7pt;"><span class="ltx_transformed_inner" style="width:40.4pt;transform:translate(-15.21pt,3.75pt) rotate(-90deg) ;">
<span id="S6.T4.3.1.2.1.1.1.1.1" class="ltx_p">3D (mm)</span>
</span></span></span>
</span>
</td>
<td id="S6.T4.3.1.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">elbows</td>
<td id="S6.T4.3.1.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">16290</td>
<td id="S6.T4.3.1.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">307.5</td>
<td id="S6.T4.3.1.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">208.0</td>
<td id="S6.T4.3.1.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">406.0</td>
<td id="S6.T4.3.1.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.2.8.1" class="ltx_text ltx_framed ltx_framed_underline">171.0</span></td>
<td id="S6.T4.3.1.2.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">179.3</td>
<td id="S6.T4.3.1.2.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">202.6</td>
<td id="S6.T4.3.1.2.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">176.9</td>
<td id="S6.T4.3.1.2.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.2.12.1" class="ltx_text ltx_font_bold">158.4</span></td>
</tr>
<tr id="S6.T4.3.1.3" class="ltx_tr">
<td id="S6.T4.3.1.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">wrists</td>
<td id="S6.T4.3.1.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">14809</td>
<td id="S6.T4.3.1.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">493.9</td>
<td id="S6.T4.3.1.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">227.1</td>
<td id="S6.T4.3.1.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">516.0</td>
<td id="S6.T4.3.1.3.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.3.7.1" class="ltx_text ltx_framed ltx_framed_underline">210.7</span></td>
<td id="S6.T4.3.1.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">217.9</td>
<td id="S6.T4.3.1.3.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">246.4</td>
<td id="S6.T4.3.1.3.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">225.1</td>
<td id="S6.T4.3.1.3.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.3.11.1" class="ltx_text ltx_font_bold">203.4</span></td>
</tr>
<tr id="S6.T4.3.1.4" class="ltx_tr">
<td id="S6.T4.3.1.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">hands</td>
<td id="S6.T4.3.1.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">13118</td>
<td id="S6.T4.3.1.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">582.3</td>
<td id="S6.T4.3.1.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">246.7</td>
<td id="S6.T4.3.1.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">576.5</td>
<td id="S6.T4.3.1.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.4.7.1" class="ltx_text ltx_framed ltx_framed_underline">238.9</span></td>
<td id="S6.T4.3.1.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">240.6</td>
<td id="S6.T4.3.1.4.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">275.1</td>
<td id="S6.T4.3.1.4.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">257.6</td>
<td id="S6.T4.3.1.4.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.4.11.1" class="ltx_text ltx_font_bold">233.7</span></td>
</tr>
<tr id="S6.T4.3.1.5" class="ltx_tr">
<td id="S6.T4.3.1.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">knees</td>
<td id="S6.T4.3.1.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">8521</td>
<td id="S6.T4.3.1.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">289.6</td>
<td id="S6.T4.3.1.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">165.9</td>
<td id="S6.T4.3.1.5.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">376.8</td>
<td id="S6.T4.3.1.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.5.7.1" class="ltx_text ltx_framed ltx_framed_underline">161.1</span></td>
<td id="S6.T4.3.1.5.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">180.8</td>
<td id="S6.T4.3.1.5.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">209.9</td>
<td id="S6.T4.3.1.5.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">161.2</td>
<td id="S6.T4.3.1.5.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.5.11.1" class="ltx_text ltx_font_bold">150.9</span></td>
</tr>
<tr id="S6.T4.3.1.6" class="ltx_tr">
<td id="S6.T4.3.1.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">ankles</td>
<td id="S6.T4.3.1.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">5135</td>
<td id="S6.T4.3.1.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">313.5</td>
<td id="S6.T4.3.1.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">225.2</td>
<td id="S6.T4.3.1.6.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">549.9</td>
<td id="S6.T4.3.1.6.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.6.7.1" class="ltx_text ltx_framed ltx_framed_underline">208.3</span></td>
<td id="S6.T4.3.1.6.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">220.6</td>
<td id="S6.T4.3.1.6.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">234.5</td>
<td id="S6.T4.3.1.6.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">222.1</td>
<td id="S6.T4.3.1.6.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.6.11.1" class="ltx_text ltx_font_bold">186.4</span></td>
</tr>
<tr id="S6.T4.3.1.7" class="ltx_tr">
<td id="S6.T4.3.1.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">toes</td>
<td id="S6.T4.3.1.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">3428</td>
<td id="S6.T4.3.1.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">354.9</td>
<td id="S6.T4.3.1.7.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">225.7</td>
<td id="S6.T4.3.1.7.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">614.7</td>
<td id="S6.T4.3.1.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.7.7.1" class="ltx_text ltx_framed ltx_framed_underline">225.5</span></td>
<td id="S6.T4.3.1.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">229.5</td>
<td id="S6.T4.3.1.7.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">232.8</td>
<td id="S6.T4.3.1.7.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">226.4</td>
<td id="S6.T4.3.1.7.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.7.11.1" class="ltx_text ltx_font_bold">200.7</span></td>
</tr>
<tr id="S6.T4.3.1.8" class="ltx_tr">
<td id="S6.T4.3.1.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">neck/head</td>
<td id="S6.T4.3.1.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">22971</td>
<td id="S6.T4.3.1.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">151.0</td>
<td id="S6.T4.3.1.8.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">198.2</td>
<td id="S6.T4.3.1.8.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">480.4</td>
<td id="S6.T4.3.1.8.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">162.4</td>
<td id="S6.T4.3.1.8.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.8.8.1" class="ltx_text ltx_framed ltx_framed_underline">156.5</span></td>
<td id="S6.T4.3.1.8.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">176.6</td>
<td id="S6.T4.3.1.8.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">179.1</td>
<td id="S6.T4.3.1.8.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.8.11.1" class="ltx_text ltx_font_bold">140.9</span></td>
</tr>
<tr id="S6.T4.3.1.9" class="ltx_tr">
<td id="S6.T4.3.1.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">torso</td>
<td id="S6.T4.3.1.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(10)</td>
<td id="S6.T4.3.1.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">20112</td>
<td id="S6.T4.3.1.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">100.4</td>
<td id="S6.T4.3.1.9.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">123.8</td>
<td id="S6.T4.3.1.9.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">238.0</td>
<td id="S6.T4.3.1.9.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.9.7.1" class="ltx_text ltx_framed ltx_framed_underline">92.5</span></td>
<td id="S6.T4.3.1.9.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">102.1</td>
<td id="S6.T4.3.1.9.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">101.0</td>
<td id="S6.T4.3.1.9.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">95.9</td>
<td id="S6.T4.3.1.9.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.9.11.1" class="ltx_text ltx_font_bold">81.3</span></td>
</tr>
<tr id="S6.T4.3.1.10" class="ltx_tr">
<td id="S6.T4.3.1.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.10.1.1" class="ltx_text ltx_font_bold">mean</span></td>
<td id="S6.T4.3.1.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">(24)</td>
<td id="S6.T4.3.1.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">15402</td>
<td id="S6.T4.3.1.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">249.5</td>
<td id="S6.T4.3.1.10.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">176.3</td>
<td id="S6.T4.3.1.10.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">392.5</td>
<td id="S6.T4.3.1.10.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.10.7.1" class="ltx_text ltx_framed ltx_framed_underline">153.4</span></td>
<td id="S6.T4.3.1.10.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">161.3</td>
<td id="S6.T4.3.1.10.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">173.6</td>
<td id="S6.T4.3.1.10.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">160.6</td>
<td id="S6.T4.3.1.10.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.10.11.1" class="ltx_text ltx_font_bold">140.1</span></td>
</tr>
<tr id="S6.T4.3.1.11" class="ltx_tr">
<td id="S6.T4.3.1.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td id="S6.T4.3.1.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S6.T4.3.1.11.2.1" class="ltx_text ltx_font_bold">mean</span> (PA)</td>
<td id="S6.T4.3.1.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">(24)</td>
<td id="S6.T4.3.1.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">15402</td>
<td id="S6.T4.3.1.11.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">141.2</td>
<td id="S6.T4.3.1.11.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">110.7</td>
<td id="S6.T4.3.1.11.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">212.5</td>
<td id="S6.T4.3.1.11.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.11.8.1" class="ltx_text ltx_framed ltx_framed_underline">84.8</span></td>
<td id="S6.T4.3.1.11.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">101.4</td>
<td id="S6.T4.3.1.11.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">104.6</td>
<td id="S6.T4.3.1.11.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">98.7</td>
<td id="S6.T4.3.1.11.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.11.12.1" class="ltx_text ltx_font_bold">84.5</span></td>
</tr>
<tr id="S6.T4.3.1.12" class="ltx_tr">
<td id="S6.T4.3.1.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="8">
<span id="S6.T4.3.1.12.1.1" class="ltx_inline-block ltx_parbox ltx_align_top" style="width:14.2pt;">
<span id="S6.T4.3.1.12.1.1.1" class="ltx_p">
<span id="S6.T4.3.1.12.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:10.0pt;height:32pt;vertical-align:-13.5pt;"><span class="ltx_transformed_inner" style="width:32.1pt;transform:translate(-11.04pt,3.75pt) rotate(-90deg) ;">
<span id="S6.T4.3.1.12.1.1.1.1.1" class="ltx_p">2D (%)</span>
</span></span></span>
</span>
</td>
<td id="S6.T4.3.1.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">elbows</td>
<td id="S6.T4.3.1.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">16290</td>
<td id="S6.T4.3.1.12.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.12.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.12.6.1" class="ltx_text ltx_font_bold">72.1</span></td>
<td id="S6.T4.3.1.12.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">271.2</td>
<td id="S6.T4.3.1.12.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">87.1</td>
<td id="S6.T4.3.1.12.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.12.9.1" class="ltx_text ltx_framed ltx_framed_underline">77.0</span></td>
<td id="S6.T4.3.1.12.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">121.4</td>
<td id="S6.T4.3.1.12.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">98.6</td>
<td id="S6.T4.3.1.12.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;">87.6</td>
</tr>
<tr id="S6.T4.3.1.13" class="ltx_tr">
<td id="S6.T4.3.1.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">wrists</td>
<td id="S6.T4.3.1.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">14809</td>
<td id="S6.T4.3.1.13.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.13.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.13.5.1" class="ltx_text ltx_font_bold">82.9</span></td>
<td id="S6.T4.3.1.13.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">273.8</td>
<td id="S6.T4.3.1.13.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">97.4</td>
<td id="S6.T4.3.1.13.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">101.1</td>
<td id="S6.T4.3.1.13.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">127.3</td>
<td id="S6.T4.3.1.13.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">102.2</td>
<td id="S6.T4.3.1.13.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.13.11.1" class="ltx_text ltx_framed ltx_framed_underline">91.3</span></td>
</tr>
<tr id="S6.T4.3.1.14" class="ltx_tr">
<td id="S6.T4.3.1.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">hands</td>
<td id="S6.T4.3.1.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.14.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">13118</td>
<td id="S6.T4.3.1.14.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.14.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.14.5.1" class="ltx_text ltx_font_bold">99.5</span></td>
<td id="S6.T4.3.1.14.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">292.5</td>
<td id="S6.T4.3.1.14.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">114.0</td>
<td id="S6.T4.3.1.14.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">125.8</td>
<td id="S6.T4.3.1.14.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">135.0</td>
<td id="S6.T4.3.1.14.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">118.0</td>
<td id="S6.T4.3.1.14.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.14.11.1" class="ltx_text ltx_framed ltx_framed_underline">108.6</span></td>
</tr>
<tr id="S6.T4.3.1.15" class="ltx_tr">
<td id="S6.T4.3.1.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">knees</td>
<td id="S6.T4.3.1.15.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">8521</td>
<td id="S6.T4.3.1.15.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.15.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.15.5.1" class="ltx_text ltx_font_bold">71.6</span></td>
<td id="S6.T4.3.1.15.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">386.6</td>
<td id="S6.T4.3.1.15.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">80.9</td>
<td id="S6.T4.3.1.15.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">96.4</td>
<td id="S6.T4.3.1.15.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">99.5</td>
<td id="S6.T4.3.1.15.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">87.9</td>
<td id="S6.T4.3.1.15.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.15.11.1" class="ltx_text ltx_framed ltx_framed_underline">77.0</span></td>
</tr>
<tr id="S6.T4.3.1.16" class="ltx_tr">
<td id="S6.T4.3.1.16.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">ankles</td>
<td id="S6.T4.3.1.16.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.16.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">5135</td>
<td id="S6.T4.3.1.16.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.16.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.16.5.1" class="ltx_text ltx_font_bold">87.2</span></td>
<td id="S6.T4.3.1.16.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">470.1</td>
<td id="S6.T4.3.1.16.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">114.8</td>
<td id="S6.T4.3.1.16.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">104.8</td>
<td id="S6.T4.3.1.16.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">101.2</td>
<td id="S6.T4.3.1.16.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">125.0</td>
<td id="S6.T4.3.1.16.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.16.11.1" class="ltx_text ltx_framed ltx_framed_underline">88.5</span></td>
</tr>
<tr id="S6.T4.3.1.17" class="ltx_tr">
<td id="S6.T4.3.1.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">toes</td>
<td id="S6.T4.3.1.17.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.17.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">3428</td>
<td id="S6.T4.3.1.17.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.17.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.17.5.1" class="ltx_text ltx_framed ltx_framed_underline">83.6</span></td>
<td id="S6.T4.3.1.17.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">572.5</td>
<td id="S6.T4.3.1.17.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">107.7</td>
<td id="S6.T4.3.1.17.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">98.5</td>
<td id="S6.T4.3.1.17.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">131.3</td>
<td id="S6.T4.3.1.17.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">122.3</td>
<td id="S6.T4.3.1.17.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.17.11.1" class="ltx_text ltx_font_bold">76.5</span></td>
</tr>
<tr id="S6.T4.3.1.18" class="ltx_tr">
<td id="S6.T4.3.1.18.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">neck/head</td>
<td id="S6.T4.3.1.18.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(2)</td>
<td id="S6.T4.3.1.18.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">22971</td>
<td id="S6.T4.3.1.18.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.18.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.18.5.1" class="ltx_text ltx_font_bold">40.6</span></td>
<td id="S6.T4.3.1.18.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">243.3</td>
<td id="S6.T4.3.1.18.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">66.9</td>
<td id="S6.T4.3.1.18.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.18.8.1" class="ltx_text ltx_framed ltx_framed_underline">46.2</span></td>
<td id="S6.T4.3.1.18.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">79.5</td>
<td id="S6.T4.3.1.18.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">92.0</td>
<td id="S6.T4.3.1.18.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">55.0</td>
</tr>
<tr id="S6.T4.3.1.19" class="ltx_tr">
<td id="S6.T4.3.1.19.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding-left:1.0pt;padding-right:1.0pt;">torso</td>
<td id="S6.T4.3.1.19.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right" style="padding-left:1.0pt;padding-right:1.0pt;">(10)</td>
<td id="S6.T4.3.1.19.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">20112</td>
<td id="S6.T4.3.1.19.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.19.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.19.5.1" class="ltx_text ltx_font_bold">57.4</span></td>
<td id="S6.T4.3.1.19.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">267.8</td>
<td id="S6.T4.3.1.19.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">69.3</td>
<td id="S6.T4.3.1.19.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.19.8.1" class="ltx_text ltx_framed ltx_framed_underline">62.3</span></td>
<td id="S6.T4.3.1.19.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">102.0</td>
<td id="S6.T4.3.1.19.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r" style="padding-left:1.0pt;padding-right:1.0pt;">93.8</td>
<td id="S6.T4.3.1.19.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">71.1</td>
</tr>
<tr id="S6.T4.3.1.20" class="ltx_tr">
<td id="S6.T4.3.1.20.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td id="S6.T4.3.1.20.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.20.2.1" class="ltx_text ltx_font_bold">mean</span></td>
<td id="S6.T4.3.1.20.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">(24)</td>
<td id="S6.T4.3.1.20.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">15402</td>
<td id="S6.T4.3.1.20.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">-</td>
<td id="S6.T4.3.1.20.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.20.6.1" class="ltx_text ltx_font_bold">68.7</span></td>
<td id="S6.T4.3.1.20.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">320.7</td>
<td id="S6.T4.3.1.20.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">84.6</td>
<td id="S6.T4.3.1.20.9" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">80.1</td>
<td id="S6.T4.3.1.20.10" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">108.8</td>
<td id="S6.T4.3.1.20.11" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">101.2</td>
<td id="S6.T4.3.1.20.12" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S6.T4.3.1.20.12.1" class="ltx_text ltx_framed ltx_framed_underline">78.4</span></td>
</tr>
</table>
</span></div>
</figure>
<div id="S6.SS3.p1" class="ltx_para ltx_noindent">
<p id="S6.SS3.p1.1" class="ltx_p"><span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_bold">Overall performances.</span>
We first report the MPJPE in 3D and in 2D in TableÂ <a href="#S6.T4" title="Table 4 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> for all methods, and for various subsets of joints.
We also report the performance of a naive baseline â€˜MEANâ€™ where the mean pose taken fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> is returned for any crop.
We additionally plot the PCK3D (left) and PCK2D (right) with their AUC in FigureÂ <a href="#S6.F5" title="Figure 5 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">Overall, we observe that the farther from the torso the joints are, the higher the error is since their degrees of freedom along the kinematic chain is also higher.</p>
</div>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">We observe that NBFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> performs quite poorly, even worse than the naive MEAN baseline.
The method predicts SMPL parameters from body part segmentation, and is therefore sensible to this step.
It appears that the body part segmentation fails in many images, resulting in an unrealistic and quite random SMPL estimate.
Among the 12 body parts considered by the method, more than 1,700 images have no segmented part at all, and about 1000 additional ones have fewer than 4 parts, <em id="S6.SS3.p3.1.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S6.SS3.p3.1.2" class="ltx_text"></span>, a total of 20% of the images, which correspond more or less to the gap in PCK compared to other methods in FigureÂ <a href="#S6.F5" title="Figure 5 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> (left).</p>
</div>
<figure id="S6.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2012.02743/assets/x1.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="207" height="158" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2012.02743/assets/x2.png" id="S6.F5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="207" height="153" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>PCK in 3D (left) and in 2D (right) averaged over all joints for varying error thresholds on the SMPL Mannequin Benchmark. AUC is indicated in parenthesis.</figcaption>
</figure>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">Overall, VIBEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> on ground-truth crops (VIBE*) performs best in 3D with 140mm MPJPE and 72.6 AUC.
This is likely because this is the only evaluated method that leverages temporal information.
It actually extends SPINÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> that performs the second best with 153mm MPJPE and 70.4 AUC.
The high performance of this image-based method can be explained by the elegant combination of learning-based and optimization-based approaches during training.
In TableÂ <a href="#S6.T4" title="Table 4 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we also show the MPJPE when applying for each estimated pose a rotation and translation to minimize the MPJPE.
Interestingly, SPIN and VIBE are on par, which means that VIBE likely allows the SPIN estimates to be stabilized over time.</p>
</div>
<div id="S6.SS3.p5" class="ltx_para">
<p id="S6.SS3.p5.1" class="ltx_p">GraphCMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> and DCTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> follow on the overall ranking and have similar performance.
GraphCMR has a slightly higher AUC (69.0 vs 68.4) with a 1mm lower MPJPE.
By looking at the per joint results, it appears that DCT performs better on farthest joints but worse on joints close to the torso.</p>
</div>
<div id="S6.SS3.p6" class="ltx_para">
<p id="S6.SS3.p6.2" class="ltx_p">Next are TexturePoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and HMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> with about 175m MPJPE and roughly 66 AUC.
Interestingly, FigureÂ <a href="#S6.F5" title="Figure 5 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> (left) shows that HMR reaches this level of AUC with a PCK that is lower at low threshold but higher at high threshold.
In other words, its joint estimates are less aberrant in extreme cases, which may be explained by the use of an adversarial loss.
TexturePose uses the same adversarial loss, and leverages also additional losses like on the consistency of the texture when multiple viewpoints are available.
We explain that it performs on par with HMR by the fact that it uses fewer in-the-wild datasets annotated with 2D pose (MPII only, <em id="S6.SS3.p6.2.1" class="ltx_emph ltx_font_italic">vs</em>.<span id="S6.SS3.p6.2.2" class="ltx_text"></span> MPII, LSP, LSPE and COCO for HMR).
Interestingly, this also explains why HMR performs the best in terms of 2D metrics, <em id="S6.SS3.p6.2.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S6.SS3.p6.2.4" class="ltx_text"></span>, after reprojection of the SMPL models into the images.
HMR even outperforms approaches like VIBE or SPIN that achieved better results with regards to the 3D metrics.
The competing approaches using this 2D metric are also trained on varied in-the-wild datasets with 2D pose annotation, <em id="S6.SS3.p6.2.5" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S6.SS3.p6.2.6" class="ltx_text"></span> UP3D and COCO DensePose for DCT or COCO, MPII and LSPE for SPIN, whereas methods like GraphCMR or TexturePose are trained on fewer in-the-wild training data and perform worse.
In terms of qualitative results, FigureÂ <a href="#S6.F6" title="Figure 6 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> displays examples on which methodsâ€™ performances are correlated, <em id="S6.SS3.p6.2.7" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S6.SS3.p6.2.8" class="ltx_text"></span> either all performing well (<math id="S6.SS3.p6.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS3.p6.1.m1.1a"><mn id="S6.SS3.p6.1.m1.1.1" xref="S6.SS3.p6.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p6.1.m1.1b"><cn type="integer" id="S6.SS3.p6.1.m1.1.1.cmml" xref="S6.SS3.p6.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p6.1.m1.1c">2</annotation></semantics></math> left columns) or poorly (<math id="S6.SS3.p6.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S6.SS3.p6.2.m2.1a"><mn id="S6.SS3.p6.2.m2.1.1" xref="S6.SS3.p6.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p6.2.m2.1b"><cn type="integer" id="S6.SS3.p6.2.m2.1.1.cmml" xref="S6.SS3.p6.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p6.2.m2.1c">2</annotation></semantics></math> right columns). We notice that state-of-the-art methods tend to succeed when the subjects are completely visible with little to no occlusions, but are more prone to errors when truncation or occlusions become stronger. Also, it appears that faces are a dominant discriminating factor, and lead to inverted body orientations or incoherent predictions when hidden (third and fourth columns).
We evaluate further the impact of occlusions in the next paragraphs.</p>
</div>
<figure id="S6.F6" class="ltx_figure"><img src="/html/2012.02743/assets/Figures/hard_vertical_short.png" id="S6.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="481" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Data samples similarly easy (left) or hard (right) for all methods. See supplementary material for results of all methods.</figcaption>
</figure>
<div id="S6.SS3.p7" class="ltx_para ltx_noindent">
<p id="S6.SS3.p7.1" class="ltx_p"><span id="S6.SS3.p7.1.1" class="ltx_text ltx_font_bold">Impact of occlusions.</span>
Our dataset contains people with varying levels of occlusion.
In FigureÂ <a href="#S6.F7" title="Figure 7 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (left), we measure the MPJPE of all methods while varying the maximum number of occluded joints.
In other words, when the x-axis has a value of 5, this means that they are maximum 5 non-visible joints, <em id="S6.SS3.p7.1.2" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S6.SS3.p7.1.3" class="ltx_text"></span>, at least 19 visible joints.
We observe that overall, the MPJPE gets worse when more joints are occluded, and in particular when reaching 10 or 15 occluded joints and more, which means that only a small part of the human is visible, <em id="S6.SS3.p7.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S6.SS3.p7.1.5" class="ltx_text"></span> half-body occlusions as visible in last column of figure <a href="#S6.F6" title="Figure 6 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.
All methods are approximately as robust/sensitive regarding this aspect.</p>
</div>
<div id="S6.SS3.p8" class="ltx_para">
<p id="S6.SS3.p8.1" class="ltx_p">TexturePoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> seems to be more sensitive, which we explain by the lower variety in their training data compared to that of other methods with humans fully visible most of the time.
NBFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> is not shown on the plot, but the MPJPE when all joints are visible is around 225mm and the plateau on the right side is at 400mm.
The method is thus even more sensitive than the others to occlusions, probably due to the fact that there is fewer body part in the segmentation, leading to aberrant output SMPL parameters.</p>
</div>
<figure id="S6.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2012.02743/assets/x3.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="81" height="63" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2012.02743/assets/x4.png" id="S6.F7.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="83" height="63" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2012.02743/assets/x5.png" id="S6.F7.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="83" height="63" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="S6.F7.4.1" class="ltx_text ltx_font_italic">Left:</span> 3D MPJPE for the subset of images where the number of occluded joints is bounded by the value on the x-axis. We did not plot NBF whose curve has a similar behavior but starting at 230mm and finishing around 400mm. <span id="S6.F7.5.2" class="ltx_text ltx_font_italic">Middle:</span> 3D MPJPE when varying the difficulty of the pose, measured as the distance between the ground-truth pose and the mean pose. The x-axis is based on bins of 50mm. <span id="S6.F7.6.3" class="ltx_text ltx_font_italic">Right:</span> 3D MPJPE when varying the tilt angle between the body and the camera vertical axis. We did not plot NBF whose MPJPE increases similarly from 330mm to 500mm.</figcaption>
</figure>
<div id="S6.SS3.p9" class="ltx_para ltx_noindent">
<p id="S6.SS3.p9.1" class="ltx_p"><span id="S6.SS3.p9.1.1" class="ltx_text ltx_font_bold">Impact of pose difficulty.</span>
Next, we investigate how difficult poses impact the performances of the different methods.
To quantify this <em id="S6.SS3.p9.1.2" class="ltx_emph ltx_font_italic">difficulty</em>, we use the difference (MPJPE) between a given ground-truth pose and the mean pose as a proxy.
We build bins according to this measure and plot the performances of the method according to the ground-truth poses in these bins. Results are shown in FigureÂ <a href="#S6.F7" title="Figure 7 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> (middle).
Clearly, poses farther from the mean pose are harder to estimate for all methods.
It appears that HMR performs the best for difficult poses, likely thanks to its adversarial loss at the image level and its variety of in-the-wild data for training.
DCT also seems to be more robust to difficult poses, as the position of hands (see TableÂ <a href="#S6.T4" title="Table 4 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>) are quite well estimated compared to other approaches, likely thanks to the loss on the texture while training on COCO-DensePose.</p>
</div>
<div id="S6.SS3.p10" class="ltx_para">
<p id="S6.SS3.p10.1" class="ltx_p">Poses where the global orientation of the body with respect to the vertical axis are not common, <em id="S6.SS3.p10.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S6.SS3.p10.1.2" class="ltx_text"></span> someone lying down, and are also quite difficult in general.
We measure the global body tilt with respect to the camera vertical axis and
plot its impact on 3D MPJPE in FigureÂ <a href="#S6.F7" title="Figure 7 â€£ 6.3 Results and discussion â€£ 6 Comparison of state-of-the-art methods â€£ SMPLy Benchmarking 3D Human Pose Estimation in the Wild" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, using a 20Â°Â Epanechnikov window smoothing.
Clearly, all methods perform worse when tilt angle increases. Interestingly, HMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> again shows better generalization capability as it seems less affected than the other methods.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We have presented a pipeline to reconstruct 3D poses from videos of still humans.
We used our method to generate a novel in-the-wild benchmark, using the recent Mannequin Challenge dataset which we validated with depth equipped acquisitions.
The presented in-the-wild dataset comprises one to two orders of magnitude more subjects than previously existing ones, with accurate ground-truth and with high variability in poses, appearances, environments and orientations.
Our experiments showed where current state of the art succeeds, but most importantly we unveiled exciting areas of improvement of such approaches, namely strong occlusions and difficult poses, which naturally arise in common videos and that were merely observed with previously existing datasets. </p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://www.apple.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.apple.com/</a><span id="bib.bib1.2.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://structure.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://structure.io/</a><span id="bib.bib2.2.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
M.Â Andriluka, L.Â Pishchulin, P.Â Gehler, and B.Â Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">2D human pose estimation: New benchmark and state of the art
analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
F.Â Bogo, A.Â Kanazawa, C.Â Lassner, P.Â V. Gehler, J.Â Romero, and M.Â J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Keep it SMPL: automatic estimation of 3D human pose and shape
from a single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Z.Â Cao, G.Â Hidalgo, T.Â Simon, S.-E. Wei, and Y.Â Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">OpenPose: realtime multi-person 2D pose estimation using Part
Affinity Fields.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1812.08008</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
A.Â Elhayek, E.Â deÂ Aguiar, A.Â Jain, J.Â Tompson, L.Â Pishchulin, M.Â Andriluka,
C.Â Bregler, B.Â Schiele, and C.Â Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Marconi-convnet-based marker-less motion capture in outdoor and
indoor scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. PAMI</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
V.Â Gabeur, J.-S. Franco, X.Â Martin, C.Â Schmid, and G.Â Rogez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Moulding humans: Non-parametric 3D human shape estimation from
single images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
S.Â Geman and D.Â McClure.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Statistical methods for tomographic image reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Bulletin of the International Statistical Institute</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, 1987.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
R.Â A. GÃ¼ler, N.Â Neverova, and I.Â Kokkinos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Densepose: Dense human pose estimation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Huang, F.Â Bogo, C.Â Lassner, A.Â Kanazawa, P.Â V. Gehler, J.Â Romero, I.Â Akhter,
and M.Â J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Towards accurate markerless human shape and pose estimation over
time.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">3DV</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
C.Â Ionescu, D.Â Papava, V.Â Olaru, and C.Â Sminchisescu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Human3.6M: Large scale datasets and predictive methods for 3D
human sensing in natural environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. PAMI</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
H.Â Jiang, J.Â Cai, and J.Â Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Skeleton-aware 3d human shape reconstruction from point clouds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
H.Â Joo, H.Â Liu, L.Â Tan, L.Â Gui, B.Â Nabbe, I.Â Matthews, T.Â Kanade, S.Â Nobuhara,
and Y.Â Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Panoptic studio: A massively multiview system for social motion
capture.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
H.Â Joo, T.Â Simon, X.Â Li, H.Â Liu, L.Â Tan, L.Â Gui, S.Â Banerjee, T.Â S. Godisart,
B.Â Nabbe, I.Â Matthews, T.Â Kanade, S.Â Nobuhara, and Y.Â Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Panoptic studio: A massively multiview system for social interaction
capture.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Trans. PAMI</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
H.Â Joo, T.Â Simon, and Y.Â Sheikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Total capture: A 3d deformation model for tracking faces, hands,
and bodies.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
A.Â Kanazawa, M.Â J. Black, D.Â W. Jacobs, and J.Â Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">End-to-end recovery of human shape and pose.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
M.Â Kocabas, N.Â Athanasiou, and M.Â J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Vibe: Video inference for human body pose and shape estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
M.Â Kocabas, S.Â Karagoz, and E.Â Akbas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Self-supervised learning of 3d human pose using multi-view geometry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
N.Â Kolotouros, G.Â Pavlakos, M.Â J. Black, and K.Â Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Learning to reconstruct 3D human pose and shape via model-fitting
in the loop.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
N.Â Kolotouros, G.Â Pavlakos, and K.Â Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Convolutional mesh regression for single-image human shape
reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
C.Â Lassner, J.Â Romero, M.Â Kiefel, F.Â Bogo, M.Â J. Black, and P.Â V. Gehler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Unite the people: Closing the loop between 3D and 2D human
representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Z.Â Li, T.Â Dekel, F.Â Cole, R.Â Tucker, N.Â Snavely, C.Â Liu, and W.Â T. Freeman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Learning the depths of moving people by watching frozen people.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
T.-Y. Lin, M.Â Maire, S.Â Belongie, J.Â Hays, P.Â Perona, D.Â Ramanan,
P.Â DollÃ¡r, and C.Â L. Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
P.Â Liu, M.Â Lyu, I.Â King, and J.Â Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Selflow: Self-supervised learning of optical flow.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
M.Â Loper, N.Â Mahmood, J.Â Romero, G.Â Pons-Moll, and M.Â J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Smpl: A skinned multi-person linear model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM transactions on Graphics</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
D.Â Mehta, H.Â Rhodin, D.Â Casas, P.Â Fua, O.Â Sotnychenko, W.Â Xu, and C.Â Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Monocular 3D human pose estimation in the wild using improved CNN
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">3DV</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
D.Â Mehta, O.Â Sotnychenko, F.Â Mueller, W.Â Xu, S.Â Sridhar, G.Â Pons-Moll, and
C.Â Theobalt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Single-shot multi-person 3D pose estimation from monocular RGB.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">3DV</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
M.Â Omran, C.Â Lassner, G.Â Pons-Moll, P.Â Gehler, and B.Â Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Neural body fitting: Unifying deep learning and model based human
pose and shape estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">3DV</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
G.Â Pavlakos, N.Â Kolotouros, and K.Â Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Texturepose: Supervising human mesh estimation with texture
consistency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Rong, Z.Â Liu, C.Â Li, K.Â Cao, and C.Â C. Loy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Delving deep into hybrid annotations for 3D human recovery in the
wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
J.Â L. SchÃ¶nberger and J.-M. Frahm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Structure-from-motion revisited.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
L.Â Sigal, A.Â Balan, and M.Â J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">HumanEva: Synchronized video and motion capture dataset and
baseline algorithm for evaluation of articulated human motion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IJCV</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 2010.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
G.Â Varol, D.Â Ceylan, B.Â Russell, J.Â Yang, E.Â Yumer, I.Â Laptev, and C.Â Schmid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">BodyNet: Volumetric inference of 3D human body shapes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
T.Â von Marcard, R.Â Henschel, M.Â Black, B.Â Rosenhahn, and G.Â Pons-Moll.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Recovering accurate 3D human pose in the wild using IMUs and a
moving camera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECCV</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
A.Â Zanfir, E.Â Marinoiu, M.Â Zanfir, A.-I. Popa, and C.Â Sminchisescu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Deep network for the integrated 3D sensing of multiple people in
natural images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NeurIPS</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Z.Â Zheng, T.Â Yu, Y.Â Wei, Q.Â Dai, and Y.Â Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Deephuman: 3D human reconstruction from a single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICCV</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 7739â€“7749, 2019.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Y.Â Zhou, C.Â Barnes, J.Â Lu, J.Â Yang, and H.Â Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">On the continuity of rotation representations in neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
H.Â Zhu, X.Â Zuo, S.Â Wang, X.Â Cao, and R.Â Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Detailed human shape estimation from a single image by hierarchical
mesh deformation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">CVPR</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2012.02742" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2012.02743" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2012.02743">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2012.02743" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2012.02744" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 02:55:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
