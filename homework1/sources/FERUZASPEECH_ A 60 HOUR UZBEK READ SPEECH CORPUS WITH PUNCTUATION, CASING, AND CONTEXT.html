<!DOCTYPE html><html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT</title>
<!--Generated on Mon Sep 23 02:52:39 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">




<base href="https://arxiv.org/html/2410.00035v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2410.00035v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2410.00035v1/#myForm">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2410.00035v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2410.00035v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S1" title="In FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S2" title="In FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>FeruzaSpeech Corpus</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S2.SS1" title="In 2 FeruzaSpeech Corpus ‣ FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Dataset Type</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S2.SS2" title="In 2 FeruzaSpeech Corpus ‣ FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Evaluation and Training Sets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S2.SS3" title="In 2 FeruzaSpeech Corpus ‣ FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Audio Format</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S2.SS4" title="In 2 FeruzaSpeech Corpus ‣ FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Sample Text</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S3" title="In FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S3.SS1" title="In 3 Experiments ‣ FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Pruned-transducer-stateless7 Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S3.SS2" title="In 3 Experiments ‣ FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Zipformer Model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S4" title="In FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S5" title="In FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#S6" title="In FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: tempora</li><li>failed: inconsolata</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a><div id="watermark-tr">arXiv:2410.00035v1 [eess.AS] 23 Sep 2024</div></div>
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">FERUZASPEECH: A 60 HOUR UZBEK READ SPEECH CORPUS WITH PUNCTUATION, CASING, AND CONTEXT</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anna Povey 
<br class="ltx_break">Redmond High School, WA, USA 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">annapovey@gmail.com</span>
<br class="ltx_break"><span class="ltx_ERROR undefined" id="id2.2.id2">\And</span>Katherine Povey 
<br class="ltx_break">University of Washington, USA 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">katherinepovey@gmail.com</span>
<br class="ltx_break">
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id4.id1"><span class="ltx_text" id="id4.id1.1">This paper introduces FeruzaSpeech, a read speech corpus of the Uzbek language, containing transcripts in both Cyrillic and Latin alphabets, freely available for academic research purposes. This corpus includes 60 hours of high-quality recordings from a single native female speaker from Tashkent, Uzbekistan. These recordings consist of short excerpts from a book and BBC News.
This paper discusses the enhancement of the Word Error Rates (WERs) on CommonVoice 16.1’s Uzbek data, Uzbek Speech Corpus data, and FeruzaSpeech data upon integrating FeruzaSpeech.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The Uzbek language, the official language of Uzbekistan, boasts upwards of 31 million native speakers across Central Asia. <span class="ltx_note ltx_role_footnote" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.worlddata.info/languages/uzbek.php" title="">https://www.worlddata.info/languages/uzbek.php</a></span></span></span>Advancement in neural network models and deep learning have significantly improved automated speech recognition (ASR) and text-to-speech (TTS) technology in recent decades. Large freely available English datasets, such as LibriSpeech <cite class="ltx_cite ltx_citemacro_cite">Panayotov et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib9" title="">2015</a>)</cite>, Libriheavy <cite class="ltx_cite ltx_citemacro_cite">Kang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib6" title="">2023b</a>)</cite>, and GigaSpeech <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib2" title="">2021</a>)</cite> are now more robust then ever, however, datasets for training these models in Uzbek are scarce.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In January 2023, the Uzbek government fully transitioned from using the Cyrillic alphabet to using the Latin alphabet
<span class="ltx_note ltx_role_footnote" id="footnotex2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://interfax.az/view/826747" title="">https://interfax.az/view/826747</a></span></span></span>, yet the country continues to use both alphabets. FeruzaSpeech is the first dataset to offer both Cyrillic and Latin transcription. To the best of our knowledge, FeruzaSpeech is also the only corpus to provide Cyrillic transcriptions at all. Datasets originally using Latin transcription cannot yet be accurately converted into Cyrillic text using online conversion calculators because there are a few discontinuities between the two alphabets. An example is when conversion calculators like this one<span class="ltx_note ltx_role_footnote" id="footnotex3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://uzlatin.com/" title="">https://uzlatin.com/</a></span></span></span> are used on Cyrillic text that include the soft sign <span class="ltx_text" id="S1.p2.1.1" lang="ru">ь</span>, it is either lost or can be incorrectly reproduced becoming a hard sign <span class="ltx_text" id="S1.p2.1.2" lang="ru">ъ</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S1.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Conversion Calculator on <span class="ltx_text" id="S1.T1.2.1" lang="ru">Польша</span></figcaption>
<table class="ltx_tabular ltx_align_middle" id="S1.T1.3">
<tbody><tr class="ltx_tr" id="S1.T1.3.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.1.1">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.1.1.1">
<span class="ltx_p" id="S1.T1.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S1.T1.3.1.1.1.1.1">Cyrillic to Latin</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S1.T1.3.1.2">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.1.2.1">
<span class="ltx_p" id="S1.T1.3.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S1.T1.3.1.2.1.1.1">Latin to Cyrillic</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S1.T1.3.2">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S1.T1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.2.1.1">
<span class="ltx_p" id="S1.T1.3.2.1.1.1"><span class="ltx_text" id="S1.T1.3.2.1.1.1.1" lang="ru">Пол<span class="ltx_text ltx_font_bold" id="S1.T1.3.2.1.1.1.1.1">ь</span>ша</span> -&gt; Pol’sha</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t" id="S1.T1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S1.T1.3.2.2.1">
<span class="ltx_p ltx_align_left" id="S1.T1.3.2.2.1.1">Pol’sha -&gt; <span class="ltx_text" id="S1.T1.3.2.2.1.1.1" lang="ru">Пол<span class="ltx_text ltx_font_bold" id="S1.T1.3.2.2.1.1.1.1">ъ</span>ша</span></span>
</span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">FeruzaSpeech aims to promote the development of speech recognition and speech synthesis technologies for the use of Uzbek speakers. Because this is a single speaker dataset with an absence of environmental noise it is better for STT when used in addition to other available speech corpuses. The dataset may be suitable for TTS applications, but such experiments are beyond the scope of this paper. It complements existing ASR datasets such Uzbek Speech Corpus (USC) <cite class="ltx_cite ltx_citemacro_cite">Musaev et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib8" title="">2021</a>)</cite>, consisting of 105 hours from 958 speakers, and the Common Voice Uzbek Dataset <cite class="ltx_cite ltx_citemacro_cite">Ardila et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib1" title="">2019</a>)</cite> <span class="ltx_note ltx_role_footnote" id="footnotex4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Download Page: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://commonvoice.mozilla.org/en/datasets" title="">https://commonvoice.mozilla.org/en/datasets</a></span></span></span>, with 265 hours from over 2,000 speakers. We chose these two corpuses because they were the only two other published datasets. When combined with these datasets, FeruzaSpeech enhances ASR model training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>FeruzaSpeech Corpus</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">This section describes the layout of the FeruzaSpeech corpus metadata, transcription, and audio format. Instructions for downloading and utilizing the data can be found on HuggingFace. <span class="ltx_note ltx_role_footnote" id="footnotex5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/k2speech/FeruzaSpeech" title="">https://huggingface.co/datasets/k2speech/FeruzaSpeech</a></span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Dataset Type</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">FeruzaSpeech consists of audio-book recordings from the texts of the book Choliqushi, a classic romance novel, and BBC Uzbek News read by our voice actress, Feruza. Table 2 shows the duration of each type of recording within the dataset. Initially read in the Cyrillic alphabet, the texts were converted to Latin using online tools<span class="ltx_note ltx_role_footnote" id="footnotex6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.lexilogos.com/keyboard/uzbek_conversion.htm" title="">https://www.lexilogos.com/keyboard/uzbek_conversion.htm</a>
and <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://uzlatin.com/" title="">https://uzlatin.com/</a></span></span></span>, with some grammatical errors being manually fixed after the use of the conversion calculator. The final transcription provides Uzbek text in both the Cyrillic and Latin alphabets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S2.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>FeruzaSpeech Recordings</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T2.3">
<tbody><tr class="ltx_tr" id="S2.T2.3.4">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T2.3.4.1"><span class="ltx_text ltx_font_bold" id="S2.T2.3.4.1.1">Type</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T2.3.4.2"><span class="ltx_text ltx_font_bold" id="S2.T2.3.4.2.1">Total</span></td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.2">Book</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T2.1.1.1">
<math alttext="21.57" class="ltx_Math" display="inline" id="S2.T2.1.1.1.m1.1"><semantics id="S2.T2.1.1.1.m1.1a"><mn id="S2.T2.1.1.1.m1.1.1" xref="S2.T2.1.1.1.m1.1.1.cmml">21.57</mn><annotation-xml encoding="MathML-Content" id="S2.T2.1.1.1.m1.1b"><cn id="S2.T2.1.1.1.m1.1.1.cmml" type="float" xref="S2.T2.1.1.1.m1.1.1">21.57</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.1.1.1.m1.1c">21.57</annotation><annotation encoding="application/x-llamapun" id="S2.T2.1.1.1.m1.1d">21.57</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S2.T2.2.2">
<td class="ltx_td ltx_align_right" id="S2.T2.2.2.2">BBC Uzbek</td>
<td class="ltx_td ltx_align_right" id="S2.T2.2.2.1">
<math alttext="38.04" class="ltx_Math" display="inline" id="S2.T2.2.2.1.m1.1"><semantics id="S2.T2.2.2.1.m1.1a"><mn id="S2.T2.2.2.1.m1.1.1" xref="S2.T2.2.2.1.m1.1.1.cmml">38.04</mn><annotation-xml encoding="MathML-Content" id="S2.T2.2.2.1.m1.1b"><cn id="S2.T2.2.2.1.m1.1.1.cmml" type="float" xref="S2.T2.2.2.1.m1.1.1">38.04</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.2.2.1.m1.1c">38.04</annotation><annotation encoding="application/x-llamapun" id="S2.T2.2.2.1.m1.1d">38.04</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S2.T2.3.3">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T2.3.3.2">Total</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T2.3.3.1">
<math alttext="59.61" class="ltx_Math" display="inline" id="S2.T2.3.3.1.m1.1"><semantics id="S2.T2.3.3.1.m1.1a"><mn id="S2.T2.3.3.1.m1.1.1" xref="S2.T2.3.3.1.m1.1.1.cmml">59.61</mn><annotation-xml encoding="MathML-Content" id="S2.T2.3.3.1.m1.1b"><cn id="S2.T2.3.3.1.m1.1.1.cmml" type="float" xref="S2.T2.3.3.1.m1.1.1">59.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T2.3.3.1.m1.1c">59.61</annotation><annotation encoding="application/x-llamapun" id="S2.T2.3.3.1.m1.1d">59.61</annotation></semantics></math>h</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Evaluation and Training Sets</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">FeruzaSpeech includes "Dev" (development), "Test" (testing), and "Train" (training) sets as detailed in Table 3. Both the Dev and Test sets only include BBC articles, while the Train set also includes the Choliqushi novel.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S2.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>FeruzaSpeech Sets</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T3.3">
<tbody><tr class="ltx_tr" id="S2.T3.3.4">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T3.3.4.1"><span class="ltx_text ltx_font_bold" id="S2.T3.3.4.1.1">Sets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T3.3.4.2"><span class="ltx_text ltx_font_bold" id="S2.T3.3.4.2.1">Total</span></td>
</tr>
<tr class="ltx_tr" id="S2.T3.1.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T3.1.1.2">Dev</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T3.1.1.1">
<math alttext="2.93" class="ltx_Math" display="inline" id="S2.T3.1.1.1.m1.1"><semantics id="S2.T3.1.1.1.m1.1a"><mn id="S2.T3.1.1.1.m1.1.1" xref="S2.T3.1.1.1.m1.1.1.cmml">2.93</mn><annotation-xml encoding="MathML-Content" id="S2.T3.1.1.1.m1.1b"><cn id="S2.T3.1.1.1.m1.1.1.cmml" type="float" xref="S2.T3.1.1.1.m1.1.1">2.93</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.1.1.1.m1.1c">2.93</annotation><annotation encoding="application/x-llamapun" id="S2.T3.1.1.1.m1.1d">2.93</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S2.T3.2.2">
<td class="ltx_td ltx_align_right" id="S2.T3.2.2.2">Test</td>
<td class="ltx_td ltx_align_right" id="S2.T3.2.2.1">
<math alttext="4.08" class="ltx_Math" display="inline" id="S2.T3.2.2.1.m1.1"><semantics id="S2.T3.2.2.1.m1.1a"><mn id="S2.T3.2.2.1.m1.1.1" xref="S2.T3.2.2.1.m1.1.1.cmml">4.08</mn><annotation-xml encoding="MathML-Content" id="S2.T3.2.2.1.m1.1b"><cn id="S2.T3.2.2.1.m1.1.1.cmml" type="float" xref="S2.T3.2.2.1.m1.1.1">4.08</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.2.2.1.m1.1c">4.08</annotation><annotation encoding="application/x-llamapun" id="S2.T3.2.2.1.m1.1d">4.08</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S2.T3.3.3">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T3.3.3.2">Train</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T3.3.3.1">
<math alttext="52.09" class="ltx_Math" display="inline" id="S2.T3.3.3.1.m1.1"><semantics id="S2.T3.3.3.1.m1.1a"><mn id="S2.T3.3.3.1.m1.1.1" xref="S2.T3.3.3.1.m1.1.1.cmml">52.09</mn><annotation-xml encoding="MathML-Content" id="S2.T3.3.3.1.m1.1b"><cn id="S2.T3.3.3.1.m1.1.1.cmml" type="float" xref="S2.T3.3.3.1.m1.1.1">52.09</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.3.3.1.m1.1c">52.09</annotation><annotation encoding="application/x-llamapun" id="S2.T3.3.3.1.m1.1d">52.09</annotation></semantics></math>h</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Audio Format</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The corpus contains high-quality, single-channel, 16-bit .wav audio files, available in 16kHz for ASR. The average recording length is 16.39 seconds, the minimum length is 3.78 seconds, and the maximum length is 50.69 seconds. Our segments are recordings of one to two full sentence and are much longer than the segments of USC <cite class="ltx_cite ltx_citemacro_cite">Musaev et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib8" title="">2021</a>)</cite>, that are mostly 2 to 3 seconds.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="152" id="S2.F1.g1" src="https://arxiv.org/html/2410.00035v1/extracted/5872123/segment_graph.png" width="219">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Length of FeruzaSpeech Segments</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Sample Text</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Table 4 shows example excerpts from the CommonVoice and USC datasets in comparison to our proposed FeruzaSpeech dataset.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S2.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>One Sentence of Sample Text from each of the Three Datasets with English Translation That Is Not in the Dataset for Reader</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S2.T4.1">
<tbody><tr class="ltx_tr" id="S2.T4.1.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S2.T4.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.1.1.1">
<span class="ltx_p" id="S2.T4.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T4.1.1.1.1.1.1">CommonVoice</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T4.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.1.2.1">
<span class="ltx_p" id="S2.T4.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.T4.1.1.2.1.1.1">USC</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T4.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.1.3.1">
<span class="ltx_p" id="S2.T4.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S2.T4.1.1.3.1.1.1">FeruzaSpeech</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T4.1.2">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S2.T4.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.2.1.1">
<span class="ltx_p" id="S2.T4.1.2.1.1.1">— Non dema! — dedi. — Nonni otini atama!</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T4.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.2.2.1">
<span class="ltx_p" id="S2.T4.1.2.2.1.1">shundan so’ng u sen aytmasang men aytaman degandek qaradi</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T4.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.2.3.1">
<span class="ltx_p" id="S2.T4.1.2.3.1.1">20 iyul kuni O‘zbekistonda 562 holatda kasallik qayd etilgan.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T4.1.3">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S2.T4.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.3.1.1">
<span class="ltx_p" id="S2.T4.1.3.1.1.1">— Don’t say bread! — he said. — Don’t utter the word bread!</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t" id="S2.T4.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.3.2.1">
<span class="ltx_p ltx_align_left" id="S2.T4.1.3.2.1.1">after that he looked like if you don’t tell I will</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r ltx_border_t" id="S2.T4.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T4.1.3.3.1">
<span class="ltx_p" id="S2.T4.1.3.3.1.1">On July 20, 562 cases of the disease were recorded in Uzbekistan.</span>
</span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">We can see that CommonVoice text was normalized but it has punctuation and casing, USC text is normalized to remove casing and punctuation, and FeruzaSpeech retains casing and punctuation. Regarding the choice to not normalize casing or punctuation, deep learning models have recently become powerful enough that for tasks like ASR and TTS it is now feasible to use "natural" text with no normalization. For instance, the recent E2TTS text-to-speech system <cite class="ltx_cite ltx_citemacro_cite">Eskimez et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib3" title="">2024</a>)</cite> is trained on data from Libriheavy <cite class="ltx_cite ltx_citemacro_cite">Kang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib7" title="">2024</a>)</cite> which is completely un-normalized. The use of un-normalized text for training tends to simplify speech processing systems because it could avoid the need for text normalization and inverse text normalization modules. Table 5 shows how the transcripts were provided in Latin and Cyrillic, but within this paper we only used Latin transcripts for comparison with available Latin datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S2.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>FeruzaSpeech Excerpt in Latin and Cyrillic with English Translation That Is Not in the Dataset for Reader</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S2.T5.1">
<tbody><tr class="ltx_tr" id="S2.T5.1.1">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S2.T5.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T5.1.1.1.1">
<span class="ltx_p" id="S2.T5.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T5.1.1.1.1.1.1">FeruzaSpeech Latin</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T5.1.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T5.1.1.2.1">
<span class="ltx_p" id="S2.T5.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.T5.1.1.2.1.1.1">FeruzaSpeech Cyrillic</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.2">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" id="S2.T5.1.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T5.1.2.1.1">
<span class="ltx_p" id="S2.T5.1.2.1.1.1">Ayni damda ishlatilib turilgan biometrik pasportlar 2019 yil 1 yanvardan deyarli yaroqsiz holatga keladi.</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" id="S2.T5.1.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">
<span class="ltx_inline-block ltx_align_top" id="S2.T5.1.2.2.1">
<span class="ltx_p" id="S2.T5.1.2.2.1.1"><span class="ltx_text" id="S2.T5.1.2.2.1.1.1" lang="ru">Айни дамда ишлатилиб турилган биометрик паспортлар 2019 йил 1 январдан деярли яроқсиз ҳолатга келади.</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.3">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r ltx_border_t" colspan="2" id="S2.T5.1.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">Biometric passports, which are currently in use,</td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.4">
<td class="ltx_td ltx_align_justify ltx_border_l ltx_border_r" colspan="2" id="S2.T5.1.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">will become almost useless from January 1,</td>
</tr>
<tr class="ltx_tr" id="S2.T5.1.5">
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_l ltx_border_r" colspan="2" id="S2.T5.1.5.1" style="padding-left:3.0pt;padding-right:3.0pt;">2019.</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To build our models we utilized the Next-Gen Kaldi framework and followed two recipes; the Icefall CommonVoice Stateless RNN-T Conformer model taken from the pruned_transducer_stateless7 recipe<span class="ltx_note ltx_role_footnote" id="footnotex7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/k2-fsa/icefall/tree/master/egs/commonvoice/ASR/pruned_transducer_stateless7" title="">https://github.com/k2-fsa/icefall/tree/master/egs/commonvoice/ASR/pruned_transducer_stateless7</a></span></span></span> and the Librispeech zipformer<span class="ltx_note ltx_role_footnote" id="footnotex8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer" title="">https://github.com/k2-fsa/icefall/tree/master/egs/librispeech/ASR/zipformer</a></span></span></span>, noting significant improvements in WER. These two models were selected because Icefall already contains CommonVoice scripts using
pruned_transducer_stateless7 in the French language and Librispeech zipformer is the current state of the art model in Next-Gen Kaldi. In our experiments we utilized three datasets: Common Voice 16.1 (CV), FeruzaSpeech (FS), and Uzbek Speech Corpus (USC). All models were trained for 60 epochs. Table 6 outlines the duration of each training dataset.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Training Dataset Duration </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T6.4">
<tbody><tr class="ltx_tr" id="S3.T6.4.5">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.4.5.1"><span class="ltx_text ltx_font_bold" id="S3.T6.4.5.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T6.4.5.2"><span class="ltx_text ltx_font_bold" id="S3.T6.4.5.2.1">Training Duration</span></td>
</tr>
<tr class="ltx_tr" id="S3.T6.1.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T6.1.1.2">CV</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T6.1.1.1">
<math alttext="54.88" class="ltx_Math" display="inline" id="S3.T6.1.1.1.m1.1"><semantics id="S3.T6.1.1.1.m1.1a"><mn id="S3.T6.1.1.1.m1.1.1" xref="S3.T6.1.1.1.m1.1.1.cmml">54.88</mn><annotation-xml encoding="MathML-Content" id="S3.T6.1.1.1.m1.1b"><cn id="S3.T6.1.1.1.m1.1.1.cmml" type="float" xref="S3.T6.1.1.1.m1.1.1">54.88</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.1.1.1.m1.1c">54.88</annotation><annotation encoding="application/x-llamapun" id="S3.T6.1.1.1.m1.1d">54.88</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S3.T6.2.2">
<td class="ltx_td ltx_align_right" id="S3.T6.2.2.2">FS</td>
<td class="ltx_td ltx_align_right" id="S3.T6.2.2.1">
<math alttext="52.09" class="ltx_Math" display="inline" id="S3.T6.2.2.1.m1.1"><semantics id="S3.T6.2.2.1.m1.1a"><mn id="S3.T6.2.2.1.m1.1.1" xref="S3.T6.2.2.1.m1.1.1.cmml">52.09</mn><annotation-xml encoding="MathML-Content" id="S3.T6.2.2.1.m1.1b"><cn id="S3.T6.2.2.1.m1.1.1.cmml" type="float" xref="S3.T6.2.2.1.m1.1.1">52.09</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.2.2.1.m1.1c">52.09</annotation><annotation encoding="application/x-llamapun" id="S3.T6.2.2.1.m1.1d">52.09</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S3.T6.3.3">
<td class="ltx_td ltx_align_right" id="S3.T6.3.3.2">USC</td>
<td class="ltx_td ltx_align_right" id="S3.T6.3.3.1">
<math alttext="90.70" class="ltx_Math" display="inline" id="S3.T6.3.3.1.m1.1"><semantics id="S3.T6.3.3.1.m1.1a"><mn id="S3.T6.3.3.1.m1.1.1" xref="S3.T6.3.3.1.m1.1.1.cmml">90.70</mn><annotation-xml encoding="MathML-Content" id="S3.T6.3.3.1.m1.1b"><cn id="S3.T6.3.3.1.m1.1.1.cmml" type="float" xref="S3.T6.3.3.1.m1.1.1">90.70</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.3.3.1.m1.1c">90.70</annotation><annotation encoding="application/x-llamapun" id="S3.T6.3.3.1.m1.1d">90.70</annotation></semantics></math>h</td>
</tr>
<tr class="ltx_tr" id="S3.T6.4.4">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T6.4.4.2">CV + FS + USC</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T6.4.4.1">
<math alttext="197.68" class="ltx_Math" display="inline" id="S3.T6.4.4.1.m1.1"><semantics id="S3.T6.4.4.1.m1.1a"><mn id="S3.T6.4.4.1.m1.1.1" xref="S3.T6.4.4.1.m1.1.1.cmml">197.68</mn><annotation-xml encoding="MathML-Content" id="S3.T6.4.4.1.m1.1b"><cn id="S3.T6.4.4.1.m1.1.1.cmml" type="float" xref="S3.T6.4.4.1.m1.1.1">197.68</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T6.4.4.1.m1.1c">197.68</annotation><annotation encoding="application/x-llamapun" id="S3.T6.4.4.1.m1.1d">197.68</annotation></semantics></math>h</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Pruned-transducer-stateless7 Model</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The Stateless RNN-T Conformer model <cite class="ltx_cite ltx_citemacro_cite">Kang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib5" title="">2023a</a>)</cite> is a stateless transducer <cite class="ltx_cite ltx_citemacro_cite">Gulati et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib4" title="">2020</a>)</cite> with a conformer encoder that reduces memory consumption, and it outperformed the small zipformer model for every test set. All models in Tables 7 and 8 are trained with Casing and Punctuation. Table 7 presents the WERs when the model is scored with Casing and Punctuation, while Table 8 presents the WERs when the model is scored with Uppercase No Punctuation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>The WERs of <span class="ltx_text ltx_font_bold" id="S3.T7.3.1">Stateless RNN-T Conformer model</span> scored with <span class="ltx_text ltx_font_bold" id="S3.T7.4.2">Casing and Punctuation (C&amp;P)</span> Common Voice 16.1 (CV), Uzbek Speech Corpus (USC), FeruzaSpeech (FS)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T7.5">
<tbody><tr class="ltx_tr" id="S3.T7.5.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.1.1"><span class="ltx_text ltx_font_bold" id="S3.T7.5.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.1.2"><span class="ltx_text ltx_font_bold" id="S3.T7.5.1.2.1">Dataset</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.1.3"><span class="ltx_text ltx_font_bold" id="S3.T7.5.1.3.1">cv-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.1.4"><span class="ltx_text ltx_font_bold" id="S3.T7.5.1.4.1">fs-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.1.5"><span class="ltx_text ltx_font_bold" id="S3.T7.5.1.5.1">usc-test</span></td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.2.1" rowspan="2"><span class="ltx_text" id="S3.T7.5.2.1.1"><span class="ltx_text" id="S3.T7.5.2.1.1.1"></span> <span class="ltx_text" id="S3.T7.5.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T7.5.2.1.1.2.1">
<span class="ltx_tr" id="S3.T7.5.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T7.5.2.1.1.2.1.1.1">greedy</span></span>
<span class="ltx_tr" id="S3.T7.5.2.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T7.5.2.1.1.2.1.2.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T7.5.2.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.2.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.2.3">33.95</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.2.4">32.9</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.2.5">51.07</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.3">
<td class="ltx_td ltx_align_left" id="S3.T7.5.3.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.3.2">89.54</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.3.3">11.58</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.3.4">85.67</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.4">
<td class="ltx_td" id="S3.T7.5.4.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.4.2">CV+FS</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.4.3">32.49</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.4.4">9.93</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.4.5">46.89</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.5">
<td class="ltx_td" id="S3.T7.5.5.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.5.2">CV+FS+USC</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.5.3">29.91</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.5.4">9.79</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.5.5">12.05</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.6.1" rowspan="2"><span class="ltx_text" id="S3.T7.5.6.1.1"><span class="ltx_text" id="S3.T7.5.6.1.1.1"></span> <span class="ltx_text" id="S3.T7.5.6.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T7.5.6.1.1.2.1">
<span class="ltx_tr" id="S3.T7.5.6.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T7.5.6.1.1.2.1.1.1">modified</span></span>
<span class="ltx_tr" id="S3.T7.5.6.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T7.5.6.1.1.2.1.2.1">beam</span></span>
<span class="ltx_tr" id="S3.T7.5.6.1.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T7.5.6.1.1.2.1.3.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T7.5.6.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.6.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.6.3">31.98</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.6.4">31.88</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T7.5.6.5">51.61</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.7">
<td class="ltx_td ltx_align_left" id="S3.T7.5.7.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.7.2">89.10</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.7.3">11.25</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.7.4">85.22</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.8">
<td class="ltx_td" id="S3.T7.5.8.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.8.2">CV+FS</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.8.3">30.47</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.8.4">9.85</td>
<td class="ltx_td ltx_align_left" id="S3.T7.5.8.5">48.6</td>
</tr>
<tr class="ltx_tr" id="S3.T7.5.9">
<td class="ltx_td ltx_border_b" id="S3.T7.5.9.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T7.5.9.2">CV+FS+USC</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T7.5.9.3">27.81</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T7.5.9.4">9.56</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T7.5.9.5">11.67</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>The WERs of <span class="ltx_text ltx_font_bold" id="S3.T8.3.1">Stateless RNN-T Conformer</span> model scored with <span class="ltx_text ltx_font_bold" id="S3.T8.4.2">Uppercase No Punctuation (UNP)</span> Common Voice 16.1 (CV), Uzbek Speech Corpus (USC), and FeruzaSpeech (FS)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T8.5">
<tbody><tr class="ltx_tr" id="S3.T8.5.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.1.1"><span class="ltx_text ltx_font_bold" id="S3.T8.5.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.1.2"><span class="ltx_text ltx_font_bold" id="S3.T8.5.1.2.1">Dataset</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.1.3"><span class="ltx_text ltx_font_bold" id="S3.T8.5.1.3.1">cv-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.1.4"><span class="ltx_text ltx_font_bold" id="S3.T8.5.1.4.1">fs-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.1.5"><span class="ltx_text ltx_font_bold" id="S3.T8.5.1.5.1">usc-test</span></td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.2.1" rowspan="2"><span class="ltx_text" id="S3.T8.5.2.1.1"><span class="ltx_text" id="S3.T8.5.2.1.1.1"></span> <span class="ltx_text" id="S3.T8.5.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T8.5.2.1.1.2.1">
<span class="ltx_tr" id="S3.T8.5.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T8.5.2.1.1.2.1.1.1">greedy</span></span>
<span class="ltx_tr" id="S3.T8.5.2.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T8.5.2.1.1.2.1.2.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T8.5.2.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.2.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.2.3">21.03</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.2.4">20.15</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.2.5">35.11</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.3">
<td class="ltx_td ltx_align_left" id="S3.T8.5.3.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.3.2">87.18</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.3.3">5.85</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.3.4">77.78</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.4">
<td class="ltx_td" id="S3.T8.5.4.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.4.2">CV+FS</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.4.3">18.91</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.4.4">4.44</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.4.5">30.53</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.5">
<td class="ltx_td" id="S3.T8.5.5.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.5.2">CV+FS+USC</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.5.3">12.07</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.5.4">4.17</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.5.5">12.05</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.6.1" rowspan="2"><span class="ltx_text" id="S3.T8.5.6.1.1"><span class="ltx_text" id="S3.T8.5.6.1.1.1"></span> <span class="ltx_text" id="S3.T8.5.6.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T8.5.6.1.1.2.1">
<span class="ltx_tr" id="S3.T8.5.6.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T8.5.6.1.1.2.1.1.1">modified</span></span>
<span class="ltx_tr" id="S3.T8.5.6.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T8.5.6.1.1.2.1.2.1">beam</span></span>
<span class="ltx_tr" id="S3.T8.5.6.1.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T8.5.6.1.1.2.1.3.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T8.5.6.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.6.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.6.3">20.16</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.6.4">19.34</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T8.5.6.5">34.03</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.7">
<td class="ltx_td ltx_align_left" id="S3.T8.5.7.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.7.2">86.26</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.7.3">5.50</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.7.4">76.24</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.8">
<td class="ltx_td" id="S3.T8.5.8.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.8.2">CV+FS</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.8.3">18.33</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.8.4">4.24</td>
<td class="ltx_td ltx_align_left" id="S3.T8.5.8.5">29.67</td>
</tr>
<tr class="ltx_tr" id="S3.T8.5.9">
<td class="ltx_td ltx_border_b" id="S3.T8.5.9.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.5.9.2">CV+FS+USC</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.5.9.3">11.17</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.5.9.4">4.05</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T8.5.9.5">11.67</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Zipformer Model</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We followed a similar procedure for the zipformer model as we did for the Stateless RNN-T Conformer model. This time, we trained a separate model on each of the following three datasets: CV, FS, CV+FS. This differs from the previous section because we excluded the USC training set. Once again, we recorded the WER for each model when
tested on each of the following test sets: cv-test, fs-test, and usc-
test, sharing results for both the greedy search and modified beam search as methods of decoding. All models in Table 9 and 10 are trained with Casing and Punctuation. Table 9 presents the WERs when the model is scored with Casing and Punctuation, while Table 10 presents the WERs when the model is scored with Uppercase No Punctuation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Note that the Common Voice recipe with default settings in the Icefall project wasn’t converging for zipformer <cite class="ltx_cite ltx_citemacro_cite">Kang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib6" title="">2023b</a>)</cite>, so we used "small zipformer" <span class="ltx_note ltx_role_footnote" id="footnotex9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/k2-fsa/icefall/blob/master/egs/librispeech/ASR/RESULTS.md" title="">https://github.com/k2-fsa/icefall/blob/master/egs/librispeech/ASR/RESULTS.md</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Yao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib10" title="">2024</a>)</cite> parameters to account for the size of our datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>The WERs of <span class="ltx_text ltx_font_bold" id="S3.T9.3.1">zipformer</span> model scored with <span class="ltx_text ltx_font_bold" id="S3.T9.4.2">Casing and Punctuation (C&amp;P)</span> Common Voice 16.1 (CV) and FeruzaSpeech (FS)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T9.5">
<tbody><tr class="ltx_tr" id="S3.T9.5.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.1.1"><span class="ltx_text ltx_font_bold" id="S3.T9.5.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.1.2"><span class="ltx_text ltx_font_bold" id="S3.T9.5.1.2.1">Dataset</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.1.3"><span class="ltx_text ltx_font_bold" id="S3.T9.5.1.3.1">cv-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.1.4"><span class="ltx_text ltx_font_bold" id="S3.T9.5.1.4.1">fs-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.1.5"><span class="ltx_text ltx_font_bold" id="S3.T9.5.1.5.1">usc-test</span></td>
</tr>
<tr class="ltx_tr" id="S3.T9.5.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.2.1" rowspan="2"><span class="ltx_text" id="S3.T9.5.2.1.1"><span class="ltx_text" id="S3.T9.5.2.1.1.1"></span> <span class="ltx_text" id="S3.T9.5.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T9.5.2.1.1.2.1">
<span class="ltx_tr" id="S3.T9.5.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T9.5.2.1.1.2.1.1.1">greedy</span></span>
<span class="ltx_tr" id="S3.T9.5.2.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T9.5.2.1.1.2.1.2.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T9.5.2.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.2.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.2.3">37.00</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.2.4">34.54</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.2.5">53.4</td>
</tr>
<tr class="ltx_tr" id="S3.T9.5.3">
<td class="ltx_td ltx_align_left" id="S3.T9.5.3.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.3.2">93.09</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.3.3">14.32</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.3.4">N/A</td>
</tr>
<tr class="ltx_tr" id="S3.T9.5.4">
<td class="ltx_td" id="S3.T9.5.4.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.4.2">CV+FS</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.4.3">35.90</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.4.4">11.05</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.4.5">52.86</td>
</tr>
<tr class="ltx_tr" id="S3.T9.5.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.5.1" rowspan="2"><span class="ltx_text" id="S3.T9.5.5.1.1"><span class="ltx_text" id="S3.T9.5.5.1.1.1"></span> <span class="ltx_text" id="S3.T9.5.5.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T9.5.5.1.1.2.1">
<span class="ltx_tr" id="S3.T9.5.5.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T9.5.5.1.1.2.1.1.1">modified</span></span>
<span class="ltx_tr" id="S3.T9.5.5.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T9.5.5.1.1.2.1.2.1">beam</span></span>
<span class="ltx_tr" id="S3.T9.5.5.1.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T9.5.5.1.1.2.1.3.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T9.5.5.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.5.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.5.3">33.96</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.5.4">32.41</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T9.5.5.5">54.07</td>
</tr>
<tr class="ltx_tr" id="S3.T9.5.6">
<td class="ltx_td ltx_align_left" id="S3.T9.5.6.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.6.2">92.61</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.6.3">13.28</td>
<td class="ltx_td ltx_align_left" id="S3.T9.5.6.4">N/A</td>
</tr>
<tr class="ltx_tr" id="S3.T9.5.7">
<td class="ltx_td ltx_border_b" id="S3.T9.5.7.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T9.5.7.2">CV+FS</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T9.5.7.3">33.15</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T9.5.7.4">10.75</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T9.5.7.5">53.08</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>The WERs of <span class="ltx_text ltx_font_bold" id="S3.T10.3.1">zipformer</span> model scored with <span class="ltx_text ltx_font_bold" id="S3.T10.4.2">Uppercase No Punctuation (UNP)</span> Common Voice 16.1 (CV) and FeruzaSpeech (FS)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T10.5">
<tbody><tr class="ltx_tr" id="S3.T10.5.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.1.1"><span class="ltx_text ltx_font_bold" id="S3.T10.5.1.1.1">Method</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.1.2"><span class="ltx_text ltx_font_bold" id="S3.T10.5.1.2.1">Dataset</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.1.3"><span class="ltx_text ltx_font_bold" id="S3.T10.5.1.3.1">cv-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.1.4"><span class="ltx_text ltx_font_bold" id="S3.T10.5.1.4.1">fs-test</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.1.5"><span class="ltx_text ltx_font_bold" id="S3.T10.5.1.5.1">usc-test</span></td>
</tr>
<tr class="ltx_tr" id="S3.T10.5.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.2.1" rowspan="2"><span class="ltx_text" id="S3.T10.5.2.1.1"><span class="ltx_text" id="S3.T10.5.2.1.1.1"></span> <span class="ltx_text" id="S3.T10.5.2.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T10.5.2.1.1.2.1">
<span class="ltx_tr" id="S3.T10.5.2.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T10.5.2.1.1.2.1.1.1">greedy</span></span>
<span class="ltx_tr" id="S3.T10.5.2.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T10.5.2.1.1.2.1.2.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T10.5.2.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.2.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.2.3">23.01</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.2.4">20.94</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.2.5">38.75</td>
</tr>
<tr class="ltx_tr" id="S3.T10.5.3">
<td class="ltx_td ltx_align_left" id="S3.T10.5.3.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.3.2">91.34</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.3.3">8.97</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.3.4">N/A</td>
</tr>
<tr class="ltx_tr" id="S3.T10.5.4">
<td class="ltx_td" id="S3.T10.5.4.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.4.2">CV+FS</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.4.3">22.34</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.4.4">5.45</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.4.5">37.4</td>
</tr>
<tr class="ltx_tr" id="S3.T10.5.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.5.1" rowspan="2"><span class="ltx_text" id="S3.T10.5.5.1.1"><span class="ltx_text" id="S3.T10.5.5.1.1.1"></span> <span class="ltx_text" id="S3.T10.5.5.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T10.5.5.1.1.2.1">
<span class="ltx_tr" id="S3.T10.5.5.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T10.5.5.1.1.2.1.1.1">modified</span></span>
<span class="ltx_tr" id="S3.T10.5.5.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T10.5.5.1.1.2.1.2.1">beam</span></span>
<span class="ltx_tr" id="S3.T10.5.5.1.1.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T10.5.5.1.1.2.1.3.1">search</span></span>
</span></span> <span class="ltx_text" id="S3.T10.5.5.1.1.3"></span></span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.5.2">CV</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.5.3">21.92</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.5.4">20.21</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T10.5.5.5">37.44</td>
</tr>
<tr class="ltx_tr" id="S3.T10.5.6">
<td class="ltx_td ltx_align_left" id="S3.T10.5.6.1">FS</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.6.2">90.54</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.6.3">7.88</td>
<td class="ltx_td ltx_align_left" id="S3.T10.5.6.4">N/A</td>
</tr>
<tr class="ltx_tr" id="S3.T10.5.7">
<td class="ltx_td ltx_border_b" id="S3.T10.5.7.1"></td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T10.5.7.2">CV+FS</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T10.5.7.3">21.35</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T10.5.7.4">5.10</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S3.T10.5.7.5">35.94</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">When adding the FeruzaSpeech dataset to the CommonVoice16.1 dataset while training the Stateless RNN-T Conformer model, WER improved 1.49 to 2.12 percent absolutely on cv-test and 3.01 to 4.58 percent absolutely on usc-test in Tables 7 and 8. And for the Zipformer model, WER improved 0.57 to 1.1 percent absolutely on cv-test and 0.54 to 1.5 percent absolutely on usc-test in tables 9 and 10. This shows that FeruzaSpeech contains quality data and is a useful addition to the current public library of Uzbek speech corpuses for TTS applications.
Also, the paper presenting the USC dataset <cite class="ltx_cite ltx_citemacro_cite">Musaev et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.00035v1#bib.bib8" title="">2021</a>)</cite> reports that the usc-test had a WER of 17.4%. Our best result for the usc-test WER is 11.67%, which is an improvement of 5.73%.
According to Table 6 and 7, when a Stateless RNN-T Conformer model was built using all three datasets combined: CV, FS, and USC, and using modified beam search as the decoding method, the model produced the best WERs for every test. Our best recorded WER on the Common Voice test set is 11.17%, as shown in Table 7. The best WER for the FeruzaSpeech test set is 4.05%, and the best WER for the Uzbek Speech Corpus test is 11.67%.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The development of FeruzaSpeech is a significant step forward in the field of Uzbek speech technology. By offering a dual alphabet corpus, this project bridges the gap between the use of Cyrillic and Latin scripts for Uzbek speakers. Our work also highlights the need for accurate alphabet conversion tools, specifically for more nuanced aspects of the language such as the soft sign (<span class="ltx_text" id="S5.p1.1.1" lang="ru">ь</span>), which tends to be lost in translation from Cyrillic to Latin.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Through integrating FeruzaSpeech with existing Uzbek datasets, notable improvements in WERs were demonstrated. In the future, we will provide this same data in a higher sampling rate and bit depth that will be more suitable for TTS. Since we recognize the value of continuity in voice data for TTS applications, our future endeavors will also focus on expanding this corpus with additional recordings from the same native speaker. This strategy aims to enrich the dataset with consistent voice quality and style across the corpus which is essential for developing TTS models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">In sum, FeruzaSpeech is beneficial for ASR model enhancement when used in addition to existing Uzbek language datasets, as observed in WER improvements. Applications of this dataset for TTS will also be explored.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">FeruzaSpeech is not an effective stand alone corpus for STT applications and should be used in compliment with other corpuses such as the Common Voice Uzbek Dataset and Uzbek Speech Corpus explored above. FeruzaSpeech has an average segment length of 16.39 seconds which each contain one or two full sentences which could be segmented into shorter utterances. The audio has no background noise and contains a singular female speaker which is not optimal for STT.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ardila et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler, Josh Meyer, Reuben Morais, Lindsay Saunders, Francis&nbsp;M Tyers, and Gregor Weber. 2019.

</span>
<span class="ltx_bibblock">Common voice: A massively-multilingual speech corpus.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:1912.06670</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guoguo Chen, Shuzhou Chai, Guanbo Wang, Jiayu Du, Wei-Qiang Zhang, Chao Weng, Dan Su, Daniel Povey, Jan Trmal, Junbo Zhang, Mingjie Jin, Sanjeev Khudanpur, Shinji Watanabe, Shuaijiang Zhao, Wei Zou, Xiangang Li, Xuchen Yao, Yongqing Wang, Yujun Wang, Zhao You, and Zhiyong Yan. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2106.06909" title="">Gigaspeech: An evolving, multi-domain asr corpus with 10,000 hours of transcribed audio</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eskimez et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sefik&nbsp;Emre Eskimez, Xiaofei Wang, Manthan Thakker, Canrun Li, Chung-Hsien Tsai, Zhen Xiao, Hemin Yang, Zirun Zhu, Min Tang, Xu&nbsp;Tan, Yanqing Liu, Sheng Zhao, and Naoyuki Kanda. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2406.18009" title="">E2 tts: Embarrassingly easy fully non-autoregressive zero-shot tts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gulati et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu&nbsp;Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, and Ruoming Pang. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2005.08100" title="">Conformer: Convolution-augmented transformer for speech recognition</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei Kang, Liyong Guo, Fangjun Kuang, Long Lin, Mingshuang Luo, Zengwei Yao, Xiaoyu Yang, Piotr Żelasko, and Daniel Povey. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICASSP49357.2023.10094567" title="">Fast and parallel decoding for transducer</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei Kang, Xiaoyu Yang, Zengwei Yao, Fangjun Kuang, Yifan Yang, Liyong Guo, Long Lin, and Daniel Povey. 2023b.

</span>
<span class="ltx_bibblock">Libriheavy: a 50,000 hours asr corpus with punctuation casing and context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2309.08105</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei Kang, Xiaoyu Yang, Zengwei Yao, Fangjun Kuang, Yifan Yang, Liyong Guo, Long Lin, and Daniel Povey. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.08105" title="">Libriheavy: a 50,000 hours asr corpus with punctuation casing and context</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Musaev et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Muhammadjon Musaev, Saida Mussakhojayeva, Ilyos Khujayorov, Yerbolat Khassanov, Mannon Ochilov, and Huseyin Atakan&nbsp;Varol. 2021.

</span>
<span class="ltx_bibblock">Usc: An open-source uzbek speech corpus and initial speech recognition experiments.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Speech and Computer: 23rd International Conference, SPECOM 2021, St. Petersburg, Russia, September 27–30, 2021, Proceedings 23</em>, pages 437–447. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Panayotov et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICASSP.2015.7178964" title="">Librispeech: An asr corpus based on public domain audio books</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pages 5206–5210.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zengwei Yao, Liyong Guo, Xiaoyu Yang, Wei Kang, Fangjun Kuang, Yifan Yang, Zengrui Jin, Long Lin, and Daniel Povey. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.11230" title="">Zipformer: A faster and better encoder for automatic speech recognition</a>.

</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>