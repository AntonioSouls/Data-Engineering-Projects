<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2301.09906] Transfer Learning for Olfactory Object Detection</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Transfer Learning for Olfactory Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Transfer Learning for Olfactory Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2301.09906">

<!--Generated on Fri Mar  1 05:23:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Transfer Learning for Olfactory Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mathias Zinnen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text" style="font-size:90%;">Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg (FAU), 91058 Erlangen, Germany</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Prathmesh Madhu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.1.id1" class="ltx_text" style="font-size:90%;">Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg (FAU), 91058 Erlangen, Germany</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Peter Bell
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Germanistik und Kunstwissenschaften (Fb09), Philipps-UniversitÃ¤t Marburg, 35032 Marburg, Germany
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andreas Maier
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id3.1.id1" class="ltx_text" style="font-size:90%;">Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg (FAU), 91058 Erlangen, Germany</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vincent Christlein
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text" style="font-size:90%;">Pattern Recognition Lab, Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg (FAU), 91058 Erlangen, Germany</span>
</span></span></span>
</div>

<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text" style="font-size:90%;">Smells are an important, yet overlooked part of cultural heritage </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a><span id="S1.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.4" class="ltx_text" style="font-size:90%;">.
The Odeuropa project</span><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>www.odeuropa.eu</span></span></span><span id="S1.p1.1.5" class="ltx_text" style="font-size:90%;"> analyzes large amounts of visual and textual corpora to investigate the cultural dimensions of smell in 16th â€“ 20th century Europe. The study of pictorial representations bears a specific challenge:
the substrate of smell is usually invisible </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p1.1.6.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a><span id="S1.p1.1.7.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p1.1.8" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text" style="font-size:90%;">Object detection is a well-researched computer vision technique, and so we start with the recognition of objects, which may then serve as a basis for the indirect recognition of more complex, and possibly more meaningful, smell references such as gestures, spaces, or iconographic allusions </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a><span id="S1.p2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p2.1.4" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2301.09906/assets/sniff2.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="840" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.5.1" class="ltx_text ltx_font_italic">Smell</span>. The Five Senses. 1558 â€“ 1617. Jan Pietersz Saenredam. National Gallery of Art. Public Domain</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="font-size:90%;">However, the detection of olfactory objects in historical artworks is a challenging task.
The visual representation of objects differs significantly between artworks and photographs </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a><span id="S1.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.4" class="ltx_text" style="font-size:90%;">. Since state-of-the-art object detection algorithms are trained and evaluated on large-scale photographic datasets such as ImageNet </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a><span id="S1.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.7" class="ltx_text" style="font-size:90%;">, MS COCO </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a><span id="S1.p3.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.10" class="ltx_text" style="font-size:90%;">, or OpenImages </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.11.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a><span id="S1.p3.1.12.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.13" class="ltx_text" style="font-size:90%;">, their performance drops significantly when applied to artistic data.
This </span><em id="S1.p3.1.14" class="ltx_emph ltx_font_italic" style="font-size:90%;">domain gap</em><span id="S1.p3.1.15" class="ltx_text" style="font-size:90%;"> between standard object detection datasets and artistic imagery can be mitigated by training directly on artworks, either by using existing datasets or by creating an annotated dataset for the target domain.
Another challenge is the mismatch between object categories present in modern datasets and historical olfactory objects, caused by historical diachrony on the one hand </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.16.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a><span id="S1.p3.1.17.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.18" class="ltx_text" style="font-size:90%;">, and the particularity of some smell-relevant objects on the other</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.19.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a><span id="S1.p3.1.20.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.21" class="ltx_text" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1.p3.1.22.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a><span id="S1.p3.1.23.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S1.p3.1.24" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<figure id="S2.F2" class="ltx_figure"><img src="/html/2301.09906/assets/venn.jpg" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="826" height="519" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Category overlap between Odeuropa &amp; OpenImages categories</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text" style="font-size:90%;">To overcome the domain gap and category mismatch between our application and the existing datasets, we apply transfer learning â€“ a training strategy where machine learning algorithms are pre-trained in one domain and then fine-tuned in another, greatly decreasing the amount of required training data in the target domain (</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a><span id="S2.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.4" class="ltx_text" style="font-size:90%;">,</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a><span id="S2.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.7" class="ltx_text" style="font-size:90%;">,</span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p1.1.8.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a><span id="S2.p1.1.9.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p1.1.10" class="ltx_text" style="font-size:90%;">].</span></p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text" style="font-size:90%;">We are continuously collecting and annotating artworks with possible olfactory relevance from multiple museum collections.
Based on these, we created a dataset of olfactory artworks containing </span><span id="S2.p2.1.2" class="ltx_text ltx_number" style="font-size:90%;">16â€‰728</span><span id="S2.p2.1.3" class="ltx_text" style="font-size:90%;"> annotations on </span><span id="S2.p2.1.4" class="ltx_text ltx_number" style="font-size:90%;">2â€‰229</span><span id="S2.p2.1.5" class="ltx_text" style="font-size:90%;"> artworks.
From this full set of annotations, we created a test set of </span><span id="S2.p2.1.6" class="ltx_text ltx_number" style="font-size:90%;">3â€‰416</span><span id="S2.p2.1.7" class="ltx_text" style="font-size:90%;"> annotations on </span><span id="S2.p2.1.8" class="ltx_text ltx_number" style="font-size:90%;">473</span><span id="S2.p2.1.9" class="ltx_text" style="font-size:90%;"> artworks, while the remaining data was used for training.</span></p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2301.09906/assets/pipelinefigurev2.jpg" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="202" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Transfer learning training strategy illustration. We start with a backbone pre-trained on ImageNet for classification, use this model to train an object detection system using different datasets. Finally, the object detection model is fine-tuned on the olfactory artworks dataset.</figcaption>
</figure>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text" style="font-size:90%;">A common transfer learning procedure is to use detection backbones that have been pre-trained on ImageNet and fine-tune them for object detection </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a><span id="S2.p3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p3.1.4" class="ltx_text" style="font-size:90%;">.
We expand this strategy by an additional pre-training step, where we train an ImageNet pre-trained object detection network </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p3.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a><span id="S2.p3.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p3.1.7" class="ltx_text" style="font-size:90%;"> using different datasets.
Finally, we fine-tune the resulting model using our olfactory artworks dataset (</span><a href="#S2.F3" title="In 2 Methodology â€£ Transfer Learning for Olfactory Object Detection" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a><span id="S2.p3.1.8" class="ltx_text" style="font-size:90%;">).</span></p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text" style="font-size:90%;">For pre-training, we use three different datasets, deviating to varying amounts from our olfactory artworks dataset in terms of categories and style (</span><a href="#S2.T1" title="In 2 Methodology â€£ Transfer Learning for Olfactory Object Detection" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">table</span>Â <span class="ltx_text ltx_ref_tag">1</span></a><span id="S2.p4.1.2" class="ltx_text" style="font-size:90%;">):
a) Same Categories, Different Styles - A subset of OpenImages (OI) containing only odor objects results in a complete category match (</span><a href="#S2.F2" title="In 2 Methodology â€£ Transfer Learning for Olfactory Object Detection" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a><span id="S2.p4.1.3" class="ltx_text" style="font-size:90%;">); however, since OpenImages contains only photographs, there is a considerable style difference.
b) Different Categories, Same Styles - We apply two object detection datasets from the art domain, which are more similar in terms of style but contain different object categories, namely IconArt (IA) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.4.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a><span id="S2.p4.1.5.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.6" class="ltx_text" style="font-size:90%;"> and PeopleArt (PA) </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.p4.1.7.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a><span id="S2.p4.1.8.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S2.p4.1.9" class="ltx_text" style="font-size:90%;">.</span></p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>An overview of domain &amp; category similarity of the experiment datasets to our olfactory artworks</figcaption>
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<th id="S2.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Dataset</span></th>
<th id="S2.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.4.1.1.2.1" class="ltx_text" style="font-size:90%;">domain similarity</span></th>
<th id="S2.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.4.1.1.3.1" class="ltx_text" style="font-size:90%;">category similarity</span></th>
<th id="S2.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.4.1.1.4.1" class="ltx_text" style="font-size:90%;"># categories</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.4.2.1" class="ltx_tr">
<td id="S2.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">OpenImages</span></td>
<td id="S2.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.4.2.1.2.1" class="ltx_text" style="font-size:90%;">low</span></td>
<td id="S2.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.4.2.1.3.1" class="ltx_text" style="font-size:90%;">complete match</span></td>
<td id="S2.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.4.2.1.4.1" class="ltx_text" style="font-size:90%;">29</span></td>
</tr>
<tr id="S2.T1.4.3.2" class="ltx_tr">
<td id="S2.T1.4.3.2.1" class="ltx_td ltx_align_left"><span id="S2.T1.4.3.2.1.1" class="ltx_text" style="font-size:90%;">IconArt</span></td>
<td id="S2.T1.4.3.2.2" class="ltx_td ltx_align_center"><span id="S2.T1.4.3.2.2.1" class="ltx_text" style="font-size:90%;">high</span></td>
<td id="S2.T1.4.3.2.3" class="ltx_td ltx_align_center"><span id="S2.T1.4.3.2.3.1" class="ltx_text" style="font-size:90%;">medium</span></td>
<td id="S2.T1.4.3.2.4" class="ltx_td ltx_align_center"><span id="S2.T1.4.3.2.4.1" class="ltx_text" style="font-size:90%;">10</span></td>
</tr>
<tr id="S2.T1.4.4.3" class="ltx_tr">
<td id="S2.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S2.T1.4.4.3.1.1" class="ltx_text" style="font-size:90%;">PeopleArt</span></td>
<td id="S2.T1.4.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.4.4.3.2.1" class="ltx_text" style="font-size:90%;">medium</span></td>
<td id="S2.T1.4.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.4.4.3.3.1" class="ltx_text" style="font-size:90%;">low</span></td>
<td id="S2.T1.4.4.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T1.4.4.3.4.1" class="ltx_text" style="font-size:90%;">1</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>

<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>
Evaluation of object detection performance.
The best performing model pre-trained with OI achieves an improvement of 6.5% pascal VOC mAP, and 3.4% COCO mAP over the baseline method without intermediate training.
We report the evaluation for each pre-training dataset, averaged over five models, fine-tuned for 50 epochs on our olfactory artworks datasets.
Best evaluation results are highlighted in bold.
The merge of two datasets <math id="S3.T2.4.m1.1" class="ltx_Math" alttext="D_{1}" display="inline"><semantics id="S3.T2.4.m1.1b"><msub id="S3.T2.4.m1.1.1" xref="S3.T2.4.m1.1.1.cmml"><mi id="S3.T2.4.m1.1.1.2" xref="S3.T2.4.m1.1.1.2.cmml">D</mi><mn id="S3.T2.4.m1.1.1.3" xref="S3.T2.4.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.4.m1.1c"><apply id="S3.T2.4.m1.1.1.cmml" xref="S3.T2.4.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.4.m1.1.1.1.cmml" xref="S3.T2.4.m1.1.1">subscript</csymbol><ci id="S3.T2.4.m1.1.1.2.cmml" xref="S3.T2.4.m1.1.1.2">ğ·</ci><cn type="integer" id="S3.T2.4.m1.1.1.3.cmml" xref="S3.T2.4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.m1.1d">D_{1}</annotation></semantics></math> and <math id="S3.T2.5.m2.1" class="ltx_Math" alttext="D_{2}" display="inline"><semantics id="S3.T2.5.m2.1b"><msub id="S3.T2.5.m2.1.1" xref="S3.T2.5.m2.1.1.cmml"><mi id="S3.T2.5.m2.1.1.2" xref="S3.T2.5.m2.1.1.2.cmml">D</mi><mn id="S3.T2.5.m2.1.1.3" xref="S3.T2.5.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T2.5.m2.1c"><apply id="S3.T2.5.m2.1.1.cmml" xref="S3.T2.5.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.5.m2.1.1.1.cmml" xref="S3.T2.5.m2.1.1">subscript</csymbol><ci id="S3.T2.5.m2.1.1.2.cmml" xref="S3.T2.5.m2.1.1.2">ğ·</ci><cn type="integer" id="S3.T2.5.m2.1.1.3.cmml" xref="S3.T2.5.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.m2.1d">D_{2}</annotation></semantics></math> is written as <math id="S3.T2.6.m3.1" class="ltx_Math" alttext="D_{1}\cup D_{2}" display="inline"><semantics id="S3.T2.6.m3.1b"><mrow id="S3.T2.6.m3.1.1" xref="S3.T2.6.m3.1.1.cmml"><msub id="S3.T2.6.m3.1.1.2" xref="S3.T2.6.m3.1.1.2.cmml"><mi id="S3.T2.6.m3.1.1.2.2" xref="S3.T2.6.m3.1.1.2.2.cmml">D</mi><mn id="S3.T2.6.m3.1.1.2.3" xref="S3.T2.6.m3.1.1.2.3.cmml">1</mn></msub><mo id="S3.T2.6.m3.1.1.1" xref="S3.T2.6.m3.1.1.1.cmml">âˆª</mo><msub id="S3.T2.6.m3.1.1.3" xref="S3.T2.6.m3.1.1.3.cmml"><mi id="S3.T2.6.m3.1.1.3.2" xref="S3.T2.6.m3.1.1.3.2.cmml">D</mi><mn id="S3.T2.6.m3.1.1.3.3" xref="S3.T2.6.m3.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T2.6.m3.1c"><apply id="S3.T2.6.m3.1.1.cmml" xref="S3.T2.6.m3.1.1"><union id="S3.T2.6.m3.1.1.1.cmml" xref="S3.T2.6.m3.1.1.1"></union><apply id="S3.T2.6.m3.1.1.2.cmml" xref="S3.T2.6.m3.1.1.2"><csymbol cd="ambiguous" id="S3.T2.6.m3.1.1.2.1.cmml" xref="S3.T2.6.m3.1.1.2">subscript</csymbol><ci id="S3.T2.6.m3.1.1.2.2.cmml" xref="S3.T2.6.m3.1.1.2.2">ğ·</ci><cn type="integer" id="S3.T2.6.m3.1.1.2.3.cmml" xref="S3.T2.6.m3.1.1.2.3">1</cn></apply><apply id="S3.T2.6.m3.1.1.3.cmml" xref="S3.T2.6.m3.1.1.3"><csymbol cd="ambiguous" id="S3.T2.6.m3.1.1.3.1.cmml" xref="S3.T2.6.m3.1.1.3">subscript</csymbol><ci id="S3.T2.6.m3.1.1.3.2.cmml" xref="S3.T2.6.m3.1.1.3.2">ğ·</ci><cn type="integer" id="S3.T2.6.m3.1.1.3.3.cmml" xref="S3.T2.6.m3.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.6.m3.1d">D_{1}\cup D_{2}</annotation></semantics></math>.
</figcaption>
<table id="S3.T2.27" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.27.22.1" class="ltx_tr">
<th id="S3.T2.27.22.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T2.27.22.1.1.1" class="ltx_text" style="font-size:90%;">Pretraining Dataset</span></th>
<th id="S3.T2.27.22.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.27.22.1.2.1" class="ltx_text" style="font-size:90%;">Pascal mAP(%)</span></th>
<th id="S3.T2.27.22.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T2.27.22.1.3.1" class="ltx_text" style="font-size:90%;">COCO mAP(%)</span></th>
</tr>
<tr id="S3.T2.8.2" class="ltx_tr">
<th id="S3.T2.8.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S3.T2.8.2.3.1" class="ltx_text" style="font-size:90%;">None (Baseline)</span></th>
<th id="S3.T2.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S3.T2.7.1.1.1" class="ltx_text" style="font-size:90%;">16.8(</span><math id="S3.T2.7.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.7.1.1.m1.1a"><mo mathsize="90%" id="S3.T2.7.1.1.m1.1.1" xref="S3.T2.7.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.7.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.7.1.1.m1.1.1.cmml" xref="S3.T2.7.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.7.1.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.7.1.1.2" class="ltx_text" style="font-size:90%;">1.3)</span>
</th>
<th id="S3.T2.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S3.T2.8.2.2.1" class="ltx_text" style="font-size:90%;">8.4(</span><math id="S3.T2.8.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.8.2.2.m1.1a"><mo mathsize="90%" id="S3.T2.8.2.2.m1.1.1" xref="S3.T2.8.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.2.2.m1.1b"><csymbol cd="latexml" id="S3.T2.8.2.2.m1.1.1.cmml" xref="S3.T2.8.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.2.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.8.2.2.2" class="ltx_text" style="font-size:90%;">0.4)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.10.4" class="ltx_tr">
<th id="S3.T2.10.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T2.10.4.3.1" class="ltx_text" style="font-size:90%;">OI</span></th>
<td id="S3.T2.9.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.9.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">23.3(<math id="S3.T2.9.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.9.3.1.1.m1.1a"><mo id="S3.T2.9.3.1.1.m1.1.1" xref="S3.T2.9.3.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.9.3.1.1.m1.1b"><csymbol cd="latexml" id="S3.T2.9.3.1.1.m1.1.1.cmml" xref="S3.T2.9.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.9.3.1.1.m1.1c">\pm</annotation></semantics></math>0.5)</span></td>
<td id="S3.T2.10.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.10.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">11.8(<math id="S3.T2.10.4.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.10.4.2.1.m1.1a"><mo id="S3.T2.10.4.2.1.m1.1.1" xref="S3.T2.10.4.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.10.4.2.1.m1.1b"><csymbol cd="latexml" id="S3.T2.10.4.2.1.m1.1.1.cmml" xref="S3.T2.10.4.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.10.4.2.1.m1.1c">\pm</annotation></semantics></math>0.4)</span></td>
</tr>
<tr id="S3.T2.12.6" class="ltx_tr">
<th id="S3.T2.12.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.12.6.3.1" class="ltx_text" style="font-size:90%;">IA</span></th>
<td id="S3.T2.11.5.1" class="ltx_td ltx_align_center">
<span id="S3.T2.11.5.1.1" class="ltx_text" style="font-size:90%;">22.6(</span><math id="S3.T2.11.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.11.5.1.m1.1a"><mo mathsize="90%" id="S3.T2.11.5.1.m1.1.1" xref="S3.T2.11.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.11.5.1.m1.1b"><csymbol cd="latexml" id="S3.T2.11.5.1.m1.1.1.cmml" xref="S3.T2.11.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.11.5.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.11.5.1.2" class="ltx_text" style="font-size:90%;">1.2)</span>
</td>
<td id="S3.T2.12.6.2" class="ltx_td ltx_align_center">
<span id="S3.T2.12.6.2.1" class="ltx_text" style="font-size:90%;">10.9(</span><math id="S3.T2.12.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.12.6.2.m1.1a"><mo mathsize="90%" id="S3.T2.12.6.2.m1.1.1" xref="S3.T2.12.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.12.6.2.m1.1b"><csymbol cd="latexml" id="S3.T2.12.6.2.m1.1.1.cmml" xref="S3.T2.12.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.12.6.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.12.6.2.2" class="ltx_text" style="font-size:90%;">0.9)</span>
</td>
</tr>
<tr id="S3.T2.14.8" class="ltx_tr">
<th id="S3.T2.14.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T2.14.8.3.1" class="ltx_text" style="font-size:90%;">PA</span></th>
<td id="S3.T2.13.7.1" class="ltx_td ltx_align_center">
<span id="S3.T2.13.7.1.1" class="ltx_text" style="font-size:90%;">21.9(</span><math id="S3.T2.13.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.13.7.1.m1.1a"><mo mathsize="90%" id="S3.T2.13.7.1.m1.1.1" xref="S3.T2.13.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.13.7.1.m1.1b"><csymbol cd="latexml" id="S3.T2.13.7.1.m1.1.1.cmml" xref="S3.T2.13.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.13.7.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.13.7.1.2" class="ltx_text" style="font-size:90%;">0.4)</span>
</td>
<td id="S3.T2.14.8.2" class="ltx_td ltx_align_center">
<span id="S3.T2.14.8.2.1" class="ltx_text" style="font-size:90%;">10.5(</span><math id="S3.T2.14.8.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.14.8.2.m1.1a"><mo mathsize="90%" id="S3.T2.14.8.2.m1.1.1" xref="S3.T2.14.8.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.14.8.2.m1.1b"><csymbol cd="latexml" id="S3.T2.14.8.2.m1.1.1.cmml" xref="S3.T2.14.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.14.8.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.14.8.2.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
</tr>
<tr id="S3.T2.17.11" class="ltx_tr">
<th id="S3.T2.15.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S3.T2.15.9.1.1" class="ltx_text" style="font-size:90%;">IA</span><math id="S3.T2.15.9.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T2.15.9.1.m1.1a"><mo mathsize="90%" id="S3.T2.15.9.1.m1.1.1" xref="S3.T2.15.9.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T2.15.9.1.m1.1b"><union id="S3.T2.15.9.1.m1.1.1.cmml" xref="S3.T2.15.9.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.15.9.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T2.15.9.1.2" class="ltx_text" style="font-size:90%;">OI</span>
</th>
<td id="S3.T2.16.10.2" class="ltx_td ltx_align_center">
<span id="S3.T2.16.10.2.1" class="ltx_text" style="font-size:90%;">21.8(</span><math id="S3.T2.16.10.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.16.10.2.m1.1a"><mo mathsize="90%" id="S3.T2.16.10.2.m1.1.1" xref="S3.T2.16.10.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.16.10.2.m1.1b"><csymbol cd="latexml" id="S3.T2.16.10.2.m1.1.1.cmml" xref="S3.T2.16.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.16.10.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.16.10.2.2" class="ltx_text" style="font-size:90%;">0.1)</span>
</td>
<td id="S3.T2.17.11.3" class="ltx_td ltx_align_center">
<span id="S3.T2.17.11.3.1" class="ltx_text" style="font-size:90%;">10.5(</span><math id="S3.T2.17.11.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.17.11.3.m1.1a"><mo mathsize="90%" id="S3.T2.17.11.3.m1.1.1" xref="S3.T2.17.11.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.17.11.3.m1.1b"><csymbol cd="latexml" id="S3.T2.17.11.3.m1.1.1.cmml" xref="S3.T2.17.11.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.17.11.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.17.11.3.2" class="ltx_text" style="font-size:90%;">0.3)</span>
</td>
</tr>
<tr id="S3.T2.20.14" class="ltx_tr">
<th id="S3.T2.18.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S3.T2.18.12.1.1" class="ltx_text" style="font-size:90%;">IA</span><math id="S3.T2.18.12.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T2.18.12.1.m1.1a"><mo mathsize="90%" id="S3.T2.18.12.1.m1.1.1" xref="S3.T2.18.12.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T2.18.12.1.m1.1b"><union id="S3.T2.18.12.1.m1.1.1.cmml" xref="S3.T2.18.12.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.18.12.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T2.18.12.1.2" class="ltx_text" style="font-size:90%;">PA</span>
</th>
<td id="S3.T2.19.13.2" class="ltx_td ltx_align_center">
<span id="S3.T2.19.13.2.1" class="ltx_text" style="font-size:90%;">22.0(</span><math id="S3.T2.19.13.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.19.13.2.m1.1a"><mo mathsize="90%" id="S3.T2.19.13.2.m1.1.1" xref="S3.T2.19.13.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.19.13.2.m1.1b"><csymbol cd="latexml" id="S3.T2.19.13.2.m1.1.1.cmml" xref="S3.T2.19.13.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.19.13.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.19.13.2.2" class="ltx_text" style="font-size:90%;">0.8)</span>
</td>
<td id="S3.T2.20.14.3" class="ltx_td ltx_align_center">
<span id="S3.T2.20.14.3.1" class="ltx_text" style="font-size:90%;">10.6(</span><math id="S3.T2.20.14.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.20.14.3.m1.1a"><mo mathsize="90%" id="S3.T2.20.14.3.m1.1.1" xref="S3.T2.20.14.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.20.14.3.m1.1b"><csymbol cd="latexml" id="S3.T2.20.14.3.m1.1.1.cmml" xref="S3.T2.20.14.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.20.14.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.20.14.3.2" class="ltx_text" style="font-size:90%;">0.3)</span>
</td>
</tr>
<tr id="S3.T2.23.17" class="ltx_tr">
<th id="S3.T2.21.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S3.T2.21.15.1.1" class="ltx_text" style="font-size:90%;">PA</span><math id="S3.T2.21.15.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T2.21.15.1.m1.1a"><mo mathsize="90%" id="S3.T2.21.15.1.m1.1.1" xref="S3.T2.21.15.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T2.21.15.1.m1.1b"><union id="S3.T2.21.15.1.m1.1.1.cmml" xref="S3.T2.21.15.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.21.15.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T2.21.15.1.2" class="ltx_text" style="font-size:90%;">OI</span>
</th>
<td id="S3.T2.22.16.2" class="ltx_td ltx_align_center">
<span id="S3.T2.22.16.2.1" class="ltx_text" style="font-size:90%;">22.6(</span><math id="S3.T2.22.16.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.22.16.2.m1.1a"><mo mathsize="90%" id="S3.T2.22.16.2.m1.1.1" xref="S3.T2.22.16.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.22.16.2.m1.1b"><csymbol cd="latexml" id="S3.T2.22.16.2.m1.1.1.cmml" xref="S3.T2.22.16.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.22.16.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.22.16.2.2" class="ltx_text" style="font-size:90%;">0.3)</span>
</td>
<td id="S3.T2.23.17.3" class="ltx_td ltx_align_center">
<span id="S3.T2.23.17.3.1" class="ltx_text" style="font-size:90%;">10.8(</span><math id="S3.T2.23.17.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.23.17.3.m1.1a"><mo mathsize="90%" id="S3.T2.23.17.3.m1.1.1" xref="S3.T2.23.17.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.23.17.3.m1.1b"><csymbol cd="latexml" id="S3.T2.23.17.3.m1.1.1.cmml" xref="S3.T2.23.17.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.23.17.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.23.17.3.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
</tr>
<tr id="S3.T2.27.21" class="ltx_tr">
<th id="S3.T2.25.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">
<span id="S3.T2.25.19.2.1" class="ltx_text" style="font-size:90%;">OI</span><math id="S3.T2.24.18.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T2.24.18.1.m1.1a"><mo mathsize="90%" id="S3.T2.24.18.1.m1.1.1" xref="S3.T2.24.18.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T2.24.18.1.m1.1b"><union id="S3.T2.24.18.1.m1.1.1.cmml" xref="S3.T2.24.18.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.24.18.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T2.25.19.2.2" class="ltx_text" style="font-size:90%;">IA</span><math id="S3.T2.25.19.2.m2.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T2.25.19.2.m2.1a"><mo mathsize="90%" id="S3.T2.25.19.2.m2.1.1" xref="S3.T2.25.19.2.m2.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T2.25.19.2.m2.1b"><union id="S3.T2.25.19.2.m2.1.1.cmml" xref="S3.T2.25.19.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.25.19.2.m2.1c">\cup</annotation></semantics></math><span id="S3.T2.25.19.2.3" class="ltx_text" style="font-size:90%;">PA</span>
</th>
<td id="S3.T2.26.20.3" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S3.T2.26.20.3.1" class="ltx_text" style="font-size:90%;">21.8(</span><math id="S3.T2.26.20.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.26.20.3.m1.1a"><mo mathsize="90%" id="S3.T2.26.20.3.m1.1.1" xref="S3.T2.26.20.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.26.20.3.m1.1b"><csymbol cd="latexml" id="S3.T2.26.20.3.m1.1.1.cmml" xref="S3.T2.26.20.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.26.20.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.26.20.3.2" class="ltx_text" style="font-size:90%;">0.4)</span>
</td>
<td id="S3.T2.27.21.4" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S3.T2.27.21.4.1" class="ltx_text" style="font-size:90%;">10.5(</span><math id="S3.T2.27.21.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T2.27.21.4.m1.1a"><mo mathsize="90%" id="S3.T2.27.21.4.m1.1.1" xref="S3.T2.27.21.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T2.27.21.4.m1.1b"><csymbol cd="latexml" id="S3.T2.27.21.4.m1.1.1.cmml" xref="S3.T2.27.21.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.27.21.4.m1.1c">\pm</annotation></semantics></math><span id="S3.T2.27.21.4.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2301.09906/assets/preds/preds_none.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="475" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(a) </span>No pretraining.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2301.09906/assets/preds/preds_pa.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="475" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(b) </span>PA pretraining.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2301.09906/assets/preds/gt_pa.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_img_landscape" width="598" height="475" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">(c) </span>Ground truth.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>
Exemplary object predictions for a detection model without intermediate training (a), with PeopleArt pretraining (b), and ground truth bounding boxes (c).
Painting: <span id="S3.F4.7.1" class="ltx_text ltx_font_italic">Boy holding a pewter tankard, by a still life of a duck, cheeses, bread and a herring.</span> 1625 â€“ 1674. Gerard van Honthorst.
RKD Digital Collection (<a target="_blank" href="https://rkd.nl/explore/images/287165" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://rkd.nl/explore/images/287165</a>). Public Domain.
</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text" style="font-size:90%;">To ensure a fair comparison between the different pre-training datasets, we reduce each of the datasets to the same size, train three models, and select the best according to a fixed validation set for each dataset.
Additionally, we merge all three datasets, i.â€‰e., combining OI, IA, and PA, using the union over their respective classes.
The resulting models are then fine-tuned on the training set of the olfactory artworks dataset and evaluated on a separate test set.
To mitigate random variations that can occur during the training process, we train five separate models for each experimental setting and report their average.
Evaluation results are reported in pascal VOC (mAP 50 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a><span id="S3.p1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p1.1.4" class="ltx_text" style="font-size:90%;">) and COCO mAP (mAP 50:95:5 </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.p1.1.5.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a><span id="S3.p1.1.6.2" class="ltx_text" style="font-size:90%;">]</span></cite><span id="S3.p1.1.7" class="ltx_text" style="font-size:90%;">), the two standard metrics to evaluate object detection models.
We conduct two separate sets of experiments:
In the first, we fine-tune the whole network, including the backbone, to assess the detection performance under realistic conditions (</span><a href="#S3.T2" title="In 3 Results â€£ Transfer Learning for Olfactory Object Detection" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">table</span>Â <span class="ltx_text ltx_ref_tag">2</span></a><span id="S3.p1.1.8" class="ltx_text" style="font-size:90%;">).
We observe a performance increase for all used pre-training datasets, with an increase of 6.5%/3,4% boost in mAP 50 and COCO mAP, respectively, for the best performing pre-training scheme, which was achieved using the OI dataset.
The exemplary object predictions in </span><a href="#S3.F4" title="In 3 Results â€£ Transfer Learning for Olfactory Object Detection" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">fig.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a><span id="S3.p1.1.9" class="ltx_text" style="font-size:90%;"> show that adding an additional pre-training stage can increase the number of recognized objects.</span></p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.21" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.21.22.1" class="ltx_tr">
<th id="S3.T3.21.22.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T3.21.22.1.1.1" class="ltx_text" style="font-size:90%;">Pretraining Dataset</span></th>
<th id="S3.T3.21.22.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T3.21.22.1.2.1" class="ltx_text" style="font-size:90%;">mAP(%) 50</span></th>
<th id="S3.T3.21.22.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S3.T3.21.22.1.3.1" class="ltx_text" style="font-size:90%;">mAP(%) 50:95</span></th>
</tr>
<tr id="S3.T3.2.2" class="ltx_tr">
<th id="S3.T3.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t"><span id="S3.T3.2.2.3.1" class="ltx_text" style="font-size:90%;">None (Baseline)</span></th>
<th id="S3.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S3.T3.1.1.1.1" class="ltx_text" style="font-size:90%;">11.7(</span><math id="S3.T3.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.1.1.1.m1.1a"><mo mathsize="90%" id="S3.T3.1.1.1.m1.1.1" xref="S3.T3.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.1.1.1.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</th>
<th id="S3.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S3.T3.2.2.2.1" class="ltx_text" style="font-size:90%;">5.5(</span><math id="S3.T3.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.2.2.2.m1.1a"><mo mathsize="90%" id="S3.T3.2.2.2.m1.1.1" xref="S3.T3.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.m1.1b"><csymbol cd="latexml" id="S3.T3.2.2.2.m1.1.1.cmml" xref="S3.T3.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.2.2.2.2" class="ltx_text" style="font-size:90%;">0.1)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.4.4" class="ltx_tr">
<th id="S3.T3.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S3.T3.4.4.3.1" class="ltx_text" style="font-size:90%;">OI</span></th>
<td id="S3.T3.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">19.4(<math id="S3.T3.3.3.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.3.3.1.1.m1.1a"><mo id="S3.T3.3.3.1.1.m1.1.1" xref="S3.T3.3.3.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.1.1.m1.1b"><csymbol cd="latexml" id="S3.T3.3.3.1.1.m1.1.1.cmml" xref="S3.T3.3.3.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.1.1.m1.1c">\pm</annotation></semantics></math>0.3)</span></td>
<td id="S3.T3.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.4.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">9.5(<math id="S3.T3.4.4.2.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.4.4.2.1.m1.1a"><mo id="S3.T3.4.4.2.1.m1.1.1" xref="S3.T3.4.4.2.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.2.1.m1.1b"><csymbol cd="latexml" id="S3.T3.4.4.2.1.m1.1.1.cmml" xref="S3.T3.4.4.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.2.1.m1.1c">\pm</annotation></semantics></math>0.1)</span></td>
</tr>
<tr id="S3.T3.6.6" class="ltx_tr">
<th id="S3.T3.6.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T3.6.6.3.1" class="ltx_text" style="font-size:90%;">IA</span></th>
<td id="S3.T3.5.5.1" class="ltx_td ltx_align_center">
<span id="S3.T3.5.5.1.1" class="ltx_text" style="font-size:90%;">13.8(</span><math id="S3.T3.5.5.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.5.5.1.m1.1a"><mo mathsize="90%" id="S3.T3.5.5.1.m1.1.1" xref="S3.T3.5.5.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.1.m1.1b"><csymbol cd="latexml" id="S3.T3.5.5.1.m1.1.1.cmml" xref="S3.T3.5.5.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.5.5.1.2" class="ltx_text" style="font-size:90%;">0.4)</span>
</td>
<td id="S3.T3.6.6.2" class="ltx_td ltx_align_center">
<span id="S3.T3.6.6.2.1" class="ltx_text" style="font-size:90%;">6.4(</span><math id="S3.T3.6.6.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.6.6.2.m1.1a"><mo mathsize="90%" id="S3.T3.6.6.2.m1.1.1" xref="S3.T3.6.6.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.2.m1.1b"><csymbol cd="latexml" id="S3.T3.6.6.2.m1.1.1.cmml" xref="S3.T3.6.6.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.6.6.2.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
</tr>
<tr id="S3.T3.8.8" class="ltx_tr">
<th id="S3.T3.8.8.3" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S3.T3.8.8.3.1" class="ltx_text" style="font-size:90%;">PA</span></th>
<td id="S3.T3.7.7.1" class="ltx_td ltx_align_center">
<span id="S3.T3.7.7.1.1" class="ltx_text" style="font-size:90%;">13.5(</span><math id="S3.T3.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.7.7.1.m1.1a"><mo mathsize="90%" id="S3.T3.7.7.1.m1.1.1" xref="S3.T3.7.7.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.1.m1.1b"><csymbol cd="latexml" id="S3.T3.7.7.1.m1.1.1.cmml" xref="S3.T3.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.1.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.7.7.1.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
<td id="S3.T3.8.8.2" class="ltx_td ltx_align_center">
<span id="S3.T3.8.8.2.1" class="ltx_text" style="font-size:90%;">6.7(</span><math id="S3.T3.8.8.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.8.8.2.m1.1a"><mo mathsize="90%" id="S3.T3.8.8.2.m1.1.1" xref="S3.T3.8.8.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.8.8.2.m1.1b"><csymbol cd="latexml" id="S3.T3.8.8.2.m1.1.1.cmml" xref="S3.T3.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.8.8.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.8.8.2.2" class="ltx_text" style="font-size:90%;">0.1)</span>
</td>
</tr>
<tr id="S3.T3.11.11" class="ltx_tr">
<th id="S3.T3.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S3.T3.9.9.1.1" class="ltx_text" style="font-size:90%;">IA</span><math id="S3.T3.9.9.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T3.9.9.1.m1.1a"><mo mathsize="90%" id="S3.T3.9.9.1.m1.1.1" xref="S3.T3.9.9.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T3.9.9.1.m1.1b"><union id="S3.T3.9.9.1.m1.1.1.cmml" xref="S3.T3.9.9.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.9.9.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T3.9.9.1.2" class="ltx_text" style="font-size:90%;">OI</span>
</th>
<td id="S3.T3.10.10.2" class="ltx_td ltx_align_center">
<span id="S3.T3.10.10.2.1" class="ltx_text" style="font-size:90%;">16.0(</span><math id="S3.T3.10.10.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.10.10.2.m1.1a"><mo mathsize="90%" id="S3.T3.10.10.2.m1.1.1" xref="S3.T3.10.10.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.10.10.2.m1.1b"><csymbol cd="latexml" id="S3.T3.10.10.2.m1.1.1.cmml" xref="S3.T3.10.10.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.10.10.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.10.10.2.2" class="ltx_text" style="font-size:90%;">0.3)</span>
</td>
<td id="S3.T3.11.11.3" class="ltx_td ltx_align_center">
<span id="S3.T3.11.11.3.1" class="ltx_text" style="font-size:90%;">7.4(</span><math id="S3.T3.11.11.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.11.11.3.m1.1a"><mo mathsize="90%" id="S3.T3.11.11.3.m1.1.1" xref="S3.T3.11.11.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.11.11.3.m1.1b"><csymbol cd="latexml" id="S3.T3.11.11.3.m1.1.1.cmml" xref="S3.T3.11.11.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.11.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.11.11.3.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
</tr>
<tr id="S3.T3.14.14" class="ltx_tr">
<th id="S3.T3.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S3.T3.12.12.1.1" class="ltx_text" style="font-size:90%;">IA</span><math id="S3.T3.12.12.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T3.12.12.1.m1.1a"><mo mathsize="90%" id="S3.T3.12.12.1.m1.1.1" xref="S3.T3.12.12.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T3.12.12.1.m1.1b"><union id="S3.T3.12.12.1.m1.1.1.cmml" xref="S3.T3.12.12.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.12.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T3.12.12.1.2" class="ltx_text" style="font-size:90%;">PA</span>
</th>
<td id="S3.T3.13.13.2" class="ltx_td ltx_align_center">
<span id="S3.T3.13.13.2.1" class="ltx_text" style="font-size:90%;">14.6(</span><math id="S3.T3.13.13.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.13.13.2.m1.1a"><mo mathsize="90%" id="S3.T3.13.13.2.m1.1.1" xref="S3.T3.13.13.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.13.13.2.m1.1b"><csymbol cd="latexml" id="S3.T3.13.13.2.m1.1.1.cmml" xref="S3.T3.13.13.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.13.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.13.13.2.2" class="ltx_text" style="font-size:90%;">1.0)</span>
</td>
<td id="S3.T3.14.14.3" class="ltx_td ltx_align_center">
<span id="S3.T3.14.14.3.1" class="ltx_text" style="font-size:90%;">6.7(</span><math id="S3.T3.14.14.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.14.14.3.m1.1a"><mo mathsize="90%" id="S3.T3.14.14.3.m1.1.1" xref="S3.T3.14.14.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.14.14.3.m1.1b"><csymbol cd="latexml" id="S3.T3.14.14.3.m1.1.1.cmml" xref="S3.T3.14.14.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.14.14.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.14.14.3.2" class="ltx_text" style="font-size:90%;">0.5)</span>
</td>
</tr>
<tr id="S3.T3.17.17" class="ltx_tr">
<th id="S3.T3.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span id="S3.T3.15.15.1.1" class="ltx_text" style="font-size:90%;">PA</span><math id="S3.T3.15.15.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T3.15.15.1.m1.1a"><mo mathsize="90%" id="S3.T3.15.15.1.m1.1.1" xref="S3.T3.15.15.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T3.15.15.1.m1.1b"><union id="S3.T3.15.15.1.m1.1.1.cmml" xref="S3.T3.15.15.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.15.15.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T3.15.15.1.2" class="ltx_text" style="font-size:90%;">OI</span>
</th>
<td id="S3.T3.16.16.2" class="ltx_td ltx_align_center">
<span id="S3.T3.16.16.2.1" class="ltx_text" style="font-size:90%;">15.8(</span><math id="S3.T3.16.16.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.16.16.2.m1.1a"><mo mathsize="90%" id="S3.T3.16.16.2.m1.1.1" xref="S3.T3.16.16.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.16.16.2.m1.1b"><csymbol cd="latexml" id="S3.T3.16.16.2.m1.1.1.cmml" xref="S3.T3.16.16.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.16.16.2.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.16.16.2.2" class="ltx_text" style="font-size:90%;">0.7)</span>
</td>
<td id="S3.T3.17.17.3" class="ltx_td ltx_align_center">
<span id="S3.T3.17.17.3.1" class="ltx_text" style="font-size:90%;">7.3(</span><math id="S3.T3.17.17.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.17.17.3.m1.1a"><mo mathsize="90%" id="S3.T3.17.17.3.m1.1.1" xref="S3.T3.17.17.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.17.17.3.m1.1b"><csymbol cd="latexml" id="S3.T3.17.17.3.m1.1.1.cmml" xref="S3.T3.17.17.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.17.17.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.17.17.3.2" class="ltx_text" style="font-size:90%;">0.4)</span>
</td>
</tr>
<tr id="S3.T3.21.21" class="ltx_tr">
<th id="S3.T3.19.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">
<span id="S3.T3.19.19.2.1" class="ltx_text" style="font-size:90%;">OI</span><math id="S3.T3.18.18.1.m1.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T3.18.18.1.m1.1a"><mo mathsize="90%" id="S3.T3.18.18.1.m1.1.1" xref="S3.T3.18.18.1.m1.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T3.18.18.1.m1.1b"><union id="S3.T3.18.18.1.m1.1.1.cmml" xref="S3.T3.18.18.1.m1.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.18.18.1.m1.1c">\cup</annotation></semantics></math><span id="S3.T3.19.19.2.2" class="ltx_text" style="font-size:90%;">IA</span><math id="S3.T3.19.19.2.m2.1" class="ltx_Math" alttext="\cup" display="inline"><semantics id="S3.T3.19.19.2.m2.1a"><mo mathsize="90%" id="S3.T3.19.19.2.m2.1.1" xref="S3.T3.19.19.2.m2.1.1.cmml">âˆª</mo><annotation-xml encoding="MathML-Content" id="S3.T3.19.19.2.m2.1b"><union id="S3.T3.19.19.2.m2.1.1.cmml" xref="S3.T3.19.19.2.m2.1.1"></union></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.19.19.2.m2.1c">\cup</annotation></semantics></math><span id="S3.T3.19.19.2.3" class="ltx_text" style="font-size:90%;">PA</span>
</th>
<td id="S3.T3.20.20.3" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S3.T3.20.20.3.1" class="ltx_text" style="font-size:90%;">16.4(</span><math id="S3.T3.20.20.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.20.20.3.m1.1a"><mo mathsize="90%" id="S3.T3.20.20.3.m1.1.1" xref="S3.T3.20.20.3.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.20.20.3.m1.1b"><csymbol cd="latexml" id="S3.T3.20.20.3.m1.1.1.cmml" xref="S3.T3.20.20.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.20.20.3.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.20.20.3.2" class="ltx_text" style="font-size:90%;">0.6)</span>
</td>
<td id="S3.T3.21.21.4" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S3.T3.21.21.4.1" class="ltx_text" style="font-size:90%;">7.6(</span><math id="S3.T3.21.21.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.T3.21.21.4.m1.1a"><mo mathsize="90%" id="S3.T3.21.21.4.m1.1.1" xref="S3.T3.21.21.4.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S3.T3.21.21.4.m1.1b"><csymbol cd="latexml" id="S3.T3.21.21.4.m1.1.1.cmml" xref="S3.T3.21.21.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.21.21.4.m1.1c">\pm</annotation></semantics></math><span id="S3.T3.21.21.4.2" class="ltx_text" style="font-size:90%;">0.2)</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>
Evaluation of object detection performance for fine-tuning of the detection heads only.
All pre-training schemes increase the detection performance, while pre-training with OI leads to the best results with an increase of 7.7% mAP 50 or 4% COCO mAP.
For every pre-training dataset, we report the evaluation averaged over five models, fine-tuned for 50 epochs on our olfactory artworks datasets each.
Best evaluation results are marked in bold.
The merge of two datasets <math id="S3.T3.25.m1.1" class="ltx_Math" alttext="D_{1}" display="inline"><semantics id="S3.T3.25.m1.1b"><msub id="S3.T3.25.m1.1.1" xref="S3.T3.25.m1.1.1.cmml"><mi id="S3.T3.25.m1.1.1.2" xref="S3.T3.25.m1.1.1.2.cmml">D</mi><mn id="S3.T3.25.m1.1.1.3" xref="S3.T3.25.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T3.25.m1.1c"><apply id="S3.T3.25.m1.1.1.cmml" xref="S3.T3.25.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.25.m1.1.1.1.cmml" xref="S3.T3.25.m1.1.1">subscript</csymbol><ci id="S3.T3.25.m1.1.1.2.cmml" xref="S3.T3.25.m1.1.1.2">ğ·</ci><cn type="integer" id="S3.T3.25.m1.1.1.3.cmml" xref="S3.T3.25.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.25.m1.1d">D_{1}</annotation></semantics></math> and <math id="S3.T3.26.m2.1" class="ltx_Math" alttext="D_{2}" display="inline"><semantics id="S3.T3.26.m2.1b"><msub id="S3.T3.26.m2.1.1" xref="S3.T3.26.m2.1.1.cmml"><mi id="S3.T3.26.m2.1.1.2" xref="S3.T3.26.m2.1.1.2.cmml">D</mi><mn id="S3.T3.26.m2.1.1.3" xref="S3.T3.26.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.T3.26.m2.1c"><apply id="S3.T3.26.m2.1.1.cmml" xref="S3.T3.26.m2.1.1"><csymbol cd="ambiguous" id="S3.T3.26.m2.1.1.1.cmml" xref="S3.T3.26.m2.1.1">subscript</csymbol><ci id="S3.T3.26.m2.1.1.2.cmml" xref="S3.T3.26.m2.1.1.2">ğ·</ci><cn type="integer" id="S3.T3.26.m2.1.1.3.cmml" xref="S3.T3.26.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.26.m2.1d">D_{2}</annotation></semantics></math> is written as <math id="S3.T3.27.m3.1" class="ltx_Math" alttext="D_{1}\cup D_{2}" display="inline"><semantics id="S3.T3.27.m3.1b"><mrow id="S3.T3.27.m3.1.1" xref="S3.T3.27.m3.1.1.cmml"><msub id="S3.T3.27.m3.1.1.2" xref="S3.T3.27.m3.1.1.2.cmml"><mi id="S3.T3.27.m3.1.1.2.2" xref="S3.T3.27.m3.1.1.2.2.cmml">D</mi><mn id="S3.T3.27.m3.1.1.2.3" xref="S3.T3.27.m3.1.1.2.3.cmml">1</mn></msub><mo id="S3.T3.27.m3.1.1.1" xref="S3.T3.27.m3.1.1.1.cmml">âˆª</mo><msub id="S3.T3.27.m3.1.1.3" xref="S3.T3.27.m3.1.1.3.cmml"><mi id="S3.T3.27.m3.1.1.3.2" xref="S3.T3.27.m3.1.1.3.2.cmml">D</mi><mn id="S3.T3.27.m3.1.1.3.3" xref="S3.T3.27.m3.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.27.m3.1c"><apply id="S3.T3.27.m3.1.1.cmml" xref="S3.T3.27.m3.1.1"><union id="S3.T3.27.m3.1.1.1.cmml" xref="S3.T3.27.m3.1.1.1"></union><apply id="S3.T3.27.m3.1.1.2.cmml" xref="S3.T3.27.m3.1.1.2"><csymbol cd="ambiguous" id="S3.T3.27.m3.1.1.2.1.cmml" xref="S3.T3.27.m3.1.1.2">subscript</csymbol><ci id="S3.T3.27.m3.1.1.2.2.cmml" xref="S3.T3.27.m3.1.1.2.2">ğ·</ci><cn type="integer" id="S3.T3.27.m3.1.1.2.3.cmml" xref="S3.T3.27.m3.1.1.2.3">1</cn></apply><apply id="S3.T3.27.m3.1.1.3.cmml" xref="S3.T3.27.m3.1.1.3"><csymbol cd="ambiguous" id="S3.T3.27.m3.1.1.3.1.cmml" xref="S3.T3.27.m3.1.1.3">subscript</csymbol><ci id="S3.T3.27.m3.1.1.3.2.cmml" xref="S3.T3.27.m3.1.1.3.2">ğ·</ci><cn type="integer" id="S3.T3.27.m3.1.1.3.3.cmml" xref="S3.T3.27.m3.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.27.m3.1d">D_{1}\cup D_{2}</annotation></semantics></math>.
</figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text" style="font-size:90%;">In a second set of experiments, we train only the detection head while the backbone remains frozen, to compare the quality of the intermediate representations that have been learned using the different pre-training schemes (</span><a href="#S3.T3" title="In 3 Results â€£ Transfer Learning for Olfactory Object Detection" class="ltx_ref" style="font-size:90%;"><span class="ltx_text ltx_ref_tag">table</span>Â <span class="ltx_text ltx_ref_tag">3</span></a><span id="S3.p2.1.2" class="ltx_text" style="font-size:90%;">).
While all pre-training schemes increase the performance, the relative increase for the OI dataset is remarkably higher.
This suggests that the style similarity between the IA and PA datasets and our target dataset is less important than we expected.
We can not yet conclude whether the superior performance of the OI dataset is due to the similarity in target categories.
It could also be caused by other properties of the dataset.
Further ablations, e.â€‰g., varying the set of OI categories are needed to more precisely assess the impact of category similarity on the detection performance, which we plan to conduct in a follow-up study.
Interestingly, the performance of the merged datasets increases even in cases where OI is not part of the dataset merge.
Given that we did not apply a sophisticated merging strategy, the performance increase for training with merged datasets is encouraging.
Developing strategies to improve the consistency of the merged dataset, e.â€‰g., weak labeling of categories not present in the respective merge partners, represents another promising line of future research.</span></p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text" style="font-size:90%;">We conclude that including an additional stage of object-detection pre-training can lead to a considerable increase in detection performance.
While our experiments suggest that style similarities between pre-training and target dataset are less important than matching categories, further experiments are needed to verify this hypothesis.</span></p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Acknowledgements</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text" style="font-size:90%;">We gratefully acknowledge the support of NVIDIA Corporation with the donation of the two Quadro RTX 8000 used for this research.
The paper has received funding by Odeuropa EU H2020 project under grant agreement No. 101004469.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="font-size:90%;">
Cecilia Bembibre and Matija StrliÄ.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.5.1" class="ltx_text" style="font-size:90%;">Smell of heritage: a framework for the identification, analysis and
archival of historic odours.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Heritage Science</span><span id="bib.bib1.7.2" class="ltx_text" style="font-size:90%;">, 5(1):1â€“11, 2017.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="font-size:90%;">
SofiaÂ Collette Ehrich, Caro Verbeek, Mathias Zinnen, Lizzie Marx, Cecilia
Bembibre, and Inger Leemans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.5.1" class="ltx_text" style="font-size:90%;">Nose first: Towards an olfactory gaze for digital art history.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">First International Workshop on Multisensory Data and
Knowledge</span><span id="bib.bib2.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Online accessed, December 09, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="font-size:90%;">
Mark Everingham, Luc VanÂ Gool, ChristopherÂ KI Williams, John Winn, and Andrew
Zisserman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.5.1" class="ltx_text" style="font-size:90%;">The pascal visual object classes (voc) challenge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International journal of computer vision</span><span id="bib.bib3.7.2" class="ltx_text" style="font-size:90%;">, 88(2):303â€“338, 2010.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">
Nicolas Gonthier, Yann Gousseau, Said Ladjal, and Olivier Bonfait.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.5.1" class="ltx_text" style="font-size:90%;">Weakly supervised object detection in artworks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV) Workshops</span><span id="bib.bib4.8.3" class="ltx_text" style="font-size:90%;">, pages 0â€“0, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="font-size:90%;">
Peter Hall, Hongping Cai, QiÂ Wu, and Tadeo Corradi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.5.1" class="ltx_text" style="font-size:90%;">Cross-depiction problem: Recognition and synthesis of photographs and
artwork.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computational Visual Media</span><span id="bib.bib5.7.2" class="ltx_text" style="font-size:90%;">, 1(2):91â€“103, 2015.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="font-size:90%;">
Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi
Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander
Kolesnikov, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.5.1" class="ltx_text" style="font-size:90%;">The open images dataset v4.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Computer Vision</span><span id="bib.bib6.7.2" class="ltx_text" style="font-size:90%;">, 128(7):1956â€“1981,
2020.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
Ramanan, Piotr DollÃ¡r, and CÂ Lawrence Zitnick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.5.1" class="ltx_text" style="font-size:90%;">Microsoft coco: Common objects in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib7.8.3" class="ltx_text" style="font-size:90%;">, pages 740â€“755.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="font-size:90%;">
Prathmesh Madhu, Angel Villar-Corrales, Ronak Kosti, Torsten Bendschus, Corinna
Reinhardt, Peter Bell, Andreas Maier, and Vincent Christlein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.5.1" class="ltx_text" style="font-size:90%;">Enhancing human pose estimation in ancient vase paintings via
perceptually-grounded style transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2012.05616</span><span id="bib.bib8.7.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">
Maria-Cristina Marinescu, Artem Reshetnikov, and JoaquimÂ MorÃ© LÃ³pez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.5.1" class="ltx_text" style="font-size:90%;">Improving object detection in paintings based on time contexts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 International Conference on Data Mining Workshops
(ICDMW)</span><span id="bib.bib9.8.3" class="ltx_text" style="font-size:90%;">, pages 926â€“932. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="font-size:90%;">
Lizzie Marx.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.5.1" class="ltx_text" style="font-size:90%;">Perfume and books of secret.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Exhibition Catalogue Mauritshuis,The Hague</span><span id="bib.bib10.7.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="font-size:90%;">
SinnoÂ Jialin Pan and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.5.1" class="ltx_text" style="font-size:90%;">A survey on transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on knowledge and data engineering</span><span id="bib.bib11.7.2" class="ltx_text" style="font-size:90%;">,
22(10):1345â€“1359, 2009.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.5.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: Towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib12.7.2" class="ltx_text" style="font-size:90%;">, 201, 2015.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="font-size:90%;">
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.5.1" class="ltx_text" style="font-size:90%;">Imagenet large scale visual recognition challenge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International journal of computer vision</span><span id="bib.bib13.7.2" class="ltx_text" style="font-size:90%;">, 115(3):211â€“252,
2015.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">
Nicholas Westlake, Hongping Cai, and Peter Hall.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.5.1" class="ltx_text" style="font-size:90%;">Detecting people in artwork with cnns.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib14.8.3" class="ltx_text" style="font-size:90%;">, pages 825â€“841.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="font-size:90%;">
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui
Xiong, and Qing He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.5.1" class="ltx_text" style="font-size:90%;">A comprehensive survey on transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE</span><span id="bib.bib15.7.2" class="ltx_text" style="font-size:90%;">, 109(1):43â€“76, 2020.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="font-size:90%;">
Mathias Zinnen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.5.1" class="ltx_text" style="font-size:90%;">How to see smells: Extracting olfactory references from artworks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Companion Proceedings of the Web Conference 2021</span><span id="bib.bib16.8.3" class="ltx_text" style="font-size:90%;">, pages
725â€“726, 2021.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2301.09905" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2301.09906" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2301.09906">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2301.09906" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2301.09907" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 05:23:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
