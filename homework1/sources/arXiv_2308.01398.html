<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.01398] A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry</title><meta property="og:description" content="This paper introduces a novel, small form-factor, aerial vehicle research platform for agile object detection, classification, tracking, and interaction tasks.
General-purpose hardware components were designed to augme…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.01398">

<!--Generated on Wed Feb 28 14:24:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document" style="font-size:173%;">A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with
Onboard Real-Time Object Detection
and Visual Odometry
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Cora A. Dimmig<sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">1</span></sup>,
Anna Goodridge<sup id="id10.10.id2" class="ltx_sup"><span id="id10.10.id2.1" class="ltx_text ltx_font_italic">2</span></sup>,
Gabriel Baraban<sup id="id11.11.id3" class="ltx_sup"><span id="id11.11.id3.1" class="ltx_text ltx_font_italic">1</span></sup>,
Pupei Zhu<sup id="id12.12.id4" class="ltx_sup"><span id="id12.12.id4.1" class="ltx_text ltx_font_italic">2</span></sup>,
Joyraj Bhowmick<sup id="id13.13.id5" class="ltx_sup"><span id="id13.13.id5.1" class="ltx_text ltx_font_italic">2</span></sup>,
and Marin Kobilarov<sup id="id14.14.id6" class="ltx_sup"><span id="id14.14.id6.1" class="ltx_text ltx_font_italic">1</span></sup>
</span><span class="ltx_author_notes"><sup id="id15.15.id1" class="ltx_sup"><span id="id15.15.id1.1" class="ltx_text ltx_font_italic">1</span></sup>Department of Mechanical Engineering and the Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD 21218, USA. Email: <span id="id16.16.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">cdimmig@jhu.edu, marin@jhu.edu</span><sup id="id17.17.id1" class="ltx_sup"><span id="id17.17.id1.1" class="ltx_text ltx_font_italic">2</span></sup>LCSR, Johns Hopkins University, Baltimore, MD 21218, USA.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id18.id1" class="ltx_p">This paper introduces a novel, small form-factor, aerial vehicle research platform for agile object detection, classification, tracking, and interaction tasks.
General-purpose hardware components were designed to augment a given aerial vehicle and enable it to perform safe and reliable grasping.
These components include a custom collision tolerant cage and low-cost Gripper Extension Package, which we call GREP, for object grasping.
Small vehicles enable applications in highly constrained environments, but are often limited by computational resources.
This work evaluates the challenges of pick-and-place tasks, with entirely onboard computation of object pose and visual odometry based state estimation on a small platform, and demonstrates experiments with enough accuracy to reliably grasp objects.
In a total of 70 trials across challenging cases such as cluttered environments, obstructed targets, and multiple instances of the same target, we demonstrated successfully grasping the target in 93% of trials.
Both the hardware component designs and software framework are released as open-source, since our intention is to enable easy reproduction and application on a wide range of small vehicles.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">INTRODUCTION</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, Uncrewed Aerial Vehicles (UAVs) have become increasingly popular for a wide variety of pick-and-place tasks such as package delivery, agriculture inspection, and warehouse management. Small agile vehicles are particularly advantageous for navigating in highly constrained environments. However, a small vehicle limits available sensing and computing options significantly, which makes running complex onboard algorithms such as image processing, motion planning, state estimation, and other intelligent autonomous functionalities challenging.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">This paper reports a novel, compact (1.7 kg, 31 cm frame) research UAV for studying aerial grasping applications in constrained environments with entirely onboard computation. We modified the UVify IFO-SX quadrotor to be collision tolerant with a carbon fiber foam cage, shock absorbing feet, and a modular Gripper Extension Package, which we call GREP. The fully configured vehicle is seen in Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We have open-sourced these designs for use with this vehicle and others. While the reported results are based on the IFO-SX, the proposed modular designs can be easily modified to enable aerial grasping using other base platforms.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2308.01398/assets/figures/quad_objects_gripper.jpg" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="407" height="238" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Aerial research platform, target objects (toy cans and bottles), and view of open gripper, <math id="S1.F1.3.m1.1" class="ltx_Math" alttext="9.5" display="inline"><semantics id="S1.F1.3.m1.1b"><mn id="S1.F1.3.m1.1.1" xref="S1.F1.3.m1.1.1.cmml">9.5</mn><annotation-xml encoding="MathML-Content" id="S1.F1.3.m1.1c"><cn type="float" id="S1.F1.3.m1.1.1.cmml" xref="S1.F1.3.m1.1.1">9.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.3.m1.1d">9.5</annotation></semantics></math> cm across, around <math id="S1.F1.4.m2.1" class="ltx_Math" alttext="6.5" display="inline"><semantics id="S1.F1.4.m2.1b"><mn id="S1.F1.4.m2.1.1" xref="S1.F1.4.m2.1.1.cmml">6.5</mn><annotation-xml encoding="MathML-Content" id="S1.F1.4.m2.1c"><cn type="float" id="S1.F1.4.m2.1.1.cmml" xref="S1.F1.4.m2.1.1">6.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.4.m2.1d">6.5</annotation></semantics></math> cm diameter can.</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2308.01398/assets/figures/quad_pick_clutter_side_view_brighter.jpg" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="407" height="239" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Autonomous system in flight grasping a can from a cluttered scene.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Furthermore, in this work, we present the integration of a task-level fault-tolerant state machine, precision model-based control, visual odometry, and real-time 6D object detection, classification, and tracking. These capabilities are implemented as modular components in an aerial autonomy software framework that can be extended to different tasks.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We first tested the proposed system in a high fidelity simulation and then in pick-and-place experiments on hardware, as seen in Fig. <a href="#S1.F2" title="Figure 2 ‣ I INTRODUCTION ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In an unknown environment, the system detects and tracks an object of interest using onboard visual pose estimation, visually servos to that object and grasps it, then detects a target destination and places the object.
Our objects of interest were 6.5 cm wide and our gripper opens 9.5 cm wide, which necessitated precise end-effector positioning.
We evaluated the system’s performance in single object environments, cluttered environments, with an obstructed view of the target, and viewing multiple instances of the same object.
A set of 70 pick-and-place hardware experiments in these challenging scenarios yielded 93% pick action success and 86% place action success.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">CONTRIBUTIONS</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The objective of this paper is to provide technical details of this newly developed platform, to analyze experimentally its performance, and to discuss challenges towards robust pick-and-place operation in constrained environments.
This work does not present any novel algorithmic developments.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Vehicle Design Contributions</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Our first objective was to design modular hardware components to enable safe aerial grasping with small UAVs in indoor settings. The contributions include:</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">Design of a light-weight collision tolerant cage and shock absorbing feet to enhance safety and reliability in constrained environments</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">Design of a low-cost, lightweight fixed arm with an angular motion gripper, including grip detection circuit</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">Open-source<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Design Information and Files: <a target="_blank" href="https://grabcad.com/library/ifo-sx-cage-and-gripper-extension-package-grep-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://grabcad.com/library/ifo-sx-cage-and-gripper-extension-package-grep-1</a></span></span></span> design files for easy reproduction</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">System Integration and Evaluation Contributions</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Our second objective was to evaluate performance in pick-and-place experiments. Such analysis is useful since few other small form-factor aerial grasping vehicles have been reported with entirely onboard computation
for image processing, 6D object pose estimation, state estimation, and motion planning. The contributions include:
</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">New real-time software that integrates established, computationally intensive algorithms on a small platform</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">High-fidelity simulation for algorithm evaluation and development that can be seamlessly run on hardware</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">Experimental results demonstrating the robustness of our proposed architecture</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p id="S2.I2.i4.p1.1" class="ltx_p">Evaluation of challenges for robust pick-and-place in constrained environments of increasing levels of complexity in terms of clutter and occlusion</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">RELATED WORK</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Aerial Manipulation Platforms</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Aerial manipulation research has been of increasing importance in the last decade <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Platforms for aerial manipulation are often specialized to the application space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, research goals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, or focused on innovative vehicle or manipulator designs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Few standardized, small aerial manipulation platforms are presented due to the variability in requirements for the platform and manipulator.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We sought a generalized research platform to investigate pick-and-place challenges in constrained environments with entirely onboard computation. Our main decision points were: (1) availability of the frame or base platform, (2) size of the vehicle (ideally less than 40 cm frame), (3) payload (for a manipulator and object), and (4) compute capabilities (including a GPU for machine learning).</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In many cases aerial platforms are built around standard frames that have since gone obsolete, such as the Matrice 100 used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> and DJI Flamewheels used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Exciting recent work towards a standardized small, agile platform is presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, however this platform is too small to support a manipulator. Conversely, the frames used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> are too large for our intended application space.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">Ultimately, we determined UVify’s IFO-SX met our criteria for a baseline research platform.
We then designed modular, lightweight safety and manipulator additions for this platform that can be easily transferred to other platforms. We offer these designs open-source to the community to aid in entering the aerial grasping space with small vehicles.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Robust flight in constrained spaces requires considering collisions with the environment. Innovative work towards collision tolerant flying robots
present specialized aerial platforms designed around protective elements,
as seen in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.
For our reproducible research platform, we designed our cage to fit over an existing frame, such that the design could be adapted for new frames, not be required for flight, and be replaceable if it were to get damaged.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Quadrotor Pose Estimation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Precision control requires robust and accurate pose estimation.
For this, motion capture systems are widely used, as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Similarly, GPS is common, as used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. However, for real world indoor applications, neither of these approaches would be practical.
Visual Odometry (VO) methods estimate autonomous vehicles’ state using a stream of images captured by onboard cameras <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. VO approaches have been widely used on aerial platforms, as seen in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.
In this work, we use a stereo keyframe-based VO approach from the NVIDIA Isaac Software Development Kit (SDK) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. As part of the NVIDIA Isaac SDK, it is computationally efficient on our onboard Jetson Xavier NX.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Object Pose Estimation</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">An integral part of aerial manipulation is the perception of the payload object pose. Some systems place the object at a known location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, or rely on fiducial markers for 6-degree-of-freedom (DOF) position tracking relative to an onboard camera, as used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. Motion capture systems can provide sub-centimeter accuracy and are highly prevalent, e.g. in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
Unfortunately, these methods are not applicable to our setting, since we assume that the environment is not instrumented and objects can be at arbitrary locations.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Visual object pose estimation can be solved through machine learning techniques, e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, with computational requirements that are typically prohibitive for onboard computation on small UAVs.
We looked to evaluate performance with entirely onboard computation using a common, off-the-shelf algorithm, for which we have not found previous studies on a small platform. For this purpose, we selected Deep Object Pose Estimation (DOPE) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, a neural network for 6-DOF pose estimation of a set of known objects.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">HARDWARE</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Compact Quadrotor Research Platform</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The IFO-SX has a 31 cm frame, 18 cm propellers, and base weight of 1.38 kg.
In this small form factor it comes equipped with a NVIDIA Jetson Xavier NX for computation, a Realsense D435i for IMU data and color, depth, and stereo infrared images, and a PX4-based autopilot.
Our weight budget for additions to the platform was 300 g calculated based off of an experimentally evaluated maximum vehicle payload and an additional 100 g for the grasped object. Therefore, weight was a driving requirement for all designs.
</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">We designed and fabricated a custom, carbon fiber foam core cage for safety and robustness to collisions. Carbon fiber foam core allows for minimal structure (keeping sensor regions free) and thus minimal weight, while maintaining rigidity. The structure was designed to protect the propellers in case of a crash and in such a way that the cage’s 2D contours could be cut and assembled with enough surface area for adhesion with epoxy.
We developed shock-absorbing feet to strain under the impact load of a hard vehicle landing much like the crumple zone of a car. Capitalizing on a monolithic structure, preexisting mounting points on the vehicle’s legs, and the ubiquity of 3D printers, the feet are 3D printed ABS with a final weight of 5g each, deflect up to 5mm before breaking, and are inexpensive enough to be replaced after hard landings.
</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">The modified platform fully configured, as seen in
Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, has a mass of 1.67 kg. Table <a href="#S4.T1" title="TABLE I ‣ IV-A Compact Quadrotor Research Platform ‣ IV HARDWARE ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> and the design files<math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="{}^{\ref{fn:design}}" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><msup id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mi id="S4.SS1.p3.1.m1.1.1a" xref="S4.SS1.p3.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_italic" id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1c.cmml"><a href="#footnote1" title="footnote 1 ‣ 3rd item ‣ II-A Vehicle Design Contributions ‣ II CONTRIBUTIONS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref ltx_font_italic" style="font-size:70%;"><span class="ltx_text ltx_ref_tag">1</span></a></mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><ci id="S4.SS1.p3.1.m1.1.1.1c.cmml" xref="S4.SS1.p3.1.m1.1.1.1"><mtext class="ltx_mathvariant_italic" mathsize="70%" id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1"><a href="#footnote1" title="footnote 1 ‣ 3rd item ‣ II-A Vehicle Design Contributions ‣ II CONTRIBUTIONS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref ltx_font_italic" style="font-size:70%;"><span class="ltx_text ltx_ref_tag">1</span></a></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">{}^{\ref{fn:design}}</annotation></semantics></math> include more detailed information about the custom components. Fig. <a href="#S4.F3" title="Figure 3 ‣ IV-A Compact Quadrotor Research Platform ‣ IV HARDWARE ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the modular components added to the base vehicle in the CAD model. These components were all designed to easily bolt on to an existing platform.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Custom Modular Designs for Robustness and Grasping </figcaption>
<table id="S4.T1.11.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.2.2" class="ltx_tr">
<th id="S4.T1.2.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.2.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.2.3.1.1" class="ltx_p" style="width:91.0pt;"><span id="S4.T1.2.2.2.3.1.1.1" class="ltx_text ltx_font_bold">Component</span></span>
</span>
</th>
<th id="S4.T1.2.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.2.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.2.4.1.1" class="ltx_p" style="width:37.0pt;"><span id="S4.T1.2.2.2.4.1.1.1" class="ltx_text ltx_font_bold">Weight [g]</span></span>
</span>
</th>
<th id="S4.T1.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.2.2.2.2.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.2.2.2.2" class="ltx_p" style="width:39.8pt;"><span id="S4.T1.2.2.2.2.2.2.2" class="ltx_text ltx_font_bold">Dimensions (L<math id="S4.T1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.1.1.1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.1.m1.1b"><times id="S4.T1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.1.m1.1c">\times</annotation></semantics></math>W<math id="S4.T1.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.2.2.2.2.2.2.2.m2.1a"><mo id="S4.T1.2.2.2.2.2.2.2.m2.1.1" xref="S4.T1.2.2.2.2.2.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.2.2.2.m2.1b"><times id="S4.T1.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.2.2.2.m2.1c">\times</annotation></semantics></math>H) [mm]</span></span>
</span>
</th>
<th id="S4.T1.2.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.2.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.2.2.2.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T1.2.2.2.5.1.1.1" class="ltx_text ltx_font_bold">Cost [$]</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.11.11.12.1" class="ltx_tr">
<td id="S4.T1.11.11.12.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.12.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.12.1.1.1.1" class="ltx_p" style="width:91.0pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.12.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.12.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.12.1.2.1.1" class="ltx_p" style="width:37.0pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.12.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.12.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.12.1.3.1.1" class="ltx_p" style="width:39.8pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.12.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;"></td>
</tr>
<tr id="S4.T1.5.5.5" class="ltx_tr">
<td id="S4.T1.3.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.3.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.3.3.1.1.1" class="ltx_p" style="width:91.0pt;"><img src="/html/2308.01398/assets/figures/Cage.png" id="S4.T1.3.3.3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="90" height="65" alt="[Uncaptioned image]"> 
<br class="ltx_break ltx_centering">Collision-Tolerant Cage</span>
</span>
</td>
<td id="S4.T1.5.5.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.5.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.4.1.1" class="ltx_p" style="width:37.0pt;">162</span>
</span>
</td>
<td id="S4.T1.5.5.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.5.5.5.3.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.3.2.2" class="ltx_p" style="width:39.8pt;">440 <math id="S4.T1.4.4.4.2.1.1.m1.1" class="ltx_centering" alttext="\times" display="inline"><semantics id="S4.T1.4.4.4.2.1.1.m1.1a"><mo id="S4.T1.4.4.4.2.1.1.m1.1.1" xref="S4.T1.4.4.4.2.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.2.1.1.m1.1b"><times id="S4.T1.4.4.4.2.1.1.m1.1.1.cmml" xref="S4.T1.4.4.4.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.2.1.1.m1.1c">\times</annotation></semantics></math> 440 <math id="S4.T1.5.5.5.3.2.2.m2.1" class="ltx_centering" alttext="\times" display="inline"><semantics id="S4.T1.5.5.5.3.2.2.m2.1a"><mo id="S4.T1.5.5.5.3.2.2.m2.1.1" xref="S4.T1.5.5.5.3.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.3.2.2.m2.1b"><times id="S4.T1.5.5.5.3.2.2.m2.1.1.cmml" xref="S4.T1.5.5.5.3.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.3.2.2.m2.1c">\times</annotation></semantics></math> 200</span>
</span>
</td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.5.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.5.5.5.5.1.1" class="ltx_p" style="width:28.5pt;">516</span>
</span>
</td>
</tr>
<tr id="S4.T1.11.11.13.2" class="ltx_tr">
<td id="S4.T1.11.11.13.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.13.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.13.2.1.1.1" class="ltx_p" style="width:91.0pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.13.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.13.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.13.2.2.1.1" class="ltx_p" style="width:37.0pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.13.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.13.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.13.2.3.1.1" class="ltx_p" style="width:39.8pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.13.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-bottom:-12.91663pt;padding-top:1.5pt;padding-bottom:1.5pt;"></td>
</tr>
<tr id="S4.T1.8.8.8" class="ltx_tr">
<td id="S4.T1.6.6.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.6.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.6.6.6.1.1.1" class="ltx_p" style="width:91.0pt;"><img src="/html/2308.01398/assets/figures/Gripper.png" id="S4.T1.6.6.6.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="91" height="27" alt="[Uncaptioned image]"> 
<br class="ltx_break ltx_centering">Gripper Extension Package</span>
</span>
</td>
<td id="S4.T1.8.8.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.8.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.4.1.1" class="ltx_p" style="width:37.0pt;">91</span>
</span>
</td>
<td id="S4.T1.8.8.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.8.8.8.3.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.3.2.2" class="ltx_p" style="width:39.8pt;">440 <math id="S4.T1.7.7.7.2.1.1.m1.1" class="ltx_centering" alttext="\times" display="inline"><semantics id="S4.T1.7.7.7.2.1.1.m1.1a"><mo id="S4.T1.7.7.7.2.1.1.m1.1.1" xref="S4.T1.7.7.7.2.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.7.2.1.1.m1.1b"><times id="S4.T1.7.7.7.2.1.1.m1.1.1.cmml" xref="S4.T1.7.7.7.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.7.2.1.1.m1.1c">\times</annotation></semantics></math> 120 <math id="S4.T1.8.8.8.3.2.2.m2.1" class="ltx_centering" alttext="\times" display="inline"><semantics id="S4.T1.8.8.8.3.2.2.m2.1a"><mo id="S4.T1.8.8.8.3.2.2.m2.1.1" xref="S4.T1.8.8.8.3.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.8.3.2.2.m2.1b"><times id="S4.T1.8.8.8.3.2.2.m2.1.1.cmml" xref="S4.T1.8.8.8.3.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.8.3.2.2.m2.1c">\times</annotation></semantics></math> 45</span>
</span>
</td>
<td id="S4.T1.8.8.8.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.8.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.8.8.8.5.1.1" class="ltx_p" style="width:28.5pt;">43</span>
</span>
</td>
</tr>
<tr id="S4.T1.11.11.14.3" class="ltx_tr">
<td id="S4.T1.11.11.14.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-bottom:-10.76385pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.14.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.14.3.1.1.1" class="ltx_p" style="width:91.0pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.14.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-bottom:-10.76385pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.14.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.14.3.2.1.1" class="ltx_p" style="width:37.0pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.14.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-bottom:-10.76385pt;padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.14.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.14.3.3.1.1" class="ltx_p" style="width:39.8pt;"></span>
</span>
</td>
<td id="S4.T1.11.11.14.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-bottom:-10.76385pt;padding-top:1.5pt;padding-bottom:1.5pt;"></td>
</tr>
<tr id="S4.T1.11.11.11" class="ltx_tr">
<td id="S4.T1.9.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.9.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.9.9.9.1.1.1" class="ltx_p" style="width:91.0pt;">    <img src="/html/2308.01398/assets/figures/Foot.png" id="S4.T1.9.9.9.1.1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="48" height="58" alt="[Uncaptioned image]"> 
<br class="ltx_break ltx_centering">Shock Absorbing Foot</span>
</span>
</td>
<td id="S4.T1.11.11.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.11.4.1.1" class="ltx_p" style="width:37.0pt;">5</span>
</span>
</td>
<td id="S4.T1.11.11.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.11.3.2" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.11.3.2.2" class="ltx_p" style="width:39.8pt;">36 <math id="S4.T1.10.10.10.2.1.1.m1.1" class="ltx_centering" alttext="\times" display="inline"><semantics id="S4.T1.10.10.10.2.1.1.m1.1a"><mo id="S4.T1.10.10.10.2.1.1.m1.1.1" xref="S4.T1.10.10.10.2.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.10.10.10.2.1.1.m1.1b"><times id="S4.T1.10.10.10.2.1.1.m1.1.1.cmml" xref="S4.T1.10.10.10.2.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.10.10.10.2.1.1.m1.1c">\times</annotation></semantics></math> 14   <math id="S4.T1.11.11.11.3.2.2.m2.1" class="ltx_centering" alttext="\times" display="inline"><semantics id="S4.T1.11.11.11.3.2.2.m2.1a"><mo id="S4.T1.11.11.11.3.2.2.m2.1.1" xref="S4.T1.11.11.11.3.2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.11.3.2.2.m2.1b"><times id="S4.T1.11.11.11.3.2.2.m2.1.1.cmml" xref="S4.T1.11.11.11.3.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.11.3.2.2.m2.1c">\times</annotation></semantics></math> 52</span>
</span>
</td>
<td id="S4.T1.11.11.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T1.11.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.11.11.11.5.1.1" class="ltx_p" style="width:28.5pt;">1</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2308.01398/assets/figures/FullCAD.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="260" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>CAD model of vehicle with integrated modular components.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Gripper Extension Package</span>
</h3>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2308.01398/assets/figures/gripper.jpg" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>GREP: Fixed arm with angular motion gripper.</figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We designed a low-cost, easy to reproduce, lightweight 2-jaw angular motion Gripper Extension Package (GREP) for picking up small objects, as seen in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Gripper Extension Package ‣ IV HARDWARE ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
GREP includes standard hardware and 3D printed ABS mounts, jaws, and linkages. All design files are open-source<math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="{}^{\ref{fn:design}}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1a" xref="S4.SS2.p1.1.m1.1.1.cmml"></mi><mtext class="ltx_mathvariant_italic" id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1c.cmml"><a href="#footnote1" title="footnote 1 ‣ 3rd item ‣ II-A Vehicle Design Contributions ‣ II CONTRIBUTIONS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref ltx_font_italic" style="font-size:70%;"><span class="ltx_text ltx_ref_tag">1</span></a></mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><ci id="S4.SS2.p1.1.m1.1.1.1c.cmml" xref="S4.SS2.p1.1.m1.1.1.1"><mtext class="ltx_mathvariant_italic" mathsize="70%" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"><a href="#footnote1" title="footnote 1 ‣ 3rd item ‣ II-A Vehicle Design Contributions ‣ II CONTRIBUTIONS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref ltx_font_italic" style="font-size:70%;"><span class="ltx_text ltx_ref_tag">1</span></a></mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">{}^{\ref{fn:design}}</annotation></semantics></math>. The horizontal design minimizes complexity, enabling a final GREP weight of 91 g, and allows for easy adaptation onto other platforms.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The length of the extension is set by an acrylic tube that can be swapped depending on the application. On this vehicle we used a 22.5 cm tube for 22 cm of extension from the edge of the cage to the tip of the jaws.
There is a rubber layer on the inside jaw surface to increase the coefficient of friction between the jaws and the target object.
As mounted in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-B Gripper Extension Package ‣ IV HARDWARE ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the gripper’s max payload is 1 kg (11 times GREP’s weight) before objects slip out, when tested with a toy can.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.2" class="ltx_p">The gripper is actuated by an onboard servo motor with a winch mechanism that pulls the gripper closed.
A spring mounted between the gripper linkages and pivot point assists returning the gripper to its open position.
The servo motor is controlled via a Seeeduino XIAO microcontroller.
Two snap-action switches at the gripper opening are used to determine if an object is gripped. The gripper opens about <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="9.5" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">9.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><cn type="float" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">9.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">9.5</annotation></semantics></math> cm at its widest point and the target objects in this report are about <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="6.5" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mn id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">6.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><cn type="float" id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">6.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">6.5</annotation></semantics></math> cm in diameter, as seen in Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Therefore, high precision control is necessary for successful grasping.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">SOFTWARE FRAMEWORK</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We designed our software in the Robot Operating System (ROS) to be highly modular for integration with different vehicles, manipulators, object detectors, and state estimators. Fig. <a href="#S5.F5" title="Figure 5 ‣ V-A Aerial Autonomy ‣ V SOFTWARE FRAMEWORK ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the key components and information flow.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Aerial Autonomy</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We use the Aerial Autonomy (AA) framework<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/jhu-asco/aerial_autonomy" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jhu-asco/aerial_autonomy</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
for task definition. We expanded this framework for use with: (1) a PX4-enabled vehicle, (2) a fixed angular motion gripper, (3) vision based object detection, and (4) VO.
For the evaluation reported herein, we used established object detection and VO algorithms, but
these high-level contributions to AA allow for easily exchanging hardware and algorithmic components.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Using these additions to the AA framework, we designed a fault-tolerant finite state machine, which continuously checks for controller and hardware failures
to allow for quick and safe recovery.
For “high level” control through Roll-Pitch-Yawrate-Thrust commands, we employ an acceleration-based controller to track a polynomial reference trajectory as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
The 9th degree polynomial reference trajectory starts from the vehicle’s position and yaw at initialization and terminates at a final position and yaw determined by the task, such as relative to an object of interest.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2308.01398/assets/figures/aa_state_machine_vo.jpg" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="509" height="429" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Software flow diagram showing a simplified pick-and-place state machine, begins at “Waiting to Pick” state.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Aerial Autonomy State Machine</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Fig. <a href="#S5.F5" title="Figure 5 ‣ V-A Aerial Autonomy ‣ V SOFTWARE FRAMEWORK ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> depicts a simplified version of the AA state machine. The vehicle starts with the object of interest in the field of view of the camera. AA begins tracking the object based on the detections from DOPE.
Mirroring the object’s yaw,
the vehicle flies to relative pre-pick and pick positions, resulting in the gripper encircling the target object and commands the gripper to close. When approaching the pick position the gripper will begin to obstruct detection of the target object and the last filtered estimate of the object’s location is used.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The system is continuously checking for system faults, such as the target object not being grasped, tracking of the object timing out, and error in the vertical axis or rotational error being above specified thresholds when entering the pick grasping region. If a fault is encountered, the vehicle resets to its original pose and looks for the object of interest again.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">If the target object is detected as successfully grasped, the vehicle moves to a post-pick waypoint, with respect to the pick position, and begins looking for the destination object. We implemented a simple search routine for the vehicle to incrementally move downwards if the destination object is not detected. Once the destination object is found, the vehicle goes to relative pre-place and place positions and releases the target object to the right of the destination object.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Quadrotor Pose Estimation</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We use stereo VO from NVIDIA’s Isaac SDK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> for pose estimation of the vehicle.
We selected this approach since it is an established algorithm optimized for our onboard computer. The VO approach operates on the stereo infrared images from the Realsense D435i, with the emitter turned off, and uses the Elburs VO library for calculation of the 3D pose of the vehicle. Running onboard the Jetson Xavier NX with the rest of our software stack, the VO publishes at about 15 Hz. We experimentally determined this to be insufficient for precision control and calculating velocities.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">To improve the state estimation, we fuse the VO estimate with the onboard PX4 Extended Kalman Filter (EKF), which we publish more reliably at about 40 Hz.
We are operating indoors without GPS, so the fused PX4 state estimation comes from the onboard VO, gyroscope, accelerometer, and magnetometer.
The high level controller uses this fused state estimate to calculate Roll-Pitch-Yawrate-Thrust commands, which are then passed to the low level PX4 controller.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">Object Pose Estimation and Grasp Strategy</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">For 6-degree-of-freedom (DOF) pose estimation and classification of objects, we use DOPE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. DOPE predicts the pose of known classes of objects from a single RGB image. We have integrated our code base with the instantiation of DOPE in NVIDIA’s Isaac SDK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> for an off-the-shelf baseline of entirely onboard computation.
We pass Realsense camera imagery and object detection and classification information through a custom Isaac ROS bridge.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.4" class="ltx_p">We use the object detections from DOPE for object tracking in AA.
To refine the poses provided by DOPE, we remove invalid poses and filter the poses.
We remove invalid poses by checking if the pose is in the camera’s field of view, or frustum. We do this by projecting the pose into pixel coordinates, using the camera intrinsic matrix, and evaluating if that pixel is within the bounds of the image. For focal length <math id="S5.SS4.p2.1.m1.2" class="ltx_Math" alttext="(f_{x},f_{y})" display="inline"><semantics id="S5.SS4.p2.1.m1.2a"><mrow id="S5.SS4.p2.1.m1.2.2.2" xref="S5.SS4.p2.1.m1.2.2.3.cmml"><mo stretchy="false" id="S5.SS4.p2.1.m1.2.2.2.3" xref="S5.SS4.p2.1.m1.2.2.3.cmml">(</mo><msub id="S5.SS4.p2.1.m1.1.1.1.1" xref="S5.SS4.p2.1.m1.1.1.1.1.cmml"><mi id="S5.SS4.p2.1.m1.1.1.1.1.2" xref="S5.SS4.p2.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S5.SS4.p2.1.m1.1.1.1.1.3" xref="S5.SS4.p2.1.m1.1.1.1.1.3.cmml">x</mi></msub><mo id="S5.SS4.p2.1.m1.2.2.2.4" xref="S5.SS4.p2.1.m1.2.2.3.cmml">,</mo><msub id="S5.SS4.p2.1.m1.2.2.2.2" xref="S5.SS4.p2.1.m1.2.2.2.2.cmml"><mi id="S5.SS4.p2.1.m1.2.2.2.2.2" xref="S5.SS4.p2.1.m1.2.2.2.2.2.cmml">f</mi><mi id="S5.SS4.p2.1.m1.2.2.2.2.3" xref="S5.SS4.p2.1.m1.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S5.SS4.p2.1.m1.2.2.2.5" xref="S5.SS4.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.2b"><interval closure="open" id="S5.SS4.p2.1.m1.2.2.3.cmml" xref="S5.SS4.p2.1.m1.2.2.2"><apply id="S5.SS4.p2.1.m1.1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p2.1.m1.1.1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S5.SS4.p2.1.m1.1.1.1.1.2.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1.2">𝑓</ci><ci id="S5.SS4.p2.1.m1.1.1.1.1.3.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1.3">𝑥</ci></apply><apply id="S5.SS4.p2.1.m1.2.2.2.2.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS4.p2.1.m1.2.2.2.2.1.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S5.SS4.p2.1.m1.2.2.2.2.2.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.2">𝑓</ci><ci id="S5.SS4.p2.1.m1.2.2.2.2.3.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.3">𝑦</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.2c">(f_{x},f_{y})</annotation></semantics></math> and principal point <math id="S5.SS4.p2.2.m2.2" class="ltx_Math" alttext="(c_{x},c_{y})" display="inline"><semantics id="S5.SS4.p2.2.m2.2a"><mrow id="S5.SS4.p2.2.m2.2.2.2" xref="S5.SS4.p2.2.m2.2.2.3.cmml"><mo stretchy="false" id="S5.SS4.p2.2.m2.2.2.2.3" xref="S5.SS4.p2.2.m2.2.2.3.cmml">(</mo><msub id="S5.SS4.p2.2.m2.1.1.1.1" xref="S5.SS4.p2.2.m2.1.1.1.1.cmml"><mi id="S5.SS4.p2.2.m2.1.1.1.1.2" xref="S5.SS4.p2.2.m2.1.1.1.1.2.cmml">c</mi><mi id="S5.SS4.p2.2.m2.1.1.1.1.3" xref="S5.SS4.p2.2.m2.1.1.1.1.3.cmml">x</mi></msub><mo id="S5.SS4.p2.2.m2.2.2.2.4" xref="S5.SS4.p2.2.m2.2.2.3.cmml">,</mo><msub id="S5.SS4.p2.2.m2.2.2.2.2" xref="S5.SS4.p2.2.m2.2.2.2.2.cmml"><mi id="S5.SS4.p2.2.m2.2.2.2.2.2" xref="S5.SS4.p2.2.m2.2.2.2.2.2.cmml">c</mi><mi id="S5.SS4.p2.2.m2.2.2.2.2.3" xref="S5.SS4.p2.2.m2.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S5.SS4.p2.2.m2.2.2.2.5" xref="S5.SS4.p2.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.2.m2.2b"><interval closure="open" id="S5.SS4.p2.2.m2.2.2.3.cmml" xref="S5.SS4.p2.2.m2.2.2.2"><apply id="S5.SS4.p2.2.m2.1.1.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p2.2.m2.1.1.1.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1.1.1">subscript</csymbol><ci id="S5.SS4.p2.2.m2.1.1.1.1.2.cmml" xref="S5.SS4.p2.2.m2.1.1.1.1.2">𝑐</ci><ci id="S5.SS4.p2.2.m2.1.1.1.1.3.cmml" xref="S5.SS4.p2.2.m2.1.1.1.1.3">𝑥</ci></apply><apply id="S5.SS4.p2.2.m2.2.2.2.2.cmml" xref="S5.SS4.p2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS4.p2.2.m2.2.2.2.2.1.cmml" xref="S5.SS4.p2.2.m2.2.2.2.2">subscript</csymbol><ci id="S5.SS4.p2.2.m2.2.2.2.2.2.cmml" xref="S5.SS4.p2.2.m2.2.2.2.2.2">𝑐</ci><ci id="S5.SS4.p2.2.m2.2.2.2.2.3.cmml" xref="S5.SS4.p2.2.m2.2.2.2.2.3">𝑦</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.2.m2.2c">(c_{x},c_{y})</annotation></semantics></math>, the point <math id="S5.SS4.p2.3.m3.3" class="ltx_Math" alttext="(x,y,z)" display="inline"><semantics id="S5.SS4.p2.3.m3.3a"><mrow id="S5.SS4.p2.3.m3.3.4.2" xref="S5.SS4.p2.3.m3.3.4.1.cmml"><mo stretchy="false" id="S5.SS4.p2.3.m3.3.4.2.1" xref="S5.SS4.p2.3.m3.3.4.1.cmml">(</mo><mi id="S5.SS4.p2.3.m3.1.1" xref="S5.SS4.p2.3.m3.1.1.cmml">x</mi><mo id="S5.SS4.p2.3.m3.3.4.2.2" xref="S5.SS4.p2.3.m3.3.4.1.cmml">,</mo><mi id="S5.SS4.p2.3.m3.2.2" xref="S5.SS4.p2.3.m3.2.2.cmml">y</mi><mo id="S5.SS4.p2.3.m3.3.4.2.3" xref="S5.SS4.p2.3.m3.3.4.1.cmml">,</mo><mi id="S5.SS4.p2.3.m3.3.3" xref="S5.SS4.p2.3.m3.3.3.cmml">z</mi><mo stretchy="false" id="S5.SS4.p2.3.m3.3.4.2.4" xref="S5.SS4.p2.3.m3.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.3.m3.3b"><vector id="S5.SS4.p2.3.m3.3.4.1.cmml" xref="S5.SS4.p2.3.m3.3.4.2"><ci id="S5.SS4.p2.3.m3.1.1.cmml" xref="S5.SS4.p2.3.m3.1.1">𝑥</ci><ci id="S5.SS4.p2.3.m3.2.2.cmml" xref="S5.SS4.p2.3.m3.2.2">𝑦</ci><ci id="S5.SS4.p2.3.m3.3.3.cmml" xref="S5.SS4.p2.3.m3.3.3">𝑧</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.3.m3.3c">(x,y,z)</annotation></semantics></math> can be projected to <math id="S5.SS4.p2.4.m4.2" class="ltx_Math" alttext="(u,v)" display="inline"><semantics id="S5.SS4.p2.4.m4.2a"><mrow id="S5.SS4.p2.4.m4.2.3.2" xref="S5.SS4.p2.4.m4.2.3.1.cmml"><mo stretchy="false" id="S5.SS4.p2.4.m4.2.3.2.1" xref="S5.SS4.p2.4.m4.2.3.1.cmml">(</mo><mi id="S5.SS4.p2.4.m4.1.1" xref="S5.SS4.p2.4.m4.1.1.cmml">u</mi><mo id="S5.SS4.p2.4.m4.2.3.2.2" xref="S5.SS4.p2.4.m4.2.3.1.cmml">,</mo><mi id="S5.SS4.p2.4.m4.2.2" xref="S5.SS4.p2.4.m4.2.2.cmml">v</mi><mo stretchy="false" id="S5.SS4.p2.4.m4.2.3.2.3" xref="S5.SS4.p2.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.4.m4.2b"><interval closure="open" id="S5.SS4.p2.4.m4.2.3.1.cmml" xref="S5.SS4.p2.4.m4.2.3.2"><ci id="S5.SS4.p2.4.m4.1.1.cmml" xref="S5.SS4.p2.4.m4.1.1">𝑢</ci><ci id="S5.SS4.p2.4.m4.2.2.cmml" xref="S5.SS4.p2.4.m4.2.2">𝑣</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.4.m4.2c">(u,v)</annotation></semantics></math> as follows.</p>
<table id="Sx1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S5.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S5.E1.m1.2" class="ltx_Math" alttext="\displaystyle(u,v)" display="inline"><semantics id="S5.E1.m1.2a"><mrow id="S5.E1.m1.2.3.2" xref="S5.E1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.E1.m1.2.3.2.1" xref="S5.E1.m1.2.3.1.cmml">(</mo><mi id="S5.E1.m1.1.1" xref="S5.E1.m1.1.1.cmml">u</mi><mo id="S5.E1.m1.2.3.2.2" xref="S5.E1.m1.2.3.1.cmml">,</mo><mi id="S5.E1.m1.2.2" xref="S5.E1.m1.2.2.cmml">v</mi><mo stretchy="false" id="S5.E1.m1.2.3.2.3" xref="S5.E1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m1.2b"><interval closure="open" id="S5.E1.m1.2.3.1.cmml" xref="S5.E1.m1.2.3.2"><ci id="S5.E1.m1.1.1.cmml" xref="S5.E1.m1.1.1">𝑢</ci><ci id="S5.E1.m1.2.2.cmml" xref="S5.E1.m1.2.2">𝑣</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m1.2c">\displaystyle(u,v)</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S5.E1.m2.2" class="ltx_Math" alttext="\displaystyle=\frac{1}{z}\bigg{(}f_{x}x+c_{x}z,~{}f_{y}y+c_{y}z\bigg{)}" display="inline"><semantics id="S5.E1.m2.2a"><mrow id="S5.E1.m2.2.2" xref="S5.E1.m2.2.2.cmml"><mi id="S5.E1.m2.2.2.4" xref="S5.E1.m2.2.2.4.cmml"></mi><mo id="S5.E1.m2.2.2.3" xref="S5.E1.m2.2.2.3.cmml">=</mo><mrow id="S5.E1.m2.2.2.2" xref="S5.E1.m2.2.2.2.cmml"><mstyle displaystyle="true" id="S5.E1.m2.2.2.2.4" xref="S5.E1.m2.2.2.2.4.cmml"><mfrac id="S5.E1.m2.2.2.2.4a" xref="S5.E1.m2.2.2.2.4.cmml"><mn id="S5.E1.m2.2.2.2.4.2" xref="S5.E1.m2.2.2.2.4.2.cmml">1</mn><mi id="S5.E1.m2.2.2.2.4.3" xref="S5.E1.m2.2.2.2.4.3.cmml">z</mi></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S5.E1.m2.2.2.2.3" xref="S5.E1.m2.2.2.2.3.cmml">​</mo><mrow id="S5.E1.m2.2.2.2.2.2" xref="S5.E1.m2.2.2.2.2.3.cmml"><mo maxsize="210%" minsize="210%" id="S5.E1.m2.2.2.2.2.2.3" xref="S5.E1.m2.2.2.2.2.3.cmml">(</mo><mrow id="S5.E1.m2.1.1.1.1.1.1" xref="S5.E1.m2.1.1.1.1.1.1.cmml"><mrow id="S5.E1.m2.1.1.1.1.1.1.2" xref="S5.E1.m2.1.1.1.1.1.1.2.cmml"><msub id="S5.E1.m2.1.1.1.1.1.1.2.2" xref="S5.E1.m2.1.1.1.1.1.1.2.2.cmml"><mi id="S5.E1.m2.1.1.1.1.1.1.2.2.2" xref="S5.E1.m2.1.1.1.1.1.1.2.2.2.cmml">f</mi><mi id="S5.E1.m2.1.1.1.1.1.1.2.2.3" xref="S5.E1.m2.1.1.1.1.1.1.2.2.3.cmml">x</mi></msub><mo lspace="0em" rspace="0em" id="S5.E1.m2.1.1.1.1.1.1.2.1" xref="S5.E1.m2.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S5.E1.m2.1.1.1.1.1.1.2.3" xref="S5.E1.m2.1.1.1.1.1.1.2.3.cmml">x</mi></mrow><mo id="S5.E1.m2.1.1.1.1.1.1.1" xref="S5.E1.m2.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S5.E1.m2.1.1.1.1.1.1.3" xref="S5.E1.m2.1.1.1.1.1.1.3.cmml"><msub id="S5.E1.m2.1.1.1.1.1.1.3.2" xref="S5.E1.m2.1.1.1.1.1.1.3.2.cmml"><mi id="S5.E1.m2.1.1.1.1.1.1.3.2.2" xref="S5.E1.m2.1.1.1.1.1.1.3.2.2.cmml">c</mi><mi id="S5.E1.m2.1.1.1.1.1.1.3.2.3" xref="S5.E1.m2.1.1.1.1.1.1.3.2.3.cmml">x</mi></msub><mo lspace="0em" rspace="0em" id="S5.E1.m2.1.1.1.1.1.1.3.1" xref="S5.E1.m2.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S5.E1.m2.1.1.1.1.1.1.3.3" xref="S5.E1.m2.1.1.1.1.1.1.3.3.cmml">z</mi></mrow></mrow><mo rspace="0.497em" id="S5.E1.m2.2.2.2.2.2.4" xref="S5.E1.m2.2.2.2.2.3.cmml">,</mo><mrow id="S5.E1.m2.2.2.2.2.2.2" xref="S5.E1.m2.2.2.2.2.2.2.cmml"><mrow id="S5.E1.m2.2.2.2.2.2.2.2" xref="S5.E1.m2.2.2.2.2.2.2.2.cmml"><msub id="S5.E1.m2.2.2.2.2.2.2.2.2" xref="S5.E1.m2.2.2.2.2.2.2.2.2.cmml"><mi id="S5.E1.m2.2.2.2.2.2.2.2.2.2" xref="S5.E1.m2.2.2.2.2.2.2.2.2.2.cmml">f</mi><mi id="S5.E1.m2.2.2.2.2.2.2.2.2.3" xref="S5.E1.m2.2.2.2.2.2.2.2.2.3.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S5.E1.m2.2.2.2.2.2.2.2.1" xref="S5.E1.m2.2.2.2.2.2.2.2.1.cmml">​</mo><mi id="S5.E1.m2.2.2.2.2.2.2.2.3" xref="S5.E1.m2.2.2.2.2.2.2.2.3.cmml">y</mi></mrow><mo id="S5.E1.m2.2.2.2.2.2.2.1" xref="S5.E1.m2.2.2.2.2.2.2.1.cmml">+</mo><mrow id="S5.E1.m2.2.2.2.2.2.2.3" xref="S5.E1.m2.2.2.2.2.2.2.3.cmml"><msub id="S5.E1.m2.2.2.2.2.2.2.3.2" xref="S5.E1.m2.2.2.2.2.2.2.3.2.cmml"><mi id="S5.E1.m2.2.2.2.2.2.2.3.2.2" xref="S5.E1.m2.2.2.2.2.2.2.3.2.2.cmml">c</mi><mi id="S5.E1.m2.2.2.2.2.2.2.3.2.3" xref="S5.E1.m2.2.2.2.2.2.2.3.2.3.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S5.E1.m2.2.2.2.2.2.2.3.1" xref="S5.E1.m2.2.2.2.2.2.2.3.1.cmml">​</mo><mi id="S5.E1.m2.2.2.2.2.2.2.3.3" xref="S5.E1.m2.2.2.2.2.2.2.3.3.cmml">z</mi></mrow></mrow><mo maxsize="210%" minsize="210%" id="S5.E1.m2.2.2.2.2.2.5" xref="S5.E1.m2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E1.m2.2b"><apply id="S5.E1.m2.2.2.cmml" xref="S5.E1.m2.2.2"><eq id="S5.E1.m2.2.2.3.cmml" xref="S5.E1.m2.2.2.3"></eq><csymbol cd="latexml" id="S5.E1.m2.2.2.4.cmml" xref="S5.E1.m2.2.2.4">absent</csymbol><apply id="S5.E1.m2.2.2.2.cmml" xref="S5.E1.m2.2.2.2"><times id="S5.E1.m2.2.2.2.3.cmml" xref="S5.E1.m2.2.2.2.3"></times><apply id="S5.E1.m2.2.2.2.4.cmml" xref="S5.E1.m2.2.2.2.4"><divide id="S5.E1.m2.2.2.2.4.1.cmml" xref="S5.E1.m2.2.2.2.4"></divide><cn type="integer" id="S5.E1.m2.2.2.2.4.2.cmml" xref="S5.E1.m2.2.2.2.4.2">1</cn><ci id="S5.E1.m2.2.2.2.4.3.cmml" xref="S5.E1.m2.2.2.2.4.3">𝑧</ci></apply><interval closure="open" id="S5.E1.m2.2.2.2.2.3.cmml" xref="S5.E1.m2.2.2.2.2.2"><apply id="S5.E1.m2.1.1.1.1.1.1.cmml" xref="S5.E1.m2.1.1.1.1.1.1"><plus id="S5.E1.m2.1.1.1.1.1.1.1.cmml" xref="S5.E1.m2.1.1.1.1.1.1.1"></plus><apply id="S5.E1.m2.1.1.1.1.1.1.2.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2"><times id="S5.E1.m2.1.1.1.1.1.1.2.1.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2.1"></times><apply id="S5.E1.m2.1.1.1.1.1.1.2.2.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S5.E1.m2.1.1.1.1.1.1.2.2.1.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S5.E1.m2.1.1.1.1.1.1.2.2.2.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2.2.2">𝑓</ci><ci id="S5.E1.m2.1.1.1.1.1.1.2.2.3.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2.2.3">𝑥</ci></apply><ci id="S5.E1.m2.1.1.1.1.1.1.2.3.cmml" xref="S5.E1.m2.1.1.1.1.1.1.2.3">𝑥</ci></apply><apply id="S5.E1.m2.1.1.1.1.1.1.3.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3"><times id="S5.E1.m2.1.1.1.1.1.1.3.1.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3.1"></times><apply id="S5.E1.m2.1.1.1.1.1.1.3.2.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S5.E1.m2.1.1.1.1.1.1.3.2.1.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S5.E1.m2.1.1.1.1.1.1.3.2.2.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3.2.2">𝑐</ci><ci id="S5.E1.m2.1.1.1.1.1.1.3.2.3.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3.2.3">𝑥</ci></apply><ci id="S5.E1.m2.1.1.1.1.1.1.3.3.cmml" xref="S5.E1.m2.1.1.1.1.1.1.3.3">𝑧</ci></apply></apply><apply id="S5.E1.m2.2.2.2.2.2.2.cmml" xref="S5.E1.m2.2.2.2.2.2.2"><plus id="S5.E1.m2.2.2.2.2.2.2.1.cmml" xref="S5.E1.m2.2.2.2.2.2.2.1"></plus><apply id="S5.E1.m2.2.2.2.2.2.2.2.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2"><times id="S5.E1.m2.2.2.2.2.2.2.2.1.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2.1"></times><apply id="S5.E1.m2.2.2.2.2.2.2.2.2.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.E1.m2.2.2.2.2.2.2.2.2.1.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S5.E1.m2.2.2.2.2.2.2.2.2.2.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2.2.2">𝑓</ci><ci id="S5.E1.m2.2.2.2.2.2.2.2.2.3.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2.2.3">𝑦</ci></apply><ci id="S5.E1.m2.2.2.2.2.2.2.2.3.cmml" xref="S5.E1.m2.2.2.2.2.2.2.2.3">𝑦</ci></apply><apply id="S5.E1.m2.2.2.2.2.2.2.3.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3"><times id="S5.E1.m2.2.2.2.2.2.2.3.1.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3.1"></times><apply id="S5.E1.m2.2.2.2.2.2.2.3.2.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S5.E1.m2.2.2.2.2.2.2.3.2.1.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3.2">subscript</csymbol><ci id="S5.E1.m2.2.2.2.2.2.2.3.2.2.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3.2.2">𝑐</ci><ci id="S5.E1.m2.2.2.2.2.2.2.3.2.3.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3.2.3">𝑦</ci></apply><ci id="S5.E1.m2.2.2.2.2.2.2.3.3.cmml" xref="S5.E1.m2.2.2.2.2.2.2.3.3">𝑧</ci></apply></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E1.m2.2c">\displaystyle=\frac{1}{z}\bigg{(}f_{x}x+c_{x}z,~{}f_{y}y+c_{y}z\bigg{)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S5.SS4.p2.5" class="ltx_p">Then we evaluate if <math id="S5.SS4.p2.5.m1.2" class="ltx_Math" alttext="(u,v)" display="inline"><semantics id="S5.SS4.p2.5.m1.2a"><mrow id="S5.SS4.p2.5.m1.2.3.2" xref="S5.SS4.p2.5.m1.2.3.1.cmml"><mo stretchy="false" id="S5.SS4.p2.5.m1.2.3.2.1" xref="S5.SS4.p2.5.m1.2.3.1.cmml">(</mo><mi id="S5.SS4.p2.5.m1.1.1" xref="S5.SS4.p2.5.m1.1.1.cmml">u</mi><mo id="S5.SS4.p2.5.m1.2.3.2.2" xref="S5.SS4.p2.5.m1.2.3.1.cmml">,</mo><mi id="S5.SS4.p2.5.m1.2.2" xref="S5.SS4.p2.5.m1.2.2.cmml">v</mi><mo stretchy="false" id="S5.SS4.p2.5.m1.2.3.2.3" xref="S5.SS4.p2.5.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.5.m1.2b"><interval closure="open" id="S5.SS4.p2.5.m1.2.3.1.cmml" xref="S5.SS4.p2.5.m1.2.3.2"><ci id="S5.SS4.p2.5.m1.1.1.cmml" xref="S5.SS4.p2.5.m1.1.1">𝑢</ci><ci id="S5.SS4.p2.5.m1.2.2.cmml" xref="S5.SS4.p2.5.m1.2.2">𝑣</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.5.m1.2c">(u,v)</annotation></semantics></math> is within the bounds of the image, if not we consider this detection invalid.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.11" class="ltx_p">Each valid detection is evaluated against the current filtered object estimates, by thresholding distance, to determine if the new detection is a new object or an updated detection of a known object.
If it is grouped as a detection of a known object, we add it to the filter for that object.
Since DOPE does not provide covariances for Kalman Filtering, we exponentially filter the position and yaw of each detected object with a decaying gain.
The gain decays over <math id="S5.SS4.p3.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S5.SS4.p3.1.m1.1a"><mi id="S5.SS4.p3.1.m1.1.1" xref="S5.SS4.p3.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.1.m1.1b"><ci id="S5.SS4.p3.1.m1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.1.m1.1c">T</annotation></semantics></math> steps and then remains fixed at the desired gain <math id="S5.SS4.p3.2.m2.1" class="ltx_Math" alttext="\gamma_{d}" display="inline"><semantics id="S5.SS4.p3.2.m2.1a"><msub id="S5.SS4.p3.2.m2.1.1" xref="S5.SS4.p3.2.m2.1.1.cmml"><mi id="S5.SS4.p3.2.m2.1.1.2" xref="S5.SS4.p3.2.m2.1.1.2.cmml">γ</mi><mi id="S5.SS4.p3.2.m2.1.1.3" xref="S5.SS4.p3.2.m2.1.1.3.cmml">d</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.2.m2.1b"><apply id="S5.SS4.p3.2.m2.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.2.m2.1.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1">subscript</csymbol><ci id="S5.SS4.p3.2.m2.1.1.2.cmml" xref="S5.SS4.p3.2.m2.1.1.2">𝛾</ci><ci id="S5.SS4.p3.2.m2.1.1.3.cmml" xref="S5.SS4.p3.2.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.2.m2.1c">\gamma_{d}</annotation></semantics></math>. At step <math id="S5.SS4.p3.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.SS4.p3.3.m3.1a"><mi id="S5.SS4.p3.3.m3.1.1" xref="S5.SS4.p3.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.3.m3.1b"><ci id="S5.SS4.p3.3.m3.1.1.cmml" xref="S5.SS4.p3.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.3.m3.1c">t</annotation></semantics></math>, when <math id="S5.SS4.p3.4.m4.1" class="ltx_Math" alttext="t&lt;T" display="inline"><semantics id="S5.SS4.p3.4.m4.1a"><mrow id="S5.SS4.p3.4.m4.1.1" xref="S5.SS4.p3.4.m4.1.1.cmml"><mi id="S5.SS4.p3.4.m4.1.1.2" xref="S5.SS4.p3.4.m4.1.1.2.cmml">t</mi><mo id="S5.SS4.p3.4.m4.1.1.1" xref="S5.SS4.p3.4.m4.1.1.1.cmml">&lt;</mo><mi id="S5.SS4.p3.4.m4.1.1.3" xref="S5.SS4.p3.4.m4.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.4.m4.1b"><apply id="S5.SS4.p3.4.m4.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1"><lt id="S5.SS4.p3.4.m4.1.1.1.cmml" xref="S5.SS4.p3.4.m4.1.1.1"></lt><ci id="S5.SS4.p3.4.m4.1.1.2.cmml" xref="S5.SS4.p3.4.m4.1.1.2">𝑡</ci><ci id="S5.SS4.p3.4.m4.1.1.3.cmml" xref="S5.SS4.p3.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.4.m4.1c">t&lt;T</annotation></semantics></math>, the current gain, <math id="S5.SS4.p3.5.m5.1" class="ltx_Math" alttext="\gamma_{t}" display="inline"><semantics id="S5.SS4.p3.5.m5.1a"><msub id="S5.SS4.p3.5.m5.1.1" xref="S5.SS4.p3.5.m5.1.1.cmml"><mi id="S5.SS4.p3.5.m5.1.1.2" xref="S5.SS4.p3.5.m5.1.1.2.cmml">γ</mi><mi id="S5.SS4.p3.5.m5.1.1.3" xref="S5.SS4.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.5.m5.1b"><apply id="S5.SS4.p3.5.m5.1.1.cmml" xref="S5.SS4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.5.m5.1.1.1.cmml" xref="S5.SS4.p3.5.m5.1.1">subscript</csymbol><ci id="S5.SS4.p3.5.m5.1.1.2.cmml" xref="S5.SS4.p3.5.m5.1.1.2">𝛾</ci><ci id="S5.SS4.p3.5.m5.1.1.3.cmml" xref="S5.SS4.p3.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.5.m5.1c">\gamma_{t}</annotation></semantics></math>, is <math id="S5.SS4.p3.6.m6.1" class="ltx_Math" alttext="\gamma_{t}=1-(1-\gamma_{d})\frac{t}{T}" display="inline"><semantics id="S5.SS4.p3.6.m6.1a"><mrow id="S5.SS4.p3.6.m6.1.1" xref="S5.SS4.p3.6.m6.1.1.cmml"><msub id="S5.SS4.p3.6.m6.1.1.3" xref="S5.SS4.p3.6.m6.1.1.3.cmml"><mi id="S5.SS4.p3.6.m6.1.1.3.2" xref="S5.SS4.p3.6.m6.1.1.3.2.cmml">γ</mi><mi id="S5.SS4.p3.6.m6.1.1.3.3" xref="S5.SS4.p3.6.m6.1.1.3.3.cmml">t</mi></msub><mo id="S5.SS4.p3.6.m6.1.1.2" xref="S5.SS4.p3.6.m6.1.1.2.cmml">=</mo><mrow id="S5.SS4.p3.6.m6.1.1.1" xref="S5.SS4.p3.6.m6.1.1.1.cmml"><mn id="S5.SS4.p3.6.m6.1.1.1.3" xref="S5.SS4.p3.6.m6.1.1.1.3.cmml">1</mn><mo id="S5.SS4.p3.6.m6.1.1.1.2" xref="S5.SS4.p3.6.m6.1.1.1.2.cmml">−</mo><mrow id="S5.SS4.p3.6.m6.1.1.1.1" xref="S5.SS4.p3.6.m6.1.1.1.1.cmml"><mrow id="S5.SS4.p3.6.m6.1.1.1.1.1.1" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.SS4.p3.6.m6.1.1.1.1.1.1.2" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.cmml"><mn id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.2" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.1" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.cmml"><mi id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.2" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.2.cmml">γ</mi><mi id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.3" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.3.cmml">d</mi></msub></mrow><mo stretchy="false" id="S5.SS4.p3.6.m6.1.1.1.1.1.1.3" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S5.SS4.p3.6.m6.1.1.1.1.2" xref="S5.SS4.p3.6.m6.1.1.1.1.2.cmml">​</mo><mfrac id="S5.SS4.p3.6.m6.1.1.1.1.3" xref="S5.SS4.p3.6.m6.1.1.1.1.3.cmml"><mi id="S5.SS4.p3.6.m6.1.1.1.1.3.2" xref="S5.SS4.p3.6.m6.1.1.1.1.3.2.cmml">t</mi><mi id="S5.SS4.p3.6.m6.1.1.1.1.3.3" xref="S5.SS4.p3.6.m6.1.1.1.1.3.3.cmml">T</mi></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.6.m6.1b"><apply id="S5.SS4.p3.6.m6.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1"><eq id="S5.SS4.p3.6.m6.1.1.2.cmml" xref="S5.SS4.p3.6.m6.1.1.2"></eq><apply id="S5.SS4.p3.6.m6.1.1.3.cmml" xref="S5.SS4.p3.6.m6.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.p3.6.m6.1.1.3.1.cmml" xref="S5.SS4.p3.6.m6.1.1.3">subscript</csymbol><ci id="S5.SS4.p3.6.m6.1.1.3.2.cmml" xref="S5.SS4.p3.6.m6.1.1.3.2">𝛾</ci><ci id="S5.SS4.p3.6.m6.1.1.3.3.cmml" xref="S5.SS4.p3.6.m6.1.1.3.3">𝑡</ci></apply><apply id="S5.SS4.p3.6.m6.1.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1.1"><minus id="S5.SS4.p3.6.m6.1.1.1.2.cmml" xref="S5.SS4.p3.6.m6.1.1.1.2"></minus><cn type="integer" id="S5.SS4.p3.6.m6.1.1.1.3.cmml" xref="S5.SS4.p3.6.m6.1.1.1.3">1</cn><apply id="S5.SS4.p3.6.m6.1.1.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1"><times id="S5.SS4.p3.6.m6.1.1.1.1.2.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.2"></times><apply id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1"><minus id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.1.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.2.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.2">1</cn><apply id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.1.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.2.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.2">𝛾</ci><ci id="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.3.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.1.1.1.3.3">𝑑</ci></apply></apply><apply id="S5.SS4.p3.6.m6.1.1.1.1.3.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.3"><divide id="S5.SS4.p3.6.m6.1.1.1.1.3.1.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.3"></divide><ci id="S5.SS4.p3.6.m6.1.1.1.1.3.2.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.3.2">𝑡</ci><ci id="S5.SS4.p3.6.m6.1.1.1.1.3.3.cmml" xref="S5.SS4.p3.6.m6.1.1.1.1.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.6.m6.1c">\gamma_{t}=1-(1-\gamma_{d})\frac{t}{T}</annotation></semantics></math>.
For <math id="S5.SS4.p3.7.m7.1" class="ltx_Math" alttext="t\geq T" display="inline"><semantics id="S5.SS4.p3.7.m7.1a"><mrow id="S5.SS4.p3.7.m7.1.1" xref="S5.SS4.p3.7.m7.1.1.cmml"><mi id="S5.SS4.p3.7.m7.1.1.2" xref="S5.SS4.p3.7.m7.1.1.2.cmml">t</mi><mo id="S5.SS4.p3.7.m7.1.1.1" xref="S5.SS4.p3.7.m7.1.1.1.cmml">≥</mo><mi id="S5.SS4.p3.7.m7.1.1.3" xref="S5.SS4.p3.7.m7.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.7.m7.1b"><apply id="S5.SS4.p3.7.m7.1.1.cmml" xref="S5.SS4.p3.7.m7.1.1"><geq id="S5.SS4.p3.7.m7.1.1.1.cmml" xref="S5.SS4.p3.7.m7.1.1.1"></geq><ci id="S5.SS4.p3.7.m7.1.1.2.cmml" xref="S5.SS4.p3.7.m7.1.1.2">𝑡</ci><ci id="S5.SS4.p3.7.m7.1.1.3.cmml" xref="S5.SS4.p3.7.m7.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.7.m7.1c">t\geq T</annotation></semantics></math>, <math id="S5.SS4.p3.8.m8.1" class="ltx_Math" alttext="\gamma_{t}=\gamma_{d}" display="inline"><semantics id="S5.SS4.p3.8.m8.1a"><mrow id="S5.SS4.p3.8.m8.1.1" xref="S5.SS4.p3.8.m8.1.1.cmml"><msub id="S5.SS4.p3.8.m8.1.1.2" xref="S5.SS4.p3.8.m8.1.1.2.cmml"><mi id="S5.SS4.p3.8.m8.1.1.2.2" xref="S5.SS4.p3.8.m8.1.1.2.2.cmml">γ</mi><mi id="S5.SS4.p3.8.m8.1.1.2.3" xref="S5.SS4.p3.8.m8.1.1.2.3.cmml">t</mi></msub><mo id="S5.SS4.p3.8.m8.1.1.1" xref="S5.SS4.p3.8.m8.1.1.1.cmml">=</mo><msub id="S5.SS4.p3.8.m8.1.1.3" xref="S5.SS4.p3.8.m8.1.1.3.cmml"><mi id="S5.SS4.p3.8.m8.1.1.3.2" xref="S5.SS4.p3.8.m8.1.1.3.2.cmml">γ</mi><mi id="S5.SS4.p3.8.m8.1.1.3.3" xref="S5.SS4.p3.8.m8.1.1.3.3.cmml">d</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.8.m8.1b"><apply id="S5.SS4.p3.8.m8.1.1.cmml" xref="S5.SS4.p3.8.m8.1.1"><eq id="S5.SS4.p3.8.m8.1.1.1.cmml" xref="S5.SS4.p3.8.m8.1.1.1"></eq><apply id="S5.SS4.p3.8.m8.1.1.2.cmml" xref="S5.SS4.p3.8.m8.1.1.2"><csymbol cd="ambiguous" id="S5.SS4.p3.8.m8.1.1.2.1.cmml" xref="S5.SS4.p3.8.m8.1.1.2">subscript</csymbol><ci id="S5.SS4.p3.8.m8.1.1.2.2.cmml" xref="S5.SS4.p3.8.m8.1.1.2.2">𝛾</ci><ci id="S5.SS4.p3.8.m8.1.1.2.3.cmml" xref="S5.SS4.p3.8.m8.1.1.2.3">𝑡</ci></apply><apply id="S5.SS4.p3.8.m8.1.1.3.cmml" xref="S5.SS4.p3.8.m8.1.1.3"><csymbol cd="ambiguous" id="S5.SS4.p3.8.m8.1.1.3.1.cmml" xref="S5.SS4.p3.8.m8.1.1.3">subscript</csymbol><ci id="S5.SS4.p3.8.m8.1.1.3.2.cmml" xref="S5.SS4.p3.8.m8.1.1.3.2">𝛾</ci><ci id="S5.SS4.p3.8.m8.1.1.3.3.cmml" xref="S5.SS4.p3.8.m8.1.1.3.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.8.m8.1c">\gamma_{t}=\gamma_{d}</annotation></semantics></math>.
Then the filtered estimate <math id="S5.SS4.p3.9.m9.1" class="ltx_Math" alttext="p_{t}" display="inline"><semantics id="S5.SS4.p3.9.m9.1a"><msub id="S5.SS4.p3.9.m9.1.1" xref="S5.SS4.p3.9.m9.1.1.cmml"><mi id="S5.SS4.p3.9.m9.1.1.2" xref="S5.SS4.p3.9.m9.1.1.2.cmml">p</mi><mi id="S5.SS4.p3.9.m9.1.1.3" xref="S5.SS4.p3.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.9.m9.1b"><apply id="S5.SS4.p3.9.m9.1.1.cmml" xref="S5.SS4.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.9.m9.1.1.1.cmml" xref="S5.SS4.p3.9.m9.1.1">subscript</csymbol><ci id="S5.SS4.p3.9.m9.1.1.2.cmml" xref="S5.SS4.p3.9.m9.1.1.2">𝑝</ci><ci id="S5.SS4.p3.9.m9.1.1.3.cmml" xref="S5.SS4.p3.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.9.m9.1c">p_{t}</annotation></semantics></math>, comes from the previous filter estimate <math id="S5.SS4.p3.10.m10.1" class="ltx_Math" alttext="p_{t-1}" display="inline"><semantics id="S5.SS4.p3.10.m10.1a"><msub id="S5.SS4.p3.10.m10.1.1" xref="S5.SS4.p3.10.m10.1.1.cmml"><mi id="S5.SS4.p3.10.m10.1.1.2" xref="S5.SS4.p3.10.m10.1.1.2.cmml">p</mi><mrow id="S5.SS4.p3.10.m10.1.1.3" xref="S5.SS4.p3.10.m10.1.1.3.cmml"><mi id="S5.SS4.p3.10.m10.1.1.3.2" xref="S5.SS4.p3.10.m10.1.1.3.2.cmml">t</mi><mo id="S5.SS4.p3.10.m10.1.1.3.1" xref="S5.SS4.p3.10.m10.1.1.3.1.cmml">−</mo><mn id="S5.SS4.p3.10.m10.1.1.3.3" xref="S5.SS4.p3.10.m10.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.10.m10.1b"><apply id="S5.SS4.p3.10.m10.1.1.cmml" xref="S5.SS4.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.10.m10.1.1.1.cmml" xref="S5.SS4.p3.10.m10.1.1">subscript</csymbol><ci id="S5.SS4.p3.10.m10.1.1.2.cmml" xref="S5.SS4.p3.10.m10.1.1.2">𝑝</ci><apply id="S5.SS4.p3.10.m10.1.1.3.cmml" xref="S5.SS4.p3.10.m10.1.1.3"><minus id="S5.SS4.p3.10.m10.1.1.3.1.cmml" xref="S5.SS4.p3.10.m10.1.1.3.1"></minus><ci id="S5.SS4.p3.10.m10.1.1.3.2.cmml" xref="S5.SS4.p3.10.m10.1.1.3.2">𝑡</ci><cn type="integer" id="S5.SS4.p3.10.m10.1.1.3.3.cmml" xref="S5.SS4.p3.10.m10.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.10.m10.1c">p_{t-1}</annotation></semantics></math>, and the current measurement from DOPE <math id="S5.SS4.p3.11.m11.1" class="ltx_Math" alttext="m_{t}" display="inline"><semantics id="S5.SS4.p3.11.m11.1a"><msub id="S5.SS4.p3.11.m11.1.1" xref="S5.SS4.p3.11.m11.1.1.cmml"><mi id="S5.SS4.p3.11.m11.1.1.2" xref="S5.SS4.p3.11.m11.1.1.2.cmml">m</mi><mi id="S5.SS4.p3.11.m11.1.1.3" xref="S5.SS4.p3.11.m11.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.11.m11.1b"><apply id="S5.SS4.p3.11.m11.1.1.cmml" xref="S5.SS4.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S5.SS4.p3.11.m11.1.1.1.cmml" xref="S5.SS4.p3.11.m11.1.1">subscript</csymbol><ci id="S5.SS4.p3.11.m11.1.1.2.cmml" xref="S5.SS4.p3.11.m11.1.1.2">𝑚</ci><ci id="S5.SS4.p3.11.m11.1.1.3.cmml" xref="S5.SS4.p3.11.m11.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.11.m11.1c">m_{t}</annotation></semantics></math>, as follows.</p>
<table id="Sx1.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S5.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S5.E2.m1.1" class="ltx_Math" alttext="\displaystyle p_{t}=p_{t-1}+\gamma_{t}(m_{t}-p_{t-1})" display="inline"><semantics id="S5.E2.m1.1a"><mrow id="S5.E2.m1.1.1" xref="S5.E2.m1.1.1.cmml"><msub id="S5.E2.m1.1.1.3" xref="S5.E2.m1.1.1.3.cmml"><mi id="S5.E2.m1.1.1.3.2" xref="S5.E2.m1.1.1.3.2.cmml">p</mi><mi id="S5.E2.m1.1.1.3.3" xref="S5.E2.m1.1.1.3.3.cmml">t</mi></msub><mo id="S5.E2.m1.1.1.2" xref="S5.E2.m1.1.1.2.cmml">=</mo><mrow id="S5.E2.m1.1.1.1" xref="S5.E2.m1.1.1.1.cmml"><msub id="S5.E2.m1.1.1.1.3" xref="S5.E2.m1.1.1.1.3.cmml"><mi id="S5.E2.m1.1.1.1.3.2" xref="S5.E2.m1.1.1.1.3.2.cmml">p</mi><mrow id="S5.E2.m1.1.1.1.3.3" xref="S5.E2.m1.1.1.1.3.3.cmml"><mi id="S5.E2.m1.1.1.1.3.3.2" xref="S5.E2.m1.1.1.1.3.3.2.cmml">t</mi><mo id="S5.E2.m1.1.1.1.3.3.1" xref="S5.E2.m1.1.1.1.3.3.1.cmml">−</mo><mn id="S5.E2.m1.1.1.1.3.3.3" xref="S5.E2.m1.1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S5.E2.m1.1.1.1.2" xref="S5.E2.m1.1.1.1.2.cmml">+</mo><mrow id="S5.E2.m1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.cmml"><msub id="S5.E2.m1.1.1.1.1.3" xref="S5.E2.m1.1.1.1.1.3.cmml"><mi id="S5.E2.m1.1.1.1.1.3.2" xref="S5.E2.m1.1.1.1.1.3.2.cmml">γ</mi><mi id="S5.E2.m1.1.1.1.1.3.3" xref="S5.E2.m1.1.1.1.1.3.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S5.E2.m1.1.1.1.1.2" xref="S5.E2.m1.1.1.1.1.2.cmml">​</mo><mrow id="S5.E2.m1.1.1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E2.m1.1.1.1.1.1.1.2" xref="S5.E2.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E2.m1.1.1.1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.1.1.1.cmml"><msub id="S5.E2.m1.1.1.1.1.1.1.1.2" xref="S5.E2.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S5.E2.m1.1.1.1.1.1.1.1.2.2" xref="S5.E2.m1.1.1.1.1.1.1.1.2.2.cmml">m</mi><mi id="S5.E2.m1.1.1.1.1.1.1.1.2.3" xref="S5.E2.m1.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S5.E2.m1.1.1.1.1.1.1.1.1" xref="S5.E2.m1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S5.E2.m1.1.1.1.1.1.1.1.3" xref="S5.E2.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S5.E2.m1.1.1.1.1.1.1.1.3.2" xref="S5.E2.m1.1.1.1.1.1.1.1.3.2.cmml">p</mi><mrow id="S5.E2.m1.1.1.1.1.1.1.1.3.3" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S5.E2.m1.1.1.1.1.1.1.1.3.3.2" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S5.E2.m1.1.1.1.1.1.1.1.3.3.1" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S5.E2.m1.1.1.1.1.1.1.1.3.3.3" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo stretchy="false" id="S5.E2.m1.1.1.1.1.1.1.3" xref="S5.E2.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.1b"><apply id="S5.E2.m1.1.1.cmml" xref="S5.E2.m1.1.1"><eq id="S5.E2.m1.1.1.2.cmml" xref="S5.E2.m1.1.1.2"></eq><apply id="S5.E2.m1.1.1.3.cmml" xref="S5.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.3.1.cmml" xref="S5.E2.m1.1.1.3">subscript</csymbol><ci id="S5.E2.m1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.3.2">𝑝</ci><ci id="S5.E2.m1.1.1.3.3.cmml" xref="S5.E2.m1.1.1.3.3">𝑡</ci></apply><apply id="S5.E2.m1.1.1.1.cmml" xref="S5.E2.m1.1.1.1"><plus id="S5.E2.m1.1.1.1.2.cmml" xref="S5.E2.m1.1.1.1.2"></plus><apply id="S5.E2.m1.1.1.1.3.cmml" xref="S5.E2.m1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.3.1.cmml" xref="S5.E2.m1.1.1.1.3">subscript</csymbol><ci id="S5.E2.m1.1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.1.3.2">𝑝</ci><apply id="S5.E2.m1.1.1.1.3.3.cmml" xref="S5.E2.m1.1.1.1.3.3"><minus id="S5.E2.m1.1.1.1.3.3.1.cmml" xref="S5.E2.m1.1.1.1.3.3.1"></minus><ci id="S5.E2.m1.1.1.1.3.3.2.cmml" xref="S5.E2.m1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S5.E2.m1.1.1.1.3.3.3.cmml" xref="S5.E2.m1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S5.E2.m1.1.1.1.1.cmml" xref="S5.E2.m1.1.1.1.1"><times id="S5.E2.m1.1.1.1.1.2.cmml" xref="S5.E2.m1.1.1.1.1.2"></times><apply id="S5.E2.m1.1.1.1.1.3.cmml" xref="S5.E2.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.3.1.cmml" xref="S5.E2.m1.1.1.1.1.3">subscript</csymbol><ci id="S5.E2.m1.1.1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.1.1.3.2">𝛾</ci><ci id="S5.E2.m1.1.1.1.1.3.3.cmml" xref="S5.E2.m1.1.1.1.1.3.3">𝑡</ci></apply><apply id="S5.E2.m1.1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.1.1.1.1.1.1"><minus id="S5.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.1"></minus><apply id="S5.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E2.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.2.2">𝑚</ci><ci id="S5.E2.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S5.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3.2">𝑝</ci><apply id="S5.E2.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3"><minus id="S5.E2.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.1"></minus><ci id="S5.E2.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.2">𝑡</ci><cn type="integer" id="S5.E2.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S5.E2.m1.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.1c">\displaystyle p_{t}=p_{t-1}+\gamma_{t}(m_{t}-p_{t-1})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S5.SS4.p4" class="ltx_para">
<p id="S5.SS4.p4.1" class="ltx_p">The closest target object to the vehicle is then identified and we employ a visual servoing controller using the object’s filtered pose to maneuver the UAV to target poses relative to the object.
As a basic grasp strategy, these target poses, which are tuned to optimize performance, are defined as relative transforms from the object that result in the gripper surrounding the object of interest, i.e. the vehicle maneuvers to a position offset from the object by the transform from the vehicle center to the gripper center, such that when the vehicle reaches that target pose, the object will be in the center of the gripper. When the error to the desired pose is within user-defined thresholds, the gripper closes.</p>
</div>
<div id="S5.SS4.p5" class="ltx_para">
<p id="S5.SS4.p5.1" class="ltx_p">As representative small objects, we use the Household Objects for Pose Estimation (HOPE) models with DOPE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>.
Fig. <a href="#S1.F1" title="Figure 1 ‣ I INTRODUCTION ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the four objects we used in this evaluation. The two target objects, Mayo and Tomato Sauce, and the corresponding destination objects, Ketchup and Green Beans. Fig. <a href="#S6.F8" title="Figure 8 ‣ VI-B Performance Evaluation ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows onboard detections of the target objects.
We found detecting two objects at a time to be the processing limit on our Jetson Xavier NX, with GPU usage up to 99%.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.5.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.6.2" class="ltx_text ltx_font_italic">High Fidelity Simulation</span>
</h3>

<figure id="S5.F6" class="ltx_figure"><img src="/html/2308.01398/assets/figures/quad_can_sim_brighter.png" id="S5.F6.g1" class="ltx_graphics ltx_img_portrait" width="246" height="340" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Gazebo simulation.</figcaption>
</figure>
<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">We built a simulation environment in Gazebo for rapid testing and prototyping of algorithms. This simulation uses PX4’s Software-In-The-Loop (SITL) simulation architecture
and allows for software to be easily tested on a simulated vehicle that can be directly swapped for a real vehicle.
We tuned the controller gains in simulation and found only minor adjustments were required on the real vehicle.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">Fig. <a href="#S5.F6" title="Figure 6 ‣ V-E High Fidelity Simulation ‣ V SOFTWARE FRAMEWORK ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the quadrotor in the Gazebo simulation environment in front of a target object on the table. The simulated camera’s view is shown at the end of the camera’s frustum. AR tags are used in simulation for object detection. The simulated environment was essential for the deployment and tuning of the onboard visual servoing control strategy.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">PICK-AND-PLACE EXPERIMENTS</span>
</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.5.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.6.2" class="ltx_text ltx_font_italic">Experiment Setup</span>
</h3>

<figure id="S6.F7" class="ltx_figure"><img src="/html/2308.01398/assets/figures/aerial_timelapse_clutter.jpg" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="500" height="129" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Aerial time lapse of a cluttered environment experiment. Pick location on the right and place location on the left.</figcaption>
</figure>
<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">We performed hardware pick-and-place experiments to evaluate our system’s performance. We placed a target object on a cart and a destination object on a table about 3 meters away, as seen in Fig. <a href="#S6.F7" title="Figure 7 ‣ VI-A Experiment Setup ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. We manually controlled the system to a variable starting location facing the target object and then switched into autonomous mode, which follows the AA state machine, as described in Section <a href="#S5.SS2" title="V-B Aerial Autonomy State Machine ‣ V SOFTWARE FRAMEWORK ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a>.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">See included video for examples of the experiments<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Pick-and-place experiments: <a target="_blank" href="https://youtu.be/XAHcYrbYhy0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://youtu.be/XAHcYrbYhy0</a></span></span></span>.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.5.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.6.2" class="ltx_text ltx_font_italic">Performance Evaluation</span>
</h3>

<figure id="S6.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/figures/mayo_single.png" id="S6.F8.sf1.g1" class="ltx_graphics ltx_img_square" width="105" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf1.2.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><span id="S6.F8.sf1.3.2" class="ltx_text" style="font-size:80%;">Single Bottle</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/figures/can_single.png" id="S6.F8.sf2.g1" class="ltx_graphics ltx_img_square" width="105" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf2.2.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><span id="S6.F8.sf2.3.2" class="ltx_text" style="font-size:80%;">Single Can</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/figures/clutter_can.png" id="S6.F8.sf3.g1" class="ltx_graphics ltx_img_square" width="105" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf3.2.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><span id="S6.F8.sf3.3.2" class="ltx_text" style="font-size:80%;">Can Clutter</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F8.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/figures/obstructed_can.png" id="S6.F8.sf4.g1" class="ltx_graphics ltx_img_square" width="105" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf4.2.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><span id="S6.F8.sf4.3.2" class="ltx_text" style="font-size:80%;">Obstructed Can</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S6.F8.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/figures/two_cans.png" id="S6.F8.sf5.g1" class="ltx_graphics ltx_img_square" width="105" height="90" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.sf5.2.1.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><span id="S6.F8.sf5.3.2" class="ltx_text" style="font-size:80%;">Multiple Can Instances</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Experiment scenarios as viewed from the vehicle’s onboard camera, including detected bounding box of target objects.</figcaption>
</figure>
<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">To evaluate the system’s performance, we ran 70 pick-and-place experiments from variable initial conditions.
The pick action was considered a success if the target was gripped.
The place action was considered a success if the target was released on the table to the right of the destination object.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">In the 70 pick-and-place experiments, we tested the following scenarios: single object, clutter, obstruction, and multiple instance, as depicted in Fig. <a href="#S6.F8" title="Figure 8 ‣ VI-B Performance Evaluation ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. In the single object trials, the object of interest was in a relatively uncluttered environment. We ran 20 trials each of two classes of objects: cans and bottles. As a challenge scenario, we performed an additional 10 trials in a cluttered environment with many different items, some visually similar, surrounding the target object and destination object. We ran another 10 trials with an object obstructing 10-30% of the target when viewed from the vehicle’s initial position. The target was rotated which required the vehicle to shift laterally to approach at an angle and avoid the obstruction.
Lastly, we ran 5 trials with multiple instances of the target object. The system needed to identify two instances of the object, filter separate pose estimates, and then pick-and-place each successively; we count these trials as two pick-and-place experiments. An additional offset is added to the place destination for each instance to assure they are not placed co-located. Cans were used as the target object for the challenging scenarios of clutter, obstruction, and multiple instances.
Clutter, obstructions, and multiple instances of objects are common points of failure for VO and object detection approaches, so we wanted to evaluate baseline performance with common, off-the-shelf algorithms running entirely onboard.
</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.5.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.6.2" class="ltx_text ltx_font_italic">Performance Metrics</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Table <a href="#S6.T3" title="TABLE III ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> shows performance metrics from each category of experiments. Our overall pick success rate across all 70 experiments was 93% and the place success rate was 86%. The number of trials the system needed to reset at least once during, due to system faults during the pick action, are tracked in Table <a href="#S6.T3" title="TABLE III ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. The system never reset during the place action. We considered a success rate of 90% or higher to be ideal performance and are shown in green, 85-90% is shown in yellow, and below 85% is in red.</p>
</div>
<figure id="S6.T3" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Pick-and-Place Performance Metrics</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S6.T3.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.1.1.1" class="ltx_tr">
<th id="S6.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;" rowspan="2"><span id="S6.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">Scenario</span></th>
<th id="S6.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;" colspan="2"><span id="S6.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Success Rates</span></th>
<th id="S6.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Pick Resets</span></th>
</tr>
<tr id="S6.T3.1.2.2" class="ltx_tr">
<th id="S6.T3.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.2.2.1.1" class="ltx_text ltx_font_italic">Pick</span></th>
<th id="S6.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.2.2.2.1" class="ltx_text ltx_font_italic">Place</span></th>
<th id="S6.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.2.2.3.1" class="ltx_text ltx_font_italic">Num Trials</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.1.3.1" class="ltx_tr">
<th id="S6.T3.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">Single Bottle</th>
<td id="S6.T3.1.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.3.1.2.1" class="ltx_text" style="background-color:#ABEBC6;">18/20</span></td>
<td id="S6.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="background-color:#F9E79F;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.3.1.3.1" class="ltx_text" style="background-color:#F9E79F;">16/18</span></td>
<td id="S6.T3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">3/20</td>
</tr>
<tr id="S6.T3.1.4.2" class="ltx_tr">
<th id="S6.T3.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Single Can</th>
<td id="S6.T3.1.4.2.2" class="ltx_td ltx_align_center" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.4.2.2.1" class="ltx_text" style="background-color:#ABEBC6;">20/20</span></td>
<td id="S6.T3.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.4.2.3.1" class="ltx_text" style="background-color:#ABEBC6;">19/20</span></td>
<td id="S6.T3.1.4.2.4" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">5/20</td>
</tr>
<tr id="S6.T3.1.5.3" class="ltx_tr">
<th id="S6.T3.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Can Cluttered Environment</th>
<td id="S6.T3.1.5.3.2" class="ltx_td ltx_align_center" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.5.3.2.1" class="ltx_text" style="background-color:#ABEBC6;">9/10</span></td>
<td id="S6.T3.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F9E79F;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.5.3.3.1" class="ltx_text" style="background-color:#F9E79F;">8/9</span></td>
<td id="S6.T3.1.5.3.4" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">3/10</td>
</tr>
<tr id="S6.T3.1.6.4" class="ltx_tr">
<th id="S6.T3.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Obstructed Can</th>
<td id="S6.T3.1.6.4.2" class="ltx_td ltx_align_center" style="background-color:#F5B7B1;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.6.4.2.1" class="ltx_text" style="background-color:#F5B7B1;">8/10</span></td>
<td id="S6.T3.1.6.4.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F5B7B1;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.6.4.3.1" class="ltx_text" style="background-color:#F5B7B1;">4/8</span></td>
<td id="S6.T3.1.6.4.4" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">3/10</td>
</tr>
<tr id="S6.T3.1.7.5" class="ltx_tr">
<th id="S6.T3.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Multiple Instance: First Can</th>
<td id="S6.T3.1.7.5.2" class="ltx_td ltx_align_center" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.7.5.2.1" class="ltx_text" style="background-color:#ABEBC6;">5/5</span></td>
<td id="S6.T3.1.7.5.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.7.5.3.1" class="ltx_text" style="background-color:#ABEBC6;">5/5</span></td>
<td id="S6.T3.1.7.5.4" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">1/5</td>
</tr>
<tr id="S6.T3.1.8.6" class="ltx_tr">
<th id="S6.T3.1.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Multiple Instance: Second Can</th>
<td id="S6.T3.1.8.6.2" class="ltx_td ltx_align_center" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.8.6.2.1" class="ltx_text" style="background-color:#ABEBC6;">5/5</span></td>
<td id="S6.T3.1.8.6.3" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#F5B7B1;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.8.6.3.1" class="ltx_text" style="background-color:#F5B7B1;">4/5</span></td>
<td id="S6.T3.1.8.6.4" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">2/5</td>
</tr>
<tr id="S6.T3.1.9.7" class="ltx_tr">
<th id="S6.T3.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">Overall</th>
<td id="S6.T3.1.9.7.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="background-color:#ABEBC6;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.9.7.2.1" class="ltx_text" style="background-color:#ABEBC6;">65/70</span></td>
<td id="S6.T3.1.9.7.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="background-color:#F9E79F;padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.1.9.7.3.1" class="ltx_text" style="background-color:#F9E79F;">56/65</span></td>
<td id="S6.T3.1.9.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">17/70</td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Pick Action Overall Metrics</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S6.T3.2" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.2.1.1" class="ltx_tr">
<th id="S6.T3.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;" colspan="2"><span id="S6.T3.2.1.1.1.1" class="ltx_text ltx_font_bold">Metric</span></th>
<th id="S6.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;"><span id="S6.T3.2.1.1.2.1" class="ltx_text ltx_font_bold">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.2.2.1" class="ltx_tr">
<td id="S6.T3.2.2.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;" rowspan="3"><span id="S6.T3.2.2.1.1.1" class="ltx_text">Starting Distance (m)</span></td>
<td id="S6.T3.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">Min</td>
<td id="S6.T3.2.2.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.78</td>
</tr>
<tr id="S6.T3.2.3.2" class="ltx_tr">
<td id="S6.T3.2.3.2.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Mean</td>
<td id="S6.T3.2.3.2.2" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">0.93</td>
</tr>
<tr id="S6.T3.2.4.3" class="ltx_tr">
<td id="S6.T3.2.4.3.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Max</td>
<td id="S6.T3.2.4.3.2" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">1.11</td>
</tr>
<tr id="S6.T3.2.5.4" class="ltx_tr">
<td id="S6.T3.2.5.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;" rowspan="4"><span id="S6.T3.2.5.4.1.1" class="ltx_text">Pick Time (sec)</span></td>
<td id="S6.T3.2.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">Min</td>
<td id="S6.T3.2.5.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">13.9</td>
</tr>
<tr id="S6.T3.2.6.5" class="ltx_tr">
<td id="S6.T3.2.6.5.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Median</td>
<td id="S6.T3.2.6.5.2" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">18.2</td>
</tr>
<tr id="S6.T3.2.7.6" class="ltx_tr">
<td id="S6.T3.2.7.6.1" class="ltx_td ltx_align_center ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Mean</td>
<td id="S6.T3.2.7.6.2" class="ltx_td ltx_align_center" style="padding-top:1.5pt;padding-bottom:1.5pt;">29.6</td>
</tr>
<tr id="S6.T3.2.8.7" class="ltx_tr">
<td id="S6.T3.2.8.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">Max</td>
<td id="S6.T3.2.8.7.2" class="ltx_td ltx_align_center ltx_border_b" style="padding-top:1.5pt;padding-bottom:1.5pt;">161.8</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">Table <a href="#S6.T3" title="TABLE III ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> shows metrics for the pick action across all 70 trials. This includes the starting distance (defined from the vehicle’s initial pose to the final filtered estimate of the target object) and the time to perform the pick action (moving from the initial pose to grasping the target object). These metrics are further broken down by experiment scenarios in Fig. <a href="#S6.F9" title="Figure 9 ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. In each boxplot the center line is the median, the box spans from the 25th to 75th percentiles and the whiskers show the bounds, excluding the outliers denoted by plus signs (+). The intention was to test the system for relatively similar starting distances across each scenario. Additionally, the pick time plot shows that the time to perform the pick action did not vary significantly across the more challenging scenarios.</p>
</div>
<figure id="S6.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/x1.png" id="S6.F9.1.g1" class="ltx_graphics ltx_img_landscape" width="518" height="249" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S6.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2308.01398/assets/x2.png" id="S6.F9.2.g1" class="ltx_graphics ltx_img_landscape" width="518" height="249" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Metrics for starting distance (top) and total time for the pick action (bottom) for each experimental scenario.</figcaption>
</figure>
<figure id="S6.F10" class="ltx_figure"><img src="/html/2308.01398/assets/x3.png" id="S6.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="244" height="248" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Distance from gripper center to target object during pick action versus normalized time across 60 trials with direct approaches (excludes obstruction trials).</figcaption>
</figure>
<div id="S6.SS3.p3" class="ltx_para">
<p id="S6.SS3.p3.1" class="ltx_p">Fig. <a href="#S6.F10" title="Figure 10 ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows the distance in meters from the gripper center to the final estimate of the target object’s pose during the pick action on the Y axis versus normalized time on the X axis. This figure includes the 60 trials where the vehicle initializes with the target object along the axis of the vehicle’s arm. The obstruction trials were excluded in this figure since the vehicle needed to translate laterally before approaching the target object. In Fig. <a href="#S6.F10" title="Figure 10 ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, each blue solid line represents a successful pick action, red dotted lines represent a failed pick action, and green dash-dot lines represent each approach to the target object that resulted in an autonomous reset due to a system fault.
After an autonomous reset the system would reattempt the pick action. These additional attempts are included in Fig. <a href="#S6.F10" title="Figure 10 ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> as new approaches and are tracked with the appropriate coloration and line type.
The points on the Y axis represent the various starting distances from the object. In each trajectory there is a plateau around 0.65m to the target object for the pre-pick position, before continuing on to the pick position.
In Fig. <a href="#S6.F10" title="Figure 10 ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, it is desired for the distance to converge to zero, indicating the center of the gripper and the target object becoming coincident. The gripper closes when the pose of the vehicle is within specified tolerances of the target object. In these experiments, those tolerances were 3 cm laterally, 2 cm along the axis of the arm, and 2 cm vertically.</p>
</div>
<div id="S6.SS3.p4" class="ltx_para">
<p id="S6.SS3.p4.1" class="ltx_p">The system fault detection imposes bounds on a grasp region. This can be seen in Fig. <a href="#S6.F10" title="Figure 10 ‣ VI-C Performance Metrics ‣ VI PICK-AND-PLACE EXPERIMENTS ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> by the successful grasps clustering around a lower terminal distance than the cluster of resets. The three pick failures in this plot fall in the region overlapping the successful approaches and reset approaches.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">DISCUSSION</span>
</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.5.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.6.2" class="ltx_text ltx_font_italic">Failure Modes</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">Fig. <a href="#S7.F11" title="Figure 11 ‣ VII-A2 Place Action Failures ‣ VII-A Failure Modes ‣ VII DISCUSSION ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> depicts the main failure modes encountered in the pick-and-place experiments. There is a bar for each scenario type. The total length of the bar is the total number of experiments in that category. The blue regions of each bar are the trials with successful pick and place actions. Each bar is further divided by the types of pick failures and place failures encountered, which are detailed in the following sections.</p>
</div>
<section id="S7.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S7.SS1.SSS1.5.1.1" class="ltx_text">VII-A</span>1 </span>Pick Action Failures</h4>

<div id="S7.SS1.SSS1.p1" class="ltx_para">
<p id="S7.SS1.SSS1.p1.1" class="ltx_p">We encountered two main failure modes in the pick action: knocking the target object over, which occurred twice, and approaching the target object from too low, which occurred three times. Both instances of knocking the target object over occurred during the single object bottle trials. In one trial the object was gripped too high, which caused it to fall. In another trial the object was bumped during approach. The bottles are less stable than the cans making them more prone to this type of failure.</p>
</div>
<div id="S7.SS1.SSS1.p2" class="ltx_para">
<p id="S7.SS1.SSS1.p2.1" class="ltx_p">Pick action failures due to approaching the object from too low occurred in two obstruction trials and one clutter trial and resulted in the gripper colliding with the box the target object was standing on. In cases, such as these, where the vehicle collided with the environment, the protective cage and shock absorbing feet prevented damage to the vehicle.</p>
</div>
<div id="S7.SS1.SSS1.p3" class="ltx_para">
<p id="S7.SS1.SSS1.p3.1" class="ltx_p">Both of these pick failure modes could be due to the quality of the detection of the object or the specification of the pick grasp region being too large. Tighter constraints on the grasp region could potentially avoid some of these issues. Additionally, greater spatial awareness of objects in the environment could mitigate these issues. The current system acts solely on the tracking information of the object.</p>
</div>
</section>
<section id="S7.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S7.SS1.SSS2.5.1.1" class="ltx_text">VII-A</span>2 </span>Place Action Failures</h4>

<div id="S7.SS1.SSS2.p1" class="ltx_para">
<p id="S7.SS1.SSS2.p1.1" class="ltx_p">The two types of place action failures encountered were due to the vehicle state estimation diverging and the destination object not being found. In cases where the destination object was not found the vehicle was too low to see the object in 3 cases and too far back in 1 case, due to human error setting up the environment. This could be mitigated by an improved search routine. Currently the vehicle searches downwards if the destination object was not found. This occurred in 17 trials, including all 4 place failures where the destination object was not found. In all other trials the search routine resulted in the destination object being found. This search routine could be expanded to more thoroughly search the environment. In this work, we looked to demonstrate a pick-and-place capability, leaving more thorough search behaviors to future work. The obstruction trials accounted for 3 of the 4 failures due to not detecting the destination object. This was likely due to the major differences in the testing setup. In the obstruction trials, due to the setup of the environment, the vehicle’s position after the pick action was shifted further from the place location in comparison to all other trials.</p>
</div>
<div id="S7.SS1.SSS2.p2" class="ltx_para">
<p id="S7.SS1.SSS2.p2.1" class="ltx_p">The other type of place action failure was due to the state estimation diverging. Two components contributed to this behavior: the visual odometry drifting and the vehicle’s magnetometer failing. The magnetometer encountered many system faults resulting in failed innovation consistency checks, making the data highly unreliable. The vehicle was only launched when the magnetometer passed innovation consistency checks, but over time could accumulate more error resulting in issues during the place action procedure. Replacing, disabling, or having redundant magnetometers could all improve performance. Furthermore, the visual odometry would occasionally drift and diverge from the fused EKF state measurement. This occurred most often after any sharp movements, such as when the vehicle turned quickly from the pick location to the place location, with an object in the gripper partially occluding the camera’s field of view.
More fault monitoring could identify these issues and potentially allow for autonomous recovery.</p>
</div>
<figure id="S7.F11" class="ltx_figure"><img src="/html/2308.01398/assets/x4.png" id="S7.F11.g1" class="ltx_graphics ltx_centering ltx_img_square" width="631" height="547" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Failure modes across each experimental scenario.</figcaption>
</figure>
</section>
<section id="S7.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S7.SS1.SSS3.5.1.1" class="ltx_text">VII-A</span>3 </span>General Failure Modes</h4>

<div id="S7.SS1.SSS3.p1" class="ltx_para">
<p id="S7.SS1.SSS3.p1.1" class="ltx_p">The quality of the object detection significantly impacts the system’s performance. Many erroneous detections of the target objects were filtered out or rejected, as described in Section <a href="#S5.SS4" title="V-D Object Pose Estimation and Grasp Strategy ‣ V SOFTWARE FRAMEWORK ‣ A Small Form Factor Aerial Research Vehicle for Pick-and-Place Tasks with Onboard Real-Time Object Detection and Visual Odometry" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-D</span></span></a>. Qualitatively, the cans were found to detect more consistently and frequently than the bottles. Occasionally, truly false detects would occur such as detecting a Ketchup bottle on the logo of the Mayo when the Mayo was in the gripper, potentially due to the red colors in the Mayo logo at that proximity and angle. While it was not encountered in the trials reported herein, this phenomenon could have resulted in placing the object in an incorrect location.</p>
</div>
</section>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.5.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.6.2" class="ltx_text ltx_font_italic">Robust System Performance</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Overall, the system performed reliably across a large number of trials of two different classes of objects and challenge cases including a cluttered environment, an obstructed target, and multiple instances of the same object, which required disambiguation of the instances and maintaining operation through two pick-and-place trials. The pick task is the most challenging, requiring precise control of the vehicle, and only encountered 5 failures across 70 trials with relatively comparable performance in the single object cases and smaller challenge scenarios. Performance could be further improved by refining the pick grasp region and incorporating more spatial awareness of the environment. In the obstruction case, the system was able to identify the object and approach from a different angle determined by the rotation of the target object. With greater spatial awareness, the correct approach direction could be determined regardless of the target object’s setup orientation.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">Through sensor improvement, further fault mitigation, and improved search behaviors, the place action performance could be further improved as well. Furthermore, to improve overall performance and reliability, the system’s gains could be further tuned to improve trajectory tracking accuracy.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">CONCLUSION</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this paper we present a novel small UAV for aerial grasping research with entirely onboard sensors and computation. We provide technical details for a collision-tolerant cage, shock-absorbing feet, and a lightweight, low-cost Gripper Extension Package (GREP). We demonstrate pick-and-place experiments successfully running DOPE and VO entirely onboard and using object pose estimates for visual servoing with enough accuracy that small objects were able to be grasped with a 93% success rate and placed at a target destination with a 86% success rate in a wide variety of challenging scenarios. Moving forward we look to more tightly couple the object pose estimation with perception information and refine the control strategy for these grasping tasks in order to further improve accuracy and agility and increase the general applicability of this work.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">ACKNOWLEDGMENT</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We gratefully acknowledge the support of
the National Science Foundation under grant #1925189.
We are grateful to Austin McWhirter who contributed to the hardware experimentation.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Ollero, M. Tognon, A. Suarez, D. Lee, and A. Franchi, “Past, present, and
future of aerial robotic manipulators,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Robotics</em>, vol. 38, no. 1, pp. 626–645, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. Suarez, F. Real, V. M. Vega, G. Heredia, A. Rodriguez-Castaño, and
A. Ollero, “Compliant bimanual aerial manipulation: Standard and long reach
configurations,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp. 88 844–88 865, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Orsag, C. Korpela, S. Bogdan, and P. Oh, “Dexterous aerial robots—mobile
manipulation using unmanned aerial systems,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Robotics</em>, vol. 33, no. 6, pp. 1453–1466, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
J. Fishman, S. Ubellacker, N. Hughes, and L. Carlone, “Dynamic grasping with a
“soft” drone: From theory to practice,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">IEEE/RSJ Int. Conf. on
Intelligent Robots and Systems</em>, 2021, pp. 4214–4221.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
C. D. Bellicoso, L. R. Buonocore, V. Lippiello, and B. Siciliano, “Design,
modeling and control of a 5-DoF light-weight robot arm for aerial
manipulation,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">2015 23rd Mediterranean Conference on Control and
Automation (MED)</em>.   IEEE, 2015, pp.
853–858.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. Gabrich, D. Saldana, V. Kumar, and M. Yim, “A flying gripper based on
cuboid modular robots,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on
Robotics and Automation (ICRA)</em>, 2018, pp. 7024–7030.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G. Garimella, M. Sheckells, S. Kim, G. Baraban, and M. Kobilarov, “Improving
the reliability of pick-and-place with aerial vehicles through fault-tolerant
software and a custom magnetic end-effector,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics and Auto.
Lett.</em>, vol. 6, no. 4, pp. 7501–7508, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
P. Chermprayong, K. Zhang, F. Xiao, and M. Kovac, “An integrated delta
manipulator for aerial repair: A new aerial robotic system,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE
Robotics &amp; Automation Magazine</em>, vol. 26, no. 1, pp. 54–66, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
I. Sa, M. Kamel, M. Burri, M. Bloesch, R. Khanna, M. Popović, J. Nieto, and
R. Siegwart, “Build your own visual-inertial drone: A cost-effective and
open-source autonomous drone,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics &amp; Automation Magazine</em>,
vol. 25, no. 1, pp. 89–103, 2017.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
K. Mohta, M. Watterson, Y. Mulgaonkar, S. Liu, C. Qu, A. Makineni, K. Saulnier,
K. Sun, A. Zhu, J. Delmerico, K. Karydis, N. Atanasov, G. Loianno,
D. Scaramuzza, K. Daniilidis, C. J. Taylor, and V. Kumar, “Fast, autonomous
flight in GPS-denied and cluttered environments,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Journal of Field
Robotics</em>, vol. 35, no. 1, pp. 101–120, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Oleynikova, C. Lanegger, Z. Taylor, M. Pantic, A. Millane, R. Siegwart, and
J. Nieto, “An open-source system for vision-based micro-aerial vehicle
mapping, planning, and flight in cluttered environments,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Journal of
Field Robotics</em>, vol. 37, no. 4, pp. 642–666, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
P. Foehn, E. Kaufmann, A. Romero, R. Penicka, S. Sun, L. Bauersfeld,
T. Laengle, G. Cioffi, Y. Song, A. Loquercio, and D. Scaramuzza,
“Agilicious: Open-source and open-hardware agile quadrotor for vision-based
flight,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Science Robotics</em>, vol. 7, no. 67, p. eabl6259, 2022.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. Baca, M. Petrlik, M. Vrba, V. Spurny, R. Penicka, D. Hert, and M. Saska,
“The MRS UAV system: Pushing the frontiers of reproducible research,
real-world deployment, and education with autonomous unmanned aerial
vehicles,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Journal of Intelligent &amp; Robotic Systems</em>, vol. 102,
no. 1, p. 26, 2021.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Briod, A. Klaptocz, J.-C. Zufferey, and D. Floreano, “The AirBurr: A
flying robot that can exploit collisions,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2012 ICME International
Conference on Complex Medical Engineering</em>, July 2012, pp. 569–574.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Briod, P. Kornatowski, J.-C. Zufferey, and D. Floreano, “A
collision-resilient flying robot,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Journal of Field Robotics</em>,
vol. 31, no. 4, pp. 496–509, 2014.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Mulgaonkar, A. Makineni, L. Guerrero-Bonilla, and V. Kumar, “Robust aerial
robot swarms without collision avoidance,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics and
Automation Letters</em>, vol. 3, no. 1, pp. 596–603, Jan 2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
P. De Petris, H. Nguyen, T. Dang, F. Mascarich, and K. Alexis,
“Collision-tolerant autonomous navigation through manhole-sized confined
environments,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">2020 IEEE International Symposium on Safety,
Security, and Rescue Robotics (SSRR)</em>, Nov 2020, pp. 84–89.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
H. Nguyen, S. H. Fyhn, P. De Petris, and K. Alexis, “Motion primitives-based
navigation planning using deep collision prediction,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Int. Conf. on
Robotics and Auto. (ICRA)</em>, May 2022, pp. 9660–9667.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
G. Heredia, A. Jimenez-Cano, I. Sanchez, D. Llorente, V. Vega, J. Braga,
J. Acosta, and A. Ollero, “Control of a multirotor outdoor aerial
manipulator,” in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">2014 IEEE/RSJ International Conference on
Intelligent Robots and Systems</em>.   IEEE,
2014, pp. 3417–3422.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
F. Fraundorfer and D. Scaramuzza, “Visual odometry: Part I: The first 30
years and fundamentals,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE Robotics &amp; Automation Magazine</em>,
vol. 18, no. 4, pp. 80–92, 2011.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
L. Meier, P. Tanskanen, L. Heng, G. H. Lee, F. Fraundorfer, and M. Pollefeys,
“PIXHAWK: A micro aerial vehicle design for autonomous flight using
onboard computer vision,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Autonomous Robots</em>, vol. 33, pp. 21–39,
2012.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
NVIDIA, “NVIDIA Isaac SDK: Stereo visual inertial odometry.” [Online].
Available:
<a target="_blank" href="https://docs.nvidia.com/isaac/archive/2020.2/packages/visual_slam/doc/visual_odometry.html" title="" class="ltx_ref ltx_url">https://docs.nvidia.com/isaac/archive/2020.2/packages/visual˙slam/doc/visual˙odometry.html</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
A. X. Appius, E. Bauer, M. Blöchlinger, A. Kalra, R. Oberson,
A. Raayatsanati, P. Strauch, S. Suresh, M. von Salis, and R. K. Katzschmann,
“RAPTOR: Rapid aerial pickup and transport of objects by robots,” in
<em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">2022 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS)</em>, 2022, pp. 349–355.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
P. Wohlhart and V. Lepetit, “Learning descriptors for object recognition and
3D pose estimation,” in <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, June 2015.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y. Hu, J. Hugonot, P. Fua, and M. Salzmann, “Segmentation-driven 6D object
pose estimation,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition (CVPR)</em>, June 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
J. Tremblay, T. To, B. Sundaralingam, Y. Xiang, D. Fox, and S. Birchfield,
“Deep object pose estimation for semantic robotic grasping of household
objects,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Conference on Robot Learning (CoRL)</em>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
NVIDIA, “NVIDIA Isaac SDK: 3D object pose estimation with DOPE.”
[Online]. Available:
<a target="_blank" href="https://docs.nvidia.com/isaac/archive/2020.2/packages/object_pose_estimation/doc/dope.html" title="" class="ltx_ref ltx_url">https://docs.nvidia.com/isaac/archive/2020.2/packages/object˙pose˙estimation/doc/dope.html</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
S. Tyree, J. Tremblay, T. To, J. Cheng, T. Mosier, J. Smith, and S. Birchfield,
“6-DoF pose estimation of household objects for robotic manipulation: An
accessible dataset and benchmark,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE/RSJ Int. Conf. on Intell.
Robots and Systems (IROS)</em>, 2022, pp. 13 081–13 088.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.01397" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.01398" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2308.01398">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.01398" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.01399" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 14:24:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
