<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2301.05499] CLIP the Gap: A Single Domain Generalization Approach for Object Detection</title><meta property="og:description" content="Single Domain Generalization (SDG) tackles the problem of training a model on a single source domain so that it generalizes to any unseen target domain. While this has been well studied for image classification, the liâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CLIP the Gap: A Single Domain Generalization Approach for Object Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="CLIP the Gap: A Single Domain Generalization Approach for Object Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2301.05499">

<!--Generated on Fri Mar  1 07:21:13 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">CLIP the Gap: A Single Domain Generalization Approach for Object Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vidit Vidit<sup id="id6.6.id1" class="ltx_sup">1</sup> Â  Martin Engilberge<sup id="id7.7.id2" class="ltx_sup">1</sup> Â  Mathieu Salzmann<sup id="id8.8.id3" class="ltx_sup"><span id="id8.8.id3.1" class="ltx_text ltx_font_italic">1,2</span></sup> 
<br class="ltx_break">CVLab, EPFL<sup id="id9.9.id4" class="ltx_sup">1</sup>, ClearSpace SA<sup id="id10.10.id5" class="ltx_sup">2</sup>
<br class="ltx_break"><span id="id11.11.id6" class="ltx_text ltx_font_typewriter" style="font-size:90%;">firstname.lastname@epfl.ch</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id12.id1" class="ltx_p">Single Domain Generalization (SDG) tackles the problem of training a model on a single source domain so that it generalizes to any unseen target domain. While this has been well studied for image classification, the literature on SDG object detection remains almost non-existent. To address the challenges of simultaneously learning robust object localization and representation, we propose to leverage a pre-trained vision-language model to introduce semantic domain concepts via textual prompts. We achieve this via a semantic augmentation strategy acting on the features extracted by the detector backbone, as well as a text-based classification loss.
Our experiments evidence the benefits of our approach, outperforming by 10% the only existing SDG object detection method, Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, on their own diverse weather-driving benchmark.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As for most machine learning models, the performance of object detectors degrades when the test data distribution deviates from the training data one. Domain adaptation techniquesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> try to alleviate this problem by learning domain invariant features between a source and a known target domain. In practice, however, it is not always possible to obtain target data, even unlabeled, precluding the use of such techniques. Domain generalization tackles this by seeking to learn representations that generalize to any target domain. While early approachesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> focused on the scenario where multiple source domains are available during training, many recent methods tackle the more challenging, yet more realistic, case of Single Domain Generalization (SDG), aiming to learn to generalize from a single source dataset. While this has been well studied for image classificationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, it remains a nascent topic in object detection. To the best of our knowledge, a single existing approach, Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, uses disentanglement and self-distillationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> to learn domain-invariant features.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2301.05499/assets/figures/teaser.png" id="S1.F1.g1" class="ltx_graphics ltx_img_portrait" width="598" height="785" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.4.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Semantic Augmentation:<span id="S1.F1.5.2.1" class="ltx_text ltx_font_medium"> We compare the PCA projections of CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> image embeddings obtained in two different manners: (Top) The embeddings were directly obtained from the real images from 5 domains corresponding to different weather conditions. (Bottom) The embeddings were obtained from the <em id="S1.F1.5.2.1.1" class="ltx_emph ltx_font_italic">day</em> images only and modified with our semantic augmentation strategy based on text prompts to reflect the other 4 domains. Note that the relative positions of the clusters in the bottom plot resembles that of the top one, showing that our augmentations let us generalize to different target domains. The principal components used are the same for both the figures.
</span></span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper, we introduce a fundamentally different approach to SDG for object detection. To this end, we build on two observations: (i) Unsupervised/self-supervised pre-training facilitates the transfer of a model to new tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>; (ii) Exploiting language supervision to train vision models allows them to generalize more easily to new categories and concepts<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.
Inspired by this, we therefore propose to leverage a self-supervised vision-language model, CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, to guide the training of an object detector so that it generalizes to unseen target domains.
Since the visual CLIP representation has been jointly learned with the textual one, we transfer text-based domain variations to the image representation during training, thus increasing the diversity of the source data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Specifically, we
define textual prompts describing potential target domain concepts, such as weather and daytime variations for road scene understanding, and use these prompts to perform semantic augmentations of the images. These augmentations, however, are done in feature space, not in image space, which is facilitated by the joint image-text CLIP latent space.
This is illustrated inÂ <a href="#S1.F1" title="In 1 Introduction â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>, which shows that, even though we did not use any target data for semantic augmentation, the resulting augmented embeddings reflect the distributions of the true image embeddings from different target domains.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We show the effectiveness of our method on the SDG driving dataset ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, which reflects a practical scenario where the training (source) images were captured on a clear day whereas the test (target) ones were acquired in rainy, foggy, night, and dusk conditions. Our experiments demonstrate the benefits of our approach over the Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> one.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To summarize our contributions, we employ a vision-language model
to improve the generalizability of an object detector; during training, we introduce domain concepts via text-prompts to augment the diversity of the learned image features and make them more robust to an unseen target domain. This enables us to achieve state-of-the-art results on the diverse weather SDG driving benchmark ofÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Domain Adaptation for Object Detection.</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">Domain adaptation methods seek to align the source domain distribution to a particular target domain. To bridge the global and instance-level domain gaps, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> learn feature alignment viaÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> adversarial training; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> utilize category-level centroids and attention maps, respectively, to better align instances in the two domains; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> generate pseudo-labels in the target domain and use them for target-aware training. Domain adaptation, however, assumes that images from the target domain are available during training. In contrast, domain generalization aims to learn models that generalize to domains that were not seen at all during training. Below, we focus on the domain generalization methods that, as us, use a single source domain to do so.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Single Domain Generalization (SDG).</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">Several image classification worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> have proposed strategies to improve the performance on <em id="S2.SS0.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">unseen</em> domains while training on a single source domain. In particular, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> introduce data augmentation strategies where diverse input images are generated via adversarial training; <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> propose normalization techniques to adapt the feature distribution to unseen domains. While SDG has been reasonably well studied for image classification, the case of object detection remains largely unexplored, and poses additional challenges related to the need to further localize the objects of interest.
This was recently tackled by Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> with an approach relying on learning domain-specific and domain-invariant features. Specifically, this was achieved by exploiting contrastive learning to disentangle the features and self-distillationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> to further improve the networkâ€™s generalizability.
Here, we introduce a fundamentally different approach that leverages the CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> pre-trained model and semantically augments the data using textual prompts. As will be shown by our results, our method outperforms the state-of-the-art Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Vision-Language Models.</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">Jointly learning a representation of images and text has been studied in many worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. They use image-text pairs to train visual-semantic embeddings which can be used not only for image classification, captioning or retrieval but also for zero-shot prediction on unseen labels. VirTexÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> relies on image-caption-based pre-training to learn a rich visual embedding from a small amount of data. CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> proposes a scalable contrastive pre-training method for joint text and image feature learning. CLIP leverages a corpus of 400 million image-text pairs and a large language modelÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> to learn a joint embedding space, which was shown to have superior zero-shot learning ability on classification tasks. The image-text-based training is also useful for Open Vocabulary Detection (OVD)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, where the objects are detected using arbitrary textual descriptions. To address this task, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> train their own visual-semantic representation, whereas Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> employ CLIP embeddings. Recently, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> introduced a phrase-grounding-based pre-training for better OVD and zero-shot object detection. In contrast to these works, whose objective is to generalize to novel <em id="S2.SS0.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">categories or objects</em>, we seek to generalize to new <em id="S2.SS0.SSS0.Px3.p1.1.2" class="ltx_emph ltx_font_italic">domains</em> depicting the same object categories as the source one.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2301.05499/assets/figures/arch.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="216" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.23.10.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.18.9" class="ltx_text ltx_font_bold" style="font-size:90%;">Our Approach:<span id="S3.F2.18.9.10" class="ltx_text ltx_font_medium"> </span>(Left)<span id="S3.F2.13.4.4" class="ltx_text ltx_font_medium"> We first estimate a set of semantic augmentations <math id="S3.F2.10.1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.F2.10.1.1.m1.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.10.1.1.m1.1.1" xref="S3.F2.10.1.1.m1.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.F2.10.1.1.m1.1c"><ci id="S3.F2.10.1.1.m1.1.1.cmml" xref="S3.F2.10.1.1.m1.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.10.1.1.m1.1d">\mathcal{A}</annotation></semantics></math> using a set of textual domain prompts <math id="S3.F2.11.2.2.m2.2" class="ltx_Math" alttext="\{\mathcal{P}^{t},p^{s}\}" display="inline"><semantics id="S3.F2.11.2.2.m2.2b"><mrow id="S3.F2.11.2.2.m2.2.2.2" xref="S3.F2.11.2.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.F2.11.2.2.m2.2.2.2.3" xref="S3.F2.11.2.2.m2.2.2.3.cmml">{</mo><msup id="S3.F2.11.2.2.m2.1.1.1.1" xref="S3.F2.11.2.2.m2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.11.2.2.m2.1.1.1.1.2" xref="S3.F2.11.2.2.m2.1.1.1.1.2.cmml">ğ’«</mi><mi id="S3.F2.11.2.2.m2.1.1.1.1.3" xref="S3.F2.11.2.2.m2.1.1.1.1.3.cmml">t</mi></msup><mo id="S3.F2.11.2.2.m2.2.2.2.4" xref="S3.F2.11.2.2.m2.2.2.3.cmml">,</mo><msup id="S3.F2.11.2.2.m2.2.2.2.2" xref="S3.F2.11.2.2.m2.2.2.2.2.cmml"><mi id="S3.F2.11.2.2.m2.2.2.2.2.2" xref="S3.F2.11.2.2.m2.2.2.2.2.2.cmml">p</mi><mi id="S3.F2.11.2.2.m2.2.2.2.2.3" xref="S3.F2.11.2.2.m2.2.2.2.2.3.cmml">s</mi></msup><mo stretchy="false" id="S3.F2.11.2.2.m2.2.2.2.5" xref="S3.F2.11.2.2.m2.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.F2.11.2.2.m2.2c"><set id="S3.F2.11.2.2.m2.2.2.3.cmml" xref="S3.F2.11.2.2.m2.2.2.2"><apply id="S3.F2.11.2.2.m2.1.1.1.1.cmml" xref="S3.F2.11.2.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.F2.11.2.2.m2.1.1.1.1.1.cmml" xref="S3.F2.11.2.2.m2.1.1.1.1">superscript</csymbol><ci id="S3.F2.11.2.2.m2.1.1.1.1.2.cmml" xref="S3.F2.11.2.2.m2.1.1.1.1.2">ğ’«</ci><ci id="S3.F2.11.2.2.m2.1.1.1.1.3.cmml" xref="S3.F2.11.2.2.m2.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.F2.11.2.2.m2.2.2.2.2.cmml" xref="S3.F2.11.2.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.F2.11.2.2.m2.2.2.2.2.1.cmml" xref="S3.F2.11.2.2.m2.2.2.2.2">superscript</csymbol><ci id="S3.F2.11.2.2.m2.2.2.2.2.2.cmml" xref="S3.F2.11.2.2.m2.2.2.2.2.2">ğ‘</ci><ci id="S3.F2.11.2.2.m2.2.2.2.2.3.cmml" xref="S3.F2.11.2.2.m2.2.2.2.2.3">ğ‘ </ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.11.2.2.m2.2d">\{\mathcal{P}^{t},p^{s}\}</annotation></semantics></math> and source domain images. The goal of these semantic augmentations is to translate source domain image embeddings to the domain specified by the prompts. We can do this because of the CLIPâ€™s joint embedding space and its ability to encode semantic relationships via algebraic operations. <math id="S3.F2.12.3.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{opt}" display="inline"><semantics id="S3.F2.12.3.3.m3.1b"><msub id="S3.F2.12.3.3.m3.1.1" xref="S3.F2.12.3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.12.3.3.m3.1.1.2" xref="S3.F2.12.3.3.m3.1.1.2.cmml">â„’</mi><mrow id="S3.F2.12.3.3.m3.1.1.3" xref="S3.F2.12.3.3.m3.1.1.3.cmml"><mi id="S3.F2.12.3.3.m3.1.1.3.2" xref="S3.F2.12.3.3.m3.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.F2.12.3.3.m3.1.1.3.1" xref="S3.F2.12.3.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.12.3.3.m3.1.1.3.3" xref="S3.F2.12.3.3.m3.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.F2.12.3.3.m3.1.1.3.1b" xref="S3.F2.12.3.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.12.3.3.m3.1.1.3.4" xref="S3.F2.12.3.3.m3.1.1.3.4.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.F2.12.3.3.m3.1c"><apply id="S3.F2.12.3.3.m3.1.1.cmml" xref="S3.F2.12.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.12.3.3.m3.1.1.1.cmml" xref="S3.F2.12.3.3.m3.1.1">subscript</csymbol><ci id="S3.F2.12.3.3.m3.1.1.2.cmml" xref="S3.F2.12.3.3.m3.1.1.2">â„’</ci><apply id="S3.F2.12.3.3.m3.1.1.3.cmml" xref="S3.F2.12.3.3.m3.1.1.3"><times id="S3.F2.12.3.3.m3.1.1.3.1.cmml" xref="S3.F2.12.3.3.m3.1.1.3.1"></times><ci id="S3.F2.12.3.3.m3.1.1.3.2.cmml" xref="S3.F2.12.3.3.m3.1.1.3.2">ğ‘œ</ci><ci id="S3.F2.12.3.3.m3.1.1.3.3.cmml" xref="S3.F2.12.3.3.m3.1.1.3.3">ğ‘</ci><ci id="S3.F2.12.3.3.m3.1.1.3.4.cmml" xref="S3.F2.12.3.3.m3.1.1.3.4">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.12.3.3.m3.1d">\mathcal{L}_{opt}</annotation></semantics></math> is minimized w.r.t <math id="S3.F2.13.4.4.m4.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.F2.13.4.4.m4.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.13.4.4.m4.1.1" xref="S3.F2.13.4.4.m4.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.F2.13.4.4.m4.1c"><ci id="S3.F2.13.4.4.m4.1.1.cmml" xref="S3.F2.13.4.4.m4.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.13.4.4.m4.1d">\mathcal{A}</annotation></semantics></math> over random image crops of the same size as CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. </span>(Right)<span id="S3.F2.18.9.9" class="ltx_text ltx_font_medium"> The optimized semantic augmentations are used to train our modified detector which minimizes a text-based classification loss <math id="S3.F2.14.5.5.m1.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S3.F2.14.5.5.m1.1b"><msub id="S3.F2.14.5.5.m1.1.1" xref="S3.F2.14.5.5.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.14.5.5.m1.1.1.2" xref="S3.F2.14.5.5.m1.1.1.2.cmml">â„’</mi><mrow id="S3.F2.14.5.5.m1.1.1.3" xref="S3.F2.14.5.5.m1.1.1.3.cmml"><mi id="S3.F2.14.5.5.m1.1.1.3.2" xref="S3.F2.14.5.5.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.F2.14.5.5.m1.1.1.3.1" xref="S3.F2.14.5.5.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.14.5.5.m1.1.1.3.3" xref="S3.F2.14.5.5.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.F2.14.5.5.m1.1.1.3.1b" xref="S3.F2.14.5.5.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.14.5.5.m1.1.1.3.4" xref="S3.F2.14.5.5.m1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.F2.14.5.5.m1.1.1.3.1c" xref="S3.F2.14.5.5.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.14.5.5.m1.1.1.3.5" xref="S3.F2.14.5.5.m1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.F2.14.5.5.m1.1.1.3.1d" xref="S3.F2.14.5.5.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.F2.14.5.5.m1.1.1.3.6" xref="S3.F2.14.5.5.m1.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.F2.14.5.5.m1.1c"><apply id="S3.F2.14.5.5.m1.1.1.cmml" xref="S3.F2.14.5.5.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.14.5.5.m1.1.1.1.cmml" xref="S3.F2.14.5.5.m1.1.1">subscript</csymbol><ci id="S3.F2.14.5.5.m1.1.1.2.cmml" xref="S3.F2.14.5.5.m1.1.1.2">â„’</ci><apply id="S3.F2.14.5.5.m1.1.1.3.cmml" xref="S3.F2.14.5.5.m1.1.1.3"><times id="S3.F2.14.5.5.m1.1.1.3.1.cmml" xref="S3.F2.14.5.5.m1.1.1.3.1"></times><ci id="S3.F2.14.5.5.m1.1.1.3.2.cmml" xref="S3.F2.14.5.5.m1.1.1.3.2">ğ‘</ci><ci id="S3.F2.14.5.5.m1.1.1.3.3.cmml" xref="S3.F2.14.5.5.m1.1.1.3.3">ğ‘™</ci><ci id="S3.F2.14.5.5.m1.1.1.3.4.cmml" xref="S3.F2.14.5.5.m1.1.1.3.4">ğ‘–</ci><ci id="S3.F2.14.5.5.m1.1.1.3.5.cmml" xref="S3.F2.14.5.5.m1.1.1.3.5">ğ‘</ci><ci id="S3.F2.14.5.5.m1.1.1.3.6.cmml" xref="S3.F2.14.5.5.m1.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.14.5.5.m1.1d">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math>. Here, we train with the full image and add a randomly sampled <math id="S3.F2.15.6.6.m2.1" class="ltx_Math" alttext="\mathcal{A}_{j}" display="inline"><semantics id="S3.F2.15.6.6.m2.1b"><msub id="S3.F2.15.6.6.m2.1.1" xref="S3.F2.15.6.6.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.15.6.6.m2.1.1.2" xref="S3.F2.15.6.6.m2.1.1.2.cmml">ğ’œ</mi><mi id="S3.F2.15.6.6.m2.1.1.3" xref="S3.F2.15.6.6.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.15.6.6.m2.1c"><apply id="S3.F2.15.6.6.m2.1.1.cmml" xref="S3.F2.15.6.6.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.15.6.6.m2.1.1.1.cmml" xref="S3.F2.15.6.6.m2.1.1">subscript</csymbol><ci id="S3.F2.15.6.6.m2.1.1.2.cmml" xref="S3.F2.15.6.6.m2.1.1.2">ğ’œ</ci><ci id="S3.F2.15.6.6.m2.1.1.3.cmml" xref="S3.F2.15.6.6.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.15.6.6.m2.1d">\mathcal{A}_{j}</annotation></semantics></math> after average pooling. This pooling operation allows us to use <math id="S3.F2.16.7.7.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.F2.16.7.7.m3.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.16.7.7.m3.1.1" xref="S3.F2.16.7.7.m3.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.F2.16.7.7.m3.1c"><ci id="S3.F2.16.7.7.m3.1.1.cmml" xref="S3.F2.16.7.7.m3.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.16.7.7.m3.1d">\mathcal{A}</annotation></semantics></math> on extracted feature maps of the arbitrary-sized image. We initialize the detector with the pre-trained CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> <math id="S3.F2.17.8.8.m4.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S3.F2.17.8.8.m4.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.17.8.8.m4.1.1" xref="S3.F2.17.8.8.m4.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S3.F2.17.8.8.m4.1c"><ci id="S3.F2.17.8.8.m4.1.1.cmml" xref="S3.F2.17.8.8.m4.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.17.8.8.m4.1d">\mathcal{V}</annotation></semantics></math> and <math id="S3.F2.18.9.9.m5.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.F2.18.9.9.m5.1b"><mi class="ltx_font_mathcaligraphic" id="S3.F2.18.9.9.m5.1.1" xref="S3.F2.18.9.9.m5.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.F2.18.9.9.m5.1c"><ci id="S3.F2.18.9.9.m5.1.1.cmml" xref="S3.F2.18.9.9.m5.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.18.9.9.m5.1d">\mathcal{T}</annotation></semantics></math> encoders to leverage their general representations.</span></span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Let us now introduce our approach to exploiting a vision-language model for single-domain generalization in object detection. Below, we first present our semantic augmentation strategy aiming to facilitate generalization to new domains. We then describe the architecture and training strategy for our object detector.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Semantic Augmentation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In SDG, we have access to images from only a single domain. To enable generalization, we seek to learn object representations that are robust to domain shifts. Here, we do so by introducing such shifts while training the model on the source data. Specifically, we exploit CLIPâ€™s joint representation to estimate shifts in the visual domain using textual prompts, as illustrated inÂ <a href="#S1.F1" title="In 1 Introduction â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. This corresponds to the optimization step shown in the left portion ofÂ <a href="#S3.F2" title="In 3 Method â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.9" class="ltx_p">Formally, let <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{T}</annotation></semantics></math> denote CLIPâ€™s text encoder and <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathcal{V}</annotation></semantics></math> its image one. For reasons that will become clear later, we further split <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathcal{V}</annotation></semantics></math> into a feature extractor <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\mathcal{V}^{a}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><msup id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">ğ’±</mi><mi id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">ğ’±</ci><ci id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathcal{V}^{a}</annotation></semantics></math> and a projector to the embedding space <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathcal{V}^{b}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msup id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">ğ’±</mi><mi id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">ğ’±</ci><ci id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\mathcal{V}^{b}</annotation></semantics></math>. The CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> model is trained to bring image features closer to their textual captions. In essence, this means that, for an image <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">â„</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\mathcal{I}</annotation></semantics></math> and a corresponding prompt <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">p</annotation></semantics></math>, it seeks to minimize the distance between <math id="S3.SS1.p2.8.m8.2" class="ltx_Math" alttext="\mathcal{V}^{b}(\mathcal{V}^{a}(I))" display="inline"><semantics id="S3.SS1.p2.8.m8.2a"><mrow id="S3.SS1.p2.8.m8.2.2" xref="S3.SS1.p2.8.m8.2.2.cmml"><msup id="S3.SS1.p2.8.m8.2.2.3" xref="S3.SS1.p2.8.m8.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.8.m8.2.2.3.2" xref="S3.SS1.p2.8.m8.2.2.3.2.cmml">ğ’±</mi><mi id="S3.SS1.p2.8.m8.2.2.3.3" xref="S3.SS1.p2.8.m8.2.2.3.3.cmml">b</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p2.8.m8.2.2.2" xref="S3.SS1.p2.8.m8.2.2.2.cmml">â€‹</mo><mrow id="S3.SS1.p2.8.m8.2.2.1.1" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.8.m8.2.2.1.1.2" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml">(</mo><mrow id="S3.SS1.p2.8.m8.2.2.1.1.1" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml"><msup id="S3.SS1.p2.8.m8.2.2.1.1.1.2" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.8.m8.2.2.1.1.1.2.2" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2.2.cmml">ğ’±</mi><mi id="S3.SS1.p2.8.m8.2.2.1.1.1.2.3" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2.3.cmml">a</mi></msup><mo lspace="0em" rspace="0em" id="S3.SS1.p2.8.m8.2.2.1.1.1.1" xref="S3.SS1.p2.8.m8.2.2.1.1.1.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.8.m8.2.2.1.1.1.3.2" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p2.8.m8.2.2.1.1.1.3.2.1" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml">(</mo><mi id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">I</mi><mo stretchy="false" id="S3.SS1.p2.8.m8.2.2.1.1.1.3.2.2" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS1.p2.8.m8.2.2.1.1.3" xref="S3.SS1.p2.8.m8.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.2b"><apply id="S3.SS1.p2.8.m8.2.2.cmml" xref="S3.SS1.p2.8.m8.2.2"><times id="S3.SS1.p2.8.m8.2.2.2.cmml" xref="S3.SS1.p2.8.m8.2.2.2"></times><apply id="S3.SS1.p2.8.m8.2.2.3.cmml" xref="S3.SS1.p2.8.m8.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.2.2.3.1.cmml" xref="S3.SS1.p2.8.m8.2.2.3">superscript</csymbol><ci id="S3.SS1.p2.8.m8.2.2.3.2.cmml" xref="S3.SS1.p2.8.m8.2.2.3.2">ğ’±</ci><ci id="S3.SS1.p2.8.m8.2.2.3.3.cmml" xref="S3.SS1.p2.8.m8.2.2.3.3">ğ‘</ci></apply><apply id="S3.SS1.p2.8.m8.2.2.1.1.1.cmml" xref="S3.SS1.p2.8.m8.2.2.1.1"><times id="S3.SS1.p2.8.m8.2.2.1.1.1.1.cmml" xref="S3.SS1.p2.8.m8.2.2.1.1.1.1"></times><apply id="S3.SS1.p2.8.m8.2.2.1.1.1.2.cmml" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.8.m8.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2">superscript</csymbol><ci id="S3.SS1.p2.8.m8.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2.2">ğ’±</ci><ci id="S3.SS1.p2.8.m8.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p2.8.m8.2.2.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS1.p2.8.m8.1.1.cmml" xref="S3.SS1.p2.8.m8.1.1">ğ¼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.2c">\mathcal{V}^{b}(\mathcal{V}^{a}(I))</annotation></semantics></math> and <math id="S3.SS1.p2.9.m9.1" class="ltx_Math" alttext="\mathcal{T}(p)" display="inline"><semantics id="S3.SS1.p2.9.m9.1a"><mrow id="S3.SS1.p2.9.m9.1.2" xref="S3.SS1.p2.9.m9.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.9.m9.1.2.2" xref="S3.SS1.p2.9.m9.1.2.2.cmml">ğ’¯</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.9.m9.1.2.1" xref="S3.SS1.p2.9.m9.1.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.9.m9.1.2.3.2" xref="S3.SS1.p2.9.m9.1.2.cmml"><mo stretchy="false" id="S3.SS1.p2.9.m9.1.2.3.2.1" xref="S3.SS1.p2.9.m9.1.2.cmml">(</mo><mi id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">p</mi><mo stretchy="false" id="S3.SS1.p2.9.m9.1.2.3.2.2" xref="S3.SS1.p2.9.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><apply id="S3.SS1.p2.9.m9.1.2.cmml" xref="S3.SS1.p2.9.m9.1.2"><times id="S3.SS1.p2.9.m9.1.2.1.cmml" xref="S3.SS1.p2.9.m9.1.2.1"></times><ci id="S3.SS1.p2.9.m9.1.2.2.cmml" xref="S3.SS1.p2.9.m9.1.2.2">ğ’¯</ci><ci id="S3.SS1.p2.9.m9.1.1.cmml" xref="S3.SS1.p2.9.m9.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">\mathcal{T}(p)</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">A useful property of the text embedding space is that algebraic operations can be used to estimate semantically related concepts. Word2VecÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> had demonstrated such a learned relationship (e.g. <em id="S3.SS1.p3.1.1" class="ltx_emph ltx_font_italic">king</em>-<em id="S3.SS1.p3.1.2" class="ltx_emph ltx_font_italic">man</em>+<em id="S3.SS1.p3.1.3" class="ltx_emph ltx_font_italic">woman</em> approaches the word representation of <em id="S3.SS1.p3.1.4" class="ltx_emph ltx_font_italic">queen</em>). Such a relationship exists with CLIP embeddings as wellÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.6" class="ltx_p">To exploit this for SDG, we define a generic textual prompt <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="{p}^{s}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msup id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">p</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">{p}^{s}</annotation></semantics></math> related to the source domain, such as <span id="S3.SS1.p4.6.1" class="ltx_text ltx_font_typewriter">An image taken during the day</span>, and a set of prompts <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{P}^{t}=\{p_{j}^{t}\}_{1}^{M}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><msup id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.2.m2.1.1.3.2" xref="S3.SS1.p4.2.m2.1.1.3.2.cmml">ğ’«</mi><mi id="S3.SS1.p4.2.m2.1.1.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.cmml">t</mi></msup><mo id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">=</mo><msubsup id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml"><mrow id="S3.SS1.p4.2.m2.1.1.1.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p4.2.m2.1.1.1.1.1.1.2" xref="S3.SS1.p4.2.m2.1.1.1.1.1.2.cmml">{</mo><msubsup id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.3" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.3.cmml">j</mi><mi id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.3" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.SS1.p4.2.m2.1.1.1.1.1.1.3" xref="S3.SS1.p4.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mn id="S3.SS1.p4.2.m2.1.1.1.1.3" xref="S3.SS1.p4.2.m2.1.1.1.1.3.cmml">1</mn><mi id="S3.SS1.p4.2.m2.1.1.1.3" xref="S3.SS1.p4.2.m2.1.1.1.3.cmml">M</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><eq id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2"></eq><apply id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.2">ğ’«</ci><ci id="S3.SS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.1">superscript</csymbol><apply id="S3.SS1.p4.2.m2.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.1">subscript</csymbol><set id="S3.SS1.p4.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1"><apply id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></set><cn type="integer" id="S3.SS1.p4.2.m2.1.1.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.1.1.3">1</cn></apply><ci id="S3.SS1.p4.2.m2.1.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.1.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\mathcal{P}^{t}=\{p_{j}^{t}\}_{1}^{M}</annotation></semantics></math> encompassing variations that can be expected to occur in different target domains, e.g, describing different weather conditions or times of the day.
Our objective then is to define augmentations <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="\{\mathcal{A}_{j}\}" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mrow id="S3.SS1.p4.3.m3.1.1.1" xref="S3.SS1.p4.3.m3.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p4.3.m3.1.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">{</mo><msub id="S3.SS1.p4.3.m3.1.1.1.1" xref="S3.SS1.p4.3.m3.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.3.m3.1.1.1.1.2" xref="S3.SS1.p4.3.m3.1.1.1.1.2.cmml">ğ’œ</mi><mi id="S3.SS1.p4.3.m3.1.1.1.1.3" xref="S3.SS1.p4.3.m3.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS1.p4.3.m3.1.1.1.3" xref="S3.SS1.p4.3.m3.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><set id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.1"><apply id="S3.SS1.p4.3.m3.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.2">ğ’œ</ci><ci id="S3.SS1.p4.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.1.1.3">ğ‘—</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">\{\mathcal{A}_{j}\}</annotation></semantics></math> of the features extracted from a source image such that the shift incurred by <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="\mathcal{A}_{j}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><msub id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.4.m4.1.1.2" xref="S3.SS1.p4.4.m4.1.1.2.cmml">ğ’œ</mi><mi id="S3.SS1.p4.4.m4.1.1.3" xref="S3.SS1.p4.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><apply id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.4.m4.1.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p4.4.m4.1.1.2.cmml" xref="S3.SS1.p4.4.m4.1.1.2">ğ’œ</ci><ci id="S3.SS1.p4.4.m4.1.1.3.cmml" xref="S3.SS1.p4.4.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\mathcal{A}_{j}</annotation></semantics></math> corresponds to the semantic difference
between <math id="S3.SS1.p4.5.m5.1" class="ltx_Math" alttext="p^{s}" display="inline"><semantics id="S3.SS1.p4.5.m5.1a"><msup id="S3.SS1.p4.5.m5.1.1" xref="S3.SS1.p4.5.m5.1.1.cmml"><mi id="S3.SS1.p4.5.m5.1.1.2" xref="S3.SS1.p4.5.m5.1.1.2.cmml">p</mi><mi id="S3.SS1.p4.5.m5.1.1.3" xref="S3.SS1.p4.5.m5.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m5.1b"><apply id="S3.SS1.p4.5.m5.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m5.1.1.1.cmml" xref="S3.SS1.p4.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.p4.5.m5.1.1.2.cmml" xref="S3.SS1.p4.5.m5.1.1.2">ğ‘</ci><ci id="S3.SS1.p4.5.m5.1.1.3.cmml" xref="S3.SS1.p4.5.m5.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m5.1c">p^{s}</annotation></semantics></math> and <math id="S3.SS1.p4.6.m6.1" class="ltx_Math" alttext="p^{t}_{j}" display="inline"><semantics id="S3.SS1.p4.6.m6.1a"><msubsup id="S3.SS1.p4.6.m6.1.1" xref="S3.SS1.p4.6.m6.1.1.cmml"><mi id="S3.SS1.p4.6.m6.1.1.2.2" xref="S3.SS1.p4.6.m6.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p4.6.m6.1.1.3" xref="S3.SS1.p4.6.m6.1.1.3.cmml">j</mi><mi id="S3.SS1.p4.6.m6.1.1.2.3" xref="S3.SS1.p4.6.m6.1.1.2.3.cmml">t</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m6.1b"><apply id="S3.SS1.p4.6.m6.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m6.1.1.1.cmml" xref="S3.SS1.p4.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.p4.6.m6.1.1.2.cmml" xref="S3.SS1.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m6.1.1.2.1.cmml" xref="S3.SS1.p4.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.p4.6.m6.1.1.2.2.cmml" xref="S3.SS1.p4.6.m6.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p4.6.m6.1.1.2.3.cmml" xref="S3.SS1.p4.6.m6.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.p4.6.m6.1.1.3.cmml" xref="S3.SS1.p4.6.m6.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m6.1c">p^{t}_{j}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.3" class="ltx_p">To achieve this, we first compute the embeddings <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="q^{s}=\mathcal{T}(p^{s})" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mrow id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><msup id="S3.SS1.p5.1.m1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.3.cmml"><mi id="S3.SS1.p5.1.m1.1.1.3.2" xref="S3.SS1.p5.1.m1.1.1.3.2.cmml">q</mi><mi id="S3.SS1.p5.1.m1.1.1.3.3" xref="S3.SS1.p5.1.m1.1.1.3.3.cmml">s</mi></msup><mo id="S3.SS1.p5.1.m1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.2.cmml">=</mo><mrow id="S3.SS1.p5.1.m1.1.1.1" xref="S3.SS1.p5.1.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.1.m1.1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.1.3.cmml">ğ’¯</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.1.m1.1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p5.1.m1.1.1.1.1.1" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p5.1.m1.1.1.1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.SS1.p5.1.m1.1.1.1.1.1.1" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p5.1.m1.1.1.1.1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.SS1.p5.1.m1.1.1.1.1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.3.cmml">s</mi></msup><mo stretchy="false" id="S3.SS1.p5.1.m1.1.1.1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><eq id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2"></eq><apply id="S3.SS1.p5.1.m1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.3.1.cmml" xref="S3.SS1.p5.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.3.2.cmml" xref="S3.SS1.p5.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p5.1.m1.1.1.3.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3.3">ğ‘ </ci></apply><apply id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1.1"><times id="S3.SS1.p5.1.m1.1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.1.2"></times><ci id="S3.SS1.p5.1.m1.1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.1.3">ğ’¯</ci><apply id="S3.SS1.p5.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.SS1.p5.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.1.1.1.1.3">ğ‘ </ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">q^{s}=\mathcal{T}(p^{s})</annotation></semantics></math> and <math id="S3.SS1.p5.2.m2.1" class="ltx_Math" alttext="q^{t}_{j}=\mathcal{T}(p^{t}_{j})" display="inline"><semantics id="S3.SS1.p5.2.m2.1a"><mrow id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml"><msubsup id="S3.SS1.p5.2.m2.1.1.3" xref="S3.SS1.p5.2.m2.1.1.3.cmml"><mi id="S3.SS1.p5.2.m2.1.1.3.2.2" xref="S3.SS1.p5.2.m2.1.1.3.2.2.cmml">q</mi><mi id="S3.SS1.p5.2.m2.1.1.3.3" xref="S3.SS1.p5.2.m2.1.1.3.3.cmml">j</mi><mi id="S3.SS1.p5.2.m2.1.1.3.2.3" xref="S3.SS1.p5.2.m2.1.1.3.2.3.cmml">t</mi></msubsup><mo id="S3.SS1.p5.2.m2.1.1.2" xref="S3.SS1.p5.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS1.p5.2.m2.1.1.1" xref="S3.SS1.p5.2.m2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.2.m2.1.1.1.3" xref="S3.SS1.p5.2.m2.1.1.1.3.cmml">ğ’¯</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.2.m2.1.1.1.2" xref="S3.SS1.p5.2.m2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p5.2.m2.1.1.1.1.1" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p5.2.m2.1.1.1.1.1.2" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.SS1.p5.2.m2.1.1.1.1.1.1" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.2.cmml">p</mi><mi id="S3.SS1.p5.2.m2.1.1.1.1.1.1.3" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.3.cmml">j</mi><mi id="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.3" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.3.cmml">t</mi></msubsup><mo stretchy="false" id="S3.SS1.p5.2.m2.1.1.1.1.1.3" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><apply id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1"><eq id="S3.SS1.p5.2.m2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2"></eq><apply id="S3.SS1.p5.2.m2.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.3.1.cmml" xref="S3.SS1.p5.2.m2.1.1.3">subscript</csymbol><apply id="S3.SS1.p5.2.m2.1.1.3.2.cmml" xref="S3.SS1.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.3.2.1.cmml" xref="S3.SS1.p5.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.3.2.2.cmml" xref="S3.SS1.p5.2.m2.1.1.3.2.2">ğ‘</ci><ci id="S3.SS1.p5.2.m2.1.1.3.2.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.p5.2.m2.1.1.3.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3.3">ğ‘—</ci></apply><apply id="S3.SS1.p5.2.m2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1.1"><times id="S3.SS1.p5.2.m2.1.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.1.2"></times><ci id="S3.SS1.p5.2.m2.1.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.1.3">ğ’¯</ci><apply id="S3.SS1.p5.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.p5.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.1.1.1.1.3">ğ‘—</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">q^{t}_{j}=\mathcal{T}(p^{t}_{j})</annotation></semantics></math> of the textual prompt. We then take multiple random crops from a source image. For each such crop <math id="S3.SS1.p5.3.m3.1" class="ltx_Math" alttext="\mathcal{I}_{crop}" display="inline"><semantics id="S3.SS1.p5.3.m3.1a"><msub id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">â„</mi><mrow id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml"><mi id="S3.SS1.p5.3.m3.1.1.3.2" xref="S3.SS1.p5.3.m3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.3.m3.1.1.3.1" xref="S3.SS1.p5.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p5.3.m3.1.1.3.3" xref="S3.SS1.p5.3.m3.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.3.m3.1.1.3.1a" xref="S3.SS1.p5.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p5.3.m3.1.1.3.4" xref="S3.SS1.p5.3.m3.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.3.m3.1.1.3.1b" xref="S3.SS1.p5.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p5.3.m3.1.1.3.5" xref="S3.SS1.p5.3.m3.1.1.3.5.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2">â„</ci><apply id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3"><times id="S3.SS1.p5.3.m3.1.1.3.1.cmml" xref="S3.SS1.p5.3.m3.1.1.3.1"></times><ci id="S3.SS1.p5.3.m3.1.1.3.2.cmml" xref="S3.SS1.p5.3.m3.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p5.3.m3.1.1.3.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.SS1.p5.3.m3.1.1.3.4.cmml" xref="S3.SS1.p5.3.m3.1.1.3.4">ğ‘œ</ci><ci id="S3.SS1.p5.3.m3.1.1.3.5.cmml" xref="S3.SS1.p5.3.m3.1.1.3.5">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">\mathcal{I}_{crop}</annotation></semantics></math>, we create a target image embedding</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="z^{\ast}_{j}={z}+\frac{q^{t}_{j}-q^{s}}{\|q^{t}_{j}-q^{s}\|_{2}}\;," display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><msubsup id="S3.E1.m1.2.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.2.2.2.cmml">z</mi><mi id="S3.E1.m1.2.2.1.1.2.3" xref="S3.E1.m1.2.2.1.1.2.3.cmml">j</mi><mo id="S3.E1.m1.2.2.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.2.2.3.cmml">âˆ—</mo></msubsup><mo id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.1.1.3" xref="S3.E1.m1.2.2.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.3.2" xref="S3.E1.m1.2.2.1.1.3.2.cmml">z</mi><mo id="S3.E1.m1.2.2.1.1.3.1" xref="S3.E1.m1.2.2.1.1.3.1.cmml">+</mo><mfrac id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><msubsup id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2.2" xref="S3.E1.m1.1.1.3.2.2.2.cmml">q</mi><mi id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml">j</mi><mi id="S3.E1.m1.1.1.3.2.2.3" xref="S3.E1.m1.1.1.3.2.2.3.cmml">t</mi></msubsup><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">âˆ’</mo><msup id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml">q</mi><mi id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml">s</mi></msup></mrow><msub id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><msubsup id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml">q</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.3.cmml">j</mi><mi id="S3.E1.m1.1.1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3.cmml">t</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msup id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.3.2.cmml">q</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.3.3.cmml">s</mi></msup></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">2</mn></msub></mfrac></mrow></mrow><mo lspace="0.280em" id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1"><eq id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"></eq><apply id="S3.E1.m1.2.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2">subscript</csymbol><apply id="S3.E1.m1.2.2.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2">superscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.2.2">ğ‘§</ci><ci id="S3.E1.m1.2.2.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.2.3">âˆ—</ci></apply><ci id="S3.E1.m1.2.2.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.3">ğ‘—</ci></apply><apply id="S3.E1.m1.2.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.3"><plus id="S3.E1.m1.2.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.3.1"></plus><ci id="S3.E1.m1.2.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.3.2">ğ‘§</ci><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><minus id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1"></minus><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2">subscript</csymbol><apply id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.2.1.cmml" xref="S3.E1.m1.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2.2">ğ‘</ci><ci id="S3.E1.m1.1.1.3.2.2.3.cmml" xref="S3.E1.m1.1.1.3.2.2.3">ğ‘¡</ci></apply><ci id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3">ğ‘—</ci></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3">superscript</csymbol><ci id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2">ğ‘</ci><ci id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3">ğ‘ </ci></apply></apply><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"></minus><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.2">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.E1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2.3">ğ‘—</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3.3">ğ‘ </ci></apply></apply></apply><cn type="integer" id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">z^{\ast}_{j}={z}+\frac{q^{t}_{j}-q^{s}}{\|q^{t}_{j}-q^{s}\|_{2}}\;,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p5.5" class="ltx_p">where <math id="S3.SS1.p5.4.m1.1" class="ltx_Math" alttext="{z}=\mathcal{V}(\mathcal{I}_{crop})" display="inline"><semantics id="S3.SS1.p5.4.m1.1a"><mrow id="S3.SS1.p5.4.m1.1.1" xref="S3.SS1.p5.4.m1.1.1.cmml"><mi id="S3.SS1.p5.4.m1.1.1.3" xref="S3.SS1.p5.4.m1.1.1.3.cmml">z</mi><mo id="S3.SS1.p5.4.m1.1.1.2" xref="S3.SS1.p5.4.m1.1.1.2.cmml">=</mo><mrow id="S3.SS1.p5.4.m1.1.1.1" xref="S3.SS1.p5.4.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.4.m1.1.1.1.3" xref="S3.SS1.p5.4.m1.1.1.1.3.cmml">ğ’±</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.4.m1.1.1.1.2" xref="S3.SS1.p5.4.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS1.p5.4.m1.1.1.1.1.1" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p5.4.m1.1.1.1.1.1.2" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p5.4.m1.1.1.1.1.1.1" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.4.m1.1.1.1.1.1.1.2" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.2.cmml">â„</mi><mrow id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.2" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.3" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1a" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.4" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1b" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.5" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.5.cmml">p</mi></mrow></msub><mo stretchy="false" id="S3.SS1.p5.4.m1.1.1.1.1.1.3" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m1.1b"><apply id="S3.SS1.p5.4.m1.1.1.cmml" xref="S3.SS1.p5.4.m1.1.1"><eq id="S3.SS1.p5.4.m1.1.1.2.cmml" xref="S3.SS1.p5.4.m1.1.1.2"></eq><ci id="S3.SS1.p5.4.m1.1.1.3.cmml" xref="S3.SS1.p5.4.m1.1.1.3">ğ‘§</ci><apply id="S3.SS1.p5.4.m1.1.1.1.cmml" xref="S3.SS1.p5.4.m1.1.1.1"><times id="S3.SS1.p5.4.m1.1.1.1.2.cmml" xref="S3.SS1.p5.4.m1.1.1.1.2"></times><ci id="S3.SS1.p5.4.m1.1.1.1.3.cmml" xref="S3.SS1.p5.4.m1.1.1.1.3">ğ’±</ci><apply id="S3.SS1.p5.4.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p5.4.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.2">â„</ci><apply id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3"><times id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.1"></times><ci id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.4.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.4">ğ‘œ</ci><ci id="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.5.cmml" xref="S3.SS1.p5.4.m1.1.1.1.1.1.1.3.5">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m1.1c">{z}=\mathcal{V}(\mathcal{I}_{crop})</annotation></semantics></math>. We then search for an augmentation <math id="S3.SS1.p5.5.m2.1" class="ltx_Math" alttext="\mathcal{A}_{j}\in\mathbb{R}^{H\times W\times C}" display="inline"><semantics id="S3.SS1.p5.5.m2.1a"><mrow id="S3.SS1.p5.5.m2.1.1" xref="S3.SS1.p5.5.m2.1.1.cmml"><msub id="S3.SS1.p5.5.m2.1.1.2" xref="S3.SS1.p5.5.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.5.m2.1.1.2.2" xref="S3.SS1.p5.5.m2.1.1.2.2.cmml">ğ’œ</mi><mi id="S3.SS1.p5.5.m2.1.1.2.3" xref="S3.SS1.p5.5.m2.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.p5.5.m2.1.1.1" xref="S3.SS1.p5.5.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p5.5.m2.1.1.3" xref="S3.SS1.p5.5.m2.1.1.3.cmml"><mi id="S3.SS1.p5.5.m2.1.1.3.2" xref="S3.SS1.p5.5.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p5.5.m2.1.1.3.3" xref="S3.SS1.p5.5.m2.1.1.3.3.cmml"><mi id="S3.SS1.p5.5.m2.1.1.3.3.2" xref="S3.SS1.p5.5.m2.1.1.3.3.2.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p5.5.m2.1.1.3.3.1" xref="S3.SS1.p5.5.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p5.5.m2.1.1.3.3.3" xref="S3.SS1.p5.5.m2.1.1.3.3.3.cmml">W</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p5.5.m2.1.1.3.3.1a" xref="S3.SS1.p5.5.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p5.5.m2.1.1.3.3.4" xref="S3.SS1.p5.5.m2.1.1.3.3.4.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.5.m2.1b"><apply id="S3.SS1.p5.5.m2.1.1.cmml" xref="S3.SS1.p5.5.m2.1.1"><in id="S3.SS1.p5.5.m2.1.1.1.cmml" xref="S3.SS1.p5.5.m2.1.1.1"></in><apply id="S3.SS1.p5.5.m2.1.1.2.cmml" xref="S3.SS1.p5.5.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.5.m2.1.1.2.1.cmml" xref="S3.SS1.p5.5.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p5.5.m2.1.1.2.2.cmml" xref="S3.SS1.p5.5.m2.1.1.2.2">ğ’œ</ci><ci id="S3.SS1.p5.5.m2.1.1.2.3.cmml" xref="S3.SS1.p5.5.m2.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS1.p5.5.m2.1.1.3.cmml" xref="S3.SS1.p5.5.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.5.m2.1.1.3.1.cmml" xref="S3.SS1.p5.5.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p5.5.m2.1.1.3.2.cmml" xref="S3.SS1.p5.5.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p5.5.m2.1.1.3.3.cmml" xref="S3.SS1.p5.5.m2.1.1.3.3"><times id="S3.SS1.p5.5.m2.1.1.3.3.1.cmml" xref="S3.SS1.p5.5.m2.1.1.3.3.1"></times><ci id="S3.SS1.p5.5.m2.1.1.3.3.2.cmml" xref="S3.SS1.p5.5.m2.1.1.3.3.2">ğ»</ci><ci id="S3.SS1.p5.5.m2.1.1.3.3.3.cmml" xref="S3.SS1.p5.5.m2.1.1.3.3.3">ğ‘Š</ci><ci id="S3.SS1.p5.5.m2.1.1.3.3.4.cmml" xref="S3.SS1.p5.5.m2.1.1.3.3.4">ğ¶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m2.1c">\mathcal{A}_{j}\in\mathbb{R}^{H\times W\times C}</annotation></semantics></math> such that</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle\bar{z}_{j}" display="inline"><semantics id="S3.E2.m1.1a"><msub id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mover accent="true" id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.2.2" xref="S3.E2.m1.1.1.2.2.cmml">z</mi><mo id="S3.E2.m1.1.1.2.1" xref="S3.E2.m1.1.1.2.1.cmml">Â¯</mo></mover><mi id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1">subscript</csymbol><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"><ci id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.2.1">Â¯</ci><ci id="S3.E2.m1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.2.2">ğ‘§</ci></apply><ci id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\bar{z}_{j}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E2.m2.1" class="ltx_Math" alttext="\displaystyle=\mathcal{V}^{b}(\mathcal{V}^{a}(\mathcal{I}_{crop})+\mathcal{A}_{j})" display="inline"><semantics id="S3.E2.m2.1a"><mrow id="S3.E2.m2.1.1" xref="S3.E2.m2.1.1.cmml"><mi id="S3.E2.m2.1.1.3" xref="S3.E2.m2.1.1.3.cmml"></mi><mo id="S3.E2.m2.1.1.2" xref="S3.E2.m2.1.1.2.cmml">=</mo><mrow id="S3.E2.m2.1.1.1" xref="S3.E2.m2.1.1.1.cmml"><msup id="S3.E2.m2.1.1.1.3" xref="S3.E2.m2.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m2.1.1.1.3.2" xref="S3.E2.m2.1.1.1.3.2.cmml">ğ’±</mi><mi id="S3.E2.m2.1.1.1.3.3" xref="S3.E2.m2.1.1.1.3.3.cmml">b</mi></msup><mo lspace="0em" rspace="0em" id="S3.E2.m2.1.1.1.2" xref="S3.E2.m2.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m2.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m2.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m2.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.cmml"><mrow id="S3.E2.m2.1.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.1.cmml"><msup id="S3.E2.m2.1.1.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m2.1.1.1.1.1.1.1.3.2" xref="S3.E2.m2.1.1.1.1.1.1.1.3.2.cmml">ğ’±</mi><mi id="S3.E2.m2.1.1.1.1.1.1.1.3.3" xref="S3.E2.m2.1.1.1.1.1.1.1.3.3.cmml">a</mi></msup><mo lspace="0em" rspace="0em" id="S3.E2.m2.1.1.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m2.1.1.1.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.2.cmml">â„</mi><mrow id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1a" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.4" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1b" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.5" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.5.cmml">p</mi></mrow></msub><mo stretchy="false" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m2.1.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.2.cmml">+</mo><msub id="S3.E2.m2.1.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m2.1.1.1.1.1.1.3.2" xref="S3.E2.m2.1.1.1.1.1.1.3.2.cmml">ğ’œ</mi><mi id="S3.E2.m2.1.1.1.1.1.1.3.3" xref="S3.E2.m2.1.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo stretchy="false" id="S3.E2.m2.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m2.1b"><apply id="S3.E2.m2.1.1.cmml" xref="S3.E2.m2.1.1"><eq id="S3.E2.m2.1.1.2.cmml" xref="S3.E2.m2.1.1.2"></eq><csymbol cd="latexml" id="S3.E2.m2.1.1.3.cmml" xref="S3.E2.m2.1.1.3">absent</csymbol><apply id="S3.E2.m2.1.1.1.cmml" xref="S3.E2.m2.1.1.1"><times id="S3.E2.m2.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.2"></times><apply id="S3.E2.m2.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.3.1.cmml" xref="S3.E2.m2.1.1.1.3">superscript</csymbol><ci id="S3.E2.m2.1.1.1.3.2.cmml" xref="S3.E2.m2.1.1.1.3.2">ğ’±</ci><ci id="S3.E2.m2.1.1.1.3.3.cmml" xref="S3.E2.m2.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E2.m2.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1"><plus id="S3.E2.m2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2"></plus><apply id="S3.E2.m2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1"><times id="S3.E2.m2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.2"></times><apply id="S3.E2.m2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E2.m2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.3.2">ğ’±</ci><ci id="S3.E2.m2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.2">â„</ci><apply id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.4">ğ‘œ</ci><ci id="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.5.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1.1.1.1.3.5">ğ‘</ci></apply></apply></apply><apply id="S3.E2.m2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3.2">ğ’œ</ci><ci id="S3.E2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3.3">ğ‘—</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m2.1c">\displaystyle=\mathcal{V}^{b}(\mathcal{V}^{a}(\mathcal{I}_{crop})+\mathcal{A}_{j})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p5.6" class="ltx_p">is as similar as possible to <math id="S3.SS1.p5.6.m1.1" class="ltx_Math" alttext="z^{\ast}_{j}" display="inline"><semantics id="S3.SS1.p5.6.m1.1a"><msubsup id="S3.SS1.p5.6.m1.1.1" xref="S3.SS1.p5.6.m1.1.1.cmml"><mi id="S3.SS1.p5.6.m1.1.1.2.2" xref="S3.SS1.p5.6.m1.1.1.2.2.cmml">z</mi><mi id="S3.SS1.p5.6.m1.1.1.3" xref="S3.SS1.p5.6.m1.1.1.3.cmml">j</mi><mo id="S3.SS1.p5.6.m1.1.1.2.3" xref="S3.SS1.p5.6.m1.1.1.2.3.cmml">âˆ—</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.6.m1.1b"><apply id="S3.SS1.p5.6.m1.1.1.cmml" xref="S3.SS1.p5.6.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m1.1.1.1.cmml" xref="S3.SS1.p5.6.m1.1.1">subscript</csymbol><apply id="S3.SS1.p5.6.m1.1.1.2.cmml" xref="S3.SS1.p5.6.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.6.m1.1.1.2.1.cmml" xref="S3.SS1.p5.6.m1.1.1">superscript</csymbol><ci id="S3.SS1.p5.6.m1.1.1.2.2.cmml" xref="S3.SS1.p5.6.m1.1.1.2.2">ğ‘§</ci><ci id="S3.SS1.p5.6.m1.1.1.2.3.cmml" xref="S3.SS1.p5.6.m1.1.1.2.3">âˆ—</ci></apply><ci id="S3.SS1.p5.6.m1.1.1.3.cmml" xref="S3.SS1.p5.6.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.6.m1.1c">z^{\ast}_{j}</annotation></semantics></math>, which we measure with the cosine similarity.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2301.05499/assets/figures/dataset.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="82" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Diverse Weather DatasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>:<span id="S3.F3.4.2.1" class="ltx_text ltx_font_medium"> Day-Clear acts as our source domain while the other weather condition are our target domains. In these domains, the objectsâ€™ appearance drastically changes from the Day-Clear scenario. As we do not utilize any target domain images, learning generalizable features on source images is crucial for the SDG task. </span></span></figcaption>
</figure>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">Ultimately, we estimate the augmentations <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="\{\mathcal{A}_{j}\}_{1}^{M}" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><msubsup id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mrow id="S3.SS1.p6.1.m1.1.1.1.1.1" xref="S3.SS1.p6.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.p6.1.m1.1.1.1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS1.p6.1.m1.1.1.1.1.1.1" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p6.1.m1.1.1.1.1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1.2.cmml">ğ’œ</mi><mi id="S3.SS1.p6.1.m1.1.1.1.1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.SS1.p6.1.m1.1.1.1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mn id="S3.SS1.p6.1.m1.1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.1.3.cmml">1</mn><mi id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">M</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1">superscript</csymbol><apply id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1">subscript</csymbol><set id="S3.SS1.p6.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.1"><apply id="S3.SS1.p6.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1.2">ğ’œ</ci><ci id="S3.SS1.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.1.1.1.1.3">ğ‘—</ci></apply></set><cn type="integer" id="S3.SS1.p6.1.m1.1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.1.3">1</cn></apply><ci id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3">ğ‘€</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">\{\mathcal{A}_{j}\}_{1}^{M}</annotation></semantics></math> through an optimization process using only source domain images. Specifically, we minimize the loss function</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="\mathcal{L}_{opt}=\sum_{\mathcal{I}_{crop}}\sum_{j}{\mathcal{D}(z^{\ast}_{j},\bar{z}_{j})+\|\bar{z}_{j}-z\|_{1}}\;," display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.5" xref="S3.E3.m1.1.1.1.1.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.5.2" xref="S3.E3.m1.1.1.1.1.5.2.cmml">â„’</mi><mrow id="S3.E3.m1.1.1.1.1.5.3" xref="S3.E3.m1.1.1.1.1.5.3.cmml"><mi id="S3.E3.m1.1.1.1.1.5.3.2" xref="S3.E3.m1.1.1.1.1.5.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.5.3.1" xref="S3.E3.m1.1.1.1.1.5.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.5.3.3" xref="S3.E3.m1.1.1.1.1.5.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.5.3.1a" xref="S3.E3.m1.1.1.1.1.5.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.5.3.4" xref="S3.E3.m1.1.1.1.1.5.3.4.cmml">t</mi></mrow></msub><mo rspace="0.111em" id="S3.E3.m1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.4.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mrow id="S3.E3.m1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.2.2.cmml"><munder id="S3.E3.m1.1.1.1.1.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><mo movablelimits="false" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.3.2" xref="S3.E3.m1.1.1.1.1.2.2.3.2.cmml">âˆ‘</mo><msub id="S3.E3.m1.1.1.1.1.2.2.3.3" xref="S3.E3.m1.1.1.1.1.2.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.2.2.3.3.2" xref="S3.E3.m1.1.1.1.1.2.2.3.3.2.cmml">â„</mi><mrow id="S3.E3.m1.1.1.1.1.2.2.3.3.3" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.3.3.3.2" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.3.3.3.1" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.2.2.3.3.3.3" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.3.3.3.1a" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.2.2.3.3.3.4" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.3.3.3.1b" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E3.m1.1.1.1.1.2.2.3.3.3.5" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.5.cmml">p</mi></mrow></msub></munder><mrow id="S3.E3.m1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.cmml"><munder id="S3.E3.m1.1.1.1.1.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.3.cmml"><mo movablelimits="false" id="S3.E3.m1.1.1.1.1.2.2.2.3.2" xref="S3.E3.m1.1.1.1.1.2.2.2.3.2.cmml">âˆ‘</mo><mi id="S3.E3.m1.1.1.1.1.2.2.2.3.3" xref="S3.E3.m1.1.1.1.1.2.2.2.3.3.cmml">j</mi></munder><mrow id="S3.E3.m1.1.1.1.1.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.2.2.2.2.4" xref="S3.E3.m1.1.1.1.1.2.2.2.2.4.cmml">ğ’Ÿ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml">(</mo><msubsup id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">z</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">j</mi><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">âˆ—</mo></msubsup><mo id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.4" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.2.cmml">z</mi><mo id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.1" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.1.cmml">Â¯</mo></mover><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.5" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.3.4" xref="S3.E3.m1.1.1.1.1.3.4.cmml">+</mo><msub id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3.cmml"><mrow id="S3.E3.m1.1.1.1.1.3.3.1.1" xref="S3.E3.m1.1.1.1.1.3.3.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.3.3.1.1.2" xref="S3.E3.m1.1.1.1.1.3.3.1.2.1.cmml">â€–</mo><mrow id="S3.E3.m1.1.1.1.1.3.3.1.1.1" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.cmml"><msub id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.cmml"><mi id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.2.cmml">z</mi><mo id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.1" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.1.cmml">Â¯</mo></mover><mi id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.3.cmml">j</mi></msub><mo id="S3.E3.m1.1.1.1.1.3.3.1.1.1.1" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E3.m1.1.1.1.1.3.3.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.3.cmml">z</mi></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.3.3.1.1.3" xref="S3.E3.m1.1.1.1.1.3.3.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E3.m1.1.1.1.1.3.3.3" xref="S3.E3.m1.1.1.1.1.3.3.3.cmml">1</mn></msub></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.4"></eq><apply id="S3.E3.m1.1.1.1.1.5.cmml" xref="S3.E3.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.5.1.cmml" xref="S3.E3.m1.1.1.1.1.5">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.5.2.cmml" xref="S3.E3.m1.1.1.1.1.5.2">â„’</ci><apply id="S3.E3.m1.1.1.1.1.5.3.cmml" xref="S3.E3.m1.1.1.1.1.5.3"><times id="S3.E3.m1.1.1.1.1.5.3.1.cmml" xref="S3.E3.m1.1.1.1.1.5.3.1"></times><ci id="S3.E3.m1.1.1.1.1.5.3.2.cmml" xref="S3.E3.m1.1.1.1.1.5.3.2">ğ‘œ</ci><ci id="S3.E3.m1.1.1.1.1.5.3.3.cmml" xref="S3.E3.m1.1.1.1.1.5.3.3">ğ‘</ci><ci id="S3.E3.m1.1.1.1.1.5.3.4.cmml" xref="S3.E3.m1.1.1.1.1.5.3.4">ğ‘¡</ci></apply></apply><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><plus id="S3.E3.m1.1.1.1.1.3.4.cmml" xref="S3.E3.m1.1.1.1.1.3.4"></plus><apply id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2"><apply id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3">subscript</csymbol><sum id="S3.E3.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.2"></sum><apply id="S3.E3.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.2">â„</ci><apply id="S3.E3.m1.1.1.1.1.2.2.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3"><times id="S3.E3.m1.1.1.1.1.2.2.3.3.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.1"></times><ci id="S3.E3.m1.1.1.1.1.2.2.3.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.2">ğ‘</ci><ci id="S3.E3.m1.1.1.1.1.2.2.3.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.3">ğ‘Ÿ</ci><ci id="S3.E3.m1.1.1.1.1.2.2.3.3.3.4.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.4">ğ‘œ</ci><ci id="S3.E3.m1.1.1.1.1.2.2.3.3.3.5.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.3.3.5">ğ‘</ci></apply></apply></apply><apply id="S3.E3.m1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2"><apply id="S3.E3.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3">subscript</csymbol><sum id="S3.E3.m1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3.2"></sum><ci id="S3.E3.m1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.3.3">ğ‘—</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2"><times id="S3.E3.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.3"></times><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.4.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.4">ğ’Ÿ</ci><interval closure="open" id="S3.E3.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘§</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.3">âˆ—</ci></apply><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2"><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.1">Â¯</ci><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.2.2">ğ‘§</ci></apply><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.2.2.2.3">ğ‘—</ci></apply></interval></apply></apply></apply><apply id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.3.3.1.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.3.3.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.2">norm</csymbol><apply id="S3.E3.m1.1.1.1.1.3.3.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1"><minus id="S3.E3.m1.1.1.1.1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.1"></minus><apply id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2">subscript</csymbol><apply id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2"><ci id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.1">Â¯</ci><ci id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.2.2">ğ‘§</ci></apply><ci id="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.2.3">ğ‘—</ci></apply><ci id="S3.E3.m1.1.1.1.1.3.3.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.1.1.1.3">ğ‘§</ci></apply></apply><cn type="integer" id="S3.E3.m1.1.1.1.1.3.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\mathcal{L}_{opt}=\sum_{\mathcal{I}_{crop}}\sum_{j}{\mathcal{D}(z^{\ast}_{j},\bar{z}_{j})+\|\bar{z}_{j}-z\|_{1}}\;,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p6.3" class="ltx_p">where</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\mathcal{D}(a,b)=1-\frac{a-b}{\|a-b\|_{2}}" display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.4" xref="S3.E4.m1.3.4.cmml"><mrow id="S3.E4.m1.3.4.2" xref="S3.E4.m1.3.4.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.3.4.2.2" xref="S3.E4.m1.3.4.2.2.cmml">ğ’Ÿ</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.4.2.1" xref="S3.E4.m1.3.4.2.1.cmml">â€‹</mo><mrow id="S3.E4.m1.3.4.2.3.2" xref="S3.E4.m1.3.4.2.3.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.4.2.3.2.1" xref="S3.E4.m1.3.4.2.3.1.cmml">(</mo><mi id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">a</mi><mo id="S3.E4.m1.3.4.2.3.2.2" xref="S3.E4.m1.3.4.2.3.1.cmml">,</mo><mi id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml">b</mi><mo stretchy="false" id="S3.E4.m1.3.4.2.3.2.3" xref="S3.E4.m1.3.4.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.4.1" xref="S3.E4.m1.3.4.1.cmml">=</mo><mrow id="S3.E4.m1.3.4.3" xref="S3.E4.m1.3.4.3.cmml"><mn id="S3.E4.m1.3.4.3.2" xref="S3.E4.m1.3.4.3.2.cmml">1</mn><mo id="S3.E4.m1.3.4.3.1" xref="S3.E4.m1.3.4.3.1.cmml">âˆ’</mo><mfrac id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml">a</mi><mo id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml">âˆ’</mo><mi id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml">b</mi></mrow><msub id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">a</mi><mo id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">b</mi></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml">2</mn></msub></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.4.cmml" xref="S3.E4.m1.3.4"><eq id="S3.E4.m1.3.4.1.cmml" xref="S3.E4.m1.3.4.1"></eq><apply id="S3.E4.m1.3.4.2.cmml" xref="S3.E4.m1.3.4.2"><times id="S3.E4.m1.3.4.2.1.cmml" xref="S3.E4.m1.3.4.2.1"></times><ci id="S3.E4.m1.3.4.2.2.cmml" xref="S3.E4.m1.3.4.2.2">ğ’Ÿ</ci><interval closure="open" id="S3.E4.m1.3.4.2.3.1.cmml" xref="S3.E4.m1.3.4.2.3.2"><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">ğ‘</ci><ci id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">ğ‘</ci></interval></apply><apply id="S3.E4.m1.3.4.3.cmml" xref="S3.E4.m1.3.4.3"><minus id="S3.E4.m1.3.4.3.1.cmml" xref="S3.E4.m1.3.4.3.1"></minus><cn type="integer" id="S3.E4.m1.3.4.3.2.cmml" xref="S3.E4.m1.3.4.3.2">1</cn><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><divide id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1"></divide><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><minus id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"></minus><ci id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2">ğ‘</ci><ci id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3">ğ‘</ci></apply><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><minus id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"></minus><ci id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply><cn type="integer" id="S3.E4.m1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\mathcal{D}(a,b)=1-\frac{a-b}{\|a-b\|_{2}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p6.2" class="ltx_p">is the cosine distance. The loss also includes an <math id="S3.SS1.p6.2.m1.1" class="ltx_Math" alttext="l_{1}" display="inline"><semantics id="S3.SS1.p6.2.m1.1a"><msub id="S3.SS1.p6.2.m1.1.1" xref="S3.SS1.p6.2.m1.1.1.cmml"><mi id="S3.SS1.p6.2.m1.1.1.2" xref="S3.SS1.p6.2.m1.1.1.2.cmml">l</mi><mn id="S3.SS1.p6.2.m1.1.1.3" xref="S3.SS1.p6.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m1.1b"><apply id="S3.SS1.p6.2.m1.1.1.cmml" xref="S3.SS1.p6.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m1.1.1.1.cmml" xref="S3.SS1.p6.2.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.2.m1.1.1.2.cmml" xref="S3.SS1.p6.2.m1.1.1.2">ğ‘™</ci><cn type="integer" id="S3.SS1.p6.2.m1.1.1.3.cmml" xref="S3.SS1.p6.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m1.1c">l_{1}</annotation></semantics></math> regularizer that prevents the embeddings from deviating too far from their initial values, so as to preserve the image content.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p">As the objective is to estimate the meaningful feature augmentation while preserving the original CLIP pre-training, we keep the image crop size the same as the original CLIP training. Note that the optimization of the augmentations is done once in an offline stage, and we then use the resulting augmentations to train our detector.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Architecture</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">Let us now describe our detector architecture. As shown in the right portion ofÂ <a href="#S3.F2" title="In 3 Method â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>, it follows a standard FasterRCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> structure but departs from it in two ways. First, to exploit the augmentations optimized as discussed in the previous section, we initialize the blocks before and after the ROI align one with the corresponding <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{V}^{a}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msup id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">ğ’±</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ’±</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{V}^{a}</annotation></semantics></math> and <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{V}^{b}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">ğ’±</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ’±</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathcal{V}^{b}</annotation></semantics></math> modules of the ResNet-based trained CLIP model. Second, to further leverage the vision-language model, we incorporate a text-based classifier in our modelâ€™s head. Note that, in contrast to OVDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> where a text-based classifier is used to handle novel categories, we employ it to keep the image features close to the pre-trained joint embedding space.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.9" class="ltx_p">Specifically, we define textual prompts that represent the individual categories we seek to detect, and extract corresponding embeddings <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{Q}\in\mathbb{R}^{(K+1)\times D_{clip}}" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.2" xref="S3.SS2.p2.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.1.m1.1.2.2" xref="S3.SS2.p2.1.m1.1.2.2.cmml">ğ’¬</mi><mo id="S3.SS2.p2.1.m1.1.2.1" xref="S3.SS2.p2.1.m1.1.2.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.1.m1.1.2.3" xref="S3.SS2.p2.1.m1.1.2.3.cmml"><mi id="S3.SS2.p2.1.m1.1.2.3.2" xref="S3.SS2.p2.1.m1.1.2.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml"><mrow id="S3.SS2.p2.1.m1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.1.m1.1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p2.1.m1.1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml">K</mi><mo id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo rspace="0.055em" stretchy="false" id="S3.SS2.p2.1.m1.1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S3.SS2.p2.1.m1.1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.1.2.cmml">Ã—</mo><msub id="S3.SS2.p2.1.m1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.1.3.2.cmml">D</mi><mrow id="S3.SS2.p2.1.m1.1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.1.3.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.3.3.2" xref="S3.SS2.p2.1.m1.1.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.1.3.3.1" xref="S3.SS2.p2.1.m1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.1.m1.1.1.1.3.3.3" xref="S3.SS2.p2.1.m1.1.1.1.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.1.3.3.1a" xref="S3.SS2.p2.1.m1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.1.m1.1.1.1.3.3.4" xref="S3.SS2.p2.1.m1.1.1.1.3.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.m1.1.1.1.3.3.1b" xref="S3.SS2.p2.1.m1.1.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.1.m1.1.1.1.3.3.5" xref="S3.SS2.p2.1.m1.1.1.1.3.3.5.cmml">p</mi></mrow></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.2"><in id="S3.SS2.p2.1.m1.1.2.1.cmml" xref="S3.SS2.p2.1.m1.1.2.1"></in><ci id="S3.SS2.p2.1.m1.1.2.2.cmml" xref="S3.SS2.p2.1.m1.1.2.2">ğ’¬</ci><apply id="S3.SS2.p2.1.m1.1.2.3.cmml" xref="S3.SS2.p2.1.m1.1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.2.3.1.cmml" xref="S3.SS2.p2.1.m1.1.2.3">superscript</csymbol><ci id="S3.SS2.p2.1.m1.1.2.3.2.cmml" xref="S3.SS2.p2.1.m1.1.2.3.2">â„</ci><apply id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1"><times id="S3.SS2.p2.1.m1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.2"></times><apply id="S3.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1"><plus id="S3.SS2.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.1"></plus><ci id="S3.SS2.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.2">ğ¾</ci><cn type="integer" id="S3.SS2.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p2.1.m1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.2">ğ·</ci><apply id="S3.SS2.p2.1.m1.1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.3"><times id="S3.SS2.p2.1.m1.1.1.1.3.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.3.1"></times><ci id="S3.SS2.p2.1.m1.1.1.1.3.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.3.2">ğ‘</ci><ci id="S3.SS2.p2.1.m1.1.1.1.3.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.3.3">ğ‘™</ci><ci id="S3.SS2.p2.1.m1.1.1.1.3.3.4.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.3.4">ğ‘–</ci><ci id="S3.SS2.p2.1.m1.1.1.1.3.3.5.cmml" xref="S3.SS2.p2.1.m1.1.1.1.3.3.5">ğ‘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathcal{Q}\in\mathbb{R}^{(K+1)\times D_{clip}}</annotation></semantics></math>, for <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">K</annotation></semantics></math> categories and the background class, using the text encoder <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\mathcal{T}</annotation></semantics></math>. For a candidate image region <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">r</annotation></semantics></math> proposed by the Region Proposal Network(RPN)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, we then compute the cosine similarities between the text embeddings <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">\mathcal{Q}</annotation></semantics></math> and the features <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{F}_{r}\in\mathbb{R}^{D_{clip}}" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mrow id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><msub id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.6.m6.1.1.2.2" xref="S3.SS2.p2.6.m6.1.1.2.2.cmml">â„±</mi><mi id="S3.SS2.p2.6.m6.1.1.2.3" xref="S3.SS2.p2.6.m6.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS2.p2.6.m6.1.1.1" xref="S3.SS2.p2.6.m6.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml"><mi id="S3.SS2.p2.6.m6.1.1.3.2" xref="S3.SS2.p2.6.m6.1.1.3.2.cmml">â„</mi><msub id="S3.SS2.p2.6.m6.1.1.3.3" xref="S3.SS2.p2.6.m6.1.1.3.3.cmml"><mi id="S3.SS2.p2.6.m6.1.1.3.3.2" xref="S3.SS2.p2.6.m6.1.1.3.3.2.cmml">D</mi><mrow id="S3.SS2.p2.6.m6.1.1.3.3.3" xref="S3.SS2.p2.6.m6.1.1.3.3.3.cmml"><mi id="S3.SS2.p2.6.m6.1.1.3.3.3.2" xref="S3.SS2.p2.6.m6.1.1.3.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.6.m6.1.1.3.3.3.1" xref="S3.SS2.p2.6.m6.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.6.m6.1.1.3.3.3.3" xref="S3.SS2.p2.6.m6.1.1.3.3.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.6.m6.1.1.3.3.3.1a" xref="S3.SS2.p2.6.m6.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.6.m6.1.1.3.3.3.4" xref="S3.SS2.p2.6.m6.1.1.3.3.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.6.m6.1.1.3.3.3.1b" xref="S3.SS2.p2.6.m6.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.6.m6.1.1.3.3.3.5" xref="S3.SS2.p2.6.m6.1.1.3.3.3.5.cmml">p</mi></mrow></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><in id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1"></in><apply id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.2.1.cmml" xref="S3.SS2.p2.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2.2">â„±</ci><ci id="S3.SS2.p2.6.m6.1.1.2.3.cmml" xref="S3.SS2.p2.6.m6.1.1.2.3">ğ‘Ÿ</ci></apply><apply id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.3.1.cmml" xref="S3.SS2.p2.6.m6.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.3.2.cmml" xref="S3.SS2.p2.6.m6.1.1.3.2">â„</ci><apply id="S3.SS2.p2.6.m6.1.1.3.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.3.3.1.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.3.3.2.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.2">ğ·</ci><apply id="S3.SS2.p2.6.m6.1.1.3.3.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3"><times id="S3.SS2.p2.6.m6.1.1.3.3.3.1.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3.1"></times><ci id="S3.SS2.p2.6.m6.1.1.3.3.3.2.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3.2">ğ‘</ci><ci id="S3.SS2.p2.6.m6.1.1.3.3.3.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3.3">ğ‘™</ci><ci id="S3.SS2.p2.6.m6.1.1.3.3.3.4.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3.4">ğ‘–</ci><ci id="S3.SS2.p2.6.m6.1.1.3.3.3.5.cmml" xref="S3.SS2.p2.6.m6.1.1.3.3.3.5">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">\mathcal{F}_{r}\in\mathbb{R}^{D_{clip}}</annotation></semantics></math> obtained by projection to the embedding space using <math id="S3.SS2.p2.7.m7.1" class="ltx_Math" alttext="\mathcal{V}^{b}" display="inline"><semantics id="S3.SS2.p2.7.m7.1a"><msup id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.7.m7.1.1.2" xref="S3.SS2.p2.7.m7.1.1.2.cmml">ğ’±</mi><mi id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2">ğ’±</ci><ci id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">\mathcal{V}^{b}</annotation></semantics></math> after ROI-AlignÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and the text embeddings <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><ci id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">\mathcal{Q}</annotation></semantics></math>. These cosine similarities, <math id="S3.SS2.p2.9.m9.2" class="ltx_Math" alttext="sim(\mathcal{F}_{r},\mathcal{Q})\in\mathbb{R}^{K+1}" display="inline"><semantics id="S3.SS2.p2.9.m9.2a"><mrow id="S3.SS2.p2.9.m9.2.2" xref="S3.SS2.p2.9.m9.2.2.cmml"><mrow id="S3.SS2.p2.9.m9.2.2.1" xref="S3.SS2.p2.9.m9.2.2.1.cmml"><mi id="S3.SS2.p2.9.m9.2.2.1.3" xref="S3.SS2.p2.9.m9.2.2.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.2.2.1.2" xref="S3.SS2.p2.9.m9.2.2.1.2.cmml">â€‹</mo><mi id="S3.SS2.p2.9.m9.2.2.1.4" xref="S3.SS2.p2.9.m9.2.2.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.2.2.1.2a" xref="S3.SS2.p2.9.m9.2.2.1.2.cmml">â€‹</mo><mi id="S3.SS2.p2.9.m9.2.2.1.5" xref="S3.SS2.p2.9.m9.2.2.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.9.m9.2.2.1.2b" xref="S3.SS2.p2.9.m9.2.2.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p2.9.m9.2.2.1.1.1" xref="S3.SS2.p2.9.m9.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.9.m9.2.2.1.1.1.2" xref="S3.SS2.p2.9.m9.2.2.1.1.2.cmml">(</mo><msub id="S3.SS2.p2.9.m9.2.2.1.1.1.1" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.9.m9.2.2.1.1.1.1.2" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1.2.cmml">â„±</mi><mi id="S3.SS2.p2.9.m9.2.2.1.1.1.1.3" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1.3.cmml">r</mi></msub><mo id="S3.SS2.p2.9.m9.2.2.1.1.1.3" xref="S3.SS2.p2.9.m9.2.2.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml">ğ’¬</mi><mo stretchy="false" id="S3.SS2.p2.9.m9.2.2.1.1.1.4" xref="S3.SS2.p2.9.m9.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p2.9.m9.2.2.2" xref="S3.SS2.p2.9.m9.2.2.2.cmml">âˆˆ</mo><msup id="S3.SS2.p2.9.m9.2.2.3" xref="S3.SS2.p2.9.m9.2.2.3.cmml"><mi id="S3.SS2.p2.9.m9.2.2.3.2" xref="S3.SS2.p2.9.m9.2.2.3.2.cmml">â„</mi><mrow id="S3.SS2.p2.9.m9.2.2.3.3" xref="S3.SS2.p2.9.m9.2.2.3.3.cmml"><mi id="S3.SS2.p2.9.m9.2.2.3.3.2" xref="S3.SS2.p2.9.m9.2.2.3.3.2.cmml">K</mi><mo id="S3.SS2.p2.9.m9.2.2.3.3.1" xref="S3.SS2.p2.9.m9.2.2.3.3.1.cmml">+</mo><mn id="S3.SS2.p2.9.m9.2.2.3.3.3" xref="S3.SS2.p2.9.m9.2.2.3.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.2b"><apply id="S3.SS2.p2.9.m9.2.2.cmml" xref="S3.SS2.p2.9.m9.2.2"><in id="S3.SS2.p2.9.m9.2.2.2.cmml" xref="S3.SS2.p2.9.m9.2.2.2"></in><apply id="S3.SS2.p2.9.m9.2.2.1.cmml" xref="S3.SS2.p2.9.m9.2.2.1"><times id="S3.SS2.p2.9.m9.2.2.1.2.cmml" xref="S3.SS2.p2.9.m9.2.2.1.2"></times><ci id="S3.SS2.p2.9.m9.2.2.1.3.cmml" xref="S3.SS2.p2.9.m9.2.2.1.3">ğ‘ </ci><ci id="S3.SS2.p2.9.m9.2.2.1.4.cmml" xref="S3.SS2.p2.9.m9.2.2.1.4">ğ‘–</ci><ci id="S3.SS2.p2.9.m9.2.2.1.5.cmml" xref="S3.SS2.p2.9.m9.2.2.1.5">ğ‘š</ci><interval closure="open" id="S3.SS2.p2.9.m9.2.2.1.1.2.cmml" xref="S3.SS2.p2.9.m9.2.2.1.1.1"><apply id="S3.SS2.p2.9.m9.2.2.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1.2">â„±</ci><ci id="S3.SS2.p2.9.m9.2.2.1.1.1.1.3.cmml" xref="S3.SS2.p2.9.m9.2.2.1.1.1.1.3">ğ‘Ÿ</ci></apply><ci id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">ğ’¬</ci></interval></apply><apply id="S3.SS2.p2.9.m9.2.2.3.cmml" xref="S3.SS2.p2.9.m9.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.2.2.3.1.cmml" xref="S3.SS2.p2.9.m9.2.2.3">superscript</csymbol><ci id="S3.SS2.p2.9.m9.2.2.3.2.cmml" xref="S3.SS2.p2.9.m9.2.2.3.2">â„</ci><apply id="S3.SS2.p2.9.m9.2.2.3.3.cmml" xref="S3.SS2.p2.9.m9.2.2.3.3"><plus id="S3.SS2.p2.9.m9.2.2.3.3.1.cmml" xref="S3.SS2.p2.9.m9.2.2.3.3.1"></plus><ci id="S3.SS2.p2.9.m9.2.2.3.3.2.cmml" xref="S3.SS2.p2.9.m9.2.2.3.3.2">ğ¾</ci><cn type="integer" id="S3.SS2.p2.9.m9.2.2.3.3.3.cmml" xref="S3.SS2.p2.9.m9.2.2.3.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.2c">sim(\mathcal{F}_{r},\mathcal{Q})\in\mathbb{R}^{K+1}</annotation></semantics></math>, act as logits to the softmax based cross-entropy loss</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.5" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}=\sum_{r}{\mathcal{L}_{CE}\left(\frac{e^{sim(\mathcal{F}_{r},\mathcal{Q}_{k})}}{\sum_{k=0}^{K}{e^{sim(\mathcal{F}_{r},\mathcal{Q}_{k})}}}\right)}\;." display="block"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5.5.1" xref="S3.E5.m1.5.5.1.1.cmml"><mrow id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml"><msub id="S3.E5.m1.5.5.1.1.2" xref="S3.E5.m1.5.5.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.5.5.1.1.2.2" xref="S3.E5.m1.5.5.1.1.2.2.cmml">â„’</mi><mrow id="S3.E5.m1.5.5.1.1.2.3" xref="S3.E5.m1.5.5.1.1.2.3.cmml"><mi id="S3.E5.m1.5.5.1.1.2.3.2" xref="S3.E5.m1.5.5.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3.1" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.1.1.2.3.3" xref="S3.E5.m1.5.5.1.1.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3.1a" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.1.1.2.3.4" xref="S3.E5.m1.5.5.1.1.2.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3.1b" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.1.1.2.3.5" xref="S3.E5.m1.5.5.1.1.2.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.3.1c" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.1.1.2.3.6" xref="S3.E5.m1.5.5.1.1.2.3.6.cmml">t</mi></mrow></msub><mo rspace="0.111em" id="S3.E5.m1.5.5.1.1.1" xref="S3.E5.m1.5.5.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.5.5.1.1.3" xref="S3.E5.m1.5.5.1.1.3.cmml"><munder id="S3.E5.m1.5.5.1.1.3.1" xref="S3.E5.m1.5.5.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E5.m1.5.5.1.1.3.1.2" xref="S3.E5.m1.5.5.1.1.3.1.2.cmml">âˆ‘</mo><mi id="S3.E5.m1.5.5.1.1.3.1.3" xref="S3.E5.m1.5.5.1.1.3.1.3.cmml">r</mi></munder><mrow id="S3.E5.m1.5.5.1.1.3.2" xref="S3.E5.m1.5.5.1.1.3.2.cmml"><msub id="S3.E5.m1.5.5.1.1.3.2.2" xref="S3.E5.m1.5.5.1.1.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.5.5.1.1.3.2.2.2" xref="S3.E5.m1.5.5.1.1.3.2.2.2.cmml">â„’</mi><mrow id="S3.E5.m1.5.5.1.1.3.2.2.3" xref="S3.E5.m1.5.5.1.1.3.2.2.3.cmml"><mi id="S3.E5.m1.5.5.1.1.3.2.2.3.2" xref="S3.E5.m1.5.5.1.1.3.2.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.3.2.2.3.1" xref="S3.E5.m1.5.5.1.1.3.2.2.3.1.cmml">â€‹</mo><mi id="S3.E5.m1.5.5.1.1.3.2.2.3.3" xref="S3.E5.m1.5.5.1.1.3.2.2.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.3.2.1" xref="S3.E5.m1.5.5.1.1.3.2.1.cmml">â€‹</mo><mrow id="S3.E5.m1.5.5.1.1.3.2.3.2" xref="S3.E5.m1.4.4.cmml"><mo id="S3.E5.m1.5.5.1.1.3.2.3.2.1" xref="S3.E5.m1.4.4.cmml">(</mo><mfrac id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml"><msup id="S3.E5.m1.2.2.2" xref="S3.E5.m1.2.2.2.cmml"><mi id="S3.E5.m1.2.2.2.4" xref="S3.E5.m1.2.2.2.4.cmml">e</mi><mrow id="S3.E5.m1.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.cmml"><mi id="S3.E5.m1.2.2.2.2.2.4" xref="S3.E5.m1.2.2.2.2.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.2.3.cmml">â€‹</mo><mi id="S3.E5.m1.2.2.2.2.2.5" xref="S3.E5.m1.2.2.2.2.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2.3a" xref="S3.E5.m1.2.2.2.2.2.3.cmml">â€‹</mo><mi id="S3.E5.m1.2.2.2.2.2.6" xref="S3.E5.m1.2.2.2.2.2.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2.3b" xref="S3.E5.m1.2.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E5.m1.2.2.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.2.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml">â„±</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml">r</mi></msub><mo id="S3.E5.m1.2.2.2.2.2.2.2.4" xref="S3.E5.m1.2.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.2.2.2.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.2.2.2.2.2.2.2" xref="S3.E5.m1.2.2.2.2.2.2.2.2.2.cmml">ğ’¬</mi><mi id="S3.E5.m1.2.2.2.2.2.2.2.2.3" xref="S3.E5.m1.2.2.2.2.2.2.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S3.E5.m1.2.2.2.2.2.2.2.5" xref="S3.E5.m1.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></msup><mrow id="S3.E5.m1.4.4.4" xref="S3.E5.m1.4.4.4.cmml"><msubsup id="S3.E5.m1.4.4.4.3" xref="S3.E5.m1.4.4.4.3.cmml"><mo id="S3.E5.m1.4.4.4.3.2.2" xref="S3.E5.m1.4.4.4.3.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.4.4.4.3.2.3" xref="S3.E5.m1.4.4.4.3.2.3.cmml"><mi id="S3.E5.m1.4.4.4.3.2.3.2" xref="S3.E5.m1.4.4.4.3.2.3.2.cmml">k</mi><mo id="S3.E5.m1.4.4.4.3.2.3.1" xref="S3.E5.m1.4.4.4.3.2.3.1.cmml">=</mo><mn id="S3.E5.m1.4.4.4.3.2.3.3" xref="S3.E5.m1.4.4.4.3.2.3.3.cmml">0</mn></mrow><mi id="S3.E5.m1.4.4.4.3.3" xref="S3.E5.m1.4.4.4.3.3.cmml">K</mi></msubsup><msup id="S3.E5.m1.4.4.4.4" xref="S3.E5.m1.4.4.4.4.cmml"><mi id="S3.E5.m1.4.4.4.4.2" xref="S3.E5.m1.4.4.4.4.2.cmml">e</mi><mrow id="S3.E5.m1.4.4.4.2.2" xref="S3.E5.m1.4.4.4.2.2.cmml"><mi id="S3.E5.m1.4.4.4.2.2.4" xref="S3.E5.m1.4.4.4.2.2.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.4.2.2.3" xref="S3.E5.m1.4.4.4.2.2.3.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.4.2.2.5" xref="S3.E5.m1.4.4.4.2.2.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.4.2.2.3a" xref="S3.E5.m1.4.4.4.2.2.3.cmml">â€‹</mo><mi id="S3.E5.m1.4.4.4.2.2.6" xref="S3.E5.m1.4.4.4.2.2.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.4.2.2.3b" xref="S3.E5.m1.4.4.4.2.2.3.cmml">â€‹</mo><mrow id="S3.E5.m1.4.4.4.2.2.2.2" xref="S3.E5.m1.4.4.4.2.2.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.4.2.2.2.2.3" xref="S3.E5.m1.4.4.4.2.2.2.3.cmml">(</mo><msub id="S3.E5.m1.3.3.3.1.1.1.1.1" xref="S3.E5.m1.3.3.3.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.3.1.1.1.1.1.2" xref="S3.E5.m1.3.3.3.1.1.1.1.1.2.cmml">â„±</mi><mi id="S3.E5.m1.3.3.3.1.1.1.1.1.3" xref="S3.E5.m1.3.3.3.1.1.1.1.1.3.cmml">r</mi></msub><mo id="S3.E5.m1.4.4.4.2.2.2.2.4" xref="S3.E5.m1.4.4.4.2.2.2.3.cmml">,</mo><msub id="S3.E5.m1.4.4.4.2.2.2.2.2" xref="S3.E5.m1.4.4.4.2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.4.4.4.2.2.2.2.2.2" xref="S3.E5.m1.4.4.4.2.2.2.2.2.2.cmml">ğ’¬</mi><mi id="S3.E5.m1.4.4.4.2.2.2.2.2.3" xref="S3.E5.m1.4.4.4.2.2.2.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S3.E5.m1.4.4.4.2.2.2.2.5" xref="S3.E5.m1.4.4.4.2.2.2.3.cmml">)</mo></mrow></mrow></msup></mrow></mfrac><mo id="S3.E5.m1.5.5.1.1.3.2.3.2.2" xref="S3.E5.m1.4.4.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E5.m1.5.5.1.2" xref="S3.E5.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.5b"><apply id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1"><eq id="S3.E5.m1.5.5.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1"></eq><apply id="S3.E5.m1.5.5.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.2.1.cmml" xref="S3.E5.m1.5.5.1.1.2">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.2.2.cmml" xref="S3.E5.m1.5.5.1.1.2.2">â„’</ci><apply id="S3.E5.m1.5.5.1.1.2.3.cmml" xref="S3.E5.m1.5.5.1.1.2.3"><times id="S3.E5.m1.5.5.1.1.2.3.1.cmml" xref="S3.E5.m1.5.5.1.1.2.3.1"></times><ci id="S3.E5.m1.5.5.1.1.2.3.2.cmml" xref="S3.E5.m1.5.5.1.1.2.3.2">ğ‘</ci><ci id="S3.E5.m1.5.5.1.1.2.3.3.cmml" xref="S3.E5.m1.5.5.1.1.2.3.3">ğ‘™</ci><ci id="S3.E5.m1.5.5.1.1.2.3.4.cmml" xref="S3.E5.m1.5.5.1.1.2.3.4">ğ‘–</ci><ci id="S3.E5.m1.5.5.1.1.2.3.5.cmml" xref="S3.E5.m1.5.5.1.1.2.3.5">ğ‘</ci><ci id="S3.E5.m1.5.5.1.1.2.3.6.cmml" xref="S3.E5.m1.5.5.1.1.2.3.6">ğ‘¡</ci></apply></apply><apply id="S3.E5.m1.5.5.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.3"><apply id="S3.E5.m1.5.5.1.1.3.1.cmml" xref="S3.E5.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.1.1.cmml" xref="S3.E5.m1.5.5.1.1.3.1">subscript</csymbol><sum id="S3.E5.m1.5.5.1.1.3.1.2.cmml" xref="S3.E5.m1.5.5.1.1.3.1.2"></sum><ci id="S3.E5.m1.5.5.1.1.3.1.3.cmml" xref="S3.E5.m1.5.5.1.1.3.1.3">ğ‘Ÿ</ci></apply><apply id="S3.E5.m1.5.5.1.1.3.2.cmml" xref="S3.E5.m1.5.5.1.1.3.2"><times id="S3.E5.m1.5.5.1.1.3.2.1.cmml" xref="S3.E5.m1.5.5.1.1.3.2.1"></times><apply id="S3.E5.m1.5.5.1.1.3.2.2.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.2.2.1.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.3.2.2.2.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2.2">â„’</ci><apply id="S3.E5.m1.5.5.1.1.3.2.2.3.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2.3"><times id="S3.E5.m1.5.5.1.1.3.2.2.3.1.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2.3.1"></times><ci id="S3.E5.m1.5.5.1.1.3.2.2.3.2.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2.3.2">ğ¶</ci><ci id="S3.E5.m1.5.5.1.1.3.2.2.3.3.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2.3.3">ğ¸</ci></apply></apply><apply id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.5.5.1.1.3.2.3.2"><divide id="S3.E5.m1.4.4.5.cmml" xref="S3.E5.m1.5.5.1.1.3.2.3.2"></divide><apply id="S3.E5.m1.2.2.2.cmml" xref="S3.E5.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2">superscript</csymbol><ci id="S3.E5.m1.2.2.2.4.cmml" xref="S3.E5.m1.2.2.2.4">ğ‘’</ci><apply id="S3.E5.m1.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2.2"><times id="S3.E5.m1.2.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.2.3"></times><ci id="S3.E5.m1.2.2.2.2.2.4.cmml" xref="S3.E5.m1.2.2.2.2.2.4">ğ‘ </ci><ci id="S3.E5.m1.2.2.2.2.2.5.cmml" xref="S3.E5.m1.2.2.2.2.2.5">ğ‘–</ci><ci id="S3.E5.m1.2.2.2.2.2.6.cmml" xref="S3.E5.m1.2.2.2.2.2.6">ğ‘š</ci><interval closure="open" id="S3.E5.m1.2.2.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.2.2.2"><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2">â„±</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3">ğ‘Ÿ</ci></apply><apply id="S3.E5.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2.2.2.2.2.2">ğ’¬</ci><ci id="S3.E5.m1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.2.2.2.2.2.3">ğ‘˜</ci></apply></interval></apply></apply><apply id="S3.E5.m1.4.4.4.cmml" xref="S3.E5.m1.4.4.4"><apply id="S3.E5.m1.4.4.4.3.cmml" xref="S3.E5.m1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.4.3.1.cmml" xref="S3.E5.m1.4.4.4.3">superscript</csymbol><apply id="S3.E5.m1.4.4.4.3.2.cmml" xref="S3.E5.m1.4.4.4.3"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.4.3.2.1.cmml" xref="S3.E5.m1.4.4.4.3">subscript</csymbol><sum id="S3.E5.m1.4.4.4.3.2.2.cmml" xref="S3.E5.m1.4.4.4.3.2.2"></sum><apply id="S3.E5.m1.4.4.4.3.2.3.cmml" xref="S3.E5.m1.4.4.4.3.2.3"><eq id="S3.E5.m1.4.4.4.3.2.3.1.cmml" xref="S3.E5.m1.4.4.4.3.2.3.1"></eq><ci id="S3.E5.m1.4.4.4.3.2.3.2.cmml" xref="S3.E5.m1.4.4.4.3.2.3.2">ğ‘˜</ci><cn type="integer" id="S3.E5.m1.4.4.4.3.2.3.3.cmml" xref="S3.E5.m1.4.4.4.3.2.3.3">0</cn></apply></apply><ci id="S3.E5.m1.4.4.4.3.3.cmml" xref="S3.E5.m1.4.4.4.3.3">ğ¾</ci></apply><apply id="S3.E5.m1.4.4.4.4.cmml" xref="S3.E5.m1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.4.4.1.cmml" xref="S3.E5.m1.4.4.4.4">superscript</csymbol><ci id="S3.E5.m1.4.4.4.4.2.cmml" xref="S3.E5.m1.4.4.4.4.2">ğ‘’</ci><apply id="S3.E5.m1.4.4.4.2.2.cmml" xref="S3.E5.m1.4.4.4.2.2"><times id="S3.E5.m1.4.4.4.2.2.3.cmml" xref="S3.E5.m1.4.4.4.2.2.3"></times><ci id="S3.E5.m1.4.4.4.2.2.4.cmml" xref="S3.E5.m1.4.4.4.2.2.4">ğ‘ </ci><ci id="S3.E5.m1.4.4.4.2.2.5.cmml" xref="S3.E5.m1.4.4.4.2.2.5">ğ‘–</ci><ci id="S3.E5.m1.4.4.4.2.2.6.cmml" xref="S3.E5.m1.4.4.4.2.2.6">ğ‘š</ci><interval closure="open" id="S3.E5.m1.4.4.4.2.2.2.3.cmml" xref="S3.E5.m1.4.4.4.2.2.2.2"><apply id="S3.E5.m1.3.3.3.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.3.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.3.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.3.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.3.1.1.1.1.1.2">â„±</ci><ci id="S3.E5.m1.3.3.3.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.3.1.1.1.1.1.3">ğ‘Ÿ</ci></apply><apply id="S3.E5.m1.4.4.4.2.2.2.2.2.cmml" xref="S3.E5.m1.4.4.4.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.4.2.2.2.2.2.1.cmml" xref="S3.E5.m1.4.4.4.2.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.4.4.4.2.2.2.2.2.2.cmml" xref="S3.E5.m1.4.4.4.2.2.2.2.2.2">ğ’¬</ci><ci id="S3.E5.m1.4.4.4.2.2.2.2.2.3.cmml" xref="S3.E5.m1.4.4.4.2.2.2.2.2.3">ğ‘˜</ci></apply></interval></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.5c">\mathcal{L}_{clip\mhyphen t}=\sum_{r}{\mathcal{L}_{CE}\left(\frac{e^{sim(\mathcal{F}_{r},\mathcal{Q}_{k})}}{\sum_{k=0}^{K}{e^{sim(\mathcal{F}_{r},\mathcal{Q}_{k})}}}\right)}\;.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.10" class="ltx_p">Similarly toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, we formulate prompts of the form <span id="S3.SS2.p2.10.1" class="ltx_text ltx_font_typewriter">a photo of a {category name}</span> to obtain our text embeddings.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Training with Augmentation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.4" class="ltx_p">Following the standard detector trainingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, we use the full image as our input. This subsequently increases the output feature map size of <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{V}^{a}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msup id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">ğ’±</mi><mi id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ’±</ci><ci id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathcal{V}^{a}</annotation></semantics></math>, hence we use average pooling operation and obtain channel-wise augmentations which can work for arbitrary-sized feature maps. The training of our modified object detector with the semantic augmentations is as follows, first, we randomly sample an augmentation <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{A}_{j}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">ğ’œ</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">ğ’œ</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\mathcal{A}_{j}</annotation></semantics></math> from the full set and collapse its spatial dimension using average pooling. We then add the resulting vector to every element in the feature map extracted by <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{V}^{a}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><msup id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">ğ’±</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">ğ’±</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\mathcal{V}^{a}</annotation></semantics></math>. In practice, we apply augmentations to a batch with a probability <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mi id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><ci id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">\theta</annotation></semantics></math>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.2" class="ltx_p">The detector is then trained with the loss</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\mathcal{L}_{det}=\mathcal{L}_{rpn}+\mathcal{L}_{reg}+\mathcal{L}_{clip\mhyphen t}\;," display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msub id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.2.2" xref="S3.E6.m1.1.1.1.1.2.2.cmml">â„’</mi><mrow id="S3.E6.m1.1.1.1.1.2.3" xref="S3.E6.m1.1.1.1.1.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.2.3.2" xref="S3.E6.m1.1.1.1.1.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.2.3.1" xref="S3.E6.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.2.3.3" xref="S3.E6.m1.1.1.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.2.3.1a" xref="S3.E6.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.2.3.4" xref="S3.E6.m1.1.1.1.1.2.3.4.cmml">t</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><msub id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.2.2" xref="S3.E6.m1.1.1.1.1.3.2.2.cmml">â„’</mi><mrow id="S3.E6.m1.1.1.1.1.3.2.3" xref="S3.E6.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2.3.2" xref="S3.E6.m1.1.1.1.1.3.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.3.1" xref="S3.E6.m1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.2.3.3" xref="S3.E6.m1.1.1.1.1.3.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.2.3.1a" xref="S3.E6.m1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.2.3.4" xref="S3.E6.m1.1.1.1.1.3.2.3.4.cmml">n</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.3.1" xref="S3.E6.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.2.cmml">â„’</mi><mrow id="S3.E6.m1.1.1.1.1.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.3.3.2" xref="S3.E6.m1.1.1.1.1.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.3.1" xref="S3.E6.m1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.3.3.3" xref="S3.E6.m1.1.1.1.1.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.3.3.1a" xref="S3.E6.m1.1.1.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.3.3.4" xref="S3.E6.m1.1.1.1.1.3.3.3.4.cmml">g</mi></mrow></msub><mo id="S3.E6.m1.1.1.1.1.3.1a" xref="S3.E6.m1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.E6.m1.1.1.1.1.3.4" xref="S3.E6.m1.1.1.1.1.3.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.1.1.3.4.2" xref="S3.E6.m1.1.1.1.1.3.4.2.cmml">â„’</mi><mrow id="S3.E6.m1.1.1.1.1.3.4.3" xref="S3.E6.m1.1.1.1.1.3.4.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.4.3.2" xref="S3.E6.m1.1.1.1.1.3.4.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.4.3.1" xref="S3.E6.m1.1.1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.4.3.3" xref="S3.E6.m1.1.1.1.1.3.4.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.4.3.1a" xref="S3.E6.m1.1.1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.4.3.4" xref="S3.E6.m1.1.1.1.1.3.4.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.4.3.1b" xref="S3.E6.m1.1.1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.4.3.5" xref="S3.E6.m1.1.1.1.1.3.4.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.1.1.3.4.3.1c" xref="S3.E6.m1.1.1.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.1.1.1.1.3.4.3.6" xref="S3.E6.m1.1.1.1.1.3.4.3.6.cmml">t</mi></mrow></msub></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"></eq><apply id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.1.1.2.2">â„’</ci><apply id="S3.E6.m1.1.1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.1.1.2.3"><times id="S3.E6.m1.1.1.1.1.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.2.3.1"></times><ci id="S3.E6.m1.1.1.1.1.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.2.3.2">ğ‘‘</ci><ci id="S3.E6.m1.1.1.1.1.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.2.3.3">ğ‘’</ci><ci id="S3.E6.m1.1.1.1.1.2.3.4.cmml" xref="S3.E6.m1.1.1.1.1.2.3.4">ğ‘¡</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><plus id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.1"></plus><apply id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.2">â„’</ci><apply id="S3.E6.m1.1.1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3"><times id="S3.E6.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.2">ğ‘Ÿ</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.3">ğ‘</ci><ci id="S3.E6.m1.1.1.1.1.3.2.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.2.3.4">ğ‘›</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.2">â„’</ci><apply id="S3.E6.m1.1.1.1.1.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3"><times id="S3.E6.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.2">ğ‘Ÿ</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.3">ğ‘’</ci><ci id="S3.E6.m1.1.1.1.1.3.3.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.3.3.4">ğ‘”</ci></apply></apply><apply id="S3.E6.m1.1.1.1.1.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.4.1.cmml" xref="S3.E6.m1.1.1.1.1.3.4">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.4.2.cmml" xref="S3.E6.m1.1.1.1.1.3.4.2">â„’</ci><apply id="S3.E6.m1.1.1.1.1.3.4.3.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3"><times id="S3.E6.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.1"></times><ci id="S3.E6.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.2">ğ‘</ci><ci id="S3.E6.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.3">ğ‘™</ci><ci id="S3.E6.m1.1.1.1.1.3.4.3.4.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.4">ğ‘–</ci><ci id="S3.E6.m1.1.1.1.1.3.4.3.5.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.5">ğ‘</ci><ci id="S3.E6.m1.1.1.1.1.3.4.3.6.cmml" xref="S3.E6.m1.1.1.1.1.3.4.3.6">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathcal{L}_{det}=\mathcal{L}_{rpn}+\mathcal{L}_{reg}+\mathcal{L}_{clip\mhyphen t}\;,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p2.1" class="ltx_p">which combines the <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">â„’</mi><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1a" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.4" xref="S3.SS3.p2.1.m1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1b" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.5" xref="S3.SS3.p2.1.m1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p2.1.m1.1.1.3.1c" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS3.p2.1.m1.1.1.3.6" xref="S3.SS3.p2.1.m1.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">â„’</ci><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><times id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1"></times><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">ğ‘™</ci><ci id="S3.SS3.p2.1.m1.1.1.3.4.cmml" xref="S3.SS3.p2.1.m1.1.1.3.4">ğ‘–</ci><ci id="S3.SS3.p2.1.m1.1.1.3.5.cmml" xref="S3.SS3.p2.1.m1.1.1.3.5">ğ‘</ci><ci id="S3.SS3.p2.1.m1.1.1.3.6.cmml" xref="S3.SS3.p2.1.m1.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math> loss ofÂ <a href="#S3.E5" title="In 3.2 Architecture â€£ 3 Method â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> with the standard RPN and regression lossesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. During inference, we use the detector without any augmentation of the feature maps.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental setup</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Datasets.</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">To evaluate our model, we use the same datasets asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. They include five sets, each containing images with different weather conditions: daytime sunny, night clear, dusk rainy, night rainy, and daytime foggy. The images have been selected from three primary datasets, Berkeley Deep Drive 100K (BBD-100K) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, Cityscapes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and Adverse-Weather <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Additionally, rainy images are rendered by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, and some of the foggy images are synthetically generated from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.
Our model is trained on the daytime sunny scenes, consisting of 19,395 training images, the remaining 8,313 daytime sunny images are used for validation and model selection. The four other weather conditions are only used during testing. They consist of 26,158 images of clear night scenes, 3501 images of rainy scenes at dusk, 2494 images of rainy scenes at night, and 3775 images of foggy scenes during daytime. All the datasets contain bounding box annotations for the objects <em id="S4.SS1.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">bus, bike, car, motorbike, person, rider</em> and <em id="S4.SS1.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">truck</em>.Â <a href="#S3.F3" title="In 3.1 Semantic Augmentation â€£ 3 Method â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> shows examples from this dataset.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Metric.</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">In all our experiments, we use the Mean Average Precision (mAP) as our metric. Specifically, followingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, we report the mAP@0.5, which considers a prediction as a true positive if it matches the ground-truth label and has an intersection over union (IOU) score of more than 0.5 with the ground-truth bounding box.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2301.05499/assets/figures/results3.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="211" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.8.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.9.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Qualitative Results.<span id="S4.F4.9.2.1" class="ltx_text ltx_font_medium"> We visualize the predictions of the detectors trained only with day-clear images. (Top) FasterRCNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> predictions. (Bottom) The predictions with our approach. Night-Clear and Night-Rainy contain scenes that are taken under low light conditions. Due to this, the appearance of the object is obscure and deviates from the daytime case. FasterRCNN fails to detect most of the objects. As shown in the Night-Clear, it misclassifies a <span id="S4.F4.9.2.1.1" class="ltx_text" style="color:#00FF00;">car</span> to <span id="S4.F4.9.2.1.2" class="ltx_text" style="color:#0000FF;">bus</span>. By contrast, we can still detect <span id="S4.F4.9.2.1.3" class="ltx_text" style="color:#00FF00;">car</span> under such a big shift. For Dusk-Rainy scenes, the rain pattern on the windscreen and the wet ground causes an appearance shift. As shown FasterRCNN fails to detect several <span id="S4.F4.9.2.1.4" class="ltx_text" style="color:#00FF00;">cars</span> and misclassifies <span id="S4.F4.9.2.1.5" class="ltx_text" style="color:#FF8000;">person</span> on the bottom-left. </span></span></figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2301.05499/assets/figures/day-foggy.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="305" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.5.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Qualitative Results.<span id="S4.F5.6.2.1" class="ltx_text ltx_font_medium"> In the foggy scenes, the objects further away w.r.t the camera are more obscure than the near ones. Due to this FasterRCNN (Top) struggles to detect them. <span id="S4.F5.6.2.1.1" class="ltx_text" style="color:#00FF00;">car</span> and <span id="S4.F5.6.2.1.2" class="ltx_text" style="color:#FF8000;">person</span> missed by FasterRCNN are successfully recovered by our approach (Bottom).</span></span></figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">We use the Detectron2Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> implementation of FasterRCNN with a ResNet101Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> backbone. We initialize the detector with CLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> pre-trained weights, where ResNet convolution blocks 1-3 act as <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{V}^{a}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">ğ’±</mi><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ğ’±</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\mathcal{V}^{a}</annotation></semantics></math>, and block-4 along with the CLIP attention pooling act as <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{V}^{b}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msup id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">ğ’±</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ğ’±</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">\mathcal{V}^{b}</annotation></semantics></math>. This follows from the standard FasterRCNN implementation with ResNet backbone.</p>
</div>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Optimization Step.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.6" class="ltx_p">As the benchmark dataset evaluates the method on different weather conditions, we curated a list of domain prompts <math id="S4.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{P}^{t}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.1.m1.1a"><msup id="S4.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">ğ’«</mi><mi id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.2">ğ’«</ci><ci id="S4.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.1.m1.1c">\mathcal{P}^{t}</annotation></semantics></math> matching the concept <em id="S4.SS2.SSS0.Px1.p1.6.1" class="ltx_emph ltx_font_italic">weather</em>. To this end, we take all the <em id="S4.SS2.SSS0.Px1.p1.6.2" class="ltx_emph ltx_font_italic">hyponyms</em> of the term <em id="S4.SS2.SSS0.Px1.p1.6.3" class="ltx_emph ltx_font_italic">weather</em> from WordNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and generate their text embeddings using the CLIP text encoder <math id="S4.SS2.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S4.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.2.m2.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.2.m2.1c">\mathcal{T}</annotation></semantics></math>. We prune away the words whose cosine similarity with the term <em id="S4.SS2.SSS0.Px1.p1.6.4" class="ltx_emph ltx_font_italic">weather</em> is lower than <math id="S4.SS2.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.3.m3.1a"><mn id="S4.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.3.m3.1b"><cn type="float" id="S4.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.3.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.3.m3.1c">0.5</annotation></semantics></math>. Additionally, we filter out the words that are not in the top <math id="S4.SS2.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.4.m4.1a"><mn id="S4.SS2.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.4.m4.1b"><cn type="integer" id="S4.SS2.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.4.m4.1c">10</annotation></semantics></math>k frequent words in GloVe wordlistÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. After combining the synonyms, we get to a list of six words: <em id="S4.SS2.SSS0.Px1.p1.6.5" class="ltx_emph ltx_font_italic">snow, fog, cloudy, rain, stormy, sunshine</em>. We remove <em id="S4.SS2.SSS0.Px1.p1.6.6" class="ltx_emph ltx_font_italic">sunshine</em> as it corresponds to our source domain concept. Furthermore, we consider three times of the day: <em id="S4.SS2.SSS0.Px1.p1.6.7" class="ltx_emph ltx_font_italic">day, night, evening</em>. This lets us generate <math id="S4.SS2.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="M=15" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.5.m5.1a"><mrow id="S4.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.2" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml">M</mi><mo id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.1" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.3" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml">15</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.5.m5.1b"><apply id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1"><eq id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.1"></eq><ci id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.2">ğ‘€</ci><cn type="integer" id="S4.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.5.m5.1.1.3">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.5.m5.1c">M=15</annotation></semantics></math> prompts using the template <span id="S4.SS2.SSS0.Px1.p1.6.8" class="ltx_text ltx_font_typewriter">an image taken on a {weather} {time of the day}</span>. We use <span id="S4.SS2.SSS0.Px1.p1.6.9" class="ltx_text ltx_font_typewriter">an image taken during the day</span> as the source domain prompt <math id="S4.SS2.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="p^{s}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p1.6.m6.1a"><msup id="S4.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p1.6.m6.1.1.2" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml">p</mi><mi id="S4.SS2.SSS0.Px1.p1.6.m6.1.1.3" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1.3.cmml">s</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p1.6.m6.1b"><apply id="S4.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1.2">ğ‘</ci><ci id="S4.SS2.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p1.6.m6.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p1.6.m6.1c">p^{s}</annotation></semantics></math>. We provide more details in our supplementary material.</p>
</div>
<div id="S4.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p2.9" class="ltx_p">To optimize the augmentations with these prompts, we generated random crops from the source images and resized them to <math id="S4.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.1.m1.1a"><mrow id="S4.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.cmml"><mn id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.2" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.1" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.3" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.1.m1.1b"><apply id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1"><times id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.2">224</cn><cn type="integer" id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.1.m1.1c">224\times 224</annotation></semantics></math> pixels. The resulting output feature map of <math id="S4.SS2.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{V}^{a}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.2.m2.1a"><msup id="S4.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.2" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1.2.cmml">ğ’±</mi><mi id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.3" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1.3.cmml">a</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.2.m2.1b"><apply id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1.2">ğ’±</ci><ci id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.2.m2.1c">\mathcal{V}^{a}</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{A}_{j}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.3.m3.1a"><msub id="S4.SS2.SSS0.Px1.p2.3.m3.1.1" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p2.3.m3.1.1.2" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml">ğ’œ</mi><mi id="S4.SS2.SSS0.Px1.p2.3.m3.1.1.3" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.3.m3.1b"><apply id="S4.SS2.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1.2">ğ’œ</ci><ci id="S4.SS2.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p2.3.m3.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.3.m3.1c">\mathcal{A}_{j}</annotation></semantics></math> are in <math id="S4.SS2.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="\mathbb{R}^{14\times 14\times 1024}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.4.m4.1a"><msup id="S4.SS2.SSS0.Px1.p2.4.m4.1.1" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.cmml"><mi id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.2" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml">â„</mi><mrow id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml"><mn id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.2" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.2.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.1" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.1.cmml">Ã—</mo><mn id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.3" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.1a" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.1.cmml">Ã—</mo><mn id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.4" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.4.cmml">1024</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.4.m4.1b"><apply id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.2">â„</ci><apply id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3"><times id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.1"></times><cn type="integer" id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.2">14</cn><cn type="integer" id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.3">14</cn><cn type="integer" id="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.4.cmml" xref="S4.SS2.SSS0.Px1.p2.4.m4.1.1.3.4">1024</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.4.m4.1c">\mathbb{R}^{14\times 14\times 1024}</annotation></semantics></math>. We initialize <math id="S4.SS2.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="\mathcal{A}_{j}\;\forall\;1\geq j\geq M" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.5.m5.1a"><mrow id="S4.SS2.SSS0.Px1.p2.5.m5.1.1" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.cmml"><mrow id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml"><msub id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.2" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.2.cmml">ğ’œ</mi><mi id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.3" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.3.cmml">j</mi></msub><mo lspace="0.447em" rspace="0em" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.1" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.1.cmml">â€‹</mo><mrow id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.cmml"><mo rspace="0.167em" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.1" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.1.cmml">âˆ€</mo><mn id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.2" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.2.cmml">â€„1</mn></mrow></mrow><mo id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.3" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml">â‰¥</mo><mi id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.4" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.4.cmml">j</mi><mo id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.5" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.5.cmml">â‰¥</mo><mi id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.6" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.6.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.5.m5.1b"><apply id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1"><and id="S4.SS2.SSS0.Px1.p2.5.m5.1.1a.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1"></and><apply id="S4.SS2.SSS0.Px1.p2.5.m5.1.1b.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1"><geq id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.3"></geq><apply id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2"><times id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.1.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.1"></times><apply id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.1.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2">subscript</csymbol><ci id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.2.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.2">ğ’œ</ci><ci id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.3.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.2.3">ğ‘—</ci></apply><apply id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3"><csymbol cd="latexml" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.1.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.1">for-all</csymbol><cn type="integer" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.2.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.2.3.2">1</cn></apply></apply><ci id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.4.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.4">ğ‘—</ci></apply><apply id="S4.SS2.SSS0.Px1.p2.5.m5.1.1c.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1"><geq id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.5.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.5"></geq><share href="#S4.SS2.SSS0.Px1.p2.5.m5.1.1.4.cmml" id="S4.SS2.SSS0.Px1.p2.5.m5.1.1d.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1"></share><ci id="S4.SS2.SSS0.Px1.p2.5.m5.1.1.6.cmml" xref="S4.SS2.SSS0.Px1.p2.5.m5.1.1.6">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.5.m5.1c">\mathcal{A}_{j}\;\forall\;1\geq j\geq M</annotation></semantics></math> with zeros and train it using the AdamÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> optimizer while keeping the CLIP encoder, <math id="S4.SS2.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p2.6.m6.1.1" xref="S4.SS2.SSS0.Px1.p2.6.m6.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.6.m6.1b"><ci id="S4.SS2.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.6.m6.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.6.m6.1c">\mathcal{V}</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px1.p2.7.m7.1.1" xref="S4.SS2.SSS0.Px1.p2.7.m7.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.7.m7.1b"><ci id="S4.SS2.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.7.m7.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.7.m7.1c">\mathcal{T}</annotation></semantics></math>, frozen. Optimization
was done for <math id="S4.SS2.SSS0.Px1.p2.8.m8.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.8.m8.1a"><mn id="S4.SS2.SSS0.Px1.p2.8.m8.1.1" xref="S4.SS2.SSS0.Px1.p2.8.m8.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.8.m8.1b"><cn type="integer" id="S4.SS2.SSS0.Px1.p2.8.m8.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.8.m8.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.8.m8.1c">1000</annotation></semantics></math> iterations with a learning rate of <math id="S4.SS2.SSS0.Px1.p2.9.m9.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S4.SS2.SSS0.Px1.p2.9.m9.1a"><mn id="S4.SS2.SSS0.Px1.p2.9.m9.1.1" xref="S4.SS2.SSS0.Px1.p2.9.m9.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.9.m9.1b"><cn type="float" id="S4.SS2.SSS0.Px1.p2.9.m9.1.1.cmml" xref="S4.SS2.SSS0.Px1.p2.9.m9.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.9.m9.1c">0.01</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Detector Training with Augmentation.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.12" class="ltx_p">When training the detector, the input image is resized to <math id="S4.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="600\times 1067" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">600</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">1067</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1"><times id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2">600</cn><cn type="integer" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3">1067</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">600\times 1067</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.1b"><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.1c">\mathcal{V}</annotation></semantics></math> and <math id="S4.SS2.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.3.m3.1b"><ci id="S4.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.3.m3.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.3.m3.1c">\mathcal{T}</annotation></semantics></math> are initialized with CLIP pre-trained weights. While <math id="S4.SS2.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S4.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.4.m4.1b"><ci id="S4.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.4.m4.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.4.m4.1c">\mathcal{T}</annotation></semantics></math> is kept frozen during the training, the ResNet blocks 3-4 and attention pooling of <math id="S4.SS2.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S4.SS2.SSS0.Px2.p1.5.m5.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.5.m5.1b"><ci id="S4.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.5.m5.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.5.m5.1c">\mathcal{V}</annotation></semantics></math>, along with the other FasterRCNN learnable blocks, are trained with Stochastic Gradient Descent (SGD) for 100k iterations. We train with a learning rate of <math id="S4.SS2.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="1e^{-3}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.6.m6.1a"><mrow id="S4.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.cmml"><mn id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.2" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.1" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml">â€‹</mo><msup id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml"><mi id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.2" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.2.cmml">e</mi><mrow id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.cmml"><mo id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3a" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.2" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.2.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.6.m6.1b"><apply id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1"><times id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.1"></times><cn type="integer" id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.2">1</cn><apply id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3">superscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.2">ğ‘’</ci><apply id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3"><minus id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.1.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3"></minus><cn type="integer" id="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.2.cmml" xref="S4.SS2.SSS0.Px2.p1.6.m6.1.1.3.3.2">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.6.m6.1c">1e^{-3}</annotation></semantics></math>, scaled down by a factor of <math id="S4.SS2.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.7.m7.1a"><mn id="S4.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S4.SS2.SSS0.Px2.p1.7.m7.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.7.m7.1b"><cn type="float" id="S4.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.7.m7.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.7.m7.1c">0.1</annotation></semantics></math> after 40k iterations. We use a batch size of <math id="S4.SS2.SSS0.Px2.p1.8.m8.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.8.m8.1a"><mn id="S4.SS2.SSS0.Px2.p1.8.m8.1.1" xref="S4.SS2.SSS0.Px2.p1.8.m8.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.8.m8.1b"><cn type="integer" id="S4.SS2.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.8.m8.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.8.m8.1c">4</annotation></semantics></math> and apply <math id="S4.SS2.SSS0.Px2.p1.9.m9.1" class="ltx_Math" alttext="\mathcal{A}_{j}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.9.m9.1a"><msub id="S4.SS2.SSS0.Px2.p1.9.m9.1.1" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.9.m9.1.1.2" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1.2.cmml">ğ’œ</mi><mi id="S4.SS2.SSS0.Px2.p1.9.m9.1.1.3" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.9.m9.1b"><apply id="S4.SS2.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.9.m9.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.9.m9.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1.2">ğ’œ</ci><ci id="S4.SS2.SSS0.Px2.p1.9.m9.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.9.m9.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.9.m9.1c">\mathcal{A}_{j}</annotation></semantics></math> to the features with probability <math id="S4.SS2.SSS0.Px2.p1.10.m10.1" class="ltx_Math" alttext="\theta=0.5" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.10.m10.1a"><mrow id="S4.SS2.SSS0.Px2.p1.10.m10.1.1" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.cmml"><mi id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.2" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.2.cmml">Î¸</mi><mo id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.1" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.1.cmml">=</mo><mn id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.3" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.10.m10.1b"><apply id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1"><eq id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.1"></eq><ci id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.2">ğœƒ</ci><cn type="float" id="S4.SS2.SSS0.Px2.p1.10.m10.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.10.m10.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.10.m10.1c">\theta=0.5</annotation></semantics></math>. We also use random horizontal flipping augmentation as in Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. <math id="S4.SS2.SSS0.Px2.p1.11.m11.1" class="ltx_Math" alttext="D_{clip}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.11.m11.1a"><msub id="S4.SS2.SSS0.Px2.p1.11.m11.1.1" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.cmml"><mi id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.2" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.2.cmml">D</mi><mrow id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.cmml"><mi id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.2" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.3" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1a" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.4" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1b" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.5" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.5.cmml">p</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.11.m11.1b"><apply id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.2">ğ·</ci><apply id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3"><times id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.1"></times><ci id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.2.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.2">ğ‘</ci><ci id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.3.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.3">ğ‘™</ci><ci id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.4.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.4">ğ‘–</ci><ci id="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.5.cmml" xref="S4.SS2.SSS0.Px2.p1.11.m11.1.1.3.5">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.11.m11.1c">D_{clip}</annotation></semantics></math> is set to 512 as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> and background class is initialized by zeros in <math id="S4.SS2.SSS0.Px2.p1.12.m12.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.12.m12.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.SSS0.Px2.p1.12.m12.1.1" xref="S4.SS2.SSS0.Px2.p1.12.m12.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.12.m12.1b"><ci id="S4.SS2.SSS0.Px2.p1.12.m12.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.12.m12.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.12.m12.1c">\mathcal{Q}</annotation></semantics></math>. All of our training was done on a single NVIDIA A100 GPU. Our code will be made public upon acceptance.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Comparison with the State of the Art</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We compare our method trained with semantic augmentations against the state-of-the-art Single-DGODÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. Similar to them, we also show comparisons with feature normalization methods, SWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, IBN-NetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, IterNormÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, and ISWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. These methods improve network generalization by using better feature normalization. We additionally report the performance of FasterRCNN (FR) initialized with ImageNet pre-trained weights. For the SDG task, we evaluate the generalization performance on unseen target domains, hence we compare the mAP scores on the out-of-domain datasets: day-foggy, night-rainy, dusk-rainy, and night-clear.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T1.2.1" class="ltx_tr">
<td id="S4.T1.2.1.1" class="ltx_td ltx_border_tt" style="padding:2.5pt 4.0pt;"></td>
<td id="S4.T1.2.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 4.0pt;" colspan="5">mAP</td>
</tr>
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.1" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">Method</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 4.0pt;">
<span id="S4.T1.2.2.2.1" class="ltx_text"></span> <span id="S4.T1.2.2.2.2" class="ltx_text">
<span id="S4.T1.2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.2.2.2.2.1.1" class="ltx_tr">
<span id="S4.T1.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Day</span></span>
<span id="S4.T1.2.2.2.2.1.2" class="ltx_tr">
<span id="S4.T1.2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Clear</span></span>
</span></span><span id="S4.T1.2.2.2.3" class="ltx_text"></span></td>
<td id="S4.T1.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">
<span id="S4.T1.2.2.3.1" class="ltx_text"></span> <span id="S4.T1.2.2.3.2" class="ltx_text">
<span id="S4.T1.2.2.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.2.2.3.2.1.1" class="ltx_tr">
<span id="S4.T1.2.2.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Night</span></span>
<span id="S4.T1.2.2.3.2.1.2" class="ltx_tr">
<span id="S4.T1.2.2.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Clear</span></span>
</span></span><span id="S4.T1.2.2.3.3" class="ltx_text"></span></td>
<td id="S4.T1.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">
<span id="S4.T1.2.2.4.1" class="ltx_text"></span> <span id="S4.T1.2.2.4.2" class="ltx_text">
<span id="S4.T1.2.2.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.2.2.4.2.1.1" class="ltx_tr">
<span id="S4.T1.2.2.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Dusk</span></span>
<span id="S4.T1.2.2.4.2.1.2" class="ltx_tr">
<span id="S4.T1.2.2.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Rainy</span></span>
</span></span><span id="S4.T1.2.2.4.3" class="ltx_text"></span></td>
<td id="S4.T1.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">
<span id="S4.T1.2.2.5.1" class="ltx_text"></span> <span id="S4.T1.2.2.5.2" class="ltx_text">
<span id="S4.T1.2.2.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.2.2.5.2.1.1" class="ltx_tr">
<span id="S4.T1.2.2.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Night</span></span>
<span id="S4.T1.2.2.5.2.1.2" class="ltx_tr">
<span id="S4.T1.2.2.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Rainy</span></span>
</span></span><span id="S4.T1.2.2.5.3" class="ltx_text"></span></td>
<td id="S4.T1.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">
<span id="S4.T1.2.2.6.1" class="ltx_text"></span> <span id="S4.T1.2.2.6.2" class="ltx_text">
<span id="S4.T1.2.2.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T1.2.2.6.2.1.1" class="ltx_tr">
<span id="S4.T1.2.2.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Day</span></span>
<span id="S4.T1.2.2.6.2.1.2" class="ltx_tr">
<span id="S4.T1.2.2.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:2.5pt 4.0pt;">Foggy</span></span>
</span></span><span id="S4.T1.2.2.6.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T1.2.3" class="ltx_tr">
<td id="S4.T1.2.3.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:2.5pt 4.0pt;">FRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T1.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:2.5pt 4.0pt;">48.1</td>
<td id="S4.T1.2.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">34.4</td>
<td id="S4.T1.2.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">26.0</td>
<td id="S4.T1.2.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">12.4</td>
<td id="S4.T1.2.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 4.0pt;">32.0</td>
</tr>
<tr id="S4.T1.2.4" class="ltx_tr">
<td id="S4.T1.2.4.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 4.0pt;">SW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>
</td>
<td id="S4.T1.2.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 4.0pt;">50.6</td>
<td id="S4.T1.2.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">33.4</td>
<td id="S4.T1.2.4.4" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">26.3</td>
<td id="S4.T1.2.4.5" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">13.7</td>
<td id="S4.T1.2.4.6" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">30.8</td>
</tr>
<tr id="S4.T1.2.5" class="ltx_tr">
<td id="S4.T1.2.5.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 4.0pt;">IBN-Net <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</td>
<td id="S4.T1.2.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 4.0pt;">49.7</td>
<td id="S4.T1.2.5.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">32.1</td>
<td id="S4.T1.2.5.4" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">26.1</td>
<td id="S4.T1.2.5.5" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">14.3</td>
<td id="S4.T1.2.5.6" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">29.6</td>
</tr>
<tr id="S4.T1.2.6" class="ltx_tr">
<td id="S4.T1.2.6.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 4.0pt;">IterNorm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S4.T1.2.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 4.0pt;">43.9</td>
<td id="S4.T1.2.6.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">29.6</td>
<td id="S4.T1.2.6.4" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">22.8</td>
<td id="S4.T1.2.6.5" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">12.6</td>
<td id="S4.T1.2.6.6" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">28.4</td>
</tr>
<tr id="S4.T1.2.7" class="ltx_tr">
<td id="S4.T1.2.7.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 4.0pt;">ISW <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S4.T1.2.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 4.0pt;">51.3</td>
<td id="S4.T1.2.7.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">33.2</td>
<td id="S4.T1.2.7.4" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">25.9</td>
<td id="S4.T1.2.7.5" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">14.1</td>
<td id="S4.T1.2.7.6" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">31.8</td>
</tr>
<tr id="S4.T1.2.8" class="ltx_tr">
<td id="S4.T1.2.8.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 4.0pt;">S-DGOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T1.2.8.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:2.5pt 4.0pt;"><span id="S4.T1.2.8.2.1" class="ltx_text ltx_font_bold">56.1</span></td>
<td id="S4.T1.2.8.3" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">36.6</td>
<td id="S4.T1.2.8.4" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">28.2</td>
<td id="S4.T1.2.8.5" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">16.6</td>
<td id="S4.T1.2.8.6" class="ltx_td ltx_align_center" style="padding:2.5pt 4.0pt;">33.5</td>
</tr>
<tr id="S4.T1.2.9" class="ltx_tr">
<td id="S4.T1.2.9.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t" style="padding:2.5pt 4.0pt;">Ours</td>
<td id="S4.T1.2.9.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding:2.5pt 4.0pt;">51.3</td>
<td id="S4.T1.2.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 4.0pt;"><span id="S4.T1.2.9.3.1" class="ltx_text ltx_font_bold">36.9</span></td>
<td id="S4.T1.2.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 4.0pt;"><span id="S4.T1.2.9.4.1" class="ltx_text ltx_font_bold">32.3</span></td>
<td id="S4.T1.2.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 4.0pt;"><span id="S4.T1.2.9.5.1" class="ltx_text ltx_font_bold">18.7</span></td>
<td id="S4.T1.2.9.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 4.0pt;"><span id="S4.T1.2.9.6.1" class="ltx_text ltx_font_bold">38.5</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Single domain generalization results.<span id="S4.T1.5.2.1" class="ltx_text ltx_font_medium"> We show consistent improvements across all the target domains. S-DGOD boosts the source domain results, but at the cost of reduced generalization ability. By contrast, our approach is robust to domain changes. The numbers for S-DGOD, SW, IBN-Net, IterNorm, ISW are taken from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.
</span></span></figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.2" class="ltx_p">Our approach of combining CLIP pre-training and semantic augmentation outperforms the baselines on all of the target domains.Â <a href="#S4.T1" title="In 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> shows a consistent improvement in all domains with close to <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">15</annotation></semantics></math>% improvement on day-foggy and dusk-rainy compared to Single-DGOD. In the challenging scenario with Night conditions, we improve by <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="12.6" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mn id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml">12.6</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><cn type="float" id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1">12.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">12.6</annotation></semantics></math>% on night-rainy while being comparable with Single-DGOD on night-clear. On the source domain, both our method and Single-DGOD are better than the FR baseline. However, while Single-DGOD gains improvement at the cost of losing out for domain generalization, we improve on both the source and target domains. The failure of feature normalization baselines suggests a large domain gap between the source and target domains.Â <a href="#S4.F4" title="In Metric. â€£ 4.1 Experimental setup â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> andÂ <a href="#S4.F5" title="In Metric. â€£ 4.1 Experimental setup â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> provide a qualitative results on different weather-datasets.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">In the remainder of this section, we discuss the per-class results on the individual target domains.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Daytime Clear to Day Foggy.</h4>

<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(29.1pt,-7.0pt) scale(1.15507753602438,1.15507753602438) ;">
<table id="S4.T2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.2.1.1" class="ltx_tr">
<td id="S4.T2.2.1.1.1" class="ltx_td ltx_border_tt" style="padding:2.5pt 3.0pt;"></td>
<td id="S4.T2.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;" colspan="7">AP</td>
<td id="S4.T2.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;">mAP</td>
</tr>
<tr id="S4.T2.2.1.2" class="ltx_tr">
<td id="S4.T2.2.1.2.1" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">Method</td>
<td id="S4.T2.2.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bus</td>
<td id="S4.T2.2.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bike</td>
<td id="S4.T2.2.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Car</td>
<td id="S4.T2.2.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Motor</td>
<td id="S4.T2.2.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Person</td>
<td id="S4.T2.2.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Rider</td>
<td id="S4.T2.2.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Truck</td>
<td id="S4.T2.2.1.2.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">All</td>
</tr>
<tr id="S4.T2.2.1.3" class="ltx_tr">
<td id="S4.T2.2.1.3.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">FRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T2.2.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">28.1</td>
<td id="S4.T2.2.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">29.7</td>
<td id="S4.T2.2.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">49.7</td>
<td id="S4.T2.2.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">26.3</td>
<td id="S4.T2.2.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">33.2</td>
<td id="S4.T2.2.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">35.5</td>
<td id="S4.T2.2.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">21.5</td>
<td id="S4.T2.2.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">32.0</td>
</tr>
<tr id="S4.T2.2.1.4" class="ltx_tr">
<td id="S4.T2.2.1.4.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 3.0pt;">S-DGOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T2.2.1.4.2" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">32.9</td>
<td id="S4.T2.2.1.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">28.0</td>
<td id="S4.T2.2.1.4.4" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">48.8</td>
<td id="S4.T2.2.1.4.5" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">29.8</td>
<td id="S4.T2.2.1.4.6" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">32.5</td>
<td id="S4.T2.2.1.4.7" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">38.2</td>
<td id="S4.T2.2.1.4.8" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">24.1</td>
<td id="S4.T2.2.1.4.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">33.5</td>
</tr>
<tr id="S4.T2.2.1.5" class="ltx_tr">
<td id="S4.T2.2.1.5.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">Ours</td>
<td id="S4.T2.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.2.1" class="ltx_text ltx_font_bold">36.1</span></td>
<td id="S4.T2.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.3.1" class="ltx_text ltx_font_bold">34.3</span></td>
<td id="S4.T2.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.4.1" class="ltx_text ltx_font_bold">58.0</span></td>
<td id="S4.T2.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.5.1" class="ltx_text ltx_font_bold">33.1</span></td>
<td id="S4.T2.2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.6.1" class="ltx_text ltx_font_bold">39.0</span></td>
<td id="S4.T2.2.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.7.1" class="ltx_text ltx_font_bold">43.9</span></td>
<td id="S4.T2.2.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.8.1" class="ltx_text ltx_font_bold">25.1</span></td>
<td id="S4.T2.2.1.5.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T2.2.1.5.9.1" class="ltx_text ltx_font_bold">38.5</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Per-class results on Daytime Clear to Day Foggy.<span id="S4.T2.5.2.1" class="ltx_text ltx_font_medium"> Our method consistently performs better on all categories for the difficult foggy domain. This shows that CLIP initialization and our semantic augmentations improve the detectorâ€™s generalizability.
</span></span></figcaption>
</figure>
<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">The object appearance drastically changes in the foggy images compared to the day-clear scenario. As shown in <a href="#S4.T2" title="In Daytime Clear to Day Foggy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>, our method brings in a large improvement for the <em id="S4.SS3.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">car</em>, <em id="S4.SS3.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">person</em>, and <em id="S4.SS3.SSS0.Px1.p1.1.3" class="ltx_emph ltx_font_italic">bike</em> categories, while still being consistently better than Single-DGOD and FR on the others.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div id="S4.T3.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(29.1pt,-7.0pt) scale(1.15507753602438,1.15507753602438) ;">
<table id="S4.T3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.2.1.1" class="ltx_tr">
<td id="S4.T3.2.1.1.1" class="ltx_td ltx_border_tt" style="padding:2.5pt 3.0pt;"></td>
<td id="S4.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;" colspan="7">AP</td>
<td id="S4.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;">mAP</td>
</tr>
<tr id="S4.T3.2.1.2" class="ltx_tr">
<td id="S4.T3.2.1.2.1" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">Method</td>
<td id="S4.T3.2.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bus</td>
<td id="S4.T3.2.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bike</td>
<td id="S4.T3.2.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Car</td>
<td id="S4.T3.2.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Motor</td>
<td id="S4.T3.2.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Person</td>
<td id="S4.T3.2.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Rider</td>
<td id="S4.T3.2.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Truck</td>
<td id="S4.T3.2.1.2.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">All</td>
</tr>
<tr id="S4.T3.2.1.3" class="ltx_tr">
<td id="S4.T3.2.1.3.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">FRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T3.2.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">28.5</td>
<td id="S4.T3.2.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">20.3</td>
<td id="S4.T3.2.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">58.2</td>
<td id="S4.T3.2.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">6.5</td>
<td id="S4.T3.2.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">23.4</td>
<td id="S4.T3.2.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">11.3</td>
<td id="S4.T3.2.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">33.9</td>
<td id="S4.T3.2.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">26.0</td>
</tr>
<tr id="S4.T3.2.1.4" class="ltx_tr">
<td id="S4.T3.2.1.4.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 3.0pt;">S-DGOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T3.2.1.4.2" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">37.1</td>
<td id="S4.T3.2.1.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">19.6</td>
<td id="S4.T3.2.1.4.4" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">50.9</td>
<td id="S4.T3.2.1.4.5" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">13.4</td>
<td id="S4.T3.2.1.4.6" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">19.7</td>
<td id="S4.T3.2.1.4.7" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">16.3</td>
<td id="S4.T3.2.1.4.8" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">40.7</td>
<td id="S4.T3.2.1.4.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">28.2</td>
</tr>
<tr id="S4.T3.2.1.5" class="ltx_tr">
<td id="S4.T3.2.1.5.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">Ours</td>
<td id="S4.T3.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.2.1" class="ltx_text ltx_font_bold">37.8</span></td>
<td id="S4.T3.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.3.1" class="ltx_text ltx_font_bold">22.8</span></td>
<td id="S4.T3.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.4.1" class="ltx_text ltx_font_bold">60.7</span></td>
<td id="S4.T3.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.5.1" class="ltx_text ltx_font_bold">16.8</span></td>
<td id="S4.T3.2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.6.1" class="ltx_text ltx_font_bold">26.8</span></td>
<td id="S4.T3.2.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.7.1" class="ltx_text ltx_font_bold">18.7</span></td>
<td id="S4.T3.2.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.8.1" class="ltx_text ltx_font_bold">42.4</span></td>
<td id="S4.T3.2.1.5.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T3.2.1.5.9.1" class="ltx_text ltx_font_bold">32.3</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.5.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Per-class results on Daytime Clear to Dusk Rainy.<span id="S4.T3.6.2.1" class="ltx_text ltx_font_medium"> Our approach generalizes to rainy road conditions along with the low light conditions of the dusk hours. The <em id="S4.T3.6.2.1.1" class="ltx_emph ltx_font_italic">car</em> category sees the biggest improvement, but we nonetheless also boost the performance of all the other classes.
</span></span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Daytime Clear to Dusk Rainy.</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">Dusk Rainy scenes reflect a low light condition and along with the rainy pattern. The image distribution is thus further away from the daytime clear images. As shown inÂ <a href="#S4.T3" title="In Daytime Clear to Day Foggy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>, our method improves the AP of each class, with the biggest improvement in the <em id="S4.SS3.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">car</em> and <em id="S4.SS3.SSS0.Px2.p1.1.2" class="ltx_emph ltx_font_italic">person</em> categories. Since we leverage CLIP pre-training and bring in concepts such as rain/cloudy/stormy and evening/night hours through our semantic augmentation, the learnt detector generalizes better.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<div id="S4.T4.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(29.1pt,-7.0pt) scale(1.15507753602438,1.15507753602438) ;">
<table id="S4.T4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.2.1.1" class="ltx_tr">
<td id="S4.T4.2.1.1.1" class="ltx_td ltx_border_tt" style="padding:2.5pt 3.0pt;"></td>
<td id="S4.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;" colspan="7">AP</td>
<td id="S4.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;">mAP</td>
</tr>
<tr id="S4.T4.2.1.2" class="ltx_tr">
<td id="S4.T4.2.1.2.1" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">Method</td>
<td id="S4.T4.2.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bus</td>
<td id="S4.T4.2.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bike</td>
<td id="S4.T4.2.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Car</td>
<td id="S4.T4.2.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Motor</td>
<td id="S4.T4.2.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Person</td>
<td id="S4.T4.2.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Rider</td>
<td id="S4.T4.2.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Truck</td>
<td id="S4.T4.2.1.2.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">All</td>
</tr>
<tr id="S4.T4.2.1.3" class="ltx_tr">
<td id="S4.T4.2.1.3.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">FRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T4.2.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">34.7</td>
<td id="S4.T4.2.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">32.0</td>
<td id="S4.T4.2.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">56.6</td>
<td id="S4.T4.2.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">13.6</td>
<td id="S4.T4.2.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">37.4</td>
<td id="S4.T4.2.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">27.6</td>
<td id="S4.T4.2.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">38.6</td>
<td id="S4.T4.2.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">34.4</td>
</tr>
<tr id="S4.T4.2.1.4" class="ltx_tr">
<td id="S4.T4.2.1.4.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 3.0pt;">S-DGOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T4.2.1.4.2" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.4.2.1" class="ltx_text ltx_font_bold">40.6</span></td>
<td id="S4.T4.2.1.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.4.3.1" class="ltx_text ltx_font_bold">35.1</span></td>
<td id="S4.T4.2.1.4.4" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">50.7</td>
<td id="S4.T4.2.1.4.5" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.4.5.1" class="ltx_text ltx_font_bold">19.7</span></td>
<td id="S4.T4.2.1.4.6" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">34.7</td>
<td id="S4.T4.2.1.4.7" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.4.7.1" class="ltx_text ltx_font_bold">32.1</span></td>
<td id="S4.T4.2.1.4.8" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.4.8.1" class="ltx_text ltx_font_bold">43.4</span></td>
<td id="S4.T4.2.1.4.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">36.6</td>
</tr>
<tr id="S4.T4.2.1.5" class="ltx_tr">
<td id="S4.T4.2.1.5.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">Ours</td>
<td id="S4.T4.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">37.7</td>
<td id="S4.T4.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">34.3</td>
<td id="S4.T4.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.5.4.1" class="ltx_text ltx_font_bold">58.0</span></td>
<td id="S4.T4.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">19.2</td>
<td id="S4.T4.2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.5.6.1" class="ltx_text ltx_font_bold">37.6</span></td>
<td id="S4.T4.2.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">28.5</td>
<td id="S4.T4.2.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">42.9</td>
<td id="S4.T4.2.1.5.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T4.2.1.5.9.1" class="ltx_text ltx_font_bold">36.9</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.6.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.7.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Per-class results on Daytime Clear to Night Clear.<span id="S4.T4.7.2.1" class="ltx_text ltx_font_medium"> While being comparable to S-DGOD on most of the categories, we improve on <em id="S4.T4.7.2.1.1" class="ltx_emph ltx_font_italic">car</em> and <em id="S4.T4.7.2.1.2" class="ltx_emph ltx_font_italic">person</em>.
</span></span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:104pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(29.1pt,-7.0pt) scale(1.15507753602438,1.15507753602438) ;">
<table id="S4.T5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.2.1.1" class="ltx_tr">
<td id="S4.T5.2.1.1.1" class="ltx_td ltx_border_tt" style="padding:2.5pt 3.0pt;"></td>
<td id="S4.T5.2.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;" colspan="7">AP</td>
<td id="S4.T5.2.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding:2.5pt 3.0pt;">mAP</td>
</tr>
<tr id="S4.T5.2.1.2" class="ltx_tr">
<td id="S4.T5.2.1.2.1" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">Method</td>
<td id="S4.T5.2.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bus</td>
<td id="S4.T5.2.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Bike</td>
<td id="S4.T5.2.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Car</td>
<td id="S4.T5.2.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Motor</td>
<td id="S4.T5.2.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Person</td>
<td id="S4.T5.2.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Rider</td>
<td id="S4.T5.2.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">Truck</td>
<td id="S4.T5.2.1.2.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">All</td>
</tr>
<tr id="S4.T5.2.1.3" class="ltx_tr">
<td id="S4.T5.2.1.3.1" class="ltx_td ltx_align_right ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">FRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</td>
<td id="S4.T5.2.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">16.8</td>
<td id="S4.T5.2.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">6.9</td>
<td id="S4.T5.2.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">26.3</td>
<td id="S4.T5.2.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">0.6</td>
<td id="S4.T5.2.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">11.6</td>
<td id="S4.T5.2.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">9.4</td>
<td id="S4.T5.2.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">15.4</td>
<td id="S4.T5.2.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding:2.5pt 3.0pt;">12.4</td>
</tr>
<tr id="S4.T5.2.1.4" class="ltx_tr">
<td id="S4.T5.2.1.4.1" class="ltx_td ltx_align_right ltx_border_r" style="padding:2.5pt 3.0pt;">S-DGOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>
</td>
<td id="S4.T5.2.1.4.2" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">24.4</td>
<td id="S4.T5.2.1.4.3" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">11.6</td>
<td id="S4.T5.2.1.4.4" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">29.5</td>
<td id="S4.T5.2.1.4.5" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.4.5.1" class="ltx_text ltx_font_bold">9.8</span></td>
<td id="S4.T5.2.1.4.6" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">10.5</td>
<td id="S4.T5.2.1.4.7" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.4.7.1" class="ltx_text ltx_font_bold">11.4</span></td>
<td id="S4.T5.2.1.4.8" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">19.2</td>
<td id="S4.T5.2.1.4.9" class="ltx_td ltx_align_center" style="padding:2.5pt 3.0pt;">16.6</td>
</tr>
<tr id="S4.T5.2.1.5" class="ltx_tr">
<td id="S4.T5.2.1.5.1" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t" style="padding:2.5pt 3.0pt;">Ours</td>
<td id="S4.T5.2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.5.2.1" class="ltx_text ltx_font_bold">28.6</span></td>
<td id="S4.T5.2.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.5.3.1" class="ltx_text ltx_font_bold">12.1</span></td>
<td id="S4.T5.2.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.5.4.1" class="ltx_text ltx_font_bold">36.1</span></td>
<td id="S4.T5.2.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">9.2</td>
<td id="S4.T5.2.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.5.6.1" class="ltx_text ltx_font_bold">12.3</span></td>
<td id="S4.T5.2.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;">9.6</td>
<td id="S4.T5.2.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.5.8.1" class="ltx_text ltx_font_bold">22.9</span></td>
<td id="S4.T5.2.1.5.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:2.5pt 3.0pt;"><span id="S4.T5.2.1.5.9.1" class="ltx_text ltx_font_bold">18.7</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.4.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Per-class results on Daytime Clear to Night Rainy.<span id="S4.T5.5.2.1" class="ltx_text ltx_font_medium"> This dataset presents the most challenging scenario, where the low light and rainy conditions obscure the objects. We still perform better than the baseline on most of the categories.
</span></span></figcaption>
</figure>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T6.1.1.2" class="ltx_tr">
<td id="S4.T6.1.1.2.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:3pt;padding-bottom:3pt;" colspan="4" rowspan="2"><span id="S4.T6.1.1.2.1.1" class="ltx_text">Model Component</span></td>
<td id="S4.T6.1.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:3pt;padding-bottom:3pt;" colspan="5">mAP</td>
</tr>
<tr id="S4.T6.1.1.3" class="ltx_tr">
<td id="S4.T6.1.1.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">Source</td>
<td id="S4.T6.1.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;" colspan="4">Target</td>
</tr>
<tr id="S4.T6.1.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">CLIP init</td>
<td id="S4.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;"><math id="S4.T6.1.1.1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S4.T6.1.1.1.1.m1.1a"><msub id="S4.T6.1.1.1.1.m1.1.1" xref="S4.T6.1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T6.1.1.1.1.m1.1.1.2" xref="S4.T6.1.1.1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T6.1.1.1.1.m1.1.1.3" xref="S4.T6.1.1.1.1.m1.1.1.3.cmml"><mi id="S4.T6.1.1.1.1.m1.1.1.3.2" xref="S4.T6.1.1.1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T6.1.1.1.1.m1.1.1.3.1" xref="S4.T6.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.1.1.1.1.m1.1.1.3.3" xref="S4.T6.1.1.1.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T6.1.1.1.1.m1.1.1.3.1a" xref="S4.T6.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.1.1.1.1.m1.1.1.3.4" xref="S4.T6.1.1.1.1.m1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T6.1.1.1.1.m1.1.1.3.1b" xref="S4.T6.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.1.1.1.1.m1.1.1.3.5" xref="S4.T6.1.1.1.1.m1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.T6.1.1.1.1.m1.1.1.3.1c" xref="S4.T6.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.1.1.1.1.m1.1.1.3.6" xref="S4.T6.1.1.1.1.m1.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.1.m1.1b"><apply id="S4.T6.1.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.1.1.1.1.m1.1.1.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T6.1.1.1.1.m1.1.1.2.cmml" xref="S4.T6.1.1.1.1.m1.1.1.2">â„’</ci><apply id="S4.T6.1.1.1.1.m1.1.1.3.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3"><times id="S4.T6.1.1.1.1.m1.1.1.3.1.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.1"></times><ci id="S4.T6.1.1.1.1.m1.1.1.3.2.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T6.1.1.1.1.m1.1.1.3.3.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.3">ğ‘™</ci><ci id="S4.T6.1.1.1.1.m1.1.1.3.4.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.4">ğ‘–</ci><ci id="S4.T6.1.1.1.1.m1.1.1.3.5.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.5">ğ‘</ci><ci id="S4.T6.1.1.1.1.m1.1.1.3.6.cmml" xref="S4.T6.1.1.1.1.m1.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.1.m1.1c">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math></td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">Attn. Pool</td>
<td id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">Sem. Aug</td>
<td id="S4.T6.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">
<span id="S4.T6.1.1.1.5.1" class="ltx_text"></span> <span id="S4.T6.1.1.1.5.2" class="ltx_text">
<span id="S4.T6.1.1.1.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.1.5.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Day</span></span>
<span id="S4.T6.1.1.1.5.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Clear</span></span>
</span></span><span id="S4.T6.1.1.1.5.3" class="ltx_text"></span></td>
<td id="S4.T6.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">
<span id="S4.T6.1.1.1.6.1" class="ltx_text"></span> <span id="S4.T6.1.1.1.6.2" class="ltx_text">
<span id="S4.T6.1.1.1.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.1.6.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Night</span></span>
<span id="S4.T6.1.1.1.6.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.1.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Clear</span></span>
</span></span><span id="S4.T6.1.1.1.6.3" class="ltx_text"></span></td>
<td id="S4.T6.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">
<span id="S4.T6.1.1.1.7.1" class="ltx_text"></span> <span id="S4.T6.1.1.1.7.2" class="ltx_text">
<span id="S4.T6.1.1.1.7.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.1.7.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Dusk</span></span>
<span id="S4.T6.1.1.1.7.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.1.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Rainy</span></span>
</span></span><span id="S4.T6.1.1.1.7.3" class="ltx_text"></span></td>
<td id="S4.T6.1.1.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">
<span id="S4.T6.1.1.1.8.1" class="ltx_text"></span> <span id="S4.T6.1.1.1.8.2" class="ltx_text">
<span id="S4.T6.1.1.1.8.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.1.8.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.1.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Night</span></span>
<span id="S4.T6.1.1.1.8.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.1.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Rainy</span></span>
</span></span><span id="S4.T6.1.1.1.8.3" class="ltx_text"></span></td>
<td id="S4.T6.1.1.1.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">
<span id="S4.T6.1.1.1.9.1" class="ltx_text"></span> <span id="S4.T6.1.1.1.9.2" class="ltx_text">
<span id="S4.T6.1.1.1.9.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T6.1.1.1.9.2.1.1" class="ltx_tr">
<span id="S4.T6.1.1.1.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Day</span></span>
<span id="S4.T6.1.1.1.9.2.1.2" class="ltx_tr">
<span id="S4.T6.1.1.1.9.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">Foggy</span></span>
</span></span><span id="S4.T6.1.1.1.9.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.1.1.4" class="ltx_tr">
<td id="S4.T6.1.1.4.1" class="ltx_td ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.4.2" class="ltx_td ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.4.3" class="ltx_td ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.4.4" class="ltx_td ltx_border_r ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">48.1</td>
<td id="S4.T6.1.1.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">34.4</td>
<td id="S4.T6.1.1.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">26.0</td>
<td id="S4.T6.1.1.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">12.4</td>
<td id="S4.T6.1.1.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:3pt;padding-bottom:3pt;">32.0</td>
</tr>
<tr id="S4.T6.1.1.5" class="ltx_tr">
<td id="S4.T6.1.1.5.1" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.5.2" class="ltx_td" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.5.3" class="ltx_td" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.5.4" class="ltx_td ltx_border_r" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.5.5" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">51.2</td>
<td id="S4.T6.1.1.5.6" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;"><span id="S4.T6.1.1.5.6.1" class="ltx_text ltx_font_bold">37.0</span></td>
<td id="S4.T6.1.1.5.7" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">31.0</td>
<td id="S4.T6.1.1.5.8" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">15.7</td>
<td id="S4.T6.1.1.5.9" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">37.5</td>
</tr>
<tr id="S4.T6.1.1.6" class="ltx_tr">
<td id="S4.T6.1.1.6.1" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.6.2" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.6.3" class="ltx_td" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.6.4" class="ltx_td ltx_border_r" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.6.5" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">50.7</td>
<td id="S4.T6.1.1.6.6" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">36.0</td>
<td id="S4.T6.1.1.6.7" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">31.3</td>
<td id="S4.T6.1.1.6.8" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">16.3</td>
<td id="S4.T6.1.1.6.9" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">36.9</td>
</tr>
<tr id="S4.T6.1.1.7" class="ltx_tr">
<td id="S4.T6.1.1.7.1" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.7.2" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.7.3" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.7.4" class="ltx_td ltx_border_r" style="padding-top:3pt;padding-bottom:3pt;"></td>
<td id="S4.T6.1.1.7.5" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">51.0</td>
<td id="S4.T6.1.1.7.6" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">35.9</td>
<td id="S4.T6.1.1.7.7" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">31.3</td>
<td id="S4.T6.1.1.7.8" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">16.7</td>
<td id="S4.T6.1.1.7.9" class="ltx_td ltx_align_center" style="padding-top:3pt;padding-bottom:3pt;">37.7</td>
</tr>
<tr id="S4.T6.1.1.8" class="ltx_tr">
<td id="S4.T6.1.1.8.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.8.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.8.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-top:3pt;padding-bottom:3pt;">âœ“</td>
<td id="S4.T6.1.1.8.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;">51.3</td>
<td id="S4.T6.1.1.8.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;">36.9</td>
<td id="S4.T6.1.1.8.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;"><span id="S4.T6.1.1.8.7.1" class="ltx_text ltx_font_bold">32.3</span></td>
<td id="S4.T6.1.1.8.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;"><span id="S4.T6.1.1.8.8.1" class="ltx_text ltx_font_bold">18.7</span></td>
<td id="S4.T6.1.1.8.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-top:3pt;padding-bottom:3pt;"><span id="S4.T6.1.1.8.9.1" class="ltx_text ltx_font_bold">38.5</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.6.2.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ablation study.<span id="S4.T6.3.1.1" class="ltx_text ltx_font_medium"> We study the influence of five different components of our approach: the backbone weight initialization strategy, the classification loss, the attention pooling, and the semantic augmentation. When those five components are removed (first row of the table) the model is equivalent to the standard FasterRCNN. Initializing the detector with CLIP weights (second row) largely improves the generalization performance; on its own it already outperforms Single-DGOD (penultimate row of <a href="#S4.T1" title="In 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>) on most of the datasets, hence suggesting that CLIP has better generalizability than ImageNet pre-trained weights. Combining this with the text embedding-based loss <math id="S4.T6.3.1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S4.T6.3.1.1.m1.1b"><msub id="S4.T6.3.1.1.m1.1.1" xref="S4.T6.3.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.T6.3.1.1.m1.1.1.2" xref="S4.T6.3.1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.T6.3.1.1.m1.1.1.3" xref="S4.T6.3.1.1.m1.1.1.3.cmml"><mi id="S4.T6.3.1.1.m1.1.1.3.2" xref="S4.T6.3.1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.T6.3.1.1.m1.1.1.3.1" xref="S4.T6.3.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.3.1.1.m1.1.1.3.3" xref="S4.T6.3.1.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.T6.3.1.1.m1.1.1.3.1b" xref="S4.T6.3.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.3.1.1.m1.1.1.3.4" xref="S4.T6.3.1.1.m1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.T6.3.1.1.m1.1.1.3.1c" xref="S4.T6.3.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.3.1.1.m1.1.1.3.5" xref="S4.T6.3.1.1.m1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.T6.3.1.1.m1.1.1.3.1d" xref="S4.T6.3.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.T6.3.1.1.m1.1.1.3.6" xref="S4.T6.3.1.1.m1.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.T6.3.1.1.m1.1c"><apply id="S4.T6.3.1.1.m1.1.1.cmml" xref="S4.T6.3.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T6.3.1.1.m1.1.1.1.cmml" xref="S4.T6.3.1.1.m1.1.1">subscript</csymbol><ci id="S4.T6.3.1.1.m1.1.1.2.cmml" xref="S4.T6.3.1.1.m1.1.1.2">â„’</ci><apply id="S4.T6.3.1.1.m1.1.1.3.cmml" xref="S4.T6.3.1.1.m1.1.1.3"><times id="S4.T6.3.1.1.m1.1.1.3.1.cmml" xref="S4.T6.3.1.1.m1.1.1.3.1"></times><ci id="S4.T6.3.1.1.m1.1.1.3.2.cmml" xref="S4.T6.3.1.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.T6.3.1.1.m1.1.1.3.3.cmml" xref="S4.T6.3.1.1.m1.1.1.3.3">ğ‘™</ci><ci id="S4.T6.3.1.1.m1.1.1.3.4.cmml" xref="S4.T6.3.1.1.m1.1.1.3.4">ğ‘–</ci><ci id="S4.T6.3.1.1.m1.1.1.3.5.cmml" xref="S4.T6.3.1.1.m1.1.1.3.5">ğ‘</ci><ci id="S4.T6.3.1.1.m1.1.1.3.6.cmml" xref="S4.T6.3.1.1.m1.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.1.1.m1.1d">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math> (third row) improves the results on the challenging scenarios of dusk rainy and night rainy, but has a detrimental effect for the other weather conditions. Adding attention pooling to the architecture (fourth row) helps to mitigate these detrimental effects as it brings the visual features closer to the joint embedding space. Finally, the best results are obtained when the semantic augmentation is added (last row), greatly helping with adverse weather, rainy and foggy, scenarios.
</span></span></figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Daytime Clear to Night Clear.</h4>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.1" class="ltx_p">The Night Clear dataset shows a challenging night driving scene under severe low-light conditions. InÂ <a href="#S4.T4" title="In Daytime Clear to Dusk Rainy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>, we show that while being comparable to Single-DGOD, we bring in a larger improvement in the <em id="S4.SS3.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">car</em> and <em id="S4.SS3.SSS0.Px3.p1.1.2" class="ltx_emph ltx_font_italic">person</em> categories. Night scenes are particularly challenging as the low light condition leads to more confusion among visually closer categories such as <em id="S4.SS3.SSS0.Px3.p1.1.3" class="ltx_emph ltx_font_italic">bus</em> and <em id="S4.SS3.SSS0.Px3.p1.1.4" class="ltx_emph ltx_font_italic">truck</em>.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Daytime Clear to Night Rainy.</h4>

<div id="S4.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px4.p1.1" class="ltx_p">This is the most challenging scenario where dark night conditions are exacerbated by patterns occurring due to rain. <a href="#S4.T5" title="In Daytime Clear to Dusk Rainy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a> shows consistent improvement by our approach for most of the classes. The <em id="S4.SS3.SSS0.Px4.p1.1.1" class="ltx_emph ltx_font_italic">car</em> class sees the biggest improvement with an increase in AP of more than 22% compared to Single-DGOD. The lower performance of the class <em id="S4.SS3.SSS0.Px4.p1.1.2" class="ltx_emph ltx_font_italic">rider</em> can be attributed to an increase in the confusion between the visually similar <em id="S4.SS3.SSS0.Px4.p1.1.3" class="ltx_emph ltx_font_italic">person</em> and <em id="S4.SS3.SSS0.Px4.p1.1.4" class="ltx_emph ltx_font_italic">rider</em> classes under adverse conditions.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p">To understand how each element of the proposed method contributes to the overall performance, we conduct an ablation study. We test five individual components of our model. Specifically, we remove semantic augmentation, replace CLIP attention pooling in <math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{V}^{b}" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><msup id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml">ğ’±</mi><mi id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">ğ’±</ci><ci id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathcal{V}^{b}</annotation></semantics></math> with average pooling, replace <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><msub id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.2.m2.1.1.2" xref="S4.SS4.p1.2.m2.1.1.2.cmml">â„’</mi><mrow id="S4.SS4.p1.2.m2.1.1.3" xref="S4.SS4.p1.2.m2.1.1.3.cmml"><mi id="S4.SS4.p1.2.m2.1.1.3.2" xref="S4.SS4.p1.2.m2.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.p1.2.m2.1.1.3.3" xref="S4.SS4.p1.2.m2.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1a" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.p1.2.m2.1.1.3.4" xref="S4.SS4.p1.2.m2.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1b" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.p1.2.m2.1.1.3.5" xref="S4.SS4.p1.2.m2.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p1.2.m2.1.1.3.1c" xref="S4.SS4.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.p1.2.m2.1.1.3.6" xref="S4.SS4.p1.2.m2.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><apply id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2">â„’</ci><apply id="S4.SS4.p1.2.m2.1.1.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3"><times id="S4.SS4.p1.2.m2.1.1.3.1.cmml" xref="S4.SS4.p1.2.m2.1.1.3.1"></times><ci id="S4.SS4.p1.2.m2.1.1.3.2.cmml" xref="S4.SS4.p1.2.m2.1.1.3.2">ğ‘</ci><ci id="S4.SS4.p1.2.m2.1.1.3.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3.3">ğ‘™</ci><ci id="S4.SS4.p1.2.m2.1.1.3.4.cmml" xref="S4.SS4.p1.2.m2.1.1.3.4">ğ‘–</ci><ci id="S4.SS4.p1.2.m2.1.1.3.5.cmml" xref="S4.SS4.p1.2.m2.1.1.3.5">ğ‘</ci><ci id="S4.SS4.p1.2.m2.1.1.3.6.cmml" xref="S4.SS4.p1.2.m2.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math> with the FasterRCNN classification loss, and change the weight initialization from the CLIP model to an ImageNet classification model. Removing those five components turns our model back into the standard FasterRCNN. The ablation study results are provided in <a href="#S4.T6" title="In Daytime Clear to Dusk Rainy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a> and discussed below.</p>
</div>
<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">CLIP initialization.</h4>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px1.p1.1" class="ltx_p">When the FasterRCNN backbone <math id="S4.SS4.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S4.SS4.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px1.p1.1.m1.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS4.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px1.p1.1.m1.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px1.p1.1.m1.1c">\mathcal{V}</annotation></semantics></math> is initialized with CLIP pre-trained weights, the model performance consistently increases both in the in-domain and out-of-domain scenarios, as shown in the second row of <a href="#S4.T6" title="In Daytime Clear to Dusk Rainy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a>. This setting itself already outperforms Single-DGOD (penultimate row of <a href="#S4.T1" title="In 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>). This goes to show that, for the generalization task, model weight initialization plays a crucial role. We further improve this performance with semantic augmentations.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Attention pooling and <math id="S4.SS4.SSS0.Px2.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S4.SS4.SSS0.Px2.1.m1.1b"><msub id="S4.SS4.SSS0.Px2.1.m1.1.1" xref="S4.SS4.SSS0.Px2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.SSS0.Px2.1.m1.1.1.2" xref="S4.SS4.SSS0.Px2.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.SS4.SSS0.Px2.1.m1.1.1.3" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.cmml"><mi id="S4.SS4.SSS0.Px2.1.m1.1.1.3.2" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.1.m1.1.1.3.1" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.1.m1.1.1.3.3" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.1.m1.1.1.3.1b" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.1.m1.1.1.3.4" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.1.m1.1.1.3.1c" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.1.m1.1.1.3.5" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.1.m1.1.1.3.1d" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.1.m1.1.1.3.6" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.1.m1.1c"><apply id="S4.SS4.SSS0.Px2.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.1.m1.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.2">â„’</ci><apply id="S4.SS4.SSS0.Px2.1.m1.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3"><times id="S4.SS4.SSS0.Px2.1.m1.1.1.3.1.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.1"></times><ci id="S4.SS4.SSS0.Px2.1.m1.1.1.3.2.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.SS4.SSS0.Px2.1.m1.1.1.3.3.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.3">ğ‘™</ci><ci id="S4.SS4.SSS0.Px2.1.m1.1.1.3.4.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.4">ğ‘–</ci><ci id="S4.SS4.SSS0.Px2.1.m1.1.1.3.5.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.5">ğ‘</ci><ci id="S4.SS4.SSS0.Px2.1.m1.1.1.3.6.cmml" xref="S4.SS4.SSS0.Px2.1.m1.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.1.m1.1d">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math>.</h4>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p1.3" class="ltx_p">Next we test the impact of the text-embedding-based loss <math id="S4.SS4.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS4.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1a" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.4" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1b" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.5" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1c" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.6" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2">â„’</ci><apply id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3"><times id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.1"></times><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.2">ğ‘</ci><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.3">ğ‘™</ci><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.4.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.4">ğ‘–</ci><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.5.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.5">ğ‘</ci><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.6.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.1.m1.1c">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math> for classification.
As visible in the third row of <a href="#S4.T6" title="In Daytime Clear to Dusk Rainy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a>, when combined with CLIP initialization, it improves the generalization performance for the rainy scenarios, but degrades it for the other ones. Replacing average pooling in <math id="S4.SS4.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{V}^{b}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.2.m2.1a"><msup id="S4.SS4.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1.2.cmml">ğ’±</mi><mi id="S4.SS4.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1.3.cmml">b</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS4.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1.2">ğ’±</ci><ci id="S4.SS4.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.2.m2.1c">\mathcal{V}^{b}</annotation></semantics></math> with CLIP attention pooling helps to mitigate the detrimental effect of <math id="S4.SS4.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}_{clip\mhyphen t}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.3.m3.1a"><msub id="S4.SS4.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.2" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.2.cmml">â„’</mi><mrow id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.2" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.3" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1a" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.4" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1b" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.5" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1c" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1.cmml">â€‹</mo><mi id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.6" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.6.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.3.m3.1b"><apply id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.2">â„’</ci><apply id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3"><times id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.1"></times><ci id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.2">ğ‘</ci><ci id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.3">ğ‘™</ci><ci id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.4.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.4">ğ‘–</ci><ci id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.5.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.5">ğ‘</ci><ci id="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.6.cmml" xref="S4.SS4.SSS0.Px2.p1.3.m3.1.1.3.6">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.3.m3.1c">\mathcal{L}_{clip\mhyphen t}</annotation></semantics></math> and exhibits consistent improvement on all datasets.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Semantic augmentation.</h4>

<div id="S4.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px3.p1.1" class="ltx_p">Finally, adding semantic augmentation gives us the best results, as shown in the last row of <a href="#S4.T6" title="In Daytime Clear to Dusk Rainy. â€£ 4.3 Comparison with the State of the Art â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a>.
Exposing the visual encoder <math id="S4.SS4.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S4.SS4.SSS0.Px3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.cmml">ğ’±</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px3.p1.1.m1.1b"><ci id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1">ğ’±</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px3.p1.1.m1.1c">\mathcal{V}</annotation></semantics></math> to targeted semantic augmentations helps the overall model to better generalize when exposed to new domains sharing similarity with the augmentations.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Additional Analyses</h3>

<section id="S4.SS5.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Study of semantic augmentation.</h4>

<div id="S4.SS5.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS5.SSS0.Px1.p1.2" class="ltx_p">Our proposed method involves translating feature maps by semantic augmentations learned using plausible domain prompts. To further study the utility of our approach, we replace the augmentation strategy in our training pipeline with (a) <span id="S4.SS5.SSS0.Px1.p1.2.1" class="ltx_text ltx_font_bold">no-aug</span>: no augmentation; (b) <span id="S4.SS5.SSS0.Px1.p1.2.2" class="ltx_text ltx_font_bold">random</span>: <math id="S4.SS5.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS5.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS5.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS5.SSS0.Px1.p1.1.m1.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS5.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS5.SSS0.Px1.p1.1.m1.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px1.p1.1.m1.1c">\mathcal{A}</annotation></semantics></math> is initialized with a normal distribution; (c) <span id="S4.SS5.SSS0.Px1.p1.2.3" class="ltx_text ltx_font_bold">clip-random</span>: we define <math id="S4.SS5.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{P}^{t}" display="inline"><semantics id="S4.SS5.SSS0.Px1.p1.2.m2.1a"><msup id="S4.SS5.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS5.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1.2.cmml">ğ’«</mi><mi id="S4.SS5.SSS0.Px1.p1.2.m2.1.1.3" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS5.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS5.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS5.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1.2">ğ’«</ci><ci id="S4.SS5.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S4.SS5.SSS0.Px1.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px1.p1.2.m2.1c">\mathcal{P}^{t}</annotation></semantics></math> with concepts that are not specific to <em id="S4.SS5.SSS0.Px1.p1.2.4" class="ltx_emph ltx_font_italic">weather</em>. We generate prompts with a template <span id="S4.SS5.SSS0.Px1.p1.2.5" class="ltx_text ltx_font_typewriter">an image of {word}</span>, where the words are <em id="S4.SS5.SSS0.Px1.p1.2.6" class="ltx_emph ltx_font_italic">desert</em>, <em id="S4.SS5.SSS0.Px1.p1.2.7" class="ltx_emph ltx_font_italic">ocean</em>, <em id="S4.SS5.SSS0.Px1.p1.2.8" class="ltx_emph ltx_font_italic">forest</em>, and <em id="S4.SS5.SSS0.Px1.p1.2.9" class="ltx_emph ltx_font_italic">mountain</em>. <a href="#S4.T7" title="In Study of semantic augmentation. â€£ 4.5 Additional Analyses â€£ 4 Experiments â€£ CLIP the Gap: A Single Domain Generalization Approach for Object Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">7</span></a> illustrates the importance of the semantics in our augmentation strategy. The <span id="S4.SS5.SSS0.Px1.p1.2.10" class="ltx_text ltx_font_bold">random</span> augmentation performs worse than the <span id="S4.SS5.SSS0.Px1.p1.2.11" class="ltx_text ltx_font_bold">no-aug</span> strategy. <span id="S4.SS5.SSS0.Px1.p1.2.12" class="ltx_text ltx_font_bold">clip-random</span> is comparable to <span id="S4.SS5.SSS0.Px1.p1.2.13" class="ltx_text ltx_font_bold">no-aug</span> and doesnâ€™t show any consistent trend but is mostly better than <span id="S4.SS5.SSS0.Px1.p1.2.14" class="ltx_text ltx_font_bold">random</span>. Our semantic augmentation strategy provides a consistent improvement over <span id="S4.SS5.SSS0.Px1.p1.2.15" class="ltx_text ltx_font_bold">no-aug</span> because the translations are performed with prompts from the relevant <em id="S4.SS5.SSS0.Px1.p1.2.16" class="ltx_emph ltx_font_italic">weather</em> concept.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<table id="S4.T7.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T7.2.1" class="ltx_tr">
<td id="S4.T7.2.1.1" class="ltx_td ltx_border_tt" style="padding:3pt 4.0pt;"></td>
<td id="S4.T7.2.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding:3pt 4.0pt;" colspan="5">mAP</td>
</tr>
<tr id="S4.T7.2.2" class="ltx_tr">
<td id="S4.T7.2.2.1" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">Aug. Type</td>
<td id="S4.T7.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:3pt 4.0pt;">
<span id="S4.T7.2.2.2.1" class="ltx_text"></span> <span id="S4.T7.2.2.2.2" class="ltx_text">
<span id="S4.T7.2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.2.2.2.2.1.1" class="ltx_tr">
<span id="S4.T7.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Day</span></span>
<span id="S4.T7.2.2.2.2.1.2" class="ltx_tr">
<span id="S4.T7.2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Clear</span></span>
</span></span><span id="S4.T7.2.2.2.3" class="ltx_text"></span></td>
<td id="S4.T7.2.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">
<span id="S4.T7.2.2.3.1" class="ltx_text"></span> <span id="S4.T7.2.2.3.2" class="ltx_text">
<span id="S4.T7.2.2.3.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.2.2.3.2.1.1" class="ltx_tr">
<span id="S4.T7.2.2.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Night</span></span>
<span id="S4.T7.2.2.3.2.1.2" class="ltx_tr">
<span id="S4.T7.2.2.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Clear</span></span>
</span></span><span id="S4.T7.2.2.3.3" class="ltx_text"></span></td>
<td id="S4.T7.2.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">
<span id="S4.T7.2.2.4.1" class="ltx_text"></span> <span id="S4.T7.2.2.4.2" class="ltx_text">
<span id="S4.T7.2.2.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.2.2.4.2.1.1" class="ltx_tr">
<span id="S4.T7.2.2.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Dusk</span></span>
<span id="S4.T7.2.2.4.2.1.2" class="ltx_tr">
<span id="S4.T7.2.2.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Rainy</span></span>
</span></span><span id="S4.T7.2.2.4.3" class="ltx_text"></span></td>
<td id="S4.T7.2.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">
<span id="S4.T7.2.2.5.1" class="ltx_text"></span> <span id="S4.T7.2.2.5.2" class="ltx_text">
<span id="S4.T7.2.2.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.2.2.5.2.1.1" class="ltx_tr">
<span id="S4.T7.2.2.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Night</span></span>
<span id="S4.T7.2.2.5.2.1.2" class="ltx_tr">
<span id="S4.T7.2.2.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Rainy</span></span>
</span></span><span id="S4.T7.2.2.5.3" class="ltx_text"></span></td>
<td id="S4.T7.2.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">
<span id="S4.T7.2.2.6.1" class="ltx_text"></span> <span id="S4.T7.2.2.6.2" class="ltx_text">
<span id="S4.T7.2.2.6.2.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T7.2.2.6.2.1.1" class="ltx_tr">
<span id="S4.T7.2.2.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Day</span></span>
<span id="S4.T7.2.2.6.2.1.2" class="ltx_tr">
<span id="S4.T7.2.2.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding:3pt 4.0pt;">Foggy</span></span>
</span></span><span id="S4.T7.2.2.6.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T7.2.3" class="ltx_tr">
<td id="S4.T7.2.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:3pt 4.0pt;">no-aug.</td>
<td id="S4.T7.2.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding:3pt 4.0pt;">51.0</td>
<td id="S4.T7.2.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">35.9</td>
<td id="S4.T7.2.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">31.3</td>
<td id="S4.T7.2.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">16.7</td>
<td id="S4.T7.2.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding:3pt 4.0pt;">37.7</td>
</tr>
<tr id="S4.T7.2.4" class="ltx_tr">
<td id="S4.T7.2.4.1" class="ltx_td ltx_align_center ltx_border_r" style="padding:3pt 4.0pt;">random</td>
<td id="S4.T7.2.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:3pt 4.0pt;">51.2</td>
<td id="S4.T7.2.4.3" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">36.0</td>
<td id="S4.T7.2.4.4" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">30.4</td>
<td id="S4.T7.2.4.5" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">15.3</td>
<td id="S4.T7.2.4.6" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">37.3</td>
</tr>
<tr id="S4.T7.2.5" class="ltx_tr">
<td id="S4.T7.2.5.1" class="ltx_td ltx_align_center ltx_border_r" style="padding:3pt 4.0pt;">clip-random</td>
<td id="S4.T7.2.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding:3pt 4.0pt;">51.5</td>
<td id="S4.T7.2.5.3" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">36.4</td>
<td id="S4.T7.2.5.4" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">30.2</td>
<td id="S4.T7.2.5.5" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">15.9</td>
<td id="S4.T7.2.5.6" class="ltx_td ltx_align_center" style="padding:3pt 4.0pt;">37.9</td>
</tr>
<tr id="S4.T7.2.6" class="ltx_tr">
<td id="S4.T7.2.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding:3pt 4.0pt;">Ours w/ seg.aug</td>
<td id="S4.T7.2.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding:3pt 4.0pt;">51.3</td>
<td id="S4.T7.2.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:3pt 4.0pt;"><span id="S4.T7.2.6.3.1" class="ltx_text ltx_font_bold">36.9</span></td>
<td id="S4.T7.2.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:3pt 4.0pt;"><span id="S4.T7.2.6.4.1" class="ltx_text ltx_font_bold">32.3</span></td>
<td id="S4.T7.2.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:3pt 4.0pt;"><span id="S4.T7.2.6.5.1" class="ltx_text ltx_font_bold">18.7</span></td>
<td id="S4.T7.2.6.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding:3pt 4.0pt;"><span id="S4.T7.2.6.6.1" class="ltx_text ltx_font_bold">38.5</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T7.8.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T7.9.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Semantic Augmentation.<span id="S4.T7.9.2.1" class="ltx_text ltx_font_medium"> Our semantic augmentation consistently outperforms other augmentation strategies. While <em id="S4.T7.9.2.1.1" class="ltx_emph ltx_font_italic">random</em> augmentations are worse than <em id="S4.T7.9.2.1.2" class="ltx_emph ltx_font_italic">no-aug.</em>, <em id="S4.T7.9.2.1.3" class="ltx_emph ltx_font_italic">clip-random</em> is comparable to <em id="S4.T7.9.2.1.4" class="ltx_emph ltx_font_italic">no-aug.</em>. Only when we give relevant prompts, there is a consistent improvement across datasets.
</span></span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Limitations</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our method augments visual features using textual prompts. To generate these prompts, it is assumed that some information about the domain gap is known. In our experiments, we assumed that the domain gap was due to changes in weather and daytime conditions. In practice, we only used the word <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">weather</em> and <em id="S5.p1.1.2" class="ltx_emph ltx_font_italic">time of the day</em> to derive all the prompts used in our augmentation; nonetheless, some extra information was used. In most applications, however, the domain gap can be known in advance, and providing a few keywords characterizing it shouldnâ€™t be an issue. In the rare cases where no information can be known, our approach still has the potential to be used by using multiple broad concept keywords such as weather, ambiance, or location.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We have proposed an approach to improving the generalization of object detectors on <em id="S6.p1.1.1" class="ltx_emph ltx_font_italic">unseen</em> target domains. Our approach fundamentally departs from existing method by leveraging a pre-trained vision-language model, CLIP, to help the detector to generalize. Specifically, we have exploited textual prompts to develop a semantic augmentation strategy that alters image embeddings so that they reflect potential target domains, and to design a text-based image classifier. We have shown that our approach outperforms the state of the art on four adverse-weather target datasets. In future work, we plan to extend our approach to learning the prompts to further improve generalization.</p>
</div>
<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Acknowledgment:</h4>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">This work was funded in part by the Swiss National Science Foundation and the Swiss Innovation Agency (Innosuisse) via the BRIDGE Discovery grant 40B2-0 194729.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Yogesh Balaji, Swami Sankaranarayanan, and Rama Chellappa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Metareg: Towards domain generalization using meta-regularization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 31, 2018.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Mathilde Caron, Hugo Touvron, Ishan Misra, HervÃ© JÃ©gou, Julien Mairal,
Piotr Bojanowski, and Armand Joulin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Emerging properties in self-supervised vision transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib2.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib2.5.3" class="ltx_text" style="font-size:90%;">, pages 9650â€“9660, 2021.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Chaoqi Chen, Zebiao Zheng, Xinghao Ding, Yue Huang, and Qi Dou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Harmonizing transferability and discriminability for adapting object
detectors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 8869â€“8878, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Xinlei Chen and Kaiming He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Exploring simple siamese representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 15750â€“15758, 2021.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Yuhua Chen, Wen Li, Christos Sakaridis, Dengxin Dai, and Luc VanÂ Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Domain adaptive faster r-cnn for object detection in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 3339â€“3348, 2018.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Sungha Choi, Sanghun Jung, Huiwon Yun, JoanneÂ T Kim, Seungryong Kim, and Jaegul
Choo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Robustnet: Improving domain generalization in urban-scene
segmentation via instance selective whitening.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 11580â€“11590, 2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler,
Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">The cityscapes dataset for semantic urban scene understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 3213â€“3223, 2016.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Jinhong Deng, Wen Li, Yuhua Chen, and Lixin Duan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Unbiased mean teacher for cross-domain object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, pages 4091â€“4101, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Karan Desai and Justin Johnson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Virtex: Learning visual representations from textual annotations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 11162â€“11173, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Qi Dou, Daniel CoelhoÂ de Castro, Konstantinos Kamnitsas, and Ben Glocker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Domain generalization via model-agnostic learning of semantic
features.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 32, 2019.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Martin Engilberge, Louis Chevallier, Patrick PÃ©rez, and Matthieu Cord.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Finding beans in burgers: Deep semantic-visual embedding with
localization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 3984â€“3993, 2018.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Fartash Faghri, DavidÂ J Fleet, JamieÂ Ryan Kiros, and Sanja Fidler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Vse++: Improving visual-semantic embeddings with hard negatives.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1707.05612</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Xinjie Fan, Qifei Wang, Junjie Ke, Feng Yang, Boqing Gong, and Mingyuan Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Adversarially adaptive normalization for single domain
generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 8208â€“8217, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Andrea Frome, GregÂ S Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Marcâ€™Aurelio
Ranzato, and Tomas Mikolov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Devise: A deep visual-semantic embedding model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 26, 2013.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, FranÃ§ois Laviolette, Mario Marchand, and Victor Lempitsky.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Domain-adversarial training of neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The journal of machine learning research</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 17(1):2096â€“2030,
2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, and Yin Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary object detection via vision and language knowledge
distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.13921</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Mahmoud Hassaballah, MouradÂ A Kenk, Khan Muhammad, and Shervin Minaee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Vehicle detection and tracking in adverse weather using a deep
learning framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on intelligent transportation systems</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">,
22(7):4230â€“4242, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Momentum contrast for unsupervised visual representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 9729â€“9738, 2020.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Georgia Gkioxari, Piotr DollÃ¡r, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Mask r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 2961â€“2969, 2017.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 770â€“778, 2016.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Lei Huang, Yi Zhou, Fan Zhu, Li Liu, and Ling Shao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Iterative normalization: Beyond standardization towards efficient
whitening.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 4874â€“4883, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Kyungyul Kim, ByeongMoon Ji, Doyoung Yoon, and Sangheum Hwang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Self-knowledge distillation: A simple way for better generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2006.12000</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 3, 2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
DiederikÂ P Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1412.6980</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Ryan Kiros, Ruslan Salakhutdinov, and RichardÂ S Zemel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Unifying visual-semantic embeddings with multimodal neural language
models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1411.2539</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Learning to generalize: Meta-learning for domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI conference on artificial
intelligence</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, volumeÂ 32, 2018.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, and TimothyÂ M
Hospedales.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Episodic training for domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 1446â€“1455, 2019.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Gen Li, Nan Duan, Yuejian Fang, Ming Gong, Daxin Jiang, and Ming Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Unicoder-vl: A universal encoder for vision and language by
cross-modal pre-training. arxiv e-prints, page.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1908.06066</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Haoliang Li, SinnoÂ Jialin Pan, Shiqi Wang, and AlexÂ C Kot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Domain generalization with adversarial feature learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, pages 5400â€“5409, 2018.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
LiunianÂ Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li,
Yiwu Zhong, Lijuan Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Grounded language-image pre-training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 10965â€“10975, 2022.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Yu-Jhe Li, Xiaoliang Dai, Chih-Yao Ma, Yen-Cheng Liu, Kan Chen, Bichen Wu,
Zijian He, Kris Kitani, and Peter Vajda.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Cross-domain adaptive teacher for object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Efficient estimation of word representations in vector space.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1301.3781</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Xingang Pan, Ping Luo, Jianping Shi, and Xiaoou Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Two at once: Enhancing learning and generalization capacities via
ibn-net.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 464â€“479, 2018.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Xingang Pan, Xiaohang Zhan, Jianping Shi, Xiaoou Tang, and Ping Luo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Switchable whitening for deep representation learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">, pages 1863â€“1871, 2019.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Jeffrey Pennington, Richard Socher, and ChristopherÂ D Manning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Glove: Global vectors for word representation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2014 conference on empirical methods in
natural language processing (EMNLP)</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 1532â€“1543, 2014.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Fengchun Qiao, Long Zhao, and Xi Peng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Learning to learn single domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 12556â€“12565, 2020.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Learning transferable visual models from natural language
supervision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages
8748â€“8763. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
Sutskever, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Language models are unsupervised multitask learners.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">OpenAI blog</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 1(8):9, 2019.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Hierarchical text-conditional image generation with clip latents.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2204.06125</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Hanoona Rasheed, Muhammad Maaz, MuhammadÂ Uzair Khattak, Salman Khan, and
FahadÂ Shahbaz Khan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Bridging the gap between object and image-level representations for
open-vocabulary detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2207.03482</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Faster r-cnn: towards real-time object detection with region proposal
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">,
39(6):1137â€“1149, 2016.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, and Kate Saenko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Strong-weak distribution alignment for adaptive object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, pages 6956â€“6965, 2019.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Christos Sakaridis, Dengxin Dai, and Luc VanÂ Gool.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Semantic foggy scene understanding with synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Computer Vision</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, 126(9):973â€“992,
2018.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Zhiqiang Shen, Harsh Maheshwari, Weichen Yao, and Marios Savvides.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Scl: Towards accurate domain adaptive object detection via gradient
detach based stacked complementary losses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1911.02559</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Princeton University.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">About wordnet.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://wordnet.princeton.edu" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://wordnet.princeton.edu</a><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">, 2010.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Riccardo Volpi, Hongseok Namkoong, Ozan Sener, JohnÂ C Duchi, Vittorio Murino,
and Silvio Savarese.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Generalizing to unseen domains via adversarial data augmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib45.4.2" class="ltx_text" style="font-size:90%;">, 31, 2018.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Vibashan VS, Vikram Gupta, Poojan Oza, VishwanathÂ A Sindagi, and VishalÂ M
Patel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Mega-cda: Memory guided attention for category-aware unsupervised
domain adaptive object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">, pages 4516â€“4526, 2021.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Xudong Wang, Zhaowei Cai, Dashan Gao, and Nuno Vasconcelos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Towards universal object detection by domain attention.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, pages 7289â€“7298, 2019.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Zijian Wang, Yadan Luo, Ruihong Qiu, Zi Huang, and Mahsa Baktashmotlagh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Learning to diversify for single domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib48.5.3" class="ltx_text" style="font-size:90%;">, pages 834â€“843, 2021.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Aming Wu and Cheng Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Single-domain generalized object detection in urban scene via
cyclic-disentangled self-distillation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib49.5.3" class="ltx_text" style="font-size:90%;">, pages 847â€“856, 2022.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Aming Wu, Rui Liu, Yahong Han, Linchao Zhu, and Yi Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Vector-decomposed disentanglement for domain-invariant object
detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, pages 9342â€“9351, 2021.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Detectron2.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/facebookresearch/detectron2" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/facebookresearch/detectron2</a><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu,
Vashisht Madhavan, and Trevor Darrell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Bdd100k: A diverse driving dataset for heterogeneous multitask
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">, pages 2636â€“2645, 2020.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Alireza Zareian, KevinÂ Dela Rosa, DerekÂ Hao Hu, and Shih-Fu Chang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Open-vocabulary object detection using captions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib53.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib53.5.3" class="ltx_text" style="font-size:90%;">, pages 14393â€“14402, 2021.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Haotian Zhang, Pengchuan Zhang, Xiaowei Hu, Yen-Chun Chen, LiunianÂ Harold Li,
Xiyang Dai, Lijuan Wang, Lu Yuan, Jenq-Neng Hwang, and Jianfeng Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Glipv2: Unifying localization and vision-language understanding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2206.05836</span><span id="bib.bib54.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Yuhao Zhang, Hang Jiang, Yasuhide Miura, ChristopherÂ D Manning, and CurtisÂ P
Langlotz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Contrastive learning of medical visual representations from paired
images and text.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.00747</span><span id="bib.bib55.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Yabin Zhang, Minghan Li, Ruihuang Li, Kui Jia, and Lei Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Exact feature distribution matching for arbitrary style transfer and
domain generalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, pages 8035â€“8045, 2022.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Shanshan Zhao, Mingming Gong, Tongliang Liu, Huan Fu, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Domain generalization via entropy regularization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib57.4.2" class="ltx_text" style="font-size:90%;">,
33:16096â€“16107, 2020.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Xinge Zhu, Jiangmiao Pang, Ceyuan Yang, Jianping Shi, and Dahua Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Adapting object detectors via selective cross-domain alignment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib58.5.3" class="ltx_text" style="font-size:90%;">, pages 687â€“696, 2019.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2301.05498" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2301.05499" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2301.05499">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2301.05499" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2301.05500" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 07:21:13 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
