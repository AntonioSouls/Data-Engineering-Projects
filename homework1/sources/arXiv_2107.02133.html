<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2107.02133] Test-Time Personalization with a Transformer for Human Pose Estimation</title><meta property="og:description" content="We propose to personalize a 2D human pose estimator given a set of test images of a person without using any manual annotations. While there is a significant advancement in human pose estimation, it is still very challâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Test-Time Personalization with a Transformer for Human Pose Estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Test-Time Personalization with a Transformer for Human Pose Estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2107.02133">

<!--Generated on Sat Mar  2 04:35:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Test-Time Personalization with a Transformer for Human Pose Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yizhuo Li 
<br class="ltx_break">Shanghai Jiao Tong University 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">liyizhuo@sjtu.edu.cn</span> 
<br class="ltx_break">&amp;Miao Hao<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> 
<br class="ltx_break">UC San Diego
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">mhao@ucsd.edu</span> 
<br class="ltx_break">Zonglin Di<span id="footnotex2" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> 
<br class="ltx_break">UC San Diego 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">zodi@ucsd.edu</span> 
<br class="ltx_break">&amp;Nitesh B. Gundavarapu 
<br class="ltx_break">UC San Diego 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_typewriter">nbgundav@ucsd.edu</span> 
<br class="ltx_break">&amp;Xiaolong Wang 
<br class="ltx_break">UC San Diego 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">xiw012@ucsd.edu</span> 
<br class="ltx_break">
</span><span class="ltx_author_notes">Equal contribution</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">We propose to personalize a 2D human pose estimator given a set of test images of a person without using any manual annotations. While there is a significant advancement in human pose estimation, it is still very challenging for a model to generalize to different unknown environments and unseen persons. Instead of using a fixed model for every test case, we adapt our pose estimator during test time to exploit person-specific information. We first train our model on diverse data with both a supervised and a self-supervised pose estimation objectives jointly. We use a Transformer model to build a transformation between the self-supervised keypoints and the supervised keypoints. During test time, we personalize and adapt our model by fine-tuning with the self-supervised objective. The pose is then improved by transforming the updated self-supervised keypoints. We experiment with multiple datasets and show significant improvements on pose estimations with our self-supervised personalization. Project page with code is available at <a target="_blank" href="https://liyz15.github.io/TTP/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://liyz15.github.io/TTP/</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent years have witnessed a large advancement in human pose estimation. A lot of efforts have been spent on learning a generic deep network on large-scale human pose datasets to handle diverse appearance changesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Instead of learning a generic model, another line of research is to personalize and customize human pose estimation for a single subjectÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. For a specific person, we can usually have a long video (e.g., instructional videos, news videos) or multiple photos from personal devices. With these data, we can adapt the model to capture the person-specific features for improving pose estimation and handling occlusion and unusual poses. However, the cost of labeling large-scale data for just one person is high and unrealistic.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2107.02133/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Test-Time Personalization<span id="S1.F1.4.2.1" class="ltx_text ltx_font_medium">. Our model is firstly trained on diverse data with both supervised and self-supervised keypoint estimation tasks. During test time, we personalize the model using only the self-supervised target in single person domain and then predict with the updated model. During Test-Time Personalization, no continuous data is required but only unlabeled samples belonging to the same person are needed. Our method boosts performance at test time without costly labeling or sacrificing privacy.</span></span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper, we propose to personalize human pose estimation with unlabeled video data during test time, namely, <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">Test-Time Personalization</em>. Our setting falls in the general paradigm of Test-Time AdaptationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, where a generic model is first trained with diverse data, and then it is fine-tuned to adapt to a specific instance during test time without using human supervision. This allows the model to generalize to out-of-distribution data and preserves privacy when training is distributed. Specifically, Sun et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> propose to generalize image classification by performing joint training with a semantic classification task and a self-supervised image rotation prediction taskÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. During inference, the shared network representation is fine-tuned on the test instance with the self-supervisory signal for adaptation. While the empirical result is encouraging, it is unclear how the rotation prediction task can help image classification, and what is the relation between two tasks besides sharing the same feature backbone.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Going beyond feature sharing with two distinct tasks, we introduce to perform joint supervised and self-supervised human keypoint estimationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> tasks where the supervised keypoint outputs are directly transformed from the self-supervised keypoints using a TransformerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. In this way, when fine-tuning with the self-supervised task in test time, the supervised pose estimation can be improved by transforming from the improved self-supervised keypoints.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We adapt the self-supervised keypoint estimation task proposed by Jakab et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. The task is built on the assumption that the human usually maintains the appearance but changes poses across time in a video. Given a video frame, it trains a network to extract a tight bottleneck in the form of sparse spatial heatmaps, which only contain pose information without appearance. The training objective is to reconstruct the same frame by combining the bottleneck heatmaps and the appearance feature extracted from another frame. Note while this framework can extract keypoints to represent the human structure, they are not aligned with the semantic keypoints defined in human pose estimation. Building on this model, we add an extra keypoint estimation objective which is trained with human supervision. Instead of simply sharing features between two objectives asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, we train a Transformer model on top of the feature backbone to extract the relation and affinity matrix between the self-supervised keypoint heatmap and the supervised keypoint heatmap. We then use the affinity matrix to transform the self-supervised keypoints as the supervised keypoint outputs. With our Transformer design, it not only increases the correlation between two tasks when training but also improves Test-Time Personalization as changing one output will directly contribute to the the output of another task.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">We perform our experiments with multiple human pose estimation datasets including Human 3.6MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, Penn ActionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, and BBC PoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> datasets. As shown in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our Test-Time Personalization can perform on frames that continuously exist in a video and also with frames that are non-continuous as long as they are for the same person. We show that by using our approach for personalizing human pose estimation in test time, we achieve significant improvements over baselines in all datasets. More interestingly, the performance of our method improves with more video frames appearing online for the same person during test time.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Human Pose Estimation.</span> Human pose estimation has been extensively studied and achieved great advancements in the past few yearsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. For example, Toshev et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> propose to regress the keypoint locations from the input images. Instead of direct location regression, Wei et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> propose to apply a cascade framework for coarse to fine heatmap prediction and achieve significant improvement. Building on this line of research, Xiao et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> provides a simple and good practice on heatmap-based pose estimation, which is utilized as our baseline model. While in our experiments we utilize video data for training, our model is a single-image pose estimator and it is fundamentally different from video pose estimation modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> which take multiple continuous frames as inputs. This gives our model the flexibility to perform pose estimation on static images and thus it is not directly comparable to approaches with video inputs. Our work is also related to personalization on human pose estimation from Charles et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, which uses multiple temporal and continuity constraints to propagate the keypoints to generate more training data. Instead of tracking keypoints, we use a self-supervised objective to perform personalization in test time. Our method is not restricted to the continuity between close frames, and the self-supervision can be applied on any two frames far away in a video as long as they belong to the same person.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Test-Time Adaptation.</span> Our personalization setting falls into the paradigm of Test-Time Adaptation which is recently proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> for generalization to out-of-distribution test data. For example, Shocher et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> propose a super-resolution framework which is only trained during test time with a single image via down-scaling the image to create training pairs. Wang et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> introduce to use entropy of the classification probability distribution to provide fine-tuning signals when given a test image. Instead of optimizing the main task itself during test time, Sun et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> propose to utilize a self-supervised rotation prediction task to help improve the visual representation during inference, which indirectly improves semantic classification. Going beyond image classification, Joo et al. Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> propose a method that proposes test time optimization for 3D human body regression. In our work for pose personalization, we try to bridge the self-supervised and supervised objectives close. We leverage a self-supervised keypoint estimation task and transform the self-supervised keypoints to supervised keypoints via a Transformer model. In this way, training with self-supervision will directly improve the supervised keypoint outputs.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Self-supervised Keypoint Estimation.</span> There are a lot of recent developments on learning keypoint representations with self-supervisionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib72" title="" class="ltx_ref">72</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. For example, Jakab et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> propose a video frame reconstruction task which disentangles the appearance feature and keypoint structure in the bottleneck. This work is then extended for control and Reinforcement LearningÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, and the keypoints can be mapped to manual defined human pose via adding adversarial learning lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. While the results are encouraging, most of the results are reported in relatively simple scenes and environments. In our paper, by leveraging the self-supervised task together with the supervised task, we can perform human pose personalization on images in the wild.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Transformers.</span> Transformer has been widely applied in both language processingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> and computer vision tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, specifically for pose estimation recentlyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. For example, Li et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> propose to utilize the encoder-decoder model in Transformers to perform keypoint regression, which allows for more general-purpose applications and requires less priors in architecture design. Inspired by these works, we apply Transformer to reason the relation and mapping between the supervised and self-supervised keypoints.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our method aims at generalizing better for pose estimation on a single image by personalizing with unlabeled data. The model is firstly trained with diverse data on both a supervised pose estimation task and a self-supervised keypoint estimation task, using a proposed Transformer design to model the relation between two tasks. During inference, the model conducts Test-Time Personalization which only requires the self-supervised keypoint estimation task, boosting performance without costly labeling or sacrificing privacy. The whole pipeline is shown in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2107.02133/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.36.17.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.32.16" class="ltx_text" style="font-size:90%;">The proposed pipeline. 1) <span id="S3.F2.32.16.1" class="ltx_text ltx_font_bold">Self-supervised task for personalization.</span> In the middle stream, the encoder <math id="S3.F2.17.1.m1.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.F2.17.1.m1.1b"><mi id="S3.F2.17.1.m1.1.1" xref="S3.F2.17.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.F2.17.1.m1.1c"><ci id="S3.F2.17.1.m1.1.1.cmml" xref="S3.F2.17.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.17.1.m1.1d">\phi</annotation></semantics></math> encodes the target image into feature <math id="S3.F2.18.2.m2.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.F2.18.2.m2.1b"><msub id="S3.F2.18.2.m2.1.1" xref="S3.F2.18.2.m2.1.1.cmml"><mi id="S3.F2.18.2.m2.1.1.2" xref="S3.F2.18.2.m2.1.1.2.cmml">F</mi><mi id="S3.F2.18.2.m2.1.1.3" xref="S3.F2.18.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.18.2.m2.1c"><apply id="S3.F2.18.2.m2.1.1.cmml" xref="S3.F2.18.2.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.18.2.m2.1.1.1.cmml" xref="S3.F2.18.2.m2.1.1">subscript</csymbol><ci id="S3.F2.18.2.m2.1.1.2.cmml" xref="S3.F2.18.2.m2.1.1.2">ğ¹</ci><ci id="S3.F2.18.2.m2.1.1.3.cmml" xref="S3.F2.18.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.18.2.m2.1d">F_{t}</annotation></semantics></math>. Then <math id="S3.F2.19.3.m3.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.F2.19.3.m3.1b"><msub id="S3.F2.19.3.m3.1.1" xref="S3.F2.19.3.m3.1.1.cmml"><mi id="S3.F2.19.3.m3.1.1.2" xref="S3.F2.19.3.m3.1.1.2.cmml">F</mi><mi id="S3.F2.19.3.m3.1.1.3" xref="S3.F2.19.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.19.3.m3.1c"><apply id="S3.F2.19.3.m3.1.1.cmml" xref="S3.F2.19.3.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.19.3.m3.1.1.1.cmml" xref="S3.F2.19.3.m3.1.1">subscript</csymbol><ci id="S3.F2.19.3.m3.1.1.2.cmml" xref="S3.F2.19.3.m3.1.1.2">ğ¹</ci><ci id="S3.F2.19.3.m3.1.1.3.cmml" xref="S3.F2.19.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.19.3.m3.1d">F_{t}</annotation></semantics></math> is fed into the self-supervised head <math id="S3.F2.20.4.m4.1" class="ltx_Math" alttext="\psi^{\text{self}}" display="inline"><semantics id="S3.F2.20.4.m4.1b"><msup id="S3.F2.20.4.m4.1.1" xref="S3.F2.20.4.m4.1.1.cmml"><mi id="S3.F2.20.4.m4.1.1.2" xref="S3.F2.20.4.m4.1.1.2.cmml">Ïˆ</mi><mtext id="S3.F2.20.4.m4.1.1.3" xref="S3.F2.20.4.m4.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.20.4.m4.1c"><apply id="S3.F2.20.4.m4.1.1.cmml" xref="S3.F2.20.4.m4.1.1"><csymbol cd="ambiguous" id="S3.F2.20.4.m4.1.1.1.cmml" xref="S3.F2.20.4.m4.1.1">superscript</csymbol><ci id="S3.F2.20.4.m4.1.1.2.cmml" xref="S3.F2.20.4.m4.1.1.2">ğœ“</ci><ci id="S3.F2.20.4.m4.1.1.3a.cmml" xref="S3.F2.20.4.m4.1.1.3"><mtext mathsize="70%" id="S3.F2.20.4.m4.1.1.3.cmml" xref="S3.F2.20.4.m4.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.20.4.m4.1d">\psi^{\text{self}}</annotation></semantics></math> obtaining self-supervised keypoint heatmaps <math id="S3.F2.21.5.m5.1" class="ltx_Math" alttext="H^{\text{self}}" display="inline"><semantics id="S3.F2.21.5.m5.1b"><msup id="S3.F2.21.5.m5.1.1" xref="S3.F2.21.5.m5.1.1.cmml"><mi id="S3.F2.21.5.m5.1.1.2" xref="S3.F2.21.5.m5.1.1.2.cmml">H</mi><mtext id="S3.F2.21.5.m5.1.1.3" xref="S3.F2.21.5.m5.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.21.5.m5.1c"><apply id="S3.F2.21.5.m5.1.1.cmml" xref="S3.F2.21.5.m5.1.1"><csymbol cd="ambiguous" id="S3.F2.21.5.m5.1.1.1.cmml" xref="S3.F2.21.5.m5.1.1">superscript</csymbol><ci id="S3.F2.21.5.m5.1.1.2.cmml" xref="S3.F2.21.5.m5.1.1.2">ğ»</ci><ci id="S3.F2.21.5.m5.1.1.3a.cmml" xref="S3.F2.21.5.m5.1.1.3"><mtext mathsize="70%" id="S3.F2.21.5.m5.1.1.3.cmml" xref="S3.F2.21.5.m5.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.21.5.m5.1d">H^{\text{self}}</annotation></semantics></math>. Passing <math id="S3.F2.22.6.m6.1" class="ltx_Math" alttext="H^{\text{self}}" display="inline"><semantics id="S3.F2.22.6.m6.1b"><msup id="S3.F2.22.6.m6.1.1" xref="S3.F2.22.6.m6.1.1.cmml"><mi id="S3.F2.22.6.m6.1.1.2" xref="S3.F2.22.6.m6.1.1.2.cmml">H</mi><mtext id="S3.F2.22.6.m6.1.1.3" xref="S3.F2.22.6.m6.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.22.6.m6.1c"><apply id="S3.F2.22.6.m6.1.1.cmml" xref="S3.F2.22.6.m6.1.1"><csymbol cd="ambiguous" id="S3.F2.22.6.m6.1.1.1.cmml" xref="S3.F2.22.6.m6.1.1">superscript</csymbol><ci id="S3.F2.22.6.m6.1.1.2.cmml" xref="S3.F2.22.6.m6.1.1.2">ğ»</ci><ci id="S3.F2.22.6.m6.1.1.3a.cmml" xref="S3.F2.22.6.m6.1.1.3"><mtext mathsize="70%" id="S3.F2.22.6.m6.1.1.3.cmml" xref="S3.F2.22.6.m6.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.22.6.m6.1d">H^{\text{self}}</annotation></semantics></math> into a keypoint encoder (skipped in the figure) leads to keypoint feature <math id="S3.F2.23.7.m7.1" class="ltx_Math" alttext="F^{\text{kp}}_{t}" display="inline"><semantics id="S3.F2.23.7.m7.1b"><msubsup id="S3.F2.23.7.m7.1.1" xref="S3.F2.23.7.m7.1.1.cmml"><mi id="S3.F2.23.7.m7.1.1.2.2" xref="S3.F2.23.7.m7.1.1.2.2.cmml">F</mi><mi id="S3.F2.23.7.m7.1.1.3" xref="S3.F2.23.7.m7.1.1.3.cmml">t</mi><mtext id="S3.F2.23.7.m7.1.1.2.3" xref="S3.F2.23.7.m7.1.1.2.3a.cmml">kp</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.23.7.m7.1c"><apply id="S3.F2.23.7.m7.1.1.cmml" xref="S3.F2.23.7.m7.1.1"><csymbol cd="ambiguous" id="S3.F2.23.7.m7.1.1.1.cmml" xref="S3.F2.23.7.m7.1.1">subscript</csymbol><apply id="S3.F2.23.7.m7.1.1.2.cmml" xref="S3.F2.23.7.m7.1.1"><csymbol cd="ambiguous" id="S3.F2.23.7.m7.1.1.2.1.cmml" xref="S3.F2.23.7.m7.1.1">superscript</csymbol><ci id="S3.F2.23.7.m7.1.1.2.2.cmml" xref="S3.F2.23.7.m7.1.1.2.2">ğ¹</ci><ci id="S3.F2.23.7.m7.1.1.2.3a.cmml" xref="S3.F2.23.7.m7.1.1.2.3"><mtext mathsize="70%" id="S3.F2.23.7.m7.1.1.2.3.cmml" xref="S3.F2.23.7.m7.1.1.2.3">kp</mtext></ci></apply><ci id="S3.F2.23.7.m7.1.1.3.cmml" xref="S3.F2.23.7.m7.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.23.7.m7.1d">F^{\text{kp}}_{t}</annotation></semantics></math>. In the bottom stream, a source image is forwarded to an appearance extractor <math id="S3.F2.24.8.m8.1" class="ltx_Math" alttext="\phi^{\text{app}}" display="inline"><semantics id="S3.F2.24.8.m8.1b"><msup id="S3.F2.24.8.m8.1.1" xref="S3.F2.24.8.m8.1.1.cmml"><mi id="S3.F2.24.8.m8.1.1.2" xref="S3.F2.24.8.m8.1.1.2.cmml">Ï•</mi><mtext id="S3.F2.24.8.m8.1.1.3" xref="S3.F2.24.8.m8.1.1.3a.cmml">app</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.24.8.m8.1c"><apply id="S3.F2.24.8.m8.1.1.cmml" xref="S3.F2.24.8.m8.1.1"><csymbol cd="ambiguous" id="S3.F2.24.8.m8.1.1.1.cmml" xref="S3.F2.24.8.m8.1.1">superscript</csymbol><ci id="S3.F2.24.8.m8.1.1.2.cmml" xref="S3.F2.24.8.m8.1.1.2">italic-Ï•</ci><ci id="S3.F2.24.8.m8.1.1.3a.cmml" xref="S3.F2.24.8.m8.1.1.3"><mtext mathsize="70%" id="S3.F2.24.8.m8.1.1.3.cmml" xref="S3.F2.24.8.m8.1.1.3">app</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.24.8.m8.1d">\phi^{\text{app}}</annotation></semantics></math> which leads to appearance feature <math id="S3.F2.25.9.m9.1" class="ltx_Math" alttext="F^{\text{app}}_{t}" display="inline"><semantics id="S3.F2.25.9.m9.1b"><msubsup id="S3.F2.25.9.m9.1.1" xref="S3.F2.25.9.m9.1.1.cmml"><mi id="S3.F2.25.9.m9.1.1.2.2" xref="S3.F2.25.9.m9.1.1.2.2.cmml">F</mi><mi id="S3.F2.25.9.m9.1.1.3" xref="S3.F2.25.9.m9.1.1.3.cmml">t</mi><mtext id="S3.F2.25.9.m9.1.1.2.3" xref="S3.F2.25.9.m9.1.1.2.3a.cmml">app</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.25.9.m9.1c"><apply id="S3.F2.25.9.m9.1.1.cmml" xref="S3.F2.25.9.m9.1.1"><csymbol cd="ambiguous" id="S3.F2.25.9.m9.1.1.1.cmml" xref="S3.F2.25.9.m9.1.1">subscript</csymbol><apply id="S3.F2.25.9.m9.1.1.2.cmml" xref="S3.F2.25.9.m9.1.1"><csymbol cd="ambiguous" id="S3.F2.25.9.m9.1.1.2.1.cmml" xref="S3.F2.25.9.m9.1.1">superscript</csymbol><ci id="S3.F2.25.9.m9.1.1.2.2.cmml" xref="S3.F2.25.9.m9.1.1.2.2">ğ¹</ci><ci id="S3.F2.25.9.m9.1.1.2.3a.cmml" xref="S3.F2.25.9.m9.1.1.2.3"><mtext mathsize="70%" id="S3.F2.25.9.m9.1.1.2.3.cmml" xref="S3.F2.25.9.m9.1.1.2.3">app</mtext></ci></apply><ci id="S3.F2.25.9.m9.1.1.3.cmml" xref="S3.F2.25.9.m9.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.25.9.m9.1d">F^{\text{app}}_{t}</annotation></semantics></math>. Together, a decoder reconstructs the target image using concatenated <math id="S3.F2.26.10.m10.1" class="ltx_Math" alttext="F^{\text{app}}_{s}" display="inline"><semantics id="S3.F2.26.10.m10.1b"><msubsup id="S3.F2.26.10.m10.1.1" xref="S3.F2.26.10.m10.1.1.cmml"><mi id="S3.F2.26.10.m10.1.1.2.2" xref="S3.F2.26.10.m10.1.1.2.2.cmml">F</mi><mi id="S3.F2.26.10.m10.1.1.3" xref="S3.F2.26.10.m10.1.1.3.cmml">s</mi><mtext id="S3.F2.26.10.m10.1.1.2.3" xref="S3.F2.26.10.m10.1.1.2.3a.cmml">app</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.26.10.m10.1c"><apply id="S3.F2.26.10.m10.1.1.cmml" xref="S3.F2.26.10.m10.1.1"><csymbol cd="ambiguous" id="S3.F2.26.10.m10.1.1.1.cmml" xref="S3.F2.26.10.m10.1.1">subscript</csymbol><apply id="S3.F2.26.10.m10.1.1.2.cmml" xref="S3.F2.26.10.m10.1.1"><csymbol cd="ambiguous" id="S3.F2.26.10.m10.1.1.2.1.cmml" xref="S3.F2.26.10.m10.1.1">superscript</csymbol><ci id="S3.F2.26.10.m10.1.1.2.2.cmml" xref="S3.F2.26.10.m10.1.1.2.2">ğ¹</ci><ci id="S3.F2.26.10.m10.1.1.2.3a.cmml" xref="S3.F2.26.10.m10.1.1.2.3"><mtext mathsize="70%" id="S3.F2.26.10.m10.1.1.2.3.cmml" xref="S3.F2.26.10.m10.1.1.2.3">app</mtext></ci></apply><ci id="S3.F2.26.10.m10.1.1.3.cmml" xref="S3.F2.26.10.m10.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.26.10.m10.1d">F^{\text{app}}_{s}</annotation></semantics></math> and <math id="S3.F2.27.11.m11.1" class="ltx_Math" alttext="F^{\text{kp}}_{t}" display="inline"><semantics id="S3.F2.27.11.m11.1b"><msubsup id="S3.F2.27.11.m11.1.1" xref="S3.F2.27.11.m11.1.1.cmml"><mi id="S3.F2.27.11.m11.1.1.2.2" xref="S3.F2.27.11.m11.1.1.2.2.cmml">F</mi><mi id="S3.F2.27.11.m11.1.1.3" xref="S3.F2.27.11.m11.1.1.3.cmml">t</mi><mtext id="S3.F2.27.11.m11.1.1.2.3" xref="S3.F2.27.11.m11.1.1.2.3a.cmml">kp</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.27.11.m11.1c"><apply id="S3.F2.27.11.m11.1.1.cmml" xref="S3.F2.27.11.m11.1.1"><csymbol cd="ambiguous" id="S3.F2.27.11.m11.1.1.1.cmml" xref="S3.F2.27.11.m11.1.1">subscript</csymbol><apply id="S3.F2.27.11.m11.1.1.2.cmml" xref="S3.F2.27.11.m11.1.1"><csymbol cd="ambiguous" id="S3.F2.27.11.m11.1.1.2.1.cmml" xref="S3.F2.27.11.m11.1.1">superscript</csymbol><ci id="S3.F2.27.11.m11.1.1.2.2.cmml" xref="S3.F2.27.11.m11.1.1.2.2">ğ¹</ci><ci id="S3.F2.27.11.m11.1.1.2.3a.cmml" xref="S3.F2.27.11.m11.1.1.2.3"><mtext mathsize="70%" id="S3.F2.27.11.m11.1.1.2.3.cmml" xref="S3.F2.27.11.m11.1.1.2.3">kp</mtext></ci></apply><ci id="S3.F2.27.11.m11.1.1.3.cmml" xref="S3.F2.27.11.m11.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.27.11.m11.1d">F^{\text{kp}}_{t}</annotation></semantics></math>. 2) <span id="S3.F2.32.16.2" class="ltx_text ltx_font_bold">Supervised task with Transformer.</span> On the top stream, a Transformer predicts an affinity matrix given learnable keypoint queries <math id="S3.F2.28.12.m12.1" class="ltx_Math" alttext="Q^{\text{sup}}" display="inline"><semantics id="S3.F2.28.12.m12.1b"><msup id="S3.F2.28.12.m12.1.1" xref="S3.F2.28.12.m12.1.1.cmml"><mi id="S3.F2.28.12.m12.1.1.2" xref="S3.F2.28.12.m12.1.1.2.cmml">Q</mi><mtext id="S3.F2.28.12.m12.1.1.3" xref="S3.F2.28.12.m12.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.28.12.m12.1c"><apply id="S3.F2.28.12.m12.1.1.cmml" xref="S3.F2.28.12.m12.1.1"><csymbol cd="ambiguous" id="S3.F2.28.12.m12.1.1.1.cmml" xref="S3.F2.28.12.m12.1.1">superscript</csymbol><ci id="S3.F2.28.12.m12.1.1.2.cmml" xref="S3.F2.28.12.m12.1.1.2">ğ‘„</ci><ci id="S3.F2.28.12.m12.1.1.3a.cmml" xref="S3.F2.28.12.m12.1.1.3"><mtext mathsize="70%" id="S3.F2.28.12.m12.1.1.3.cmml" xref="S3.F2.28.12.m12.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.28.12.m12.1d">Q^{\text{sup}}</annotation></semantics></math> and <math id="S3.F2.29.13.m13.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.F2.29.13.m13.1b"><msub id="S3.F2.29.13.m13.1.1" xref="S3.F2.29.13.m13.1.1.cmml"><mi id="S3.F2.29.13.m13.1.1.2" xref="S3.F2.29.13.m13.1.1.2.cmml">F</mi><mi id="S3.F2.29.13.m13.1.1.3" xref="S3.F2.29.13.m13.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.29.13.m13.1c"><apply id="S3.F2.29.13.m13.1.1.cmml" xref="S3.F2.29.13.m13.1.1"><csymbol cd="ambiguous" id="S3.F2.29.13.m13.1.1.1.cmml" xref="S3.F2.29.13.m13.1.1">subscript</csymbol><ci id="S3.F2.29.13.m13.1.1.2.cmml" xref="S3.F2.29.13.m13.1.1.2">ğ¹</ci><ci id="S3.F2.29.13.m13.1.1.3.cmml" xref="S3.F2.29.13.m13.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.29.13.m13.1d">F_{t}</annotation></semantics></math>. The final supervised heatmaps <math id="S3.F2.30.14.m14.1" class="ltx_Math" alttext="H^{\text{sup}}" display="inline"><semantics id="S3.F2.30.14.m14.1b"><msup id="S3.F2.30.14.m14.1.1" xref="S3.F2.30.14.m14.1.1.cmml"><mi id="S3.F2.30.14.m14.1.1.2" xref="S3.F2.30.14.m14.1.1.2.cmml">H</mi><mtext id="S3.F2.30.14.m14.1.1.3" xref="S3.F2.30.14.m14.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.30.14.m14.1c"><apply id="S3.F2.30.14.m14.1.1.cmml" xref="S3.F2.30.14.m14.1.1"><csymbol cd="ambiguous" id="S3.F2.30.14.m14.1.1.1.cmml" xref="S3.F2.30.14.m14.1.1">superscript</csymbol><ci id="S3.F2.30.14.m14.1.1.2.cmml" xref="S3.F2.30.14.m14.1.1.2">ğ»</ci><ci id="S3.F2.30.14.m14.1.1.3a.cmml" xref="S3.F2.30.14.m14.1.1.3"><mtext mathsize="70%" id="S3.F2.30.14.m14.1.1.3.cmml" xref="S3.F2.30.14.m14.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.30.14.m14.1d">H^{\text{sup}}</annotation></semantics></math> is given as weighted sum of <math id="S3.F2.31.15.m15.1" class="ltx_Math" alttext="H^{\text{self}}" display="inline"><semantics id="S3.F2.31.15.m15.1b"><msup id="S3.F2.31.15.m15.1.1" xref="S3.F2.31.15.m15.1.1.cmml"><mi id="S3.F2.31.15.m15.1.1.2" xref="S3.F2.31.15.m15.1.1.2.cmml">H</mi><mtext id="S3.F2.31.15.m15.1.1.3" xref="S3.F2.31.15.m15.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.F2.31.15.m15.1c"><apply id="S3.F2.31.15.m15.1.1.cmml" xref="S3.F2.31.15.m15.1.1"><csymbol cd="ambiguous" id="S3.F2.31.15.m15.1.1.1.cmml" xref="S3.F2.31.15.m15.1.1">superscript</csymbol><ci id="S3.F2.31.15.m15.1.1.2.cmml" xref="S3.F2.31.15.m15.1.1.2">ğ»</ci><ci id="S3.F2.31.15.m15.1.1.3a.cmml" xref="S3.F2.31.15.m15.1.1.3"><mtext mathsize="70%" id="S3.F2.31.15.m15.1.1.3.cmml" xref="S3.F2.31.15.m15.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.31.15.m15.1d">H^{\text{self}}</annotation></semantics></math> using <math id="S3.F2.32.16.m16.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.F2.32.16.m16.1b"><mi id="S3.F2.32.16.m16.1.1" xref="S3.F2.32.16.m16.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.F2.32.16.m16.1c"><ci id="S3.F2.32.16.m16.1.1.cmml" xref="S3.F2.32.16.m16.1.1">ğ‘Š</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.32.16.m16.1d">W</annotation></semantics></math>.</span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Joint Training for Pose Estimation with a Transformer</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.4" class="ltx_p">Given a set of <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">N</annotation></semantics></math> labeled images of a single person <math id="S3.SS1.p1.2.m2.3" class="ltx_Math" alttext="\mathbf{I}=\left\{I_{1},I_{2}\dots,I_{N}\right\}" display="inline"><semantics id="S3.SS1.p1.2.m2.3a"><mrow id="S3.SS1.p1.2.m2.3.3" xref="S3.SS1.p1.2.m2.3.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.5" xref="S3.SS1.p1.2.m2.3.3.5.cmml">ğˆ</mi><mo id="S3.SS1.p1.2.m2.3.3.4" xref="S3.SS1.p1.2.m2.3.3.4.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.3.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml"><mo id="S3.SS1.p1.2.m2.3.3.3.3.4" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml">{</mo><msub id="S3.SS1.p1.2.m2.1.1.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.1.1.1.1.1.2.cmml">I</mi><mn id="S3.SS1.p1.2.m2.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.2.m2.3.3.3.3.5" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml">,</mo><mrow id="S3.SS1.p1.2.m2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.cmml"><msub id="S3.SS1.p1.2.m2.2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.2.m2.2.2.2.2.2.2.2" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.2.cmml">I</mi><mn id="S3.SS1.p1.2.m2.2.2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.2.2.2.2.2.1" xref="S3.SS1.p1.2.m2.2.2.2.2.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.SS1.p1.2.m2.2.2.2.2.2.3" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3.cmml">â€¦</mi></mrow><mo id="S3.SS1.p1.2.m2.3.3.3.3.6" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.3.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.3.3.3.2" xref="S3.SS1.p1.2.m2.3.3.3.3.3.2.cmml">I</mi><mi id="S3.SS1.p1.2.m2.3.3.3.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.3.3.3.cmml">N</mi></msub><mo id="S3.SS1.p1.2.m2.3.3.3.3.7" xref="S3.SS1.p1.2.m2.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.3b"><apply id="S3.SS1.p1.2.m2.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3"><eq id="S3.SS1.p1.2.m2.3.3.4.cmml" xref="S3.SS1.p1.2.m2.3.3.4"></eq><ci id="S3.SS1.p1.2.m2.3.3.5.cmml" xref="S3.SS1.p1.2.m2.3.3.5">ğˆ</ci><set id="S3.SS1.p1.2.m2.3.3.3.4.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3"><apply id="S3.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.2">ğ¼</ci><cn type="integer" id="S3.SS1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2"><times id="S3.SS1.p1.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.1"></times><apply id="S3.SS1.p1.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.2">ğ¼</ci><cn type="integer" id="S3.SS1.p1.2.m2.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.2.m2.2.2.2.2.2.3">â€¦</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.3.3.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.3.3.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3.3.2">ğ¼</ci><ci id="S3.SS1.p1.2.m2.3.3.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3.3.3">ğ‘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.3c">\mathbf{I}=\left\{I_{1},I_{2}\dots,I_{N}\right\}</annotation></semantics></math>, a shared encoder <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\phi</annotation></semantics></math> maps them into feature space <math id="S3.SS1.p1.4.m4.3" class="ltx_Math" alttext="\mathbf{F}=\left\{F_{1},F_{2}\dots,F_{N}\right\}" display="inline"><semantics id="S3.SS1.p1.4.m4.3a"><mrow id="S3.SS1.p1.4.m4.3.3" xref="S3.SS1.p1.4.m4.3.3.cmml"><mi id="S3.SS1.p1.4.m4.3.3.5" xref="S3.SS1.p1.4.m4.3.3.5.cmml">ğ…</mi><mo id="S3.SS1.p1.4.m4.3.3.4" xref="S3.SS1.p1.4.m4.3.3.4.cmml">=</mo><mrow id="S3.SS1.p1.4.m4.3.3.3.3" xref="S3.SS1.p1.4.m4.3.3.3.4.cmml"><mo id="S3.SS1.p1.4.m4.3.3.3.3.4" xref="S3.SS1.p1.4.m4.3.3.3.4.cmml">{</mo><msub id="S3.SS1.p1.4.m4.1.1.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.1.1.1.2" xref="S3.SS1.p1.4.m4.1.1.1.1.1.2.cmml">F</mi><mn id="S3.SS1.p1.4.m4.1.1.1.1.1.3" xref="S3.SS1.p1.4.m4.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.4.m4.3.3.3.3.5" xref="S3.SS1.p1.4.m4.3.3.3.4.cmml">,</mo><mrow id="S3.SS1.p1.4.m4.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.cmml"><msub id="S3.SS1.p1.4.m4.2.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml">F</mi><mn id="S3.SS1.p1.4.m4.2.2.2.2.2.2.3" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS1.p1.4.m4.2.2.2.2.2.1" xref="S3.SS1.p1.4.m4.2.2.2.2.2.1.cmml">â€‹</mo><mi mathvariant="normal" id="S3.SS1.p1.4.m4.2.2.2.2.2.3" xref="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml">â€¦</mi></mrow><mo id="S3.SS1.p1.4.m4.3.3.3.3.6" xref="S3.SS1.p1.4.m4.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p1.4.m4.3.3.3.3.3" xref="S3.SS1.p1.4.m4.3.3.3.3.3.cmml"><mi id="S3.SS1.p1.4.m4.3.3.3.3.3.2" xref="S3.SS1.p1.4.m4.3.3.3.3.3.2.cmml">F</mi><mi id="S3.SS1.p1.4.m4.3.3.3.3.3.3" xref="S3.SS1.p1.4.m4.3.3.3.3.3.3.cmml">N</mi></msub><mo id="S3.SS1.p1.4.m4.3.3.3.3.7" xref="S3.SS1.p1.4.m4.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.3b"><apply id="S3.SS1.p1.4.m4.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3"><eq id="S3.SS1.p1.4.m4.3.3.4.cmml" xref="S3.SS1.p1.4.m4.3.3.4"></eq><ci id="S3.SS1.p1.4.m4.3.3.5.cmml" xref="S3.SS1.p1.4.m4.3.3.5">ğ…</ci><set id="S3.SS1.p1.4.m4.3.3.3.4.cmml" xref="S3.SS1.p1.4.m4.3.3.3.3"><apply id="S3.SS1.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.2">ğ¹</ci><cn type="integer" id="S3.SS1.p1.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2"><times id="S3.SS1.p1.4.m4.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.1"></times><apply id="S3.SS1.p1.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.2">ğ¹</ci><cn type="integer" id="S3.SS1.p1.4.m4.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.4.m4.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.4.m4.2.2.2.2.2.3">â€¦</ci></apply><apply id="S3.SS1.p1.4.m4.3.3.3.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.3.3.3.3.3.1.cmml" xref="S3.SS1.p1.4.m4.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.4.m4.3.3.3.3.3.2.cmml" xref="S3.SS1.p1.4.m4.3.3.3.3.3.2">ğ¹</ci><ci id="S3.SS1.p1.4.m4.3.3.3.3.3.3.cmml" xref="S3.SS1.p1.4.m4.3.3.3.3.3.3">ğ‘</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.3c">\mathbf{F}=\left\{F_{1},F_{2}\dots,F_{N}\right\}</annotation></semantics></math>, which is shared by both a supervised and a self-supervised keypoint estimation tasks. We introduce both tasks and the joint framework as follows.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Self-supervised Keypoint Estimation</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.8" class="ltx_p">For the self-supervised task, we build upon the work from Jakab et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> which uses an image reconstruction task to perform disentanglement of human structure and appearance, which leads to self-supervised keypoints as intermediate results. Given two images of a single person <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="I_{s}" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><msub id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">I_{s}</annotation></semantics></math> and <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><msub id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">I_{t}</annotation></semantics></math>, the task aims at reconstructing <math id="S3.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="S3.SS1.SSS1.p1.3.m3.1a"><msub id="S3.SS1.SSS1.p1.3.m3.1.1" xref="S3.SS1.SSS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p1.3.m3.1.1.2" xref="S3.SS1.SSS1.p1.3.m3.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p1.3.m3.1.1.3" xref="S3.SS1.SSS1.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.3.m3.1b"><apply id="S3.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p1.3.m3.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p1.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.3.m3.1c">I_{t}</annotation></semantics></math> using structural keypoint information from target <math id="S3.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="S3.SS1.SSS1.p1.4.m4.1a"><msub id="S3.SS1.SSS1.p1.4.m4.1.1" xref="S3.SS1.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.p1.4.m4.1.1.2" xref="S3.SS1.SSS1.p1.4.m4.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p1.4.m4.1.1.3" xref="S3.SS1.SSS1.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.4.m4.1b"><apply id="S3.SS1.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p1.4.m4.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p1.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.4.m4.1c">I_{t}</annotation></semantics></math> and appearance information from source <math id="S3.SS1.SSS1.p1.5.m5.1" class="ltx_Math" alttext="I_{s}" display="inline"><semantics id="S3.SS1.SSS1.p1.5.m5.1a"><msub id="S3.SS1.SSS1.p1.5.m5.1.1" xref="S3.SS1.SSS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS1.p1.5.m5.1.1.2" xref="S3.SS1.SSS1.p1.5.m5.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p1.5.m5.1.1.3" xref="S3.SS1.SSS1.p1.5.m5.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.5.m5.1b"><apply id="S3.SS1.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p1.5.m5.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p1.5.m5.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.5.m5.1c">I_{s}</annotation></semantics></math>. The appearance information <math id="S3.SS1.SSS1.p1.6.m6.1" class="ltx_Math" alttext="F^{\text{app}}_{s}" display="inline"><semantics id="S3.SS1.SSS1.p1.6.m6.1a"><msubsup id="S3.SS1.SSS1.p1.6.m6.1.1" xref="S3.SS1.SSS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS1.p1.6.m6.1.1.2.2" xref="S3.SS1.SSS1.p1.6.m6.1.1.2.2.cmml">F</mi><mi id="S3.SS1.SSS1.p1.6.m6.1.1.3" xref="S3.SS1.SSS1.p1.6.m6.1.1.3.cmml">s</mi><mtext id="S3.SS1.SSS1.p1.6.m6.1.1.2.3" xref="S3.SS1.SSS1.p1.6.m6.1.1.2.3a.cmml">app</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.6.m6.1b"><apply id="S3.SS1.SSS1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.6.m6.1.1.2.1.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p1.6.m6.1.1.2.2.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1.2.2">ğ¹</ci><ci id="S3.SS1.SSS1.p1.6.m6.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p1.6.m6.1.1.2.3.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1.2.3">app</mtext></ci></apply><ci id="S3.SS1.SSS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS1.p1.6.m6.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.6.m6.1c">F^{\text{app}}_{s}</annotation></semantics></math> of source image <math id="S3.SS1.SSS1.p1.7.m7.1" class="ltx_Math" alttext="I_{s}" display="inline"><semantics id="S3.SS1.SSS1.p1.7.m7.1a"><msub id="S3.SS1.SSS1.p1.7.m7.1.1" xref="S3.SS1.SSS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.SSS1.p1.7.m7.1.1.2" xref="S3.SS1.SSS1.p1.7.m7.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p1.7.m7.1.1.3" xref="S3.SS1.SSS1.p1.7.m7.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.7.m7.1b"><apply id="S3.SS1.SSS1.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS1.p1.7.m7.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.SSS1.p1.7.m7.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.7.m7.1c">I_{s}</annotation></semantics></math> is extracted with a simple extractor <math id="S3.SS1.SSS1.p1.8.m8.1" class="ltx_Math" alttext="\phi^{\text{app}}" display="inline"><semantics id="S3.SS1.SSS1.p1.8.m8.1a"><msup id="S3.SS1.SSS1.p1.8.m8.1.1" xref="S3.SS1.SSS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.SSS1.p1.8.m8.1.1.2" xref="S3.SS1.SSS1.p1.8.m8.1.1.2.cmml">Ï•</mi><mtext id="S3.SS1.SSS1.p1.8.m8.1.1.3" xref="S3.SS1.SSS1.p1.8.m8.1.1.3a.cmml">app</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.8.m8.1b"><apply id="S3.SS1.SSS1.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS1.p1.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS1.p1.8.m8.1.1.2">italic-Ï•</ci><ci id="S3.SS1.SSS1.p1.8.m8.1.1.3a.cmml" xref="S3.SS1.SSS1.p1.8.m8.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.SSS1.p1.8.m8.1.1.3">app</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.8.m8.1c">\phi^{\text{app}}</annotation></semantics></math> (see the bottom stream in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). The extraction of keypoints information from the target image follows three steps as below (also the see the middle stream in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Method â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.10" class="ltx_p">Firstly, the target image <math id="S3.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><msub id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p2.1.m1.1.1.2" xref="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS1.p2.1.m1.1.1.3" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><apply id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">I_{t}</annotation></semantics></math> is forwarded to the encoder <math id="S3.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><mi id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><ci id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">\phi</annotation></semantics></math> to obtain shared feature <math id="S3.SS1.SSS1.p2.3.m3.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><msub id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p2.3.m3.1.1.2" xref="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS1.p2.3.m3.1.1.3" xref="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><apply id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">F_{t}</annotation></semantics></math>. The self-supervised head <math id="S3.SS1.SSS1.p2.4.m4.1" class="ltx_Math" alttext="\psi^{\text{self}}" display="inline"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><msup id="S3.SS1.SSS1.p2.4.m4.1.1" xref="S3.SS1.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.p2.4.m4.1.1.2" xref="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml">Ïˆ</mi><mtext id="S3.SS1.SSS1.p2.4.m4.1.1.3" xref="S3.SS1.SSS1.p2.4.m4.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.4.m4.1b"><apply id="S3.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.2">ğœ“</ci><ci id="S3.SS1.SSS1.p2.4.m4.1.1.3a.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.4.m4.1c">\psi^{\text{self}}</annotation></semantics></math> further encodes the shared feature <math id="S3.SS1.SSS1.p2.5.m5.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.5.m5.1a"><msub id="S3.SS1.SSS1.p2.5.m5.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.SSS1.p2.5.m5.1.1.2" xref="S3.SS1.SSS1.p2.5.m5.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS1.p2.5.m5.1.1.3" xref="S3.SS1.SSS1.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.5.m5.1b"><apply id="S3.SS1.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.5.m5.1c">F_{t}</annotation></semantics></math> into heatmaps <math id="S3.SS1.SSS1.p2.6.m6.1" class="ltx_Math" alttext="H^{\text{self}}_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.6.m6.1a"><msubsup id="S3.SS1.SSS1.p2.6.m6.1.1" xref="S3.SS1.SSS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.SSS1.p2.6.m6.1.1.2.2" xref="S3.SS1.SSS1.p2.6.m6.1.1.2.2.cmml">H</mi><mi id="S3.SS1.SSS1.p2.6.m6.1.1.3" xref="S3.SS1.SSS1.p2.6.m6.1.1.3.cmml">t</mi><mtext id="S3.SS1.SSS1.p2.6.m6.1.1.2.3" xref="S3.SS1.SSS1.p2.6.m6.1.1.2.3a.cmml">self</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.6.m6.1b"><apply id="S3.SS1.SSS1.p2.6.m6.1.1.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1.2.2">ğ»</ci><ci id="S3.SS1.SSS1.p2.6.m6.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1.2.3">self</mtext></ci></apply><ci id="S3.SS1.SSS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.SSS1.p2.6.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.6.m6.1c">H^{\text{self}}_{t}</annotation></semantics></math>. Note the number of channels in the heatmap <math id="S3.SS1.SSS1.p2.7.m7.1" class="ltx_Math" alttext="H^{\text{self}}_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.7.m7.1a"><msubsup id="S3.SS1.SSS1.p2.7.m7.1.1" xref="S3.SS1.SSS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.SSS1.p2.7.m7.1.1.2.2" xref="S3.SS1.SSS1.p2.7.m7.1.1.2.2.cmml">H</mi><mi id="S3.SS1.SSS1.p2.7.m7.1.1.3" xref="S3.SS1.SSS1.p2.7.m7.1.1.3.cmml">t</mi><mtext id="S3.SS1.SSS1.p2.7.m7.1.1.2.3" xref="S3.SS1.SSS1.p2.7.m7.1.1.2.3a.cmml">self</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.7.m7.1b"><apply id="S3.SS1.SSS1.p2.7.m7.1.1.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.7.m7.1.1.2.1.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p2.7.m7.1.1.2.2.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1.2.2">ğ»</ci><ci id="S3.SS1.SSS1.p2.7.m7.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.7.m7.1.1.2.3.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1.2.3">self</mtext></ci></apply><ci id="S3.SS1.SSS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.SSS1.p2.7.m7.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.7.m7.1c">H^{\text{self}}_{t}</annotation></semantics></math> is equal to the number of self-supervised keypoints. Secondly, <math id="S3.SS1.SSS1.p2.8.m8.1" class="ltx_Math" alttext="H^{\text{self}}_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.8.m8.1a"><msubsup id="S3.SS1.SSS1.p2.8.m8.1.1" xref="S3.SS1.SSS1.p2.8.m8.1.1.cmml"><mi id="S3.SS1.SSS1.p2.8.m8.1.1.2.2" xref="S3.SS1.SSS1.p2.8.m8.1.1.2.2.cmml">H</mi><mi id="S3.SS1.SSS1.p2.8.m8.1.1.3" xref="S3.SS1.SSS1.p2.8.m8.1.1.3.cmml">t</mi><mtext id="S3.SS1.SSS1.p2.8.m8.1.1.2.3" xref="S3.SS1.SSS1.p2.8.m8.1.1.2.3a.cmml">self</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.8.m8.1b"><apply id="S3.SS1.SSS1.p2.8.m8.1.1.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.8.m8.1.1.1.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p2.8.m8.1.1.2.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.8.m8.1.1.2.1.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p2.8.m8.1.1.2.2.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1.2.2">ğ»</ci><ci id="S3.SS1.SSS1.p2.8.m8.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.8.m8.1.1.2.3.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1.2.3">self</mtext></ci></apply><ci id="S3.SS1.SSS1.p2.8.m8.1.1.3.cmml" xref="S3.SS1.SSS1.p2.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.8.m8.1c">H^{\text{self}}_{t}</annotation></semantics></math> is normalized using a <math id="S3.SS1.SSS1.p2.9.m9.1" class="ltx_Math" alttext="\mathrm{Softmax}" display="inline"><semantics id="S3.SS1.SSS1.p2.9.m9.1a"><mi id="S3.SS1.SSS1.p2.9.m9.1.1" xref="S3.SS1.SSS1.p2.9.m9.1.1.cmml">Softmax</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.9.m9.1b"><ci id="S3.SS1.SSS1.p2.9.m9.1.1.cmml" xref="S3.SS1.SSS1.p2.9.m9.1.1">Softmax</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.9.m9.1c">\mathrm{Softmax}</annotation></semantics></math> function and thus becomes condensed keypoints. In the third step, the heatmaps are replaced with fixed Gaussian distribution centered at condensed points, which serves as keypoint information <math id="S3.SS1.SSS1.p2.10.m10.1" class="ltx_Math" alttext="F^{\text{kp}}_{t}" display="inline"><semantics id="S3.SS1.SSS1.p2.10.m10.1a"><msubsup id="S3.SS1.SSS1.p2.10.m10.1.1" xref="S3.SS1.SSS1.p2.10.m10.1.1.cmml"><mi id="S3.SS1.SSS1.p2.10.m10.1.1.2.2" xref="S3.SS1.SSS1.p2.10.m10.1.1.2.2.cmml">F</mi><mi id="S3.SS1.SSS1.p2.10.m10.1.1.3" xref="S3.SS1.SSS1.p2.10.m10.1.1.3.cmml">t</mi><mtext id="S3.SS1.SSS1.p2.10.m10.1.1.2.3" xref="S3.SS1.SSS1.p2.10.m10.1.1.2.3a.cmml">kp</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.10.m10.1b"><apply id="S3.SS1.SSS1.p2.10.m10.1.1.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.10.m10.1.1.1.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p2.10.m10.1.1.2.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.10.m10.1.1.2.1.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p2.10.m10.1.1.2.2.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1.2.2">ğ¹</ci><ci id="S3.SS1.SSS1.p2.10.m10.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.10.m10.1.1.2.3.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1.2.3">kp</mtext></ci></apply><ci id="S3.SS1.SSS1.p2.10.m10.1.1.3.cmml" xref="S3.SS1.SSS1.p2.10.m10.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.10.m10.1c">F^{\text{kp}}_{t}</annotation></semantics></math>. These three steps ensure a bottleneck of keypoint information, ensuring there is not enough capacity to encode appearance features to avoid trivial solutions.</p>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para">
<p id="S3.SS1.SSS1.p3.1" class="ltx_p">The objective of the self-supervised task is to reconstruct the target image with a decoder using both appearance and keypoint features: <math id="S3.SS1.SSS1.p3.1.m1.2" class="ltx_Math" alttext="\hat{I}_{t}=\phi^{\text{render}}\left(F^{\text{app}}_{s},F^{\text{kp}}_{t}\right)" display="inline"><semantics id="S3.SS1.SSS1.p3.1.m1.2a"><mrow id="S3.SS1.SSS1.p3.1.m1.2.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.cmml"><msub id="S3.SS1.SSS1.p3.1.m1.2.2.4" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.cmml"><mover accent="true" id="S3.SS1.SSS1.p3.1.m1.2.2.4.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.2.cmml"><mi id="S3.SS1.SSS1.p3.1.m1.2.2.4.2.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.2.2.cmml">I</mi><mo id="S3.SS1.SSS1.p3.1.m1.2.2.4.2.1" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.2.1.cmml">^</mo></mover><mi id="S3.SS1.SSS1.p3.1.m1.2.2.4.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.3.cmml">t</mi></msub><mo id="S3.SS1.SSS1.p3.1.m1.2.2.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.3.cmml">=</mo><mrow id="S3.SS1.SSS1.p3.1.m1.2.2.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.cmml"><msup id="S3.SS1.SSS1.p3.1.m1.2.2.2.4" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4.cmml"><mi id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4.2.cmml">Ï•</mi><mtext id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4.3a.cmml">render</mtext></msup><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.p3.1.m1.2.2.2.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.3.cmml"><mo id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.3.cmml">(</mo><msubsup id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.2" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.2.cmml">F</mi><mi id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.3" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.3.cmml">s</mi><mtext id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.3" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.3a.cmml">app</mtext></msubsup><mo id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.4" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.cmml"><mi id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.2" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.2.cmml">F</mi><mi id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.3.cmml">t</mi><mtext id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.3" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.3a.cmml">kp</mtext></msubsup><mo id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.5" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p3.1.m1.2b"><apply id="S3.SS1.SSS1.p3.1.m1.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2"><eq id="S3.SS1.SSS1.p3.1.m1.2.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.3"></eq><apply id="S3.SS1.SSS1.p3.1.m1.2.2.4.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.2.2.4.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.4">subscript</csymbol><apply id="S3.SS1.SSS1.p3.1.m1.2.2.4.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.2"><ci id="S3.SS1.SSS1.p3.1.m1.2.2.4.2.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.2.1">^</ci><ci id="S3.SS1.SSS1.p3.1.m1.2.2.4.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.2.2">ğ¼</ci></apply><ci id="S3.SS1.SSS1.p3.1.m1.2.2.4.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.4.3">ğ‘¡</ci></apply><apply id="S3.SS1.SSS1.p3.1.m1.2.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2"><times id="S3.SS1.SSS1.p3.1.m1.2.2.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.3"></times><apply id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4">superscript</csymbol><ci id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4.2">italic-Ï•</ci><ci id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.3a.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p3.1.m1.2.2.2.4.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.4.3">render</mtext></ci></apply><interval closure="open" id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2"><apply id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.2">ğ¹</ci><ci id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.3a.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.2.3">app</mtext></ci></apply><ci id="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.1.1.1.1.1.1.3">ğ‘ </ci></apply><apply id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2">subscript</csymbol><apply id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2">superscript</csymbol><ci id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.2">ğ¹</ci><ci id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.3a.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.2.3">kp</mtext></ci></apply><ci id="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS1.p3.1.m1.2.2.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p3.1.m1.2c">\hat{I}_{t}=\phi^{\text{render}}\left(F^{\text{app}}_{s},F^{\text{kp}}_{t}\right)</annotation></semantics></math>. Since the bottleneck structure from the target stream limits the information to be passed in the form of keypoints, the image reconstruction enforces the disentanglement and the network has to borrow appearance information from source stream. The Perceptual lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and L2 distance are utilized as the reconstruction objective,</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\mathcal{L}^{\text{self}}=\mathrm{PerceptualLoss}\left(I_{t},\hat{I}_{t}\right)+\left\|I_{t}-\hat{I}_{t}\right\|^{2}" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><msup id="S3.E1.m1.3.3.5" xref="S3.E1.m1.3.3.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.3.5.2" xref="S3.E1.m1.3.3.5.2.cmml">â„’</mi><mtext id="S3.E1.m1.3.3.5.3" xref="S3.E1.m1.3.3.5.3a.cmml">self</mtext></msup><mo id="S3.E1.m1.3.3.4" xref="S3.E1.m1.3.3.4.cmml">=</mo><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.4.cmml">PerceptualLoss</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml">â€‹</mo><mrow id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.3.cmml"><mo id="S3.E1.m1.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">I</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.3.cmml">,</mo><msub id="S3.E1.m1.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.cmml"><mover accent="true" id="S3.E1.m1.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml">I</mi><mo id="S3.E1.m1.2.2.2.2.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.2.2.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.2.2.5" xref="S3.E1.m1.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.3.3.3.4" xref="S3.E1.m1.3.3.3.4.cmml">+</mo><msup id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml"><mrow id="S3.E1.m1.3.3.3.3.1.1" xref="S3.E1.m1.3.3.3.3.1.2.cmml"><mo id="S3.E1.m1.3.3.3.3.1.1.2" xref="S3.E1.m1.3.3.3.3.1.2.1.cmml">â€–</mo><mrow id="S3.E1.m1.3.3.3.3.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.cmml"><msub id="S3.E1.m1.3.3.3.3.1.1.1.2" xref="S3.E1.m1.3.3.3.3.1.1.1.2.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.1.2.2" xref="S3.E1.m1.3.3.3.3.1.1.1.2.2.cmml">I</mi><mi id="S3.E1.m1.3.3.3.3.1.1.1.2.3" xref="S3.E1.m1.3.3.3.3.1.1.1.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.3.3.3.3.1.1.1.1" xref="S3.E1.m1.3.3.3.3.1.1.1.1.cmml">âˆ’</mo><msub id="S3.E1.m1.3.3.3.3.1.1.1.3" xref="S3.E1.m1.3.3.3.3.1.1.1.3.cmml"><mover accent="true" id="S3.E1.m1.3.3.3.3.1.1.1.3.2" xref="S3.E1.m1.3.3.3.3.1.1.1.3.2.cmml"><mi id="S3.E1.m1.3.3.3.3.1.1.1.3.2.2" xref="S3.E1.m1.3.3.3.3.1.1.1.3.2.2.cmml">I</mi><mo id="S3.E1.m1.3.3.3.3.1.1.1.3.2.1" xref="S3.E1.m1.3.3.3.3.1.1.1.3.2.1.cmml">^</mo></mover><mi id="S3.E1.m1.3.3.3.3.1.1.1.3.3" xref="S3.E1.m1.3.3.3.3.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.3.3.3.3.1.1.3" xref="S3.E1.m1.3.3.3.3.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E1.m1.3.3.3.3.3" xref="S3.E1.m1.3.3.3.3.3.cmml">2</mn></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.4.cmml" xref="S3.E1.m1.3.3.4"></eq><apply id="S3.E1.m1.3.3.5.cmml" xref="S3.E1.m1.3.3.5"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.5.1.cmml" xref="S3.E1.m1.3.3.5">superscript</csymbol><ci id="S3.E1.m1.3.3.5.2.cmml" xref="S3.E1.m1.3.3.5.2">â„’</ci><ci id="S3.E1.m1.3.3.5.3a.cmml" xref="S3.E1.m1.3.3.5.3"><mtext mathsize="70%" id="S3.E1.m1.3.3.5.3.cmml" xref="S3.E1.m1.3.3.5.3">self</mtext></ci></apply><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><plus id="S3.E1.m1.3.3.3.4.cmml" xref="S3.E1.m1.3.3.3.4"></plus><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><times id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3"></times><ci id="S3.E1.m1.2.2.2.2.4.cmml" xref="S3.E1.m1.2.2.2.2.4">PerceptualLoss</ci><interval closure="open" id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">ğ¼</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2">subscript</csymbol><apply id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2"><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.1">^</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2.2">ğ¼</ci></apply><ci id="S3.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply><apply id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.3">superscript</csymbol><apply id="S3.E1.m1.3.3.3.3.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.3.3.1.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.2">norm</csymbol><apply id="S3.E1.m1.3.3.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1"><minus id="S3.E1.m1.3.3.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.1"></minus><apply id="S3.E1.m1.3.3.3.3.1.1.1.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.3.3.3.3.1.1.1.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.2.2">ğ¼</ci><ci id="S3.E1.m1.3.3.3.3.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.3.3.3.3.1.1.1.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.3.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.3">subscript</csymbol><apply id="S3.E1.m1.3.3.3.3.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.3.2"><ci id="S3.E1.m1.3.3.3.3.1.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.3.2.1">^</ci><ci id="S3.E1.m1.3.3.3.3.1.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.3.2.2">ğ¼</ci></apply><ci id="S3.E1.m1.3.3.3.3.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.3.3.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply><cn type="integer" id="S3.E1.m1.3.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\mathcal{L}^{\text{self}}=\mathrm{PerceptualLoss}\left(I_{t},\hat{I}_{t}\right)+\left\|I_{t}-\hat{I}_{t}\right\|^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS1.p3.2" class="ltx_p">Instead of self-supervised tasks like image rotation predictionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> or colorizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, choosing an explicitly related self-supervised key-point task in joint training naturally preserves or even improves performance, and it is more beneficial to test-time personalization. Attention should be paid that our method requires only label of one single image and unlabeled samples belonging to the same person. Compared to multiple labeled samples of the same person or even more costly consecutively labeled video, acquiring such data is much more easier and efficient.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Supervised Keypoint Estimation with a Transformer</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.2" class="ltx_p">A natural and basic choice for supervised keypoint estimation is to use an unshared supervised head <math id="S3.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><msup id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p1.1.m1.1.1.2" xref="S3.SS1.SSS2.p1.1.m1.1.1.2.cmml">Ïˆ</mi><mtext id="S3.SS1.SSS2.p1.1.m1.1.1.3" xref="S3.SS1.SSS2.p1.1.m1.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><apply id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1.2">ğœ“</ci><ci id="S3.SS1.SSS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">\psi^{\text{sup}}</annotation></semantics></math> to predict supervised keypoints based on <math id="S3.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><msub id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p1.2.m2.1.1.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS2.p1.2.m2.1.1.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><apply id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">F_{t}</annotation></semantics></math>. However, despite the effectiveness of multi-task learning on two pose estimation tasks, their relation still stays plain on the surface. As similar tasks do not necessarily help each other even when sharing features, we propose to use a Transformer decoder to further strengthen their coupling. The Transformer decoder models the relation between two tasks by learning an affinity matrix between the supervised and the self-supervised keypoint heatmaps.</p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.8" class="ltx_p">Given the target image <math id="S3.SS1.SSS2.p2.1.m1.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="S3.SS1.SSS2.p2.1.m1.1a"><msub id="S3.SS1.SSS2.p2.1.m1.1.1" xref="S3.SS1.SSS2.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p2.1.m1.1.1.2" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.cmml">I</mi><mi id="S3.SS1.SSS2.p2.1.m1.1.1.3" xref="S3.SS1.SSS2.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.1.m1.1b"><apply id="S3.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.2">ğ¼</ci><ci id="S3.SS1.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.1.m1.1c">I_{t}</annotation></semantics></math>, its feature <math id="S3.SS1.SSS2.p2.2.m2.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS2.p2.2.m2.1a"><msub id="S3.SS1.SSS2.p2.2.m2.1.1" xref="S3.SS1.SSS2.p2.2.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p2.2.m2.1.1.2" xref="S3.SS1.SSS2.p2.2.m2.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS2.p2.2.m2.1.1.3" xref="S3.SS1.SSS2.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.2.m2.1b"><apply id="S3.SS1.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p2.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.2.m2.1c">F_{t}</annotation></semantics></math> and self-supervised heatmap <math id="S3.SS1.SSS2.p2.3.m3.1" class="ltx_Math" alttext="H^{\text{self}}_{t}\in\mathbb{R}^{h\times w\times k^{\text{self}}}" display="inline"><semantics id="S3.SS1.SSS2.p2.3.m3.1a"><mrow id="S3.SS1.SSS2.p2.3.m3.1.1" xref="S3.SS1.SSS2.p2.3.m3.1.1.cmml"><msubsup id="S3.SS1.SSS2.p2.3.m3.1.1.2" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.cmml"><mi id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.2" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.2.2.cmml">H</mi><mi id="S3.SS1.SSS2.p2.3.m3.1.1.2.3" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.3.cmml">t</mi><mtext id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.3" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.2.3a.cmml">self</mtext></msubsup><mo id="S3.SS1.SSS2.p2.3.m3.1.1.1" xref="S3.SS1.SSS2.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p2.3.m3.1.1.3" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.SSS2.p2.3.m3.1.1.3.2" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p2.3.m3.1.1.3.3" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.2" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.2.cmml">h</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.1" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.3" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.3.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.1a" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.1.cmml">Ã—</mo><msup id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.cmml"><mi id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.2" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.3" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.3a.cmml">self</mtext></msup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.3.m3.1b"><apply id="S3.SS1.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1"><in id="S3.SS1.SSS2.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.1"></in><apply id="S3.SS1.SSS2.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2">subscript</csymbol><apply id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.2.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.2.2">ğ»</ci><ci id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.3a.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.2.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.3.m3.1.1.2.2.3.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.2.3">self</mtext></ci></apply><ci id="S3.SS1.SSS2.p2.3.m3.1.1.2.3.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.SSS2.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.2">â„</ci><apply id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3"><times id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.2">â„</ci><ci id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.3">ğ‘¤</ci><apply id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.1.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4">superscript</csymbol><ci id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.2.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.3a.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.3"><mtext mathsize="50%" id="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.3.cmml" xref="S3.SS1.SSS2.p2.3.m3.1.1.3.3.4.3">self</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.3.m3.1c">H^{\text{self}}_{t}\in\mathbb{R}^{h\times w\times k^{\text{self}}}</annotation></semantics></math> are extracted using encoder <math id="S3.SS1.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS1.SSS2.p2.4.m4.1a"><mi id="S3.SS1.SSS2.p2.4.m4.1.1" xref="S3.SS1.SSS2.p2.4.m4.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.4.m4.1b"><ci id="S3.SS1.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p2.4.m4.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.4.m4.1c">\phi</annotation></semantics></math> and self-supervised head <math id="S3.SS1.SSS2.p2.5.m5.1" class="ltx_Math" alttext="\psi^{\text{self}}" display="inline"><semantics id="S3.SS1.SSS2.p2.5.m5.1a"><msup id="S3.SS1.SSS2.p2.5.m5.1.1" xref="S3.SS1.SSS2.p2.5.m5.1.1.cmml"><mi id="S3.SS1.SSS2.p2.5.m5.1.1.2" xref="S3.SS1.SSS2.p2.5.m5.1.1.2.cmml">Ïˆ</mi><mtext id="S3.SS1.SSS2.p2.5.m5.1.1.3" xref="S3.SS1.SSS2.p2.5.m5.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.5.m5.1b"><apply id="S3.SS1.SSS2.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.5.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p2.5.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p2.5.m5.1.1.2">ğœ“</ci><ci id="S3.SS1.SSS2.p2.5.m5.1.1.3a.cmml" xref="S3.SS1.SSS2.p2.5.m5.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.5.m5.1.1.3.cmml" xref="S3.SS1.SSS2.p2.5.m5.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.5.m5.1c">\psi^{\text{self}}</annotation></semantics></math> respectively, where <math id="S3.SS1.SSS2.p2.6.m6.3" class="ltx_Math" alttext="h,w,k^{\text{self}}" display="inline"><semantics id="S3.SS1.SSS2.p2.6.m6.3a"><mrow id="S3.SS1.SSS2.p2.6.m6.3.3.1" xref="S3.SS1.SSS2.p2.6.m6.3.3.2.cmml"><mi id="S3.SS1.SSS2.p2.6.m6.1.1" xref="S3.SS1.SSS2.p2.6.m6.1.1.cmml">h</mi><mo id="S3.SS1.SSS2.p2.6.m6.3.3.1.2" xref="S3.SS1.SSS2.p2.6.m6.3.3.2.cmml">,</mo><mi id="S3.SS1.SSS2.p2.6.m6.2.2" xref="S3.SS1.SSS2.p2.6.m6.2.2.cmml">w</mi><mo id="S3.SS1.SSS2.p2.6.m6.3.3.1.3" xref="S3.SS1.SSS2.p2.6.m6.3.3.2.cmml">,</mo><msup id="S3.SS1.SSS2.p2.6.m6.3.3.1.1" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1.cmml"><mi id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.2" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.3" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1.3a.cmml">self</mtext></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.6.m6.3b"><list id="S3.SS1.SSS2.p2.6.m6.3.3.2.cmml" xref="S3.SS1.SSS2.p2.6.m6.3.3.1"><ci id="S3.SS1.SSS2.p2.6.m6.1.1.cmml" xref="S3.SS1.SSS2.p2.6.m6.1.1">â„</ci><ci id="S3.SS1.SSS2.p2.6.m6.2.2.cmml" xref="S3.SS1.SSS2.p2.6.m6.2.2">ğ‘¤</ci><apply id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.cmml" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.1.cmml" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.2.cmml" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.3a.cmml" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.6.m6.3.3.1.1.3.cmml" xref="S3.SS1.SSS2.p2.6.m6.3.3.1.1.3">self</mtext></ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.6.m6.3c">h,w,k^{\text{self}}</annotation></semantics></math> are the height, width and number of keypoints of the heatmap. The Transformer module learns the affinity matrix based on learnable supervised keypoint queries <math id="S3.SS1.SSS2.p2.7.m7.1" class="ltx_Math" alttext="Q^{\text{sup}}\in\mathbb{R}^{k^{\text{sup}}\times c}" display="inline"><semantics id="S3.SS1.SSS2.p2.7.m7.1a"><mrow id="S3.SS1.SSS2.p2.7.m7.1.1" xref="S3.SS1.SSS2.p2.7.m7.1.1.cmml"><msup id="S3.SS1.SSS2.p2.7.m7.1.1.2" xref="S3.SS1.SSS2.p2.7.m7.1.1.2.cmml"><mi id="S3.SS1.SSS2.p2.7.m7.1.1.2.2" xref="S3.SS1.SSS2.p2.7.m7.1.1.2.2.cmml">Q</mi><mtext id="S3.SS1.SSS2.p2.7.m7.1.1.2.3" xref="S3.SS1.SSS2.p2.7.m7.1.1.2.3a.cmml">sup</mtext></msup><mo id="S3.SS1.SSS2.p2.7.m7.1.1.1" xref="S3.SS1.SSS2.p2.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p2.7.m7.1.1.3" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.cmml"><mi id="S3.SS1.SSS2.p2.7.m7.1.1.3.2" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p2.7.m7.1.1.3.3" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.cmml"><msup id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.cmml"><mi id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.2" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.3" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.3a.cmml">sup</mtext></msup><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.1" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.3" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.3.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.7.m7.1b"><apply id="S3.SS1.SSS2.p2.7.m7.1.1.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1"><in id="S3.SS1.SSS2.p2.7.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.1"></in><apply id="S3.SS1.SSS2.p2.7.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.7.m7.1.1.2.1.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS2.p2.7.m7.1.1.2.2.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.2.2">ğ‘„</ci><ci id="S3.SS1.SSS2.p2.7.m7.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p2.7.m7.1.1.2.3.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.2.3">sup</mtext></ci></apply><apply id="S3.SS1.SSS2.p2.7.m7.1.1.3.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.7.m7.1.1.3.1.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p2.7.m7.1.1.3.2.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.2">â„</ci><apply id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3"><times id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.1"></times><apply id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.1.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2">superscript</csymbol><ci id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.2.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.3a.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.3"><mtext mathsize="50%" id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.3.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.2.3">sup</mtext></ci></apply><ci id="S3.SS1.SSS2.p2.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p2.7.m7.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.7.m7.1c">Q^{\text{sup}}\in\mathbb{R}^{k^{\text{sup}}\times c}</annotation></semantics></math> and context feature <math id="S3.SS1.SSS2.p2.8.m8.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS2.p2.8.m8.1a"><msub id="S3.SS1.SSS2.p2.8.m8.1.1" xref="S3.SS1.SSS2.p2.8.m8.1.1.cmml"><mi id="S3.SS1.SSS2.p2.8.m8.1.1.2" xref="S3.SS1.SSS2.p2.8.m8.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS2.p2.8.m8.1.1.3" xref="S3.SS1.SSS2.p2.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.8.m8.1b"><apply id="S3.SS1.SSS2.p2.8.m8.1.1.cmml" xref="S3.SS1.SSS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.8.m8.1.1.1.cmml" xref="S3.SS1.SSS2.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p2.8.m8.1.1.2.cmml" xref="S3.SS1.SSS2.p2.8.m8.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p2.8.m8.1.1.3.cmml" xref="S3.SS1.SSS2.p2.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.8.m8.1c">F_{t}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.SSS2.p3" class="ltx_para">
<p id="S3.SS1.SSS2.p3.3" class="ltx_p">A standard transformer decoder layer consists of a multi-head attention layer and a feed-forward network. The spatial feature <math id="S3.SS1.SSS2.p3.1.m1.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS2.p3.1.m1.1a"><msub id="S3.SS1.SSS2.p3.1.m1.1.1" xref="S3.SS1.SSS2.p3.1.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p3.1.m1.1.1.2" xref="S3.SS1.SSS2.p3.1.m1.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS2.p3.1.m1.1.1.3" xref="S3.SS1.SSS2.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.1.m1.1b"><apply id="S3.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p3.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.1.m1.1c">F_{t}</annotation></semantics></math> is flattened to <math id="S3.SS1.SSS2.p3.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS1.SSS2.p3.2.m2.1a"><mi id="S3.SS1.SSS2.p3.2.m2.1.1" xref="S3.SS1.SSS2.p3.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.2.m2.1b"><ci id="S3.SS1.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.2.m2.1c">n</annotation></semantics></math> tokens such that <math id="S3.SS1.SSS2.p3.3.m3.1" class="ltx_Math" alttext="F_{t}\in\mathbb{R}^{n\times c}" display="inline"><semantics id="S3.SS1.SSS2.p3.3.m3.1a"><mrow id="S3.SS1.SSS2.p3.3.m3.1.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.cmml"><msub id="S3.SS1.SSS2.p3.3.m3.1.1.2" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.cmml"><mi id="S3.SS1.SSS2.p3.3.m3.1.1.2.2" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.2.cmml">F</mi><mi id="S3.SS1.SSS2.p3.3.m3.1.1.2.3" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS1.SSS2.p3.3.m3.1.1.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p3.3.m3.1.1.3" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.cmml"><mi id="S3.SS1.SSS2.p3.3.m3.1.1.3.2" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p3.3.m3.1.1.3.3" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.2" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.1" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.3" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.3.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.3.m3.1b"><apply id="S3.SS1.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1"><in id="S3.SS1.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.1"></in><apply id="S3.SS1.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS2.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.2">ğ¹</ci><ci id="S3.SS1.SSS2.p3.3.m3.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.2">â„</ci><apply id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3"><times id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.2">ğ‘›</ci><ci id="S3.SS1.SSS2.p3.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p3.3.m3.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.3.m3.1c">F_{t}\in\mathbb{R}^{n\times c}</annotation></semantics></math>. In a single-head attention layer,</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="Q=Q^{\text{sup}}T^{Q},\&gt;K=F_{t}T^{K},\&gt;V=F_{t}T^{V}" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">Q</mi><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><msup id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.cmml">Q</mi><mtext id="S3.E2.m1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.3.2.3a.cmml">sup</mtext></msup><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml">â€‹</mo><msup id="S3.E2.m1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.3.3.2.cmml">T</mi><mi id="S3.E2.m1.1.1.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.3.3.3.cmml">Q</mi></msup></mrow></mrow><mo rspace="0.387em" id="S3.E2.m1.2.2.2.3" xref="S3.E2.m1.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.3.cmml"><mrow id="S3.E2.m1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.2.cmml">K</mi><mo id="S3.E2.m1.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.3.cmml"><msub id="S3.E2.m1.2.2.2.2.1.1.3.2" xref="S3.E2.m1.2.2.2.2.1.1.3.2.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.3.2.2" xref="S3.E2.m1.2.2.2.2.1.1.3.2.2.cmml">F</mi><mi id="S3.E2.m1.2.2.2.2.1.1.3.2.3" xref="S3.E2.m1.2.2.2.2.1.1.3.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.1.1.3.1" xref="S3.E2.m1.2.2.2.2.1.1.3.1.cmml">â€‹</mo><msup id="S3.E2.m1.2.2.2.2.1.1.3.3" xref="S3.E2.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.3.3.2" xref="S3.E2.m1.2.2.2.2.1.1.3.3.2.cmml">T</mi><mi id="S3.E2.m1.2.2.2.2.1.1.3.3.3" xref="S3.E2.m1.2.2.2.2.1.1.3.3.3.cmml">K</mi></msup></mrow></mrow><mo rspace="0.387em" id="S3.E2.m1.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.2.2.cmml">V</mi><mo id="S3.E2.m1.2.2.2.2.2.2.1" xref="S3.E2.m1.2.2.2.2.2.2.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.2.2.3.cmml"><msub id="S3.E2.m1.2.2.2.2.2.2.3.2" xref="S3.E2.m1.2.2.2.2.2.2.3.2.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.3.2.2" xref="S3.E2.m1.2.2.2.2.2.2.3.2.2.cmml">F</mi><mi id="S3.E2.m1.2.2.2.2.2.2.3.2.3" xref="S3.E2.m1.2.2.2.2.2.2.3.2.3.cmml">t</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.2.3.1" xref="S3.E2.m1.2.2.2.2.2.2.3.1.cmml">â€‹</mo><msup id="S3.E2.m1.2.2.2.2.2.2.3.3" xref="S3.E2.m1.2.2.2.2.2.2.3.3.cmml"><mi id="S3.E2.m1.2.2.2.2.2.2.3.3.2" xref="S3.E2.m1.2.2.2.2.2.2.3.3.2.cmml">T</mi><mi id="S3.E2.m1.2.2.2.2.2.2.3.3.3" xref="S3.E2.m1.2.2.2.2.2.2.3.3.3.cmml">V</mi></msup></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3a.cmml" xref="S3.E2.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><ci id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2">ğ‘„</ci><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"></times><apply id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2">ğ‘„</ci><ci id="S3.E2.m1.1.1.1.1.3.2.3a.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3"><mtext mathsize="70%" id="S3.E2.m1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3">sup</mtext></ci></apply><apply id="S3.E2.m1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.3">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.3.2">ğ‘‡</ci><ci id="S3.E2.m1.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3.3">ğ‘„</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.3a.cmml" xref="S3.E2.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.2.2.2.2.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1"><eq id="S3.E2.m1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1"></eq><ci id="S3.E2.m1.2.2.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.2">ğ¾</ci><apply id="S3.E2.m1.2.2.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3"><times id="S3.E2.m1.2.2.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.1"></times><apply id="S3.E2.m1.2.2.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.2.2">ğ¹</ci><ci id="S3.E2.m1.2.2.2.2.1.1.3.2.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.2.2.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.3">superscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.3.2">ğ‘‡</ci><ci id="S3.E2.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.3.3.3">ğ¾</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2"><eq id="S3.E2.m1.2.2.2.2.2.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.1"></eq><ci id="S3.E2.m1.2.2.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.2">ğ‘‰</ci><apply id="S3.E2.m1.2.2.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3"><times id="S3.E2.m1.2.2.2.2.2.2.3.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.1"></times><apply id="S3.E2.m1.2.2.2.2.2.2.3.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.3.2.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.2.3.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.2.2">ğ¹</ci><ci id="S3.E2.m1.2.2.2.2.2.2.3.2.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.2.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.2.2.2.2.2.2.3.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.2.2.3.3.1.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.3">superscript</csymbol><ci id="S3.E2.m1.2.2.2.2.2.2.3.3.2.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.3.2">ğ‘‡</ci><ci id="S3.E2.m1.2.2.2.2.2.2.3.3.3.cmml" xref="S3.E2.m1.2.2.2.2.2.2.3.3.3">ğ‘‰</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">Q=Q^{\text{sup}}T^{Q},\&gt;K=F_{t}T^{K},\&gt;V=F_{t}T^{V}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p3.8" class="ltx_p">where <math id="S3.SS1.SSS2.p3.4.m1.3" class="ltx_Math" alttext="T^{Q},T^{K},T^{V}\in\mathbb{R}^{c\times c}" display="inline"><semantics id="S3.SS1.SSS2.p3.4.m1.3a"><mrow id="S3.SS1.SSS2.p3.4.m1.3.3" xref="S3.SS1.SSS2.p3.4.m1.3.3.cmml"><mrow id="S3.SS1.SSS2.p3.4.m1.3.3.3.3" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.4.cmml"><msup id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.2" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.2.cmml">T</mi><mi id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.3" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.3.cmml">Q</mi></msup><mo id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.4" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.4.cmml">,</mo><msup id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.2" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.2.cmml">T</mi><mi id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.3" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.3.cmml">K</mi></msup><mo id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.5" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.4.cmml">,</mo><msup id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.cmml"><mi id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.2" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.2.cmml">T</mi><mi id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.3" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.3.cmml">V</mi></msup></mrow><mo id="S3.SS1.SSS2.p3.4.m1.3.3.4" xref="S3.SS1.SSS2.p3.4.m1.3.3.4.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p3.4.m1.3.3.5" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.cmml"><mi id="S3.SS1.SSS2.p3.4.m1.3.3.5.2" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p3.4.m1.3.3.5.3" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.cmml"><mi id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.2" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.2.cmml">c</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.1" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.3" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.3.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.4.m1.3b"><apply id="S3.SS1.SSS2.p3.4.m1.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3"><in id="S3.SS1.SSS2.p3.4.m1.3.3.4.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.4"></in><list id="S3.SS1.SSS2.p3.4.m1.3.3.3.4.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3"><apply id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.2">ğ‘‡</ci><ci id="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.1.1.1.1.1.3">ğ‘„</ci></apply><apply id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2">superscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.2">ğ‘‡</ci><ci id="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.2.2.2.2.2.3">ğ¾</ci></apply><apply id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.1.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3">superscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.2.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.2">ğ‘‡</ci><ci id="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.3.3.3.3">ğ‘‰</ci></apply></list><apply id="S3.SS1.SSS2.p3.4.m1.3.3.5.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.4.m1.3.3.5.1.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5">superscript</csymbol><ci id="S3.SS1.SSS2.p3.4.m1.3.3.5.2.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.2">â„</ci><apply id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3"><times id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.1.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.1"></times><ci id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.2.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.2">ğ‘</ci><ci id="S3.SS1.SSS2.p3.4.m1.3.3.5.3.3.cmml" xref="S3.SS1.SSS2.p3.4.m1.3.3.5.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.4.m1.3c">T^{Q},T^{K},T^{V}\in\mathbb{R}^{c\times c}</annotation></semantics></math> are weight matrices. We use <math id="S3.SS1.SSS2.p3.5.m2.1" class="ltx_Math" alttext="Q^{\text{sup}}" display="inline"><semantics id="S3.SS1.SSS2.p3.5.m2.1a"><msup id="S3.SS1.SSS2.p3.5.m2.1.1" xref="S3.SS1.SSS2.p3.5.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.5.m2.1.1.2" xref="S3.SS1.SSS2.p3.5.m2.1.1.2.cmml">Q</mi><mtext id="S3.SS1.SSS2.p3.5.m2.1.1.3" xref="S3.SS1.SSS2.p3.5.m2.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.5.m2.1b"><apply id="S3.SS1.SSS2.p3.5.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.5.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.5.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p3.5.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.5.m2.1.1.2">ğ‘„</ci><ci id="S3.SS1.SSS2.p3.5.m2.1.1.3a.cmml" xref="S3.SS1.SSS2.p3.5.m2.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p3.5.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.5.m2.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.5.m2.1c">Q^{\text{sup}}</annotation></semantics></math> as the query input and the network feature <math id="S3.SS1.SSS2.p3.6.m3.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS2.p3.6.m3.1a"><msub id="S3.SS1.SSS2.p3.6.m3.1.1" xref="S3.SS1.SSS2.p3.6.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p3.6.m3.1.1.2" xref="S3.SS1.SSS2.p3.6.m3.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS2.p3.6.m3.1.1.3" xref="S3.SS1.SSS2.p3.6.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.6.m3.1b"><apply id="S3.SS1.SSS2.p3.6.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.6.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.6.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p3.6.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.6.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p3.6.m3.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p3.6.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p3.6.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.6.m3.1c">F_{t}</annotation></semantics></math> as the key and value inputs. The attention weights <math id="S3.SS1.SSS2.p3.7.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.SSS2.p3.7.m4.1a"><mi id="S3.SS1.SSS2.p3.7.m4.1.1" xref="S3.SS1.SSS2.p3.7.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.7.m4.1b"><ci id="S3.SS1.SSS2.p3.7.m4.1.1.cmml" xref="S3.SS1.SSS2.p3.7.m4.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.7.m4.1c">A</annotation></semantics></math> and attention results <math id="S3.SS1.SSS2.p3.8.m5.1" class="ltx_Math" alttext="\mathrm{attn}" display="inline"><semantics id="S3.SS1.SSS2.p3.8.m5.1a"><mi id="S3.SS1.SSS2.p3.8.m5.1.1" xref="S3.SS1.SSS2.p3.8.m5.1.1.cmml">attn</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.8.m5.1b"><ci id="S3.SS1.SSS2.p3.8.m5.1.1.cmml" xref="S3.SS1.SSS2.p3.8.m5.1.1">attn</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.8.m5.1c">\mathrm{attn}</annotation></semantics></math> is given by,</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="A=\mathrm{Softmax}\left(QK^{\top}\right)" display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mi id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml">A</mi><mo id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml">Softmax</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mo id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml">â€‹</mo><msup id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.1.1.3.2.cmml">K</mi><mo id="S3.E3.m1.1.1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.1.1.3.3.cmml">âŠ¤</mo></msup></mrow><mo id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"></eq><ci id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3">ğ´</ci><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3">Softmax</ci><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><times id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">ğ‘„</ci><apply id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.2">ğ¾</ci><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3.3">top</csymbol></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">A=\mathrm{Softmax}\left(QK^{\top}\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\mathrm{attn}\left(Q^{\text{sup}},F_{t},F_{t}\right)=AV" display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><mrow id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml"><mi id="S3.E4.m1.3.3.3.5" xref="S3.E4.m1.3.3.3.5.cmml">attn</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.3.4" xref="S3.E4.m1.3.3.3.4.cmml">â€‹</mo><mrow id="S3.E4.m1.3.3.3.3.3" xref="S3.E4.m1.3.3.3.3.4.cmml"><mo id="S3.E4.m1.3.3.3.3.3.4" xref="S3.E4.m1.3.3.3.3.4.cmml">(</mo><msup id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">Q</mi><mtext id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3a.cmml">sup</mtext></msup><mo id="S3.E4.m1.3.3.3.3.3.5" xref="S3.E4.m1.3.3.3.3.4.cmml">,</mo><msub id="S3.E4.m1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.cmml"><mi id="S3.E4.m1.2.2.2.2.2.2.2" xref="S3.E4.m1.2.2.2.2.2.2.2.cmml">F</mi><mi id="S3.E4.m1.2.2.2.2.2.2.3" xref="S3.E4.m1.2.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E4.m1.3.3.3.3.3.6" xref="S3.E4.m1.3.3.3.3.4.cmml">,</mo><msub id="S3.E4.m1.3.3.3.3.3.3" xref="S3.E4.m1.3.3.3.3.3.3.cmml"><mi id="S3.E4.m1.3.3.3.3.3.3.2" xref="S3.E4.m1.3.3.3.3.3.3.2.cmml">F</mi><mi id="S3.E4.m1.3.3.3.3.3.3.3" xref="S3.E4.m1.3.3.3.3.3.3.3.cmml">t</mi></msub><mo id="S3.E4.m1.3.3.3.3.3.7" xref="S3.E4.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.3.3.4" xref="S3.E4.m1.3.3.4.cmml">=</mo><mrow id="S3.E4.m1.3.3.5" xref="S3.E4.m1.3.3.5.cmml"><mi id="S3.E4.m1.3.3.5.2" xref="S3.E4.m1.3.3.5.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.5.1" xref="S3.E4.m1.3.3.5.1.cmml">â€‹</mo><mi id="S3.E4.m1.3.3.5.3" xref="S3.E4.m1.3.3.5.3.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><eq id="S3.E4.m1.3.3.4.cmml" xref="S3.E4.m1.3.3.4"></eq><apply id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3"><times id="S3.E4.m1.3.3.3.4.cmml" xref="S3.E4.m1.3.3.3.4"></times><ci id="S3.E4.m1.3.3.3.5.cmml" xref="S3.E4.m1.3.3.3.5">attn</ci><vector id="S3.E4.m1.3.3.3.3.4.cmml" xref="S3.E4.m1.3.3.3.3.3"><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">ğ‘„</ci><ci id="S3.E4.m1.1.1.1.1.1.1.3a.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">sup</mtext></ci></apply><apply id="S3.E4.m1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E4.m1.2.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.2">ğ¹</ci><ci id="S3.E4.m1.2.2.2.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.E4.m1.3.3.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.3.3.3.3.1.cmml" xref="S3.E4.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S3.E4.m1.3.3.3.3.3.3.2.cmml" xref="S3.E4.m1.3.3.3.3.3.3.2">ğ¹</ci><ci id="S3.E4.m1.3.3.3.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3.3.3.3">ğ‘¡</ci></apply></vector></apply><apply id="S3.E4.m1.3.3.5.cmml" xref="S3.E4.m1.3.3.5"><times id="S3.E4.m1.3.3.5.1.cmml" xref="S3.E4.m1.3.3.5.1"></times><ci id="S3.E4.m1.3.3.5.2.cmml" xref="S3.E4.m1.3.3.5.2">ğ´</ci><ci id="S3.E4.m1.3.3.5.3.cmml" xref="S3.E4.m1.3.3.5.3">ğ‘‰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\mathrm{attn}\left(Q^{\text{sup}},F_{t},F_{t}\right)=AV</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p3.15" class="ltx_p">In multi-head attention <math id="S3.SS1.SSS2.p3.9.m1.1" class="ltx_Math" alttext="\mathrm{MHA}()" display="inline"><semantics id="S3.SS1.SSS2.p3.9.m1.1a"><mrow id="S3.SS1.SSS2.p3.9.m1.1.1" xref="S3.SS1.SSS2.p3.9.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p3.9.m1.1.1.2" xref="S3.SS1.SSS2.p3.9.m1.1.1.2.cmml">MHA</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p3.9.m1.1.1.1" xref="S3.SS1.SSS2.p3.9.m1.1.1.1.cmml">â€‹</mo><mrow id="S3.SS1.SSS2.p3.9.m1.1.1.3.2" xref="S3.SS1.SSS2.p3.9.m1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p3.9.m1.1.1.3.2.1" xref="S3.SS1.SSS2.p3.9.m1.1.1.3.1.cmml">(</mo><mo stretchy="false" id="S3.SS1.SSS2.p3.9.m1.1.1.3.2.2" xref="S3.SS1.SSS2.p3.9.m1.1.1.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.9.m1.1b"><apply id="S3.SS1.SSS2.p3.9.m1.1.1.cmml" xref="S3.SS1.SSS2.p3.9.m1.1.1"><times id="S3.SS1.SSS2.p3.9.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.9.m1.1.1.1"></times><ci id="S3.SS1.SSS2.p3.9.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p3.9.m1.1.1.2">MHA</ci><list id="S3.SS1.SSS2.p3.9.m1.1.1.3.1.cmml" xref="S3.SS1.SSS2.p3.9.m1.1.1.3.2.1"></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.9.m1.1c">\mathrm{MHA}()</annotation></semantics></math>, <math id="S3.SS1.SSS2.p3.10.m2.1" class="ltx_Math" alttext="Q^{\text{sup}}" display="inline"><semantics id="S3.SS1.SSS2.p3.10.m2.1a"><msup id="S3.SS1.SSS2.p3.10.m2.1.1" xref="S3.SS1.SSS2.p3.10.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.10.m2.1.1.2" xref="S3.SS1.SSS2.p3.10.m2.1.1.2.cmml">Q</mi><mtext id="S3.SS1.SSS2.p3.10.m2.1.1.3" xref="S3.SS1.SSS2.p3.10.m2.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.10.m2.1b"><apply id="S3.SS1.SSS2.p3.10.m2.1.1.cmml" xref="S3.SS1.SSS2.p3.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.10.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.10.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p3.10.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.10.m2.1.1.2">ğ‘„</ci><ci id="S3.SS1.SSS2.p3.10.m2.1.1.3a.cmml" xref="S3.SS1.SSS2.p3.10.m2.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p3.10.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.10.m2.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.10.m2.1c">Q^{\text{sup}}</annotation></semantics></math> and <math id="S3.SS1.SSS2.p3.11.m3.1" class="ltx_Math" alttext="F_{t}" display="inline"><semantics id="S3.SS1.SSS2.p3.11.m3.1a"><msub id="S3.SS1.SSS2.p3.11.m3.1.1" xref="S3.SS1.SSS2.p3.11.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p3.11.m3.1.1.2" xref="S3.SS1.SSS2.p3.11.m3.1.1.2.cmml">F</mi><mi id="S3.SS1.SSS2.p3.11.m3.1.1.3" xref="S3.SS1.SSS2.p3.11.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.11.m3.1b"><apply id="S3.SS1.SSS2.p3.11.m3.1.1.cmml" xref="S3.SS1.SSS2.p3.11.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.11.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p3.11.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.11.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p3.11.m3.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p3.11.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p3.11.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.11.m3.1c">F_{t}</annotation></semantics></math> is split to <math id="S3.SS1.SSS2.p3.12.m4.3" class="ltx_Math" alttext="Q^{\text{sup}}_{1},\dots,Q^{\text{sup}}_{M}" display="inline"><semantics id="S3.SS1.SSS2.p3.12.m4.3a"><mrow id="S3.SS1.SSS2.p3.12.m4.3.3.2" xref="S3.SS1.SSS2.p3.12.m4.3.3.3.cmml"><msubsup id="S3.SS1.SSS2.p3.12.m4.2.2.1.1" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.cmml"><mi id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.2" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.2.cmml">Q</mi><mn id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.3" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.3.cmml">1</mn><mtext id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.3" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.3a.cmml">sup</mtext></msubsup><mo id="S3.SS1.SSS2.p3.12.m4.3.3.2.3" xref="S3.SS1.SSS2.p3.12.m4.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.SSS2.p3.12.m4.1.1" xref="S3.SS1.SSS2.p3.12.m4.1.1.cmml">â€¦</mi><mo id="S3.SS1.SSS2.p3.12.m4.3.3.2.4" xref="S3.SS1.SSS2.p3.12.m4.3.3.3.cmml">,</mo><msubsup id="S3.SS1.SSS2.p3.12.m4.3.3.2.2" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.cmml"><mi id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.2" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.2.cmml">Q</mi><mi id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.3" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.3.cmml">M</mi><mtext id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.3" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.3a.cmml">sup</mtext></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.12.m4.3b"><list id="S3.SS1.SSS2.p3.12.m4.3.3.3.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2"><apply id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.1.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1">subscript</csymbol><apply id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.2">ğ‘„</ci><ci id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.2.3">sup</mtext></ci></apply><cn type="integer" id="S3.SS1.SSS2.p3.12.m4.2.2.1.1.3.cmml" xref="S3.SS1.SSS2.p3.12.m4.2.2.1.1.3">1</cn></apply><ci id="S3.SS1.SSS2.p3.12.m4.1.1.cmml" xref="S3.SS1.SSS2.p3.12.m4.1.1">â€¦</ci><apply id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.1.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2">subscript</csymbol><apply id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.1.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2">superscript</csymbol><ci id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.2.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.2">ğ‘„</ci><ci id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.3a.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.3.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.2.3">sup</mtext></ci></apply><ci id="S3.SS1.SSS2.p3.12.m4.3.3.2.2.3.cmml" xref="S3.SS1.SSS2.p3.12.m4.3.3.2.2.3">ğ‘€</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.12.m4.3c">Q^{\text{sup}}_{1},\dots,Q^{\text{sup}}_{M}</annotation></semantics></math> and <math id="S3.SS1.SSS2.p3.13.m5.7" class="ltx_Math" alttext="F_{(t,1)},\dots,F_{(t,M)}" display="inline"><semantics id="S3.SS1.SSS2.p3.13.m5.7a"><mrow id="S3.SS1.SSS2.p3.13.m5.7.7.2" xref="S3.SS1.SSS2.p3.13.m5.7.7.3.cmml"><msub id="S3.SS1.SSS2.p3.13.m5.6.6.1.1" xref="S3.SS1.SSS2.p3.13.m5.6.6.1.1.cmml"><mi id="S3.SS1.SSS2.p3.13.m5.6.6.1.1.2" xref="S3.SS1.SSS2.p3.13.m5.6.6.1.1.2.cmml">F</mi><mrow id="S3.SS1.SSS2.p3.13.m5.2.2.2.4" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p3.13.m5.2.2.2.4.1" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.3.cmml">(</mo><mi id="S3.SS1.SSS2.p3.13.m5.1.1.1.1" xref="S3.SS1.SSS2.p3.13.m5.1.1.1.1.cmml">t</mi><mo id="S3.SS1.SSS2.p3.13.m5.2.2.2.4.2" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.3.cmml">,</mo><mn id="S3.SS1.SSS2.p3.13.m5.2.2.2.2" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.SSS2.p3.13.m5.2.2.2.4.3" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.3.cmml">)</mo></mrow></msub><mo id="S3.SS1.SSS2.p3.13.m5.7.7.2.3" xref="S3.SS1.SSS2.p3.13.m5.7.7.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.SSS2.p3.13.m5.5.5" xref="S3.SS1.SSS2.p3.13.m5.5.5.cmml">â€¦</mi><mo id="S3.SS1.SSS2.p3.13.m5.7.7.2.4" xref="S3.SS1.SSS2.p3.13.m5.7.7.3.cmml">,</mo><msub id="S3.SS1.SSS2.p3.13.m5.7.7.2.2" xref="S3.SS1.SSS2.p3.13.m5.7.7.2.2.cmml"><mi id="S3.SS1.SSS2.p3.13.m5.7.7.2.2.2" xref="S3.SS1.SSS2.p3.13.m5.7.7.2.2.2.cmml">F</mi><mrow id="S3.SS1.SSS2.p3.13.m5.4.4.2.4" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS2.p3.13.m5.4.4.2.4.1" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.3.cmml">(</mo><mi id="S3.SS1.SSS2.p3.13.m5.3.3.1.1" xref="S3.SS1.SSS2.p3.13.m5.3.3.1.1.cmml">t</mi><mo id="S3.SS1.SSS2.p3.13.m5.4.4.2.4.2" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.3.cmml">,</mo><mi id="S3.SS1.SSS2.p3.13.m5.4.4.2.2" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.2.cmml">M</mi><mo stretchy="false" id="S3.SS1.SSS2.p3.13.m5.4.4.2.4.3" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.3.cmml">)</mo></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.13.m5.7b"><list id="S3.SS1.SSS2.p3.13.m5.7.7.3.cmml" xref="S3.SS1.SSS2.p3.13.m5.7.7.2"><apply id="S3.SS1.SSS2.p3.13.m5.6.6.1.1.cmml" xref="S3.SS1.SSS2.p3.13.m5.6.6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.13.m5.6.6.1.1.1.cmml" xref="S3.SS1.SSS2.p3.13.m5.6.6.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p3.13.m5.6.6.1.1.2.cmml" xref="S3.SS1.SSS2.p3.13.m5.6.6.1.1.2">ğ¹</ci><interval closure="open" id="S3.SS1.SSS2.p3.13.m5.2.2.2.3.cmml" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.4"><ci id="S3.SS1.SSS2.p3.13.m5.1.1.1.1.cmml" xref="S3.SS1.SSS2.p3.13.m5.1.1.1.1">ğ‘¡</ci><cn type="integer" id="S3.SS1.SSS2.p3.13.m5.2.2.2.2.cmml" xref="S3.SS1.SSS2.p3.13.m5.2.2.2.2">1</cn></interval></apply><ci id="S3.SS1.SSS2.p3.13.m5.5.5.cmml" xref="S3.SS1.SSS2.p3.13.m5.5.5">â€¦</ci><apply id="S3.SS1.SSS2.p3.13.m5.7.7.2.2.cmml" xref="S3.SS1.SSS2.p3.13.m5.7.7.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.13.m5.7.7.2.2.1.cmml" xref="S3.SS1.SSS2.p3.13.m5.7.7.2.2">subscript</csymbol><ci id="S3.SS1.SSS2.p3.13.m5.7.7.2.2.2.cmml" xref="S3.SS1.SSS2.p3.13.m5.7.7.2.2.2">ğ¹</ci><interval closure="open" id="S3.SS1.SSS2.p3.13.m5.4.4.2.3.cmml" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.4"><ci id="S3.SS1.SSS2.p3.13.m5.3.3.1.1.cmml" xref="S3.SS1.SSS2.p3.13.m5.3.3.1.1">ğ‘¡</ci><ci id="S3.SS1.SSS2.p3.13.m5.4.4.2.2.cmml" xref="S3.SS1.SSS2.p3.13.m5.4.4.2.2">ğ‘€</ci></interval></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.13.m5.7c">F_{(t,1)},\dots,F_{(t,M)}</annotation></semantics></math>, where <math id="S3.SS1.SSS2.p3.14.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS1.SSS2.p3.14.m6.1a"><mi id="S3.SS1.SSS2.p3.14.m6.1.1" xref="S3.SS1.SSS2.p3.14.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.14.m6.1b"><ci id="S3.SS1.SSS2.p3.14.m6.1.1.cmml" xref="S3.SS1.SSS2.p3.14.m6.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.14.m6.1c">M</annotation></semantics></math> is the number of heads and every part is split to dimension <math id="S3.SS1.SSS2.p3.15.m7.1" class="ltx_Math" alttext="c^{\prime}=c/M" display="inline"><semantics id="S3.SS1.SSS2.p3.15.m7.1a"><mrow id="S3.SS1.SSS2.p3.15.m7.1.1" xref="S3.SS1.SSS2.p3.15.m7.1.1.cmml"><msup id="S3.SS1.SSS2.p3.15.m7.1.1.2" xref="S3.SS1.SSS2.p3.15.m7.1.1.2.cmml"><mi id="S3.SS1.SSS2.p3.15.m7.1.1.2.2" xref="S3.SS1.SSS2.p3.15.m7.1.1.2.2.cmml">c</mi><mo id="S3.SS1.SSS2.p3.15.m7.1.1.2.3" xref="S3.SS1.SSS2.p3.15.m7.1.1.2.3.cmml">â€²</mo></msup><mo id="S3.SS1.SSS2.p3.15.m7.1.1.1" xref="S3.SS1.SSS2.p3.15.m7.1.1.1.cmml">=</mo><mrow id="S3.SS1.SSS2.p3.15.m7.1.1.3" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.cmml"><mi id="S3.SS1.SSS2.p3.15.m7.1.1.3.2" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.2.cmml">c</mi><mo id="S3.SS1.SSS2.p3.15.m7.1.1.3.1" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.1.cmml">/</mo><mi id="S3.SS1.SSS2.p3.15.m7.1.1.3.3" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p3.15.m7.1b"><apply id="S3.SS1.SSS2.p3.15.m7.1.1.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1"><eq id="S3.SS1.SSS2.p3.15.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.1"></eq><apply id="S3.SS1.SSS2.p3.15.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p3.15.m7.1.1.2.1.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS2.p3.15.m7.1.1.2.2.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.2.2">ğ‘</ci><ci id="S3.SS1.SSS2.p3.15.m7.1.1.2.3.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.2.3">â€²</ci></apply><apply id="S3.SS1.SSS2.p3.15.m7.1.1.3.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.3"><divide id="S3.SS1.SSS2.p3.15.m7.1.1.3.1.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.1"></divide><ci id="S3.SS1.SSS2.p3.15.m7.1.1.3.2.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.2">ğ‘</ci><ci id="S3.SS1.SSS2.p3.15.m7.1.1.3.3.cmml" xref="S3.SS1.SSS2.p3.15.m7.1.1.3.3">ğ‘€</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p3.15.m7.1c">c^{\prime}=c/M</annotation></semantics></math>,</p>
</div>
<div id="S3.SS1.SSS2.p4" class="ltx_para">
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.11" class="ltx_Math" alttext="\tilde{Q}^{\text{sup}}=\left[\mathrm{attn}_{1}(Q^{\text{sup}}_{1},F_{(t,1)},F_{(t,1)});\dots;\mathrm{attn}_{M}(Q^{\text{sup}}_{M},F_{(t,M)},F_{(t,M)})\right]" display="block"><semantics id="S3.E5.m1.11a"><mrow id="S3.E5.m1.11.11" xref="S3.E5.m1.11.11.cmml"><msup id="S3.E5.m1.11.11.4" xref="S3.E5.m1.11.11.4.cmml"><mover accent="true" id="S3.E5.m1.11.11.4.2" xref="S3.E5.m1.11.11.4.2.cmml"><mi id="S3.E5.m1.11.11.4.2.2" xref="S3.E5.m1.11.11.4.2.2.cmml">Q</mi><mo id="S3.E5.m1.11.11.4.2.1" xref="S3.E5.m1.11.11.4.2.1.cmml">~</mo></mover><mtext id="S3.E5.m1.11.11.4.3" xref="S3.E5.m1.11.11.4.3a.cmml">sup</mtext></msup><mo id="S3.E5.m1.11.11.3" xref="S3.E5.m1.11.11.3.cmml">=</mo><mrow id="S3.E5.m1.11.11.2.2" xref="S3.E5.m1.11.11.2.3.cmml"><mo id="S3.E5.m1.11.11.2.2.3" xref="S3.E5.m1.11.11.2.3.cmml">[</mo><mrow id="S3.E5.m1.10.10.1.1.1" xref="S3.E5.m1.10.10.1.1.1.cmml"><msub id="S3.E5.m1.10.10.1.1.1.5" xref="S3.E5.m1.10.10.1.1.1.5.cmml"><mi id="S3.E5.m1.10.10.1.1.1.5.2" xref="S3.E5.m1.10.10.1.1.1.5.2.cmml">attn</mi><mn id="S3.E5.m1.10.10.1.1.1.5.3" xref="S3.E5.m1.10.10.1.1.1.5.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.10.10.1.1.1.4" xref="S3.E5.m1.10.10.1.1.1.4.cmml">â€‹</mo><mrow id="S3.E5.m1.10.10.1.1.1.3.3" xref="S3.E5.m1.10.10.1.1.1.3.4.cmml"><mo stretchy="false" id="S3.E5.m1.10.10.1.1.1.3.3.4" xref="S3.E5.m1.10.10.1.1.1.3.4.cmml">(</mo><msubsup id="S3.E5.m1.10.10.1.1.1.1.1.1" xref="S3.E5.m1.10.10.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.cmml">Q</mi><mn id="S3.E5.m1.10.10.1.1.1.1.1.1.3" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3.cmml">1</mn><mtext id="S3.E5.m1.10.10.1.1.1.1.1.1.2.3" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.3a.cmml">sup</mtext></msubsup><mo id="S3.E5.m1.10.10.1.1.1.3.3.5" xref="S3.E5.m1.10.10.1.1.1.3.4.cmml">,</mo><msub id="S3.E5.m1.10.10.1.1.1.2.2.2" xref="S3.E5.m1.10.10.1.1.1.2.2.2.cmml"><mi id="S3.E5.m1.10.10.1.1.1.2.2.2.2" xref="S3.E5.m1.10.10.1.1.1.2.2.2.2.cmml">F</mi><mrow id="S3.E5.m1.2.2.2.4" xref="S3.E5.m1.2.2.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.2.2.2.4.1" xref="S3.E5.m1.2.2.2.3.cmml">(</mo><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">t</mi><mo id="S3.E5.m1.2.2.2.4.2" xref="S3.E5.m1.2.2.2.3.cmml">,</mo><mn id="S3.E5.m1.2.2.2.2" xref="S3.E5.m1.2.2.2.2.cmml">1</mn><mo stretchy="false" id="S3.E5.m1.2.2.2.4.3" xref="S3.E5.m1.2.2.2.3.cmml">)</mo></mrow></msub><mo id="S3.E5.m1.10.10.1.1.1.3.3.6" xref="S3.E5.m1.10.10.1.1.1.3.4.cmml">,</mo><msub id="S3.E5.m1.10.10.1.1.1.3.3.3" xref="S3.E5.m1.10.10.1.1.1.3.3.3.cmml"><mi id="S3.E5.m1.10.10.1.1.1.3.3.3.2" xref="S3.E5.m1.10.10.1.1.1.3.3.3.2.cmml">F</mi><mrow id="S3.E5.m1.4.4.2.4" xref="S3.E5.m1.4.4.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.2.4.1" xref="S3.E5.m1.4.4.2.3.cmml">(</mo><mi id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml">t</mi><mo id="S3.E5.m1.4.4.2.4.2" xref="S3.E5.m1.4.4.2.3.cmml">,</mo><mn id="S3.E5.m1.4.4.2.2" xref="S3.E5.m1.4.4.2.2.cmml">1</mn><mo stretchy="false" id="S3.E5.m1.4.4.2.4.3" xref="S3.E5.m1.4.4.2.3.cmml">)</mo></mrow></msub><mo stretchy="false" id="S3.E5.m1.10.10.1.1.1.3.3.7" xref="S3.E5.m1.10.10.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.11.11.2.2.4" xref="S3.E5.m1.11.11.2.3.cmml">;</mo><mi mathvariant="normal" id="S3.E5.m1.9.9" xref="S3.E5.m1.9.9.cmml">â€¦</mi><mo id="S3.E5.m1.11.11.2.2.5" xref="S3.E5.m1.11.11.2.3.cmml">;</mo><mrow id="S3.E5.m1.11.11.2.2.2" xref="S3.E5.m1.11.11.2.2.2.cmml"><msub id="S3.E5.m1.11.11.2.2.2.5" xref="S3.E5.m1.11.11.2.2.2.5.cmml"><mi id="S3.E5.m1.11.11.2.2.2.5.2" xref="S3.E5.m1.11.11.2.2.2.5.2.cmml">attn</mi><mi id="S3.E5.m1.11.11.2.2.2.5.3" xref="S3.E5.m1.11.11.2.2.2.5.3.cmml">M</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.11.11.2.2.2.4" xref="S3.E5.m1.11.11.2.2.2.4.cmml">â€‹</mo><mrow id="S3.E5.m1.11.11.2.2.2.3.3" xref="S3.E5.m1.11.11.2.2.2.3.4.cmml"><mo stretchy="false" id="S3.E5.m1.11.11.2.2.2.3.3.4" xref="S3.E5.m1.11.11.2.2.2.3.4.cmml">(</mo><msubsup id="S3.E5.m1.11.11.2.2.2.1.1.1" xref="S3.E5.m1.11.11.2.2.2.1.1.1.cmml"><mi id="S3.E5.m1.11.11.2.2.2.1.1.1.2.2" xref="S3.E5.m1.11.11.2.2.2.1.1.1.2.2.cmml">Q</mi><mi id="S3.E5.m1.11.11.2.2.2.1.1.1.3" xref="S3.E5.m1.11.11.2.2.2.1.1.1.3.cmml">M</mi><mtext id="S3.E5.m1.11.11.2.2.2.1.1.1.2.3" xref="S3.E5.m1.11.11.2.2.2.1.1.1.2.3a.cmml">sup</mtext></msubsup><mo id="S3.E5.m1.11.11.2.2.2.3.3.5" xref="S3.E5.m1.11.11.2.2.2.3.4.cmml">,</mo><msub id="S3.E5.m1.11.11.2.2.2.2.2.2" xref="S3.E5.m1.11.11.2.2.2.2.2.2.cmml"><mi id="S3.E5.m1.11.11.2.2.2.2.2.2.2" xref="S3.E5.m1.11.11.2.2.2.2.2.2.2.cmml">F</mi><mrow id="S3.E5.m1.6.6.2.4" xref="S3.E5.m1.6.6.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.6.6.2.4.1" xref="S3.E5.m1.6.6.2.3.cmml">(</mo><mi id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml">t</mi><mo id="S3.E5.m1.6.6.2.4.2" xref="S3.E5.m1.6.6.2.3.cmml">,</mo><mi id="S3.E5.m1.6.6.2.2" xref="S3.E5.m1.6.6.2.2.cmml">M</mi><mo stretchy="false" id="S3.E5.m1.6.6.2.4.3" xref="S3.E5.m1.6.6.2.3.cmml">)</mo></mrow></msub><mo id="S3.E5.m1.11.11.2.2.2.3.3.6" xref="S3.E5.m1.11.11.2.2.2.3.4.cmml">,</mo><msub id="S3.E5.m1.11.11.2.2.2.3.3.3" xref="S3.E5.m1.11.11.2.2.2.3.3.3.cmml"><mi id="S3.E5.m1.11.11.2.2.2.3.3.3.2" xref="S3.E5.m1.11.11.2.2.2.3.3.3.2.cmml">F</mi><mrow id="S3.E5.m1.8.8.2.4" xref="S3.E5.m1.8.8.2.3.cmml"><mo stretchy="false" id="S3.E5.m1.8.8.2.4.1" xref="S3.E5.m1.8.8.2.3.cmml">(</mo><mi id="S3.E5.m1.7.7.1.1" xref="S3.E5.m1.7.7.1.1.cmml">t</mi><mo id="S3.E5.m1.8.8.2.4.2" xref="S3.E5.m1.8.8.2.3.cmml">,</mo><mi id="S3.E5.m1.8.8.2.2" xref="S3.E5.m1.8.8.2.2.cmml">M</mi><mo stretchy="false" id="S3.E5.m1.8.8.2.4.3" xref="S3.E5.m1.8.8.2.3.cmml">)</mo></mrow></msub><mo stretchy="false" id="S3.E5.m1.11.11.2.2.2.3.3.7" xref="S3.E5.m1.11.11.2.2.2.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.11.11.2.2.6" xref="S3.E5.m1.11.11.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.11b"><apply id="S3.E5.m1.11.11.cmml" xref="S3.E5.m1.11.11"><eq id="S3.E5.m1.11.11.3.cmml" xref="S3.E5.m1.11.11.3"></eq><apply id="S3.E5.m1.11.11.4.cmml" xref="S3.E5.m1.11.11.4"><csymbol cd="ambiguous" id="S3.E5.m1.11.11.4.1.cmml" xref="S3.E5.m1.11.11.4">superscript</csymbol><apply id="S3.E5.m1.11.11.4.2.cmml" xref="S3.E5.m1.11.11.4.2"><ci id="S3.E5.m1.11.11.4.2.1.cmml" xref="S3.E5.m1.11.11.4.2.1">~</ci><ci id="S3.E5.m1.11.11.4.2.2.cmml" xref="S3.E5.m1.11.11.4.2.2">ğ‘„</ci></apply><ci id="S3.E5.m1.11.11.4.3a.cmml" xref="S3.E5.m1.11.11.4.3"><mtext mathsize="70%" id="S3.E5.m1.11.11.4.3.cmml" xref="S3.E5.m1.11.11.4.3">sup</mtext></ci></apply><list id="S3.E5.m1.11.11.2.3.cmml" xref="S3.E5.m1.11.11.2.2"><apply id="S3.E5.m1.10.10.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1"><times id="S3.E5.m1.10.10.1.1.1.4.cmml" xref="S3.E5.m1.10.10.1.1.1.4"></times><apply id="S3.E5.m1.10.10.1.1.1.5.cmml" xref="S3.E5.m1.10.10.1.1.1.5"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.5.1.cmml" xref="S3.E5.m1.10.10.1.1.1.5">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.5.2.cmml" xref="S3.E5.m1.10.10.1.1.1.5.2">attn</ci><cn type="integer" id="S3.E5.m1.10.10.1.1.1.5.3.cmml" xref="S3.E5.m1.10.10.1.1.1.5.3">1</cn></apply><vector id="S3.E5.m1.10.10.1.1.1.3.4.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3"><apply id="S3.E5.m1.10.10.1.1.1.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m1.10.10.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.2">ğ‘„</ci><ci id="S3.E5.m1.10.10.1.1.1.1.1.1.2.3a.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S3.E5.m1.10.10.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.2.3">sup</mtext></ci></apply><cn type="integer" id="S3.E5.m1.10.10.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.10.10.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E5.m1.10.10.1.1.1.2.2.2.cmml" xref="S3.E5.m1.10.10.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.2.2.2.1.cmml" xref="S3.E5.m1.10.10.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.10.10.1.1.1.2.2.2.2">ğ¹</ci><interval closure="open" id="S3.E5.m1.2.2.2.3.cmml" xref="S3.E5.m1.2.2.2.4"><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">ğ‘¡</ci><cn type="integer" id="S3.E5.m1.2.2.2.2.cmml" xref="S3.E5.m1.2.2.2.2">1</cn></interval></apply><apply id="S3.E5.m1.10.10.1.1.1.3.3.3.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.10.10.1.1.1.3.3.3.1.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E5.m1.10.10.1.1.1.3.3.3.2.cmml" xref="S3.E5.m1.10.10.1.1.1.3.3.3.2">ğ¹</ci><interval closure="open" id="S3.E5.m1.4.4.2.3.cmml" xref="S3.E5.m1.4.4.2.4"><ci id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1.1">ğ‘¡</ci><cn type="integer" id="S3.E5.m1.4.4.2.2.cmml" xref="S3.E5.m1.4.4.2.2">1</cn></interval></apply></vector></apply><ci id="S3.E5.m1.9.9.cmml" xref="S3.E5.m1.9.9">â€¦</ci><apply id="S3.E5.m1.11.11.2.2.2.cmml" xref="S3.E5.m1.11.11.2.2.2"><times id="S3.E5.m1.11.11.2.2.2.4.cmml" xref="S3.E5.m1.11.11.2.2.2.4"></times><apply id="S3.E5.m1.11.11.2.2.2.5.cmml" xref="S3.E5.m1.11.11.2.2.2.5"><csymbol cd="ambiguous" id="S3.E5.m1.11.11.2.2.2.5.1.cmml" xref="S3.E5.m1.11.11.2.2.2.5">subscript</csymbol><ci id="S3.E5.m1.11.11.2.2.2.5.2.cmml" xref="S3.E5.m1.11.11.2.2.2.5.2">attn</ci><ci id="S3.E5.m1.11.11.2.2.2.5.3.cmml" xref="S3.E5.m1.11.11.2.2.2.5.3">ğ‘€</ci></apply><vector id="S3.E5.m1.11.11.2.2.2.3.4.cmml" xref="S3.E5.m1.11.11.2.2.2.3.3"><apply id="S3.E5.m1.11.11.2.2.2.1.1.1.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.11.11.2.2.2.1.1.1.1.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1">subscript</csymbol><apply id="S3.E5.m1.11.11.2.2.2.1.1.1.2.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.11.11.2.2.2.1.1.1.2.1.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1">superscript</csymbol><ci id="S3.E5.m1.11.11.2.2.2.1.1.1.2.2.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1.2.2">ğ‘„</ci><ci id="S3.E5.m1.11.11.2.2.2.1.1.1.2.3a.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1.2.3"><mtext mathsize="70%" id="S3.E5.m1.11.11.2.2.2.1.1.1.2.3.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1.2.3">sup</mtext></ci></apply><ci id="S3.E5.m1.11.11.2.2.2.1.1.1.3.cmml" xref="S3.E5.m1.11.11.2.2.2.1.1.1.3">ğ‘€</ci></apply><apply id="S3.E5.m1.11.11.2.2.2.2.2.2.cmml" xref="S3.E5.m1.11.11.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.11.11.2.2.2.2.2.2.1.cmml" xref="S3.E5.m1.11.11.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.11.11.2.2.2.2.2.2.2.cmml" xref="S3.E5.m1.11.11.2.2.2.2.2.2.2">ğ¹</ci><interval closure="open" id="S3.E5.m1.6.6.2.3.cmml" xref="S3.E5.m1.6.6.2.4"><ci id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1.1">ğ‘¡</ci><ci id="S3.E5.m1.6.6.2.2.cmml" xref="S3.E5.m1.6.6.2.2">ğ‘€</ci></interval></apply><apply id="S3.E5.m1.11.11.2.2.2.3.3.3.cmml" xref="S3.E5.m1.11.11.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.11.11.2.2.2.3.3.3.1.cmml" xref="S3.E5.m1.11.11.2.2.2.3.3.3">subscript</csymbol><ci id="S3.E5.m1.11.11.2.2.2.3.3.3.2.cmml" xref="S3.E5.m1.11.11.2.2.2.3.3.3.2">ğ¹</ci><interval closure="open" id="S3.E5.m1.8.8.2.3.cmml" xref="S3.E5.m1.8.8.2.4"><ci id="S3.E5.m1.7.7.1.1.cmml" xref="S3.E5.m1.7.7.1.1">ğ‘¡</ci><ci id="S3.E5.m1.8.8.2.2.cmml" xref="S3.E5.m1.8.8.2.2">ğ‘€</ci></interval></apply></vector></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.11c">\tilde{Q}^{\text{sup}}=\left[\mathrm{attn}_{1}(Q^{\text{sup}}_{1},F_{(t,1)},F_{(t,1)});\dots;\mathrm{attn}_{M}(Q^{\text{sup}}_{M},F_{(t,M)},F_{(t,M)})\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.4" class="ltx_Math" alttext="\mathrm{MHA}\left(Q^{\text{sup}},F_{t},F_{t}\right)=\mathrm{LayerNorm}\left(Q^{\text{sup}}+\mathrm{Dropout}\left(\tilde{Q}L\right)\right)" display="block"><semantics id="S3.E6.m1.4a"><mrow id="S3.E6.m1.4.4" xref="S3.E6.m1.4.4.cmml"><mrow id="S3.E6.m1.3.3.3" xref="S3.E6.m1.3.3.3.cmml"><mi id="S3.E6.m1.3.3.3.5" xref="S3.E6.m1.3.3.3.5.cmml">MHA</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.3.4" xref="S3.E6.m1.3.3.3.4.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.3.3.3" xref="S3.E6.m1.3.3.3.3.4.cmml"><mo id="S3.E6.m1.3.3.3.3.3.4" xref="S3.E6.m1.3.3.3.3.4.cmml">(</mo><msup id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">Q</mi><mtext id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.3a.cmml">sup</mtext></msup><mo id="S3.E6.m1.3.3.3.3.3.5" xref="S3.E6.m1.3.3.3.3.4.cmml">,</mo><msub id="S3.E6.m1.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.cmml"><mi id="S3.E6.m1.2.2.2.2.2.2.2" xref="S3.E6.m1.2.2.2.2.2.2.2.cmml">F</mi><mi id="S3.E6.m1.2.2.2.2.2.2.3" xref="S3.E6.m1.2.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E6.m1.3.3.3.3.3.6" xref="S3.E6.m1.3.3.3.3.4.cmml">,</mo><msub id="S3.E6.m1.3.3.3.3.3.3" xref="S3.E6.m1.3.3.3.3.3.3.cmml"><mi id="S3.E6.m1.3.3.3.3.3.3.2" xref="S3.E6.m1.3.3.3.3.3.3.2.cmml">F</mi><mi id="S3.E6.m1.3.3.3.3.3.3.3" xref="S3.E6.m1.3.3.3.3.3.3.3.cmml">t</mi></msub><mo id="S3.E6.m1.3.3.3.3.3.7" xref="S3.E6.m1.3.3.3.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.5" xref="S3.E6.m1.4.4.5.cmml">=</mo><mrow id="S3.E6.m1.4.4.4" xref="S3.E6.m1.4.4.4.cmml"><mi id="S3.E6.m1.4.4.4.3" xref="S3.E6.m1.4.4.4.3.cmml">LayerNorm</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.2" xref="S3.E6.m1.4.4.4.2.cmml">â€‹</mo><mrow id="S3.E6.m1.4.4.4.1.1" xref="S3.E6.m1.4.4.4.1.1.1.cmml"><mo id="S3.E6.m1.4.4.4.1.1.2" xref="S3.E6.m1.4.4.4.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.4.4.4.1.1.1" xref="S3.E6.m1.4.4.4.1.1.1.cmml"><msup id="S3.E6.m1.4.4.4.1.1.1.3" xref="S3.E6.m1.4.4.4.1.1.1.3.cmml"><mi id="S3.E6.m1.4.4.4.1.1.1.3.2" xref="S3.E6.m1.4.4.4.1.1.1.3.2.cmml">Q</mi><mtext id="S3.E6.m1.4.4.4.1.1.1.3.3" xref="S3.E6.m1.4.4.4.1.1.1.3.3a.cmml">sup</mtext></msup><mo id="S3.E6.m1.4.4.4.1.1.1.2" xref="S3.E6.m1.4.4.4.1.1.1.2.cmml">+</mo><mrow id="S3.E6.m1.4.4.4.1.1.1.1" xref="S3.E6.m1.4.4.4.1.1.1.1.cmml"><mi id="S3.E6.m1.4.4.4.1.1.1.1.3" xref="S3.E6.m1.4.4.4.1.1.1.1.3.cmml">Dropout</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.1.1.1.1.2" xref="S3.E6.m1.4.4.4.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E6.m1.4.4.4.1.1.1.1.1.1" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.4.4.4.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.2" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.2.cmml">Q</mi><mo id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.1" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.3.cmml">L</mi></mrow><mo id="S3.E6.m1.4.4.4.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.4.4.4.1.1.3" xref="S3.E6.m1.4.4.4.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.4b"><apply id="S3.E6.m1.4.4.cmml" xref="S3.E6.m1.4.4"><eq id="S3.E6.m1.4.4.5.cmml" xref="S3.E6.m1.4.4.5"></eq><apply id="S3.E6.m1.3.3.3.cmml" xref="S3.E6.m1.3.3.3"><times id="S3.E6.m1.3.3.3.4.cmml" xref="S3.E6.m1.3.3.3.4"></times><ci id="S3.E6.m1.3.3.3.5.cmml" xref="S3.E6.m1.3.3.3.5">MHA</ci><vector id="S3.E6.m1.3.3.3.3.4.cmml" xref="S3.E6.m1.3.3.3.3.3"><apply id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.2">ğ‘„</ci><ci id="S3.E6.m1.1.1.1.1.1.1.3a.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S3.E6.m1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3">sup</mtext></ci></apply><apply id="S3.E6.m1.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.2.2.2.2.2.2.1.cmml" xref="S3.E6.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E6.m1.2.2.2.2.2.2.2.cmml" xref="S3.E6.m1.2.2.2.2.2.2.2">ğ¹</ci><ci id="S3.E6.m1.2.2.2.2.2.2.3.cmml" xref="S3.E6.m1.2.2.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.E6.m1.3.3.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.3.3.3.3.1.cmml" xref="S3.E6.m1.3.3.3.3.3.3">subscript</csymbol><ci id="S3.E6.m1.3.3.3.3.3.3.2.cmml" xref="S3.E6.m1.3.3.3.3.3.3.2">ğ¹</ci><ci id="S3.E6.m1.3.3.3.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3.3.3.3">ğ‘¡</ci></apply></vector></apply><apply id="S3.E6.m1.4.4.4.cmml" xref="S3.E6.m1.4.4.4"><times id="S3.E6.m1.4.4.4.2.cmml" xref="S3.E6.m1.4.4.4.2"></times><ci id="S3.E6.m1.4.4.4.3.cmml" xref="S3.E6.m1.4.4.4.3">LayerNorm</ci><apply id="S3.E6.m1.4.4.4.1.1.1.cmml" xref="S3.E6.m1.4.4.4.1.1"><plus id="S3.E6.m1.4.4.4.1.1.1.2.cmml" xref="S3.E6.m1.4.4.4.1.1.1.2"></plus><apply id="S3.E6.m1.4.4.4.1.1.1.3.cmml" xref="S3.E6.m1.4.4.4.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.1.1.1.3.1.cmml" xref="S3.E6.m1.4.4.4.1.1.1.3">superscript</csymbol><ci id="S3.E6.m1.4.4.4.1.1.1.3.2.cmml" xref="S3.E6.m1.4.4.4.1.1.1.3.2">ğ‘„</ci><ci id="S3.E6.m1.4.4.4.1.1.1.3.3a.cmml" xref="S3.E6.m1.4.4.4.1.1.1.3.3"><mtext mathsize="70%" id="S3.E6.m1.4.4.4.1.1.1.3.3.cmml" xref="S3.E6.m1.4.4.4.1.1.1.3.3">sup</mtext></ci></apply><apply id="S3.E6.m1.4.4.4.1.1.1.1.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1"><times id="S3.E6.m1.4.4.4.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.2"></times><ci id="S3.E6.m1.4.4.4.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.3">Dropout</ci><apply id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1"><times id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.1"></times><apply id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2"><ci id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.2.2">ğ‘„</ci></apply><ci id="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.4.1.1.1.1.1.1.1.3">ğ¿</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.4c">\mathrm{MHA}\left(Q^{\text{sup}},F_{t},F_{t}\right)=\mathrm{LayerNorm}\left(Q^{\text{sup}}+\mathrm{Dropout}\left(\tilde{Q}L\right)\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.SSS2.p5" class="ltx_para">
<p id="S3.SS1.SSS2.p5.10" class="ltx_p">where <math id="S3.SS1.SSS2.p5.1.m1.1" class="ltx_Math" alttext="\mathrm{LayerNorm}" display="inline"><semantics id="S3.SS1.SSS2.p5.1.m1.1a"><mi id="S3.SS1.SSS2.p5.1.m1.1.1" xref="S3.SS1.SSS2.p5.1.m1.1.1.cmml">LayerNorm</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.1.m1.1b"><ci id="S3.SS1.SSS2.p5.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p5.1.m1.1.1">LayerNorm</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.1.m1.1c">\mathrm{LayerNorm}</annotation></semantics></math> is layer normalizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, <math id="S3.SS1.SSS2.p5.2.m2.1" class="ltx_Math" alttext="\mathrm{Dropout}" display="inline"><semantics id="S3.SS1.SSS2.p5.2.m2.1a"><mi id="S3.SS1.SSS2.p5.2.m2.1.1" xref="S3.SS1.SSS2.p5.2.m2.1.1.cmml">Dropout</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.2.m2.1b"><ci id="S3.SS1.SSS2.p5.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p5.2.m2.1.1">Dropout</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.2.m2.1c">\mathrm{Dropout}</annotation></semantics></math> is dropout operationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> and <math id="S3.SS1.SSS2.p5.3.m3.1" class="ltx_Math" alttext="L\in\mathbb{R}^{c\times c}" display="inline"><semantics id="S3.SS1.SSS2.p5.3.m3.1a"><mrow id="S3.SS1.SSS2.p5.3.m3.1.1" xref="S3.SS1.SSS2.p5.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p5.3.m3.1.1.2" xref="S3.SS1.SSS2.p5.3.m3.1.1.2.cmml">L</mi><mo id="S3.SS1.SSS2.p5.3.m3.1.1.1" xref="S3.SS1.SSS2.p5.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p5.3.m3.1.1.3" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.cmml"><mi id="S3.SS1.SSS2.p5.3.m3.1.1.3.2" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p5.3.m3.1.1.3.3" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.2" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.2.cmml">c</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.1" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.3" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.3.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.3.m3.1b"><apply id="S3.SS1.SSS2.p5.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1"><in id="S3.SS1.SSS2.p5.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.1"></in><ci id="S3.SS1.SSS2.p5.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.2">ğ¿</ci><apply id="S3.SS1.SSS2.p5.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p5.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.2">â„</ci><apply id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3"><times id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.2">ğ‘</ci><ci id="S3.SS1.SSS2.p5.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p5.3.m3.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.3.m3.1c">L\in\mathbb{R}^{c\times c}</annotation></semantics></math> is a projection. Passing the result to a feed-forward network which is effectively a two layer linear projection with <math id="S3.SS1.SSS2.p5.4.m4.1" class="ltx_Math" alttext="\mathrm{ReLU}" display="inline"><semantics id="S3.SS1.SSS2.p5.4.m4.1a"><mi id="S3.SS1.SSS2.p5.4.m4.1.1" xref="S3.SS1.SSS2.p5.4.m4.1.1.cmml">ReLU</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.4.m4.1b"><ci id="S3.SS1.SSS2.p5.4.m4.1.1.cmml" xref="S3.SS1.SSS2.p5.4.m4.1.1">ReLU</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.4.m4.1c">\mathrm{ReLU}</annotation></semantics></math> activation followed also by residual connection, <math id="S3.SS1.SSS2.p5.5.m5.1" class="ltx_Math" alttext="\mathrm{Dropout}" display="inline"><semantics id="S3.SS1.SSS2.p5.5.m5.1a"><mi id="S3.SS1.SSS2.p5.5.m5.1.1" xref="S3.SS1.SSS2.p5.5.m5.1.1.cmml">Dropout</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.5.m5.1b"><ci id="S3.SS1.SSS2.p5.5.m5.1.1.cmml" xref="S3.SS1.SSS2.p5.5.m5.1.1">Dropout</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.5.m5.1c">\mathrm{Dropout}</annotation></semantics></math> and <math id="S3.SS1.SSS2.p5.6.m6.1" class="ltx_Math" alttext="\mathrm{LayerNorm}" display="inline"><semantics id="S3.SS1.SSS2.p5.6.m6.1a"><mi id="S3.SS1.SSS2.p5.6.m6.1.1" xref="S3.SS1.SSS2.p5.6.m6.1.1.cmml">LayerNorm</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.6.m6.1b"><ci id="S3.SS1.SSS2.p5.6.m6.1.1.cmml" xref="S3.SS1.SSS2.p5.6.m6.1.1">LayerNorm</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.6.m6.1c">\mathrm{LayerNorm}</annotation></semantics></math> completes the Transformer decoder layer. Stacking multiple layers gives us the affinity feature <math id="S3.SS1.SSS2.p5.7.m7.1" class="ltx_Math" alttext="F^{\text{aff}}\in\mathbb{R}^{k^{\text{sup}}\times c}" display="inline"><semantics id="S3.SS1.SSS2.p5.7.m7.1a"><mrow id="S3.SS1.SSS2.p5.7.m7.1.1" xref="S3.SS1.SSS2.p5.7.m7.1.1.cmml"><msup id="S3.SS1.SSS2.p5.7.m7.1.1.2" xref="S3.SS1.SSS2.p5.7.m7.1.1.2.cmml"><mi id="S3.SS1.SSS2.p5.7.m7.1.1.2.2" xref="S3.SS1.SSS2.p5.7.m7.1.1.2.2.cmml">F</mi><mtext id="S3.SS1.SSS2.p5.7.m7.1.1.2.3" xref="S3.SS1.SSS2.p5.7.m7.1.1.2.3a.cmml">aff</mtext></msup><mo id="S3.SS1.SSS2.p5.7.m7.1.1.1" xref="S3.SS1.SSS2.p5.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p5.7.m7.1.1.3" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.cmml"><mi id="S3.SS1.SSS2.p5.7.m7.1.1.3.2" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p5.7.m7.1.1.3.3" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.cmml"><msup id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.cmml"><mi id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.2" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.3" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.3a.cmml">sup</mtext></msup><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.1" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.3" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.3.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.7.m7.1b"><apply id="S3.SS1.SSS2.p5.7.m7.1.1.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1"><in id="S3.SS1.SSS2.p5.7.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.1"></in><apply id="S3.SS1.SSS2.p5.7.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.7.m7.1.1.2.1.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS2.p5.7.m7.1.1.2.2.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.2.2">ğ¹</ci><ci id="S3.SS1.SSS2.p5.7.m7.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p5.7.m7.1.1.2.3.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.2.3">aff</mtext></ci></apply><apply id="S3.SS1.SSS2.p5.7.m7.1.1.3.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.7.m7.1.1.3.1.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p5.7.m7.1.1.3.2.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.2">â„</ci><apply id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3"><times id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.1"></times><apply id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.1.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2">superscript</csymbol><ci id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.2.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.3a.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.3"><mtext mathsize="50%" id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.3.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.2.3">sup</mtext></ci></apply><ci id="S3.SS1.SSS2.p5.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p5.7.m7.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.7.m7.1c">F^{\text{aff}}\in\mathbb{R}^{k^{\text{sup}}\times c}</annotation></semantics></math>. Then <math id="S3.SS1.SSS2.p5.8.m8.1" class="ltx_Math" alttext="F^{\text{aff}}" display="inline"><semantics id="S3.SS1.SSS2.p5.8.m8.1a"><msup id="S3.SS1.SSS2.p5.8.m8.1.1" xref="S3.SS1.SSS2.p5.8.m8.1.1.cmml"><mi id="S3.SS1.SSS2.p5.8.m8.1.1.2" xref="S3.SS1.SSS2.p5.8.m8.1.1.2.cmml">F</mi><mtext id="S3.SS1.SSS2.p5.8.m8.1.1.3" xref="S3.SS1.SSS2.p5.8.m8.1.1.3a.cmml">aff</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.8.m8.1b"><apply id="S3.SS1.SSS2.p5.8.m8.1.1.cmml" xref="S3.SS1.SSS2.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.8.m8.1.1.1.cmml" xref="S3.SS1.SSS2.p5.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p5.8.m8.1.1.2.cmml" xref="S3.SS1.SSS2.p5.8.m8.1.1.2">ğ¹</ci><ci id="S3.SS1.SSS2.p5.8.m8.1.1.3a.cmml" xref="S3.SS1.SSS2.p5.8.m8.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p5.8.m8.1.1.3.cmml" xref="S3.SS1.SSS2.p5.8.m8.1.1.3">aff</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.8.m8.1c">F^{\text{aff}}</annotation></semantics></math> is linearly projected to the space of supervised keypoints by weight matrix <math id="S3.SS1.SSS2.p5.9.m9.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S3.SS1.SSS2.p5.9.m9.1a"><mi id="S3.SS1.SSS2.p5.9.m9.1.1" xref="S3.SS1.SSS2.p5.9.m9.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.9.m9.1b"><ci id="S3.SS1.SSS2.p5.9.m9.1.1.cmml" xref="S3.SS1.SSS2.p5.9.m9.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.9.m9.1c">P</annotation></semantics></math> and transformed using <math id="S3.SS1.SSS2.p5.10.m10.1" class="ltx_Math" alttext="\mathrm{Softmax}" display="inline"><semantics id="S3.SS1.SSS2.p5.10.m10.1a"><mi id="S3.SS1.SSS2.p5.10.m10.1.1" xref="S3.SS1.SSS2.p5.10.m10.1.1.cmml">Softmax</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.10.m10.1b"><ci id="S3.SS1.SSS2.p5.10.m10.1.1.cmml" xref="S3.SS1.SSS2.p5.10.m10.1.1">Softmax</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.10.m10.1c">\mathrm{Softmax}</annotation></semantics></math> function among self-supervised keypoints into affinity matrix,</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="W=\mathrm{Softmax}\left(F^{\text{aff}}P\right)" display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><mi id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml">W</mi><mo id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml">=</mo><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.cmml"><mi id="S3.E7.m1.1.1.1.3" xref="S3.E7.m1.1.1.1.3.cmml">Softmax</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml"><msup id="S3.E7.m1.1.1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E7.m1.1.1.1.1.1.1.2.2" xref="S3.E7.m1.1.1.1.1.1.1.2.2.cmml">F</mi><mtext id="S3.E7.m1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.1.1.1.1.1.1.2.3a.cmml">aff</mtext></msup><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.3.cmml">P</mi></mrow><mo id="S3.E7.m1.1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><eq id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2"></eq><ci id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3">ğ‘Š</ci><apply id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><times id="S3.E7.m1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.2"></times><ci id="S3.E7.m1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.3">Softmax</ci><apply id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"><times id="S3.E7.m1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.1"></times><apply id="S3.E7.m1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.2">ğ¹</ci><ci id="S3.E7.m1.1.1.1.1.1.1.2.3a.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S3.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.2.3">aff</mtext></ci></apply><ci id="S3.E7.m1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.1.1.3">ğ‘ƒ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">W=\mathrm{Softmax}\left(F^{\text{aff}}P\right)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p5.12" class="ltx_p">Each row in <math id="S3.SS1.SSS2.p5.11.m1.1" class="ltx_Math" alttext="W\in\mathbb{R}^{k^{\text{sup}}\times k^{\text{self}}}" display="inline"><semantics id="S3.SS1.SSS2.p5.11.m1.1a"><mrow id="S3.SS1.SSS2.p5.11.m1.1.1" xref="S3.SS1.SSS2.p5.11.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p5.11.m1.1.1.2" xref="S3.SS1.SSS2.p5.11.m1.1.1.2.cmml">W</mi><mo id="S3.SS1.SSS2.p5.11.m1.1.1.1" xref="S3.SS1.SSS2.p5.11.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS2.p5.11.m1.1.1.3" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.cmml"><mi id="S3.SS1.SSS2.p5.11.m1.1.1.3.2" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS2.p5.11.m1.1.1.3.3" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.cmml"><msup id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.cmml"><mi id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.2" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.3" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.3a.cmml">sup</mtext></msup><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.1" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.1.cmml">Ã—</mo><msup id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.cmml"><mi id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.2" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.3" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.3a.cmml">self</mtext></msup></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.11.m1.1b"><apply id="S3.SS1.SSS2.p5.11.m1.1.1.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1"><in id="S3.SS1.SSS2.p5.11.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.1"></in><ci id="S3.SS1.SSS2.p5.11.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.2">ğ‘Š</ci><apply id="S3.SS1.SSS2.p5.11.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.11.m1.1.1.3.1.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p5.11.m1.1.1.3.2.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.2">â„</ci><apply id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3"><times id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.1.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.1"></times><apply id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.1.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2">superscript</csymbol><ci id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.2.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.3a.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.3"><mtext mathsize="50%" id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.3.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.2.3">sup</mtext></ci></apply><apply id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.1.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3">superscript</csymbol><ci id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.2.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.3a.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.3"><mtext mathsize="50%" id="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.3.cmml" xref="S3.SS1.SSS2.p5.11.m1.1.1.3.3.3.3">self</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.11.m1.1c">W\in\mathbb{R}^{k^{\text{sup}}\times k^{\text{self}}}</annotation></semantics></math> represents the relation between self-supervised keypoints and corresponding supervised keypoint. Typically we have <math id="S3.SS1.SSS2.p5.12.m2.1" class="ltx_Math" alttext="k^{\text{sup}}\leq k^{\text{self}}" display="inline"><semantics id="S3.SS1.SSS2.p5.12.m2.1a"><mrow id="S3.SS1.SSS2.p5.12.m2.1.1" xref="S3.SS1.SSS2.p5.12.m2.1.1.cmml"><msup id="S3.SS1.SSS2.p5.12.m2.1.1.2" xref="S3.SS1.SSS2.p5.12.m2.1.1.2.cmml"><mi id="S3.SS1.SSS2.p5.12.m2.1.1.2.2" xref="S3.SS1.SSS2.p5.12.m2.1.1.2.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p5.12.m2.1.1.2.3" xref="S3.SS1.SSS2.p5.12.m2.1.1.2.3a.cmml">sup</mtext></msup><mo id="S3.SS1.SSS2.p5.12.m2.1.1.1" xref="S3.SS1.SSS2.p5.12.m2.1.1.1.cmml">â‰¤</mo><msup id="S3.SS1.SSS2.p5.12.m2.1.1.3" xref="S3.SS1.SSS2.p5.12.m2.1.1.3.cmml"><mi id="S3.SS1.SSS2.p5.12.m2.1.1.3.2" xref="S3.SS1.SSS2.p5.12.m2.1.1.3.2.cmml">k</mi><mtext id="S3.SS1.SSS2.p5.12.m2.1.1.3.3" xref="S3.SS1.SSS2.p5.12.m2.1.1.3.3a.cmml">self</mtext></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.12.m2.1b"><apply id="S3.SS1.SSS2.p5.12.m2.1.1.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1"><leq id="S3.SS1.SSS2.p5.12.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.1"></leq><apply id="S3.SS1.SSS2.p5.12.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.12.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.2">superscript</csymbol><ci id="S3.SS1.SSS2.p5.12.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.2.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p5.12.m2.1.1.2.3a.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.2.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p5.12.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.2.3">sup</mtext></ci></apply><apply id="S3.SS1.SSS2.p5.12.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.12.m2.1.1.3.1.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS2.p5.12.m2.1.1.3.2.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.3.2">ğ‘˜</ci><ci id="S3.SS1.SSS2.p5.12.m2.1.1.3.3a.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.3.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p5.12.m2.1.1.3.3.cmml" xref="S3.SS1.SSS2.p5.12.m2.1.1.3.3">self</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.12.m2.1c">k^{\text{sup}}\leq k^{\text{self}}</annotation></semantics></math> for higher flexibility. The final supervised heatmaps is given by,</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.1" class="ltx_Math" alttext="H^{\text{sup}}_{t}=H^{\text{self}}_{t}W^{\top}" display="block"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1" xref="S3.E8.m1.1.1.cmml"><msubsup id="S3.E8.m1.1.1.2" xref="S3.E8.m1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.2.2.2" xref="S3.E8.m1.1.1.2.2.2.cmml">H</mi><mi id="S3.E8.m1.1.1.2.3" xref="S3.E8.m1.1.1.2.3.cmml">t</mi><mtext id="S3.E8.m1.1.1.2.2.3" xref="S3.E8.m1.1.1.2.2.3a.cmml">sup</mtext></msubsup><mo id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.cmml">=</mo><mrow id="S3.E8.m1.1.1.3" xref="S3.E8.m1.1.1.3.cmml"><msubsup id="S3.E8.m1.1.1.3.2" xref="S3.E8.m1.1.1.3.2.cmml"><mi id="S3.E8.m1.1.1.3.2.2.2" xref="S3.E8.m1.1.1.3.2.2.2.cmml">H</mi><mi id="S3.E8.m1.1.1.3.2.3" xref="S3.E8.m1.1.1.3.2.3.cmml">t</mi><mtext id="S3.E8.m1.1.1.3.2.2.3" xref="S3.E8.m1.1.1.3.2.2.3a.cmml">self</mtext></msubsup><mo lspace="0em" rspace="0em" id="S3.E8.m1.1.1.3.1" xref="S3.E8.m1.1.1.3.1.cmml">â€‹</mo><msup id="S3.E8.m1.1.1.3.3" xref="S3.E8.m1.1.1.3.3.cmml"><mi id="S3.E8.m1.1.1.3.3.2" xref="S3.E8.m1.1.1.3.3.2.cmml">W</mi><mo id="S3.E8.m1.1.1.3.3.3" xref="S3.E8.m1.1.1.3.3.3.cmml">âŠ¤</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.cmml" xref="S3.E8.m1.1.1"><eq id="S3.E8.m1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"></eq><apply id="S3.E8.m1.1.1.2.cmml" xref="S3.E8.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.2">subscript</csymbol><apply id="S3.E8.m1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.2.2.1.cmml" xref="S3.E8.m1.1.1.2">superscript</csymbol><ci id="S3.E8.m1.1.1.2.2.2.cmml" xref="S3.E8.m1.1.1.2.2.2">ğ»</ci><ci id="S3.E8.m1.1.1.2.2.3a.cmml" xref="S3.E8.m1.1.1.2.2.3"><mtext mathsize="70%" id="S3.E8.m1.1.1.2.2.3.cmml" xref="S3.E8.m1.1.1.2.2.3">sup</mtext></ci></apply><ci id="S3.E8.m1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.E8.m1.1.1.3.cmml" xref="S3.E8.m1.1.1.3"><times id="S3.E8.m1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.3.1"></times><apply id="S3.E8.m1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.2.1.cmml" xref="S3.E8.m1.1.1.3.2">subscript</csymbol><apply id="S3.E8.m1.1.1.3.2.2.cmml" xref="S3.E8.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.2.2.1.cmml" xref="S3.E8.m1.1.1.3.2">superscript</csymbol><ci id="S3.E8.m1.1.1.3.2.2.2.cmml" xref="S3.E8.m1.1.1.3.2.2.2">ğ»</ci><ci id="S3.E8.m1.1.1.3.2.2.3a.cmml" xref="S3.E8.m1.1.1.3.2.2.3"><mtext mathsize="70%" id="S3.E8.m1.1.1.3.2.2.3.cmml" xref="S3.E8.m1.1.1.3.2.2.3">self</mtext></ci></apply><ci id="S3.E8.m1.1.1.3.2.3.cmml" xref="S3.E8.m1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="S3.E8.m1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.3.3">superscript</csymbol><ci id="S3.E8.m1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.3.3.2">ğ‘Š</ci><csymbol cd="latexml" id="S3.E8.m1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.3.3.3">top</csymbol></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">H^{\text{sup}}_{t}=H^{\text{self}}_{t}W^{\top}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p5.14" class="ltx_p">That is, supervised heatmaps are a weighted sum or selection of the self-supervised heatmaps. This presents supervised loss as,</p>
<table id="S3.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E9.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{sup}}=\left\|H_{t}^{\text{sup}}-H_{t}^{\text{gt}}\right\|^{2}" display="block"><semantics id="S3.E9.m1.1a"><mrow id="S3.E9.m1.1.1" xref="S3.E9.m1.1.1.cmml"><msup id="S3.E9.m1.1.1.3" xref="S3.E9.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E9.m1.1.1.3.2" xref="S3.E9.m1.1.1.3.2.cmml">â„’</mi><mtext id="S3.E9.m1.1.1.3.3" xref="S3.E9.m1.1.1.3.3a.cmml">sup</mtext></msup><mo id="S3.E9.m1.1.1.2" xref="S3.E9.m1.1.1.2.cmml">=</mo><msup id="S3.E9.m1.1.1.1" xref="S3.E9.m1.1.1.1.cmml"><mrow id="S3.E9.m1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.2.cmml"><mo id="S3.E9.m1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E9.m1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.cmml"><msubsup id="S3.E9.m1.1.1.1.1.1.1.2" xref="S3.E9.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.2.2.2" xref="S3.E9.m1.1.1.1.1.1.1.2.2.2.cmml">H</mi><mi id="S3.E9.m1.1.1.1.1.1.1.2.2.3" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3.cmml">t</mi><mtext id="S3.E9.m1.1.1.1.1.1.1.2.3" xref="S3.E9.m1.1.1.1.1.1.1.2.3a.cmml">sup</mtext></msubsup><mo id="S3.E9.m1.1.1.1.1.1.1.1" xref="S3.E9.m1.1.1.1.1.1.1.1.cmml">âˆ’</mo><msubsup id="S3.E9.m1.1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.1.1.3.cmml"><mi id="S3.E9.m1.1.1.1.1.1.1.3.2.2" xref="S3.E9.m1.1.1.1.1.1.1.3.2.2.cmml">H</mi><mi id="S3.E9.m1.1.1.1.1.1.1.3.2.3" xref="S3.E9.m1.1.1.1.1.1.1.3.2.3.cmml">t</mi><mtext id="S3.E9.m1.1.1.1.1.1.1.3.3" xref="S3.E9.m1.1.1.1.1.1.1.3.3a.cmml">gt</mtext></msubsup></mrow><mo id="S3.E9.m1.1.1.1.1.1.3" xref="S3.E9.m1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E9.m1.1.1.1.3" xref="S3.E9.m1.1.1.1.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.E9.m1.1b"><apply id="S3.E9.m1.1.1.cmml" xref="S3.E9.m1.1.1"><eq id="S3.E9.m1.1.1.2.cmml" xref="S3.E9.m1.1.1.2"></eq><apply id="S3.E9.m1.1.1.3.cmml" xref="S3.E9.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.3">superscript</csymbol><ci id="S3.E9.m1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.3.2">â„’</ci><ci id="S3.E9.m1.1.1.3.3a.cmml" xref="S3.E9.m1.1.1.3.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.3.3">sup</mtext></ci></apply><apply id="S3.E9.m1.1.1.1.cmml" xref="S3.E9.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E9.m1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1"><minus id="S3.E9.m1.1.1.1.1.1.1.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.1"></minus><apply id="S3.E9.m1.1.1.1.1.1.1.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.2">ğ»</ci><ci id="S3.E9.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.2.3">ğ‘¡</ci></apply><ci id="S3.E9.m1.1.1.1.1.1.1.2.3a.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.2.3">sup</mtext></ci></apply><apply id="S3.E9.m1.1.1.1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S3.E9.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E9.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E9.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3.2.2">ğ»</ci><ci id="S3.E9.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><ci id="S3.E9.m1.1.1.1.1.1.1.3.3a.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.E9.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E9.m1.1.1.1.1.1.1.3.3">gt</mtext></ci></apply></apply></apply><cn type="integer" id="S3.E9.m1.1.1.1.3.cmml" xref="S3.E9.m1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E9.m1.1c">\mathcal{L}^{\text{sup}}=\left\|H_{t}^{\text{sup}}-H_{t}^{\text{gt}}\right\|^{2}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p5.13" class="ltx_p">where <math id="S3.SS1.SSS2.p5.13.m1.1" class="ltx_Math" alttext="H_{t}^{\text{gt}}" display="inline"><semantics id="S3.SS1.SSS2.p5.13.m1.1a"><msubsup id="S3.SS1.SSS2.p5.13.m1.1.1" xref="S3.SS1.SSS2.p5.13.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p5.13.m1.1.1.2.2" xref="S3.SS1.SSS2.p5.13.m1.1.1.2.2.cmml">H</mi><mi id="S3.SS1.SSS2.p5.13.m1.1.1.2.3" xref="S3.SS1.SSS2.p5.13.m1.1.1.2.3.cmml">t</mi><mtext id="S3.SS1.SSS2.p5.13.m1.1.1.3" xref="S3.SS1.SSS2.p5.13.m1.1.1.3a.cmml">gt</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p5.13.m1.1b"><apply id="S3.SS1.SSS2.p5.13.m1.1.1.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.13.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1">superscript</csymbol><apply id="S3.SS1.SSS2.p5.13.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p5.13.m1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p5.13.m1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1.2.2">ğ»</ci><ci id="S3.SS1.SSS2.p5.13.m1.1.1.2.3.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.SSS2.p5.13.m1.1.1.3a.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p5.13.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p5.13.m1.1.1.3">gt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p5.13.m1.1c">H_{t}^{\text{gt}}</annotation></semantics></math> is the ground truth keypoint heatmap of target image built by placing a 2D gaussian at each jointâ€™s location <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>.</p>
</div>
<div id="S3.SS1.SSS2.p6" class="ltx_para">
<p id="S3.SS1.SSS2.p6.1" class="ltx_p">Our Transformer design explicitly models the relation between supervised and self-supervised tasks. Basic feature sharing model, even with the self-supervised task replaced by a similar pose estimation task, still fails to make sure that two tasks will cooperate instead of competing with each other. Learning an affinity matrix aligns self-supervised keypoints with supervised ones, avoiding the conflicts in multi-task training. During Test-Time Personalization, basic feature sharing model often lacks flexibility and is faced with the risk of overfitting to self-supervised task, due to the decoupling structure of two task heads. Our method, however, enforces the coupling between tasks using an affinity matrix and maintains flexibility as typically there are more self-supervised keypoints than supervised ones. Besides, compared to convolution model, Transformer shows superior ability to capture global context information, which is particularly needed when learning the relation between one supervised keypoint and all self-supervised ones.</p>
</div>
<div id="S3.SS1.SSS2.p7" class="ltx_para">
<p id="S3.SS1.SSS2.p7.2" class="ltx_p">Finally, we jointly optimize those two tasks during training. For a training sample, besides the supervised task, we randomly choose another sample belonging to the same person as the target to reconstruct. The final loss is given by</p>
<table id="S3.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E10.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}^{\text{sup}}+\lambda\mathcal{L}^{\text{self}}" display="block"><semantics id="S3.E10.m1.1a"><mrow id="S3.E10.m1.1.1" xref="S3.E10.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.1.1.2" xref="S3.E10.m1.1.1.2.cmml">â„’</mi><mo id="S3.E10.m1.1.1.1" xref="S3.E10.m1.1.1.1.cmml">=</mo><mrow id="S3.E10.m1.1.1.3" xref="S3.E10.m1.1.1.3.cmml"><msup id="S3.E10.m1.1.1.3.2" xref="S3.E10.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.1.1.3.2.2" xref="S3.E10.m1.1.1.3.2.2.cmml">â„’</mi><mtext id="S3.E10.m1.1.1.3.2.3" xref="S3.E10.m1.1.1.3.2.3a.cmml">sup</mtext></msup><mo id="S3.E10.m1.1.1.3.1" xref="S3.E10.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E10.m1.1.1.3.3" xref="S3.E10.m1.1.1.3.3.cmml"><mi id="S3.E10.m1.1.1.3.3.2" xref="S3.E10.m1.1.1.3.3.2.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S3.E10.m1.1.1.3.3.1" xref="S3.E10.m1.1.1.3.3.1.cmml">â€‹</mo><msup id="S3.E10.m1.1.1.3.3.3" xref="S3.E10.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E10.m1.1.1.3.3.3.2" xref="S3.E10.m1.1.1.3.3.3.2.cmml">â„’</mi><mtext id="S3.E10.m1.1.1.3.3.3.3" xref="S3.E10.m1.1.1.3.3.3.3a.cmml">self</mtext></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E10.m1.1b"><apply id="S3.E10.m1.1.1.cmml" xref="S3.E10.m1.1.1"><eq id="S3.E10.m1.1.1.1.cmml" xref="S3.E10.m1.1.1.1"></eq><ci id="S3.E10.m1.1.1.2.cmml" xref="S3.E10.m1.1.1.2">â„’</ci><apply id="S3.E10.m1.1.1.3.cmml" xref="S3.E10.m1.1.1.3"><plus id="S3.E10.m1.1.1.3.1.cmml" xref="S3.E10.m1.1.1.3.1"></plus><apply id="S3.E10.m1.1.1.3.2.cmml" xref="S3.E10.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.2.1.cmml" xref="S3.E10.m1.1.1.3.2">superscript</csymbol><ci id="S3.E10.m1.1.1.3.2.2.cmml" xref="S3.E10.m1.1.1.3.2.2">â„’</ci><ci id="S3.E10.m1.1.1.3.2.3a.cmml" xref="S3.E10.m1.1.1.3.2.3"><mtext mathsize="70%" id="S3.E10.m1.1.1.3.2.3.cmml" xref="S3.E10.m1.1.1.3.2.3">sup</mtext></ci></apply><apply id="S3.E10.m1.1.1.3.3.cmml" xref="S3.E10.m1.1.1.3.3"><times id="S3.E10.m1.1.1.3.3.1.cmml" xref="S3.E10.m1.1.1.3.3.1"></times><ci id="S3.E10.m1.1.1.3.3.2.cmml" xref="S3.E10.m1.1.1.3.3.2">ğœ†</ci><apply id="S3.E10.m1.1.1.3.3.3.cmml" xref="S3.E10.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E10.m1.1.1.3.3.3.1.cmml" xref="S3.E10.m1.1.1.3.3.3">superscript</csymbol><ci id="S3.E10.m1.1.1.3.3.3.2.cmml" xref="S3.E10.m1.1.1.3.3.3.2">â„’</ci><ci id="S3.E10.m1.1.1.3.3.3.3a.cmml" xref="S3.E10.m1.1.1.3.3.3.3"><mtext mathsize="70%" id="S3.E10.m1.1.1.3.3.3.3.cmml" xref="S3.E10.m1.1.1.3.3.3.3">self</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10.m1.1c">\mathcal{L}=\mathcal{L}^{\text{sup}}+\lambda\mathcal{L}^{\text{self}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p7.1" class="ltx_p">where <math id="S3.SS1.SSS2.p7.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS1.SSS2.p7.1.m1.1a"><mi id="S3.SS1.SSS2.p7.1.m1.1.1" xref="S3.SS1.SSS2.p7.1.m1.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p7.1.m1.1b"><ci id="S3.SS1.SSS2.p7.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p7.1.m1.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p7.1.m1.1c">\lambda</annotation></semantics></math> is a weight coefficient for balancing two tasks.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Test-Time Personalization</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.8" class="ltx_p">During inference with a specific person domain, we apply Test-Time Personalization by fine-tuning the model relying solely on the self-supervised task. Given a set of <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="N^{\text{test}}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msup id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">N</mi><mtext id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3a.cmml">test</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘</ci><ci id="S3.SS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">test</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">N^{\text{test}}</annotation></semantics></math> images of the same person <math id="S3.SS2.p1.2.m2.3" class="ltx_Math" alttext="I^{\text{test}}_{1},\dots,I^{\text{test}}_{N^{\text{test}}}" display="inline"><semantics id="S3.SS2.p1.2.m2.3a"><mrow id="S3.SS2.p1.2.m2.3.3.2" xref="S3.SS2.p1.2.m2.3.3.3.cmml"><msubsup id="S3.SS2.p1.2.m2.2.2.1.1" xref="S3.SS2.p1.2.m2.2.2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.2.2.1.1.2.2" xref="S3.SS2.p1.2.m2.2.2.1.1.2.2.cmml">I</mi><mn id="S3.SS2.p1.2.m2.2.2.1.1.3" xref="S3.SS2.p1.2.m2.2.2.1.1.3.cmml">1</mn><mtext id="S3.SS2.p1.2.m2.2.2.1.1.2.3" xref="S3.SS2.p1.2.m2.2.2.1.1.2.3a.cmml">test</mtext></msubsup><mo id="S3.SS2.p1.2.m2.3.3.2.3" xref="S3.SS2.p1.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS2.p1.2.m2.3.3.2.4" xref="S3.SS2.p1.2.m2.3.3.3.cmml">,</mo><msubsup id="S3.SS2.p1.2.m2.3.3.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.cmml"><mi id="S3.SS2.p1.2.m2.3.3.2.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml">I</mi><msup id="S3.SS2.p1.2.m2.3.3.2.2.3" xref="S3.SS2.p1.2.m2.3.3.2.2.3.cmml"><mi id="S3.SS2.p1.2.m2.3.3.2.2.3.2" xref="S3.SS2.p1.2.m2.3.3.2.2.3.2.cmml">N</mi><mtext id="S3.SS2.p1.2.m2.3.3.2.2.3.3" xref="S3.SS2.p1.2.m2.3.3.2.2.3.3a.cmml">test</mtext></msup><mtext id="S3.SS2.p1.2.m2.3.3.2.2.2.3" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3a.cmml">test</mtext></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.3b"><list id="S3.SS2.p1.2.m2.3.3.3.cmml" xref="S3.SS2.p1.2.m2.3.3.2"><apply id="S3.SS2.p1.2.m2.2.2.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1">subscript</csymbol><apply id="S3.SS2.p1.2.m2.2.2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.2.2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.2.2">ğ¼</ci><ci id="S3.SS2.p1.2.m2.2.2.1.1.2.3a.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.2.3"><mtext mathsize="70%" id="S3.SS2.p1.2.m2.2.2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.2.3">test</mtext></ci></apply><cn type="integer" id="S3.SS2.p1.2.m2.2.2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">â€¦</ci><apply id="S3.SS2.p1.2.m2.3.3.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.3.3.2.2.1.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2">subscript</csymbol><apply id="S3.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2">superscript</csymbol><ci id="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2">ğ¼</ci><ci id="S3.SS2.p1.2.m2.3.3.2.2.2.3a.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3"><mtext mathsize="70%" id="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3">test</mtext></ci></apply><apply id="S3.SS2.p1.2.m2.3.3.2.2.3.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.3.3.2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.3">superscript</csymbol><ci id="S3.SS2.p1.2.m2.3.3.2.2.3.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.3.2">ğ‘</ci><ci id="S3.SS2.p1.2.m2.3.3.2.2.3.3a.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.3.3"><mtext mathsize="50%" id="S3.SS2.p1.2.m2.3.3.2.2.3.3.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.3.3">test</mtext></ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.3c">I^{\text{test}}_{1},\dots,I^{\text{test}}_{N^{\text{test}}}</annotation></semantics></math>, where <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="N^{\text{test}}&gt;1" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><msup id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.2.2.cmml">N</mi><mtext id="S3.SS2.p1.3.m3.1.1.2.3" xref="S3.SS2.p1.3.m3.1.1.2.3a.cmml">test</mtext></msup><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">&gt;</mo><mn id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><gt id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></gt><apply id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1.2">superscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.2">ğ‘</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3a.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3"><mtext mathsize="70%" id="S3.SS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3">test</mtext></ci></apply><cn type="integer" id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">N^{\text{test}}&gt;1</annotation></semantics></math>, we first freeze the supervised Transformer part and update the shared encoder <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\phi</annotation></semantics></math> and the self-supervised head <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="\psi^{\text{self}}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><msup id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">Ïˆ</mi><mtext id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">ğœ“</ci><ci id="S3.SS2.p1.5.m5.1.1.3a.cmml" xref="S3.SS2.p1.5.m5.1.1.3"><mtext mathsize="70%" id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\psi^{\text{self}}</annotation></semantics></math> with the reconstruction loss <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{L}^{\text{self}}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><msup id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">â„’</mi><mtext id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">â„’</ci><ci id="S3.SS2.p1.6.m6.1.1.3a.cmml" xref="S3.SS2.p1.6.m6.1.1.3"><mtext mathsize="70%" id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\mathcal{L}^{\text{self}}</annotation></semantics></math>. Then the updated shared encoder <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="\phi^{*}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><msup id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">Ï•</mi><mo id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">italic-Ï•</ci><times id="S3.SS2.p1.7.m7.1.1.3.cmml" xref="S3.SS2.p1.7.m7.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">\phi^{*}</annotation></semantics></math> and self-supervised head <math id="S3.SS2.p1.8.m8.2" class="ltx_Math" alttext="\psi^{\text{self}*}" display="inline"><semantics id="S3.SS2.p1.8.m8.2a"><msup id="S3.SS2.p1.8.m8.2.3" xref="S3.SS2.p1.8.m8.2.3.cmml"><mi id="S3.SS2.p1.8.m8.2.3.2" xref="S3.SS2.p1.8.m8.2.3.2.cmml">Ïˆ</mi><mrow id="S3.SS2.p1.8.m8.2.2.2.4" xref="S3.SS2.p1.8.m8.2.2.2.3.cmml"><mtext id="S3.SS2.p1.8.m8.1.1.1.1" xref="S3.SS2.p1.8.m8.1.1.1.1a.cmml">self</mtext><mo lspace="0.222em" id="S3.SS2.p1.8.m8.2.2.2.4.1" xref="S3.SS2.p1.8.m8.2.2.2.3.cmml">â£</mo><mo id="S3.SS2.p1.8.m8.2.2.2.2" xref="S3.SS2.p1.8.m8.2.2.2.2.cmml">âˆ—</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.2b"><apply id="S3.SS2.p1.8.m8.2.3.cmml" xref="S3.SS2.p1.8.m8.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.8.m8.2.3.1.cmml" xref="S3.SS2.p1.8.m8.2.3">superscript</csymbol><ci id="S3.SS2.p1.8.m8.2.3.2.cmml" xref="S3.SS2.p1.8.m8.2.3.2">ğœ“</ci><list id="S3.SS2.p1.8.m8.2.2.2.3.cmml" xref="S3.SS2.p1.8.m8.2.2.2.4"><ci id="S3.SS2.p1.8.m8.1.1.1.1a.cmml" xref="S3.SS2.p1.8.m8.1.1.1.1"><mtext mathsize="70%" id="S3.SS2.p1.8.m8.1.1.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1.1.1">self</mtext></ci><times id="S3.SS2.p1.8.m8.2.2.2.2.cmml" xref="S3.SS2.p1.8.m8.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.2c">\psi^{\text{self}*}</annotation></semantics></math> are used along with the supervised head for final prediction. Specifically, during prediction, the updated features and self-supervised head will output improved keypoint heatmaps which leads to better reconstruction. These improved self-supervised heatmaps will go through the Transformer at the same time to generate improved supervised keypoints.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">During the personalization process, we propose two settings including the <em id="S3.SS2.p2.1.1" class="ltx_emph ltx_font_italic">online</em> scenario which works in a stream of incoming data and the <em id="S3.SS2.p2.1.2" class="ltx_emph ltx_font_italic">offline</em> scenario which performs personalization on an unordered test image set. We illustrate the details below.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.4" class="ltx_p"><span id="S3.SS2.p3.4.1" class="ltx_text ltx_font_bold">(i) The online scenario</span>, which takes input as a sequence and requires real-time inference such as an online camera. In this setting, we can only choose both source <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="I^{\text{test}}_{s}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msubsup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2.2" xref="S3.SS2.p3.1.m1.1.1.2.2.cmml">I</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">s</mi><mtext id="S3.SS2.p3.1.m1.1.1.2.3" xref="S3.SS2.p3.1.m1.1.1.2.3a.cmml">test</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><apply id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.2.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2.2">ğ¼</ci><ci id="S3.SS2.p3.1.m1.1.1.2.3a.cmml" xref="S3.SS2.p3.1.m1.1.1.2.3"><mtext mathsize="70%" id="S3.SS2.p3.1.m1.1.1.2.3.cmml" xref="S3.SS2.p3.1.m1.1.1.2.3">test</mtext></ci></apply><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">I^{\text{test}}_{s}</annotation></semantics></math> and target <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="I^{\text{test}}_{t}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msubsup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.cmml">I</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">t</mi><mtext id="S3.SS2.p3.2.m2.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.2.3a.cmml">test</mtext></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2">ğ¼</ci><ci id="S3.SS2.p3.2.m2.1.1.2.3a.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3"><mtext mathsize="70%" id="S3.SS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3">test</mtext></ci></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">I^{\text{test}}_{t}</annotation></semantics></math> with the constraint <math id="S3.SS2.p3.3.m3.2" class="ltx_Math" alttext="s\leq T,t\leq T" display="inline"><semantics id="S3.SS2.p3.3.m3.2a"><mrow id="S3.SS2.p3.3.m3.2.2.2" xref="S3.SS2.p3.3.m3.2.2.3.cmml"><mrow id="S3.SS2.p3.3.m3.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.1.1.2" xref="S3.SS2.p3.3.m3.1.1.1.1.2.cmml">s</mi><mo id="S3.SS2.p3.3.m3.1.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.1.cmml">â‰¤</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1.3" xref="S3.SS2.p3.3.m3.1.1.1.1.3.cmml">T</mi></mrow><mo id="S3.SS2.p3.3.m3.2.2.2.3" xref="S3.SS2.p3.3.m3.2.2.3a.cmml">,</mo><mrow id="S3.SS2.p3.3.m3.2.2.2.2" xref="S3.SS2.p3.3.m3.2.2.2.2.cmml"><mi id="S3.SS2.p3.3.m3.2.2.2.2.2" xref="S3.SS2.p3.3.m3.2.2.2.2.2.cmml">t</mi><mo id="S3.SS2.p3.3.m3.2.2.2.2.1" xref="S3.SS2.p3.3.m3.2.2.2.2.1.cmml">â‰¤</mo><mi id="S3.SS2.p3.3.m3.2.2.2.2.3" xref="S3.SS2.p3.3.m3.2.2.2.2.3.cmml">T</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.2b"><apply id="S3.SS2.p3.3.m3.2.2.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.2.2.3a.cmml" xref="S3.SS2.p3.3.m3.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p3.3.m3.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1"><leq id="S3.SS2.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.1"></leq><ci id="S3.SS2.p3.3.m3.1.1.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.2">ğ‘ </ci><ci id="S3.SS2.p3.3.m3.1.1.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1.3">ğ‘‡</ci></apply><apply id="S3.SS2.p3.3.m3.2.2.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.2"><leq id="S3.SS2.p3.3.m3.2.2.2.2.1.cmml" xref="S3.SS2.p3.3.m3.2.2.2.2.1"></leq><ci id="S3.SS2.p3.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.p3.3.m3.2.2.2.2.2">ğ‘¡</ci><ci id="S3.SS2.p3.3.m3.2.2.2.2.3.cmml" xref="S3.SS2.p3.3.m3.2.2.2.2.3">ğ‘‡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.2c">s\leq T,t\leq T</annotation></semantics></math> at time <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">T</annotation></semantics></math> for fine-tuning. Prediction is performed after each updating step.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">(ii) The offline scenario</span>, which has access to the whole person domain data and has no requirement of real-time inference, assuming we have access to an offline video or a set of unordered images for a person. In this setting, we shuffle the images in the dataset and perform offline fine-tuning, and then we perform prediction at once for all the images.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">Compared to <em id="S3.SS2.p5.1.1" class="ltx_emph ltx_font_italic">online</em> scenario, <em id="S3.SS2.p5.1.2" class="ltx_emph ltx_font_italic">offline</em> scenario benefits from more diverse source and target sample pairs and avoids the variance drifts when updating the model. Since our method is designed to personalize pose estimation, the model is initialized with diversely trained weights when switching person identity. In each scenario, different re-initialization strategies can also be applied to avoid overfitting to a local minimum. The various combination of scenarios and reinitializing strategies engifts our method with great flexibility.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p">It should be noted that our method has <em id="S3.SS2.p6.1.1" class="ltx_emph ltx_font_italic">no requirement of consecutive or continuous</em> frames but only unlabeled images belonging to the same person, which is less costly and beyond the reach of temporal methods such as 3D convolution with multiple frames. Test-Time Personalization can be done at inference without annotations and thus is remarkably suitable for privacy protection: The process can be proceeded locally rather than uploading data of your own for annotating for specialization.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Our experiments are performed on three human pose datasets with large varieties to prove the generality and effectiveness of our methods. While the datasets are continuous videos, we emphasize that our approach can be generalized to discontinuous images. In fact, we take the datasets as unordered image collections when performing <em id="S4.SS1.p1.1.1" class="ltx_emph ltx_font_italic">offline</em> Test-Time Personalization. All input images are resized to 128<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mo id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><times id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\times</annotation></semantics></math>128 with the human located in the center.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Human 3.6M</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> contains 3.6 million images and provides both 2D and 3D pose annotations. We only use 2D labels. Following the standard protocolÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, we used 5 subjects for training and 2 subjects for testing. We sample the training set every 5 frames and the testing set every 200 frames. We use the Percentage of Correct Key (PCK) as the metric and the threshold we use is the 20% distance of the torso length.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Penn Action</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> contains 2,236 video sequences of different people. 13 pose joints are given for each sample in the annotations. We use the standard training/testing split and also use PCK with threshold distance of half distance of torso as the evaluation metric.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.2" class="ltx_p"><span id="S4.SS1.p4.2.1" class="ltx_text ltx_font_bold">BBC Pose</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> consists of 20 videos of different sign language interpreter. We use 610,115 labeled frames in the first ten videos for training, and we use 2,000 frames in the remaining ten videos (200 frames per video) with manual annotation for testing. The testing frames are not consecutive. The evaluation method of BBC Pose is the joint accuracy with <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mi id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><ci id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">d</annotation></semantics></math> pixels of ground truth where <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mi id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><ci id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">d</annotation></semantics></math> is 6 followingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Implementation Details</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.10" class="ltx_p"><span id="S4.SS2.p1.10.1" class="ltx_text ltx_font_bold">Network Architecture.</span> We use ResNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> followed by three transposed convolution layers as encoder <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="\phi" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">Ï•</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">italic-Ï•</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\phi</annotation></semantics></math>. Every convolution layer has 256 channels, consisting of BatchNorm and ReLU activation and upsampling 2 times to generate the final feature <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">F</annotation></semantics></math> of size <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="256\times 32\times 32" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.3.m3.1.1.1a" xref="S4.SS2.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS2.p1.3.m3.1.1.4" xref="S4.SS2.p1.3.m3.1.1.4.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><times id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></times><cn type="integer" id="S4.SS2.p1.3.m3.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.2">256</cn><cn type="integer" id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">32</cn><cn type="integer" id="S4.SS2.p1.3.m3.1.1.4.cmml" xref="S4.SS2.p1.3.m3.1.1.4">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">256\times 32\times 32</annotation></semantics></math> and <math id="S4.SS2.p1.4.m4.1" class="ltx_Math" alttext="c=256" display="inline"><semantics id="S4.SS2.p1.4.m4.1a"><mrow id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml"><mi id="S4.SS2.p1.4.m4.1.1.2" xref="S4.SS2.p1.4.m4.1.1.2.cmml">c</mi><mo id="S4.SS2.p1.4.m4.1.1.1" xref="S4.SS2.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.4.m4.1.1.3" xref="S4.SS2.p1.4.m4.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><apply id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"><eq id="S4.SS2.p1.4.m4.1.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1.1"></eq><ci id="S4.SS2.p1.4.m4.1.1.2.cmml" xref="S4.SS2.p1.4.m4.1.1.2">ğ‘</ci><cn type="integer" id="S4.SS2.p1.4.m4.1.1.3.cmml" xref="S4.SS2.p1.4.m4.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">c=256</annotation></semantics></math>. Considering the diversity of datasets, we use ResNet50 for Penn Action and ResNet18 for both Human 3.6M and BBC Pose. We use one convolution layer as the supervised head <math id="S4.SS2.p1.5.m5.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="S4.SS2.p1.5.m5.1a"><msup id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">Ïˆ</mi><mtext id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">ğœ“</ci><ci id="S4.SS2.p1.5.m5.1.1.3a.cmml" xref="S4.SS2.p1.5.m5.1.1.3"><mtext mathsize="70%" id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">\psi^{\text{sup}}</annotation></semantics></math> and another convolution layer for self-supervised head <math id="S4.SS2.p1.6.m6.1" class="ltx_Math" alttext="\psi^{\text{self}}" display="inline"><semantics id="S4.SS2.p1.6.m6.1a"><msup id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml"><mi id="S4.SS2.p1.6.m6.1.1.2" xref="S4.SS2.p1.6.m6.1.1.2.cmml">Ïˆ</mi><mtext id="S4.SS2.p1.6.m6.1.1.3" xref="S4.SS2.p1.6.m6.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><apply id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.6.m6.1.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">superscript</csymbol><ci id="S4.SS2.p1.6.m6.1.1.2.cmml" xref="S4.SS2.p1.6.m6.1.1.2">ğœ“</ci><ci id="S4.SS2.p1.6.m6.1.1.3a.cmml" xref="S4.SS2.p1.6.m6.1.1.3"><mtext mathsize="70%" id="S4.SS2.p1.6.m6.1.1.3.cmml" xref="S4.SS2.p1.6.m6.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">\psi^{\text{self}}</annotation></semantics></math>,  where the supervised head <math id="S4.SS2.p1.7.m7.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="S4.SS2.p1.7.m7.1a"><msup id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml"><mi id="S4.SS2.p1.7.m7.1.1.2" xref="S4.SS2.p1.7.m7.1.1.2.cmml">Ïˆ</mi><mtext id="S4.SS2.p1.7.m7.1.1.3" xref="S4.SS2.p1.7.m7.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><apply id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.7.m7.1.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1">superscript</csymbol><ci id="S4.SS2.p1.7.m7.1.1.2.cmml" xref="S4.SS2.p1.7.m7.1.1.2">ğœ“</ci><ci id="S4.SS2.p1.7.m7.1.1.3a.cmml" xref="S4.SS2.p1.7.m7.1.1.3"><mtext mathsize="70%" id="S4.SS2.p1.7.m7.1.1.3.cmml" xref="S4.SS2.p1.7.m7.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">\psi^{\text{sup}}</annotation></semantics></math> denotes the standard structure used in Appendix <a href="#A1" title="Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. For all three datasets, the output channel for self-supervised keypoints is <math id="S4.SS2.p1.8.m8.1" class="ltx_Math" alttext="k^{\text{self}}=30" display="inline"><semantics id="S4.SS2.p1.8.m8.1a"><mrow id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml"><msup id="S4.SS2.p1.8.m8.1.1.2" xref="S4.SS2.p1.8.m8.1.1.2.cmml"><mi id="S4.SS2.p1.8.m8.1.1.2.2" xref="S4.SS2.p1.8.m8.1.1.2.2.cmml">k</mi><mtext id="S4.SS2.p1.8.m8.1.1.2.3" xref="S4.SS2.p1.8.m8.1.1.2.3a.cmml">self</mtext></msup><mo id="S4.SS2.p1.8.m8.1.1.1" xref="S4.SS2.p1.8.m8.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.8.m8.1.1.3" xref="S4.SS2.p1.8.m8.1.1.3.cmml">30</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><apply id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1"><eq id="S4.SS2.p1.8.m8.1.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1.1"></eq><apply id="S4.SS2.p1.8.m8.1.1.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p1.8.m8.1.1.2.1.cmml" xref="S4.SS2.p1.8.m8.1.1.2">superscript</csymbol><ci id="S4.SS2.p1.8.m8.1.1.2.2.cmml" xref="S4.SS2.p1.8.m8.1.1.2.2">ğ‘˜</ci><ci id="S4.SS2.p1.8.m8.1.1.2.3a.cmml" xref="S4.SS2.p1.8.m8.1.1.2.3"><mtext mathsize="70%" id="S4.SS2.p1.8.m8.1.1.2.3.cmml" xref="S4.SS2.p1.8.m8.1.1.2.3">self</mtext></ci></apply><cn type="integer" id="S4.SS2.p1.8.m8.1.1.3.cmml" xref="S4.SS2.p1.8.m8.1.1.3">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">k^{\text{self}}=30</annotation></semantics></math>. We adopt a 1-layer Transformer with 4 heads and the hidden layer in feed-forward has 1024 dimensions. The weight of self-supervised loss is set to <math id="S4.SS2.p1.9.m9.1" class="ltx_Math" alttext="\lambda=1\times 10^{-3}" display="inline"><semantics id="S4.SS2.p1.9.m9.1a"><mrow id="S4.SS2.p1.9.m9.1.1" xref="S4.SS2.p1.9.m9.1.1.cmml"><mi id="S4.SS2.p1.9.m9.1.1.2" xref="S4.SS2.p1.9.m9.1.1.2.cmml">Î»</mi><mo id="S4.SS2.p1.9.m9.1.1.1" xref="S4.SS2.p1.9.m9.1.1.1.cmml">=</mo><mrow id="S4.SS2.p1.9.m9.1.1.3" xref="S4.SS2.p1.9.m9.1.1.3.cmml"><mn id="S4.SS2.p1.9.m9.1.1.3.2" xref="S4.SS2.p1.9.m9.1.1.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.9.m9.1.1.3.1" xref="S4.SS2.p1.9.m9.1.1.3.1.cmml">Ã—</mo><msup id="S4.SS2.p1.9.m9.1.1.3.3" xref="S4.SS2.p1.9.m9.1.1.3.3.cmml"><mn id="S4.SS2.p1.9.m9.1.1.3.3.2" xref="S4.SS2.p1.9.m9.1.1.3.3.2.cmml">10</mn><mrow id="S4.SS2.p1.9.m9.1.1.3.3.3" xref="S4.SS2.p1.9.m9.1.1.3.3.3.cmml"><mo id="S4.SS2.p1.9.m9.1.1.3.3.3a" xref="S4.SS2.p1.9.m9.1.1.3.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.9.m9.1.1.3.3.3.2" xref="S4.SS2.p1.9.m9.1.1.3.3.3.2.cmml">3</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m9.1b"><apply id="S4.SS2.p1.9.m9.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1"><eq id="S4.SS2.p1.9.m9.1.1.1.cmml" xref="S4.SS2.p1.9.m9.1.1.1"></eq><ci id="S4.SS2.p1.9.m9.1.1.2.cmml" xref="S4.SS2.p1.9.m9.1.1.2">ğœ†</ci><apply id="S4.SS2.p1.9.m9.1.1.3.cmml" xref="S4.SS2.p1.9.m9.1.1.3"><times id="S4.SS2.p1.9.m9.1.1.3.1.cmml" xref="S4.SS2.p1.9.m9.1.1.3.1"></times><cn type="integer" id="S4.SS2.p1.9.m9.1.1.3.2.cmml" xref="S4.SS2.p1.9.m9.1.1.3.2">1</cn><apply id="S4.SS2.p1.9.m9.1.1.3.3.cmml" xref="S4.SS2.p1.9.m9.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.9.m9.1.1.3.3.1.cmml" xref="S4.SS2.p1.9.m9.1.1.3.3">superscript</csymbol><cn type="integer" id="S4.SS2.p1.9.m9.1.1.3.3.2.cmml" xref="S4.SS2.p1.9.m9.1.1.3.3.2">10</cn><apply id="S4.SS2.p1.9.m9.1.1.3.3.3.cmml" xref="S4.SS2.p1.9.m9.1.1.3.3.3"><minus id="S4.SS2.p1.9.m9.1.1.3.3.3.1.cmml" xref="S4.SS2.p1.9.m9.1.1.3.3.3"></minus><cn type="integer" id="S4.SS2.p1.9.m9.1.1.3.3.3.2.cmml" xref="S4.SS2.p1.9.m9.1.1.3.3.3.2">3</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m9.1c">\lambda=1\times 10^{-3}</annotation></semantics></math> for Penn Action and BBC Pose, <math id="S4.SS2.p1.10.m10.1" class="ltx_Math" alttext="\lambda=1\times 10^{-5}" display="inline"><semantics id="S4.SS2.p1.10.m10.1a"><mrow id="S4.SS2.p1.10.m10.1.1" xref="S4.SS2.p1.10.m10.1.1.cmml"><mi id="S4.SS2.p1.10.m10.1.1.2" xref="S4.SS2.p1.10.m10.1.1.2.cmml">Î»</mi><mo id="S4.SS2.p1.10.m10.1.1.1" xref="S4.SS2.p1.10.m10.1.1.1.cmml">=</mo><mrow id="S4.SS2.p1.10.m10.1.1.3" xref="S4.SS2.p1.10.m10.1.1.3.cmml"><mn id="S4.SS2.p1.10.m10.1.1.3.2" xref="S4.SS2.p1.10.m10.1.1.3.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.10.m10.1.1.3.1" xref="S4.SS2.p1.10.m10.1.1.3.1.cmml">Ã—</mo><msup id="S4.SS2.p1.10.m10.1.1.3.3" xref="S4.SS2.p1.10.m10.1.1.3.3.cmml"><mn id="S4.SS2.p1.10.m10.1.1.3.3.2" xref="S4.SS2.p1.10.m10.1.1.3.3.2.cmml">10</mn><mrow id="S4.SS2.p1.10.m10.1.1.3.3.3" xref="S4.SS2.p1.10.m10.1.1.3.3.3.cmml"><mo id="S4.SS2.p1.10.m10.1.1.3.3.3a" xref="S4.SS2.p1.10.m10.1.1.3.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p1.10.m10.1.1.3.3.3.2" xref="S4.SS2.p1.10.m10.1.1.3.3.3.2.cmml">5</mn></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m10.1b"><apply id="S4.SS2.p1.10.m10.1.1.cmml" xref="S4.SS2.p1.10.m10.1.1"><eq id="S4.SS2.p1.10.m10.1.1.1.cmml" xref="S4.SS2.p1.10.m10.1.1.1"></eq><ci id="S4.SS2.p1.10.m10.1.1.2.cmml" xref="S4.SS2.p1.10.m10.1.1.2">ğœ†</ci><apply id="S4.SS2.p1.10.m10.1.1.3.cmml" xref="S4.SS2.p1.10.m10.1.1.3"><times id="S4.SS2.p1.10.m10.1.1.3.1.cmml" xref="S4.SS2.p1.10.m10.1.1.3.1"></times><cn type="integer" id="S4.SS2.p1.10.m10.1.1.3.2.cmml" xref="S4.SS2.p1.10.m10.1.1.3.2">1</cn><apply id="S4.SS2.p1.10.m10.1.1.3.3.cmml" xref="S4.SS2.p1.10.m10.1.1.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.10.m10.1.1.3.3.1.cmml" xref="S4.SS2.p1.10.m10.1.1.3.3">superscript</csymbol><cn type="integer" id="S4.SS2.p1.10.m10.1.1.3.3.2.cmml" xref="S4.SS2.p1.10.m10.1.1.3.3.2">10</cn><apply id="S4.SS2.p1.10.m10.1.1.3.3.3.cmml" xref="S4.SS2.p1.10.m10.1.1.3.3.3"><minus id="S4.SS2.p1.10.m10.1.1.3.3.3.1.cmml" xref="S4.SS2.p1.10.m10.1.1.3.3.3"></minus><cn type="integer" id="S4.SS2.p1.10.m10.1.1.3.3.3.2.cmml" xref="S4.SS2.p1.10.m10.1.1.3.3.3.2">5</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m10.1c">\lambda=1\times 10^{-5}</annotation></semantics></math> for Human 3.6M.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Joint Training.</span> We apply the same training schedule across methods. For all datasets, we use batch size of 32, AdamÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> optimizer with learning rate <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="float" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">0.001</annotation></semantics></math> and decay the learning rate twice during training. We use learning schedule [18k, 24k, 28k], [246k, 328k, 383k] and [90k, 120k, 140k] for BBC Pose, Penn Action, and Human 3.6M respectively. We divide the learning rate by 10 after each stage. The training schedule of BBC Pose is shortened since the data is less diverse.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.2" class="ltx_p"><span id="S4.SS2.p3.2.1" class="ltx_text ltx_font_bold">Test-Time Personalization (TTP).</span> During Test-Time Personalization, we use Adam optimizer with fixed learning rate <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mn id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">Ã—</mo><msup id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml"><mn id="S4.SS2.p3.1.m1.1.1.3.2" xref="S4.SS2.p3.1.m1.1.1.3.2.cmml">10</mn><mrow id="S4.SS2.p3.1.m1.1.1.3.3" xref="S4.SS2.p3.1.m1.1.1.3.3.cmml"><mo id="S4.SS2.p3.1.m1.1.1.3.3a" xref="S4.SS2.p3.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS2.p3.1.m1.1.1.3.3.2" xref="S4.SS2.p3.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><times id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">1</cn><apply id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.2">10</cn><apply id="S4.SS2.p3.1.m1.1.1.3.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3"><minus id="S4.SS2.p3.1.m1.1.1.3.3.1.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.3.2.cmml" xref="S4.SS2.p3.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">1\times 10^{-4}</annotation></semantics></math>. The supervised head <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><msup id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">Ïˆ</mi><mtext id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">ğœ“</ci><ci id="S4.SS2.p3.2.m2.1.1.3a.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><mtext mathsize="70%" id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\psi^{\text{sup}}</annotation></semantics></math> and Transformer are frozen at this stage. Test-Time Personalization is applied without weight reset unless specified. In offline scenario, even though the model can be updated for arbitrary steps, we adopt the same number of steps as the online scenario for a fair comparison. See AppendixÂ <a href="#A3" title="Appendix C More Implementation Details â€£ Appendix B Visualization â€£ Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> for more details.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Batching Strategy.</span> In joint training and TTP offline scenario, both target and source images are randomly chosen and are different within a batch. In TTP online scenario, the target images are always the current frame, which are the same within a batch, whereas the source images are randomly chosen from the previous frames and are different in a batch. In all the scenarios, each target-source pair is performed data augmentation with same rotation angle and scale factor for the two images to make reconstruction easier.</p>
</div>
<figure id="S4.SS2.1" class="ltx_table">

<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.SS2.1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.SS2.1.4.2" class="ltx_text" style="font-size:90%;">Evaluation results on pose estimation. Our proposed method is denoted as <span id="S4.SS2.1.4.2.1" class="ltx_text ltx_font_italic">TransformerÂ (keypoint)</span>. For Human 3.6M and Penn Action datasets, mPCK is employed as the metric while for BBC Pose we use mAcc. The proposed method not only performs better on the validation set but also enjoys more gain in Test-Time Personalization.</span></figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="S4.SS2.1.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS2.1.1.2.1" class="ltx_tr">
<th id="S4.SS2.1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_border_t">Method</th>
<th id="S4.SS2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_border_t">TTP Scenario</th>
<th id="S4.SS2.1.1.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Human 3.6M</th>
<th id="S4.SS2.1.1.2.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Penn Action</th>
<th id="S4.SS2.1.1.2.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">BBC Pose</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS2.1.1.3.1" class="ltx_tr">
<th id="S4.SS2.1.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Baseline</th>
<th id="S4.SS2.1.1.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">w/o TTP</th>
<td id="S4.SS2.1.1.3.1.3" class="ltx_td ltx_align_left ltx_border_t">85.42</td>
<td id="S4.SS2.1.1.3.1.4" class="ltx_td ltx_align_left ltx_border_t">85.23</td>
<td id="S4.SS2.1.1.3.1.5" class="ltx_td ltx_align_left ltx_border_t">88.69</td>
</tr>
<tr id="S4.SS2.1.1.1" class="ltx_tr">
<th id="S4.SS2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.SS2.1.1.1.2.1" class="ltx_ERROR undefined">\hdashline</span></th>
<th id="S4.SS2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">w/o TTP</th>
<td id="S4.SS2.1.1.1.4" class="ltx_td ltx_align_left">87.37 <span id="S4.SS2.1.1.1.4.1" class="ltx_text" style="font-size:90%;">(+1.95)</span>
</td>
<td id="S4.SS2.1.1.1.1" class="ltx_td ltx_align_left">84.90 <span id="S4.SS2.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(
<span id="S4.SS2.1.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:2.1pt;height:3.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-0.4pt,0.0pt) scale(0.7,1.0) ;">
<span id="S4.SS2.1.1.1.1.1.1.1" class="ltx_p"><math id="S4.SS2.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="S4.SS2.1.1.1.1.1.1.1.m1.1a"><mo id="S4.SS2.1.1.1.1.1.1.1.m1.1.1" xref="S4.SS2.1.1.1.1.1.1.1.m1.1.1.cmml">âˆ’</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.1.1.1.1.1.1.1.m1.1b"><minus id="S4.SS2.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS2.1.1.1.1.1.1.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.1.1.1.1.1.1.1.m1.1c">-</annotation></semantics></math></span>
</span></span>0.33)</span>
</td>
<td id="S4.SS2.1.1.1.5" class="ltx_td ltx_align_left">89.07 <span id="S4.SS2.1.1.1.5.1" class="ltx_text" style="font-size:90%;">(+0.38)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.4.2" class="ltx_tr">
<th id="S4.SS2.1.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Feat. shared (<span id="S4.SS2.1.1.4.2.1.1" class="ltx_text ltx_font_italic">rotation</span>)</th>
<th id="S4.SS2.1.1.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">Online</th>
<td id="S4.SS2.1.1.4.2.3" class="ltx_td ltx_align_left">88.01 <span id="S4.SS2.1.1.4.2.3.1" class="ltx_text" style="font-size:90%;">(+2.59)</span>
</td>
<td id="S4.SS2.1.1.4.2.4" class="ltx_td ltx_align_left">85.86 <span id="S4.SS2.1.1.4.2.4.1" class="ltx_text" style="font-size:90%;">(+0.63)</span>
</td>
<td id="S4.SS2.1.1.4.2.5" class="ltx_td ltx_align_left">89.34 <span id="S4.SS2.1.1.4.2.5.1" class="ltx_text" style="font-size:90%;">(+0.65)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.5.3" class="ltx_tr">
<th id="S4.SS2.1.1.5.3.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.SS2.1.1.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">Offline</th>
<td id="S4.SS2.1.1.5.3.3" class="ltx_td ltx_align_left">88.26 <span id="S4.SS2.1.1.5.3.3.1" class="ltx_text" style="font-size:90%;">(+2.84)</span>
</td>
<td id="S4.SS2.1.1.5.3.4" class="ltx_td ltx_align_left">85.93 <span id="S4.SS2.1.1.5.3.4.1" class="ltx_text" style="font-size:90%;">(+0.70)</span>
</td>
<td id="S4.SS2.1.1.5.3.5" class="ltx_td ltx_align_left">88.90 <span id="S4.SS2.1.1.5.3.5.1" class="ltx_text" style="font-size:90%;">(+0.21)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.6.4" class="ltx_tr">
<th id="S4.SS2.1.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.SS2.1.1.6.4.1.1" class="ltx_ERROR undefined">\hdashline</span></th>
<th id="S4.SS2.1.1.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">w/o TTP</th>
<td id="S4.SS2.1.1.6.4.3" class="ltx_td ltx_align_left">87.41 <span id="S4.SS2.1.1.6.4.3.1" class="ltx_text" style="font-size:90%;">(+1.99)</span>
</td>
<td id="S4.SS2.1.1.6.4.4" class="ltx_td ltx_align_left">85.78 <span id="S4.SS2.1.1.6.4.4.1" class="ltx_text" style="font-size:90%;">(+0.55)</span>
</td>
<td id="S4.SS2.1.1.6.4.5" class="ltx_td ltx_align_left">89.65 <span id="S4.SS2.1.1.6.4.5.1" class="ltx_text" style="font-size:90%;">(+0.96)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.7.5" class="ltx_tr">
<th id="S4.SS2.1.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Feat. shared (<span id="S4.SS2.1.1.7.5.1.1" class="ltx_text ltx_font_italic">keypoint</span>)</th>
<th id="S4.SS2.1.1.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">Online</th>
<td id="S4.SS2.1.1.7.5.3" class="ltx_td ltx_align_left">89.43 <span id="S4.SS2.1.1.7.5.3.1" class="ltx_text" style="font-size:90%;">(+4.01)</span>
</td>
<td id="S4.SS2.1.1.7.5.4" class="ltx_td ltx_align_left">87.27 <span id="S4.SS2.1.1.7.5.4.1" class="ltx_text" style="font-size:90%;">(+2.04)</span>
</td>
<td id="S4.SS2.1.1.7.5.5" class="ltx_td ltx_align_left">91.48 <span id="S4.SS2.1.1.7.5.5.1" class="ltx_text" style="font-size:90%;">(+2.79)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.8.6" class="ltx_tr">
<th id="S4.SS2.1.1.8.6.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.SS2.1.1.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">Offline</th>
<td id="S4.SS2.1.1.8.6.3" class="ltx_td ltx_align_left">89.05 <span id="S4.SS2.1.1.8.6.3.1" class="ltx_text" style="font-size:90%;">(+3.63)</span>
</td>
<td id="S4.SS2.1.1.8.6.4" class="ltx_td ltx_align_left">88.12 <span id="S4.SS2.1.1.8.6.4.1" class="ltx_text" style="font-size:90%;">(+2.89)</span>
</td>
<td id="S4.SS2.1.1.8.6.5" class="ltx_td ltx_align_left">91.65 <span id="S4.SS2.1.1.8.6.5.1" class="ltx_text" style="font-size:90%;">(+2.96)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.9.7" class="ltx_tr">
<th id="S4.SS2.1.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.SS2.1.1.9.7.1.1" class="ltx_ERROR undefined">\hdashline</span></th>
<th id="S4.SS2.1.1.9.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">w/o TTP</th>
<td id="S4.SS2.1.1.9.7.3" class="ltx_td ltx_align_left">87.90 <span id="S4.SS2.1.1.9.7.3.1" class="ltx_text" style="font-size:90%;">(+2.48)</span>
</td>
<td id="S4.SS2.1.1.9.7.4" class="ltx_td ltx_align_left">86.16 <span id="S4.SS2.1.1.9.7.4.1" class="ltx_text" style="font-size:90%;">(+0.93)</span>
</td>
<td id="S4.SS2.1.1.9.7.5" class="ltx_td ltx_align_left">90.19 <span id="S4.SS2.1.1.9.7.5.1" class="ltx_text" style="font-size:90%;">(+1.50)</span>
</td>
</tr>
<tr id="S4.SS2.1.1.10.8" class="ltx_tr">
<th id="S4.SS2.1.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Transformer (<span id="S4.SS2.1.1.10.8.1.1" class="ltx_text ltx_font_italic">keypoint</span>)</th>
<th id="S4.SS2.1.1.10.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">Online</th>
<td id="S4.SS2.1.1.10.8.3" class="ltx_td ltx_align_left">91.70 <span id="S4.SS2.1.1.10.8.3.1" class="ltx_text" style="font-size:90%;">(+6.28)</span>
</td>
<td id="S4.SS2.1.1.10.8.4" class="ltx_td ltx_align_left">87.75 <span id="S4.SS2.1.1.10.8.4.1" class="ltx_text" style="font-size:90%;">(+2.52)</span>
</td>
<td id="S4.SS2.1.1.10.8.5" class="ltx_td ltx_align_left"><span id="S4.SS2.1.1.10.8.5.1" class="ltx_text ltx_font_bold">92.51 <span id="S4.SS2.1.1.10.8.5.1.1" class="ltx_text" style="font-size:90%;">(+3.82)</span></span></td>
</tr>
<tr id="S4.SS2.1.1.11.9" class="ltx_tr">
<th id="S4.SS2.1.1.11.9.1" class="ltx_td ltx_th ltx_th_row ltx_border_bb"></th>
<th id="S4.SS2.1.1.11.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">Offline</th>
<td id="S4.SS2.1.1.11.9.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.SS2.1.1.11.9.3.1" class="ltx_text ltx_font_bold">92.05 <span id="S4.SS2.1.1.11.9.3.1.1" class="ltx_text" style="font-size:90%;">(+6.63)</span></span></td>
<td id="S4.SS2.1.1.11.9.4" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.SS2.1.1.11.9.4.1" class="ltx_text ltx_font_bold">88.98 <span id="S4.SS2.1.1.11.9.4.1.1" class="ltx_text" style="font-size:90%;">(+3.75)</span></span></td>
<td id="S4.SS2.1.1.11.9.5" class="ltx_td ltx_align_left ltx_border_bb">92.21 <span id="S4.SS2.1.1.11.9.5.1" class="ltx_text" style="font-size:90%;">(+3.52)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<section id="S4.SS3" class="ltx_subsection ltx_figure_panel">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Main Results</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.5" class="ltx_p">To better analyze the proposed method, in TableÂ <a href="#S4.SS2" title="4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a> we compare it with three baselines: (i) <span id="S4.SS3.p1.5.1" class="ltx_text ltx_font_bold">Baseline.</span> The plain baseline trained with supervised loss only. (ii) <span id="S4.SS3.p1.5.2" class="ltx_text ltx_font_bold">Feat. shared (rotation).</span> Instead of self-supervised keypoint estimation, we use rotation prediction to compute the self-supervised loss <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}^{\text{self}}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><msup id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">â„’</mi><mtext id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">â„’</ci><ci id="S4.SS3.p1.1.m1.1.1.3a.cmml" xref="S4.SS3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\mathcal{L}^{\text{self}}</annotation></semantics></math> in Eq.Â <a href="#S3.E10" title="In 3.1.2 Supervised Keypoint Estimation with a Transformer â€£ 3.1 Joint Training for Pose Estimation with a Transformer â€£ 3 Method â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> following Sun et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>. Rotation is predicted with a standalone supervised head <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><msup id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">Ïˆ</mi><mtext id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">ğœ“</ci><ci id="S4.SS3.p1.2.m2.1.1.3a.cmml" xref="S4.SS3.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\psi^{\text{sup}}</annotation></semantics></math>. The two tasks have no direct relation except they share the same feature backbone. Weight coefficient <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mi id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><ci id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\lambda</annotation></semantics></math> is set to <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="1\times 10^{-4}" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><mn id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">Ã—</mo><msup id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml"><mn id="S4.SS3.p1.4.m4.1.1.3.2" xref="S4.SS3.p1.4.m4.1.1.3.2.cmml">10</mn><mrow id="S4.SS3.p1.4.m4.1.1.3.3" xref="S4.SS3.p1.4.m4.1.1.3.3.cmml"><mo id="S4.SS3.p1.4.m4.1.1.3.3a" xref="S4.SS3.p1.4.m4.1.1.3.3.cmml">âˆ’</mo><mn id="S4.SS3.p1.4.m4.1.1.3.3.2" xref="S4.SS3.p1.4.m4.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><times id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></times><cn type="integer" id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2">1</cn><apply id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.3">superscript</csymbol><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.2.cmml" xref="S4.SS3.p1.4.m4.1.1.3.2">10</cn><apply id="S4.SS3.p1.4.m4.1.1.3.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3"><minus id="S4.SS3.p1.4.m4.1.1.3.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3"></minus><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.3.2.cmml" xref="S4.SS3.p1.4.m4.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">1\times 10^{-4}</annotation></semantics></math> for better performance. (iii) <span id="S4.SS3.p1.5.3" class="ltx_text ltx_font_bold">Feat. shared (keypoint).</span> We use the self-supervised keypoint estimation taskÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> as the self-supervised objective. However, supervised keypoints are still estimated with a standalone supervised head <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><msup id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">Ïˆ</mi><mtext id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">superscript</csymbol><ci id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2">ğœ“</ci><ci id="S4.SS3.p1.5.m5.1.1.3a.cmml" xref="S4.SS3.p1.5.m5.1.1.3"><mtext mathsize="70%" id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">\psi^{\text{sup}}</annotation></semantics></math> instead of our Transformer design. The two tasks are only connected by sharing the same feature backbone. See AppendixÂ <a href="#A1" title="Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for more details. Finally, our proposed method is denoted as <span id="S4.SS3.p1.5.4" class="ltx_text ltx_font_bold">Transformer (keypoint)</span>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Despite using calibrated self-supervised task weight, <span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_italic">Feat. shared (rotation)</span> still shows limited and even degraded performance on all three datasets, indicating that a general self-supervised task without a specific design is likely to hurt the performance of supervised one. On the other hand, <span id="S4.SS3.p2.1.2" class="ltx_text ltx_font_italic">Feat. shared (keypoint)</span> presents superior performance over <span id="S4.SS3.p2.1.3" class="ltx_text ltx_font_italic">Baseline</span>, even without Test-Time Personalization. This demonstrates the hypothesis that selecting a related or similar self-supervised task can facilitate the original supervised task and thus naturally leads to better performance in Test-Time Personalization. The results of Test-Time Personalization show the personalizing ability of our method. Personalizing for a single person results in significant improvement.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text ltx_font_italic">Transformer (keypoint)</span> further boosts performance with Test-Time Personalization, with an improvement of 6.63 mPCK on Human 3.6M, 3.75 mPCK on Penn Action, and 3.82 mAcc on BBC Pose. More importantly, our design of learning an affinity matrix not only improves the performance of joint training but also achieves a higher improvement in Test-Time Personalization. For example, TTP in online scenario has an improvement of 2.32 mAcc with <span id="S4.SS3.p3.1.2" class="ltx_text ltx_font_italic">Transformer (keypoint)</span> compared to an improvement of 1.83 mAcc with <span id="S4.SS3.p3.1.3" class="ltx_text ltx_font_italic">Feat. shared (keypoint)</span> for BBC Pose. This demonstrates that using the proposed Transformer, two tasks cooperate better in joint training and have higher flexibility in Test-Time Personalization.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">In terms of different scenarios for Test-Time Personalization, it is found that the offline scenario does not always surpass online scenario. For example in BBC Pose, both online scenario and offline scenario improve performance, yet in offline scenario, there is a small decrease in mAcc. This is expected for two reasons. Firstly the major advantage of offline scenario comes from the diversity of test samples while BBC Pose has a nonconsecutive validation set selected specifically for diversity. Secondly, we set the learning rate based on the performance of online scenario and follow it in all settings to demonstrates the generality of our method. Better results can be achieved if the learning rate is adjusted more carefully.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.02133/assets/x3.png" id="S4.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="128" height="85" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.02133/assets/x4.png" id="S4.F3.2.g1" class="ltx_graphics ltx_img_landscape" width="125" height="84" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F3.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="" id="S4.F3.3.g1" class="ltx_graphics ltx_missing ltx_missing_image" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.5.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.6.2" class="ltx_text" style="font-size:90%;">Improvement vs FrameÂ ID in online scenario for 3 datasets. We plot the gap between the Test-Time Personalization and the baseline model for each frame step. We adopt the averaged metric across all test videos. In most cases, we observe TTP improves more over time.</span></figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:255.8pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.1.1" class="ltx_figure ltx_figure_panel"><img src="/html/2107.02133/assets/x6.png" id="S4.F4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="121" height="75" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2107.02133/assets/x7.png" id="S4.F4.2.2.g1" class="ltx_graphics ltx_img_landscape" width="112" height="75" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.5.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.2.6.2" class="ltx_text" style="font-size:90%;">Test-Time Personalization with different numbers of unlabeled test samples. <span id="S4.F4.2.6.2.1" class="ltx_text ltx_font_bold">Left:</span> mAcc for different video length on BBC Pose. <span id="S4.F4.2.6.2.2" class="ltx_text ltx_font_bold">Right:</span> mPCK for different video length on Human 3.6M. Test-Time Personalization benefits from utilizing more unlabeled test samples.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:173.4pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T2" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">Test-Time Personalization in online scenario with different update iterations.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.F4.fig1.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.F4.fig1.1.1.1" class="ltx_tr">
<th id="S4.F4.fig1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Iters</th>
<th id="S4.F4.fig1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Penn Action</th>
<th id="S4.F4.fig1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">BBC Pose</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.F4.fig1.1.2.1" class="ltx_tr">
<th id="S4.F4.fig1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="S4.F4.fig1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">87.75</td>
<td id="S4.F4.fig1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">92.51</td>
</tr>
<tr id="S4.F4.fig1.1.3.2" class="ltx_tr">
<th id="S4.F4.fig1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">2</th>
<td id="S4.F4.fig1.1.3.2.2" class="ltx_td ltx_align_center"><span id="S4.F4.fig1.1.3.2.2.1" class="ltx_text ltx_font_bold">88.01</span></td>
<td id="S4.F4.fig1.1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.F4.fig1.1.3.2.3.1" class="ltx_text ltx_font_bold">92.64</span></td>
</tr>
<tr id="S4.F4.fig1.1.4.3" class="ltx_tr">
<th id="S4.F4.fig1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">3</th>
<td id="S4.F4.fig1.1.4.3.2" class="ltx_td ltx_align_center">76.27</td>
<td id="S4.F4.fig1.1.4.3.3" class="ltx_td ltx_align_center">92.59</td>
</tr>
<tr id="S4.F4.fig1.1.5.4" class="ltx_tr">
<th id="S4.F4.fig1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">4</th>
<td id="S4.F4.fig1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">76.13</td>
<td id="S4.F4.fig1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb">92.53</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</figure>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Analysis on Test-Time Personalization</h3>

<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Number of Unlabeled Test Samples.</h5>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px1.p1.1" class="ltx_p">Our method exploits personal information using unlabeled samples in a single person domain. We observe that more unlabeled samples can further improve the performance in Test-Time Personalization. We study the number of unlabeled samples using extra validation samples of BBC Pose and Human 3.6M. We emphasize that although labels are also provided for extra validation samples, we only use images <em id="S4.SS4.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">without</em> labels. All experiments have the same setting as Transformer in online scenario and the prediction and evaluation are on the same fixed test set. In FigureÂ <a href="#S4.F4" title="Figure 4 â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we report results of TTP by using different video lengths of samples in fine-tuning in an online manner. For video length smaller than the actual test sequences, we apply reinitializing strategy to simulate shorter videos. We observe that for Human 3.6M, the performance of our model increases as the number of unlabeled samples grows. Similar results appear in BBC Pose except that the performance reduces slightly after using more than 600 frames in fine-tuning. The reason is that the changes of the person images in BBC Pose are very small over time, which leads to overfitting.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Improvement in Online Scenario.</h5>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p1.1" class="ltx_p">FigureÂ <a href="#S4.F3" title="Figure 3 â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the improvement curve within each test video in the online scenario with respect to the ID (<math id="S4.SS4.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.1.m1.1a"><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.1.m1.1b"><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.1.m1.1c">n</annotation></semantics></math>-th update) of frames in TTP. We compute the metric gap between our method using TTP and baseline without TTP for each ID. The results are averaged across all the test videos. In Human 3.6M, we report on a single subject S9. The curves are smoothed to reduce variance for better visualization. The result suggests the gap keeps increasing within a single test video, as the model updates at every frame. Moreover, in later frames, the model has seen more test samples, which helps enlarge the performance gap.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2107.02133/assets/figures/penn_arrow.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="417" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Visualization on Penn Action. The images from the left to the right are: the original image, the image with 30 self-supervised keypoints, the image with 13 supervised keypoints, and the reconstructed image from the self-supervised task. The arrows between keypoints indicate their correspondences obtained from the affinity matrix with the Transformer. Warmer color indicates higher confidence.</span></figcaption>
</figure>
<div id="S4.SS4.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p2.1" class="ltx_p">In Human 3.6M, which has much more samples in a single person domain, the performance improves at the beginning but the improvement starts to drop a bit at 600 time steps due to overfitting in later frames. This phenomenon is expected since the examples in Human 3.6M are also quite similar. Note that the gap still exists for later frames, it is only the improvement that becomes smaller.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Transfer Across Datasets.</h5>

<div id="S4.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px3.p1.1" class="ltx_p">We test the generalization of the model by conducting the full training on one dataset and applying TTP on another dataset. We train our model on the Penn Action, and then perform TTP to transfer the model to Human 3.6M. As shown in Table <a href="#S4.T6" title="Table 6 â€£ Visualization. â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, our method using TTP can improve over the baselines by a large margin. Our offline approach achieves around <math id="S4.SS4.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="8\%" display="inline"><semantics id="S4.SS4.SSS0.Px3.p1.1.m1.1a"><mrow id="S4.SS4.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.cmml"><mn id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2.cmml">8</mn><mo id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS0.Px3.p1.1.m1.1.1.2">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px3.p1.1.m1.1c">8\%</annotation></semantics></math> improvement over the baseline without using Transformer and TTP. This shows TTP can significantly help generalize and adapt the pose estimator across data from different distribution.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Update Iterations.</h5>

<div id="S4.SS4.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px4.p1.1" class="ltx_p">We show the ablation on update iterations in TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:repeat</span>. Note that in our online scenario setting, we only update the model once for every incoming test image. We present results where we update more iterations in TableÂ <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:tab:repeat</span>. It suggests that more update iterations do not help much. Specifically, for Penn Action the performance drops when we update 3 to 4 iterations. The reason is, in each step of online setting, we only perform training on one single frame, which can lead to overfitting to a particular image.</p>
</div>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Comparisons with Video Models</h3>

<figure id="S4.SS5.fig1" class="ltx_figure ltx_align_floatright">
<div id="S4.SS5.fig1.1" class="ltx_block">
<figure id="S4.T3" class="ltx_table ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.3.2" class="ltx_text" style="font-size:90%;">Comparisons with state-of-the-art on Penn Action.</span></figcaption>
</figure>
<table id="S4.SS5.fig1.1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.SS5.fig1.1.1.1.1" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Method</th>
<td id="S4.SS5.fig1.1.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt">Penn Action</td>
</tr>
<tr id="S4.SS5.fig1.1.1.2.2" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Baseline</th>
<td id="S4.SS5.fig1.1.1.2.2.2" class="ltx_td ltx_align_right ltx_border_t">85.2</td>
</tr>
<tr id="S4.SS5.fig1.1.1.3.3" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours</th>
<td id="S4.SS5.fig1.1.1.3.3.2" class="ltx_td ltx_align_right">89.0</td>
</tr>
<tr id="S4.SS5.fig1.1.1.4.4" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="2">
<span id="S4.SS5.fig1.1.1.4.4.1.1" class="ltx_ERROR undefined">\hdashline</span> Â Â Â Â  Â Â Â Â Â Â <span id="S4.SS5.fig1.1.1.4.4.1.2" class="ltx_text ltx_font_bold ltx_font_italic">video-based methods</span>
</th>
</tr>
<tr id="S4.SS5.fig1.1.1.5.5" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Iqbal et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</th>
<td id="S4.SS5.fig1.1.1.5.5.2" class="ltx_td ltx_align_right">81.1</td>
</tr>
<tr id="S4.SS5.fig1.1.1.6.6" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Song et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</th>
<td id="S4.SS5.fig1.1.1.6.6.2" class="ltx_td ltx_align_right">96.5</td>
</tr>
<tr id="S4.SS5.fig1.1.1.7.7" class="ltx_tr">
<th id="S4.SS5.fig1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Luo et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>
</th>
<td id="S4.SS5.fig1.1.1.7.7.2" class="ltx_td ltx_align_right ltx_border_bb">97.7</td>
</tr>
</tbody>
</table>
<figure id="S4.T4" class="ltx_table ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S4.T4.4.2" class="ltx_text" style="font-size:90%;">Comparisons with state-of-the-art on BBC Pose. Result with (*) is reported in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Ours <span id="S4.T4.4.2.1" class="ltx_text ltx_font_italic">(best)</span> is with extra unlabeled samples.</span></figcaption>
</figure>
<table id="S4.SS5.fig1.1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.SS5.fig1.1.2.1.1" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Method</th>
<td id="S4.SS5.fig1.1.2.1.1.2" class="ltx_td ltx_align_right ltx_border_tt">BBC Pose</td>
</tr>
<tr id="S4.SS5.fig1.1.2.2.2" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">*Charles et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</th>
<td id="S4.SS5.fig1.1.2.2.2.2" class="ltx_td ltx_align_right ltx_border_t">79.9</td>
</tr>
<tr id="S4.SS5.fig1.1.2.3.3" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Baseline</th>
<td id="S4.SS5.fig1.1.2.3.3.2" class="ltx_td ltx_align_right">88.7</td>
</tr>
<tr id="S4.SS5.fig1.1.2.4.4" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours</th>
<td id="S4.SS5.fig1.1.2.4.4.2" class="ltx_td ltx_align_right">92.5</td>
</tr>
<tr id="S4.SS5.fig1.1.2.5.5" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours <span id="S4.SS5.fig1.1.2.5.5.1.1" class="ltx_text ltx_font_bold ltx_font_italic">(best)</span>
</th>
<td id="S4.SS5.fig1.1.2.5.5.2" class="ltx_td ltx_align_right">93.1</td>
</tr>
<tr id="S4.SS5.fig1.1.2.6.6" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="2">
<span id="S4.SS5.fig1.1.2.6.6.1.1" class="ltx_ERROR undefined">\hdashline</span> Â Â Â Â  Â Â Â Â Â Â <span id="S4.SS5.fig1.1.2.6.6.1.2" class="ltx_text ltx_font_bold ltx_font_italic">video-based methods</span>
</th>
</tr>
<tr id="S4.SS5.fig1.1.2.7.7" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Pfister et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</th>
<td id="S4.SS5.fig1.1.2.7.7.2" class="ltx_td ltx_align_right">88.0</td>
</tr>
<tr id="S4.SS5.fig1.1.2.8.8" class="ltx_tr">
<th id="S4.SS5.fig1.1.2.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Charles et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>
</th>
<td id="S4.SS5.fig1.1.2.8.8.2" class="ltx_td ltx_align_right ltx_border_bb">95.6</td>
</tr>
</tbody>
</table>
<section id="S4.SS5.SSS0.Px1" class="ltx_paragraph ltx_centering">
<h5 class="ltx_title ltx_title_paragraph">Visualization.</h5>

<div id="S4.SS5.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS5.SSS0.Px1.p1.1" class="ltx_p">We provide visualization on Penn Action experiments in FigureÂ <a href="#S4.F5" title="Figure 5 â€£ Improvement in Online Scenario. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We visualize the self-supervised keypoints and the supervised keypoints (2nd and 3rd columns). The arrows from the self-supervised keypoints and supervised keypoints indicate the keypoint correspondence, according to the affinity matrix in the Transformer. We show arrows (correspondence) where the probability is larger than 0.1 in the affinity matrix. We use warmer color to indicate larger confidence for both keypoints and arrows. The last column visualizes the reconstructed target image in our self-supervised task, which has the size as the network inputs cropped from the original images. See AppendixÂ <a href="#A2" title="Appendix B Visualization â€£ Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a> for more visualization results.</p>
</div>
<figure id="S4.SS5.SSS0.Px1.2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.SS5.SSS0.Px1.1.fig1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:216.8pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T5" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.2.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.3.2" class="ltx_text" style="font-size:90%;">Smoothing results for Penn Action. Our method is complementary to temporal methods.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.SS5.SSS0.Px1.1.fig1.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS5.SSS0.Px1.1.fig1.1.1.1" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.1.fig1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S4.SS5.SSS0.Px1.1.fig1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">TTP Scenario</th>
<th id="S4.SS5.SSS0.Px1.1.fig1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">mPCK</th>
<th id="S4.SS5.SSS0.Px1.1.fig1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">w/ smoothing</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS5.SSS0.Px1.1.fig1.1.2.1" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.1.fig1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Baseline</th>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">w/o TTP</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">85.23</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">85.68 <span id="S4.SS5.SSS0.Px1.1.fig1.1.2.1.4.1" class="ltx_text" style="font-size:90%;">(+0.45)</span>
</td>
</tr>
<tr id="S4.SS5.SSS0.Px1.1.fig1.1.3.2" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.1.fig1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Transformer</th>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.3.2.2" class="ltx_td ltx_align_center">w/o TTP</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.3.2.3" class="ltx_td ltx_align_center">86.16</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.3.2.4" class="ltx_td ltx_align_center">86.58 <span id="S4.SS5.SSS0.Px1.1.fig1.1.3.2.4.1" class="ltx_text" style="font-size:90%;">(+0.42)</span>
</td>
</tr>
<tr id="S4.SS5.SSS0.Px1.1.fig1.1.4.3" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.1.fig1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Transformer</th>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.4.3.2" class="ltx_td ltx_align_center">Online</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.4.3.3" class="ltx_td ltx_align_center">87.75</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.4.3.4" class="ltx_td ltx_align_center">88.31 <span id="S4.SS5.SSS0.Px1.1.fig1.1.4.3.4.1" class="ltx_text" style="font-size:90%;">(+0.56)</span>
</td>
</tr>
<tr id="S4.SS5.SSS0.Px1.1.fig1.1.5.4" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Transformer</th>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">Offline</td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.3.1" class="ltx_text ltx_font_bold">88.98</span></td>
<td id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.4.1" class="ltx_text ltx_font_bold">89.51 <span id="S4.SS5.SSS0.Px1.1.fig1.1.5.4.4.1.1" class="ltx_text" style="font-size:90%;">(+0.53)</span></span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.SS5.SSS0.Px1.2.fig2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:173.4pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T6" class="ltx_table ltx_figure_panel">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.3.2" class="ltx_text" style="font-size:90%;">The results of transferring the model trained on Penn to Human3.6M.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.SS5.SSS0.Px1.2.fig2.1" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.SS5.SSS0.Px1.2.fig2.1.1.1" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.2.fig2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Method</th>
<th id="S4.SS5.SSS0.Px1.2.fig2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">TTP Scenario</th>
<th id="S4.SS5.SSS0.Px1.2.fig2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">mPCK</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.SS5.SSS0.Px1.2.fig2.1.2.1" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.2.fig2.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Baseline</th>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">w/o TTP</td>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">52.60</td>
</tr>
<tr id="S4.SS5.SSS0.Px1.2.fig2.1.3.2" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.2.fig2.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Transformer</th>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.3.2.2" class="ltx_td ltx_align_center">w/o TTP</td>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.3.2.3" class="ltx_td ltx_align_center">56.27</td>
</tr>
<tr id="S4.SS5.SSS0.Px1.2.fig2.1.4.3" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.2.fig2.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Transformer</th>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.4.3.2" class="ltx_td ltx_align_center">Online</td>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.4.3.3" class="ltx_td ltx_align_center">60.14</td>
</tr>
<tr id="S4.SS5.SSS0.Px1.2.fig2.1.5.4" class="ltx_tr">
<th id="S4.SS5.SSS0.Px1.2.fig2.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Transformer</th>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">Offline</td>
<td id="S4.SS5.SSS0.Px1.2.fig2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb">61.04</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</figure>
</section>
<section id="S4.SS5.SSS0.Px2" class="ltx_paragraph ltx_centering">
<h5 class="ltx_title ltx_title_paragraph">Complementary to Temporal Methods.</h5>

<div id="S4.SS5.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS5.SSS0.Px2.p1.1" class="ltx_p">Even though our method is designed for single image input and requires no consecutive frames like videos, it is complementary to temporal methods such as 3D convolutionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> or smoothing techniquesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. We apply Savitzkyâ€“Golay filter for smoothing along with our methods for demonstration. In TableÂ <a href="#S4.T5" title="Table 5 â€£ Visualization. â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we present the results on Penn Action, as Penn Action is the only dataset here with completely consecutive test samples. After smoothing, our method presents a similar improvement to baseline. The increase in accuracy when performing smoothing is too small so the performance gain of our method does not come from temporal information and can be further improved combined with temporal methods.</p>
</div>
</section>
<section id="S4.SS5.SSS0.Px3" class="ltx_paragraph ltx_centering">
<h5 class="ltx_title ltx_title_paragraph">Comparisons with State-of-the-Art.</h5>

<div id="S4.SS5.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS5.SSS0.Px3.p1.1" class="ltx_p">In TableÂ <a href="#S4.SS5" title="4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a> and TableÂ <a href="#S4.SS5" title="4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.5</span></a> we compare our best results with state-of-the-art models on Penn Action and BBC Pose. Note that most of the methods on both datasets use multiple video frames as inputs and use larger input resolutions, which makes them not directly comparable with our method. We report the results for references. We argue that our approach with single image input has more flexibility and can be generalized beyond video data. Most works on HumanÂ 3.6M focus on 3D pose estimation thus are not reported.</p>
</div>
</section>
<section id="S5" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we propose to personalize human pose estimation with unlabeled test samples during test time. Our proposed Test-Time Personalization approach is firstly trained with diverse data, and then updated during test time using self-supervised keypoints to adapt to a specific subject. To enhance the relation between supervised and self-supervised tasks, we propose a Transformer design that allows supervised pose estimation to be directly improved from fine-tuning self-supervised keypoints. Our proposed method shows significant improvement over baseline on multiple datasets.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Societal Impact.</span> The proposed method improves the performance on the human pose estimation task, which has a variety of applications such as falling detection, body language understanding, autonomously sports and dancing teaching. Furthermore, our method utilizes unlabeled personal data and thus can be deployed locally, reducing human effort and avoiding privacy violation. However, the proposed method can also be used for malicious purposes, such as surveillance. To avoid possible harmful applications, we are committed to limit our methods from any potential malicious usage.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Acknowledgments and Funding Transparency Statement.</span> This work was supported, in part, by gifts from Qualcomm, TuSimple and Picsart.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography ltx_centering">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Bruno Artacho and Andreas Savakis.

</span>
<span class="ltx_bibblock">Unipose: Unified human pose estimation in single images and videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 7035â€“7044, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
JimmyÂ Lei Ba, JamieÂ Ryan Kiros, and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Layer normalization.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1607.06450</span>, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan
Zhu, and Antonio Torralba.

</span>
<span class="ltx_bibblock">Semantic photo manipulation with a generative image prior.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">ACM Trans. Graph.</span>, 38(4), 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Yue Cao, Jiarui Xu, Stephen Lin, Fangyun Wei, and Han Hu.

</span>
<span class="ltx_bibblock">Gcnet: Non-local networks meet squeeze-excitation networks and
beyond.

</span>
<span class="ltx_bibblock">In <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision Workshops</span>, pages 0â€“0, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh.

</span>
<span class="ltx_bibblock">Openpose: realtime multi-person 2d pose estimation using part
affinity fields.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>,
43(1):172â€“186, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
Kirillov, and Sergey Zagoruyko.

</span>
<span class="ltx_bibblock">End-to-end object detection with transformers.

</span>
<span class="ltx_bibblock">In <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">European Conference on Computer Vision</span>, pages 213â€“229.
Springer, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Joao Carreira, Pulkit Agrawal, Katerina Fragkiadaki, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Human pose estimation with iterative error feedback.

</span>
<span class="ltx_bibblock">In <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 4733â€“4742, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
James Charles, Tomas Pfister, Mark Everingham, and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Automatic and efficient human pose estimation for sign language
videos.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">International Journal of Computer Vision</span>, 110(1):70â€“90, 2014.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
James Charles, Tomas Pfister, D.Â Magee, DavidÂ C. Hogg, and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Domain adaptation for upper body pose tracking in signed tv
broadcasts.

</span>
<span class="ltx_bibblock">In <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">BMVC</span>, 2013.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
James Charles, Tomas Pfister, Derek Magee, David Hogg, and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Personalizing human video pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 3063â€“3072, 2016.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
Ilya Sutskever.

</span>
<span class="ltx_bibblock">Generative pretraining from pixels.

</span>
<span class="ltx_bibblock">In <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
1691â€“1703. PMLR, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Xianjie Chen and Alan Yuille.

</span>
<span class="ltx_bibblock">Articulated pose estimation by a graphical model with image dependent
pairwise relations.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1407.3399</span>, 2014.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Yilun Chen, Zhicheng Wang, Yuxiang Peng, Zhiqiang Zhang, Gang Yu, and Jian Sun.

</span>
<span class="ltx_bibblock">Cascaded pyramid network for multi-person pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 7103â€“7112, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Bowen Cheng, Bin Xiao, Jingdong Wang, Honghui Shi, ThomasÂ S Huang, and Lei
Zhang.

</span>
<span class="ltx_bibblock">Higherhrnet: Scale-aware representation learning for bottom-up human
pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 5386â€“5395, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Xiao Chu, Wanli Ouyang, Hongsheng Li, and Xiaogang Wang.

</span>
<span class="ltx_bibblock">Structured feature learning for pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">CVPR</span>, 2016.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, etÂ al.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at
scale.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2010.11929</span>, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.

</span>
<span class="ltx_bibblock">Unsupervised representation learning by predicting image rotations.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1803.07728</span>, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Rohit Girdhar, Georgia Gkioxari, Lorenzo Torresani, Manohar Paluri, and
DuÂ Tran.

</span>
<span class="ltx_bibblock">Detect-and-track: Efficient pose estimation in videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 350â€“359, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Nicklas Hansen, Rishabh Jangir, YuÂ Sun, Guillem AlenyÃ , Pieter Abbeel,
AlexeiÂ A. Efros, Lerrel Pinto, and Xiaolong Wang.

</span>
<span class="ltx_bibblock">Self-supervised policy adaptation during deployment.

</span>
<span class="ltx_bibblock">In <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Kaiming He, Georgia Gkioxari, Piotr DollÃ¡r, and Ross Girshick.

</span>
<span class="ltx_bibblock">Mask r-cnn.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</span>, pages 2961â€“2969, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 770â€“778, 2016.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, and Yichen Wei.

</span>
<span class="ltx_bibblock">Relation networks for object detection.

</span>
<span class="ltx_bibblock">In <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 3588â€“3597, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Catalin Ionescu, Dragos Papava, Vlad Olaru, and Cristian Sminchisescu.

</span>
<span class="ltx_bibblock">Human3.6m: Large scale datasets and predictive methods for 3d human
sensing in natural environments.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>,
36(7):1325â€“1339, jul 2014.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Umar Iqbal, Martin Garbade, and Juergen Gall.

</span>
<span class="ltx_bibblock">Pose for action-action for pose.

</span>
<span class="ltx_bibblock">In <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">2017 12th IEEE International Conference on Automatic Face &amp;
Gesture Recognition (FG 2017)</span>, pages 438â€“445. IEEE, 2017.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Tomas Jakab, Ankush Gupta, Hakan Bilen, and Andrea Vedaldi.

</span>
<span class="ltx_bibblock">Unsupervised learning of object landmarks through conditional image
generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1806.07823</span>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Tomas Jakab, Ankush Gupta, Hakan Bilen, and Andrea Vedaldi.

</span>
<span class="ltx_bibblock">Self-supervised learning of interpretable keypoints from unlabelled
videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 8787â€“8797, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Hanwen Jiang, Shaowei Liu, Jiashun Wang, and Xiaolong Wang.

</span>
<span class="ltx_bibblock">Hand-object contact consistency reasoning for human grasps
generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.03304</span>, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Justin Johnson, Alexandre Alahi, and LiÂ Fei-Fei.

</span>
<span class="ltx_bibblock">Perceptual losses for real-time style transfer and super-resolution.

</span>
<span class="ltx_bibblock">In <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, pages 694â€“711.
Springer, 2016.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Hanbyul Joo, Natalia Neverova, and Andrea Vedaldi.

</span>
<span class="ltx_bibblock">Exemplar fine-tuning for 3d human model fitting towards in-the-wild
3d human pose estimation.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2004.03686</span>, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
DiederikÂ P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1412.6980</span>, 2014.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
TejasÂ D Kulkarni, Ankush Gupta, Catalin Ionescu, Sebastian Borgeaud, Malcolm
Reynolds, Andrew Zisserman, and Volodymyr Mnih.

</span>
<span class="ltx_bibblock">Unsupervised learning of object keypoints for perception and control.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>,
32:10724â€“10734, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
KeÂ Li, Shijie Wang, Xiang Zhang, Yifan Xu, Weijian Xu, and Zhuowen Tu.

</span>
<span class="ltx_bibblock">Pose recognition with cascade transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.06976</span>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Sijin Li and AntoniÂ B Chan.

</span>
<span class="ltx_bibblock">3d human pose estimation from monocular images with deep
convolutional neural network.

</span>
<span class="ltx_bibblock">In <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Asian Conference on Computer Vision</span>, pages 332â€“347.
Springer, 2014.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Xueting Li, Sifei Liu, Shalini DeÂ Mello, Kihwan Kim, Xiaolong Wang, Ming-Hsuan
Yang, and Jan Kautz.

</span>
<span class="ltx_bibblock">Online adaptation for consistent mesh reconstruction in the wild.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.03196</span>, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Yunzhu Li, Antonio Torralba, Animashree Anandkumar, Dieter Fox, and Animesh
Garg.

</span>
<span class="ltx_bibblock">Causal discovery in physical systems from videos.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.00631</span>, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran,
Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf.

</span>
<span class="ltx_bibblock">Object-centric learning with slot attention.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.15055</span>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Dominik Lorenz, Leonard Bereska, Timo Milbich, and Bjorn Ommer.

</span>
<span class="ltx_bibblock">Unsupervised part-based disentangling of object shape and appearance.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 10955â€“10964, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Yue Luo, Jimmy Ren, Zhouxia Wang, Wenxiu Sun, Jinshan Pan, Jianbo Liu, Jiahao
Pang, and Liang Lin.

</span>
<span class="ltx_bibblock">Lstm pose machines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 5207â€“5215, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Lucas Manuelli, Yunzhu Li, Pete Florence, and Russ Tedrake.

</span>
<span class="ltx_bibblock">Keypoints into the future: Self-supervised correspondence in
model-based reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.05085</span>, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Weian Mao, Yongtao Ge, Chunhua Shen, Zhi Tian, Xinlong Wang, and Zhibin Wang.

</span>
<span class="ltx_bibblock">Tfpose: Direct human pose estimation with transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.15320</span>, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Jiteng Mu, Weichao Qiu, Adam Kortylewski, Alan Yuille, Nuno Vasconcelos, and
Xiaolong Wang.

</span>
<span class="ltx_bibblock">A-sdf: Learning disentangled signed distance functions for
articulated shape representation.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2104.07645</span>, 2021.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Alejandro Newell, Kaiyu Yang, and Jia Deng.

</span>
<span class="ltx_bibblock">Stacked hourglass networks for human pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, pages 483â€“499.
Springer, 2016.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Xuecheng Nie, Jiashi Feng, Jianfeng Zhang, and Shuicheng Yan.

</span>
<span class="ltx_bibblock">Single-stage multi-person pose machines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span>, pages 6951â€“6960, 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan
Tompson, Chris Bregler, and Kevin Murphy.

</span>
<span class="ltx_bibblock">Towards accurate multi-person pose estimation in the wild.

</span>
<span class="ltx_bibblock">In <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 4903â€“4911, 2017.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer,
Alexander Ku, and Dustin Tran.

</span>
<span class="ltx_bibblock">Image transformer.

</span>
<span class="ltx_bibblock">In <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
4055â€“4064. PMLR, 2018.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli.

</span>
<span class="ltx_bibblock">3d human pose estimation in video with temporal convolutions and
semi-supervised training.

</span>
<span class="ltx_bibblock">In <span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 7753â€“7762, 2019.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Tomas Pfister, James Charles, and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Flowing convnets for human pose estimation in videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</span>, pages 1913â€“1921, 2015.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya,
and Jonathon Shlens.

</span>
<span class="ltx_bibblock">Stand-alone self-attention in vision models.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1906.05909</span>, 2019.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Assaf Shocher, Shai Bagon, Phillip Isola, and Michal Irani.

</span>
<span class="ltx_bibblock">Ingan: Capturing and remapping the "dna" of a natural image, 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Assaf Shocher, Nadav Cohen, and Michal Irani.

</span>
<span class="ltx_bibblock">"zero-shot" super-resolution using deep internal learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">CVPR</span>, pages 3118â€“3126. IEEE Computer Society, 2018.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Jie Song, Limin Wang, Luc VanÂ Gool, and Otmar Hilliges.

</span>
<span class="ltx_bibblock">Thin-slicing network: A deep structured model for pose estimation in
videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 4220â€“4229, 2017.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov.

</span>
<span class="ltx_bibblock">Dropout: A simple way to prevent neural networks from overfitting.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Journal of Machine Learning Research</span>, 15(56):1929â€“1958, 2014.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Lucas Stoffl, Maxime Vidal, and Alexander Mathis.

</span>
<span class="ltx_bibblock">End-to-end trainable multi-instance pose estimation with
transformers.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2103.12115</span>, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Omer Sumer, Tobias Dencker, and Bjorn Ommer.

</span>
<span class="ltx_bibblock">Self-supervised learning of pose embeddings from spatiotemporal
relations in videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</span>, pages 4298â€“4307, 2017.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid.

</span>
<span class="ltx_bibblock">Videobert: A joint model for video and language representation
learning.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span>, pages 7464â€“7473, 2019.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
KeÂ Sun, Bin Xiao, Dong Liu, and Jingdong Wang.

</span>
<span class="ltx_bibblock">Deep high-resolution representation learning for human pose
estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">CVPR</span>, 2019.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
YuÂ Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.

</span>
<span class="ltx_bibblock">Test-time training with self-supervision for generalization under
distribution shifts.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
9229â€“9248. PMLR, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Alexander Toshev and Christian Szegedy.

</span>
<span class="ltx_bibblock">Deeppose: Human pose estimation via deep neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 1653â€“1660, 2014.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
AidanÂ N Gomez, Lukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1706.03762</span>, 2017.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.

</span>
<span class="ltx_bibblock">Fully test-time adaptation by entropy minimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.10726</span>, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Manchen Wang, Joseph Tighe, and Davide Modolo.

</span>
<span class="ltx_bibblock">Combining detection and tracking for human pose estimation in videos.

</span>
<span class="ltx_bibblock">In <span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 11088â€“11096, 2020.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.

</span>
<span class="ltx_bibblock">Non-local neural networks.

</span>
<span class="ltx_bibblock">In <span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</span>, pages 7794â€“7803, 2018.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Shih-En Wei, Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh.

</span>
<span class="ltx_bibblock">Convolutional pose machines.

</span>
<span class="ltx_bibblock">In <span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition</span>, pages 4724â€“4732, 2016.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Bin Xiao, Haiping Wu, and Yichen Wei.

</span>
<span class="ltx_bibblock">Simple baselines for human pose estimation and tracking.

</span>
<span class="ltx_bibblock">In <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Proceedings of the European conference on computer vision
(ECCV)</span>, pages 466â€“481, 2018.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Sen Yang, Zhibin Quan, MuÂ Nie, and Wankou Yang.

</span>
<span class="ltx_bibblock">Transpose: Towards explainable human pose estimation by transformer.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2012.14214</span>, 2020.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Wei Yang, Shuang Li, Wanli Ouyang, Hongsheng Li, and Xiaogang Wang.

</span>
<span class="ltx_bibblock">Learning feature pyramids for human pose estimation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">proceedings of the IEEE international conference on computer
vision</span>, pages 1281â€“1290, 2017.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Xianfang Zeng, Yusu Pan, Mengmeng Wang, Jiangning Zhang, and Yong Liu.

</span>
<span class="ltx_bibblock">Realistic face reenactment via self-supervised disentangling of
identity and pose.

</span>
<span class="ltx_bibblock">In <span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</span>, volumeÂ 34, pages 12757â€“12764, 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine,
and Chelsea Finn.

</span>
<span class="ltx_bibblock">Adaptive risk minimization: A meta-learning approach for tackling
group distribution shift.

</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2007.02931</span>, 2020.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Richard Zhang, Phillip Isola, and AlexeiÂ A Efros.

</span>
<span class="ltx_bibblock">Colorful image colorization.

</span>
<span class="ltx_bibblock">In <span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">European conference on computer vision</span>, pages 649â€“666.
Springer, 2016.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Weiyu Zhang, Menglong Zhu, and KonstantinosÂ G Derpanis.

</span>
<span class="ltx_bibblock">From actemes to action: A strongly-supervised representation for
detailed action understanding.

</span>
<span class="ltx_bibblock">In <span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</span>, pages 2248â€“2255, 2013.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Yuting Zhang, Yijie Guo, Yixin Jin, Yijun Luo, Zhiyuan He, and Honglak Lee.

</span>
<span class="ltx_bibblock">Unsupervised discovery of object landmarks as structural
representations.

</span>
<span class="ltx_bibblock">In <span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span>, pages 2694â€“2703, 2018.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Hengshuang Zhao, Jiaya Jia, and Vladlen Koltun.

</span>
<span class="ltx_bibblock">Exploring self-attention for image recognition.

</span>
<span class="ltx_bibblock">In <span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span>, pages 10076â€“10085, 2020.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Xingyi Zhou, Qixing Huang, Xiao Sun, Xiangyang Xue, and Yichen Wei.

</span>
<span class="ltx_bibblock">Towards 3d human pose estimation in the wild: A weakly-supervised
approach.

</span>
<span class="ltx_bibblock">In <span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">The IEEE International Conference on Computer Vision (ICCV)</span>,
Oct 2017.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Xingyi Zhou, Dequan Wang, and Philipp KrÃ¤henbÃ¼hl.

</span>
<span class="ltx_bibblock">Objects as points.

</span>
<span class="ltx_bibblock"><span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1904.07850</span>, 2019.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_centering ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix ltx_centering">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Pipeline of the Alternative Method</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.2" class="ltx_p">For clarification, we show the alternative method we discussed and compared the proposed method with. It is denoted as <span id="A1.p1.2.1" class="ltx_text ltx_font_italic">Feat. shared (keypoint)</span> in SectionÂ <a href="#S4.SS3" title="4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>. Instead of using a Transformer to model the relation between two sets of keypoints, we simply use a supervised head <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="\psi^{\text{sup}}" display="inline"><semantics id="A1.p1.1.m1.1a"><msup id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mi id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml">Ïˆ</mi><mtext id="A1.p1.1.m1.1.1.3" xref="A1.p1.1.m1.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1">superscript</csymbol><ci id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">ğœ“</ci><ci id="A1.p1.1.m1.1.1.3a.cmml" xref="A1.p1.1.m1.1.1.3"><mtext mathsize="70%" id="A1.p1.1.m1.1.1.3.cmml" xref="A1.p1.1.m1.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">\psi^{\text{sup}}</annotation></semantics></math> to predict <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="H^{\text{sup}}" display="inline"><semantics id="A1.p1.2.m2.1a"><msup id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml"><mi id="A1.p1.2.m2.1.1.2" xref="A1.p1.2.m2.1.1.2.cmml">H</mi><mtext id="A1.p1.2.m2.1.1.3" xref="A1.p1.2.m2.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1">superscript</csymbol><ci id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1.2">ğ»</ci><ci id="A1.p1.2.m2.1.1.3a.cmml" xref="A1.p1.2.m2.1.1.3"><mtext mathsize="70%" id="A1.p1.2.m2.1.1.3.cmml" xref="A1.p1.2.m2.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">H^{\text{sup}}</annotation></semantics></math>. Two tasks are only connected by sharing a feature backbone.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2107.02133/assets/x8.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="A1.F6.4.2" class="ltx_text" style="font-size:90%;">The alternative pipeline <span id="A1.F6.4.2.1" class="ltx_text ltx_font_italic">Feat. shared (keypoint)</span> we discussed and compared the proposed method with.</span></figcaption>
</figure>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Visualization</h2>

<figure id="A2.F7" class="ltx_figure"><img src="/html/2107.02133/assets/x9.png" id="A2.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A2.F7.3.2" class="ltx_text" style="font-size:90%;">Visualization of our proposed method on Penn Action validation set.</span></figcaption>
</figure>
<figure id="A2.F8" class="ltx_figure"><img src="/html/2107.02133/assets/x10.png" id="A2.F8.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="A2.F8.3.2" class="ltx_text" style="font-size:90%;">Visualization of our proposed method on Penn Action validation set.</span></figcaption>
</figure>
<div id="A2.p1" class="ltx_para">
<p id="A2.p1.3" class="ltx_p">In FigureÂ <a href="#A2.F7" title="Figure 7 â€£ Appendix B Visualization â€£ Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and FigureÂ <a href="#A2.F8" title="Figure 8 â€£ Appendix B Visualization â€£ Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> we visualize our predictions on Penn Action validation set. From top to bottom, the images are: (i)Â <span id="A2.p1.3.1" class="ltx_text ltx_font_bold">target image</span> <math id="A2.p1.1.m1.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="A2.p1.1.m1.1a"><msub id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mi id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml">I</mi><mi id="A2.p1.1.m1.1.1.3" xref="A2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1">subscript</csymbol><ci id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">ğ¼</ci><ci id="A2.p1.1.m1.1.1.3.cmml" xref="A2.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">I_{t}</annotation></semantics></math>, i.e. the input image. (ii)Â <span id="A2.p1.3.2" class="ltx_text ltx_font_bold">source image</span> <math id="A2.p1.2.m2.1" class="ltx_Math" alttext="I_{s}" display="inline"><semantics id="A2.p1.2.m2.1a"><msub id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml"><mi id="A2.p1.2.m2.1.1.2" xref="A2.p1.2.m2.1.1.2.cmml">I</mi><mi id="A2.p1.2.m2.1.1.3" xref="A2.p1.2.m2.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><apply id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.p1.2.m2.1.1.1.cmml" xref="A2.p1.2.m2.1.1">subscript</csymbol><ci id="A2.p1.2.m2.1.1.2.cmml" xref="A2.p1.2.m2.1.1.2">ğ¼</ci><ci id="A2.p1.2.m2.1.1.3.cmml" xref="A2.p1.2.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">I_{s}</annotation></semantics></math>, which provides appearance. (iii)Â <span id="A2.p1.3.3" class="ltx_text ltx_font_bold">reconstruction</span> <math id="A2.p1.3.m3.1" class="ltx_Math" alttext="\hat{I}_{t}" display="inline"><semantics id="A2.p1.3.m3.1a"><msub id="A2.p1.3.m3.1.1" xref="A2.p1.3.m3.1.1.cmml"><mover accent="true" id="A2.p1.3.m3.1.1.2" xref="A2.p1.3.m3.1.1.2.cmml"><mi id="A2.p1.3.m3.1.1.2.2" xref="A2.p1.3.m3.1.1.2.2.cmml">I</mi><mo id="A2.p1.3.m3.1.1.2.1" xref="A2.p1.3.m3.1.1.2.1.cmml">^</mo></mover><mi id="A2.p1.3.m3.1.1.3" xref="A2.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.1b"><apply id="A2.p1.3.m3.1.1.cmml" xref="A2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A2.p1.3.m3.1.1.1.cmml" xref="A2.p1.3.m3.1.1">subscript</csymbol><apply id="A2.p1.3.m3.1.1.2.cmml" xref="A2.p1.3.m3.1.1.2"><ci id="A2.p1.3.m3.1.1.2.1.cmml" xref="A2.p1.3.m3.1.1.2.1">^</ci><ci id="A2.p1.3.m3.1.1.2.2.cmml" xref="A2.p1.3.m3.1.1.2.2">ğ¼</ci></apply><ci id="A2.p1.3.m3.1.1.3.cmml" xref="A2.p1.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.1c">\hat{I}_{t}</annotation></semantics></math>. (iv)Â <span id="A2.p1.3.4" class="ltx_text ltx_font_bold">self-supervised keypoints</span>. There are 30 self-supervised keypoints in our setting. (v)Â <span id="A2.p1.3.5" class="ltx_text ltx_font_bold">supervised keypoints</span>. (vi)Â <span id="A2.p1.3.6" class="ltx_text ltx_font_bold">ground-truth</span>.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.9" class="ltx_p">For self-supervised keypoints, we show the contribution of each keypoint to the final pose estimation with color. This is computed as follows. Recall that the Transformer models the relation between two tasks as the affinity matrix</p>
<table id="A2.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E11.m1.1" class="ltx_Math" alttext="W\in\mathbb{R}^{k^{\text{sup}}\times k^{\text{self}}}," display="block"><semantics id="A2.E11.m1.1a"><mrow id="A2.E11.m1.1.1.1" xref="A2.E11.m1.1.1.1.1.cmml"><mrow id="A2.E11.m1.1.1.1.1" xref="A2.E11.m1.1.1.1.1.cmml"><mi id="A2.E11.m1.1.1.1.1.2" xref="A2.E11.m1.1.1.1.1.2.cmml">W</mi><mo id="A2.E11.m1.1.1.1.1.1" xref="A2.E11.m1.1.1.1.1.1.cmml">âˆˆ</mo><msup id="A2.E11.m1.1.1.1.1.3" xref="A2.E11.m1.1.1.1.1.3.cmml"><mi id="A2.E11.m1.1.1.1.1.3.2" xref="A2.E11.m1.1.1.1.1.3.2.cmml">â„</mi><mrow id="A2.E11.m1.1.1.1.1.3.3" xref="A2.E11.m1.1.1.1.1.3.3.cmml"><msup id="A2.E11.m1.1.1.1.1.3.3.2" xref="A2.E11.m1.1.1.1.1.3.3.2.cmml"><mi id="A2.E11.m1.1.1.1.1.3.3.2.2" xref="A2.E11.m1.1.1.1.1.3.3.2.2.cmml">k</mi><mtext id="A2.E11.m1.1.1.1.1.3.3.2.3" xref="A2.E11.m1.1.1.1.1.3.3.2.3a.cmml">sup</mtext></msup><mo lspace="0.222em" rspace="0.222em" id="A2.E11.m1.1.1.1.1.3.3.1" xref="A2.E11.m1.1.1.1.1.3.3.1.cmml">Ã—</mo><msup id="A2.E11.m1.1.1.1.1.3.3.3" xref="A2.E11.m1.1.1.1.1.3.3.3.cmml"><mi id="A2.E11.m1.1.1.1.1.3.3.3.2" xref="A2.E11.m1.1.1.1.1.3.3.3.2.cmml">k</mi><mtext id="A2.E11.m1.1.1.1.1.3.3.3.3" xref="A2.E11.m1.1.1.1.1.3.3.3.3a.cmml">self</mtext></msup></mrow></msup></mrow><mo id="A2.E11.m1.1.1.1.2" xref="A2.E11.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.E11.m1.1b"><apply id="A2.E11.m1.1.1.1.1.cmml" xref="A2.E11.m1.1.1.1"><in id="A2.E11.m1.1.1.1.1.1.cmml" xref="A2.E11.m1.1.1.1.1.1"></in><ci id="A2.E11.m1.1.1.1.1.2.cmml" xref="A2.E11.m1.1.1.1.1.2">ğ‘Š</ci><apply id="A2.E11.m1.1.1.1.1.3.cmml" xref="A2.E11.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="A2.E11.m1.1.1.1.1.3.1.cmml" xref="A2.E11.m1.1.1.1.1.3">superscript</csymbol><ci id="A2.E11.m1.1.1.1.1.3.2.cmml" xref="A2.E11.m1.1.1.1.1.3.2">â„</ci><apply id="A2.E11.m1.1.1.1.1.3.3.cmml" xref="A2.E11.m1.1.1.1.1.3.3"><times id="A2.E11.m1.1.1.1.1.3.3.1.cmml" xref="A2.E11.m1.1.1.1.1.3.3.1"></times><apply id="A2.E11.m1.1.1.1.1.3.3.2.cmml" xref="A2.E11.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="A2.E11.m1.1.1.1.1.3.3.2.1.cmml" xref="A2.E11.m1.1.1.1.1.3.3.2">superscript</csymbol><ci id="A2.E11.m1.1.1.1.1.3.3.2.2.cmml" xref="A2.E11.m1.1.1.1.1.3.3.2.2">ğ‘˜</ci><ci id="A2.E11.m1.1.1.1.1.3.3.2.3a.cmml" xref="A2.E11.m1.1.1.1.1.3.3.2.3"><mtext mathsize="50%" id="A2.E11.m1.1.1.1.1.3.3.2.3.cmml" xref="A2.E11.m1.1.1.1.1.3.3.2.3">sup</mtext></ci></apply><apply id="A2.E11.m1.1.1.1.1.3.3.3.cmml" xref="A2.E11.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="A2.E11.m1.1.1.1.1.3.3.3.1.cmml" xref="A2.E11.m1.1.1.1.1.3.3.3">superscript</csymbol><ci id="A2.E11.m1.1.1.1.1.3.3.3.2.cmml" xref="A2.E11.m1.1.1.1.1.3.3.3.2">ğ‘˜</ci><ci id="A2.E11.m1.1.1.1.1.3.3.3.3a.cmml" xref="A2.E11.m1.1.1.1.1.3.3.3.3"><mtext mathsize="50%" id="A2.E11.m1.1.1.1.1.3.3.3.3.cmml" xref="A2.E11.m1.1.1.1.1.3.3.3.3">self</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.E11.m1.1c">W\in\mathbb{R}^{k^{\text{sup}}\times k^{\text{self}}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p id="A2.p2.2" class="ltx_p">where <math id="A2.p2.1.m1.1" class="ltx_Math" alttext="k^{\text{sup}}" display="inline"><semantics id="A2.p2.1.m1.1a"><msup id="A2.p2.1.m1.1.1" xref="A2.p2.1.m1.1.1.cmml"><mi id="A2.p2.1.m1.1.1.2" xref="A2.p2.1.m1.1.1.2.cmml">k</mi><mtext id="A2.p2.1.m1.1.1.3" xref="A2.p2.1.m1.1.1.3a.cmml">sup</mtext></msup><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.1b"><apply id="A2.p2.1.m1.1.1.cmml" xref="A2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p2.1.m1.1.1.1.cmml" xref="A2.p2.1.m1.1.1">superscript</csymbol><ci id="A2.p2.1.m1.1.1.2.cmml" xref="A2.p2.1.m1.1.1.2">ğ‘˜</ci><ci id="A2.p2.1.m1.1.1.3a.cmml" xref="A2.p2.1.m1.1.1.3"><mtext mathsize="70%" id="A2.p2.1.m1.1.1.3.cmml" xref="A2.p2.1.m1.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.1c">k^{\text{sup}}</annotation></semantics></math> and <math id="A2.p2.2.m2.1" class="ltx_Math" alttext="k^{\text{self}}" display="inline"><semantics id="A2.p2.2.m2.1a"><msup id="A2.p2.2.m2.1.1" xref="A2.p2.2.m2.1.1.cmml"><mi id="A2.p2.2.m2.1.1.2" xref="A2.p2.2.m2.1.1.2.cmml">k</mi><mtext id="A2.p2.2.m2.1.1.3" xref="A2.p2.2.m2.1.1.3a.cmml">self</mtext></msup><annotation-xml encoding="MathML-Content" id="A2.p2.2.m2.1b"><apply id="A2.p2.2.m2.1.1.cmml" xref="A2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A2.p2.2.m2.1.1.1.cmml" xref="A2.p2.2.m2.1.1">superscript</csymbol><ci id="A2.p2.2.m2.1.1.2.cmml" xref="A2.p2.2.m2.1.1.2">ğ‘˜</ci><ci id="A2.p2.2.m2.1.1.3a.cmml" xref="A2.p2.2.m2.1.1.3"><mtext mathsize="70%" id="A2.p2.2.m2.1.1.3.cmml" xref="A2.p2.2.m2.1.1.3">self</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.2.m2.1c">k^{\text{self}}</annotation></semantics></math> are the number of supervised and self-supervised keypoints. Also recall that</p>
<table id="A2.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E12.m1.1" class="ltx_Math" alttext="H^{\text{sup}}_{t}=H^{\text{self}}_{t}W^{\top}." display="block"><semantics id="A2.E12.m1.1a"><mrow id="A2.E12.m1.1.1.1" xref="A2.E12.m1.1.1.1.1.cmml"><mrow id="A2.E12.m1.1.1.1.1" xref="A2.E12.m1.1.1.1.1.cmml"><msubsup id="A2.E12.m1.1.1.1.1.2" xref="A2.E12.m1.1.1.1.1.2.cmml"><mi id="A2.E12.m1.1.1.1.1.2.2.2" xref="A2.E12.m1.1.1.1.1.2.2.2.cmml">H</mi><mi id="A2.E12.m1.1.1.1.1.2.3" xref="A2.E12.m1.1.1.1.1.2.3.cmml">t</mi><mtext id="A2.E12.m1.1.1.1.1.2.2.3" xref="A2.E12.m1.1.1.1.1.2.2.3a.cmml">sup</mtext></msubsup><mo id="A2.E12.m1.1.1.1.1.1" xref="A2.E12.m1.1.1.1.1.1.cmml">=</mo><mrow id="A2.E12.m1.1.1.1.1.3" xref="A2.E12.m1.1.1.1.1.3.cmml"><msubsup id="A2.E12.m1.1.1.1.1.3.2" xref="A2.E12.m1.1.1.1.1.3.2.cmml"><mi id="A2.E12.m1.1.1.1.1.3.2.2.2" xref="A2.E12.m1.1.1.1.1.3.2.2.2.cmml">H</mi><mi id="A2.E12.m1.1.1.1.1.3.2.3" xref="A2.E12.m1.1.1.1.1.3.2.3.cmml">t</mi><mtext id="A2.E12.m1.1.1.1.1.3.2.2.3" xref="A2.E12.m1.1.1.1.1.3.2.2.3a.cmml">self</mtext></msubsup><mo lspace="0em" rspace="0em" id="A2.E12.m1.1.1.1.1.3.1" xref="A2.E12.m1.1.1.1.1.3.1.cmml">â€‹</mo><msup id="A2.E12.m1.1.1.1.1.3.3" xref="A2.E12.m1.1.1.1.1.3.3.cmml"><mi id="A2.E12.m1.1.1.1.1.3.3.2" xref="A2.E12.m1.1.1.1.1.3.3.2.cmml">W</mi><mo id="A2.E12.m1.1.1.1.1.3.3.3" xref="A2.E12.m1.1.1.1.1.3.3.3.cmml">âŠ¤</mo></msup></mrow></mrow><mo lspace="0em" id="A2.E12.m1.1.1.1.2" xref="A2.E12.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.E12.m1.1b"><apply id="A2.E12.m1.1.1.1.1.cmml" xref="A2.E12.m1.1.1.1"><eq id="A2.E12.m1.1.1.1.1.1.cmml" xref="A2.E12.m1.1.1.1.1.1"></eq><apply id="A2.E12.m1.1.1.1.1.2.cmml" xref="A2.E12.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A2.E12.m1.1.1.1.1.2.1.cmml" xref="A2.E12.m1.1.1.1.1.2">subscript</csymbol><apply id="A2.E12.m1.1.1.1.1.2.2.cmml" xref="A2.E12.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="A2.E12.m1.1.1.1.1.2.2.1.cmml" xref="A2.E12.m1.1.1.1.1.2">superscript</csymbol><ci id="A2.E12.m1.1.1.1.1.2.2.2.cmml" xref="A2.E12.m1.1.1.1.1.2.2.2">ğ»</ci><ci id="A2.E12.m1.1.1.1.1.2.2.3a.cmml" xref="A2.E12.m1.1.1.1.1.2.2.3"><mtext mathsize="70%" id="A2.E12.m1.1.1.1.1.2.2.3.cmml" xref="A2.E12.m1.1.1.1.1.2.2.3">sup</mtext></ci></apply><ci id="A2.E12.m1.1.1.1.1.2.3.cmml" xref="A2.E12.m1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="A2.E12.m1.1.1.1.1.3.cmml" xref="A2.E12.m1.1.1.1.1.3"><times id="A2.E12.m1.1.1.1.1.3.1.cmml" xref="A2.E12.m1.1.1.1.1.3.1"></times><apply id="A2.E12.m1.1.1.1.1.3.2.cmml" xref="A2.E12.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A2.E12.m1.1.1.1.1.3.2.1.cmml" xref="A2.E12.m1.1.1.1.1.3.2">subscript</csymbol><apply id="A2.E12.m1.1.1.1.1.3.2.2.cmml" xref="A2.E12.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="A2.E12.m1.1.1.1.1.3.2.2.1.cmml" xref="A2.E12.m1.1.1.1.1.3.2">superscript</csymbol><ci id="A2.E12.m1.1.1.1.1.3.2.2.2.cmml" xref="A2.E12.m1.1.1.1.1.3.2.2.2">ğ»</ci><ci id="A2.E12.m1.1.1.1.1.3.2.2.3a.cmml" xref="A2.E12.m1.1.1.1.1.3.2.2.3"><mtext mathsize="70%" id="A2.E12.m1.1.1.1.1.3.2.2.3.cmml" xref="A2.E12.m1.1.1.1.1.3.2.2.3">self</mtext></ci></apply><ci id="A2.E12.m1.1.1.1.1.3.2.3.cmml" xref="A2.E12.m1.1.1.1.1.3.2.3">ğ‘¡</ci></apply><apply id="A2.E12.m1.1.1.1.1.3.3.cmml" xref="A2.E12.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A2.E12.m1.1.1.1.1.3.3.1.cmml" xref="A2.E12.m1.1.1.1.1.3.3">superscript</csymbol><ci id="A2.E12.m1.1.1.1.1.3.3.2.cmml" xref="A2.E12.m1.1.1.1.1.3.3.2">ğ‘Š</ci><csymbol cd="latexml" id="A2.E12.m1.1.1.1.1.3.3.3.cmml" xref="A2.E12.m1.1.1.1.1.3.3.3">top</csymbol></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.E12.m1.1c">H^{\text{sup}}_{t}=H^{\text{self}}_{t}W^{\top}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
<p id="A2.p2.6" class="ltx_p">An entry <math id="A2.p2.3.m1.2" class="ltx_Math" alttext="W_{i,j}" display="inline"><semantics id="A2.p2.3.m1.2a"><msub id="A2.p2.3.m1.2.3" xref="A2.p2.3.m1.2.3.cmml"><mi id="A2.p2.3.m1.2.3.2" xref="A2.p2.3.m1.2.3.2.cmml">W</mi><mrow id="A2.p2.3.m1.2.2.2.4" xref="A2.p2.3.m1.2.2.2.3.cmml"><mi id="A2.p2.3.m1.1.1.1.1" xref="A2.p2.3.m1.1.1.1.1.cmml">i</mi><mo id="A2.p2.3.m1.2.2.2.4.1" xref="A2.p2.3.m1.2.2.2.3.cmml">,</mo><mi id="A2.p2.3.m1.2.2.2.2" xref="A2.p2.3.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A2.p2.3.m1.2b"><apply id="A2.p2.3.m1.2.3.cmml" xref="A2.p2.3.m1.2.3"><csymbol cd="ambiguous" id="A2.p2.3.m1.2.3.1.cmml" xref="A2.p2.3.m1.2.3">subscript</csymbol><ci id="A2.p2.3.m1.2.3.2.cmml" xref="A2.p2.3.m1.2.3.2">ğ‘Š</ci><list id="A2.p2.3.m1.2.2.2.3.cmml" xref="A2.p2.3.m1.2.2.2.4"><ci id="A2.p2.3.m1.1.1.1.1.cmml" xref="A2.p2.3.m1.1.1.1.1">ğ‘–</ci><ci id="A2.p2.3.m1.2.2.2.2.cmml" xref="A2.p2.3.m1.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.3.m1.2c">W_{i,j}</annotation></semantics></math> actually represents the weight of <math id="A2.p2.4.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="A2.p2.4.m2.1a"><mi id="A2.p2.4.m2.1.1" xref="A2.p2.4.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="A2.p2.4.m2.1b"><ci id="A2.p2.4.m2.1.1.cmml" xref="A2.p2.4.m2.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.4.m2.1c">j</annotation></semantics></math>-th self-supervised keypoint in computing the <math id="A2.p2.5.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="A2.p2.5.m3.1a"><mi id="A2.p2.5.m3.1.1" xref="A2.p2.5.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.p2.5.m3.1b"><ci id="A2.p2.5.m3.1.1.cmml" xref="A2.p2.5.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.5.m3.1c">i</annotation></semantics></math>-th supervised keypoint. We then define the contribution of <math id="A2.p2.6.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="A2.p2.6.m4.1a"><mi id="A2.p2.6.m4.1.1" xref="A2.p2.6.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="A2.p2.6.m4.1b"><ci id="A2.p2.6.m4.1.1.cmml" xref="A2.p2.6.m4.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.6.m4.1c">j</annotation></semantics></math>-th self-supervised keypoint to the final pose prediction as follows</p>
<table id="A2.E13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E13.m1.3" class="ltx_Math" alttext="c_{j}=\sum_{i=1}^{k^{\text{sup}}}W_{i,j}." display="block"><semantics id="A2.E13.m1.3a"><mrow id="A2.E13.m1.3.3.1" xref="A2.E13.m1.3.3.1.1.cmml"><mrow id="A2.E13.m1.3.3.1.1" xref="A2.E13.m1.3.3.1.1.cmml"><msub id="A2.E13.m1.3.3.1.1.2" xref="A2.E13.m1.3.3.1.1.2.cmml"><mi id="A2.E13.m1.3.3.1.1.2.2" xref="A2.E13.m1.3.3.1.1.2.2.cmml">c</mi><mi id="A2.E13.m1.3.3.1.1.2.3" xref="A2.E13.m1.3.3.1.1.2.3.cmml">j</mi></msub><mo rspace="0.111em" id="A2.E13.m1.3.3.1.1.1" xref="A2.E13.m1.3.3.1.1.1.cmml">=</mo><mrow id="A2.E13.m1.3.3.1.1.3" xref="A2.E13.m1.3.3.1.1.3.cmml"><munderover id="A2.E13.m1.3.3.1.1.3.1" xref="A2.E13.m1.3.3.1.1.3.1.cmml"><mo movablelimits="false" id="A2.E13.m1.3.3.1.1.3.1.2.2" xref="A2.E13.m1.3.3.1.1.3.1.2.2.cmml">âˆ‘</mo><mrow id="A2.E13.m1.3.3.1.1.3.1.2.3" xref="A2.E13.m1.3.3.1.1.3.1.2.3.cmml"><mi id="A2.E13.m1.3.3.1.1.3.1.2.3.2" xref="A2.E13.m1.3.3.1.1.3.1.2.3.2.cmml">i</mi><mo id="A2.E13.m1.3.3.1.1.3.1.2.3.1" xref="A2.E13.m1.3.3.1.1.3.1.2.3.1.cmml">=</mo><mn id="A2.E13.m1.3.3.1.1.3.1.2.3.3" xref="A2.E13.m1.3.3.1.1.3.1.2.3.3.cmml">1</mn></mrow><msup id="A2.E13.m1.3.3.1.1.3.1.3" xref="A2.E13.m1.3.3.1.1.3.1.3.cmml"><mi id="A2.E13.m1.3.3.1.1.3.1.3.2" xref="A2.E13.m1.3.3.1.1.3.1.3.2.cmml">k</mi><mtext id="A2.E13.m1.3.3.1.1.3.1.3.3" xref="A2.E13.m1.3.3.1.1.3.1.3.3a.cmml">sup</mtext></msup></munderover><msub id="A2.E13.m1.3.3.1.1.3.2" xref="A2.E13.m1.3.3.1.1.3.2.cmml"><mi id="A2.E13.m1.3.3.1.1.3.2.2" xref="A2.E13.m1.3.3.1.1.3.2.2.cmml">W</mi><mrow id="A2.E13.m1.2.2.2.4" xref="A2.E13.m1.2.2.2.3.cmml"><mi id="A2.E13.m1.1.1.1.1" xref="A2.E13.m1.1.1.1.1.cmml">i</mi><mo id="A2.E13.m1.2.2.2.4.1" xref="A2.E13.m1.2.2.2.3.cmml">,</mo><mi id="A2.E13.m1.2.2.2.2" xref="A2.E13.m1.2.2.2.2.cmml">j</mi></mrow></msub></mrow></mrow><mo lspace="0em" id="A2.E13.m1.3.3.1.2" xref="A2.E13.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.E13.m1.3b"><apply id="A2.E13.m1.3.3.1.1.cmml" xref="A2.E13.m1.3.3.1"><eq id="A2.E13.m1.3.3.1.1.1.cmml" xref="A2.E13.m1.3.3.1.1.1"></eq><apply id="A2.E13.m1.3.3.1.1.2.cmml" xref="A2.E13.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="A2.E13.m1.3.3.1.1.2.1.cmml" xref="A2.E13.m1.3.3.1.1.2">subscript</csymbol><ci id="A2.E13.m1.3.3.1.1.2.2.cmml" xref="A2.E13.m1.3.3.1.1.2.2">ğ‘</ci><ci id="A2.E13.m1.3.3.1.1.2.3.cmml" xref="A2.E13.m1.3.3.1.1.2.3">ğ‘—</ci></apply><apply id="A2.E13.m1.3.3.1.1.3.cmml" xref="A2.E13.m1.3.3.1.1.3"><apply id="A2.E13.m1.3.3.1.1.3.1.cmml" xref="A2.E13.m1.3.3.1.1.3.1"><csymbol cd="ambiguous" id="A2.E13.m1.3.3.1.1.3.1.1.cmml" xref="A2.E13.m1.3.3.1.1.3.1">superscript</csymbol><apply id="A2.E13.m1.3.3.1.1.3.1.2.cmml" xref="A2.E13.m1.3.3.1.1.3.1"><csymbol cd="ambiguous" id="A2.E13.m1.3.3.1.1.3.1.2.1.cmml" xref="A2.E13.m1.3.3.1.1.3.1">subscript</csymbol><sum id="A2.E13.m1.3.3.1.1.3.1.2.2.cmml" xref="A2.E13.m1.3.3.1.1.3.1.2.2"></sum><apply id="A2.E13.m1.3.3.1.1.3.1.2.3.cmml" xref="A2.E13.m1.3.3.1.1.3.1.2.3"><eq id="A2.E13.m1.3.3.1.1.3.1.2.3.1.cmml" xref="A2.E13.m1.3.3.1.1.3.1.2.3.1"></eq><ci id="A2.E13.m1.3.3.1.1.3.1.2.3.2.cmml" xref="A2.E13.m1.3.3.1.1.3.1.2.3.2">ğ‘–</ci><cn type="integer" id="A2.E13.m1.3.3.1.1.3.1.2.3.3.cmml" xref="A2.E13.m1.3.3.1.1.3.1.2.3.3">1</cn></apply></apply><apply id="A2.E13.m1.3.3.1.1.3.1.3.cmml" xref="A2.E13.m1.3.3.1.1.3.1.3"><csymbol cd="ambiguous" id="A2.E13.m1.3.3.1.1.3.1.3.1.cmml" xref="A2.E13.m1.3.3.1.1.3.1.3">superscript</csymbol><ci id="A2.E13.m1.3.3.1.1.3.1.3.2.cmml" xref="A2.E13.m1.3.3.1.1.3.1.3.2">ğ‘˜</ci><ci id="A2.E13.m1.3.3.1.1.3.1.3.3a.cmml" xref="A2.E13.m1.3.3.1.1.3.1.3.3"><mtext mathsize="50%" id="A2.E13.m1.3.3.1.1.3.1.3.3.cmml" xref="A2.E13.m1.3.3.1.1.3.1.3.3">sup</mtext></ci></apply></apply><apply id="A2.E13.m1.3.3.1.1.3.2.cmml" xref="A2.E13.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="A2.E13.m1.3.3.1.1.3.2.1.cmml" xref="A2.E13.m1.3.3.1.1.3.2">subscript</csymbol><ci id="A2.E13.m1.3.3.1.1.3.2.2.cmml" xref="A2.E13.m1.3.3.1.1.3.2.2">ğ‘Š</ci><list id="A2.E13.m1.2.2.2.3.cmml" xref="A2.E13.m1.2.2.2.4"><ci id="A2.E13.m1.1.1.1.1.cmml" xref="A2.E13.m1.1.1.1.1">ğ‘–</ci><ci id="A2.E13.m1.2.2.2.2.cmml" xref="A2.E13.m1.2.2.2.2">ğ‘—</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.E13.m1.3c">c_{j}=\sum_{i=1}^{k^{\text{sup}}}W_{i,j}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
</table>
<p id="A2.p2.8" class="ltx_p">The keypoints with larger <math id="A2.p2.7.m1.1" class="ltx_Math" alttext="c_{j}" display="inline"><semantics id="A2.p2.7.m1.1a"><msub id="A2.p2.7.m1.1.1" xref="A2.p2.7.m1.1.1.cmml"><mi id="A2.p2.7.m1.1.1.2" xref="A2.p2.7.m1.1.1.2.cmml">c</mi><mi id="A2.p2.7.m1.1.1.3" xref="A2.p2.7.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="A2.p2.7.m1.1b"><apply id="A2.p2.7.m1.1.1.cmml" xref="A2.p2.7.m1.1.1"><csymbol cd="ambiguous" id="A2.p2.7.m1.1.1.1.cmml" xref="A2.p2.7.m1.1.1">subscript</csymbol><ci id="A2.p2.7.m1.1.1.2.cmml" xref="A2.p2.7.m1.1.1.2">ğ‘</ci><ci id="A2.p2.7.m1.1.1.3.cmml" xref="A2.p2.7.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.7.m1.1c">c_{j}</annotation></semantics></math> are more important to the final pose prediction. Whereas the keypoints with smaller <math id="A2.p2.8.m2.1" class="ltx_Math" alttext="c_{j}" display="inline"><semantics id="A2.p2.8.m2.1a"><msub id="A2.p2.8.m2.1.1" xref="A2.p2.8.m2.1.1.cmml"><mi id="A2.p2.8.m2.1.1.2" xref="A2.p2.8.m2.1.1.2.cmml">c</mi><mi id="A2.p2.8.m2.1.1.3" xref="A2.p2.8.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="A2.p2.8.m2.1b"><apply id="A2.p2.8.m2.1.1.cmml" xref="A2.p2.8.m2.1.1"><csymbol cd="ambiguous" id="A2.p2.8.m2.1.1.1.cmml" xref="A2.p2.8.m2.1.1">subscript</csymbol><ci id="A2.p2.8.m2.1.1.2.cmml" xref="A2.p2.8.m2.1.1.2">ğ‘</ci><ci id="A2.p2.8.m2.1.1.3.cmml" xref="A2.p2.8.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.8.m2.1c">c_{j}</annotation></semantics></math> are less important to the final pose prediction and serve to facilitate the self-supervised task of reconstruction.</p>
</div>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">In FigureÂ <a href="#A2.F7" title="Figure 7 â€£ Appendix B Visualization â€£ Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and FigureÂ <a href="#A2.F8" title="Figure 8 â€£ Appendix B Visualization â€£ Appendix A Pipeline of the Alternative Method â€£ 4.5 Comparisons with Video Models â€£ Update Iterations. â€£ 4.4 Analysis on Test-Time Personalization â€£ 4.3 Main Results â€£ 4.2 Implementation Details â€£ 4 Experiment â€£ Test-Time Personalization with a Transformer for Human Pose Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> we show the self-supervised keypoints with their contribution to the final pose estimation in the fourth row. It is clear that the points that align with the position of supervised keypoints usually have higher contribution. Other points with deviated positions have lower contribution. They appear to serve more to facilitate the self-supervised task. Interestingly, some keypoints with minor contribution locate the non-human objects in Penn Action (barbell, bowling ball).</p>
</div>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>More Implementation Details</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.10" class="ltx_p"><span id="A3.p1.10.1" class="ltx_text ltx_font_bold">More Model Details.</span> Normally, the images <math id="A3.p1.1.m1.1" class="ltx_Math" alttext="I_{s}" display="inline"><semantics id="A3.p1.1.m1.1a"><msub id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml"><mi id="A3.p1.1.m1.1.1.2" xref="A3.p1.1.m1.1.1.2.cmml">I</mi><mi id="A3.p1.1.m1.1.1.3" xref="A3.p1.1.m1.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><apply id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A3.p1.1.m1.1.1.1.cmml" xref="A3.p1.1.m1.1.1">subscript</csymbol><ci id="A3.p1.1.m1.1.1.2.cmml" xref="A3.p1.1.m1.1.1.2">ğ¼</ci><ci id="A3.p1.1.m1.1.1.3.cmml" xref="A3.p1.1.m1.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">I_{s}</annotation></semantics></math> and <math id="A3.p1.2.m2.1" class="ltx_Math" alttext="I_{t}" display="inline"><semantics id="A3.p1.2.m2.1a"><msub id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml"><mi id="A3.p1.2.m2.1.1.2" xref="A3.p1.2.m2.1.1.2.cmml">I</mi><mi id="A3.p1.2.m2.1.1.3" xref="A3.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><apply id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A3.p1.2.m2.1.1.1.cmml" xref="A3.p1.2.m2.1.1">subscript</csymbol><ci id="A3.p1.2.m2.1.1.2.cmml" xref="A3.p1.2.m2.1.1.2">ğ¼</ci><ci id="A3.p1.2.m2.1.1.3.cmml" xref="A3.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">I_{t}</annotation></semantics></math> are <math id="A3.p1.3.m3.1" class="ltx_Math" alttext="128\times 128" display="inline"><semantics id="A3.p1.3.m3.1a"><mrow id="A3.p1.3.m3.1.1" xref="A3.p1.3.m3.1.1.cmml"><mn id="A3.p1.3.m3.1.1.2" xref="A3.p1.3.m3.1.1.2.cmml">128</mn><mo lspace="0.222em" rspace="0.222em" id="A3.p1.3.m3.1.1.1" xref="A3.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="A3.p1.3.m3.1.1.3" xref="A3.p1.3.m3.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.3.m3.1b"><apply id="A3.p1.3.m3.1.1.cmml" xref="A3.p1.3.m3.1.1"><times id="A3.p1.3.m3.1.1.1.cmml" xref="A3.p1.3.m3.1.1.1"></times><cn type="integer" id="A3.p1.3.m3.1.1.2.cmml" xref="A3.p1.3.m3.1.1.2">128</cn><cn type="integer" id="A3.p1.3.m3.1.1.3.cmml" xref="A3.p1.3.m3.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.3.m3.1c">128\times 128</annotation></semantics></math>. The heatmaps <math id="A3.p1.4.m4.1" class="ltx_Math" alttext="H^{\text{sup}}_{t}" display="inline"><semantics id="A3.p1.4.m4.1a"><msubsup id="A3.p1.4.m4.1.1" xref="A3.p1.4.m4.1.1.cmml"><mi id="A3.p1.4.m4.1.1.2.2" xref="A3.p1.4.m4.1.1.2.2.cmml">H</mi><mi id="A3.p1.4.m4.1.1.3" xref="A3.p1.4.m4.1.1.3.cmml">t</mi><mtext id="A3.p1.4.m4.1.1.2.3" xref="A3.p1.4.m4.1.1.2.3a.cmml">sup</mtext></msubsup><annotation-xml encoding="MathML-Content" id="A3.p1.4.m4.1b"><apply id="A3.p1.4.m4.1.1.cmml" xref="A3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A3.p1.4.m4.1.1.1.cmml" xref="A3.p1.4.m4.1.1">subscript</csymbol><apply id="A3.p1.4.m4.1.1.2.cmml" xref="A3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A3.p1.4.m4.1.1.2.1.cmml" xref="A3.p1.4.m4.1.1">superscript</csymbol><ci id="A3.p1.4.m4.1.1.2.2.cmml" xref="A3.p1.4.m4.1.1.2.2">ğ»</ci><ci id="A3.p1.4.m4.1.1.2.3a.cmml" xref="A3.p1.4.m4.1.1.2.3"><mtext mathsize="70%" id="A3.p1.4.m4.1.1.2.3.cmml" xref="A3.p1.4.m4.1.1.2.3">sup</mtext></ci></apply><ci id="A3.p1.4.m4.1.1.3.cmml" xref="A3.p1.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.4.m4.1c">H^{\text{sup}}_{t}</annotation></semantics></math> and <math id="A3.p1.5.m5.1" class="ltx_Math" alttext="H^{\text{self}}_{t}" display="inline"><semantics id="A3.p1.5.m5.1a"><msubsup id="A3.p1.5.m5.1.1" xref="A3.p1.5.m5.1.1.cmml"><mi id="A3.p1.5.m5.1.1.2.2" xref="A3.p1.5.m5.1.1.2.2.cmml">H</mi><mi id="A3.p1.5.m5.1.1.3" xref="A3.p1.5.m5.1.1.3.cmml">t</mi><mtext id="A3.p1.5.m5.1.1.2.3" xref="A3.p1.5.m5.1.1.2.3a.cmml">self</mtext></msubsup><annotation-xml encoding="MathML-Content" id="A3.p1.5.m5.1b"><apply id="A3.p1.5.m5.1.1.cmml" xref="A3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A3.p1.5.m5.1.1.1.cmml" xref="A3.p1.5.m5.1.1">subscript</csymbol><apply id="A3.p1.5.m5.1.1.2.cmml" xref="A3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A3.p1.5.m5.1.1.2.1.cmml" xref="A3.p1.5.m5.1.1">superscript</csymbol><ci id="A3.p1.5.m5.1.1.2.2.cmml" xref="A3.p1.5.m5.1.1.2.2">ğ»</ci><ci id="A3.p1.5.m5.1.1.2.3a.cmml" xref="A3.p1.5.m5.1.1.2.3"><mtext mathsize="70%" id="A3.p1.5.m5.1.1.2.3.cmml" xref="A3.p1.5.m5.1.1.2.3">self</mtext></ci></apply><ci id="A3.p1.5.m5.1.1.3.cmml" xref="A3.p1.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.5.m5.1c">H^{\text{self}}_{t}</annotation></semantics></math> are <math id="A3.p1.6.m6.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="A3.p1.6.m6.1a"><mrow id="A3.p1.6.m6.1.1" xref="A3.p1.6.m6.1.1.cmml"><mn id="A3.p1.6.m6.1.1.2" xref="A3.p1.6.m6.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="A3.p1.6.m6.1.1.1" xref="A3.p1.6.m6.1.1.1.cmml">Ã—</mo><mn id="A3.p1.6.m6.1.1.3" xref="A3.p1.6.m6.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.6.m6.1b"><apply id="A3.p1.6.m6.1.1.cmml" xref="A3.p1.6.m6.1.1"><times id="A3.p1.6.m6.1.1.1.cmml" xref="A3.p1.6.m6.1.1.1"></times><cn type="integer" id="A3.p1.6.m6.1.1.2.cmml" xref="A3.p1.6.m6.1.1.2">32</cn><cn type="integer" id="A3.p1.6.m6.1.1.3.cmml" xref="A3.p1.6.m6.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.6.m6.1c">32\times 32</annotation></semantics></math>. In self-supervised task, appearance information <math id="A3.p1.7.m7.1" class="ltx_Math" alttext="F^{\text{app}}_{s}" display="inline"><semantics id="A3.p1.7.m7.1a"><msubsup id="A3.p1.7.m7.1.1" xref="A3.p1.7.m7.1.1.cmml"><mi id="A3.p1.7.m7.1.1.2.2" xref="A3.p1.7.m7.1.1.2.2.cmml">F</mi><mi id="A3.p1.7.m7.1.1.3" xref="A3.p1.7.m7.1.1.3.cmml">s</mi><mtext id="A3.p1.7.m7.1.1.2.3" xref="A3.p1.7.m7.1.1.2.3a.cmml">app</mtext></msubsup><annotation-xml encoding="MathML-Content" id="A3.p1.7.m7.1b"><apply id="A3.p1.7.m7.1.1.cmml" xref="A3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A3.p1.7.m7.1.1.1.cmml" xref="A3.p1.7.m7.1.1">subscript</csymbol><apply id="A3.p1.7.m7.1.1.2.cmml" xref="A3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A3.p1.7.m7.1.1.2.1.cmml" xref="A3.p1.7.m7.1.1">superscript</csymbol><ci id="A3.p1.7.m7.1.1.2.2.cmml" xref="A3.p1.7.m7.1.1.2.2">ğ¹</ci><ci id="A3.p1.7.m7.1.1.2.3a.cmml" xref="A3.p1.7.m7.1.1.2.3"><mtext mathsize="70%" id="A3.p1.7.m7.1.1.2.3.cmml" xref="A3.p1.7.m7.1.1.2.3">app</mtext></ci></apply><ci id="A3.p1.7.m7.1.1.3.cmml" xref="A3.p1.7.m7.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.7.m7.1c">F^{\text{app}}_{s}</annotation></semantics></math> and keypoint information <math id="A3.p1.8.m8.1" class="ltx_Math" alttext="F^{\text{kp}}_{t}" display="inline"><semantics id="A3.p1.8.m8.1a"><msubsup id="A3.p1.8.m8.1.1" xref="A3.p1.8.m8.1.1.cmml"><mi id="A3.p1.8.m8.1.1.2.2" xref="A3.p1.8.m8.1.1.2.2.cmml">F</mi><mi id="A3.p1.8.m8.1.1.3" xref="A3.p1.8.m8.1.1.3.cmml">t</mi><mtext id="A3.p1.8.m8.1.1.2.3" xref="A3.p1.8.m8.1.1.2.3a.cmml">kp</mtext></msubsup><annotation-xml encoding="MathML-Content" id="A3.p1.8.m8.1b"><apply id="A3.p1.8.m8.1.1.cmml" xref="A3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A3.p1.8.m8.1.1.1.cmml" xref="A3.p1.8.m8.1.1">subscript</csymbol><apply id="A3.p1.8.m8.1.1.2.cmml" xref="A3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A3.p1.8.m8.1.1.2.1.cmml" xref="A3.p1.8.m8.1.1">superscript</csymbol><ci id="A3.p1.8.m8.1.1.2.2.cmml" xref="A3.p1.8.m8.1.1.2.2">ğ¹</ci><ci id="A3.p1.8.m8.1.1.2.3a.cmml" xref="A3.p1.8.m8.1.1.2.3"><mtext mathsize="70%" id="A3.p1.8.m8.1.1.2.3.cmml" xref="A3.p1.8.m8.1.1.2.3">kp</mtext></ci></apply><ci id="A3.p1.8.m8.1.1.3.cmml" xref="A3.p1.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.8.m8.1c">F^{\text{kp}}_{t}</annotation></semantics></math> has size <math id="A3.p1.9.m9.1" class="ltx_Math" alttext="16\times 16" display="inline"><semantics id="A3.p1.9.m9.1a"><mrow id="A3.p1.9.m9.1.1" xref="A3.p1.9.m9.1.1.cmml"><mn id="A3.p1.9.m9.1.1.2" xref="A3.p1.9.m9.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="A3.p1.9.m9.1.1.1" xref="A3.p1.9.m9.1.1.1.cmml">Ã—</mo><mn id="A3.p1.9.m9.1.1.3" xref="A3.p1.9.m9.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.9.m9.1b"><apply id="A3.p1.9.m9.1.1.cmml" xref="A3.p1.9.m9.1.1"><times id="A3.p1.9.m9.1.1.1.cmml" xref="A3.p1.9.m9.1.1.1"></times><cn type="integer" id="A3.p1.9.m9.1.1.2.cmml" xref="A3.p1.9.m9.1.1.2">16</cn><cn type="integer" id="A3.p1.9.m9.1.1.3.cmml" xref="A3.p1.9.m9.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.9.m9.1c">16\times 16</annotation></semantics></math> with <math id="A3.p1.10.m10.1" class="ltx_Math" alttext="256" display="inline"><semantics id="A3.p1.10.m10.1a"><mn id="A3.p1.10.m10.1.1" xref="A3.p1.10.m10.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="A3.p1.10.m10.1b"><cn type="integer" id="A3.p1.10.m10.1.1.cmml" xref="A3.p1.10.m10.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.10.m10.1c">256</annotation></semantics></math> channels. For the perceptual loss, we use a VGG-16 network pretrained on ImageNet to extract semantic informations. We do not use flip test during inference.</p>
</div>
</section>
</section>
</section>
</div>
</figure>
</section>
</section>
</section>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2107.02132" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2107.02133" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2107.02133">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2107.02133" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2107.02134" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 04:35:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
