<!DOCTYPE html><html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”</title>
<!--Generated on Mon Sep 30 06:13:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">




<base href="https://arxiv.org/html/2410.03727v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2410.03727v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2410.03727v1/#myForm">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2410.03727v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2410.03727v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S1" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S2" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S2.SS0.SSS0.Px1" title="In 2 Related Works ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Contextual LLM and retrieval-augmented generation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S2.SS0.SSS0.Px2" title="In 2 Related Works ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Hallucination and faithfulness evaluation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S2.SS0.SSS0.Px3" title="In 2 Related Works ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Adversarial context generation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>FaithEval Benchmark</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS1" title="In 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Task Overview</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS1.SSS0.Px1" title="In 3.1 Task Overview ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Source datasets.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS2" title="In 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Task Construction and Validation Framework</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS2.SSS0.Px1" title="In 3.2 Task Construction and Validation Framework ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Task construction.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS2.SSS0.Px2" title="In 3.2 Task Construction and Validation Framework ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Auto validation and human annotation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS3" title="In 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Main Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.SS1" title="In 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Unanswerable Context</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.SS1.SSS0.Px1" title="In 4.1 Unanswerable Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Abstaining is challenging, even when explicitly instructed.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.SS2" title="In 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Inconsistent Context</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.SS2.SSS0.Px1" title="In 4.2 Inconsistent Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Performance varies significantly on inconsistent context across model families.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.SS3" title="In 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Counterfactual Context</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.SS3.SSS0.Px1" title="In 4.3 Counterfactual Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Faithfulness remains a limitation for contextual LLMs.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussions and Further Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.SS0.SSS0.Px1" title="In 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">A closer look at Unanswerable and Inconsistent Contexts.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.SS0.SSS0.Px2" title="In 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">A closer look at Inconsistent Context.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.SS0.SSS0.Px3" title="In 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Strict vs. non-strict matching.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.SS0.SSS0.Px4" title="In 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Sycophancy with task-specific instructions.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.SS0.SSS0.Px5" title="In 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Does chain-of-thought prompting improve faithfulness?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S6" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Additional Experiment Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1.SS0.SSS0.Px1" title="In Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Context Generation Model.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1.SS0.SSS0.Px2" title="In Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Context Evaluation Model.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1.SS0.SSS0.Px3" title="In Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Valid phrases for non-strict matching.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1.SS0.SSS0.Px4" title="In Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title">Model sizes.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Prompt for Contextual QA Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Detailed Experiment Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A4" title="In FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Verification for Counterfactual Context</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: fontawesome</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">No License</a><div id="watermark-tr">arXiv:2410.03727v1 [cs.CL] 30 Sep 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yifei Ming<sup class="ltx_sup" id="id4.4.id1">1</sup>, Senthil Purushwalkam, Shrey Pandit, Zixuan Ke, Xuan-Phi Nguyen 
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id5.5.id2">Caiming Xiong</span>, <span class="ltx_text ltx_font_bold" id="id6.6.id3">Shafiq Joty</span>
<br class="ltx_break"><sup class="ltx_sup" id="id7.7.id4">1</sup>Salesforce AI Research   <sup class="ltx_sup" id="id8.8.id5">2</sup>University of Texas at Austin 
<br class="ltx_break">
</span><span class="ltx_author_notes">Correspondence: <span class="ltx_ERROR undefined" id="id9.9.id1">\faEnvelope</span>&nbsp;<span class="ltx_text ltx_font_typewriter" id="id10.10.id2">yifei.ming@salesforce.com</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id11.id1">Ensuring faithfulness to context in large language models (LLMs) and retrieval-augmented generation (RAG) systems is crucial for reliable deployment in real-world applications, as incorrect or unsupported information can erode user trust. Despite advancements on standard benchmarks, faithfulness hallucination—where models generate responses misaligned with the provided context—remains a significant challenge. In this work, we introduce FaithEval, a novel and comprehensive benchmark tailored to evaluate the faithfulness of LLMs in contextual scenarios across three diverse tasks: unanswerable, inconsistent, and counterfactual contexts. These tasks simulate real-world challenges where retrieval mechanisms may surface incomplete, contradictory, or fabricated information. FaithEval comprises 4.9K high-quality problems in total, validated through a rigorous four-stage context construction and validation framework, employing both LLM-based auto-evaluation and human validation. Our extensive study across a wide range of open-source and proprietary models reveals that even state-of-the-art models often struggle to remain faithful to the given context, and that larger models do not necessarily exhibit improved faithfulness. Project is available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/SalesforceAIResearch/FaithEval" title="">https://github.com/SalesforceAIResearch/FaithEval</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The rapid development of large language models (LLMs) has significantly advanced natural language understanding and generation tasks, enabling systems to produce fluent and coherent responses across a variety of applications&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bubeck et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib6" title="">2023</a>; Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib69" title="">2024b</a>; Wu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib62" title="">2024</a>)</cite>. The capabilities of these models have been further enhanced by integrating external information from the Internet or knowledge sources using a popular approach of Retrieval-Augmented Generation (RAG)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib33" title="">2020</a>; Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib68" title="">2024a</a>)</cite>. In this paradigm, generated outputs are enhanced by retrieving and encoding relevant information as context to the model. While RAG facilitates the integration of additional knowledge, hallucination—where models generate unsupported or ungrounded content—remains a critical challenge&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Nguyen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib46" title="">2024</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="331" id="S1.F1.g1" src="https://arxiv.org/html/2410.03727v1/x1.png" width="457">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Performance summary on FaithEval Benchmark. Each bar shows the combined accuracy (normalized) for the best model from each organization across three tasks: Counterfactual, Inconsistent, and Unanswerable (Sec&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS1" title="3.1 Task Overview ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3.1</span></a>). Different colors in each bar represent the accuracy for each task.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Hallucination in LLMs can be generally categorized into two types: <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">factual hallucination</em>, where generated content deviates from established world knowledge, and <em class="ltx_emph ltx_font_italic" id="S1.p2.1.2">faithfulness hallucination</em>, where the generated response is inconsistent with the provided context&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib18" title="">2023a</a>)</cite>. While factuality has received extensive attention, with numerous benchmarks designed to evaluate correctness against common sense or world knowledge&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lee et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib32" title="">2022</a>; Min et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib45" title="">2023</a>; Chern et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib10" title="">2023</a>; Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib61" title="">2024</a>)</cite>, a fine-grained
and holistic evaluation of faithfulness on noisy contexts remains underexplored, particularly when the context contradicts commonly accepted facts. Maintaining faithfulness to the context is especially important for various personalized applications and can be critical in high-stakes domains such as healthcare, finance and law, where inaccurate or ungrounded responses can erode user trust and lead to severe consequences&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bommarito &amp; Katz, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib4" title="">2022</a>; Pal et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib47" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">One of the key challenges in addressing faithfulness hallucination in RAG stems from the retrieval process, where the wealth of documents on the Internet varies in credibility.
This complexity is further compounded when long retrieved content includes multiple relevant paragraphs that omit key details, present conflicting evidence, or propagate counterfactual claims. Existing hallucination evaluation benchmarks fall short in providing fine-grained assessments of how well models align their responses with the context. They often do not disentangle factuality from faithfulness&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib37" title="">2024b</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib9" title="">2024b</a>)</cite> or capture the full range of contextual nuances&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib39" title="">2022</a>; Yin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib66" title="">2023</a>)</cite>. Moreover, current hallucination detection solutions focus on identifying hallucinations in model outputs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib40" title="">2021</a>; Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib36" title="">2023b</a>; Hu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib17" title="">2024</a>)</cite>, which is orthogonal to the task of understanding the impact of contexts on faithfulness hallucination.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we introduce FaithEval, a comprehensive benchmark specifically designed to evaluate the contextual faithfulness of LLMs across <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">three</em> diverse tasks: unanswerable, inconsistent, and counterfactual contexts. These tasks simulate real-world challenges where retrieval mechanisms may surface incomplete, contradictory, or fabricated information (Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.F2" title="Figure 2 ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">2</span></a>). FaithEval includes a total of 4.9K high-quality samples, constructed using a rigorous four-stage framework with multi-turn LLM-based context verification and human validation. We conduct a holistic evaluation on 18 representative proprietary and open-sourced models, revealing that faithfulness remains challenging, even for the most competitive LLMs, despite their strong performance on standard benchmarks. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the performance of representative models from each organization, with each bar representing performance on the individual tasks. To our knowledge, FaithEval is the <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">first fine-grained and comprehensive benchmark</em> specifically targeting contextual faithfulness hallucination, contributing to the broader effort toward developing reliable next-generation foundation models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Our key contributions are summarized as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We introduce FaithEval, a novel and comprehensive benchmark dedicated to evaluating contextual faithfulness in LLMs across three diverse tasks: unanswerable, inconsistent, and counterfactual contexts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We develop a scalable four-stage framework for context construction and validation, which incorporates multi-turn LLM-based validation and human annotation to ensure high-quality contextual QA pairs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We perform an extensive and in-depth study on a wide range of competitive open-source and proprietary models. We highlight that faithfulness remains a significant challenge for recent LLMs and that allegedly larger models, such as GPT-4o and Llama-3-70B-Instruct, do not necessarily lead to improved faithfulness.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Contextual LLM and retrieval-augmented generation.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">As the demand for contextual LLMs continues to grow, retrieval-augmented generation (RAG) systems offer a promising solution by integrating external knowledge retrieval with LLMs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib33" title="">2020</a>; Sarto et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib52" title="">2022</a>; Ramos et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib51" title="">2022</a>; Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib19" title="">2023b</a>; Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib68" title="">2024a</a>)</cite>.
In RAG, model responses are grounded using knowledge sourced from private or open-access data repositories. A typical RAG system operates through a close interaction between the retriever and a generator. The retriever&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Meng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib44" title="">2024</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib8" title="">2024a</a>; Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib34" title="">2023a</a>)</cite> identifies relevant documents from the source, and this retrieved information is supplied to the generator (<em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.1.1">e.g.,</em> a language model) to produce grounded outputs&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib33" title="">2020</a>; Borgeaud et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib5" title="">2021</a>; Izacard &amp; Grave, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib21" title="">2020</a>; Ke et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib25" title="">2024</a>)</cite>. Recent works develop more sophisticate RAG frameworks to improve answer reliability&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Asai et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib2" title="">2023</a>; Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib38" title="">2024c</a>; Xu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib64" title="">2024</a>)</cite>. The increased context sizes in LLMs have improved their ability to handle longer text sequences, allowing them to handle complex tasks requiring extensive background knowledge&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib16" title="">2023</a>; Song et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib55" title="">2024</a>)</cite>. These improvements are particularly beneficial for long-form question answering&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Joshi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib24" title="">2017</a>; Kwiatkowski et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib29" title="">2019b</a>; Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib35" title="">2024a</a>)</cite>. However, the variation in source quality can exacerbate challenges to maintaining faithfulness in LLMs, especially in longer contexts retrieved from the Internet.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Hallucination and faithfulness evaluation.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Hallucination in LLMs refers to the generation of ungrounded content, either from the provided context or established world knowledge. The former is typically described as factuality hallucination, while the latter is known as faithfulness hallucination, which highlights the discrepancy between the model’s output and the context&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib18" title="">2023a</a>)</cite>. While there is rich literature on factuality evaluation and benchmarks with and without contexts&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lee et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib32" title="">2022</a>; Min et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib45" title="">2023</a>; Chern et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib10" title="">2023</a>; Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib61" title="">2024</a>)</cite>, faithfulness has mostly been explored for summarization&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Laban et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib30" title="">2023</a>; Jia et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib22" title="">2023</a>)</cite> and natural language explanations&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Atanasova et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib3" title="">2023</a>; Siegel et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib54" title="">2024</a>)</cite>. Another line of research focuses on hallucination detection&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib40" title="">2021</a>; Li et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib36" title="">2023b</a>; Hu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib17" title="">2024</a>)</cite>, which aims to detect hallucinated outputs. The task focuses on the model output instead of the context (input). Additional efforts have been made to create QA benchmarks based on common misconceptions&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib39" title="">2022</a>)</cite> or questions that are unanswerable by nature&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib66" title="">2023</a>)</cite>. However, none of these datasets are contextual. In contrast, each question in FaithEval is accompanied by a multi-paragraph context, mimicking RAG scenarios with long and noisy contexts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Adversarial context generation.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Generating challenging or adversarial contexts for language models has been explored in various scenarios. One line of research focuses on context modification. <cite class="ltx_cite ltx_citemacro_citet">Shi et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib53" title="">2023</a>)</cite> propose a template-based framework that adds irrelevant facts to the context and studies the effectiveness of different prompting techniques. <cite class="ltx_cite ltx_citemacro_citet">Yu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib67" title="">2024</a>)</cite> leverage LLMs to perturb original evidence, potentially altering the answers, while <cite class="ltx_cite ltx_citemacro_citet">Manakul et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib43" title="">2023</a>)</cite> utilize LLMs to generate purely synthetic contexts that support given statements. To study the impact of knowledge conflicts, <cite class="ltx_cite ltx_citemacro_citet">Xie et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib63" title="">2024</a>)</cite> use LLMs to create adversarial contexts that conflict with the models’ internal knowledge, improving coherence compared to previous word-level editing methods <cite class="ltx_cite ltx_citemacro_citep">(Longpre et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib42" title="">2021</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib7" title="">2022</a>)</cite>. Another research direction involves modifying the question. <cite class="ltx_cite ltx_citemacro_citet">Ramakrishna et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib50" title="">2023</a>)</cite> generate invalid (unanswerable) questions, while <cite class="ltx_cite ltx_citemacro_citet">Huang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib20" title="">2024</a>)</cite> build a small-scale dataset with 209 questions containing adversarial facts or incorrect information based on diverse templates. In contrast, we introduce the first fine-grained, larger-scale (4.9K) high-quality contextual QA benchmark featuring multi-paragraph coherent contexts across three diverse tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>FaithEval Benchmark</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="332" id="S3.F2.g1" src="https://arxiv.org/html/2410.03727v1/x2.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Demonstration of each task in FaithEval. Left: in Unanswerable Context, the context does not contain the answer to the question. Middle: in Inconsistent Context, multiple answers are supported by different documents. Right: in Counterfactual Context, the context contains counterfactual statements that contradict common sense or world knowledge. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Task Overview</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">To systematically evaluate the contextual faithfulness of LLMs, FaithEval contains three diverse tasks including unanswerable context, inconsistent context, and counterfactual context. Each sample <math alttext="(\mathbf{c},q,a)" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.3"><semantics id="S3.SS1.p1.1.m1.3a"><mrow id="S3.SS1.p1.1.m1.3.4.2" xref="S3.SS1.p1.1.m1.3.4.1.cmml"><mo id="S3.SS1.p1.1.m1.3.4.2.1" stretchy="false" xref="S3.SS1.p1.1.m1.3.4.1.cmml">(</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">𝐜</mi><mo id="S3.SS1.p1.1.m1.3.4.2.2" xref="S3.SS1.p1.1.m1.3.4.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml">q</mi><mo id="S3.SS1.p1.1.m1.3.4.2.3" xref="S3.SS1.p1.1.m1.3.4.1.cmml">,</mo><mi id="S3.SS1.p1.1.m1.3.3" xref="S3.SS1.p1.1.m1.3.3.cmml">a</mi><mo id="S3.SS1.p1.1.m1.3.4.2.4" stretchy="false" xref="S3.SS1.p1.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.3b"><vector id="S3.SS1.p1.1.m1.3.4.1.cmml" xref="S3.SS1.p1.1.m1.3.4.2"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐜</ci><ci id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2">𝑞</ci><ci id="S3.SS1.p1.1.m1.3.3.cmml" xref="S3.SS1.p1.1.m1.3.3">𝑎</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.3c">(\mathbf{c},q,a)</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.3d">( bold_c , italic_q , italic_a )</annotation></semantics></math> consists of a question <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_q</annotation></semantics></math>, and a long context passage made up of one or more documents <math alttext="\mathbf{c}=(d_{1},...,d_{n})" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.3"><semantics id="S3.SS1.p1.3.m3.3a"><mrow id="S3.SS1.p1.3.m3.3.3" xref="S3.SS1.p1.3.m3.3.3.cmml"><mi id="S3.SS1.p1.3.m3.3.3.4" xref="S3.SS1.p1.3.m3.3.3.4.cmml">𝐜</mi><mo id="S3.SS1.p1.3.m3.3.3.3" xref="S3.SS1.p1.3.m3.3.3.3.cmml">=</mo><mrow id="S3.SS1.p1.3.m3.3.3.2.2" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml"><mo id="S3.SS1.p1.3.m3.3.3.2.2.3" stretchy="false" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">(</mo><msub id="S3.SS1.p1.3.m3.2.2.1.1.1" xref="S3.SS1.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.3.m3.2.2.1.1.1.2" xref="S3.SS1.p1.3.m3.2.2.1.1.1.2.cmml">d</mi><mn id="S3.SS1.p1.3.m3.2.2.1.1.1.3" xref="S3.SS1.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.3.m3.3.3.2.2.4" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">,</mo><mi id="S3.SS1.p1.3.m3.1.1" mathvariant="normal" xref="S3.SS1.p1.3.m3.1.1.cmml">…</mi><mo id="S3.SS1.p1.3.m3.3.3.2.2.5" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p1.3.m3.3.3.2.2.2" xref="S3.SS1.p1.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS1.p1.3.m3.3.3.2.2.2.2" xref="S3.SS1.p1.3.m3.3.3.2.2.2.2.cmml">d</mi><mi id="S3.SS1.p1.3.m3.3.3.2.2.2.3" xref="S3.SS1.p1.3.m3.3.3.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS1.p1.3.m3.3.3.2.2.6" stretchy="false" xref="S3.SS1.p1.3.m3.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.3b"><apply id="S3.SS1.p1.3.m3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3"><eq id="S3.SS1.p1.3.m3.3.3.3.cmml" xref="S3.SS1.p1.3.m3.3.3.3"></eq><ci id="S3.SS1.p1.3.m3.3.3.4.cmml" xref="S3.SS1.p1.3.m3.3.3.4">𝐜</ci><vector id="S3.SS1.p1.3.m3.3.3.2.3.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2"><apply id="S3.SS1.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.3.m3.2.2.1.1.1.2">𝑑</ci><cn id="S3.SS1.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">…</ci><apply id="S3.SS1.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2.2">𝑑</ci><ci id="S3.SS1.p1.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.3.3.2.2.2.3">𝑛</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.3c">\mathbf{c}=(d_{1},...,d_{n})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.3d">bold_c = ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math>, and a groundtruth answer <math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_a</annotation></semantics></math>. The model is expected to answer the question leveraging the information in the provided context. An overview of each task is presented in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.F2" title="Figure 2 ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">2</span></a>. Next, we illustrate the construction of each task in detail.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Unanswerable Context.</span> An unanswerable context arises when the context includes relevant details but lacks the information needed to answer the question. In FaithEval, answerability is determined <em class="ltx_emph ltx_font_italic" id="S3.SS1.p2.1.2">solely</em> by the context, regardless of whether the question itself is unanswerable.
For instance, in the example in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.F2" title="Figure 2 ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">2</span></a> (Left), the context provides the proportion of both types of commuters in 2015. However, the question “Which group of commuters in Dallas in 2009 is larger: carpooling or transit?” is unanswerable, as the context lacks specific data from 2009.
To create such task, we modify the context from a collection of 10 contextual QA datasets, covering a wide range of domains (see Source datasets below). For each sample, we prompt an LLM to modify the original context so that it no longer contains the supporting evidence for the ground truth answer. Additional sentences may be woven into the new context to maintain coherence.
The full prompt is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2.F12" title="Figure 12 ‣ Appendix B Prompt for Contextual QA Generation ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">12</span></a>. This process resulted in a total of 2.4k contextual QA pairs for the Unanswerable Context task. To verify the quality of the modified contexts, we achieved over 98% agreement with professional human annotators (Sec&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS2" title="3.2 Task Construction and Validation Framework ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Inconsistent Context.</span> An inconsistent context involves multiple documents, each providing a different answer to the same question. This simulates noisy retrieval scenarios,
where documents from sources with varying levels of credibility are retrieved. For instance, as shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.F2" title="Figure 2 ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">2</span></a> (Middle), the context presents conflicting information about the tiger’s name in the novel <em class="ltx_emph ltx_font_italic" id="S3.SS1.p3.1.2">Life of Pi</em>. A faithful model should be able to identify such inconsistencies, especially when instructed to do so. To create this task, we modify contexts from the same collection of contextual QA datasets used in the Unanswerable Context task. For each sample, the LLM is provided with a context passage, a question, and an original answer, which is supported by the context. The goal is to modify the context so that it introduces fabricated supporting evidence for a new, conflicting answer.
The detailed prompt is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2.F13" title="Figure 13 ‣ Appendix B Prompt for Contextual QA Generation ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">13</span></a>. Since this task is more challenging, we curated a collection of 1.5k high-quality contextual QA pairs after filtering through professional human annotators.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Counterfactual Context.</span> A counterfactual context contains statements that contradict with common sense or widely accepted facts, such as “water freeze at 100 degrees Celsius” or “carbon dioxide is the most abundant greenhouse gas in the lower atmosphere”.
Unlike the other two tasks, the questions in this task are required to be relevant to such well-known facts. We curate this task based on ARC-Challenge&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Clark et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib11" title="">2018</a>)</cite>, a QA dataset covering grade-school level, multiple-choice science questions. Since the original dataset does not include context, we prompt an LLM to generate a long, multi-paragraph context that seamlessly provides fabricated supporting evidence for a counterfactual answer.
The detailed prompt is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2.F14" title="Figure 14 ‣ Appendix B Prompt for Contextual QA Generation ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">14</span></a>. This process resulted in a total of 1k contextual QA pairs, each with three to five options. Due to the multiple-choice nature, we can use keyword matching to verify the quality of the synthetic contexts (Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A4" title="Appendix D Verification for Counterfactual Context ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">D</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="218" id="S3.F3.g1" src="https://arxiv.org/html/2410.03727v1/x3.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of task construction and validation framework. Our framework contains four stages: (1) Context Generation: given a source QA dataset, we prompt an LLM to generate a new context based on a question, the original answer, and optionally the original context. (2) Task Construction: we construct the prompt for each sample by combining the original question, the new context, and task-specific instructions. (3) Auto Eval by LLM Judge: we validate the quality of the new context by checking if and only-if the new answer is supported by the new context. (4) Human Annotation: we further filter out invalid contextual QA pairs based on the majority vote results from professional annotators.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Source datasets.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">We curate new contexts based on a diverse collection of contextual QA datasets, including SQuAD&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Rajpurkar et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib49" title="">2016</a>)</cite>, NewsQA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Trischler et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib57" title="">2017</a>)</cite>, TriviaQA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Joshi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib24" title="">2017</a>)</cite>, NaturalQuestions&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib28" title="">2019a</a>)</cite>, SearchQA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dunn et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib14" title="">2017</a>)</cite>, HotpotQA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Yang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib65" title="">2018</a>)</cite>, BioASQ&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tsatsaronis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib58" title="">2015</a>)</cite>, DROP&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Dua et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib13" title="">2019</a>)</cite>, RACE&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lai et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib31" title="">2017</a>)</cite>, TextbookQA&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Kembhavi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib26" title="">2017</a>)</cite>. We adopt the test splits from &nbsp;<cite class="ltx_cite ltx_citemacro_cite">Fisch et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib15" title="">2019</a>)</cite>. Due to variations in human annotations, the final collection consists of 150 samples per dataset for the Inconsistent Context task and around 240 samples per dataset for the Unanswerable Context task.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Task Construction and Validation Framework</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Task construction.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">An overview of our task construction and validation framework is shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.F3" title="Figure 3 ‣ 3.1 Task Overview ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3</span></a>. Given a source QA sample and an original context (optional), we prompt an LLM to generate both a new context and a new answer for the Counterfactual and Inconsistent tasks, or only a new context (that supports no answer) for the Unanswerable task. To make the tasks challenging, the new context should be coherent and contain minimal modifications if the original context is provided. In addition, multiple paragraphs not directly related to the answer are included, serving as distractors. The new context is generated with detailed justifications explaining how it satisfies the task criterion. We construct the prompt for each sample by combining the original question, the new context, and task-specific instructions (Sec&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS3" title="3.3 Evaluation ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3.3</span></a>). In particular, an inconsistent context is created by concatenating the new context with the original context.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Auto validation and human annotation.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">We validate the quality of the new context by using a separate LLM judge to verify whether the new answer is valid given the context ("if" condition) and whether the context does not support alternative answers ("only-if" condition). For example, the new context in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.F2" title="Figure 2 ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">2</span></a> (Right) should not mention <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS0.Px2.p1.1.1">wood is buoyant</span>. Samples that fail to meet both conditions are filtered out. Next, we perform meticulous human annotation. Depending on the task’s validation difficulty, we employ different strategies. As the Inconsistent Context task is challenging to validate, we rely on full human annotation. Three Mechanical Turk&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Crowston, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib12" title="">2012</a>)</cite> workers judge whether each contextual QA pair meets the "if" and "only-if" conditions, with final inclusion determined by majority agreement. This yields 1.5K samples. For the Unanswerable Context task, which is easier to validate, we use a similar majority-vote approach, achieving over 98% agreement among human annotators. This yields 2.4K samples. For the Counterfactual Context task, since the answer options are provided within the context, we validate using a string-based matching method, where the context passes if all words from the answer appear in the context. This results in 1K samples. After filtering, the FaithEval benchmark contains a total of 4.9K high-quality contextual QA pairs. More details are included in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1" title="Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">A</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">Models.</span> We evaluate a wide range of competitive open-sourced and proprietary language models with different scales, including the most recent releases up to Sep 10, 2024.
Our initial experiments suggest that instruction-tuned (chat) models significantly outperform base models. Therefore, we consider 18 competitive chat models, including Phi-3-mini-128k-instruct (3.8B), Phi-3-medium-128k-instruct (14B), Phi-3.5-mini-instruct (3.8B)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Abdin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib1" title="">2024</a>)</cite>, LLaMA-3-8B-Instruct, LLaMA-3.1-8B-Instruct, LLaMA-3-70B-Instruct, LLaMA-3.1-70B-Instruct&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Llama, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib41" title="">2024</a>)</cite>, Mistral-7B-Instruct-v0.3, Mistral-Nemo-Instruct-2407 (12B)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib23" title="">2023</a>)</cite>, Gemma-2-9B-it, and Gemma-2-27B-it&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib56" title="">2024</a>)</cite>. For proprietary models, we consider Open AI’s GPT-3.5 Turbo, GPT-4o-mini, GPT-4o, GPT-4 Turbo, Cohere’s Command R (35B), Command R+ (104B), and Anthropic’s Claude 3.5 Sonnet.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Default Evaluation Scheme</span>. For all tasks, we append the following prompt to each question: <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.2">You are an expert in retrieval-based question answering. Please respond with the exact answer, using only the information provided in the context</span>. For the Unanswerable Context task, we append an additional instruction: <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.3">If there is no information available from the context, the answer should be “unknown”</span>. Similarly, for the Inconsistent Context task, the instruction is: <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.4">If there is conflicting information or multiple answers in the context, the answer should be “conflict”</span>. Our primary evaluation metric across all tasks is accuracy (ACC), where a model’s response is considered correct if it mentions the ground truth answer. All models are evaluated using their default configurations with deterministic decoding (temperature = 0). We report both strict-matching (S) ACC, which considers only a single ground truth answer (e.g., “unknown”), and non-strict matching (N) ACC, which allows a broader range of semantically similar phrases. A detailed list of valid phrases is provided in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1" title="Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">A</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Alternative Evaluation Schemes</span>. We study alternative evaluation strategies in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5" title="5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">5</span></a>. Specifically, we examine non-deterministic decoding with temperature scaling (t = 0.3, top-<math alttext="p" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">italic_p</annotation></semantics></math> = 0.9). Additionally, we investigate the impact of chain-of-thought (CoT) prompting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib59" title="">2022</a>; Kojima et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib27" title="">2022</a>)</cite> using the following instruction: <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.1.2">Given the context, first provide a brief answer to the question. Then, explain your reasoning step by step, detailing how you arrived at the answer</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Main Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Unanswerable Context</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="214" id="S4.F4.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/original_vs_remove_performance.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Model performance comparison on the Unanswerable Context task, where no evidence supports the answer. Columns are sorted by performance on the original context. Proprietary model names are highlighted in orange.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Abstaining is challenging, even when explicitly instructed.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">The results of the Unanswerable Context task are summarized in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.F4" title="Figure 4 ‣ 4.1 Unanswerable Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">4</span></a>, ranked by performance on the original context. Proprietary model names are highlighted in orange.
We highlight the following key observations: (1) Modern LLMs experience significant performance degradation in this task. Across all chat models, the performance gap ranges from 13.6% to 68.4%. (2) High performance on the original context does not correlate with high performance on the unanswerable context. For example, while Phi-3-medium-128k-instruct achieves 76.8% accuracy on the original context, closely approaching the SoTA (80.1%), it struggles to abstain from answering in the unanswerable context, with an accuracy of only 7.4%. (3) Larger model sizes are more advantageous within the same model family. For instance, compared to the 7B model, Llama-3.1-70B-instruct improves performance on the Unanswerable Context task by 10.3%. Similar trends hold for the Gemma-2 and Llama-3 model families.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Inconsistent Context</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Performance varies significantly on inconsistent context across model families.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">The model performance on the Inconsistent Context task is summarized in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.F5" title="Figure 5 ‣ Performance varies significantly on inconsistent context across model families. ‣ 4.2 Inconsistent Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">5</span></a>. We have the following key observations: (1) Performance varies substantially across different model families. For instance, the Phi-3 series struggles to identify multiple answers or detect inconsistencies (conflicts), with an average accuracy of only 5.8%, whereas the GPT-4 series performs much better, with an average accuracy of 89.35%. (2) Open-source models lag behind proprietary models. Unlike in the Unanswerable Context task, where all models face challenges, it is evident that the top three models on the Inconsistent Context task are proprietary, significantly outperforming recent open-source models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="214" id="S4.F5.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/model_performance_ic.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Model performance comparison on the Inconsistent Context task. Columns are sorted by the performance on the original context. Proprietary models are colored in orange.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="S4.F6.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/model_performance_cc.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Model performance comparison on Counterfactual Context, which contains evidence supporting a counterfactual answer. Proprietary models are colored in orange.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Counterfactual Context</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Faithfulness remains a limitation for contextual LLMs.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">The results on the Counterfactual Context task are shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.F6" title="Figure 6 ‣ Performance varies significantly on inconsistent context across model families. ‣ 4.2 Inconsistent Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">6</span></a>. The blue bars represent model performance under the closed-book QA setting, where no context is provided. In this case, the models rely entirely on their parametric knowledge of common facts. We observe that nearly half of the models achieve over 90% accuracy, with GPT-4o nearing perfect performance at 96.3%. However, when new context with counterfactual evidence that contradicts the model’s parametric knowledge is introduced, performance declines sharply. For example, GPT-4o achieves only 47.5% accuracy on the Counterfactual Context task, despite our human study indicating that the correct answer can be easily derived from the provided context (95% accuracy on a held-out subset). This highlights a significant gap in faithfulness—the ability to generate outputs that align with the provided context—between current state-of-the-art models and human-level performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussions and Further Analysis</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="S5.F7.1.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/individual/Llama-3.1-8B-Instruct_results_no_text.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="S5.F7.2.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/individual/Mistral-7B-Instruct-v0.3_results_no_text.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="S5.F7.3.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/individual/gemma-2-9b-it_results_no_text.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="S5.F7.4.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/individual/Llama-3.1-8B-Instruct_results_c_no_text.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="S5.F7.5.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/individual/Mistral-7B-Instruct-v0.3_results_c_no_text.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F7.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="S5.F7.6.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/individual/gemma-2-9b-it_results_c_no_text.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Performance decomposition on individual datasets for Unanswerable Context (top row) and Inconsistent Context (bottom row). Full results for all models can be seen in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3" title="Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">C</span></a>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">A closer look at Unanswerable and Inconsistent Contexts.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">We present the performance breakdown for each of the ten individual datasets in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.F7" title="Figure 7 ‣ 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">7</span></a> for the Unanswerable (top row) and Inconsistent Context (bottom row) tasks. We include three representative smaller-scale models: LLama-3.1-8B-Instruct, Mistral-7B-Instruct-v0.3, and Gemma-2-9b-it. Full results for other models are provided in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3" title="Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">C</span></a>. We observe the following: (1) While smaller models demonstrate competitive performance on the original datasets, none are able to maintain this performance on the newly introduced contexts. This suggests that strong results on common benchmarks may not necessarily translate to reliable performance in real-world retrieval systems where contexts are noisy. (2) Although performance across individual datasets varies by model family, SearchQA and TextbookQA consistently pose greater challenges compared to the other datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">A closer look at Inconsistent Context.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">Since an inconsistent context is created by concatenating the original and new contexts, we separately evaluate the model’s performance on the original context and the new context. The results, shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.F8" title="Figure 8 ‣ A closer look at Inconsistent Context. ‣ 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">8</span></a>, reveal that while models struggle when both context passages are presented together (Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4.F5" title="Figure 5 ‣ Performance varies significantly on inconsistent context across model families. ‣ 4.2 Inconsistent Context ‣ 4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">5</span></a>), most models do not find the new context more challenging than the original when it is presented alone. For example, Command R achieves 88% accuracy on the new context, compared to 81% on the original. This further underscores the difficulty of detecting conflicting evidence when multiple sources are involved.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="S5.F8.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/original_vs_new.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Model performance comparison on the Original Context v.s. New Context for Inconsistent Context task. Proprietary models are colored in orange.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="190" id="S5.F9.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/strict_vs_non_strict.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Impact of strict vs. non-strict matching on Unanswerable Context. Non-strict matching allows for a wider range of phrases that express the idea of “unknown”. The comparison on Inconsistent Context is shown in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3" title="Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">C</span></a>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Strict vs. non-strict matching.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1">In the Unanswerable and Inconsistent Context tasks, no explicit options are provided in the prompt. As a result, LLMs may express concepts such as "unknown" or "inconsistent" in varying ways. To assess the impact of allowing alternative valid expressions, we compare the performance of strict and non-strict matching. Strict matching only accepts the exact phrases "unknown" or "conflict" as specified in the prompt, while non-strict matching permits a broader range of expressions that convey similar ideas (see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1" title="Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">A</span></a> for the full list of valid expressions). We observe that performance remains stable across most models. For instance, Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.F9" title="Figure 9 ‣ A closer look at Inconsistent Context. ‣ 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">9</span></a> summarizes the results for Unanswerable Context. For competitive models such as gpt-4o and Claude 3.5, the gaps are less than 1%. Full results can be found in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3.T3" title="Table 3 ‣ Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3</span></a> and Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3.T4" title="Table 4 ‣ Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">4</span></a> in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3" title="Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">C</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.18" style="width:377.6pt;height:74.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-130.6pt,25.8pt) scale(0.591194121001708,0.591194121001708) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T1.18.18">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.18.18.19.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.1"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.1.1">Task-spec. Inst.</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.2.1">BioASQ</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.3"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.3.1">DROP</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.4"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.4.1">HotpotQA</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.5"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.5.1">NQ</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.6"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.6.1">NewsQA</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.7"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.7.1">RACE</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.8"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.8.1">SQuAD</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.9"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.9.1">SearchQA</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.10"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.10.1">TextbookQA</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.11"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.11.1">TriviaQA</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T1.18.18.19.1.12"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.19.1.12.1">AVG</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.18.18.20.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="12" id="S5.T1.18.18.20.2.1"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.20.2.1.1">Claude 3.5 Sonnet</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.18.18.21.3">
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.1">✗ (original prompt)</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.2">0.90</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.3">0.94</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.4">0.89</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.5">0.86</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.6">0.81</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.7">0.84</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.8">0.93</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.9">0.97</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.10">0.97</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.11">0.86</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.21.3.12">0.90</td>
</tr>
<tr class="ltx_tr" id="S5.T1.9.9.9">
<td class="ltx_td ltx_align_left" id="S5.T1.9.9.9.10">✓ (+conflict prompt)</td>
<td class="ltx_td ltx_align_left" id="S5.T1.1.1.1.1">0.85 <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.1.1.1.1.m1.1"><semantics id="S5.T1.1.1.1.1.m1.1a"><mo id="S5.T1.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.1.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.2.2.2.2">0.84<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.2.2.2.2.m1.1"><semantics id="S5.T1.2.2.2.2.m1.1a"><mo id="S5.T1.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T1.2.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.2.m1.1b"><ci id="S5.T1.2.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.2.2.2.2.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.3.3.3.3">0.86<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.3.3.3.3.m1.1"><semantics id="S5.T1.3.3.3.3.m1.1a"><mo id="S5.T1.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T1.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.3.m1.1b"><ci id="S5.T1.3.3.3.3.m1.1.1.cmml" xref="S5.T1.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.4.4.4.4">0.78<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.4.4.4.4.m1.1"><semantics id="S5.T1.4.4.4.4.m1.1a"><mo id="S5.T1.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T1.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.4.m1.1b"><ci id="S5.T1.4.4.4.4.m1.1.1.cmml" xref="S5.T1.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.5.5.5.5">0.75 <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.5.5.5.5.m1.1"><semantics id="S5.T1.5.5.5.5.m1.1a"><mo id="S5.T1.5.5.5.5.m1.1.1" stretchy="false" xref="S5.T1.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.5.m1.1b"><ci id="S5.T1.5.5.5.5.m1.1.1.cmml" xref="S5.T1.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.6.6.6.6">0.77<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.6.6.6.6.m1.1"><semantics id="S5.T1.6.6.6.6.m1.1a"><mo id="S5.T1.6.6.6.6.m1.1.1" stretchy="false" xref="S5.T1.6.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.6.m1.1b"><ci id="S5.T1.6.6.6.6.m1.1.1.cmml" xref="S5.T1.6.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.6.6.6.6.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.9.9.9.11">0.95</td>
<td class="ltx_td ltx_align_left" id="S5.T1.7.7.7.7">0.91<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.7.7.7.7.m1.1"><semantics id="S5.T1.7.7.7.7.m1.1a"><mo id="S5.T1.7.7.7.7.m1.1.1" stretchy="false" xref="S5.T1.7.7.7.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.7.7.m1.1b"><ci id="S5.T1.7.7.7.7.m1.1.1.cmml" xref="S5.T1.7.7.7.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.7.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.7.7.7.7.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.8.8.8.8">0.90<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.8.8.8.8.m1.1"><semantics id="S5.T1.8.8.8.8.m1.1a"><mo id="S5.T1.8.8.8.8.m1.1.1" stretchy="false" xref="S5.T1.8.8.8.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.8.8.m1.1b"><ci id="S5.T1.8.8.8.8.m1.1.1.cmml" xref="S5.T1.8.8.8.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.8.8.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.8.8.8.8.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left" id="S5.T1.9.9.9.12">0.86</td>
<td class="ltx_td ltx_align_left" id="S5.T1.9.9.9.9">0.85<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.9.9.9.9.m1.1"><semantics id="S5.T1.9.9.9.9.m1.1a"><mo id="S5.T1.9.9.9.9.m1.1.1" stretchy="false" xref="S5.T1.9.9.9.9.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.9.9.9.9.m1.1b"><ci id="S5.T1.9.9.9.9.m1.1.1.cmml" xref="S5.T1.9.9.9.9.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.9.9.9.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.9.9.9.9.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T1.18.18.22.4">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="12" id="S5.T1.18.18.22.4.1"><span class="ltx_text ltx_font_bold" id="S5.T1.18.18.22.4.1.1">GPT-4o</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.18.18.23.5">
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.1">✗ (original prompt)</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.2">0.84</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.3">0.81</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.4">0.89</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.5">0.80</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.6">0.78</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.7">0.79</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.8">0.95</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.9">0.90</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.10">0.93</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.11">0.87</td>
<td class="ltx_td ltx_align_left" id="S5.T1.18.18.23.5.12">0.85</td>
</tr>
<tr class="ltx_tr" id="S5.T1.18.18.18">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.18.18.18.10">✓ (+conflict prompt)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.10.10.10.1">0.77<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.10.10.10.1.m1.1"><semantics id="S5.T1.10.10.10.1.m1.1a"><mo id="S5.T1.10.10.10.1.m1.1.1" stretchy="false" xref="S5.T1.10.10.10.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.10.10.10.1.m1.1b"><ci id="S5.T1.10.10.10.1.m1.1.1.cmml" xref="S5.T1.10.10.10.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.10.10.10.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.10.10.10.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.18.18.18.11">0.83</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.11.11.11.2">0.85<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.11.11.11.2.m1.1"><semantics id="S5.T1.11.11.11.2.m1.1a"><mo id="S5.T1.11.11.11.2.m1.1.1" stretchy="false" xref="S5.T1.11.11.11.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.11.11.11.2.m1.1b"><ci id="S5.T1.11.11.11.2.m1.1.1.cmml" xref="S5.T1.11.11.11.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.11.11.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.11.11.11.2.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.12.12.12.3">0.79<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.12.12.12.3.m1.1"><semantics id="S5.T1.12.12.12.3.m1.1a"><mo id="S5.T1.12.12.12.3.m1.1.1" stretchy="false" xref="S5.T1.12.12.12.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.12.12.12.3.m1.1b"><ci id="S5.T1.12.12.12.3.m1.1.1.cmml" xref="S5.T1.12.12.12.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.12.12.12.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.12.12.12.3.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.13.13.13.4">0.73<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.13.13.13.4.m1.1"><semantics id="S5.T1.13.13.13.4.m1.1a"><mo id="S5.T1.13.13.13.4.m1.1.1" stretchy="false" xref="S5.T1.13.13.13.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.13.13.13.4.m1.1b"><ci id="S5.T1.13.13.13.4.m1.1.1.cmml" xref="S5.T1.13.13.13.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.13.13.13.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.13.13.13.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.18.18.18.12">0.81</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.14.14.14.5">0.93<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.14.14.14.5.m1.1"><semantics id="S5.T1.14.14.14.5.m1.1a"><mo id="S5.T1.14.14.14.5.m1.1.1" stretchy="false" xref="S5.T1.14.14.14.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.14.14.14.5.m1.1b"><ci id="S5.T1.14.14.14.5.m1.1.1.cmml" xref="S5.T1.14.14.14.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.14.14.14.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.14.14.14.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.15.15.15.6">0.87<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.15.15.15.6.m1.1"><semantics id="S5.T1.15.15.15.6.m1.1a"><mo id="S5.T1.15.15.15.6.m1.1.1" stretchy="false" xref="S5.T1.15.15.15.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.15.15.15.6.m1.1b"><ci id="S5.T1.15.15.15.6.m1.1.1.cmml" xref="S5.T1.15.15.15.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.15.15.15.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.15.15.15.6.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.16.16.16.7">0.91<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.16.16.16.7.m1.1"><semantics id="S5.T1.16.16.16.7.m1.1a"><mo id="S5.T1.16.16.16.7.m1.1.1" stretchy="false" xref="S5.T1.16.16.16.7.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.16.16.16.7.m1.1b"><ci id="S5.T1.16.16.16.7.m1.1.1.cmml" xref="S5.T1.16.16.16.7.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.16.16.16.7.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.16.16.16.7.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.17.17.17.8">0.86<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.17.17.17.8.m1.1"><semantics id="S5.T1.17.17.17.8.m1.1a"><mo id="S5.T1.17.17.17.8.m1.1.1" stretchy="false" xref="S5.T1.17.17.17.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.17.17.17.8.m1.1b"><ci id="S5.T1.17.17.17.8.m1.1.1.cmml" xref="S5.T1.17.17.17.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.17.17.17.8.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.17.17.17.8.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.18.18.18.9">0.83<math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T1.18.18.18.9.m1.1"><semantics id="S5.T1.18.18.18.9.m1.1a"><mo id="S5.T1.18.18.18.9.m1.1.1" stretchy="false" xref="S5.T1.18.18.18.9.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T1.18.18.18.9.m1.1b"><ci id="S5.T1.18.18.18.9.m1.1.1.cmml" xref="S5.T1.18.18.18.9.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.18.18.18.9.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.18.18.18.9.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Impact of task-specific instructions on the normal (original) context. Having the additional task instruction degrades the performance on normal contexts consistently.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Sycophancy with task-specific instructions.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px4.p1.1">While the additional instructions used in the Unanswerable and Inconsistent Context tasks (Sec&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS3" title="3.3 Evaluation ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3.3</span></a>) improve the model’s awareness of such scenarios, they can also introduce unintended effects when the context is normal (<em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.1">i.e.</em>, answerable and consistent). This can lead to what is known as sycophantic behavior&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Perez et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib48" title="">2023</a>; Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib60" title="">2023</a>)</cite>, where models adjust their responses to align with the user’s expectations, even when those expectations are objectively incorrect. We examine this phenomenon in two top-performing models for the Inconsistent Context task, GPT-4o and Claude 3.5 Sonnet. Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.T1" title="Table 1 ‣ Strict vs. non-strict matching. ‣ 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">1</span></a> shows the performance on normal contexts with the additional “conflict instruction”. We observe a consistent performance drop for both models, with Claude 3.5 experiencing a 5% decrease in average accuracy. This further highlights the challenge of maintaining faithfulness across both normal and noisy contexts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="435" id="S5.F10.sf1.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/cot_remove_performance.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Direct Ans vs. CoT on Unanswerable Context</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="435" id="S5.F10.sf2.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/cot_conflict_performance.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Direct Ans vs. CoT on Inconsistent Context</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>The impact of CoT prompting on Unanswerable (Left) and Inconsistent Contexts (Right). Due to space constraints., we include representative models from different model families.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Does chain-of-thought prompting improve faithfulness?</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px5.p1.1">Popular prompting techniques, such as CoT, have shown promising performance on various tasks that require multi-step reasoning. We adopt the prompt format in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S3.SS3" title="3.3 Evaluation ‣ 3 FaithEval Benchmark ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">3.3</span></a> and summarize the results in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.F10" title="Figure 10 ‣ Sycophancy with task-specific instructions. ‣ 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">10</span></a>. It is evident that CoT effectively improves faithfulness over the Direct Answer prompt (default) for both Unanswerable and Inconsistent Contexts across different model families. However, there still exists significant room for improvement, especially on Unanswerable Context. For instance, the leading model achieves only 71.8% Acc, suggesting that further advancements are needed for next-generation contextual LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="S5.F11.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/model_performance_temp.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>The impact of decoding strategy. The plot displays greedy (non-sampling) vs. sampling-based decoding (t=0.3, top-p=0.9) on Counterfactual Context. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S5.SS0.SSS0.Px5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS0.SSS0.Px5.p2.1.1">Impact of decoding strategies.</span> By default, we adopt greedy decoding. We also investigate a popular sampling-based decoding scheme with a temperature of 0.3 and top-p of 0.9. The results are shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S5.F11" title="Figure 11 ‣ Does chain-of-thought prompting improve faithfulness? ‣ 5 Discussions and Further Analysis ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">11</span></a> based on Counterfactual Context. Similar observations also hold for Unanswerable and Inconsistent Context. We can see that sampling-based decoding marginally improves the performance over greedy decoding across all models. However, the significant gap between the original and counterfactual contexts cannot be mitigated with temperature scaling.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this work, we propose FaithEval, a novel and challenging benchmark designed to assess the faithfulness of contextual LLMs. FaithEval comprises 4.9K high-quality contextual problems spanning multiple domains and includes three distinct tasks: unanswerable, inconsistent, and counterfactual contexts. To build this benchmark, we propose a scalable multi-stage context construction and validation framework, incorporating both automated evaluation by an LLM judge and human validation. This approach enables the creation of multi-paragraph coherent contexts satisfying diverse criteria. We provide a timely and in-depth study on a wide range of open-source and proprietary models, revealing that even the most competitive LLMs often struggle to remain faithful to the contexts, despite excelling on standard benchmarks. We hope our work will contribute to more holistic evaluations of contextual LLMs and inspire further advancements in developing faithful LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdin et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Marah Abdin et&nbsp;al.

</span>
<span class="ltx_bibblock">Phi-3 technical report: A highly capable language model locally on your phone, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-RAG: Learning to retrieve, generate, and critique through self-reflection.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2310.11511</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Atanasova et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pepa Atanasova, Oana-Maria Camburu, Christina Lioma, Thomas Lukasiewicz, Jakob&nbsp;Grue Simonsen, and Isabelle Augenstein.

</span>
<span class="ltx_bibblock">Faithfulness tests for natural language explanations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pp.&nbsp; 283–294, July 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bommarito &amp; Katz (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael&nbsp;J. Bommarito and Daniel&nbsp;M. Katz.

</span>
<span class="ltx_bibblock">Gpt takes the bar exam: What artificial intelligence and machine learning mean for the practice of law.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2212.14402</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van&nbsp;den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de&nbsp;Las&nbsp;Casas, Aurelia Guy, Jacob Menick, Roman Ring, T.&nbsp;W. Hennigan, Saffron Huang, Lorenzo Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack&nbsp;W. Rae, Erich Elsen, and L.&nbsp;Sifre.

</span>
<span class="ltx_bibblock">Improving language models by retrieving from trillions of tokens.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">International Conference on Machine Learning</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bubeck et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin&nbsp;Tat Lee, Yuanzhi Li, Scott Lundberg, et&nbsp;al.

</span>
<span class="ltx_bibblock">Sparks of artificial general intelligence: Early experiments with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2303.12712</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hung-Ting Chen, Michael&nbsp;JQ Zhang, and Eunsol Choi.

</span>
<span class="ltx_bibblock">Rich knowledge sources bring complex knowledge conflicts: Recalibrating models to reflect conflicting evidence.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianlv Chen, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu.

</span>
<span class="ltx_bibblock">Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Annual Meeting of the Association for Computational Linguistics</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiang Chen, Duanzheng Song, Honghao Gui, Chenxi Wang, Ningyu Zhang, Yong Jiang, Fei Huang, Chengfei Lyu, Dan Zhang, and Huajun Chen.

</span>
<span class="ltx_bibblock">Factchd: Benchmarking fact-conflicting hallucination detection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-24</em>, pp.&nbsp; 6216–6224, 8 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chern et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
I&nbsp;Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Factool: Factuality detection in generative ai–a tool augmented framework for multi-task and multi-domain scenarios.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2307.13528</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:1803.05457</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crowston (2012)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kevin Crowston.

</span>
<span class="ltx_bibblock">Amazon mechanical turk: A research tool for organizations and information systems scholars.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Shaping the Future of ICT Research</em>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner.

</span>
<span class="ltx_bibblock">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pp.&nbsp; 2368–2378, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dunn et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Matthew Dunn, Levent Sagun, Mickael Higgins, V&nbsp;Ugur Guney, Volkan Cirik, and Kyunghyun Cho.

</span>
<span class="ltx_bibblock">Searchqa: A new q&amp;a dataset augmented with context from a search engine.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:1704.05179</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fisch et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo, Eunsol Choi, and Danqi Chen.

</span>
<span class="ltx_bibblock">MRQA 2019 shared task: Evaluating generalization in reading comprehension.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 2nd Workshop on Machine Reading for Question Answering</em>, pp.&nbsp; 1–13, November 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yifei Gao, Lei Wang, Jun Fang, Longhua Hu, and Jun Cheng.

</span>
<span class="ltx_bibblock">Empower your model with longer and better context comprehension, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiangkun Hu, Dongyu Ru, Lin Qiu, Qipeng Guo, Tianhang Zhang, Yang Xu, Yun Luo, Pengfei Liu, Yue Zhang, and Zheng Zhang.

</span>
<span class="ltx_bibblock">Refchecker: Reference-based fine-grained hallucination checker and benchmark for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2405.14486</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et&nbsp;al.

</span>
<span class="ltx_bibblock">A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2311.05232</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rongjie Huang, Jia-Bin Huang, Dongchao Yang, Yi&nbsp;Ren, Luping Liu, Mingze Li, Zhenhui Ye, Jinglin Liu, Xiaoyue Yin, and Zhou Zhao.

</span>
<span class="ltx_bibblock">Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">ArXiv</em>, abs/2301.12661, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yue Huang, Lichao Sun, Haoran Wang, Siyuan Wu, Qihui Zhang, Yuan Li, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Hanchi Sun, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bertie Vidgen, Bhavya Kailkhura, Caiming Xiong, Chaowei Xiao, Chunyuan Li, Eric&nbsp;P. Xing, Furong Huang, Hao Liu, Heng Ji, Hongyi Wang, Huan Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik, Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao, Jiliang Tang, Jindong Wang, Joaquin Vanschoren, John Mitchell, Kai Shu, Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang, Michael Backes, Neil&nbsp;Zhenqiang Gong, Philip&nbsp;S. Yu, Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shuiwang Ji, Suman Jana, Tianlong Chen, Tianming Liu, Tianyi Zhou, William&nbsp;Yang Wang, Xiang Li, Xiangliang Zhang, Xiao Wang, Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanfang Ye, Yinzhi Cao, Yong Chen, and Yue Zhao.

</span>
<span class="ltx_bibblock">Trustllm: Trustworthiness in large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Forty-first International Conference on Machine Learning</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard &amp; Grave (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gautier Izacard and Edouard Grave.

</span>
<span class="ltx_bibblock">Leveraging passage retrieval with generative models for open domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">ArXiv</em>, abs/2007.01282, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qi&nbsp;Jia, Siyu Ren, Yizhu Liu, and Kenny Zhu.

</span>
<span class="ltx_bibblock">Zero-shot faithfulness evaluation for text summarization with foundation language model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 11017–11031, December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel&nbsp;S Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 1601–1611, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zixuan Ke, Weize Kong, Cheng Li, Mingyang Zhang, Qiaozhu Mei, and Michael Bendersky.

</span>
<span class="ltx_bibblock">Bridging the preference gap between retrievers and llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2401.06954</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kembhavi et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aniruddha Kembhavi, Matteo Salvato, Minjoon Seo, Harish Kannan, Aniruddha Singh, Li&nbsp;Fei-Fei, Ali Farhadi, and Mark Yatskar.

</span>
<span class="ltx_bibblock">Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 4999–5007, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kojima et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang&nbsp;Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Advances in neural information processing systems</em>, 35:22199–22213, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. (2019a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et&nbsp;al.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Transactions of the Association for Computational Linguistics</em>, 7:453–466, 2019a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. (2019b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina&nbsp;N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Transactions of the Association of Computational Linguistics</em>, 2019b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laban et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Philippe Laban, Wojciech Kryscinski, Divyansh Agarwal, Alexander Fabbri, Caiming Xiong, Shafiq Joty, and Chien-Sheng Wu.

</span>
<span class="ltx_bibblock">SummEdits: Measuring LLM ability at factual reasoning through the lens of summarization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 9662–9676, December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy.

</span>
<span class="ltx_bibblock">RACE: Large-scale ReAding comprehension dataset from examinations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 785–794, September 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale&nbsp;N Fung, Mohammad Shoeybi, and Bryan Catanzaro.

</span>
<span class="ltx_bibblock">Factuality enhanced language models for open-ended text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Advances in Neural Information Processing Systems</em>, 35:34586–34599, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, NIPS ’20, Red Hook, NY, USA, 2020. Curran Associates Inc.

</span>
<span class="ltx_bibblock">ISBN 9781713829546.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chaofan Li, Zheng Liu, Shitao Xiao, and Yingxia Shao.

</span>
<span class="ltx_bibblock">Making large language models a better foundation for dense retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ArXiv</em>, abs/2312.15503, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaqi Li, Mengmeng Wang, Zilong Zheng, and Muhan Zhang.

</span>
<span class="ltx_bibblock">LooGLE: Can long-context language models understand long contexts?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 16304–16333, August 2024a.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2024.acl-long.859</span>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junyi Li, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">HaluEval: A large-scale hallucination evaluation benchmark for large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 6449–6464, December 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Junyi Li, Jie Chen, Ruiyang Ren, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">The dawn after the dark: An empirical study on factuality hallucination in large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 10879–10899, August 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2024c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xingxuan Li, Ruochen Zhao, Yew&nbsp;Ken Chia, Bosheng Ding, Shafiq Joty, Soujanya Poria, and Lidong Bing.

</span>
<span class="ltx_bibblock">Chain-of-knowledge: Grounding large language models via dynamic knowledge adapting over heterogeneous sources.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">The Twelfth International Conference on Learning Representations</em>, 2024c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">TruthfulQA: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 3214–3252, May 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianyu Liu, Yizhe Zhang, Chris Brockett, Yi&nbsp;Mao, Zhifang Sui, Weizhu Chen, and Bill Dolan.

</span>
<span class="ltx_bibblock">A token-level reference-free hallucination detection benchmark for free-form text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2104.08704</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Llama (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Llama.

</span>
<span class="ltx_bibblock">The llama 3 herd of models, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh.

</span>
<span class="ltx_bibblock">Entity-based knowledge conflicts in question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 7052–7063, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manakul et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Potsawee Manakul, Adian Liusie, and Mark Gales.

</span>
<span class="ltx_bibblock">SelfCheckGPT: Zero-resource black-box hallucination detection for generative large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 9004–9017, Singapore, December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rui Meng, Ye&nbsp;Liu, Shafiq&nbsp;Rayhan Joty, Caiming Xiong, Yingbo Zhou, and Semih Yavuz.

</span>
<span class="ltx_bibblock">Sfr-embedding-mistral:enhance text retrieval with transfer learning.

</span>
<span class="ltx_bibblock">Salesforce AI Research Blog, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://blog.salesforceairesearch.com/sfr-embedded-mistral/" title="">https://blog.salesforceairesearch.com/sfr-embedded-mistral/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">FActScore: Fine-grained atomic evaluation of factual precision in long form text generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 12076–12100, December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xuan-Phi Nguyen, Shrey Pandit, Senthil Purushwalkam, Austin Xu, Hailin Chen, Yifei Ming, Zixuan Ke, Silvio Savarese, Caiming Xong, and Shafiq Joty.

</span>
<span class="ltx_bibblock">Sfr-rag: Towards contextually faithful llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2409.09916</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ankit Pal, Logesh&nbsp;Kumar Umapathi, and Malaikannan Sankarasubbu.

</span>
<span class="ltx_bibblock">Med-HALT: Medical domain hallucination test for large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)</em>, pp.&nbsp; 314–334, December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perez et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ethan Perez, Sam Ringer, Kamile Lukosiute, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, Andy Jones, Anna Chen, Benjamin Mann, Brian Israel, Bryan Seethor, Cameron McKinnon, Christopher Olah, Da&nbsp;Yan, Daniela Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, Guro Khundadze, Jackson Kernion, James Landis, Jamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua Landau, Kamal Ndousse, Landon Goldberg, Liane Lovitt, Martin Lucas, Michael Sellitto, Miranda Zhang, Neerav Kingsland, Nelson Elhage, Nicholas Joseph, Noemi Mercado, Nova DasSarma, Oliver Rausch, Robin Larson, Sam McCandlish, Scott Johnston, Shauna Kravec, Sheer El&nbsp;Showk, Tamera Lanham, Timothy Telleen-Lawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Jack Clark, Samuel&nbsp;R. Bowman, Amanda Askell, Roger Grosse, Danny Hernandez, Deep Ganguli, Evan Hubinger, Nicholas Schiefer, and Jared Kaplan.

</span>
<span class="ltx_bibblock">Discovering language model behaviors with model-written evaluations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, July 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et&nbsp;al. (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ questions for machine comprehension of text.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 2383–2392, November 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramakrishna et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anil Ramakrishna, Rahul Gupta, Jens Lehmann, and Morteza Ziyadi.

</span>
<span class="ltx_bibblock">Invite: a testbed of automatically generated invalid questions to evaluate large language models for hallucinations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pp.&nbsp; 5422–5429, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramos et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rita&nbsp;Parada Ramos, Bruno Martins, Desmond Elliott, and Yova Kementchedjhieva.

</span>
<span class="ltx_bibblock">Smallcap: Lightweight image captioning prompted with retrieval augmentation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp.&nbsp; 2840–2849, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarto et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sara Sarto, Marcella Cornia, Lorenzo Baraldi, and Rita Cucchiara.

</span>
<span class="ltx_bibblock">Retrieval-augmented transformer for image captioning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 19th International Conference on Content-based Multimedia Indexing</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed&nbsp;H Chi, Nathanael Schärli, and Denny Zhou.

</span>
<span class="ltx_bibblock">Large language models can be easily distracted by irrelevant context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">International Conference on Machine Learning</em>, pp.&nbsp; 31210–31227. PMLR, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siegel et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noah Siegel, Oana-Maria Camburu, Nicolas Heess, and Maria Perez-Ortiz.

</span>
<span class="ltx_bibblock">The probabilities also matter: A more faithful metric for faithfulness of free-text explanations in large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, pp.&nbsp; 530–546, August 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mingyang Song, Mao Zheng, and Xuan Luo.

</span>
<span class="ltx_bibblock">Counting-stars: A multi-evidence, position-aware, and scalable benchmark for evaluating long-context large language models, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gemma Team.

</span>
<span class="ltx_bibblock">Gemma 2: Improving open language models at a practical size, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trischler et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman.

</span>
<span class="ltx_bibblock">Newsqa: A machine comprehension dataset.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Proceedings of the 2nd Workshop on Representation Learning for NLP</em>, pp.&nbsp; 191–200, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsatsaronis et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Michael&nbsp;R Alvers, Dirk Weissenborn, Anastasia Krithara, Sergios Petridis, Dimitris Polychronopoulos, et&nbsp;al.

</span>
<span class="ltx_bibblock">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">BMC bioinformatics</em>, 16:1–28, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V Le, Denny Zhou, et&nbsp;al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">Advances in neural information processing systems</em>, 35:24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jerry Wei, Da&nbsp;Huang, Yifeng Lu, Denny Zhou, and Quoc&nbsp;V Le.

</span>
<span class="ltx_bibblock">Simple synthetic data reduces sycophancy in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2308.03958</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, Ruibo Liu, Da&nbsp;Huang, Cosmo Du, et&nbsp;al.

</span>
<span class="ltx_bibblock">Long-form factuality in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">arXiv preprint arXiv:2403.18802</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu, Hengshu Zhu, Qi&nbsp;Liu, et&nbsp;al.

</span>
<span class="ltx_bibblock">A survey on large language models for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">World Wide Web</em>, 27(5):60, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and Yu&nbsp;Su.

</span>
<span class="ltx_bibblock">Adaptive chameleon or stubborn sloth: Revealing the behavior of large language models in knowledge conflicts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fangyuan Xu, Weijia Shi, and Eunsol Choi.

</span>
<span class="ltx_bibblock">RECOMP: Improving retrieval-augmented LMs with context compression and selective augmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William&nbsp;W Cohen, Ruslan Salakhutdinov, and Christopher&nbsp;D Manning.

</span>
<span class="ltx_bibblock">Hotpotqa: A dataset for diverse, explainable multi-hop question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 2369–2380, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, and Xuanjing Huang.

</span>
<span class="ltx_bibblock">Do large language models know what they don’t know?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pp.&nbsp; 8653–8665, July 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaodong Yu, Hao Cheng, Xiaodong Liu, Dan Roth, and Jianfeng Gao.

</span>
<span class="ltx_bibblock">Reeval: Automatic hallucination evaluation for retrieval-augmented large language models via transferable adversarial attacks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">NAACL-Findings</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, and Bin Cui.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for ai-generated content: A survey, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wayne&nbsp;Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">A survey of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv preprint arXiv:2303.18223</em>, 2024b.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional Experiment Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Context Generation Model.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px1.p1.1">By default, we use the latest GPT-4o (gpt-4o-2024-05-13) as the context generator. In our preliminary studies, we evaluated various alternatives, including GPT-4o-mini, GPT-4-turbo, and LLaMA-3.1-70B. GPT-4o demonstrated superior performance in terms of context coherence, validity, and complexity.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Context Evaluation Model.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px2.p1.1">We use gpt-4o-mini as the judge model for context verification. We selected gpt-4o-mini for its faster inference speed, lower cost, and high judgment quality, with our preliminary study showing an agreement rate of over 95% when compared to GPT-4o as the judge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Valid phrases for non-strict matching.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px3.p1.1">The following keywords are considered valid for <em class="ltx_emph ltx_font_italic" id="A1.SS0.SSS0.Px3.p1.1.1">Unknown Context</em>: "unknown", "no answer", "no information", "not", "unclear". For <em class="ltx_emph ltx_font_italic" id="A1.SS0.SSS0.Px3.p1.1.2">Inconsistent Context</em>, the valid phrases include: "conflict", "conflicting", "disagreement", "inconsistent", "contradictory", "contradiction", "inconsistency", "two answers", "2 answers", "multiple answers". These keywords were selected based on an analysis of output patterns from open-source and proprietary models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Model sizes.</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="A1.SS0.SSS0.Px4.p1.1">In this work, we evaluate on 18 competitive open-sourced and proprietary models. A summary of model sizes from different model families are shown in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A1.T2" title="Table 2 ‣ Model sizes. ‣ Appendix A Additional Experiment Details ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T2.1" style="width:151.0pt;height:363.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.7pt,52.3pt) scale(0.776585920752504,0.776585920752504) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T2.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T2.1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.1.1.1">Model Name</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T2.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.1.2.1">Model Size</span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.2.2.1.1">Phi-3 Family&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Abdin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib1" title="">2024</a>)</cite></span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.3.3">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.3.3.1">Phi-3-mini-128k-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.3.3.2">3.8B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.4.4">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.4.4.1">Phi-3-medium-128k-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.4.4.2">14B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.5.5">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.5.5.1">Phi-3.5-mini-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.5.5.2">3.8B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.6.6.1.1">LLaMA-3 Family&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Llama, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib41" title="">2024</a>)</cite></span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.7.7">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.7.7.1">LLaMA-3-8B-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.7.7.2">8B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.8.8">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.8.8.1">LLaMA-3.1-8B-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.8.8.2">8B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.9.9">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.9.9.1">LLaMA-3-70B-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.9.9.2">70B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.10.10">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.10.10.1">LLaMA-3.1-70B-instruct</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.10.10.2">70B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.11.11">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.11.11.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.11.11.1.1">Mistral Family&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib23" title="">2023</a>)</cite></span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.12.12">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.12.12.1">Mistral-7B-instruct-v0.3</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.12.12.2">7B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.13.13">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.13.13.1">Mistral-Nemo-instruct-2407</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.13.13.2">12B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.14.14">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.14.14.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.14.14.1.1">Gemma-2 Family&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Team, <a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#bib.bib56" title="">2024</a>)</cite></span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.15.15">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.15.15.1">Gemma-2-9B-it</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.15.15.2">9B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.16.16">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.16.16.1">Gemma-2-27B-it</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.16.16.2">27B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.17.17">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.17.17.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.17.17.1.1">OpenAI</span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.18.18">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.18.18.1">GPT-3.5 Turbo</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.18.18.2">unknown</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.19.19">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.19.19.1">GPT-4o-mini</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.19.19.2">unknown</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.20.20">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.20.20.1">GPT-4o</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.20.20.2">unknown</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.21.21">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.21.21.1">GPT-4 Turbo</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.21.21.2">unknown</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.22.22">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.22.22.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.22.22.1.1">Cohere</span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.23.23">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.23.23.1">Command R</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.23.23.2">35B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.24.24">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.24.24.1">Command R+</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.24.24.2">104B</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.25.25">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="A1.T2.1.1.25.25.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.25.25.1.1">Anthropic</span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.26.26">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T2.1.1.26.26.1">Claude 3.5 Sonnet</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T2.1.1.26.26.2">unknown</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Model sizes across different model families. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Prompt for Contextual QA Generation</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">The system prompt for generating Unanswerable Context, Inconsistent Context, and Counterfactual Context are shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2.F12" title="Figure 12 ‣ Appendix B Prompt for Contextual QA Generation ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">12</span></a>, Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2.F13" title="Figure 13 ‣ Appendix B Prompt for Contextual QA Generation ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">13</span></a>, and Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A2.F14" title="Figure 14 ‣ Appendix B Prompt for Contextual QA Generation ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">14</span></a>, respectively.
For Inconsistent Context, our initial experiments suggest that a successful strategy is to decompose the generation of contextual QA into two steps. Step 1: generate a new answer that is fabricated and challenges common sense or well-known facts. Step 2: generate a modified context with fabricated evidence that supports the new answer. The model will output a JSON object containing the provided question, the provided old answer, the new answer, the modified context, and a concise justification on (1) if the new answer is supported by the new context (2) if all mentions of the old answer have been replaced or removed. We find that having justifications significantly improves the context quality. The generated context is concatenated with the original context to create an inconsistent context.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A2.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="480" id="A2.F12.g1" src="https://arxiv.org/html/2410.03727v1/x4.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>System prompt for Unanswerable Context. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A2.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="584" id="A2.F13.g1" src="https://arxiv.org/html/2410.03727v1/x5.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>System prompt for Inconsistent Context.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A2.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="450" id="A2.F14.g1" src="https://arxiv.org/html/2410.03727v1/x6.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>System prompt for Counterfactual Context. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Detailed Experiment Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">The results for all models on each of the ten datasets are summarized in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3.F15" title="Figure 15 ‣ Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">15</span></a> and Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3.F16" title="Figure 16 ‣ Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">16</span></a> for Unanswerable Context; Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3.F17" title="Figure 17 ‣ Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">17</span></a> and Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A3.F18" title="Figure 18 ‣ Appendix C Detailed Experiment Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">18</span></a> for Inconsistent Context.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F15">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.1.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3.1-8B-Instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.2.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3-8B-Instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.3.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3-70B-Instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.4.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3.1-70B-Instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.5.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Command_R_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.6.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Command_R+_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.7.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gemma-2-9b-it_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.8.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gemma-2-27b-it_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F15.9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F15.9.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-3.5-turbo_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Performance decomposition on individual datasets for Unanswerable Context (part I).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F16">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.1.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-4-turbo_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.2.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-4o_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.3.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-4o-mini_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.4.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Mistral-7B-Instruct-v0.3_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.5.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Mistral-Nemo-Instruct-2407_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.6.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Phi-3-mini-128k-instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.7.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Phi-3-medium-128k-instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.8.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Phi-3.5-mini-instruct_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F16.9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F16.9.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Claude_3.5_Sonnet_results.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Performance decomposition on individual datasets for Unanswerable Context (part II).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F17">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.1.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3.1-8B-Instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.2.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3-8B-Instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.3.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3-70B-Instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.4.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Llama-3.1-70B-Instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.5.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Command_R_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.6.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Command_R+_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.7.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gemma-2-9b-it_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.8.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gemma-2-27b-it_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F17.9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F17.9.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-3.5-turbo_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Performance decomposition on individual datasets for Inconsistent Context (part I).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F18">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.1.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-4-turbo_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.2.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-4o_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.3.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/gpt-4o-mini_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.4.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Mistral-7B-Instruct-v0.3_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.5.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Mistral-Nemo-Instruct-2407_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.6.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Phi-3-mini-128k-instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.7.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Phi-3-medium-128k-instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.8.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Phi-3.5-mini-instruct_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F18.9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="532" id="A3.F18.9.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/app_individual/Claude_3.5_Sonnet_results_c.png" width="548">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 18: </span>Performance decomposition on individual datasets for Inconsistent Context (part II).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A3.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance comparison on Unanswerable Context with strict (S) and non-strict (N) matching.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T3.1" style="width:397.5pt;height:159pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-251.2pt,100.5pt) scale(0.441730904514284,0.441730904514284) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T3.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T3.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.1.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.2.1">BioASQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.3.1">DROP</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.4.1">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.5.1">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.6.1">NewsQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.7.1">RACE</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.8.1">SQuAD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.9.1">SearchQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.10"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.10.1">TextbookQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.11.1">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T3.1.1.1.1.12"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.1.1.12.1">AVG</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="A3.T3.1.1.2.2.1"></th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.2.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.3.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.4.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.5.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.6"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.6.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.7"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.7.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.8"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.8.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.9"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.9.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.10"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.10.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.11"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.11.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.12"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.12.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.13"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.13.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.14"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.14.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.15"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.15.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.16"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.16.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.17"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.17.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.18"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.18.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.19"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.19.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.20"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.20.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.21"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.21.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.22"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.22.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.2.2.23"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.2.2.23.1">N</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A3.T3.1.1.3.3.1">Llama-3-70B-Instruct</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.2">0.508</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.3">0.512</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.4">0.644</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.5">0.656</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.6">0.548</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.7">0.552</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.8">0.508</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.9">0.516</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.10">0.512</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.11">0.520</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.12">0.396</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.13">0.408</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.14">0.588</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.15">0.592</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.16">0.112</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.17">0.116</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.18">0.488</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.19">0.488</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.20">0.455</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.21">0.463</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.22">0.476</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.3.3.23">0.482</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.4.4.1">Llama-3-8B-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.2">0.268</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.3">0.272</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.4">0.528</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.5">0.532</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.6">0.252</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.7">0.252</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.8">0.224</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.9">0.232</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.10">0.344</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.11">0.364</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.12">0.336</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.13">0.352</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.14">0.436</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.15">0.444</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.16">0.140</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.17">0.144</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.18">0.232</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.19">0.236</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.20">0.248</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.21">0.252</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.22">0.301</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.4.4.23">0.308</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.5.5.1">Llama-3.1-70B-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.2">0.452</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.3">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.4">0.676</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.5">0.684</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.6">0.628</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.7">0.632</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.8">0.468</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.9">0.500</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.10">0.500</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.11">0.524</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.12">0.408</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.13">0.424</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.14">0.612</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.15">0.616</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.16">0.096</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.17">0.108</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.18">0.436</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.19">0.440</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.20">0.517</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.21">0.525</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.22">0.479</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.5.5.23">0.491</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.6.6.1">Llama-3.1-8B-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.2">0.292</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.3">0.300</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.4">0.632</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.5">0.636</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.6">0.448</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.7">0.452</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.8">0.388</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.9">0.400</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.10">0.420</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.11">0.428</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.12">0.396</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.13">0.420</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.14">0.532</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.15">0.544</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.16">0.116</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.17">0.128</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.18">0.212</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.19">0.228</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.20">0.326</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.21">0.339</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.22">0.376</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.6.6.23">0.388</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.7.7.1">Mistral-7B-Instruct-v0.3</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.2">0.304</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.3">0.360</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.4">0.476</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.5">0.528</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.6">0.400</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.7">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.8">0.336</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.9">0.468</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.10">0.252</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.11">0.484</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.12">0.256</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.13">0.412</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.14">0.392</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.15">0.516</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.16">0.132</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.17">0.184</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.18">0.116</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.19">0.232</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.20">0.236</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.21">0.306</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.22">0.290</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.7.7.23">0.395</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.8.8.1">Mistral-Nemo-Instruct-2407</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.2">0.192</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.3">0.196</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.4">0.436</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.5">0.444</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.6">0.380</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.7">0.380</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.8">0.284</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.9">0.288</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.10">0.308</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.11">0.332</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.12">0.316</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.13">0.340</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.14">0.416</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.15">0.428</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.16">0.224</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.17">0.224</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.18">0.108</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.19">0.112</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.20">0.140</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.21">0.140</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.22">0.280</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.8.8.23">0.288</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.9.9.1">Phi-3-medium-128k-instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.2">0.024</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.3">0.204</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.4">0.124</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.5">0.428</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.6">0.176</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.7">0.312</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.8">0.116</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.9">0.288</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.10">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.11">0.360</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.12">0.044</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.13">0.312</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.14">0.128</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.15">0.448</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.16">0.024</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.17">0.052</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.18">0.036</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.19">0.068</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.20">0.008</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.21">0.062</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.22">0.074</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.9.9.23">0.253</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.10.10.1">Phi-3-mini-128k-instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.2">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.3">0.096</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.4">0.108</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.5">0.248</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.6">0.096</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.7">0.148</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.8">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.9">0.168</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.10">0.076</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.11">0.188</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.12">0.040</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.13">0.104</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.14">0.076</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.15">0.232</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.16">0.072</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.17">0.084</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.18">0.012</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.19">0.024</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.20">0.029</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.21">0.045</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.22">0.063</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.10.10.23">0.134</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.11.11.1">Phi-3.5-mini-instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.2">0.076</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.3">0.140</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.4">0.292</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.5">0.348</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.6">0.176</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.7">0.244</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.8">0.188</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.9">0.260</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.10">0.116</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.11">0.264</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.12">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.13">0.152</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.14">0.220</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.15">0.316</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.16">0.064</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.17">0.080</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.18">0.032</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.19">0.044</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.20">0.050</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.21">0.116</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.22">0.131</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.11.11.23">0.196</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.12.12.1">gemma-2-27b-it</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.2">0.712</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.3">0.716</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.4">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.5">0.684</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.6">0.628</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.7">0.628</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.8">0.636</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.9">0.640</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.10">0.512</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.11">0.512</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.12">0.488</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.13">0.488</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.14">0.676</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.15">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.16">0.156</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.17">0.160</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.18">0.412</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.19">0.412</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.20">0.558</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.21">0.562</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.22"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.12.12.22.1">0.546</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.12.12.23"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.12.12.23.1">0.548</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.13.13.1">gemma-2-9b-it</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.2">0.628</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.3">0.632</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.4">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.5">0.664</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.6">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.7">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.8">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.9">0.612</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.10">0.492</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.11">0.500</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.12">0.444</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.13">0.448</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.14">0.664</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.15">0.668</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.16">0.152</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.17">0.152</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.18">0.356</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.19">0.356</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.20">0.442</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.21">0.450</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.22"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T3.1.1.13.13.22.1">0.503</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.13.13.23"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T3.1.1.13.13.23.1">0.507</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A3.T3.1.1.14.14.1">Command R</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.2">0.448</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.3">0.452</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.4">0.436</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.5">0.440</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.6">0.460</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.7">0.464</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.8">0.380</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.9">0.396</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.10">0.396</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.11">0.412</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.12">0.344</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.13">0.352</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.14">0.496</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.15">0.508</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.16">0.236</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.17">0.236</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.18">0.436</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.19">0.436</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.20">0.380</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.21">0.393</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.22">0.401</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T3.1.1.14.14.23">0.409</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.15.15.1">Command R+</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.2">0.368</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.3">0.376</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.4">0.548</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.5">0.552</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.6">0.424</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.7">0.424</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.8">0.372</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.9">0.372</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.10">0.440</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.11">0.456</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.12">0.352</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.13">0.356</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.14">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.15">0.596</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.16">0.192</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.17">0.196</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.18">0.312</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.19">0.316</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.20">0.364</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.21">0.364</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.22">0.396</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.15.15.23">0.401</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.16.16.1">gpt-3.5-turbo</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.2">0.056</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.3">0.072</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.4">0.132</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.5">0.156</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.6">0.288</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.7">0.292</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.8">0.216</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.9">0.228</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.10">0.152</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.11">0.204</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.12">0.108</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.13">0.160</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.14">0.212</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.15">0.236</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.16">0.084</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.17">0.084</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.18">0.072</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.19">0.076</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.20">0.017</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.21">0.033</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.22">0.134</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.16.16.23">0.154</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.17.17.1">gpt-4-turbo</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.2">0.432</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.3">0.468</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.4">0.684</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.5">0.692</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.6">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.7">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.8">0.508</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.9">0.524</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.10">0.480</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.11">0.520</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.12">0.488</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.13">0.532</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.14">0.636</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.15">0.640</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.16">0.164</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.17">0.164</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.18">0.320</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.19">0.336</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.20">0.310</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.21">0.326</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.22">0.468</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.17.17.23">0.486</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.18.18.1">gpt-4o</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.2">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.3">0.592</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.4">0.728</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.5">0.732</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.6">0.812</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.7">0.812</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.8">0.728</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.9">0.732</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.10">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.11">0.604</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.12">0.540</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.13">0.544</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.14">0.748</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.15">0.748</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.16">0.180</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.17">0.184</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.18">0.576</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.19">0.576</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.20">0.463</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.21">0.463</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.22"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T3.1.1.18.18.22.1">0.597</span></td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.18.18.23"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T3.1.1.18.18.23.1">0.599</span></td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T3.1.1.19.19.1">gpt-4o-mini</th>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.2">0.576</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.3">0.588</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.4">0.688</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.5">0.692</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.6">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.7">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.8">0.688</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.9">0.692</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.10">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.11">0.472</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.12">0.512</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.13">0.532</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.14">0.676</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.15">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.16">0.244</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.17">0.244</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.18">0.388</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.19">0.396</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.20">0.322</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.21">0.326</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.22">0.523</td>
<td class="ltx_td ltx_align_center" id="A3.T3.1.1.19.19.23">0.530</td>
</tr>
<tr class="ltx_tr" id="A3.T3.1.1.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T3.1.1.20.20.1">Claude 3.5 Sonnet</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.2">0.832</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.3">0.840</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.4">0.784</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.5">0.792</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.6">0.716</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.7">0.716</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.8">0.640</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.9">0.648</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.10">0.512</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.11">0.544</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.12">0.524</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.13">0.536</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.14">0.704</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.15">0.712</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.16">0.228</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.17">0.236</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.18">0.648</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.19">0.648</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.20">0.624</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.21">0.624</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.22"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.20.20.22.1">0.621</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T3.1.1.20.20.23"><span class="ltx_text ltx_font_bold" id="A3.T3.1.1.20.20.23.1">0.630</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A3.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance comparison on Inconsistent Context with strict (S) and non-strict (N) matching.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T4.1" style="width:397.5pt;height:159pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-251.2pt,100.5pt) scale(0.441730904514284,0.441730904514284) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T4.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T4.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A3.T4.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.1.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.2.1">BioASQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.3.1">DROP</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.4.1">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.5.1">NQ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.6.1">NewsQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.7.1">RACE</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.8.1">SQuAD</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.9.1">SearchQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.10"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.10.1">TextbookQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.11.1">TriviaQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T4.1.1.1.1.12"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.1.1.12.1">AVG</span></td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="A3.T4.1.1.2.2.1"></th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.2.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.3.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.4.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.5.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.6"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.6.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.7"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.7.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.8"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.8.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.9"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.9.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.10"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.10.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.11"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.11.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.12"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.12.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.13"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.13.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.14"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.14.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.15"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.15.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.16"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.16.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.17"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.17.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.18"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.18.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.19"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.19.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.20"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.20.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.21"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.21.1">N</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.22"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.22.1">S</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.2.2.23"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.2.2.23.1">N</span></td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A3.T4.1.1.3.3.1">Llama-3-70B-Instruct</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.2">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.3">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.4">0.347</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.5">0.347</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.6">0.460</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.7">0.460</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.8">0.593</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.9">0.593</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.10">0.480</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.11">0.480</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.12">0.453</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.13">0.453</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.14">0.780</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.15">0.780</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.16">0.100</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.17">0.100</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.18">0.293</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.19">0.293</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.20">0.347</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.21">0.347</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.22">0.429</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.3.3.23">0.429</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.4.4.1">Llama-3-8B-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.2">0.313</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.3">0.313</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.4">0.307</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.5">0.307</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.6">0.387</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.7">0.387</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.8">0.260</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.9">0.260</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.10">0.280</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.11">0.280</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.12">0.187</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.13">0.187</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.14">0.273</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.15">0.273</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.16">0.073</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.17">0.073</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.18">0.113</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.19">0.113</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.20">0.173</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.21">0.173</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.22">0.237</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.4.4.23">0.237</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.5.5.1">Llama-3.1-70B-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.2">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.3">0.627</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.4">0.587</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.5">0.587</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.6">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.7">0.680</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.8">0.773</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.9">0.773</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.10">0.593</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.11">0.593</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.12">0.407</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.13">0.407</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.14">0.847</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.15">0.847</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.16">0.293</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.17">0.293</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.18">0.367</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.19">0.367</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.20">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.21">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.22"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.5.5.22.1">0.563</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.5.5.23"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.5.5.23.1">0.563</span></td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.6.6.1">Llama-3.1-8B-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.2">0.407</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.3">0.407</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.4">0.500</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.5">0.500</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.6">0.533</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.7">0.533</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.8">0.587</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.9">0.587</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.10">0.333</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.11">0.333</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.12">0.333</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.13">0.333</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.14">0.473</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.15">0.473</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.16">0.200</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.17">0.200</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.18">0.087</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.19">0.087</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.20">0.267</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.21">0.267</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.22">0.372</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.6.6.23">0.372</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.7.7.1">Mistral-Nemo-Instruct-2407</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.2">0.440</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.3">0.440</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.4">0.607</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.5">0.607</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.6">0.600</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.7">0.600</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.8">0.507</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.9">0.507</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.10">0.587</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.11">0.587</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.12">0.560</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.13">0.560</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.14">0.580</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.15">0.580</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.16">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.17">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.18">0.300</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.19">0.300</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.20">0.380</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.21">0.380</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.22"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T4.1.1.7.7.22.1">0.502</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.7.7.23"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T4.1.1.7.7.23.1">0.502</span></td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.8.8.1">Mixtral-8x7B-Instruct-v0.1</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.2">0.547</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.3">0.547</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.4">0.567</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.5">0.567</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.6">0.400</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.7">0.400</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.8">0.507</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.9">0.507</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.10">0.213</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.11">0.213</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.12">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.13">0.460</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.14">0.727</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.15">0.727</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.16">0.227</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.17">0.227</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.18">0.307</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.19">0.313</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.20">0.207</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.21">0.207</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.22">0.416</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.8.8.23">0.417</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.9.9.1">Phi-3-medium-128k-instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.2">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.3">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.4">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.5">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.6">0.047</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.7">0.047</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.8">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.9">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.10">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.11">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.12">0.067</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.13">0.067</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.14">0.093</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.15">0.093</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.16">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.17">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.18">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.19">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.20">0.013</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.21">0.013</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.22">0.040</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.9.9.23">0.040</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.10.10.1">Phi-3-mini-128k-instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.2">0.027</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.3">0.027</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.4">0.013</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.5">0.013</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.6">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.7">0.020</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.8">0.087</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.9">0.087</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.10">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.11">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.12">0.027</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.13">0.027</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.14">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.15">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.16">0.013</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.17">0.013</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.18">0.000</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.19">0.000</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.20">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.21">0.007</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.22">0.026</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.10.10.23">0.026</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.11.11.1">Phi-3.5-mini-instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.2">0.107</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.3">0.107</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.4">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.5">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.6">0.133</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.7">0.133</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.8">0.180</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.9">0.180</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.10">0.053</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.11">0.053</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.12">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.13">0.120</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.14">0.313</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.15">0.313</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.16">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.17">0.060</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.18">0.033</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.19">0.033</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.20">0.033</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.21">0.033</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.22">0.109</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.11.11.23">0.109</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.12.12.1">gemma-2-27b-it</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.2">0.280</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.3">0.280</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.4">0.153</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.5">0.153</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.6">0.340</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.7">0.340</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.8">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.9">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.10">0.213</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.11">0.213</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.12">0.133</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.13">0.133</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.14">0.400</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.15">0.400</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.16">0.073</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.17">0.073</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.18">0.093</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.19">0.093</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.20">0.187</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.21">0.187</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.22">0.249</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.12.12.23">0.249</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.13.13.1">gemma-2-9b-it</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.2">0.347</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.3">0.347</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.4">0.293</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.5">0.293</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.6">0.307</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.7">0.307</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.8">0.580</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.9">0.580</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.10">0.193</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.11">0.193</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.12">0.233</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.13">0.233</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.14">0.413</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.15">0.413</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.16">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.17">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.18">0.027</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.19">0.027</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.20">0.213</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.21">0.213</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.22">0.271</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.13.13.23">0.271</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A3.T4.1.1.14.14.1">Command R</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.2">0.493</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.3">0.493</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.4">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.5">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.6">0.447</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.7">0.447</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.8">0.600</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.9">0.600</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.10">0.467</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.11">0.467</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.12">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.13">0.433</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.14">0.527</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.15">0.527</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.16">0.360</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.17">0.360</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.18">0.207</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.19">0.207</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.20">0.460</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.21">0.460</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.22">0.443</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T4.1.1.14.14.23">0.443</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.15.15.1">Command R+</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.2">0.373</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.3">0.373</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.4">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.5">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.6">0.533</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.7">0.533</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.8">0.733</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.9">0.733</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.10">0.427</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.11">0.427</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.12">0.487</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.13">0.487</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.14">0.760</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.15">0.760</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.16">0.393</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.17">0.393</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.18">0.247</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.19">0.247</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.20">0.533</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.21">0.533</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.22">0.511</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.15.15.23">0.511</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.16.16.1">gpt-3.5-turbo</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.2">0.087</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.3">0.087</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.4">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.5">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.6">0.227</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.7">0.227</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.8">0.320</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.9">0.320</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.10">0.147</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.11">0.147</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.12">0.147</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.13">0.147</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.14">0.220</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.15">0.220</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.16">0.040</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.17">0.040</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.18">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.19">0.100</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.20">0.053</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.21">0.053</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.22">0.144</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.16.16.23">0.144</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.17.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.17.17.1">gpt-4-turbo</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.2">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.3">0.800</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.4">0.933</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.5">0.933</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.6">0.913</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.7">0.913</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.8">0.920</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.9">0.920</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.10">0.893</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.11">0.893</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.12">0.807</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.13">0.807</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.14">0.967</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.15">0.967</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.16">0.773</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.17">0.773</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.18">0.767</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.19">0.767</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.20">0.773</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.21">0.773</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.22">0.855</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.17.17.23">0.855</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.18.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.18.18.1">gpt-4o</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.2">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.3">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.4">0.900</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.5">0.900</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.6">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.7">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.8">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.9">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.10">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.11">0.960</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.12">0.880</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.13">0.880</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.14">0.980</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.15">0.980</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.16">0.813</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.17">0.813</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.18">0.973</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.19">0.973</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.20">0.933</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.21">0.933</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.22"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T4.1.1.18.18.22.1">0.932</span></td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.18.18.23"><span class="ltx_text ltx_framed ltx_framed_underline" id="A3.T4.1.1.18.18.23.1">0.932</span></td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.19.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A3.T4.1.1.19.19.1">gpt-4o-mini</th>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.2">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.3">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.4">0.527</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.5">0.527</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.6">0.787</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.7">0.787</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.8">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.9">0.660</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.10">0.407</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.11">0.407</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.12">0.373</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.13">0.373</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.14">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.15">0.620</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.16">0.740</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.17">0.740</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.18">0.347</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.19">0.347</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.20">0.580</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.21">0.580</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.22">0.570</td>
<td class="ltx_td ltx_align_center" id="A3.T4.1.1.19.19.23">0.570</td>
</tr>
<tr class="ltx_tr" id="A3.T4.1.1.20.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A3.T4.1.1.20.20.1">Claude 3.5 Sonnet</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.2">0.993</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.3">0.993</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.4">0.960</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.5">0.960</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.6">0.960</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.7">0.960</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.8">0.953</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.9">0.953</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.10">0.987</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.11">0.987</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.12">0.913</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.13">0.913</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.14">0.987</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.15">0.987</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.16">0.800</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.17">0.800</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.18">0.947</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.19">0.947</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.20">0.940</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.21">0.940</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.22"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.20.20.22.1">0.944</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T4.1.1.20.20.23"><span class="ltx_text ltx_font_bold" id="A3.T4.1.1.20.20.23.1">0.944</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Verification for Counterfactual Context</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">For the Counterfactual Context task, since the answer options are provided within the context, we can validate the new context using a simple keyword-based matching method, where a context passes if the answer phrase exists in the context. This results in a pass rate of 68.9%, where the new context clearly contains the new answer. The results on this filtered subset are shown in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#A4.F19" title="Figure 19 ‣ Appendix D Verification for Counterfactual Context ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">19</span></a>. We can see that the same trend still holds as shown in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4" title="4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">4</span></a>: a significant gap remains between the performance on the original task (with no context) and the new task with counterfactual contexts, across the majority of instruction-tuned models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A4.F19"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="A4.F19.g1" src="https://arxiv.org/html/2410.03727v1/extracted/5888891/img/model_performance_cc.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 19: </span>Model performance comparison on the clean subset of Counterfactual Context. The same trend still holds as in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2410.03727v1#S4" title="4 Main Results ‣ FaithEval: Can Your Language Model Stay Faithful to Context, Even If “The Moon is Made of Marshmallows”"><span class="ltx_text ltx_ref_tag">4</span></a>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>