<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SPHINX: Structural Prediction using Hypergraph Inference Network</title>
<!--Generated on Fri Oct  4 07:49:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03208v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S1" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S2" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S2.SS0.SSS0.Px1" title="In 2 Related work â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title">Structural inference on graph.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S2.SS0.SSS0.Px2" title="In 2 Related work â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title">Structural inference on hypergraphs.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Structure Prediction using Hypergraph Inference Network</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.SS1" title="In 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Hypergraph predictor</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.SS1.SSS0.Px1" title="In 3.1 Hypergraph predictor â€£ 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title">Slot Attention for probabilistic incidence prediction.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.SS1.SSS0.Px2" title="In 3.1 Hypergraph predictor â€£ 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title">Sequential Slot Attention for solving ambiguities.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.SS2" title="In 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Discrete constrained sampling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.SS3" title="In 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Hypergraph processing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experimental Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.SS1" title="In 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Particle Simulations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.SS2" title="In 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>NBA Dataset</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S5" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S5.SS0.SSS0.Px1" title="In 5 Conclusion â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title">Acknowledgment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A1" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Broader Impact &amp; Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A2" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Visualisations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A3" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Experimental details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A3.SS1" title="In Appendix C Experimental details â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Datasets details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A3.SS2" title="In Appendix C Experimental details â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Implementation details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4" title="In SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Additional experiments</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.SS1" title="In Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>Full results on Particle Simulation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.SS1.SSS0.Px1" title="In D.1 Full results on Particle Simulation â€£ Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.SS2" title="In Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>Varying. number of hyperedges</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\LetLtxMacro</span><span class="ltx_ERROR undefined" id="p1.2">\oldpm</span>
<p class="ltx_p" id="p1.3">Â±

</p>
</div>
<h1 class="ltx_title ltx_title_document">SPHINX: Structural Prediction using Hypergraph Inference Network</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Iulia
Duta 
<br class="ltx_break"/>University of Cambridge 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">id366@cam.ac.uk</span>
<br class="ltx_break"/>&amp;Pietro LiÃ²
<br class="ltx_break"/>University of Cambridge 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.2.id2">pl219@cam.ac.uk</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">The importance of higher-order relations is widely recognized in a large number of real-world systems. However, annotating them is a tedious and sometimes impossible task. Consequently, current approaches for data modelling either ignore the higher-order interactions altogether or simplify them into pairwise connections.
In order to facilitate higher-order processing, even when a hypergraph structure is not available, we introduce Structural Prediction using Hypergraph Inference Network (SPHINX), a model that learns to infer a latent hypergraph structure in an unsupervised way, solely from the final node-level signal. The model consists of a soft, differentiable clustering method used to sequentially predict, for each hyperedge, the probability distribution over the nodes and a sampling algorithm that converts them into an explicit hypergraph structure. We show that the recent advancement in <math alttext="k" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mi id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><ci id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling represents a suitable tool for producing discrete hypergraph structures, addressing some of the training instabilities exhibited by prior works.
The resulting model can generate the higher-order structure necessary for any modern hypergraph neural network, facilitating the capture of higher-order interaction in domains where annotating them is difficult. Through extensive ablation studies and experiments conducted on two challenging datasets for trajectory prediction, we demonstrate that our model is capable of inferring suitable latent hypergraphs, that are interpretable and enhance the final performance.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Graph data is universally recognized as the standard representation for relational data. However, their capabilities are restricted to only modelling pairwise connections. Emerging research shows that real-world applications including neuroscienceÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib2" title="">2</a>]</cite>, chemistryÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib3" title="">3</a>]</cite>, biologyÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib4" title="">4</a>]</cite>, often exhibit group interactions, involving more that two elements. This leads to the development of a new field dedicated to representing higher-order relations, in the form of hypergraphs.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, while graph datasets are widespread in the machine learning communityÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib6" title="">6</a>]</cite>, the availability of hypergraph datasets is much more limited. Recent workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib7" title="">7</a>]</cite> highlights two potential causes for the lack of higher-order data. On one hand, current technology used for collecting information are mostly designed or optimised to detect pairwise interactions. Furthermore, even in the exceptional cases when the data is gathered in a higher-order format, the published version is often released in a reduced, pairwise form.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.2">Therefore, to preserve the higher-order information, it is crucial to develop methods for learning the hypergraph structure in an unsupervised way, only from point-wise observations. Motivated by this, we introduce Structural Prediction using Hypergraph Inference Network (<span class="ltx_text ltx_font_bold" id="S1.p3.2.1">SPHINX</span>), a model for unsupervised latent hypergraph inference, that can be used in conjunction with any recent models designed for hypergraph processing. SPHINX models the hyperedge discovery as a clustering problem, adapting a soft clustering algorithm to sequentially identify subsets of highly-correlated nodes, corresponding to each hyperedge. To produce a discrete hypergraphs structure, we take advantage of the recent development in differentiable <math alttext="k" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_k</annotation></semantics></math>-subset samplingÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib9" title="">9</a>]</cite>, obtaining a more effective training procedure, that eliminates the necessity for heavy regularisation. While classical selection methods such as Gumbel-Softmax Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib10" title="">10</a>]</cite> fail to control the sparsity of the hypergraph, our constrained <math alttext="k" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mi id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.p3.2.m2.1d">italic_k</annotation></semantics></math>-subset sampling produces more accurate latent structure.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Our model improves the relational processing by learning an appropriate hypergraph structure for the downstream task, without any supervision at the structure level. Our experiments on trajectory prediction show that the inferred structure correlates well with the ground-truth connectivity that guides the dynamical process, while also being beneficial for improving the performance on the higher-level task. The resulting model is general, easy to optimise, which makes it an excellent candidate for modelling higher-order relations, even in the absence of an annotated connectivity.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Our main contributions</span> are summarised as follow:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">novel method for explicit hypergraph inference</span>, that uses a sequential, differentiable clustering approach for identifying subsets of highly-related nodes and a <math alttext="k" class="ltx_Math" display="inline" id="S1.I1.i1.p1.1.m1.1"><semantics id="S1.I1.i1.p1.1.m1.1a"><mi id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><ci id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i1.p1.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling to produce an explicit hypergraph structure, that can be plugged into any hypergraph neural network.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">The model performs <span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">unsupervised hypergraph discovery</span>, by using supervision only from the weak node-level signal. We empirically show that the predicted hypergraph correlates well with the true higher-order structure, even if the model was not optimised for this task.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">The latent hypergraph inference enforces an <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">inductive bias towards capturing higher-order correlations</span>, even in the absence of the real structure, which proved to be <span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.2">beneficial for high-level tasks</span> such as trajectory prediction. Having an explicit structure enables us to visualise the discovered hypergraph, adding another layer of interpretability into the model.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Structural inference on graph.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Modelling relational data using Graph Neural Networks (GNNs)Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib12" title="">12</a>]</cite> proves to be beneficial in several real-world domains including healthcareÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib13" title="">13</a>]</cite>, physicsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib14" title="">14</a>]</cite>, weather forecastÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib15" title="">15</a>]</cite>, mathematicsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib16" title="">16</a>]</cite>, sports analysisÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib17" title="">17</a>]</cite>, chemistryÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib18" title="">18</a>]</cite> and many more. Most of the current graph methods assume that the graph connectivity is known. However, providing the relational structure is a highly challenging task, that, when possible to compute, requires either expensive tools, or advanced domain knowledge. These limitations led to the development of a new machine learning field dedicated to learning to infer structure from data in an unsupervised way.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Neural Relational InferenceÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib19" title="">19</a>]</cite> is one of the pioneering works inferring an adjacency matrix from point-wise observations. The model consists of an encoder that learns to predict a distribution over the potential relationships and a GNN decoder that receives a sampled graph structure and learn to predict the future trajectory. fNRIÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib20" title="">20</a>]</cite> extends this work by inferring a factorised latent space, capable to encode multiple relational types, while Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib21" title="">21</a>]</cite> incorporates causal relations into the framework. When using temporal data, these models infer a single structure for the entire timeseries. dNRIÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib22" title="">22</a>]</cite> improves on that respect, by modifying the graph structure at each timestep.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS0.SSS0.Px1.p3.1.1">Hypergraph Networks.</span> While being a versatile, widespread data structure, graphs are constrained to only represent pairwise connections. Many real-world events contains higher-order interactions, where a relationship contains more than two elements. Several data structures for higher-order modelling were proposed in mathematics, including simplicial complexesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib23" title="">23</a>]</cite>, cell complexesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib24" title="">24</a>]</cite>, and more generally, hypergraphsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib25" title="">25</a>]</cite>. To model hypergraphs, several deep learning methods have recently emerged. Hypergraph Neural NetworksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib26" title="">26</a>]</cite> applies GNNs on top of a weighted clique expansion. This could be seen as a two-stage message passing scheme. In the first stage the information is send from nodes to hyperedges, while in the second stage the messages are send back from hyperedges to nodes. UniGNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib27" title="">27</a>]</cite> and AllDeepSetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib28" title="">28</a>]</cite> introduce a more general framework in which the two stages can be implemented as any permutation-invariant function such as GNNs, DeepSetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib29" title="">29</a>]</cite> or TransformersÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib30" title="">30</a>]</cite>. Further proposed extensions include the integration of attention mechanismsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib31" title="">31</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib33" title="">33</a>]</cite>, or attaching additional geometric structure to the hypergraph, through the incorporation of cellular sheaves Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib34" title="">34</a>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Structural inference on hypergraphs.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Providing the hypergraph structure to the model requires measuring higher-order correlations, which often implies a highly difficult and expensive annotation process. This leads to the necessity of inferring the hypergraph structure directly from data. However, when moving from the graph realm to the hypergraph domain, the set of potential edge candidates abruptly increases from quadratic to exponential. This makes the problem of inferring the latent hypergraph structure significantly more challenging. Classical attempts of achieving this includes methods based on Bayesian inferenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib35" title="">35</a>]</cite> or statistical approaches that compares against a null model for hypergraphs to filter the possible hyperedgesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib36" title="">36</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">While relational inference for graph data is an established field in deep learning, it remains largely unexplored in the hypergraph domain. Cellular complexes represent an alternative, hierarchical data structure for modelling higher-order relationships. DCMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib37" title="">37</a>]</cite> performs structural inference for cellular complexes by proposing a method that learns to efficiently filter from the pool of all possible polygons associated with a graph. Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib38" title="">38</a>]</cite> proposes a supervised, iterative refinement method for set-to-hypergraph task, suitable for large input set sizes. For environments when a ground-truth hypergraph structure is not available, most of the existing methods focuses on the transductive setup, where a single hypergraph is inferred for the entire dataset. Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib39" title="">39</a>]</cite> treats the incidence matrix as a learnable parameter, while Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib41" title="">41</a>]</cite> build a closed-form solution for the label propagation task.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p3.1">On the other hand, for the inductive setup, where each example requires inferring a distinct hypergraph, the literature is very scarce. GroupNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib42" title="">42</a>]</cite> extracts a subset of nodes by identifying highly connected blocks in the correlation matrix. Alternatively, EvolveHypergraphÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib43" title="">43</a>]</cite> uses a GNN model to infer the probabilities of each node being part of a hypergraph and transform this into a hypergraph structure using a Gumbel-SoftmaxÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib10" title="">10</a>]</cite> sampling technique. While obtaining good results on the trajectory prediction tasks, properly optimising these methods requires a high degree of regularisation techniques, including auxiliary loss terms for reconstruction, smoothness or diversity. We believe that this mainly stems from challenges in effectively propagating gradients during the discretization phase. Gumbel-Softmax struggles to control the cardinality of the hyperedges, while top-<math alttext="k" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p3.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p3.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p3.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p3.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p3.1.m1.1d">italic_k</annotation></semantics></math> operations only partially tracks gradients. Moreover, these methods suffer a severe drop in performance when using only the hypergraph structure, with best performance requiring additional pairwise computation.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p4">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p4.1">On the other hand, we are proposing a dedicated hypergraph-only model, that can be easily optimised solely from the final, downstream supervision, eliminating the need for additional optimisation heuristics. As we demonstrate in the experimental section, this advantage is brought by two important design choices: 1) the sequential differentiable-clustering which creates globally-informed probability distribution, alleviating the ambiguity existent in the hyperedge prediction problem and 2) adopting the <math alttext="k" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p4.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p4.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p4.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p4.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p4.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p4.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p4.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p4.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling for discretizing the structure, a method that produces high-quality gradients for the constrained sampling operation.
The resulting model is a versatile and general module, useful for hypergraph processing in scenarios where the hypergraph is not available.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="363" id="S2.F1.g1" src="extracted/5900948/figures/main_fig.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S2.F1.9.1">SPHINX architecture</span>, designed to capture higher-order interactions without having access to the ground-truth hypergraph structure. The model consists of three stages: A) The <span class="ltx_text ltx_font_bold" id="S2.F1.10.2">hypergraph predictor</span> infers a probabilistic latent hypergraph structure, by using a sequential clustering algorithm to produce global, history-aware hyperedges. At each timestep, the node features are enriched with the information about the already predicted hyperedges and the resulting cluster represent the hyperedge membership. B) A <math alttext="k" class="ltx_Math" display="inline" id="S2.F1.3.m1.1"><semantics id="S2.F1.3.m1.1b"><mi id="S2.F1.3.m1.1.1" xref="S2.F1.3.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.F1.3.m1.1c"><ci id="S2.F1.3.m1.1.1.cmml" xref="S2.F1.3.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.3.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S2.F1.3.m1.1e">italic_k</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S2.F1.11.3">-subset sampling</span> algorithm is applied to transform each probability distribution into discrete incidence relations, while maintaining the end-to-end differentiability of the framework. The <math alttext="k" class="ltx_Math" display="inline" id="S2.F1.4.m2.1"><semantics id="S2.F1.4.m2.1b"><mi id="S2.F1.4.m2.1.1" xref="S2.F1.4.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.F1.4.m2.1c"><ci id="S2.F1.4.m2.1.1.cmml" xref="S2.F1.4.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.4.m2.1d">k</annotation><annotation encoding="application/x-llamapun" id="S2.F1.4.m2.1e">italic_k</annotation></semantics></math>-nodes constraint ensures a more stable optimisation process, beneficial for the final performance. C) The predicted hypergraph structure can be used in any standard <span class="ltx_text ltx_font_bold" id="S2.F1.12.4">hypergraph neural network</span> in order to produce higher-order representations.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Structure Prediction using Hypergraph Inference Network</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The Structure Prediction using Hypergraph Inference Network (SPHINX) model is designed to produce higher-order representations without access to a ground-truth hypergraph structure. From the set of point-level observations, the model learns to infer a latent hypergraph that can be further used in conjunction with any classical hypergraph neural network architecture.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.6">Our input consists of a set of nodes <math alttext="V=\{v_{i}|i\in\{1\dots N\}\}" class="ltx_Math" display="inline" id="S3.p2.1.m1.2"><semantics id="S3.p2.1.m1.2a"><mrow id="S3.p2.1.m1.2.2" xref="S3.p2.1.m1.2.2.cmml"><mi id="S3.p2.1.m1.2.2.4" xref="S3.p2.1.m1.2.2.4.cmml">V</mi><mo id="S3.p2.1.m1.2.2.3" xref="S3.p2.1.m1.2.2.3.cmml">=</mo><mrow id="S3.p2.1.m1.2.2.2.2" xref="S3.p2.1.m1.2.2.2.3.cmml"><mo id="S3.p2.1.m1.2.2.2.2.3" stretchy="false" xref="S3.p2.1.m1.2.2.2.3.1.cmml">{</mo><msub id="S3.p2.1.m1.1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.1.2.cmml">v</mi><mi id="S3.p2.1.m1.1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.p2.1.m1.2.2.2.2.4" lspace="0em" rspace="0em" xref="S3.p2.1.m1.2.2.2.3.1.cmml">|</mo><mrow id="S3.p2.1.m1.2.2.2.2.2" xref="S3.p2.1.m1.2.2.2.2.2.cmml"><mi id="S3.p2.1.m1.2.2.2.2.2.3" xref="S3.p2.1.m1.2.2.2.2.2.3.cmml">i</mi><mo id="S3.p2.1.m1.2.2.2.2.2.2" xref="S3.p2.1.m1.2.2.2.2.2.2.cmml">âˆˆ</mo><mrow id="S3.p2.1.m1.2.2.2.2.2.1.1" xref="S3.p2.1.m1.2.2.2.2.2.1.2.cmml"><mo id="S3.p2.1.m1.2.2.2.2.2.1.1.2" stretchy="false" xref="S3.p2.1.m1.2.2.2.2.2.1.2.cmml">{</mo><mrow id="S3.p2.1.m1.2.2.2.2.2.1.1.1" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.cmml"><mn id="S3.p2.1.m1.2.2.2.2.2.1.1.1.2" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.2.cmml">1</mn><mo id="S3.p2.1.m1.2.2.2.2.2.1.1.1.1" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.1.cmml">â¢</mo><mi id="S3.p2.1.m1.2.2.2.2.2.1.1.1.3" mathvariant="normal" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.3.cmml">â€¦</mi><mo id="S3.p2.1.m1.2.2.2.2.2.1.1.1.1a" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.1.cmml">â¢</mo><mi id="S3.p2.1.m1.2.2.2.2.2.1.1.1.4" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.4.cmml">N</mi></mrow><mo id="S3.p2.1.m1.2.2.2.2.2.1.1.3" stretchy="false" xref="S3.p2.1.m1.2.2.2.2.2.1.2.cmml">}</mo></mrow></mrow><mo id="S3.p2.1.m1.2.2.2.2.5" stretchy="false" xref="S3.p2.1.m1.2.2.2.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.2b"><apply id="S3.p2.1.m1.2.2.cmml" xref="S3.p2.1.m1.2.2"><eq id="S3.p2.1.m1.2.2.3.cmml" xref="S3.p2.1.m1.2.2.3"></eq><ci id="S3.p2.1.m1.2.2.4.cmml" xref="S3.p2.1.m1.2.2.4">ğ‘‰</ci><apply id="S3.p2.1.m1.2.2.2.3.cmml" xref="S3.p2.1.m1.2.2.2.2"><csymbol cd="latexml" id="S3.p2.1.m1.2.2.2.3.1.cmml" xref="S3.p2.1.m1.2.2.2.2.3">conditional-set</csymbol><apply id="S3.p2.1.m1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.1.2">ğ‘£</ci><ci id="S3.p2.1.m1.1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.p2.1.m1.2.2.2.2.2.cmml" xref="S3.p2.1.m1.2.2.2.2.2"><in id="S3.p2.1.m1.2.2.2.2.2.2.cmml" xref="S3.p2.1.m1.2.2.2.2.2.2"></in><ci id="S3.p2.1.m1.2.2.2.2.2.3.cmml" xref="S3.p2.1.m1.2.2.2.2.2.3">ğ‘–</ci><set id="S3.p2.1.m1.2.2.2.2.2.1.2.cmml" xref="S3.p2.1.m1.2.2.2.2.2.1.1"><apply id="S3.p2.1.m1.2.2.2.2.2.1.1.1.cmml" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1"><times id="S3.p2.1.m1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.1"></times><cn id="S3.p2.1.m1.2.2.2.2.2.1.1.1.2.cmml" type="integer" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.2">1</cn><ci id="S3.p2.1.m1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.3">â€¦</ci><ci id="S3.p2.1.m1.2.2.2.2.2.1.1.1.4.cmml" xref="S3.p2.1.m1.2.2.2.2.2.1.1.1.4">ğ‘</ci></apply></set></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.2c">V=\{v_{i}|i\in\{1\dots N\}\}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.2d">italic_V = { italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_i âˆˆ { 1 â€¦ italic_N } }</annotation></semantics></math>, each one characterised by a feature vector <math alttext="x_{i}\in\mathbb{R}^{f}" class="ltx_Math" display="inline" id="S3.p2.2.m2.1"><semantics id="S3.p2.2.m2.1a"><mrow id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><msub id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml"><mi id="S3.p2.2.m2.1.1.2.2" xref="S3.p2.2.m2.1.1.2.2.cmml">x</mi><mi id="S3.p2.2.m2.1.1.2.3" xref="S3.p2.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.p2.2.m2.1.1.1" xref="S3.p2.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml"><mi id="S3.p2.2.m2.1.1.3.2" xref="S3.p2.2.m2.1.1.3.2.cmml">â„</mi><mi id="S3.p2.2.m2.1.1.3.3" xref="S3.p2.2.m2.1.1.3.3.cmml">f</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><in id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1"></in><apply id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.2.1.cmml" xref="S3.p2.2.m2.1.1.2">subscript</csymbol><ci id="S3.p2.2.m2.1.1.2.2.cmml" xref="S3.p2.2.m2.1.1.2.2">ğ‘¥</ci><ci id="S3.p2.2.m2.1.1.2.3.cmml" xref="S3.p2.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.3.1.cmml" xref="S3.p2.2.m2.1.1.3">superscript</csymbol><ci id="S3.p2.2.m2.1.1.3.2.cmml" xref="S3.p2.2.m2.1.1.3.2">â„</ci><ci id="S3.p2.2.m2.1.1.3.3.cmml" xref="S3.p2.2.m2.1.1.3.3">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">x_{i}\in\mathbb{R}^{f}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT</annotation></semantics></math>, which can either represent general characteristics of the nodes or, in our experiments, the summary of an observed <math alttext="T" class="ltx_Math" display="inline" id="S3.p2.3.m3.1"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.p2.3.m3.1d">italic_T</annotation></semantics></math>-seconds trajectory. The goal is to predict, for each node, the target <math alttext="y_{i}\in\mathbb{R}^{c}" class="ltx_Math" display="inline" id="S3.p2.4.m4.1"><semantics id="S3.p2.4.m4.1a"><mrow id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><msub id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml"><mi id="S3.p2.4.m4.1.1.2.2" xref="S3.p2.4.m4.1.1.2.2.cmml">y</mi><mi id="S3.p2.4.m4.1.1.2.3" xref="S3.p2.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.p2.4.m4.1.1.1" xref="S3.p2.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml"><mi id="S3.p2.4.m4.1.1.3.2" xref="S3.p2.4.m4.1.1.3.2.cmml">â„</mi><mi id="S3.p2.4.m4.1.1.3.3" xref="S3.p2.4.m4.1.1.3.3.cmml">c</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><in id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1.1"></in><apply id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.2.1.cmml" xref="S3.p2.4.m4.1.1.2">subscript</csymbol><ci id="S3.p2.4.m4.1.1.2.2.cmml" xref="S3.p2.4.m4.1.1.2.2">ğ‘¦</ci><ci id="S3.p2.4.m4.1.1.2.3.cmml" xref="S3.p2.4.m4.1.1.2.3">ğ‘–</ci></apply><apply id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.p2.4.m4.1.1.3.1.cmml" xref="S3.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.p2.4.m4.1.1.3.2.cmml" xref="S3.p2.4.m4.1.1.3.2">â„</ci><ci id="S3.p2.4.m4.1.1.3.3.cmml" xref="S3.p2.4.m4.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">y_{i}\in\mathbb{R}^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.4.m4.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math>. In the entire paper, we are following the assumption that the node-level target <math alttext="y_{i}" class="ltx_Math" display="inline" id="S3.p2.5.m5.1"><semantics id="S3.p2.5.m5.1a"><msub id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mi id="S3.p2.5.m5.1.1.2" xref="S3.p2.5.m5.1.1.2.cmml">y</mi><mi id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1">subscript</csymbol><ci id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1.2">ğ‘¦</ci><ci id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.5.m5.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the result of a higher-order dynamics, guided by an unknown higher-order structure <math alttext="\mathcal{\tilde{H}}" class="ltx_Math" display="inline" id="S3.p2.6.m6.1"><semantics id="S3.p2.6.m6.1a"><mover accent="true" id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.6.m6.1.1.2" xref="S3.p2.6.m6.1.1.2.cmml">â„‹</mi><mo id="S3.p2.6.m6.1.1.1" xref="S3.p2.6.m6.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><apply id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1"><ci id="S3.p2.6.m6.1.1.1.cmml" xref="S3.p2.6.m6.1.1.1">~</ci><ci id="S3.p2.6.m6.1.1.2.cmml" xref="S3.p2.6.m6.1.1.2">â„‹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">\mathcal{\tilde{H}}</annotation><annotation encoding="application/x-llamapun" id="S3.p2.6.m6.1d">over~ start_ARG caligraphic_H end_ARG</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">The processing stages of our method are summarized in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S2.F1" title="Figure 1 â€£ Structural inference on hypergraphs. â€£ 2 Related work â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">1</span></a>. First, we will predict the latent hypergraph based on the input features <math alttext="\mathbf{X}" class="ltx_Math" display="inline" id="S3.p3.1.m1.1"><semantics id="S3.p3.1.m1.1a"><mi id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">ğ—</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">ğ—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">\mathbf{X}</annotation><annotation encoding="application/x-llamapun" id="S3.p3.1.m1.1d">bold_X</annotation></semantics></math>. The inferred hypergraph structure will then be fed into a hypergraph network to obtain the final prediction. To obtain a powerful, general model, our method needs to fulfill two important characteristics. Firstly, the entire pipeline need to be end-to-end differentiable, such that the latent hypergraph inference can be trained in a weakly supervised fashion, solely from the final downstream prediction, without access to the ground-truth hypergraph structure. Secondly, the model needs to be general enough such that it can be used inside any existing architecture for hypergraph processing.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p" id="S3.p4.6">To achieve these desiderata, we designed the model using two core components: a learnable soft clustering that predicts a probability distributions for each one of the <math alttext="M" class="ltx_Math" display="inline" id="S3.p4.1.m1.1"><semantics id="S3.p4.1.m1.1a"><mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.p4.1.m1.1d">italic_M</annotation></semantics></math> potential hyperedges, and a differentiable <math alttext="k" class="ltx_Math" display="inline" id="S3.p4.2.m2.1"><semantics id="S3.p4.2.m2.1a"><mi id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><ci id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.p4.2.m2.1d">italic_k</annotation></semantics></math>-sampling that, based on these probability distribution, samples discrete subsets of <math alttext="k" class="ltx_Math" display="inline" id="S3.p4.3.m3.1"><semantics id="S3.p4.3.m3.1a"><mi id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><ci id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.p4.3.m3.1d">italic_k</annotation></semantics></math> nodes forming the hypergraph structure. Both components are differentiable such that the model can be easily trained using standard backpropagation techniques. Moreover, the predicted hypergraph structure is a discrete object, following the classical structural representation used in any hypergraph processing models <math alttext="\mathcal{H}=(V,E)" class="ltx_Math" display="inline" id="S3.p4.4.m4.2"><semantics id="S3.p4.4.m4.2a"><mrow id="S3.p4.4.m4.2.3" xref="S3.p4.4.m4.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p4.4.m4.2.3.2" xref="S3.p4.4.m4.2.3.2.cmml">â„‹</mi><mo id="S3.p4.4.m4.2.3.1" xref="S3.p4.4.m4.2.3.1.cmml">=</mo><mrow id="S3.p4.4.m4.2.3.3.2" xref="S3.p4.4.m4.2.3.3.1.cmml"><mo id="S3.p4.4.m4.2.3.3.2.1" stretchy="false" xref="S3.p4.4.m4.2.3.3.1.cmml">(</mo><mi id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml">V</mi><mo id="S3.p4.4.m4.2.3.3.2.2" xref="S3.p4.4.m4.2.3.3.1.cmml">,</mo><mi id="S3.p4.4.m4.2.2" xref="S3.p4.4.m4.2.2.cmml">E</mi><mo id="S3.p4.4.m4.2.3.3.2.3" stretchy="false" xref="S3.p4.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.2b"><apply id="S3.p4.4.m4.2.3.cmml" xref="S3.p4.4.m4.2.3"><eq id="S3.p4.4.m4.2.3.1.cmml" xref="S3.p4.4.m4.2.3.1"></eq><ci id="S3.p4.4.m4.2.3.2.cmml" xref="S3.p4.4.m4.2.3.2">â„‹</ci><interval closure="open" id="S3.p4.4.m4.2.3.3.1.cmml" xref="S3.p4.4.m4.2.3.3.2"><ci id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1">ğ‘‰</ci><ci id="S3.p4.4.m4.2.2.cmml" xref="S3.p4.4.m4.2.2">ğ¸</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.2c">\mathcal{H}=(V,E)</annotation><annotation encoding="application/x-llamapun" id="S3.p4.4.m4.2d">caligraphic_H = ( italic_V , italic_E )</annotation></semantics></math>, where <math alttext="V" class="ltx_Math" display="inline" id="S3.p4.5.m5.1"><semantics id="S3.p4.5.m5.1a"><mi id="S3.p4.5.m5.1.1" xref="S3.p4.5.m5.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.p4.5.m5.1b"><ci id="S3.p4.5.m5.1.1.cmml" xref="S3.p4.5.m5.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m5.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.p4.5.m5.1d">italic_V</annotation></semantics></math> is a the of nodes and <math alttext="E" class="ltx_Math" display="inline" id="S3.p4.6.m6.1"><semantics id="S3.p4.6.m6.1a"><mi id="S3.p4.6.m6.1.1" xref="S3.p4.6.m6.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.p4.6.m6.1b"><ci id="S3.p4.6.m6.1.1.cmml" xref="S3.p4.6.m6.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m6.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.p4.6.m6.1d">italic_E</annotation></semantics></math> is a the of hyperedges.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Hypergraph predictor</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.6">The goal of this module is to transform a set of node features <math alttext="\mathbf{X}\in\mathbb{R}^{N\times f}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">ğ—</mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.3.2" xref="S3.SS1.p1.1.m1.1.1.3.3.2.cmml">N</mi><mo id="S3.SS1.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.3.cmml">f</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><in id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1"></in><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ—</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">â„</ci><apply id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3"><times id="S3.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.2">ğ‘</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3.3">ğ‘“</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathbf{X}\in\mathbb{R}^{N\times f}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">bold_X âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_f end_POSTSUPERSCRIPT</annotation></semantics></math> into a set of incidence probabilities <math alttext="\mathbf{P}\in\mathbb{R}^{N\times M}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">ğ</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.cmml">N</mi><mo id="S3.SS1.p1.2.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.cmml">M</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">ğ</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3"><times id="S3.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2">ğ‘</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3">ğ‘€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbf{P}\in\mathbb{R}^{N\times M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">bold_P âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_M end_POSTSUPERSCRIPT</annotation></semantics></math> where <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_N</annotation></semantics></math> represents the number of node and <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_M</annotation></semantics></math> represents the expected number of hyperedges. Each column <math alttext="j\in\{1\dots M\}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">j</mi><mo id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">âˆˆ</mo><mrow id="S3.SS1.p1.5.m5.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.2.cmml"><mo id="S3.SS1.p1.5.m5.1.1.1.1.2" stretchy="false" xref="S3.SS1.p1.5.m5.1.1.1.2.cmml">{</mo><mrow id="S3.SS1.p1.5.m5.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.cmml"><mn id="S3.SS1.p1.5.m5.1.1.1.1.1.2" xref="S3.SS1.p1.5.m5.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS1.p1.5.m5.1.1.1.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.SS1.p1.5.m5.1.1.1.1.1.3" mathvariant="normal" xref="S3.SS1.p1.5.m5.1.1.1.1.1.3.cmml">â€¦</mi><mo id="S3.SS1.p1.5.m5.1.1.1.1.1.1a" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.SS1.p1.5.m5.1.1.1.1.1.4" xref="S3.SS1.p1.5.m5.1.1.1.1.1.4.cmml">M</mi></mrow><mo id="S3.SS1.p1.5.m5.1.1.1.1.3" stretchy="false" xref="S3.SS1.p1.5.m5.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><in id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"></in><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">ğ‘—</ci><set id="S3.SS1.p1.5.m5.1.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1"><apply id="S3.SS1.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1"><times id="S3.SS1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.1"></times><cn id="S3.SS1.p1.5.m5.1.1.1.1.1.2.cmml" type="integer" xref="S3.SS1.p1.5.m5.1.1.1.1.1.2">1</cn><ci id="S3.SS1.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.3">â€¦</ci><ci id="S3.SS1.p1.5.m5.1.1.1.1.1.4.cmml" xref="S3.SS1.p1.5.m5.1.1.1.1.1.4">ğ‘€</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">j\in\{1\dots M\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_j âˆˆ { 1 â€¦ italic_M }</annotation></semantics></math> corresponds to a hyperedge and represents the probability of each node being part of the hyperedge <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_j</annotation></semantics></math>. In order to accurately predict these probabilities, the model needs to have a global understanding of the nodes interactions and identify the subsets that are more likely to exhibit a higher-order relationship.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.6">Taking inspiration from the computer vision literature for unsupervised object detectionÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib44" title="">44</a>]</cite>, we model the hypergraph discovery task as a soft clustering problem, where each cluster correspond to a hyperedge. We adapt the iterative slot-attention algorithmÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib45" title="">45</a>]</cite> to produce <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_M</annotation></semantics></math> clusters, each one corresponding to a predicted hyperedge. The probability of a node <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_i</annotation></semantics></math> being part of a cluster <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_j</annotation></semantics></math>, computed as the node-cluster similarity, represents the incidence probabilities <math alttext="p_{ij}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msub id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">p</mi><mrow id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">i</mi><mo id="S3.SS1.p2.4.m4.1.1.3.1" xref="S3.SS1.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">ğ‘</ci><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><times id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3.1"></times><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">ğ‘–</ci><ci id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3">ğ‘—</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">p_{ij}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_p start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT</annotation></semantics></math> corresponding to node <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">italic_i</annotation></semantics></math> and hyperedge <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_j</annotation></semantics></math>. Therefore, we will use the terms slots and hyperedges interchangeably.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Slot Attention for probabilistic incidence prediction.</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.9">We start by creating <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.1.m1.1d">italic_M</annotation></semantics></math> slots, one for each hyperedge. Each slot <math alttext="s_{j}\in\mathbb{R}^{f}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2.cmml">s</mi><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">â„</mi><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">f</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><in id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1"></in><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.2">ğ‘ </ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2">â„</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">s_{j}\in\mathbb{R}^{f}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT</annotation></semantics></math> is randomly initialized from a normal distribution. At each iteration, the slots representation is updated as the weighted average of all the nodes, with the weights computed as a learnable dot-product similarity as indicated by EquationÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.E1" title="In Slot Attention for probabilistic incidence prediction. â€£ 3.1 Hypergraph predictor â€£ 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">1</span></a>, where <math alttext="f_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml">f</mi><mn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2">ğ‘“</ci><cn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">f_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.3.m3.1d">italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="f_{2}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml">f</mi><mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2">ğ‘“</ci><cn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">f_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.4.m4.1d">italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f_{3}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml">f</mi><mn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2">ğ‘“</ci><cn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">f_{3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.5.m5.1d">italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT</annotation></semantics></math> represent MLPs and <math alttext="\sigma" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.6.m6.1"><semantics id="S3.SS1.SSS0.Px1.p1.6.m6.1a"><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m6.1b"><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m6.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.6.m6.1d">italic_Ïƒ</annotation></semantics></math> is a non-linearity. After <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.7.m7.1"><semantics id="S3.SS1.SSS0.Px1.p1.7.m7.1a"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m7.1b"><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m7.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.7.m7.1d">italic_Q</annotation></semantics></math> iterations, the pairwise similarity between the updated slot representation and the set of node features represents the predicted probability distribution <math alttext="p_{:,j}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.8.m8.2"><semantics id="S3.SS1.SSS0.Px1.p1.8.m8.2a"><msub id="S3.SS1.SSS0.Px1.p1.8.m8.2.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.2.3.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.3.2.cmml">p</mi><mrow id="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.4" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.3.cmml"><mo id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1" rspace="0em" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.cmml">:</mo><mo id="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.4.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m8.2b"><apply id="S3.SS1.SSS0.Px1.p1.8.m8.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m8.2.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.8.m8.2.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.3.2">ğ‘</ci><list id="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.4"><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1">:</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m8.2c">p_{:,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.8.m8.2d">italic_p start_POSTSUBSCRIPT : , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> for hyperedge <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.9.m9.1"><semantics id="S3.SS1.SSS0.Px1.p1.9.m9.1a"><mi id="S3.SS1.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m9.1b"><ci id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m9.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.9.m9.1d">italic_j</annotation></semantics></math>.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A4.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle s_{j}^{q+1}" class="ltx_Math" display="inline" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><msubsup id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">s</mi><mi id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml">j</mi><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml">q</mi><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">+</mo><mn id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1">superscript</csymbol><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">ğ‘ </ci><ci id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3">ğ‘—</ci></apply><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><plus id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1"></plus><ci id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2">ğ‘</ci><cn id="S3.E1.m1.1.1.3.3.cmml" type="integer" xref="S3.E1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle s_{j}^{q+1}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_q + 1 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\sum_{i}\big{(}\sigma(f_{1}(s_{j}^{q})^{T}f_{2}(x_{i}))f_{3}(x_{%
i})\big{)}" class="ltx_Math" display="inline" id="S3.E1.m2.1"><semantics id="S3.E1.m2.1a"><mrow id="S3.E1.m2.1.1" xref="S3.E1.m2.1.1.cmml"><mi id="S3.E1.m2.1.1.3" xref="S3.E1.m2.1.1.3.cmml"></mi><mo id="S3.E1.m2.1.1.2" xref="S3.E1.m2.1.1.2.cmml">=</mo><mrow id="S3.E1.m2.1.1.1" xref="S3.E1.m2.1.1.1.cmml"><mstyle displaystyle="true" id="S3.E1.m2.1.1.1.2" xref="S3.E1.m2.1.1.1.2.cmml"><munder id="S3.E1.m2.1.1.1.2a" xref="S3.E1.m2.1.1.1.2.cmml"><mo id="S3.E1.m2.1.1.1.2.2" movablelimits="false" xref="S3.E1.m2.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.E1.m2.1.1.1.2.3" xref="S3.E1.m2.1.1.1.2.3.cmml">i</mi></munder></mstyle><mrow id="S3.E1.m2.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.cmml"><mo id="S3.E1.m2.1.1.1.1.1.2" maxsize="120%" minsize="120%" xref="S3.E1.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m2.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.4" xref="S3.E1.m2.1.1.1.1.1.1.4.cmml">Ïƒ</mi><mo id="S3.E1.m2.1.1.1.1.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.3.cmml">â¢</mo><mrow id="S3.E1.m2.1.1.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m2.1.1.1.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.2" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.2.cmml">f</mi><mn id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.3.cmml">1</mn></msub><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.3.cmml">â¢</mo><msup id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">s</mi><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">j</mi><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">q</mi></msubsup><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.3.cmml">T</mi></msup><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.3a" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.3.cmml">â¢</mo><msub id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.2" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.2.cmml">f</mi><mn id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.3.cmml">2</mn></msub><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.3b" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.3.cmml">â¢</mo><mrow id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.2" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><msub id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.2" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.2.cmml">x</mi><mi id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.3" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m2.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E1.m2.1.1.1.1.1.1.3a" xref="S3.E1.m2.1.1.1.1.1.1.3.cmml">â¢</mo><msub id="S3.E1.m2.1.1.1.1.1.1.5" xref="S3.E1.m2.1.1.1.1.1.1.5.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.5.2" xref="S3.E1.m2.1.1.1.1.1.1.5.2.cmml">f</mi><mn id="S3.E1.m2.1.1.1.1.1.1.5.3" xref="S3.E1.m2.1.1.1.1.1.1.5.3.cmml">3</mn></msub><mo id="S3.E1.m2.1.1.1.1.1.1.3b" xref="S3.E1.m2.1.1.1.1.1.1.3.cmml">â¢</mo><mrow id="S3.E1.m2.1.1.1.1.1.1.2.1" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.cmml"><mo id="S3.E1.m2.1.1.1.1.1.1.2.1.2" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.cmml">(</mo><msub id="S3.E1.m2.1.1.1.1.1.1.2.1.1" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.cmml"><mi id="S3.E1.m2.1.1.1.1.1.1.2.1.1.2" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.2.cmml">x</mi><mi id="S3.E1.m2.1.1.1.1.1.1.2.1.1.3" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m2.1.1.1.1.1.1.2.1.3" stretchy="false" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m2.1.1.1.1.1.3" maxsize="120%" minsize="120%" xref="S3.E1.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m2.1b"><apply id="S3.E1.m2.1.1.cmml" xref="S3.E1.m2.1.1"><eq id="S3.E1.m2.1.1.2.cmml" xref="S3.E1.m2.1.1.2"></eq><csymbol cd="latexml" id="S3.E1.m2.1.1.3.cmml" xref="S3.E1.m2.1.1.3">absent</csymbol><apply id="S3.E1.m2.1.1.1.cmml" xref="S3.E1.m2.1.1.1"><apply id="S3.E1.m2.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.2.1.cmml" xref="S3.E1.m2.1.1.1.2">subscript</csymbol><sum id="S3.E1.m2.1.1.1.2.2.cmml" xref="S3.E1.m2.1.1.1.2.2"></sum><ci id="S3.E1.m2.1.1.1.2.3.cmml" xref="S3.E1.m2.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E1.m2.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1"><times id="S3.E1.m2.1.1.1.1.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.3"></times><ci id="S3.E1.m2.1.1.1.1.1.1.4.cmml" xref="S3.E1.m2.1.1.1.1.1.1.4">ğœ</ci><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1"><times id="S3.E1.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.3"></times><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.2">ğ‘“</ci><cn id="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.3.cmml" type="integer" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.4.3">1</cn></apply><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘ </ci><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.1.3">ğ‘‡</ci></apply><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.2">ğ‘“</ci><cn id="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.3.cmml" type="integer" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.5.3">2</cn></apply><apply id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.2">ğ‘¥</ci><ci id="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.1.1.1.2.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.E1.m2.1.1.1.1.1.1.5.cmml" xref="S3.E1.m2.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.5.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.5">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.5.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.5.2">ğ‘“</ci><cn id="S3.E1.m2.1.1.1.1.1.1.5.3.cmml" type="integer" xref="S3.E1.m2.1.1.1.1.1.1.5.3">3</cn></apply><apply id="S3.E1.m2.1.1.1.1.1.1.2.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S3.E1.m2.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2.1">subscript</csymbol><ci id="S3.E1.m2.1.1.1.1.1.1.2.1.1.2.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.2">ğ‘¥</ci><ci id="S3.E1.m2.1.1.1.1.1.1.2.1.1.3.cmml" xref="S3.E1.m2.1.1.1.1.1.1.2.1.1.3">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m2.1c">\displaystyle=\sum_{i}\big{(}\sigma(f_{1}(s_{j}^{q})^{T}f_{2}(x_{i}))f_{3}(x_{%
i})\big{)}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m2.1d">= âˆ‘ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_Ïƒ ( italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle p_{i,j}" class="ltx_Math" display="inline" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><msub id="S3.E2.m1.2.3" xref="S3.E2.m1.2.3.cmml"><mi id="S3.E2.m1.2.3.2" xref="S3.E2.m1.2.3.2.cmml">p</mi><mrow id="S3.E2.m1.2.2.2.4" xref="S3.E2.m1.2.2.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">i</mi><mo id="S3.E2.m1.2.2.2.4.1" xref="S3.E2.m1.2.2.2.3.cmml">,</mo><mi id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.3.cmml" xref="S3.E2.m1.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.3.1.cmml" xref="S3.E2.m1.2.3">subscript</csymbol><ci id="S3.E2.m1.2.3.2.cmml" xref="S3.E2.m1.2.3.2">ğ‘</ci><list id="S3.E2.m1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.4"><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">ğ‘–</ci><ci id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\displaystyle p_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.2d">italic_p start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=p(v_{i}\in e_{j})=\sigma(f_{1}(s_{j}^{Q})^{T}f_{2}(x_{i}))" class="ltx_Math" display="inline" id="S3.E2.m2.2"><semantics id="S3.E2.m2.2a"><mrow id="S3.E2.m2.2.2" xref="S3.E2.m2.2.2.cmml"><mi id="S3.E2.m2.2.2.4" xref="S3.E2.m2.2.2.4.cmml"></mi><mo id="S3.E2.m2.2.2.5" xref="S3.E2.m2.2.2.5.cmml">=</mo><mrow id="S3.E2.m2.1.1.1" xref="S3.E2.m2.1.1.1.cmml"><mi id="S3.E2.m2.1.1.1.3" xref="S3.E2.m2.1.1.1.3.cmml">p</mi><mo id="S3.E2.m2.1.1.1.2" xref="S3.E2.m2.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m2.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.cmml"><mo id="S3.E2.m2.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m2.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.cmml"><msub id="S3.E2.m2.1.1.1.1.1.1.2" xref="S3.E2.m2.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m2.1.1.1.1.1.1.2.2" xref="S3.E2.m2.1.1.1.1.1.1.2.2.cmml">v</mi><mi id="S3.E2.m2.1.1.1.1.1.1.2.3" xref="S3.E2.m2.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S3.E2.m2.1.1.1.1.1.1.1" xref="S3.E2.m2.1.1.1.1.1.1.1.cmml">âˆˆ</mo><msub id="S3.E2.m2.1.1.1.1.1.1.3" xref="S3.E2.m2.1.1.1.1.1.1.3.cmml"><mi id="S3.E2.m2.1.1.1.1.1.1.3.2" xref="S3.E2.m2.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E2.m2.1.1.1.1.1.1.3.3" xref="S3.E2.m2.1.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S3.E2.m2.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m2.2.2.6" xref="S3.E2.m2.2.2.6.cmml">=</mo><mrow id="S3.E2.m2.2.2.2" xref="S3.E2.m2.2.2.2.cmml"><mi id="S3.E2.m2.2.2.2.3" xref="S3.E2.m2.2.2.2.3.cmml">Ïƒ</mi><mo id="S3.E2.m2.2.2.2.2" xref="S3.E2.m2.2.2.2.2.cmml">â¢</mo><mrow id="S3.E2.m2.2.2.2.1.1" xref="S3.E2.m2.2.2.2.1.1.1.cmml"><mo id="S3.E2.m2.2.2.2.1.1.2" stretchy="false" xref="S3.E2.m2.2.2.2.1.1.1.cmml">(</mo><mrow id="S3.E2.m2.2.2.2.1.1.1" xref="S3.E2.m2.2.2.2.1.1.1.cmml"><msub id="S3.E2.m2.2.2.2.1.1.1.4" xref="S3.E2.m2.2.2.2.1.1.1.4.cmml"><mi id="S3.E2.m2.2.2.2.1.1.1.4.2" xref="S3.E2.m2.2.2.2.1.1.1.4.2.cmml">f</mi><mn id="S3.E2.m2.2.2.2.1.1.1.4.3" xref="S3.E2.m2.2.2.2.1.1.1.4.3.cmml">1</mn></msub><mo id="S3.E2.m2.2.2.2.1.1.1.3" xref="S3.E2.m2.2.2.2.1.1.1.3.cmml">â¢</mo><msup id="S3.E2.m2.2.2.2.1.1.1.1" xref="S3.E2.m2.2.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m2.2.2.2.1.1.1.1.1.1" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m2.2.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.2.cmml">s</mi><mi id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.3" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.3.cmml">j</mi><mi id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.3.cmml">Q</mi></msubsup><mo id="S3.E2.m2.2.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.E2.m2.2.2.2.1.1.1.1.3" xref="S3.E2.m2.2.2.2.1.1.1.1.3.cmml">T</mi></msup><mo id="S3.E2.m2.2.2.2.1.1.1.3a" xref="S3.E2.m2.2.2.2.1.1.1.3.cmml">â¢</mo><msub id="S3.E2.m2.2.2.2.1.1.1.5" xref="S3.E2.m2.2.2.2.1.1.1.5.cmml"><mi id="S3.E2.m2.2.2.2.1.1.1.5.2" xref="S3.E2.m2.2.2.2.1.1.1.5.2.cmml">f</mi><mn id="S3.E2.m2.2.2.2.1.1.1.5.3" xref="S3.E2.m2.2.2.2.1.1.1.5.3.cmml">2</mn></msub><mo id="S3.E2.m2.2.2.2.1.1.1.3b" xref="S3.E2.m2.2.2.2.1.1.1.3.cmml">â¢</mo><mrow id="S3.E2.m2.2.2.2.1.1.1.2.1" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.cmml"><mo id="S3.E2.m2.2.2.2.1.1.1.2.1.2" stretchy="false" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.cmml">(</mo><msub id="S3.E2.m2.2.2.2.1.1.1.2.1.1" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.cmml"><mi id="S3.E2.m2.2.2.2.1.1.1.2.1.1.2" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.2.cmml">x</mi><mi id="S3.E2.m2.2.2.2.1.1.1.2.1.1.3" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m2.2.2.2.1.1.1.2.1.3" stretchy="false" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m2.2.2.2.1.1.3" stretchy="false" xref="S3.E2.m2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m2.2b"><apply id="S3.E2.m2.2.2.cmml" xref="S3.E2.m2.2.2"><and id="S3.E2.m2.2.2a.cmml" xref="S3.E2.m2.2.2"></and><apply id="S3.E2.m2.2.2b.cmml" xref="S3.E2.m2.2.2"><eq id="S3.E2.m2.2.2.5.cmml" xref="S3.E2.m2.2.2.5"></eq><csymbol cd="latexml" id="S3.E2.m2.2.2.4.cmml" xref="S3.E2.m2.2.2.4">absent</csymbol><apply id="S3.E2.m2.1.1.1.cmml" xref="S3.E2.m2.1.1.1"><times id="S3.E2.m2.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.2"></times><ci id="S3.E2.m2.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.3">ğ‘</ci><apply id="S3.E2.m2.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1"><in id="S3.E2.m2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.1"></in><apply id="S3.E2.m2.1.1.1.1.1.1.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2.2">ğ‘£</ci><ci id="S3.E2.m2.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E2.m2.1.1.1.1.1.1.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m2.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m2.1.1.1.1.1.1.3.3">ğ‘—</ci></apply></apply></apply></apply><apply id="S3.E2.m2.2.2c.cmml" xref="S3.E2.m2.2.2"><eq id="S3.E2.m2.2.2.6.cmml" xref="S3.E2.m2.2.2.6"></eq><share href="https://arxiv.org/html/2410.03208v1#S3.E2.m2.1.1.1.cmml" id="S3.E2.m2.2.2d.cmml" xref="S3.E2.m2.2.2"></share><apply id="S3.E2.m2.2.2.2.cmml" xref="S3.E2.m2.2.2.2"><times id="S3.E2.m2.2.2.2.2.cmml" xref="S3.E2.m2.2.2.2.2"></times><ci id="S3.E2.m2.2.2.2.3.cmml" xref="S3.E2.m2.2.2.2.3">ğœ</ci><apply id="S3.E2.m2.2.2.2.1.1.1.cmml" xref="S3.E2.m2.2.2.2.1.1"><times id="S3.E2.m2.2.2.2.1.1.1.3.cmml" xref="S3.E2.m2.2.2.2.1.1.1.3"></times><apply id="S3.E2.m2.2.2.2.1.1.1.4.cmml" xref="S3.E2.m2.2.2.2.1.1.1.4"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.1.1.1.4.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.4">subscript</csymbol><ci id="S3.E2.m2.2.2.2.1.1.1.4.2.cmml" xref="S3.E2.m2.2.2.2.1.1.1.4.2">ğ‘“</ci><cn id="S3.E2.m2.2.2.2.1.1.1.4.3.cmml" type="integer" xref="S3.E2.m2.2.2.2.1.1.1.4.3">1</cn></apply><apply id="S3.E2.m2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.1.1.1.1.2.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1">superscript</csymbol><apply id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.2">ğ‘ </ci><ci id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.1.1.1.3">ğ‘„</ci></apply><ci id="S3.E2.m2.2.2.2.1.1.1.1.3.cmml" xref="S3.E2.m2.2.2.2.1.1.1.1.3">ğ‘‡</ci></apply><apply id="S3.E2.m2.2.2.2.1.1.1.5.cmml" xref="S3.E2.m2.2.2.2.1.1.1.5"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.1.1.1.5.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.5">subscript</csymbol><ci id="S3.E2.m2.2.2.2.1.1.1.5.2.cmml" xref="S3.E2.m2.2.2.2.1.1.1.5.2">ğ‘“</ci><cn id="S3.E2.m2.2.2.2.1.1.1.5.3.cmml" type="integer" xref="S3.E2.m2.2.2.2.1.1.1.5.3">2</cn></apply><apply id="S3.E2.m2.2.2.2.1.1.1.2.1.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.2.1"><csymbol cd="ambiguous" id="S3.E2.m2.2.2.2.1.1.1.2.1.1.1.cmml" xref="S3.E2.m2.2.2.2.1.1.1.2.1">subscript</csymbol><ci id="S3.E2.m2.2.2.2.1.1.1.2.1.1.2.cmml" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.2">ğ‘¥</ci><ci id="S3.E2.m2.2.2.2.1.1.1.2.1.1.3.cmml" xref="S3.E2.m2.2.2.2.1.1.1.2.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m2.2c">\displaystyle=p(v_{i}\in e_{j})=\sigma(f_{1}(s_{j}^{Q})^{T}f_{2}(x_{i}))</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m2.2d">= italic_p ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = italic_Ïƒ ( italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.10">Note that this procedure is similar to a differentiable <math alttext="k" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.10.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.10.m1.1a"><mi id="S3.SS1.SSS0.Px1.p1.10.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.10.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.10.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.10.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.10.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.10.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.10.m1.1d">italic_k</annotation></semantics></math>-means clusterization, where the hyperedges represent the centroids and the similarity coefficient represent the soft assignment corresponding to each node-cluster pair. At a high level, the probability of a node being part of a hyperedge can be interpreted as the likelihood of an element being assigned to a certain cluster.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Sequential Slot Attention for solving ambiguities.</h4>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">The above algorithm suffers from a strong limitation. Due to the symmetries exhibited by the set of hyperedges, independently inferring <math alttext="M" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p1.1.m1.1d">italic_M</annotation></semantics></math> hyperedges leads to strong ambiguity issues. Concretely, since the slots are initialized randomly, there is no mechanism in place to distribute the hyperedges between slots: multiple slots could be attached to the same obvious hyperedge, leaving others completely uncovered.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p2.9">To alleviate this, we propose a sequential slot attention. Instead of predicting all hyperedges simultaneously, we will predict them sequentially, one at a time, ensuring that at each timestep the hyperedge prediction mechanism is aware of the hyperedges predicted so far. To achieve that, the features of each node <math alttext="x_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.1.m1.1"><semantics id="S3.SS1.SSS0.Px2.p2.1.m1.1a"><msub id="S3.SS1.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is enriched with an additional binary vector <math alttext="b_{i}\in\{0,1\}^{(M-1)}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.2.m2.3"><semantics id="S3.SS1.SSS0.Px2.p2.2.m2.3a"><mrow id="S3.SS1.SSS0.Px2.p2.2.m2.3.4" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.cmml"><msub id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.cmml"><mi id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.2" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.2.cmml">b</mi><mi id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.3" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.1" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.cmml"><mrow id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.2" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.1.cmml"><mo id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.2.1" stretchy="false" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.1.cmml">{</mo><mn id="S3.SS1.SSS0.Px2.p2.2.m2.2.2" xref="S3.SS1.SSS0.Px2.p2.2.m2.2.2.cmml">0</mn><mo id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.2.2" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.1.cmml">,</mo><mn id="S3.SS1.SSS0.Px2.p2.2.m2.3.3" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.3.cmml">1</mn><mo id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.2.3" stretchy="false" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.1.cmml">}</mo></mrow><mrow id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.cmml">M</mi><mo id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.1" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.3" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.2.m2.3b"><apply id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4"><in id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.1"></in><apply id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.2">ğ‘</ci><ci id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.2.3">ğ‘–</ci></apply><apply id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3">superscript</csymbol><set id="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.4.3.2.2"><cn id="S3.SS1.SSS0.Px2.p2.2.m2.2.2.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p2.2.m2.2.2">0</cn><cn id="S3.SS1.SSS0.Px2.p2.2.m2.3.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p2.2.m2.3.3">1</cn></set><apply id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1"><minus id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.1"></minus><ci id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.2">ğ‘€</ci><cn id="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p2.2.m2.1.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.2.m2.3c">b_{i}\in\{0,1\}^{(M-1)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.2.m2.3d">italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ { 0 , 1 } start_POSTSUPERSCRIPT ( italic_M - 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math> indicating the relationship between that node and the previously predicted hypergraphs. Specifically, when predicting hyperedge <math alttext="j" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.3.m3.1"><semantics id="S3.SS1.SSS0.Px2.p2.3.m3.1a"><mi id="S3.SS1.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.3.m3.1b"><ci id="S3.SS1.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.3.m3.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.3.m3.1d">italic_j</annotation></semantics></math>, for each previous hyperedge <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.4.m4.1"><semantics id="S3.SS1.SSS0.Px2.p2.4.m4.1a"><mi id="S3.SS1.SSS0.Px2.p2.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.4.m4.1b"><ci id="S3.SS1.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.4.m4.1d">italic_t</annotation></semantics></math> (<math alttext="t&lt;j" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.5.m5.1"><semantics id="S3.SS1.SSS0.Px2.p2.5.m5.1a"><mrow id="S3.SS1.SSS0.Px2.p2.5.m5.1.1" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.cmml">t</mi><mo id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1.cmml">&lt;</mo><mi id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.5.m5.1b"><apply id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1"><lt id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.1"></lt><ci id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.2">ğ‘¡</ci><ci id="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p2.5.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.5.m5.1c">t&lt;j</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.5.m5.1d">italic_t &lt; italic_j</annotation></semantics></math>), <math alttext="b_{it}=1" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.6.m6.1"><semantics id="S3.SS1.SSS0.Px2.p2.6.m6.1a"><mrow id="S3.SS1.SSS0.Px2.p2.6.m6.1.1" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.2" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.2.cmml">b</mi><mrow id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.2" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.2.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.1" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.3" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.3.cmml">t</mi></mrow></msub><mo id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.1" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.3" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.6.m6.1b"><apply id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1"><eq id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.1"></eq><apply id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.2">ğ‘</ci><apply id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3"><times id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.1"></times><ci id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.2.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.2">ğ‘–</ci><ci id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.3.cmml" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.2.3.3">ğ‘¡</ci></apply></apply><cn id="S3.SS1.SSS0.Px2.p2.6.m6.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.6.m6.1c">b_{it}=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.6.m6.1d">italic_b start_POSTSUBSCRIPT italic_i italic_t end_POSTSUBSCRIPT = 1</annotation></semantics></math> if the node <math alttext="i" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.7.m7.1"><semantics id="S3.SS1.SSS0.Px2.p2.7.m7.1a"><mi id="S3.SS1.SSS0.Px2.p2.7.m7.1.1" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.7.m7.1b"><ci id="S3.SS1.SSS0.Px2.p2.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.7.m7.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.7.m7.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.7.m7.1d">italic_i</annotation></semantics></math> was previously selected to be part of the hyperedge <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.8.m8.1"><semantics id="S3.SS1.SSS0.Px2.p2.8.m8.1a"><mi id="S3.SS1.SSS0.Px2.p2.8.m8.1.1" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.8.m8.1b"><ci id="S3.SS1.SSS0.Px2.p2.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.8.m8.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.8.m8.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.8.m8.1d">italic_t</annotation></semantics></math> and <math alttext="b_{it}=0" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px2.p2.9.m9.1"><semantics id="S3.SS1.SSS0.Px2.p2.9.m9.1a"><mrow id="S3.SS1.SSS0.Px2.p2.9.m9.1.1" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml"><msub id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.cmml"><mi id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.2" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.2.cmml">b</mi><mrow id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.cmml"><mi id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.2" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.2.cmml">i</mi><mo id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.1" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.1.cmml">â¢</mo><mi id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.3" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.3.cmml">t</mi></mrow></msub><mo id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.1" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p2.9.m9.1b"><apply id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1"><eq id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.1"></eq><apply id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.1.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.2">ğ‘</ci><apply id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3"><times id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.1.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.1"></times><ci id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.2.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.2">ğ‘–</ci><ci id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.3.cmml" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.2.3.3">ğ‘¡</ci></apply></apply><cn id="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px2.p2.9.m9.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p2.9.m9.1c">b_{it}=0</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px2.p2.9.m9.1d">italic_b start_POSTSUBSCRIPT italic_i italic_t end_POSTSUBSCRIPT = 0</annotation></semantics></math> otherwise. This way, the slot-attention algorithm has the capacity to produce more diverse hyperedges, as we experimentally validated in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.SS1" title="4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">4.1</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Discrete constrained sampling</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">The hypergraph predictor module, as described above, produces a probabilistic incidence matrix <math alttext="\mathbf{P}\in\mathbb{R}^{N\times M}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">ğ</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">â„</mi><mrow id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.2" xref="S3.SS2.p1.1.m1.1.1.3.3.2.cmml">N</mi><mo id="S3.SS2.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS2.p1.1.m1.1.1.3.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.3.cmml">M</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><in id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></in><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">â„</ci><apply id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3"><times id="S3.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2">ğ‘</ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3">ğ‘€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathbf{P}\in\mathbb{R}^{N\times M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">bold_P âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_M end_POSTSUPERSCRIPT</annotation></semantics></math>, where each element <math alttext="p_{i,j}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.2"><semantics id="S3.SS2.p1.2.m2.2a"><msub id="S3.SS2.p1.2.m2.2.3" xref="S3.SS2.p1.2.m2.2.3.cmml"><mi id="S3.SS2.p1.2.m2.2.3.2" xref="S3.SS2.p1.2.m2.2.3.2.cmml">p</mi><mrow id="S3.SS2.p1.2.m2.2.2.2.4" xref="S3.SS2.p1.2.m2.2.2.2.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p1.2.m2.2.2.2.4.1" xref="S3.SS2.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p1.2.m2.2.2.2.2" xref="S3.SS2.p1.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.2b"><apply id="S3.SS2.p1.2.m2.2.3.cmml" xref="S3.SS2.p1.2.m2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.3.1.cmml" xref="S3.SS2.p1.2.m2.2.3">subscript</csymbol><ci id="S3.SS2.p1.2.m2.2.3.2.cmml" xref="S3.SS2.p1.2.m2.2.3.2">ğ‘</ci><list id="S3.SS2.p1.2.m2.2.2.2.3.cmml" xref="S3.SS2.p1.2.m2.2.2.2.4"><ci id="S3.SS2.p1.2.m2.1.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1.1">ğ‘–</ci><ci id="S3.SS2.p1.2.m2.2.2.2.2.cmml" xref="S3.SS2.p1.2.m2.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.2c">p_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.2d">italic_p start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> denotes the probability of a node <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_i</annotation></semantics></math> being part of the hyperedge <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_j</annotation></semantics></math>. However, the standard hypergraph neural network architectures are designed to work with discrete rather than probabilistic structures.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">Previous workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib43" title="">43</a>]</cite> employs Gumbel-SoftmaxÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib10" title="">10</a>]</cite> to sample from a categorical distribution in a differentiable way. However, these techniques sample each element in the hyperedge independently, without any control on the cardinality of the hyperedge. This leads to unstable optimisation, that requires additional training strategies such as specific sparsity regularisation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3">To address this issue, we are leveraging the recent advancement in constrained <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_k</annotation></semantics></math>-subset samplingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib46" title="">46</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib9" title="">9</a>]</cite>. These methods were successfully used to tackle discrete problems such as combinatorical optimisation, learning explanations and, more recently, rewiring graph topologyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib47" title="">47</a>]</cite>. Different than classical differentiable samplersÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib10" title="">10</a>]</cite>, the <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_k</annotation></semantics></math>-subset sampler would produce a subset of size exactly <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_k</annotation></semantics></math>, equipped with a gradient estimator useful for backpropagation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.4">In our work, we took advantage of these recent advancements and apply it to produce a discrete incidence matrix from the probabilities inferred by the slot attention algorithm.
Concretely, given the probability distribution <math alttext="p_{:,j}" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.2"><semantics id="S3.SS2.p4.1.m1.2a"><msub id="S3.SS2.p4.1.m1.2.3" xref="S3.SS2.p4.1.m1.2.3.cmml"><mi id="S3.SS2.p4.1.m1.2.3.2" xref="S3.SS2.p4.1.m1.2.3.2.cmml">p</mi><mrow id="S3.SS2.p4.1.m1.2.2.2.4" xref="S3.SS2.p4.1.m1.2.2.2.3.cmml"><mo id="S3.SS2.p4.1.m1.1.1.1.1" rspace="0em" xref="S3.SS2.p4.1.m1.1.1.1.1.cmml">:</mo><mo id="S3.SS2.p4.1.m1.2.2.2.4.1" xref="S3.SS2.p4.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p4.1.m1.2.2.2.2" xref="S3.SS2.p4.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.2b"><apply id="S3.SS2.p4.1.m1.2.3.cmml" xref="S3.SS2.p4.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.2.3.1.cmml" xref="S3.SS2.p4.1.m1.2.3">subscript</csymbol><ci id="S3.SS2.p4.1.m1.2.3.2.cmml" xref="S3.SS2.p4.1.m1.2.3.2">ğ‘</ci><list id="S3.SS2.p4.1.m1.2.2.2.3.cmml" xref="S3.SS2.p4.1.m1.2.2.2.4"><ci id="S3.SS2.p4.1.m1.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1.1.1">:</ci><ci id="S3.SS2.p4.1.m1.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.2c">p_{:,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.2d">italic_p start_POSTSUBSCRIPT : , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> for each hyperedge <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mi id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_j</annotation></semantics></math>, the discrete sampler would select a subset of nodes, representing the group of nodes forming the hyperedge. As demonstrated in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.SS1" title="4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">4.1</span></a>, by ensuring that each hyperedge contains exactly <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_k</annotation></semantics></math> elements, this approach improves over the previous techniques, manifesting an easier optimisation. While the cardinality <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><mi id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">italic_k</annotation></semantics></math> needs to be set apriori, as a hyperparameter, this value can vary between different hyperedges.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Hypergraph processing</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.2">Producing a discrete hypergraph structure and being able to propagate the gradient through the entire pipeline, enable us to process the resulting latent hypergraph with any existing architecture designed for higher-order representations.
In the recent years, several architectures were developed for hypergraph-structured inputÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib48" title="">48</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib28" title="">28</a>]</cite>. Most of them are following the general two-stage message-passing framework.
In the first stage, the information is sent from nodes to the hyperedges using a permutation-invariant operator <math alttext="z_{j}=f_{V\rightarrow E}(\{x_{i}|v_{i}\in e_{j}\})" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mrow id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">z</mi><mi id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">j</mi></msub><mo id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">=</mo><mrow id="S3.SS3.p1.1.m1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml"><msub id="S3.SS3.p1.1.m1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.1.3.2.cmml">f</mi><mrow id="S3.SS3.p1.1.m1.1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.1.3.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.3.3.2" xref="S3.SS3.p1.1.m1.1.1.1.3.3.2.cmml">V</mi><mo id="S3.SS3.p1.1.m1.1.1.1.3.3.1" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.3.3.1.cmml">â†’</mo><mi id="S3.SS3.p1.1.m1.1.1.1.3.3.3" xref="S3.SS3.p1.1.m1.1.1.1.3.3.3.cmml">E</mi></mrow></msub><mo id="S3.SS3.p1.1.m1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.cmml"><mo id="S3.SS3.p1.1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml"><mo id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.3" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.3.1.cmml">{</mo><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.4" lspace="0em" rspace="0em" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.3.1.cmml">|</mo><mrow id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.cmml"><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.2.cmml">v</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.1" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.1.cmml">âˆˆ</mo><msub id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.2" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.2.cmml">e</mi><mi id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.3" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.3.cmml">j</mi></msub></mrow><mo id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.5" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.3.1.cmml">}</mo></mrow><mo id="S3.SS3.p1.1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.1.m1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><eq id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2"></eq><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">ğ‘§</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">ğ‘—</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1"><times id="S3.SS3.p1.1.m1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.2"></times><apply id="S3.SS3.p1.1.m1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3.2">ğ‘“</ci><apply id="S3.SS3.p1.1.m1.1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3.3"><ci id="S3.SS3.p1.1.m1.1.1.1.3.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3.3.1">â†’</ci><ci id="S3.SS3.p1.1.m1.1.1.1.3.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3.3.2">ğ‘‰</ci><ci id="S3.SS3.p1.1.m1.1.1.1.3.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.3.3.3">ğ¸</ci></apply></apply><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.3">conditional-set</csymbol><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2"><in id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.1"></in><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.2">ğ‘£</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.2">ğ‘’</ci><ci id="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.1.1.1.1.2.2.3.3">ğ‘—</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">z_{j}=f_{V\rightarrow E}(\{x_{i}|v_{i}\in e_{j}\})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_V â†’ italic_E end_POSTSUBSCRIPT ( { italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } )</annotation></semantics></math>. On the second stage the messages are sent back from hyperedge to nodes <math alttext="x_{i}=f_{E\rightarrow V}(\{z_{j}|v_{i}\in e_{j}\})" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><msub id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">x</mi><mi id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3.cmml">i</mi></msub><mo id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml"><msub id="S3.SS3.p1.2.m2.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.1.3.2.cmml">f</mi><mrow id="S3.SS3.p1.2.m2.1.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.1.3.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.3.3.2" xref="S3.SS3.p1.2.m2.1.1.1.3.3.2.cmml">E</mi><mo id="S3.SS3.p1.2.m2.1.1.1.3.3.1" stretchy="false" xref="S3.SS3.p1.2.m2.1.1.1.3.3.1.cmml">â†’</mo><mi id="S3.SS3.p1.2.m2.1.1.1.3.3.3" xref="S3.SS3.p1.2.m2.1.1.1.3.3.3.cmml">V</mi></mrow></msub><mo id="S3.SS3.p1.2.m2.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS3.p1.2.m2.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml"><mo id="S3.SS3.p1.2.m2.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p1.2.m2.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.cmml"><mo id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.3" stretchy="false" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.1.cmml">{</mo><msub id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.3" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.4" lspace="0em" rspace="0em" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.1.cmml">|</mo><mrow id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.cmml"><msub id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.2.cmml">v</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.3" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.1" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.1.cmml">âˆˆ</mo><msub id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.cmml"><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.2" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.2.cmml">e</mi><mi id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.3" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.3.cmml">j</mi></msub></mrow><mo id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.5" stretchy="false" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.1.cmml">}</mo></mrow><mo id="S3.SS3.p1.2.m2.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p1.2.m2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><eq id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2"></eq><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">ğ‘¥</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"><times id="S3.SS3.p1.2.m2.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.2"></times><apply id="S3.SS3.p1.2.m2.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.2">ğ‘“</ci><apply id="S3.SS3.p1.2.m2.1.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.3"><ci id="S3.SS3.p1.2.m2.1.1.1.3.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.3.1">â†’</ci><ci id="S3.SS3.p1.2.m2.1.1.1.3.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.3.2">ğ¸</ci><ci id="S3.SS3.p1.2.m2.1.1.1.3.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.3.3.3">ğ‘‰</ci></apply></apply><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2"><csymbol cd="latexml" id="S3.SS3.p1.2.m2.1.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.3">conditional-set</csymbol><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2"><in id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.1"></in><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.2">ğ‘£</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.2.3">ğ‘–</ci></apply><apply id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.2">ğ‘’</ci><ci id="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.1.1.1.1.2.2.3.3">ğ‘—</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">x_{i}=f_{E\rightarrow V}(\{z_{j}|v_{i}\in e_{j}\})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_E â†’ italic_V end_POSTSUBSCRIPT ( { italic_z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.2">In our experiments we use a similar setup to the one proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib28" title="">28</a>]</cite>, in which the two functions <math alttext="f_{V\rightarrow E}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">f</mi><mrow id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.p2.1.m1.1.1.3.2" xref="S3.SS3.p2.1.m1.1.1.3.2.cmml">V</mi><mo id="S3.SS3.p2.1.m1.1.1.3.1" stretchy="false" xref="S3.SS3.p2.1.m1.1.1.3.1.cmml">â†’</mo><mi id="S3.SS3.p2.1.m1.1.1.3.3" xref="S3.SS3.p2.1.m1.1.1.3.3.cmml">E</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ğ‘“</ci><apply id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3"><ci id="S3.SS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.p2.1.m1.1.1.3.1">â†’</ci><ci id="S3.SS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.p2.1.m1.1.1.3.2">ğ‘‰</ci><ci id="S3.SS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3.3">ğ¸</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">f_{V\rightarrow E}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_f start_POSTSUBSCRIPT italic_V â†’ italic_E end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="f_{E\rightarrow V}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">f</mi><mrow id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS3.p2.2.m2.1.1.3.2" xref="S3.SS3.p2.2.m2.1.1.3.2.cmml">E</mi><mo id="S3.SS3.p2.2.m2.1.1.3.1" stretchy="false" xref="S3.SS3.p2.2.m2.1.1.3.1.cmml">â†’</mo><mi id="S3.SS3.p2.2.m2.1.1.3.3" xref="S3.SS3.p2.2.m2.1.1.3.3.cmml">V</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">ğ‘“</ci><apply id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3"><ci id="S3.SS3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS3.p2.2.m2.1.1.3.1">â†’</ci><ci id="S3.SS3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS3.p2.2.m2.1.1.3.2">ğ¸</ci><ci id="S3.SS3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3.3">ğ‘‰</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">f_{E\rightarrow V}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_f start_POSTSUBSCRIPT italic_E â†’ italic_V end_POSTSUBSCRIPT</annotation></semantics></math> are implemented as DeepSetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib29" title="">29</a>]</cite> models.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A4.EGx2">
<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle f_{V\rightarrow E}(S)=f_{E\rightarrow V}(S)=\text{MLP}(\sum_{s%
\in S}(\text{MLP}(s)))" class="ltx_Math" display="inline" id="S3.Ex1.m1.4"><semantics id="S3.Ex1.m1.4a"><mrow id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.4.4.cmml"><mrow id="S3.Ex1.m1.4.4.3" xref="S3.Ex1.m1.4.4.3.cmml"><msub id="S3.Ex1.m1.4.4.3.2" xref="S3.Ex1.m1.4.4.3.2.cmml"><mi id="S3.Ex1.m1.4.4.3.2.2" xref="S3.Ex1.m1.4.4.3.2.2.cmml">f</mi><mrow id="S3.Ex1.m1.4.4.3.2.3" xref="S3.Ex1.m1.4.4.3.2.3.cmml"><mi id="S3.Ex1.m1.4.4.3.2.3.2" xref="S3.Ex1.m1.4.4.3.2.3.2.cmml">V</mi><mo id="S3.Ex1.m1.4.4.3.2.3.1" stretchy="false" xref="S3.Ex1.m1.4.4.3.2.3.1.cmml">â†’</mo><mi id="S3.Ex1.m1.4.4.3.2.3.3" xref="S3.Ex1.m1.4.4.3.2.3.3.cmml">E</mi></mrow></msub><mo id="S3.Ex1.m1.4.4.3.1" xref="S3.Ex1.m1.4.4.3.1.cmml">â¢</mo><mrow id="S3.Ex1.m1.4.4.3.3.2" xref="S3.Ex1.m1.4.4.3.cmml"><mo id="S3.Ex1.m1.4.4.3.3.2.1" stretchy="false" xref="S3.Ex1.m1.4.4.3.cmml">(</mo><mi id="S3.Ex1.m1.1.1" xref="S3.Ex1.m1.1.1.cmml">S</mi><mo id="S3.Ex1.m1.4.4.3.3.2.2" stretchy="false" xref="S3.Ex1.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.4.4.4" xref="S3.Ex1.m1.4.4.4.cmml">=</mo><mrow id="S3.Ex1.m1.4.4.5" xref="S3.Ex1.m1.4.4.5.cmml"><msub id="S3.Ex1.m1.4.4.5.2" xref="S3.Ex1.m1.4.4.5.2.cmml"><mi id="S3.Ex1.m1.4.4.5.2.2" xref="S3.Ex1.m1.4.4.5.2.2.cmml">f</mi><mrow id="S3.Ex1.m1.4.4.5.2.3" xref="S3.Ex1.m1.4.4.5.2.3.cmml"><mi id="S3.Ex1.m1.4.4.5.2.3.2" xref="S3.Ex1.m1.4.4.5.2.3.2.cmml">E</mi><mo id="S3.Ex1.m1.4.4.5.2.3.1" stretchy="false" xref="S3.Ex1.m1.4.4.5.2.3.1.cmml">â†’</mo><mi id="S3.Ex1.m1.4.4.5.2.3.3" xref="S3.Ex1.m1.4.4.5.2.3.3.cmml">V</mi></mrow></msub><mo id="S3.Ex1.m1.4.4.5.1" xref="S3.Ex1.m1.4.4.5.1.cmml">â¢</mo><mrow id="S3.Ex1.m1.4.4.5.3.2" xref="S3.Ex1.m1.4.4.5.cmml"><mo id="S3.Ex1.m1.4.4.5.3.2.1" stretchy="false" xref="S3.Ex1.m1.4.4.5.cmml">(</mo><mi id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml">S</mi><mo id="S3.Ex1.m1.4.4.5.3.2.2" stretchy="false" xref="S3.Ex1.m1.4.4.5.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.4.4.6" xref="S3.Ex1.m1.4.4.6.cmml">=</mo><mrow id="S3.Ex1.m1.4.4.1" xref="S3.Ex1.m1.4.4.1.cmml"><mtext id="S3.Ex1.m1.4.4.1.3" xref="S3.Ex1.m1.4.4.1.3a.cmml">MLP</mtext><mo id="S3.Ex1.m1.4.4.1.2" xref="S3.Ex1.m1.4.4.1.2.cmml">â¢</mo><mrow id="S3.Ex1.m1.4.4.1.1.1" xref="S3.Ex1.m1.4.4.1.1.1.1.cmml"><mo id="S3.Ex1.m1.4.4.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.4.4.1.1.1.1" xref="S3.Ex1.m1.4.4.1.1.1.1.cmml"><mstyle displaystyle="true" id="S3.Ex1.m1.4.4.1.1.1.1.2" xref="S3.Ex1.m1.4.4.1.1.1.1.2.cmml"><munder id="S3.Ex1.m1.4.4.1.1.1.1.2a" xref="S3.Ex1.m1.4.4.1.1.1.1.2.cmml"><mo id="S3.Ex1.m1.4.4.1.1.1.1.2.2" movablelimits="false" xref="S3.Ex1.m1.4.4.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.Ex1.m1.4.4.1.1.1.1.2.3" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.cmml"><mi id="S3.Ex1.m1.4.4.1.1.1.1.2.3.2" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.2.cmml">s</mi><mo id="S3.Ex1.m1.4.4.1.1.1.1.2.3.1" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.1.cmml">âˆˆ</mo><mi id="S3.Ex1.m1.4.4.1.1.1.1.2.3.3" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.3.cmml">S</mi></mrow></munder></mstyle><mrow id="S3.Ex1.m1.4.4.1.1.1.1.1.1" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.4.4.1.1.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml"><mtext id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.2a.cmml">MLP</mtext><mo id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.1.cmml">â¢</mo><mrow id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.3.2" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml"><mo id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml">(</mo><mi id="S3.Ex1.m1.3.3" xref="S3.Ex1.m1.3.3.cmml">s</mi><mo id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.4.4.1.1.1.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.4.4.1.1.1.3" stretchy="false" xref="S3.Ex1.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.4b"><apply id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4"><and id="S3.Ex1.m1.4.4a.cmml" xref="S3.Ex1.m1.4.4"></and><apply id="S3.Ex1.m1.4.4b.cmml" xref="S3.Ex1.m1.4.4"><eq id="S3.Ex1.m1.4.4.4.cmml" xref="S3.Ex1.m1.4.4.4"></eq><apply id="S3.Ex1.m1.4.4.3.cmml" xref="S3.Ex1.m1.4.4.3"><times id="S3.Ex1.m1.4.4.3.1.cmml" xref="S3.Ex1.m1.4.4.3.1"></times><apply id="S3.Ex1.m1.4.4.3.2.cmml" xref="S3.Ex1.m1.4.4.3.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.4.4.3.2.1.cmml" xref="S3.Ex1.m1.4.4.3.2">subscript</csymbol><ci id="S3.Ex1.m1.4.4.3.2.2.cmml" xref="S3.Ex1.m1.4.4.3.2.2">ğ‘“</ci><apply id="S3.Ex1.m1.4.4.3.2.3.cmml" xref="S3.Ex1.m1.4.4.3.2.3"><ci id="S3.Ex1.m1.4.4.3.2.3.1.cmml" xref="S3.Ex1.m1.4.4.3.2.3.1">â†’</ci><ci id="S3.Ex1.m1.4.4.3.2.3.2.cmml" xref="S3.Ex1.m1.4.4.3.2.3.2">ğ‘‰</ci><ci id="S3.Ex1.m1.4.4.3.2.3.3.cmml" xref="S3.Ex1.m1.4.4.3.2.3.3">ğ¸</ci></apply></apply><ci id="S3.Ex1.m1.1.1.cmml" xref="S3.Ex1.m1.1.1">ğ‘†</ci></apply><apply id="S3.Ex1.m1.4.4.5.cmml" xref="S3.Ex1.m1.4.4.5"><times id="S3.Ex1.m1.4.4.5.1.cmml" xref="S3.Ex1.m1.4.4.5.1"></times><apply id="S3.Ex1.m1.4.4.5.2.cmml" xref="S3.Ex1.m1.4.4.5.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.4.4.5.2.1.cmml" xref="S3.Ex1.m1.4.4.5.2">subscript</csymbol><ci id="S3.Ex1.m1.4.4.5.2.2.cmml" xref="S3.Ex1.m1.4.4.5.2.2">ğ‘“</ci><apply id="S3.Ex1.m1.4.4.5.2.3.cmml" xref="S3.Ex1.m1.4.4.5.2.3"><ci id="S3.Ex1.m1.4.4.5.2.3.1.cmml" xref="S3.Ex1.m1.4.4.5.2.3.1">â†’</ci><ci id="S3.Ex1.m1.4.4.5.2.3.2.cmml" xref="S3.Ex1.m1.4.4.5.2.3.2">ğ¸</ci><ci id="S3.Ex1.m1.4.4.5.2.3.3.cmml" xref="S3.Ex1.m1.4.4.5.2.3.3">ğ‘‰</ci></apply></apply><ci id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2">ğ‘†</ci></apply></apply><apply id="S3.Ex1.m1.4.4c.cmml" xref="S3.Ex1.m1.4.4"><eq id="S3.Ex1.m1.4.4.6.cmml" xref="S3.Ex1.m1.4.4.6"></eq><share href="https://arxiv.org/html/2410.03208v1#S3.Ex1.m1.4.4.5.cmml" id="S3.Ex1.m1.4.4d.cmml" xref="S3.Ex1.m1.4.4"></share><apply id="S3.Ex1.m1.4.4.1.cmml" xref="S3.Ex1.m1.4.4.1"><times id="S3.Ex1.m1.4.4.1.2.cmml" xref="S3.Ex1.m1.4.4.1.2"></times><ci id="S3.Ex1.m1.4.4.1.3a.cmml" xref="S3.Ex1.m1.4.4.1.3"><mtext id="S3.Ex1.m1.4.4.1.3.cmml" xref="S3.Ex1.m1.4.4.1.3">MLP</mtext></ci><apply id="S3.Ex1.m1.4.4.1.1.1.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1"><apply id="S3.Ex1.m1.4.4.1.1.1.1.2.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.4.4.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2">subscript</csymbol><sum id="S3.Ex1.m1.4.4.1.1.1.1.2.2.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2.2"></sum><apply id="S3.Ex1.m1.4.4.1.1.1.1.2.3.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3"><in id="S3.Ex1.m1.4.4.1.1.1.1.2.3.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.1"></in><ci id="S3.Ex1.m1.4.4.1.1.1.1.2.3.2.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.2">ğ‘ </ci><ci id="S3.Ex1.m1.4.4.1.1.1.1.2.3.3.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.2.3.3">ğ‘†</ci></apply></apply><apply id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1"><times id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.1"></times><ci id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.2a.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.2"><mtext id="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.4.4.1.1.1.1.1.1.1.2">MLP</mtext></ci><ci id="S3.Ex1.m1.3.3.cmml" xref="S3.Ex1.m1.3.3">ğ‘ </ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.4c">\displaystyle f_{V\rightarrow E}(S)=f_{E\rightarrow V}(S)=\text{MLP}(\sum_{s%
\in S}(\text{MLP}(s)))</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.4d">italic_f start_POSTSUBSCRIPT italic_V â†’ italic_E end_POSTSUBSCRIPT ( italic_S ) = italic_f start_POSTSUBSCRIPT italic_E â†’ italic_V end_POSTSUBSCRIPT ( italic_S ) = MLP ( âˆ‘ start_POSTSUBSCRIPT italic_s âˆˆ italic_S end_POSTSUBSCRIPT ( MLP ( italic_s ) ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p2.3">Note that, although we experimented primarily with the architecture presented above, the framework is general enough to be used with any other hypergraph network. Our experiments demonstrated that even simpler hypergraph models enable the discovery of accurate higher-order structures.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Analysis</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">While the importance of higher-order processing is widely accepted in the machine learning communityÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib49" title="">49</a>]</cite> and beyondÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib50" title="">50</a>]</cite>, the amount of benchmarks developed to properly validate the hypergraph methods is still insufficient. This issue becomes even more pronounced when it comes to latent hypergraph inference. Although there is evidence that many existing real-world tasks exhibit underlining higher-order interactions that can be beneficial to capture, evaluating the capability of a neural network to predict the latent structure remains challenging. First, the input features should contain enough information to predict the hypergraph structure. Secondly, even if we do not need the hypergraph structure as a supervision signal, having access to it is necessary to properly evaluate to what extent the model learns to infer the correct structure.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">To alleviate these shortcomings, current works adopt one of the following approaches: either using synthetic data, where we can directly have access to the higher-order relationships used to generate the outcome, or by using real-world data and only evaluate the capability of the model to improve the final prediction, without directly computing the accuracy of the discovered latent structure.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">In our work we adopt both of these approaches. First, we will perform an in depth ablation study on a synthetic dataset containing particle simulations. Then, we will move on to the NBA real-world dataset where we will evaluate to what extent our latent hypergraph structure improves the trajectory prediction performance. Our goal is two fold. We show that our model is capable of learning an appropriate latent hypergraph structure in an unsupervised way. Additionally, we prove that the latent higher-order structure, learnt jointly with the rest of the model, helps the performance of the downstream task.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Particle Simulations</h3>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.F3.3" style="width:190.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="718" id="S4.F3.1.g1" src="extracted/5900948/figures/synthetic_exp.png" width="598"/>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> <span class="ltx_text ltx_font_bold" id="S4.F3.3.8.1">Ablation studying the importance of hypergraph inference</span> on the Particle Simulation. The sequential prediction and constrained <math alttext="k" class="ltx_Math" display="inline" id="S4.F3.3.2.m1.1"><semantics id="S4.F3.3.2.m1.1b"><mi id="S4.F3.3.2.m1.1.1" xref="S4.F3.3.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.F3.3.2.m1.1c"><ci id="S4.F3.3.2.m1.1.1.cmml" xref="S4.F3.3.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.3.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S4.F3.3.2.m1.1e">italic_k</annotation></semantics></math>-subset sampling clearly helps the performance. SPHINX obtains the best results across both datasets.
</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.F3.4" style="width:229.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="423" id="S4.F3.4.g1" src="extracted/5900948/figures/visualisations.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S4.F3.4.2.1">Predicted trajectories and the latent hypergraph structures</span> on the Particle Simulation and the real-world NBA datasets. The model learns to produce accurate trajectories and useful hypergraph structures (depicted as polygons) that correlates well with the ground truth connectivity. We observe that, for the NBA dataset, the hyperedges tends to contain the ball-node (represented as a white dot). This aligns well with our intuition that players dynamics should be highly influence by the position of the ball.
</figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.10">Our simulated system consist of <math alttext="N" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_N</annotation></semantics></math> particles moving in a 2D space. For each example, <math alttext="K" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math> random triangles were uniformly sampled to represent <math alttext="K" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.1"><semantics id="S4.SS1.p1.3.m3.1a"><mi id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><ci id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.1d">italic_K</annotation></semantics></math> 3-order interactions. All the particles that are part of a triangle rotate around the triangleâ€™s center of mass with a random angular velocity <math alttext="\theta_{i}" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.1"><semantics id="S4.SS1.p1.4.m4.1a"><msub id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">Î¸</mi><mi id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">ğœƒ</ci><ci id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">\theta_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_Î¸ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> characteristic to each particle <math alttext="i" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mi id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><ci id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">italic_i</annotation></semantics></math>. If one particle is part of multiple triangles, the rotation will happen around their average center of mass. Examples of such trajectories are depicted in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F3" title="Figure 3 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a>. For each trajectory we observe the position of the particles in the first <math alttext="22" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mn id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">22</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><cn id="S4.SS1.p1.6.m6.1.1.cmml" type="integer" xref="S4.SS1.p1.6.m6.1.1">22</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">22</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">22</annotation></semantics></math> steps, and the task is to infer the trajectory for the following <math alttext="25" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><mn id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><cn id="S4.SS1.p1.7.m7.1.1.cmml" type="integer" xref="S4.SS1.p1.7.m7.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">25</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">25</annotation></semantics></math> steps. We are experimenting with 2 variants of the dataset. A simpler one, containing a single higher-order interaction per trajectory (denoted as One-Triangle), and a more challenging one containing two higher-order interaction per trajectory (denoted as Two-Triangles). Each dataset contains <math alttext="1000" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.1"><semantics id="S4.SS1.p1.8.m8.1a"><mn id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><cn id="S4.SS1.p1.8.m8.1.1.cmml" type="integer" xref="S4.SS1.p1.8.m8.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.1d">1000</annotation></semantics></math> training, <math alttext="1000" class="ltx_Math" display="inline" id="S4.SS1.p1.9.m9.1"><semantics id="S4.SS1.p1.9.m9.1a"><mn id="S4.SS1.p1.9.m9.1.1" xref="S4.SS1.p1.9.m9.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.1b"><cn id="S4.SS1.p1.9.m9.1.1.cmml" type="integer" xref="S4.SS1.p1.9.m9.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.9.m9.1d">1000</annotation></semantics></math> validation and <math alttext="1000" class="ltx_Math" display="inline" id="S4.SS1.p1.10.m10.1"><semantics id="S4.SS1.p1.10.m10.1a"><mn id="S4.SS1.p1.10.m10.1.1" xref="S4.SS1.p1.10.m10.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m10.1b"><cn id="S4.SS1.p1.10.m10.1.1.cmml" type="integer" xref="S4.SS1.p1.10.m10.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m10.1c">1000</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.10.m10.1d">1000</annotation></semantics></math> test trajectories.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.5">For all our experiments, the hypergraph predictor treats particles as nodes. For each particle, the node features consist of the <math alttext="(x,y)" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.2"><semantics id="S4.SS1.p2.1.m1.2a"><mrow id="S4.SS1.p2.1.m1.2.3.2" xref="S4.SS1.p2.1.m1.2.3.1.cmml"><mo id="S4.SS1.p2.1.m1.2.3.2.1" stretchy="false" xref="S4.SS1.p2.1.m1.2.3.1.cmml">(</mo><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">x</mi><mo id="S4.SS1.p2.1.m1.2.3.2.2" xref="S4.SS1.p2.1.m1.2.3.1.cmml">,</mo><mi id="S4.SS1.p2.1.m1.2.2" xref="S4.SS1.p2.1.m1.2.2.cmml">y</mi><mo id="S4.SS1.p2.1.m1.2.3.2.3" stretchy="false" xref="S4.SS1.p2.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.2b"><interval closure="open" id="S4.SS1.p2.1.m1.2.3.1.cmml" xref="S4.SS1.p2.1.m1.2.3.2"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">ğ‘¥</ci><ci id="S4.SS1.p2.1.m1.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2">ğ‘¦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.2c">(x,y)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.2d">( italic_x , italic_y )</annotation></semantics></math> coordinates corresponding to the first <math alttext="T" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mi id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><ci id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">italic_T</annotation></semantics></math> timesteps. These features will be used to predict the hypergraph incidence matrix <math alttext="H" class="ltx_Math" display="inline" id="S4.SS1.p2.3.m3.1"><semantics id="S4.SS1.p2.3.m3.1a"><mi id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><ci id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">ğ»</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">H</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.3.m3.1d">italic_H</annotation></semantics></math>. During training, the hypergraph processor receives the predicted hypergraph structure together with the particleâ€™s position at timestep <math alttext="t" class="ltx_Math" display="inline" id="S4.SS1.p2.4.m4.1"><semantics id="S4.SS1.p2.4.m4.1a"><mi id="S4.SS1.p2.4.m4.1.1" xref="S4.SS1.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.4.m4.1b"><ci id="S4.SS1.p2.4.m4.1.1.cmml" xref="S4.SS1.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.4.m4.1d">italic_t</annotation></semantics></math>, and the goal is to predict the position of the particles at timestep <math alttext="t+1" class="ltx_Math" display="inline" id="S4.SS1.p2.5.m5.1"><semantics id="S4.SS1.p2.5.m5.1a"><mrow id="S4.SS1.p2.5.m5.1.1" xref="S4.SS1.p2.5.m5.1.1.cmml"><mi id="S4.SS1.p2.5.m5.1.1.2" xref="S4.SS1.p2.5.m5.1.1.2.cmml">t</mi><mo id="S4.SS1.p2.5.m5.1.1.1" xref="S4.SS1.p2.5.m5.1.1.1.cmml">+</mo><mn id="S4.SS1.p2.5.m5.1.1.3" xref="S4.SS1.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.5.m5.1b"><apply id="S4.SS1.p2.5.m5.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1"><plus id="S4.SS1.p2.5.m5.1.1.1.cmml" xref="S4.SS1.p2.5.m5.1.1.1"></plus><ci id="S4.SS1.p2.5.m5.1.1.2.cmml" xref="S4.SS1.p2.5.m5.1.1.2">ğ‘¡</ci><cn id="S4.SS1.p2.5.m5.1.1.3.cmml" type="integer" xref="S4.SS1.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.5.m5.1c">t+1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.5.m5.1d">italic_t + 1</annotation></semantics></math>. To generate longer trajectories, during testing, the model receives at each moment in time the position predicted at the previous timestep.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Hypergraph discovery.</span> These datasets allow us to experiment with learning the higher-order relations in a setup where we have access to the ground-truth connectivity. Our model produces discrete hypergraph structures that we can inspect and evaluate, offering an additional level of interpetability to the framework. Visualisations of our learned hypergraph structure (see FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F3" title="Figure 3 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a>) reveals that they are highly correlated to the ground-truth interactions used to generate the dataset.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">We quantitatively evaluate to what extent our model learns the true higher-order relationships, by computing the overlap between our modelâ€™s prediction and the ground-truth hyperedges. We refer to the Supplementary Material for a full descriptions of the metric used in this experiments. In FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F4" title="Figure 4 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">4</span></a> we observe that, even if we do not explicitly optimise for this task, the accuracy of the hypergraph structure predictor increases during training, reaching more than <math alttext="90\%" class="ltx_Math" display="inline" id="S4.SS1.p4.1.m1.1"><semantics id="S4.SS1.p4.1.m1.1a"><mrow id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml"><mn id="S4.SS1.p4.1.m1.1.1.2" xref="S4.SS1.p4.1.m1.1.1.2.cmml">90</mn><mo id="S4.SS1.p4.1.m1.1.1.1" xref="S4.SS1.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><apply id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p4.1.m1.1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1.1">percent</csymbol><cn id="S4.SS1.p4.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p4.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">90\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p4.1.m1.1d">90 %</annotation></semantics></math> overlap for both the One-Triangle dataset and the Two-Triangles dataset.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p5.1.1">General and versatile</span>, our model is designed to predict hypergraph structure that is useful for any hypergraph neural network. However, since the supervision signal comes from the high-level tasks, the architecture used for hypergraph processing can impose certain inductive biases, influencing the hypergraph structure learned by the predictor.
In the experiment depicted in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F4" title="Figure 4 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">4</span></a>, we investigate to what extent our model learns an accurate higher-order structure, regardless of the hypergraph processing architecture. We train a set of models using the same hypergraph predictor for inferring the hypergraph structure, but various hypergraph networks for processing it. For this, we experiment with AllDeepSetsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib28" title="">28</a>]</cite>, HGNNÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib26" title="">26</a>]</cite> and HCHAÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib31" title="">31</a>]</cite>. The results show that our model is capable of learning the suitable structure irrespective of the specifics in the processing model.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">These experiments prove that the hypergraph discovery task is highly correlated with the trajectory prediction problem. Our model, explicitly designed to infer the latent hypergraph structure, is capable not only to accurately solve the downstream task but also to recover the true higher-order relations, without access to the ground-truth hypergraph connectivity.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p7.1.1">Importance of sequential prediction.</span>
While the classical slot-attention algorithm infers all the clusters in parallel, we argue that this is not an appropriate design choice for hypergraph prediction. Often, the set of hyperedges is mostly symmetric, which makes the problem of attaching the slots to different hyperedges highly ambiguous. In fact, we visually observed that, when predicting all the hyperedges simultaneously, the model tends to associate multiple slots to the same hyperedge, leaving others completely uncovered (see Supplementary Material for more visualisations). This behaviour leads to both a decrease in downstream performance and a less accurate hypergraph predictor. As described in SectionÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S3.SS1" title="3.1 Hypergraph predictor â€£ 3 Structure Prediction using Hypergraph Inference Network â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3.1</span></a>, SPHINX alleviates this issue by inferring the slots sequentially, and providing at each step historical information about the structure predicted so far. FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F3" title="Figure 3 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a> and TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.T1" title="Table 1 â€£ Figure 4 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates the benefits of our design choices. Sequential prediction have a clear advantage, outperforming the classical slot-attention predictor.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.4"><span class="ltx_text ltx_font_bold" id="S4.SS1.p8.1.1">Influence of <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p8.1.1.m1.1"><semantics id="S4.SS1.p8.1.1.m1.1a"><mi id="S4.SS1.p8.1.1.m1.1.1" xref="S4.SS1.p8.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.1.1.m1.1b"><ci id="S4.SS1.p8.1.1.m1.1.1.cmml" xref="S4.SS1.p8.1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.1.1.m1.1d">italic_k</annotation></semantics></math>-sampling.</span>
Previous work on inferring hypergraphsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib43" title="">43</a>]</cite> takes inspiration from the graph relational inferenceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib19" title="">19</a>]</cite> where the differentiable sampling is achieved using the Gumbel-Softmax trick. We argue that, inferring the subset of nodes that are part of a hyperedge generates more challenges compare to the graph scenarios. In the beginning of training, sampling each node-hyperedge incidence independently, without any constraints, can lead to hyperedges containing either too few or too many nodes, which highly damage the optimisation. In this work, we leverage the recent advance in differentiable <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p8.2.m1.1"><semantics id="S4.SS1.p8.2.m1.1a"><mi id="S4.SS1.p8.2.m1.1.1" xref="S4.SS1.p8.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.2.m1.1b"><ci id="S4.SS1.p8.2.m1.1.1.cmml" xref="S4.SS1.p8.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.2.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.2.m1.1d">italic_k</annotation></semantics></math>-subset sampling, which imposes the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p8.3.m2.1"><semantics id="S4.SS1.p8.3.m2.1a"><mi id="S4.SS1.p8.3.m2.1.1" xref="S4.SS1.p8.3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.3.m2.1b"><ci id="S4.SS1.p8.3.m2.1.1.cmml" xref="S4.SS1.p8.3.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.3.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.3.m2.1d">italic_k</annotation></semantics></math>-nodes constraint, while still allowing to estimate the gradient during backpropagation. The experiments in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F3" title="Figure 3 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a> show that the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p8.4.m3.1"><semantics id="S4.SS1.p8.4.m3.1a"><mi id="S4.SS1.p8.4.m3.1.1" xref="S4.SS1.p8.4.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p8.4.m3.1b"><ci id="S4.SS1.p8.4.m3.1.1.cmml" xref="S4.SS1.p8.4.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p8.4.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p8.4.m3.1d">italic_k</annotation></semantics></math>-subset sampling improves the results, leading to an easier optimisation and better final performance. This is in line with the results reported inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib43" title="">43</a>]</cite> where smoothness and sparsity regularisation are crucial for improving the results on a real-world dataset. In contrast, our model obtains competitive performance without any optimisation trick.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p9">
<p class="ltx_p" id="S4.SS1.p9.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p9.1.1">Comparison with baselines.</span>
Both versions of the datasets used in our experiments heavily relies on higher-order processing. In order to predict the particle movement, the model needs to identify the higher-order structures that guides the rotation and use it to generate the displacement from the previous position. To understand to what extent our model is able to produce and process a useful hypergraph structure, we compare against two baseline: a model using a random structure (denoted as <span class="ltx_text ltx_font_italic" id="S4.SS1.p9.1.2">random</span> in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.F3" title="Figure 3 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a>) and a node-level model, that ignores the hypergraph structure (denoted as <span class="ltx_text ltx_font_italic" id="S4.SS1.p9.1.3">w/o structure</span>) by setting the incidence matrix on zero. Both models perform much worse that our learnable hypergraph model, indicating that the dataset highly depends on higher-order interactions and our model is capable of discovering an appropriate latent structure. Inspired byÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib19" title="">19</a>]</cite>, we also compare our model against an LSTM baseline that is agnostic to the hypergraph structure and only receives the concatenation of all the particles. While performing comparable on the 1 step prediction metric (2e-5 MSE for SPHINX and 3e-5 for the LSTM), the performance degrades quickly when evaluating on the long-range prediction (6e-3 MSE for SPHINX compared to 1.7e-1 for the LSTM). For the complete numerical results, see Supplementary Material.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.F4.1" style="width:216.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="252" id="S4.F4.1.g1" src="extracted/5900948/figures/accuracy.png" width="628"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S4.F4.1.4.1">Hypergraph discovery improves during training</span> on the synthetic datasets, even if the model is not supervised for this task. Regardless of the hypergraph architectures, the overlap between our (unsupervised) predicted hypergraph and the gt. connectivity increases, demonstrating that the model recovers the real structure to a high extent.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.F4.fig1" style="width:199.5pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text ltx_font_bold" id="S4.T1.4.1">Ablation study on the NBA dataset</span>. Both using sequential, history-aware predictors and using <math alttext="k" class="ltx_Math" display="inline" id="S4.T1.2.m1.1"><semantics id="S4.T1.2.m1.1b"><mi id="S4.T1.2.m1.1.1" xref="S4.T1.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T1.2.m1.1c"><ci id="S4.T1.2.m1.1.1.cmml" xref="S4.T1.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.m1.1e">italic_k</annotation></semantics></math>-subset sampling prove to be beneficial for the final performance (ADE/FDE metrics reported). Moreover, our model shows a clear advantage compared to the best recent work on the single-trajectory prediction task.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S4.F4.fig1.1" style="width:433.6pt;height:162.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(72.8pt,-27.3pt) scale(1.5053323605627,1.5053323605627) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.F4.fig1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.F4.fig1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.F4.fig1.1.1.1.1.1">Time</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.F4.fig1.1.1.1.1.2">GroupNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.F4.fig1.1.1.1.1.3">SPHINX</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.F4.fig1.1.1.1.1.4">SPHINX</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.F4.fig1.1.1.1.1.5">SPHINX</th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_tt" id="S4.F4.fig1.1.1.1.1.6"></th>
</tr>
<tr class="ltx_tr" id="S4.F4.fig1.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S4.F4.fig1.1.1.2.2.1"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S4.F4.fig1.1.1.2.2.2"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.F4.fig1.1.1.2.2.3">w/o sequential</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.F4.fig1.1.1.2.2.4">w Gumbel</th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.F4.fig1.1.1.2.2.5"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.F4.fig1.1.1.2.2.6"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F4.fig1.1.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.F4.fig1.1.1.3.1.1">1sec</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.F4.fig1.1.1.3.1.2">0.65/1.03</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.F4.fig1.1.1.3.1.3">0.62/0.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.F4.fig1.1.1.3.1.4">1.29/1.81</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.F4.fig1.1.1.3.1.5">
<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.3.1.5.1">0.59</span>/<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.3.1.5.2">0.92</span>
</td>
<td class="ltx_td ltx_border_t" id="S4.F4.fig1.1.1.3.1.6"></td>
</tr>
<tr class="ltx_tr" id="S4.F4.fig1.1.1.4.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.F4.fig1.1.1.4.2.1">2sec</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.F4.fig1.1.1.4.2.2">1.38/2.61</td>
<td class="ltx_td ltx_align_center" id="S4.F4.fig1.1.1.4.2.3">1.18/2.08</td>
<td class="ltx_td ltx_align_center" id="S4.F4.fig1.1.1.4.2.4">2.10/3.34</td>
<td class="ltx_td ltx_align_center" id="S4.F4.fig1.1.1.4.2.5">
<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.4.2.5.1">1.12</span>/<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.4.2.5.2">2.06</span>
</td>
<td class="ltx_td" id="S4.F4.fig1.1.1.4.2.6"></td>
</tr>
<tr class="ltx_tr" id="S4.F4.fig1.1.1.5.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.F4.fig1.1.1.5.3.1">3sec</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.F4.fig1.1.1.5.3.2">2.15/4.11</td>
<td class="ltx_td ltx_align_center" id="S4.F4.fig1.1.1.5.3.3">1.73/3.14</td>
<td class="ltx_td ltx_align_center" id="S4.F4.fig1.1.1.5.3.4">2.81/4.60</td>
<td class="ltx_td ltx_align_center" id="S4.F4.fig1.1.1.5.3.5">
<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.5.3.5.1">1.65</span>/<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.5.3.5.2">3.13</span>
</td>
<td class="ltx_td" id="S4.F4.fig1.1.1.5.3.6"></td>
</tr>
<tr class="ltx_tr" id="S4.F4.fig1.1.1.6.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.F4.fig1.1.1.6.4.1">4sec</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.F4.fig1.1.1.6.4.2">2.83/5.15</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.F4.fig1.1.1.6.4.3">2.25/4.08</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.F4.fig1.1.1.6.4.4">3.45/5.66</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.F4.fig1.1.1.6.4.5">
<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.6.4.5.1">2.14</span>/<span class="ltx_text ltx_font_bold" id="S4.F4.fig1.1.1.6.4.5.2">4.09</span>
</td>
<td class="ltx_td ltx_border_bb" id="S4.F4.fig1.1.1.6.4.6"></td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p10">
<p class="ltx_p" id="S4.SS1.p10.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p10.1.1">Implementation details.</span>
Unless otherwise stated, the One-Triangle experiments use a single slot in the slot-attention module, while the Two-Triangles uses two slots. For estimating the gradients in the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p10.1.m1.1"><semantics id="S4.SS1.p10.1.m1.1a"><mi id="S4.SS1.p10.1.m1.1.1" xref="S4.SS1.p10.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p10.1.m1.1b"><ci id="S4.SS1.p10.1.m1.1.1.cmml" xref="S4.SS1.p10.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p10.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p10.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling algorithm we experiment with SIMPLEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib8" title="">8</a>]</cite>, AIMLEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib9" title="">9</a>]</cite> and IMLEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib46" title="">46</a>]</cite> algorithms. According to our experiments, the first two perform on par, while IMLEÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib46" title="">46</a>]</cite> mostly suffer from gradient issues. Unless otherwise specified, our models use the AllDeepSetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib28" title="">28</a>]</cite> hypergraph processor. In all experiments,
we use Adam optimizer for 1000 epochs, trained on a single GPU.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p11">
<p class="ltx_p" id="S4.SS1.p11.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p11.1.1">Key findings.</span> The results presented in this section demonstrates that: <span class="ltx_text" id="S4.SS1.p11.1.2" style="font-size:120%;">\small1âƒ</span>Â Our model predicts accurate hypergraph connectivity, that correlates well with the ground-truth structure, even without being optimized for this task and <span class="ltx_text" id="S4.SS1.p11.1.3" style="font-size:120%;">\small2âƒ</span>Â irrespective of the hypergraph architecture used as decoder. <span class="ltx_text" id="S4.SS1.p11.1.4" style="font-size:120%;">\small3âƒ</span>Â Predicting the hyperedges sequentially ameliorate the ambiguity issue, improving the hypergraph inference. <span class="ltx_text" id="S4.SS1.p11.1.5" style="font-size:120%;">\small4âƒ</span>Â <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.p11.1.m1.1"><semantics id="S4.SS1.p11.1.m1.1a"><mi id="S4.SS1.p11.1.m1.1.1" xref="S4.SS1.p11.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p11.1.m1.1b"><ci id="S4.SS1.p11.1.m1.1.1.cmml" xref="S4.SS1.p11.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p11.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p11.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling is crucial for a good performance, proving to be superior to the standard Gumbel-Softmax approach and allows us to eliminate the regularisation tricks. <span class="ltx_text" id="S4.SS1.p11.1.6" style="font-size:120%;">\small5âƒ</span>Â Finally, discovering the latent hypergraph structure is clearly beneficial for the downstream prediction.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>NBA Dataset</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.4">To evaluate our model on a real-world dataset, we use the NBA SportVU dataset, containing information about the movement of the players during the basketball matches. Each example contains <math alttext="11" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn id="S4.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">11</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">11</annotation></semantics></math> trajectories, <math alttext="5" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mn id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><cn id="S4.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">5</annotation></semantics></math> players from each team and one trajectory for the ball. Similar to the synthetic setup, the hypergraph predictor receives as node features the first part of each trajectory (the initial <math alttext="5" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn id="S4.SS2.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">5</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">5</annotation></semantics></math> steps) and the goal is to predict the next <math alttext="10" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mn id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><cn id="S4.SS2.p1.4.m4.1.1.cmml" type="integer" xref="S4.SS2.p1.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">10</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">10</annotation></semantics></math> steps. While our model is not especially designed as a tracking systems, the dynamics followed by the basketball game contains higher-order relations that are difficult to identify, thus representing a good testbed for our hypergraph inference method.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Ablation study.</span> We assess our core design choices on the real-world dataset as well. In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.T1" title="Table 1 â€£ Figure 4 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">1</span></a> we are reporting the average displacement error (ADE) and final displacement error (FDE) metrics. Similar to the particle simulation datasets, we observe that predicting the hyperedges sequentially outperforms the simultaneous approach used by standard differentiable clustering algorithms. Moreover, the <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling prove to be clearly superior to the Gumbel-Softmax used in the previous methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Comparison to recent methods.</span> In TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.T2" title="Table 2 â€£ 4.2 NBA Dataset â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">2</span></a> we compare against other structure-based methods in the literature including graph-based methods: NRIÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib19" title="">19</a>]</cite>, DNRIÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib22" title="">22</a>]</cite>, EvolveGraphÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib51" title="">51</a>]</cite>, STGATÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib52" title="">52</a>]</cite>, Trajectron++Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib53" title="">53</a>]</cite> and hypergraph-based methods: higher-order-only EvolveHypergraph, the full EvolveHypergraph modelÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib43" title="">43</a>]</cite> and GroupNetÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib42" title="">42</a>]</cite>. Our method improves the short and medium-term prediction, while obtaining competitive results on the long-term prediction. Note that, compared to the other hypergraph-based methods, our model do not requires any auxiliary loss function or additional pairwise predictions.</p>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.3">The metrics used in the recent literature (<math alttext="\text{minADE}_{20}" class="ltx_Math" display="inline" id="S4.SS2.p4.1.m1.1"><semantics id="S4.SS2.p4.1.m1.1a"><msub id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mtext id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2a.cmml">minADE</mtext><mn id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2a.cmml" xref="S4.SS2.p4.1.m1.1.1.2"><mtext id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">minADE</mtext></ci><cn id="S4.SS2.p4.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.p4.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">\text{minADE}_{20}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">minADE start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\text{minFDE}_{20}" class="ltx_Math" display="inline" id="S4.SS2.p4.2.m2.1"><semantics id="S4.SS2.p4.2.m2.1a"><msub id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mtext id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2a.cmml">minFDE</mtext><mn id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2a.cmml" xref="S4.SS2.p4.2.m2.1.1.2"><mtext id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">minFDE</mtext></ci><cn id="S4.SS2.p4.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.p4.2.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">\text{minFDE}_{20}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.2.m2.1d">minFDE start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT</annotation></semantics></math>) takes into account only the best trajectory from a pool of <math alttext="20" class="ltx_Math" display="inline" id="S4.SS2.p4.3.m3.1"><semantics id="S4.SS2.p4.3.m3.1a"><mn id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><cn id="S4.SS2.p4.3.m3.1.1.cmml" type="integer" xref="S4.SS2.p4.3.m3.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.3.m3.1c">20</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.3.m3.1d">20</annotation></semantics></math> sampled trajectories. Recent workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib54" title="">54</a>]</cite> shows that these metrics suffer from a series of limitations, favouring methods that produce diverse, but not necessarily accurate trajectories. Thus, in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#S4.T1" title="Table 1 â€£ Figure 4 â€£ 4.1 Particle Simulations â€£ 4 Experimental Analysis â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">1</span></a>, we also compared against the top hypergraph-based method using the single-trajectory prediction metrics, ADE and FDE (the code for EvolveHypergraph is not publicly available). The results clearly show that for single-trajectory prediction our method obtains better results both on short and long-term prediction.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p5.1.1">Implementation details.</span>
In all our experiments we follow the train-valid-test split fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib42" title="">42</a>]</cite>. For the observed trajectory, besides the coordinates of each player, the node features are enhanced with the velocity computed based on consecutive frames. For the unobserved trajectory, the velocity is computed based on the predicted position. The models are trained for 300 epochs, using Adam optimiser with learning rate 0.001, decreased by a factor of 10 when reaching a plateau. Similar to the synthetic setup, we are treating the algorithm used to perform <math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.p5.1.m1.1"><semantics id="S4.SS2.p5.1.m1.1a"><mi id="S4.SS2.p5.1.m1.1.1" xref="S4.SS2.p5.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p5.1.m1.1b"><ci id="S4.SS2.p5.1.m1.1.1.cmml" xref="S4.SS2.p5.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p5.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p5.1.m1.1d">italic_k</annotation></semantics></math>-sampling as a hyperparameter, experimenting with both AIMLEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib9" title="">9</a>]</cite> and SIMPLEÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib8" title="">8</a>]</cite> algorithm. More details for the hyperparameters tuned in our experiments are presented in the Supplementary Material.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold" id="S4.T2.6.1">Performance on the NBA dataset</span> in terms of <math alttext="\text{minADE}_{20}" class="ltx_Math" display="inline" id="S4.T2.3.m1.1"><semantics id="S4.T2.3.m1.1b"><msub id="S4.T2.3.m1.1.1" xref="S4.T2.3.m1.1.1.cmml"><mtext id="S4.T2.3.m1.1.1.2" xref="S4.T2.3.m1.1.1.2a.cmml">minADE</mtext><mn id="S4.T2.3.m1.1.1.3" xref="S4.T2.3.m1.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.3.m1.1c"><apply id="S4.T2.3.m1.1.1.cmml" xref="S4.T2.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.m1.1.1.1.cmml" xref="S4.T2.3.m1.1.1">subscript</csymbol><ci id="S4.T2.3.m1.1.1.2a.cmml" xref="S4.T2.3.m1.1.1.2"><mtext id="S4.T2.3.m1.1.1.2.cmml" xref="S4.T2.3.m1.1.1.2">minADE</mtext></ci><cn id="S4.T2.3.m1.1.1.3.cmml" type="integer" xref="S4.T2.3.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.m1.1d">\text{minADE}_{20}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.m1.1e">minADE start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\text{minFDE}_{20}" class="ltx_Math" display="inline" id="S4.T2.4.m2.1"><semantics id="S4.T2.4.m2.1b"><msub id="S4.T2.4.m2.1.1" xref="S4.T2.4.m2.1.1.cmml"><mtext id="S4.T2.4.m2.1.1.2" xref="S4.T2.4.m2.1.1.2a.cmml">minFDE</mtext><mn id="S4.T2.4.m2.1.1.3" xref="S4.T2.4.m2.1.1.3.cmml">20</mn></msub><annotation-xml encoding="MathML-Content" id="S4.T2.4.m2.1c"><apply id="S4.T2.4.m2.1.1.cmml" xref="S4.T2.4.m2.1.1"><csymbol cd="ambiguous" id="S4.T2.4.m2.1.1.1.cmml" xref="S4.T2.4.m2.1.1">subscript</csymbol><ci id="S4.T2.4.m2.1.1.2a.cmml" xref="S4.T2.4.m2.1.1.2"><mtext id="S4.T2.4.m2.1.1.2.cmml" xref="S4.T2.4.m2.1.1.2">minFDE</mtext></ci><cn id="S4.T2.4.m2.1.1.3.cmml" type="integer" xref="S4.T2.4.m2.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.m2.1d">\text{minFDE}_{20}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.m2.1e">minFDE start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT</annotation></semantics></math> metrics. Our model performing higher-order processing using a learnable hypergraph structure prove to be beneficial for trajectory prediction tasks, obtaining competitive performance.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.7" style="width:433.6pt;height:79.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-78.4pt,14.3pt) scale(0.734394448752301,0.734394448752301) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.7.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T2.7.1.1.1.1">Time</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.2">NRI</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.3">DNRI</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.4">EvolveGraph</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.5">STGAT</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T2.7.1.1.1.6">Trajectron++</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.7">EvolveHgraph</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.8">EvolveHgraph</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.9">GroupNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.7.1.1.1.10">SPHINX</th>
</tr>
<tr class="ltx_tr" id="S4.T2.7.1.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S4.T2.7.1.2.2.1"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T2.7.1.2.2.2"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T2.7.1.2.2.3"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T2.7.1.2.2.4"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T2.7.1.2.2.5"></th>
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S4.T2.7.1.2.2.6"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.7.1.2.2.7">HO only</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T2.7.1.2.2.8">full</th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T2.7.1.2.2.9"></th>
<th class="ltx_td ltx_th ltx_th_column" id="S4.T2.7.1.2.2.10"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.7.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.7.1.3.1.1">1sec</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.2">0.51/0.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.3">0.59/0.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.4">0.35/0.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.5">0.45/0.66</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.7.1.3.1.6">0.44/0.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.7">0.49/0.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.8">0.33/0.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.9">0.34/0.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.1.3.1.10">
<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.3.1.10.1">0.30</span>/<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.3.1.10.2">0.43</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.1.4.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.1.4.2.1">2sec</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.2">0.96/1.65</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.3">0.93/1.52</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.4">0.66/0.97</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.5">0.87/1.41</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.1.4.2.6">0.79/1.18</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.7">0.95/1.68</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.8">0.63/0.95</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.9">0.62/0.95</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.4.2.10">
<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.4.2.10.1">0.59</span>/<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.4.2.10.2">0.94</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.1.5.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.1.5.3.1">3sec</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.2">1.42/2.50</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.3">1.38/2.21</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.4">1.15/1.86</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.5">1.28/2.08</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.7.1.5.3.6">1.51/2.49</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.7">1.44/2.27</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.8">0.93/1.36</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.9">
<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.5.3.9.1">0.87</span>/<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.5.3.9.2">1.31</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T2.7.1.5.3.10">0.88/1.38</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.1.6.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.7.1.6.4.1">4sec</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.2">1.86/3.26</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.3">1.78/2.81</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.4">1.64/2.64</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.5">1.69/2.66</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T2.7.1.6.4.6">2.09/3.52</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.7">1.91/3.08</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.8">1.21/1.74</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.9">
<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.6.4.9.1">1.13</span>/<span class="ltx_text ltx_font_bold" id="S4.T2.7.1.6.4.9.2">1.69</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.7.1.6.4.10">1.16/1.74</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper we are introducing Structural Prediction using Hypergraph
Inference Network (SPHINX), a model for unsupervised hypergraph inference that enables higher-order processing in tasks where hypergraph structure is not provided. The model adopts a global processing in the form of sequential soft clustering for predicting hyperedge probability, paired with a <math alttext="k" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><mi id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><ci id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling algorithm for discretizing the structure such that it can be used with any hypergraph neural network decoder and eliminating the need for heavy optimisation tricks. Overall, the resulting method is a general and broadly applicable solution for relational processing, facilitating seamless integration into any real-world systems perceived to necessitate higher-order analysis.</p>
</div>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Acknowledgment</h4>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">The authors would like to thank Charlotte Magister, Daniel McFadyen, Alex Norcliffe and Paul Scherer for fruitful discussions and constructive suggestions during the development of the paper. Iulia Duta is a PhD student funded by a Twitter scholarship.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
NicolasÂ A. Crossley, Andrea Mechelli, Jessica Scott, Francesco Carletti, PeterÂ T. Fox, PhilipÂ K. McGuire, and EdwardÂ T. Bullmore.

</span>
<span class="ltx_bibblock">The hubs of the human connectome are generally implicated in the anatomy of brain disorders.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Brain</span>, 137:2382 â€“ 2395, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Tingting Guo, Yining Zhang, Yanfang Xue, and Lishan Qiao.

</span>
<span class="ltx_bibblock">Brain function network: Higher order vs. more discrimination.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Frontiers in Neuroscience</span>, 15, 08 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
JÃ¼rgen Jost and Raffaella Mulas.

</span>
<span class="ltx_bibblock">Hypergraph laplace operators for chemical reaction networks, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Ramon ViÃ±as, ChaitanyaÂ K. Joshi, Dobrik Georgiev, Bianca Dumitrascu, EricÂ R. Gamazon, and Pietro LiÃ².

</span>
<span class="ltx_bibblock">Hypergraph factorisation for multi-tissue gene expression imputation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">bioRxiv</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Jure Leskovec, JonÂ M. Kleinberg, and Christos Faloutsos.

</span>
<span class="ltx_bibblock">Graphs over time: densification laws, shrinking diameters and possible explanations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Knowledge Discovery and Data Mining</span>, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec.

</span>
<span class="ltx_bibblock">Open graph benchmark: Datasets for machine learning on graphs.

</span>
<span class="ltx_bibblock">In H.Â Larochelle, M.Â Ranzato, R.Â Hadsell, M.F. Balcan, and H.Â Lin, editors, <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Advances in Neural Information Processing Systems</span>, volumeÂ 33, pages 22118â€“22133. Curran Associates, Inc., 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Yanbang Wang and Jon Kleinberg.

</span>
<span class="ltx_bibblock">From graphs to hypergraphs: Hypergraph projection and its reconstruction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">The Twelfth International Conference on Learning Representations</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Kareem Ahmed, Zhe Zeng, Mathias Niepert, and Guy VanÂ den Broeck.

</span>
<span class="ltx_bibblock">Simple: A gradient estimator for k-subset sampling.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</span>, may 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Pasquale Minervini, Luca Franceschi, and Mathias Niepert.

</span>
<span class="ltx_bibblock">Adaptive perturbation-based gradient estimation for discrete latent variable models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</span>, 37(8):9200â€“9208, Jun. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Eric Jang, Shixiang Gu, and Ben Poole.

</span>
<span class="ltx_bibblock">Categorical reparameterization with gumbel-softmax.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings</span>. OpenReview.net, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
ThomasÂ N. Kipf and Max Welling.

</span>
<span class="ltx_bibblock">Semi-supervised classification with graph convolutional networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">International Conference on Learning Representations (ICLR)</span>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Petar VeliÄkoviÄ‡, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro LiÃ², and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Graph attention networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib12.1.1">International Conference on Learning Representations</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Ioana Bica and Mihaela vanÂ der Schaar.

</span>
<span class="ltx_bibblock">Transfer learning on heterogeneous feature spaces for treatment effects estimation.

</span>
<span class="ltx_bibblock">In S.Â Koyejo, S.Â Mohamed, A.Â Agarwal, D.Â Belgrave, K.Â Cho, and A.Â Oh, editors, <span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Advances in Neural Information Processing Systems</span>, volumeÂ 35, pages 37184â€“37198. Curran Associates, Inc., 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter Battaglia.

</span>
<span class="ltx_bibblock">Learning to simulate complex physics with graph networks.

</span>
<span class="ltx_bibblock">In HalÂ DaumÃ© III and Aarti Singh, editors, <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 37th International Conference on Machine Learning</span>, volume 119, pages 8459â€“8468, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Remi Lam, Alvaro Sanchez-Gonzalez, Matthew Willson, Peter Wirnsberger, Meire Fortunato, Ferran Alet, Suman Ravuri, Timo Ewalds, Zach Eaton-Rosen, Weihua Hu, Alexander Merose, Stephan Hoyer, George Holland, Oriol Vinyals, Jacklynn Stott, Alexander Pritzel, Shakir Mohamed, and Peter Battaglia.

</span>
<span class="ltx_bibblock">Learning skillful medium-range global weather forecasting.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">Science</span>, 382(6677):1416â€“1421, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Alex Davies, Petar Velickovic, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Tomasev, Richard Tanburn, PeterÂ W. Battaglia, Charles Blundell, AndrÃ¡s JuhÃ¡sz, Marc Lackenby, Geordie Williamson, Demis Hassabis, and Pushmeet Kohli.

</span>
<span class="ltx_bibblock">Advancing mathematics by guiding human intuition with ai.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Nature</span>, 600:70 â€“ 74, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Zhe Wang, Petar VeliÄkoviÄ‡, Daniel Hennes, Nenad TomaÅ¡ev, Laurel Prince, Michael Kaisers, Yoram Bachrach, Romuald Elie, LiÂ Wenliang, Federico Piccinini, William Spearman, Ian Graham, Jerome Connor, YiÂ Yang, AdriÃ  Recasens, Mina Khan, Nathalie Beauguerlange, Pablo Sprechmann, Pol Moreno, and Karl Tuyls.

</span>
<span class="ltx_bibblock">Tacticai: an ai assistant for football tactics.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">Nature Communications</span>, 15, 03 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Justin Gilmer, SamuelÂ S. Schoenholz, PatrickÂ F. Riley, Oriol Vinyals, and GeorgeÂ E. Dahl.

</span>
<span class="ltx_bibblock">Neural message passing for quantum chemistry.

</span>
<span class="ltx_bibblock">In Doina Precup and YeeÂ Whye Teh, editors, <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 34th International Conference on Machine Learning</span>, volumeÂ 70 of <span class="ltx_text ltx_font_italic" id="bib.bib18.2.2">Proceedings of Machine Learning Research</span>, pages 1263â€“1272, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
T.Â Fetaya, Elias Wang, K.-C. Welling, Michelle Zemel, Thomas Kipf, Ethan Fetaya, Kuan-ChiehÂ Jackson Wang, Max Welling, and RichardÂ S. Zemel.

</span>
<span class="ltx_bibblock">Neural relational inference for interacting systems.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">International Conference on Machine Learning</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Ezra Webb, Ben Day, Helena AndrÃ©s-TerrÃ©, and Pietro Lioâ€™.

</span>
<span class="ltx_bibblock">Factorised neural relational inference for multi-interaction systems.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">ArXiv</span>, abs/1905.08721, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Sindy Lowe, David Madras, Richard Zemel, and Max Welling.

</span>
<span class="ltx_bibblock">Amortized causal discovery: Learning to infer causal graphs from time-series data.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Causal Learning and Reasoning (CLeaR)</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Colin Graber and AlexanderÂ G. Schwing.

</span>
<span class="ltx_bibblock">Dynamic neural relational inference.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span>, June 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
JoaquÃ­nÂ J. Torres and Ginestra Bianconi.

</span>
<span class="ltx_bibblock">Simplicial complexes: higher-order spectral dimension and dynamics.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Journal of Physics: Complexity</span>, 1, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
AlbertÂ T. Lundell and Stephen Weingram.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">CW Complexes</span>, pages 41â€“76.

</span>
<span class="ltx_bibblock">Springer New York, New York, NY, 1969.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Anirban Banerjee.

</span>
<span class="ltx_bibblock">On the spectrum of hypergraphs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Linear Algebra and its Applications</span>, 614:82â€“110, 2021.

</span>
<span class="ltx_bibblock">Special Issue ILAS 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, and Yue Gao.

</span>
<span class="ltx_bibblock">Hypergraph neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Proc. Conf. AAAI Artif. Intell.</span>, 33(01):3558â€“3565, July 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Jing Huang and Jie Yang.

</span>
<span class="ltx_bibblock">Unignn: a unified framework for graph and hypergraph neural networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Eli Chien, Chao Pan, Jianhao Peng, and Olgica Milenkovic.

</span>
<span class="ltx_bibblock">You are allset: A multiset function framework for hypergraph neural networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib28.1.1">International Conference on Learning Representations</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, RussÂ R Salakhutdinov, and AlexanderÂ J Smola.

</span>
<span class="ltx_bibblock">Deep sets.

</span>
<span class="ltx_bibblock">In I.Â Guyon, U.Â Von Luxburg, S.Â Bengio, H.Â Wallach, R.Â Fergus, S.Â Vishwanathan, and R.Â Garnett, editors, <span class="ltx_text ltx_font_italic" id="bib.bib29.1.1">Advances in Neural Information Processing Systems</span>, volumeÂ 30. Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, ÅÂ ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In I.Â Guyon, U.Â Von Luxburg, S.Â Bengio, H.Â Wallach, R.Â Fergus, S.Â Vishwanathan, and R.Â Garnett, editors, <span class="ltx_text ltx_font_italic" id="bib.bib30.1.1">Advances in Neural Information Processing Systems</span>, volumeÂ 30. Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Song Bai, Feihu Zhang, and PhilipÂ H.S. Torr.

</span>
<span class="ltx_bibblock">Hypergraph convolution and hypergraph attention.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">Pattern Recognition</span>, 110:107637, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Jiying Zhang, Yuzhao Chen, Xiong Xiao, Runiu Lu, and Shutao Xia.

</span>
<span class="ltx_bibblock">Learnable hypergraph laplacian for hypergraph learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">ICASSP</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
DobrikÂ Georgiev Georgiev, Marc Brockschmidt, and Miltiadis Allamanis.

</span>
<span class="ltx_bibblock">HEAT: Hyperedge attention networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">Transactions on Machine Learning Research</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Iulia Duta, Giulia CassarÃ , Fabrizio Silvestri, and Pietro Lio.

</span>
<span class="ltx_bibblock">Sheaf hypergraph networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">Thirty-seventh Conference on Neural Information Processing Systems</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Hypergraph reconstruction from network data.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Communications Physics</span>, 4(1), June 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Detecting informative higher-order interactions in statistically validated hypergraphs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">Communications Physics</span>, 4, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Claudio Battiloro, Indro Spinelli, Lev Telyatnikov, MichaelÂ M. Bronstein, Simone Scardapane, and PaoloÂ Di Lorenzo.

</span>
<span class="ltx_bibblock">From latent graph to latent topology inference: Differentiable cell complex module.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib37.1.1">ArXiv</span>, abs/2305.16174, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
DavidÂ W Zhang, GertjanÂ J. Burghouts, and Cees G.Â M. Snoek.

</span>
<span class="ltx_bibblock">Pruning edges and gradients to learn hypergraphs from larger sets.

</span>
<span class="ltx_bibblock">In Bastian Rieck and Razvan Pascanu, editors, <span class="ltx_text ltx_font_italic" id="bib.bib38.1.1">Proceedings of the First Learning on Graphs Conference</span>, volume 198 of <span class="ltx_text ltx_font_italic" id="bib.bib38.2.2">Proceedings of Machine Learning Research</span>, pages 53:1â€“53:18. PMLR, 09â€“12 Dec 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Jun Yu, Dacheng Tao, and Meng Wang.

</span>
<span class="ltx_bibblock">Adaptive hypergraph learning and its application in image classification.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">IEEE Transactions on Image Processing</span>, 21(7):3262â€“3272, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Zizhao Zhang, Haojie Lin, and Yue Gao.

</span>
<span class="ltx_bibblock">Dynamic hypergraph structure learning.

</span>
<span class="ltx_bibblock">IJCAIâ€™18, page 3162â€“3169. AAAI Press, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Yue Gao, Zizhao Zhang, Haojie Lin, Xibin Zhao, S.Â Du, and Changqing Zou.

</span>
<span class="ltx_bibblock">Hypergraph learning: Methods and practices.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>, 44:2548â€“2566, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Chenxin Xu, Maosen Li, Zhenyang Ni, YaÂ Zhang, and Siheng Chen.

</span>
<span class="ltx_bibblock">Groupnet: Multiscale hypergraph neural networks for trajectory prediction with relational reasoning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib42.1.1">The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Jiachen Li, Chuanbo Hua, Jinkyoo Park, Hengbo Ma, Victoria Dax, and MykelÂ J. Kochenderfer.

</span>
<span class="ltx_bibblock">Evolvehypergraph: Group-aware dynamic relational reasoning for trajectory prediction, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Klaus Greff, Sjoerd van Steenkiste, and JÃ¼rgen Schmidhuber.

</span>
<span class="ltx_bibblock">On the binding problem in artificial neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib44.1.1">ArXiv</span>, abs/2012.05208, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf.

</span>
<span class="ltx_bibblock">Object-centric learning with slot attention.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2006.15055</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Mathias Niepert, Pasquale Minervini, and Luca Franceschi.

</span>
<span class="ltx_bibblock">Implicit MLE: Backpropagating through discrete exponential family distributions.

</span>
<span class="ltx_bibblock">In A.Â Beygelzimer, Y.Â Dauphin, P.Â Liang, and J.Â Wortman Vaughan, editors, <span class="ltx_text ltx_font_italic" id="bib.bib46.1.1">Advances in Neural Information Processing Systems</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Chendi Qian, Andrei Manolache, Kareem Ahmed, Zhe Zeng, GuyÂ Van den Broeck, Mathias Niepert, and Christopher Morris.

</span>
<span class="ltx_bibblock">Probabilistically rewired message-passing neural networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib47.1.1">ArXiv</span>, abs/2310.02156, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Peihao Wang, Shenghao Yang, Yunyu Liu, Zhangyang Wang, and Pan Li.

</span>
<span class="ltx_bibblock">Equivariant hypergraph diffusion neural operators.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2207.06680</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Dengyong Zhou, Jiayuan Huang, and Bernhard SchÃ¶lkopf.

</span>
<span class="ltx_bibblock">Learning with hypergraphs: Clustering, classification, and embedding.

</span>
<span class="ltx_bibblock">In B.Â SchÃ¶lkopf, J.Â Platt, and T.Â Hoffman, editors, <span class="ltx_text ltx_font_italic" id="bib.bib49.1.1">Advances in Neural Information Processing Systems</span>, volumeÂ 19. MIT Press, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Songyang Zhang, Zhi Ding, and Shuguang Cui.

</span>
<span class="ltx_bibblock">Introducing hypergraph signal processing: Theoretical foundation and practical applications.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib50.1.1">IEEE Internet of Things Journal</span>, 7(1):639â€“660, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Jiachen Li, Fan Yang, Masayoshi Tomizuka, and Chiho Choi.

</span>
<span class="ltx_bibblock">Evolvegraph: Multi-agent trajectory prediction with dynamic relational reasoning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib51.1.1">arXiv: Computer Vision and Pattern Recognition</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Yingfan Huang, Huikun Bi, Zhaoxin Li, Tianlu Mao, and Zhaoqi Wang.

</span>
<span class="ltx_bibblock">Stgat: Modeling spatial-temporal interactions for human trajectory prediction.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib52.1.1">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</span>, pages 6271â€“6280, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Tim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and Marco Pavone.

</span>
<span class="ltx_bibblock">Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib53.1.1">Computer Vision â€“ ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part XVIII</span>, page 683â€“700, Berlin, Heidelberg, 2020. Springer-Verlag.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Ross Greer, Nachiket Deo, and MohanÂ Manubhai Trivedi.

</span>
<span class="ltx_bibblock">Trajectory prediction in autonomous driving with a lane heading auxiliary loss.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib54.1.1">IEEE Robotics and Automation Letters</span>, 6:4907â€“4914, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Sepp Hochreiter and JÃ¼rgen Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib55.1.1">Neural computation</span>, 9(8):1735â€“1780, 1997.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_font_bold ltx_title_appendix" style="font-size:173%;">Appendix: SPHINX Structural Prediction using Hypergraph Inference Network</h2>
<div class="ltx_para" id="Ax1.p1">
<p class="ltx_p" id="Ax1.p1.1">This appendix contains details related to our proposed Structural Prediction using
Hypergraph Inference Network (SPHINX) model, including broader impact and potential limitations, qualitative visualisations from our model and the baselines we compared against in this paper, details about the proposed dataset, information about the implementation of the model and additional experiments referred in the main paper.</p>
</div>
<div class="ltx_para" id="Ax1.p2">
<ul class="ltx_itemize" id="Ax1.I1">
<li class="ltx_item" id="Ax1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="Ax1.I1.i1.p1">
<p class="ltx_p" id="Ax1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i1.p1.1.1">Section A</span> highlights a series of potential limitations that can be address to improve the current work, together with a discussion about the social impact of our approach.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="Ax1.I1.i2.p1">
<p class="ltx_p" id="Ax1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i2.p1.1.1">Section B</span> contains visualisation of the discovered hypergraph structure and the predicted trajectory for our proposed model and different variations of it.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="Ax1.I1.i3.p1">
<p class="ltx_p" id="Ax1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i3.p1.1.1">Section C</span> provides more details about the proposed synthetic dataset, further information about the method and its training process.</p>
</div>
</li>
<li class="ltx_item" id="Ax1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="Ax1.I1.i4.p1">
<p class="ltx_p" id="Ax1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="Ax1.I1.i4.p1.1.1">Section D</span> presents additional ablation studies showing the influence of varying the number of hyperedges in our model, but also a more detailed analysis of the synthetic experiments presented in the paper, including the numerical results.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Broader Impact &amp; Limitations</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">In this paper, we are proposing a framework for processing higher-order interactions in scenarios where a ground-truth hypergraph connectivity is either too expensive or not accessible at all. We are showing that our model is capable of recovering the latent higher-order structure without supervision at the hypergraph level, thus improving the final, higher-level performance. While we mainly tested on trajectory prediction tasks, our model is general and versatile and can be applied to any scenarios where we suspect capturing and modeling higher-order relations can be beneficial. Consequently, we believe that our model doesnâ€™t have any direct negative societal impact. Moreover, the method has the advantage of allowing us to inspect the learned latent hypergraph structure (as we can see in Section B of this Supplementary Material). This offer an advantage in terms of interpretability, allowing us to better understand and address potential mistakes in the modelâ€™s prediction.</p>
</div>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.3">By construction, our model predicts a set of <math alttext="M" class="ltx_Math" display="inline" id="A1.p2.1.m1.1"><semantics id="A1.p2.1.m1.1a"><mi id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><ci id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="A1.p2.1.m1.1d">italic_M</annotation></semantics></math> slots, each one corresponding to a hyperedge. This process is sequential, with one slot predicted at each time-step. While stopping criterion can be imposed to allow dynamic number of hyperedges, in order to be able to take advantage of the historical features <math alttext="b\in\{0,1\}^{N\times(M-1)}" class="ltx_Math" display="inline" id="A1.p2.2.m2.3"><semantics id="A1.p2.2.m2.3a"><mrow id="A1.p2.2.m2.3.4" xref="A1.p2.2.m2.3.4.cmml"><mi id="A1.p2.2.m2.3.4.2" xref="A1.p2.2.m2.3.4.2.cmml">b</mi><mo id="A1.p2.2.m2.3.4.1" xref="A1.p2.2.m2.3.4.1.cmml">âˆˆ</mo><msup id="A1.p2.2.m2.3.4.3" xref="A1.p2.2.m2.3.4.3.cmml"><mrow id="A1.p2.2.m2.3.4.3.2.2" xref="A1.p2.2.m2.3.4.3.2.1.cmml"><mo id="A1.p2.2.m2.3.4.3.2.2.1" stretchy="false" xref="A1.p2.2.m2.3.4.3.2.1.cmml">{</mo><mn id="A1.p2.2.m2.2.2" xref="A1.p2.2.m2.2.2.cmml">0</mn><mo id="A1.p2.2.m2.3.4.3.2.2.2" xref="A1.p2.2.m2.3.4.3.2.1.cmml">,</mo><mn id="A1.p2.2.m2.3.3" xref="A1.p2.2.m2.3.3.cmml">1</mn><mo id="A1.p2.2.m2.3.4.3.2.2.3" stretchy="false" xref="A1.p2.2.m2.3.4.3.2.1.cmml">}</mo></mrow><mrow id="A1.p2.2.m2.1.1.1" xref="A1.p2.2.m2.1.1.1.cmml"><mi id="A1.p2.2.m2.1.1.1.3" xref="A1.p2.2.m2.1.1.1.3.cmml">N</mi><mo id="A1.p2.2.m2.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="A1.p2.2.m2.1.1.1.2.cmml">Ã—</mo><mrow id="A1.p2.2.m2.1.1.1.1.1" xref="A1.p2.2.m2.1.1.1.1.1.1.cmml"><mo id="A1.p2.2.m2.1.1.1.1.1.2" stretchy="false" xref="A1.p2.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="A1.p2.2.m2.1.1.1.1.1.1" xref="A1.p2.2.m2.1.1.1.1.1.1.cmml"><mi id="A1.p2.2.m2.1.1.1.1.1.1.2" xref="A1.p2.2.m2.1.1.1.1.1.1.2.cmml">M</mi><mo id="A1.p2.2.m2.1.1.1.1.1.1.1" xref="A1.p2.2.m2.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="A1.p2.2.m2.1.1.1.1.1.1.3" xref="A1.p2.2.m2.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="A1.p2.2.m2.1.1.1.1.1.3" stretchy="false" xref="A1.p2.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.3b"><apply id="A1.p2.2.m2.3.4.cmml" xref="A1.p2.2.m2.3.4"><in id="A1.p2.2.m2.3.4.1.cmml" xref="A1.p2.2.m2.3.4.1"></in><ci id="A1.p2.2.m2.3.4.2.cmml" xref="A1.p2.2.m2.3.4.2">ğ‘</ci><apply id="A1.p2.2.m2.3.4.3.cmml" xref="A1.p2.2.m2.3.4.3"><csymbol cd="ambiguous" id="A1.p2.2.m2.3.4.3.1.cmml" xref="A1.p2.2.m2.3.4.3">superscript</csymbol><set id="A1.p2.2.m2.3.4.3.2.1.cmml" xref="A1.p2.2.m2.3.4.3.2.2"><cn id="A1.p2.2.m2.2.2.cmml" type="integer" xref="A1.p2.2.m2.2.2">0</cn><cn id="A1.p2.2.m2.3.3.cmml" type="integer" xref="A1.p2.2.m2.3.3">1</cn></set><apply id="A1.p2.2.m2.1.1.1.cmml" xref="A1.p2.2.m2.1.1.1"><times id="A1.p2.2.m2.1.1.1.2.cmml" xref="A1.p2.2.m2.1.1.1.2"></times><ci id="A1.p2.2.m2.1.1.1.3.cmml" xref="A1.p2.2.m2.1.1.1.3">ğ‘</ci><apply id="A1.p2.2.m2.1.1.1.1.1.1.cmml" xref="A1.p2.2.m2.1.1.1.1.1"><minus id="A1.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="A1.p2.2.m2.1.1.1.1.1.1.1"></minus><ci id="A1.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="A1.p2.2.m2.1.1.1.1.1.1.2">ğ‘€</ci><cn id="A1.p2.2.m2.1.1.1.1.1.1.3.cmml" type="integer" xref="A1.p2.2.m2.1.1.1.1.1.1.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.3c">b\in\{0,1\}^{N\times(M-1)}</annotation><annotation encoding="application/x-llamapun" id="A1.p2.2.m2.3d">italic_b âˆˆ { 0 , 1 } start_POSTSUPERSCRIPT italic_N Ã— ( italic_M - 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math> we need to have access to a pre-defined maximum number of hyperedges <math alttext="M" class="ltx_Math" display="inline" id="A1.p2.3.m3.1"><semantics id="A1.p2.3.m3.1a"><mi id="A1.p2.3.m3.1.1" xref="A1.p2.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A1.p2.3.m3.1b"><ci id="A1.p2.3.m3.1.1.cmml" xref="A1.p2.3.m3.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.3.m3.1c">M</annotation><annotation encoding="application/x-llamapun" id="A1.p2.3.m3.1d">italic_M</annotation></semantics></math>. In the current version of our work, this number is picked as a hyperparameter. However, in Section D, we experimentally show that the chosen value doesnâ€™t have a significant impact on the results. As long as the number of hyperedges is larger than the expected one, the performance doesnâ€™t decrease.</p>
</div>
<div class="ltx_para" id="A1.p3">
<p class="ltx_p" id="A1.p3.6">Furthermore, as we show in our experimental analysis, the <math alttext="k" class="ltx_Math" display="inline" id="A1.p3.1.m1.1"><semantics id="A1.p3.1.m1.1a"><mi id="A1.p3.1.m1.1.1" xref="A1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p3.1.m1.1b"><ci id="A1.p3.1.m1.1.1.cmml" xref="A1.p3.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p3.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling has a clear, positive impact on the performance of our model. However, this comes with a limitation: the sampled hyperedge is constrained to have exactly <math alttext="k" class="ltx_Math" display="inline" id="A1.p3.2.m2.1"><semantics id="A1.p3.2.m2.1a"><mi id="A1.p3.2.m2.1.1" xref="A1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p3.2.m2.1b"><ci id="A1.p3.2.m2.1.1.cmml" xref="A1.p3.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p3.2.m2.1d">italic_k</annotation></semantics></math> nodes. During training, this constrain helps the optimisation in terms of stability, allowing us to easily train our model without the need for regularisation or optimisation tricks. However, we are restricted to predict only <math alttext="k" class="ltx_Math" display="inline" id="A1.p3.3.m3.1"><semantics id="A1.p3.3.m3.1a"><mi id="A1.p3.3.m3.1.1" xref="A1.p3.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p3.3.m3.1b"><ci id="A1.p3.3.m3.1.1.cmml" xref="A1.p3.3.m3.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p3.3.m3.1d">italic_k</annotation></semantics></math>-regular hyperedges (i.e. hyperedges containing exactly <math alttext="k" class="ltx_Math" display="inline" id="A1.p3.4.m4.1"><semantics id="A1.p3.4.m4.1a"><mi id="A1.p3.4.m4.1.1" xref="A1.p3.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p3.4.m4.1b"><ci id="A1.p3.4.m4.1.1.cmml" xref="A1.p3.4.m4.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.4.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p3.4.m4.1d">italic_k</annotation></semantics></math> nodes). While in all our experiments we use the same constant <math alttext="k" class="ltx_Math" display="inline" id="A1.p3.5.m5.1"><semantics id="A1.p3.5.m5.1a"><mi id="A1.p3.5.m5.1.1" xref="A1.p3.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p3.5.m5.1b"><ci id="A1.p3.5.m5.1.1.cmml" xref="A1.p3.5.m5.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.5.m5.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p3.5.m5.1d">italic_k</annotation></semantics></math> for all hyperedges, the framework allows us to use a sequence of cardinalities, ones for each hyperedge. However, additional domain knowledge is needed to pre-determined this sequence. Since having extra slots proved to be harmless for our model, one solution is to provide a diverse list of <math alttext="k" class="ltx_Math" display="inline" id="A1.p3.6.m6.1"><semantics id="A1.p3.6.m6.1a"><mi id="A1.p3.6.m6.1.1" xref="A1.p3.6.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p3.6.m6.1b"><ci id="A1.p3.6.m6.1.1.cmml" xref="A1.p3.6.m6.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.6.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p3.6.m6.1d">italic_k</annotation></semantics></math> such that it covers a broader range of possibilities. While interesting to explore, these experiments are left as future work.</p>
</div>
<div class="ltx_para" id="A1.p4">
<p class="ltx_p" id="A1.p4.1">In order to better align with the current literature, we mainly validate our model on the trajectory prediction task. However, in the current form, our model predicts a single hypergraph structure for the entire trajectory. This is well suited for the synthetic benchmark, where the dynamics for each example is determined by a single hypergraph structure, that does not change in time. On the other hand, in real-world setups, such as the NBA dataset, the higher-order interactions between the players might change along the game. Thus, having a distinct, dynamic hypergraph structure, that evolves in time, could be beneficial. However, solving trajectory prediction is not the main goal for our model. Instead, our purpose is to have a general model, that allows us to infer and process higher-order interaction. We believe that adapting SPHINX to more specific scenarios, such as creating a dynamic, evolving structure is an interesting area for future work.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Visualisations</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">One of the advantages brought by our method is providing a discrete latent hypergraph structure, that can be easily visualise, offering a higher level of interpretability compared to attention-based methods.
FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A3.F6" title="Figure 6 â€£ C.1 Datasets details â€£ Appendix C Experimental details â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">6</span></a> shows the trajectories and latent structure learned by our model on some examples from the Two-Triangles and NBA datasets. We are visualising the ground-truth trajectories, the trajectories and structure predicted by our full model, and the trajectories and learned structure corresponding to the model used in our ablation study: <span class="ltx_text ltx_font_italic" id="A2.p1.1.1">SPHINX w/o sequential</span> and <span class="ltx_text ltx_font_italic" id="A2.p1.1.2">SPHINX w Gumbel</span>.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">When the slots are predicted in parallel, without access to the already predicted hyperedges (the model called <span class="ltx_text ltx_font_italic" id="A2.p2.1.1">SPHINX w/o sequential</span>), the slots tends to collapse in a single hyperedge represented by all the slots. On the other hand, removing the constraints on the cardinality of the hyperedges, by applying Gumbel-Softmax (the model called <span class="ltx_text ltx_font_italic" id="A2.p2.1.2">SPHINX w Gumbel</span>) , the optimisation process leads to "greedy" slots, that covers all the nodes in the hypergraph.</p>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.1">In contrast, our <span class="ltx_text ltx_font_italic" id="A2.p3.1.1">SPHINX</span> model learns sparse and intuitive hypergraph structures, alleviating the slot collapsing behaviour. On the synthetic dataset, the predicted hypergraph highly coincide with the real connectivity. By inspecting the higher-order structures learned by our model on the NBA dataset, we observe that most of the inferred hyperedges contains the node associated with the ball (denoted as a white node in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A3.F6" title="Figure 6 â€£ C.1 Datasets details â€£ Appendix C Experimental details â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">6</span></a>). we believe that this is a natural choice, since the position of the ball should have a critical influence on the decision taken by all basketball players.</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experimental details</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Datasets details</h3>
<figure class="ltx_figure" id="A3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="96" id="A3.F5.g1" src="extracted/5900948/figures/examples_dataset.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="A3.F5.2.1">Examples of <math alttext="25" class="ltx_Math" display="inline" id="A3.F5.2.1.m1.1"><semantics id="A3.F5.2.1.m1.1b"><mn id="A3.F5.2.1.m1.1.1" xref="A3.F5.2.1.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A3.F5.2.1.m1.1c"><cn id="A3.F5.2.1.m1.1.1.cmml" type="integer" xref="A3.F5.2.1.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.F5.2.1.m1.1d">25</annotation><annotation encoding="application/x-llamapun" id="A3.F5.2.1.m1.1e">25</annotation></semantics></math>-steps trajectories from the Particle Simulation datasets</span> for both the One-Triangle and the Two-Triangles variants. The highlighted triangles represent the 3-order interactions used to generate the trajectories.</figcaption>
</figure>
<div class="ltx_para" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">We create a synthetic benchmark, Particle Simulation, to validate the capabilities of our model in terms of downstream performance, while also enabling the evaluation of the predicted higher-order interactions. Previous works used various synthetic setups to achieve this goal. However, to our knowledge, none of them are publicly available.</p>
</div>
<div class="ltx_para" id="A3.SS1.p2">
<p class="ltx_p" id="A3.SS1.p2.7">Particle Simulation dataset contains a set of particles moving according to a higher-order law. Each example in our dataset consists of <math alttext="N=6" class="ltx_Math" display="inline" id="A3.SS1.p2.1.m1.1"><semantics id="A3.SS1.p2.1.m1.1a"><mrow id="A3.SS1.p2.1.m1.1.1" xref="A3.SS1.p2.1.m1.1.1.cmml"><mi id="A3.SS1.p2.1.m1.1.1.2" xref="A3.SS1.p2.1.m1.1.1.2.cmml">N</mi><mo id="A3.SS1.p2.1.m1.1.1.1" xref="A3.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="A3.SS1.p2.1.m1.1.1.3" xref="A3.SS1.p2.1.m1.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.1.m1.1b"><apply id="A3.SS1.p2.1.m1.1.1.cmml" xref="A3.SS1.p2.1.m1.1.1"><eq id="A3.SS1.p2.1.m1.1.1.1.cmml" xref="A3.SS1.p2.1.m1.1.1.1"></eq><ci id="A3.SS1.p2.1.m1.1.1.2.cmml" xref="A3.SS1.p2.1.m1.1.1.2">ğ‘</ci><cn id="A3.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="A3.SS1.p2.1.m1.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.1.m1.1c">N=6</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.1.m1.1d">italic_N = 6</annotation></semantics></math> particles moving in a 2D space. Among them, <math alttext="K" class="ltx_Math" display="inline" id="A3.SS1.p2.2.m2.1"><semantics id="A3.SS1.p2.2.m2.1a"><mi id="A3.SS1.p2.2.m2.1.1" xref="A3.SS1.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.2.m2.1b"><ci id="A3.SS1.p2.2.m2.1.1.cmml" xref="A3.SS1.p2.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.2.m2.1d">italic_K</annotation></semantics></math> random triangles where uniformly sampled to represent <math alttext="K" class="ltx_Math" display="inline" id="A3.SS1.p2.3.m3.1"><semantics id="A3.SS1.p2.3.m3.1a"><mi id="A3.SS1.p2.3.m3.1.1" xref="A3.SS1.p2.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.3.m3.1b"><ci id="A3.SS1.p2.3.m3.1.1.cmml" xref="A3.SS1.p2.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.3.m3.1d">italic_K</annotation></semantics></math> 3-order interactions. All the particles that are part of a triangles are rotating around the triangleâ€™s center of mass with an angular velocity <math alttext="\theta_{i}" class="ltx_Math" display="inline" id="A3.SS1.p2.4.m4.1"><semantics id="A3.SS1.p2.4.m4.1a"><msub id="A3.SS1.p2.4.m4.1.1" xref="A3.SS1.p2.4.m4.1.1.cmml"><mi id="A3.SS1.p2.4.m4.1.1.2" xref="A3.SS1.p2.4.m4.1.1.2.cmml">Î¸</mi><mi id="A3.SS1.p2.4.m4.1.1.3" xref="A3.SS1.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.4.m4.1b"><apply id="A3.SS1.p2.4.m4.1.1.cmml" xref="A3.SS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="A3.SS1.p2.4.m4.1.1.1.cmml" xref="A3.SS1.p2.4.m4.1.1">subscript</csymbol><ci id="A3.SS1.p2.4.m4.1.1.2.cmml" xref="A3.SS1.p2.4.m4.1.1.2">ğœƒ</ci><ci id="A3.SS1.p2.4.m4.1.1.3.cmml" xref="A3.SS1.p2.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.4.m4.1c">\theta_{i}</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.4.m4.1d">italic_Î¸ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> randomly sampled for each particle <math alttext="i" class="ltx_Math" display="inline" id="A3.SS1.p2.5.m5.1"><semantics id="A3.SS1.p2.5.m5.1a"><mi id="A3.SS1.p2.5.m5.1.1" xref="A3.SS1.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.5.m5.1b"><ci id="A3.SS1.p2.5.m5.1.1.cmml" xref="A3.SS1.p2.5.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.5.m5.1d">italic_i</annotation></semantics></math>. If one particle is part of multiple triangles, the rotation will happen around their average center of mass. The task is, given the first <math alttext="t=22" class="ltx_Math" display="inline" id="A3.SS1.p2.6.m6.1"><semantics id="A3.SS1.p2.6.m6.1a"><mrow id="A3.SS1.p2.6.m6.1.1" xref="A3.SS1.p2.6.m6.1.1.cmml"><mi id="A3.SS1.p2.6.m6.1.1.2" xref="A3.SS1.p2.6.m6.1.1.2.cmml">t</mi><mo id="A3.SS1.p2.6.m6.1.1.1" xref="A3.SS1.p2.6.m6.1.1.1.cmml">=</mo><mn id="A3.SS1.p2.6.m6.1.1.3" xref="A3.SS1.p2.6.m6.1.1.3.cmml">22</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.6.m6.1b"><apply id="A3.SS1.p2.6.m6.1.1.cmml" xref="A3.SS1.p2.6.m6.1.1"><eq id="A3.SS1.p2.6.m6.1.1.1.cmml" xref="A3.SS1.p2.6.m6.1.1.1"></eq><ci id="A3.SS1.p2.6.m6.1.1.2.cmml" xref="A3.SS1.p2.6.m6.1.1.2">ğ‘¡</ci><cn id="A3.SS1.p2.6.m6.1.1.3.cmml" type="integer" xref="A3.SS1.p2.6.m6.1.1.3">22</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.6.m6.1c">t=22</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.6.m6.1d">italic_t = 22</annotation></semantics></math> time steps of the trajectory (only the position of the particles and the angle velocity associated with the particles, no triangles provided), to be able to predict the rest of the trajectory (<math alttext="25" class="ltx_Math" display="inline" id="A3.SS1.p2.7.m7.1"><semantics id="A3.SS1.p2.7.m7.1a"><mn id="A3.SS1.p2.7.m7.1.1" xref="A3.SS1.p2.7.m7.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A3.SS1.p2.7.m7.1b"><cn id="A3.SS1.p2.7.m7.1.1.cmml" type="integer" xref="A3.SS1.p2.7.m7.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p2.7.m7.1c">25</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p2.7.m7.1d">25</annotation></semantics></math> steps). Note that, for each example in the dataset, we have different triangles connecting the particles. Given the hypergraph structure, the task satisfy the Markovian property, but in order to predict the hypergraph structure you need access to at least 2 consecutive timesteps.</p>
</div>
<div class="ltx_para" id="A3.SS1.p3">
<p class="ltx_p" id="A3.SS1.p3.3">We create two variants of the dataset. A simpler one, containing a single higher-order interaction per trajectory (denoted as One-Triangle), and a more challenging one containing two higher-order interaction per trajectory (denoted as Two-Triangles). Each dataset contains <math alttext="1000" class="ltx_Math" display="inline" id="A3.SS1.p3.1.m1.1"><semantics id="A3.SS1.p3.1.m1.1a"><mn id="A3.SS1.p3.1.m1.1.1" xref="A3.SS1.p3.1.m1.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.SS1.p3.1.m1.1b"><cn id="A3.SS1.p3.1.m1.1.1.cmml" type="integer" xref="A3.SS1.p3.1.m1.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p3.1.m1.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p3.1.m1.1d">1000</annotation></semantics></math> training, <math alttext="1000" class="ltx_Math" display="inline" id="A3.SS1.p3.2.m2.1"><semantics id="A3.SS1.p3.2.m2.1a"><mn id="A3.SS1.p3.2.m2.1.1" xref="A3.SS1.p3.2.m2.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.SS1.p3.2.m2.1b"><cn id="A3.SS1.p3.2.m2.1.1.cmml" type="integer" xref="A3.SS1.p3.2.m2.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p3.2.m2.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p3.2.m2.1d">1000</annotation></semantics></math> validation and <math alttext="1000" class="ltx_Math" display="inline" id="A3.SS1.p3.3.m3.1"><semantics id="A3.SS1.p3.3.m3.1a"><mn id="A3.SS1.p3.3.m3.1.1" xref="A3.SS1.p3.3.m3.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.SS1.p3.3.m3.1b"><cn id="A3.SS1.p3.3.m3.1.1.cmml" type="integer" xref="A3.SS1.p3.3.m3.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p3.3.m3.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p3.3.m3.1d">1000</annotation></semantics></math> test trajectories.</p>
</div>
<div class="ltx_para" id="A3.SS1.p4">
<p class="ltx_p" id="A3.SS1.p4.1">Some examples of the datasets are depicted in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A3.F5" title="Figure 5 â€£ C.1 Datasets details â€£ Appendix C Experimental details â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_figure" id="A3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="563" id="A3.F6.g1" src="extracted/5900948/figures/visual_ablation.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="A3.F6.2.1">Visualisation of the trajectories</span> predicted by our full model (SPHINX) and the two variations used in the ablation study (SPHINX w/o sequential and SPHINX w Gumbel) on the Two-Triangles and NBA dataset. In the ground-truth column the highlighted polygons represent the true connectivity, while for the models they represent the discovered hyperedges. Both using Gumbel-Softmax and dropping the sequential prediction clearly impact the predicted hypergraphs. On the other hand, our model manage to discover diverse structures, close to the ground0truth ones in the synthetic scenario.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Implementation details</h3>
<div class="ltx_para ltx_noindent" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.SS2.p1.1.1">Model details. </span> To encode the observed part of the trajectory into the hypergraph predictor, we are experimenting with two variants. Either we are using an MLP that receives the concatenation of the nodeâ€™s coordinates from all timesteps, or a 1D temporal Convolutional Neural Network acting on the temporal dimension.</p>
</div>
<div class="ltx_para" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.1">For the synthetic dataset, both the hypergraph predictor and the hypergraph processor are receiving as input the (x,y) coordinates of each node, while for the NBA dataset the spatial coordinates are enriched with information about the velocity (the real velocity for the observed trajectory and the estimated one during evaluation).</p>
</div>
<div class="ltx_para" id="A3.SS2.p3">
<p class="ltx_p" id="A3.SS2.p3.3">For the AllDeepSets model, used as Hypergraph Processor, we adapt the standard architecture, by incorporating information about the angular velocity <math alttext="\theta_{i}" class="ltx_Math" display="inline" id="A3.SS2.p3.1.m1.1"><semantics id="A3.SS2.p3.1.m1.1a"><msub id="A3.SS2.p3.1.m1.1.1" xref="A3.SS2.p3.1.m1.1.1.cmml"><mi id="A3.SS2.p3.1.m1.1.1.2" xref="A3.SS2.p3.1.m1.1.1.2.cmml">Î¸</mi><mi id="A3.SS2.p3.1.m1.1.1.3" xref="A3.SS2.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.SS2.p3.1.m1.1b"><apply id="A3.SS2.p3.1.m1.1.1.cmml" xref="A3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A3.SS2.p3.1.m1.1.1.1.cmml" xref="A3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="A3.SS2.p3.1.m1.1.1.2.cmml" xref="A3.SS2.p3.1.m1.1.1.2">ğœƒ</ci><ci id="A3.SS2.p3.1.m1.1.1.3.cmml" xref="A3.SS2.p3.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p3.1.m1.1c">\theta_{i}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p3.1.m1.1d">italic_Î¸ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> at each layer, in the form of <math alttext="sin(\theta_{i})" class="ltx_Math" display="inline" id="A3.SS2.p3.2.m2.1"><semantics id="A3.SS2.p3.2.m2.1a"><mrow id="A3.SS2.p3.2.m2.1.1" xref="A3.SS2.p3.2.m2.1.1.cmml"><mi id="A3.SS2.p3.2.m2.1.1.3" xref="A3.SS2.p3.2.m2.1.1.3.cmml">s</mi><mo id="A3.SS2.p3.2.m2.1.1.2" xref="A3.SS2.p3.2.m2.1.1.2.cmml">â¢</mo><mi id="A3.SS2.p3.2.m2.1.1.4" xref="A3.SS2.p3.2.m2.1.1.4.cmml">i</mi><mo id="A3.SS2.p3.2.m2.1.1.2a" xref="A3.SS2.p3.2.m2.1.1.2.cmml">â¢</mo><mi id="A3.SS2.p3.2.m2.1.1.5" xref="A3.SS2.p3.2.m2.1.1.5.cmml">n</mi><mo id="A3.SS2.p3.2.m2.1.1.2b" xref="A3.SS2.p3.2.m2.1.1.2.cmml">â¢</mo><mrow id="A3.SS2.p3.2.m2.1.1.1.1" xref="A3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mo id="A3.SS2.p3.2.m2.1.1.1.1.2" stretchy="false" xref="A3.SS2.p3.2.m2.1.1.1.1.1.cmml">(</mo><msub id="A3.SS2.p3.2.m2.1.1.1.1.1" xref="A3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="A3.SS2.p3.2.m2.1.1.1.1.1.2" xref="A3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">Î¸</mi><mi id="A3.SS2.p3.2.m2.1.1.1.1.1.3" xref="A3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A3.SS2.p3.2.m2.1.1.1.1.3" stretchy="false" xref="A3.SS2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p3.2.m2.1b"><apply id="A3.SS2.p3.2.m2.1.1.cmml" xref="A3.SS2.p3.2.m2.1.1"><times id="A3.SS2.p3.2.m2.1.1.2.cmml" xref="A3.SS2.p3.2.m2.1.1.2"></times><ci id="A3.SS2.p3.2.m2.1.1.3.cmml" xref="A3.SS2.p3.2.m2.1.1.3">ğ‘ </ci><ci id="A3.SS2.p3.2.m2.1.1.4.cmml" xref="A3.SS2.p3.2.m2.1.1.4">ğ‘–</ci><ci id="A3.SS2.p3.2.m2.1.1.5.cmml" xref="A3.SS2.p3.2.m2.1.1.5">ğ‘›</ci><apply id="A3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="A3.SS2.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="A3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="A3.SS2.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="A3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="A3.SS2.p3.2.m2.1.1.1.1.1.2">ğœƒ</ci><ci id="A3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="A3.SS2.p3.2.m2.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p3.2.m2.1c">sin(\theta_{i})</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p3.2.m2.1d">italic_s italic_i italic_n ( italic_Î¸ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, <math alttext="cos(\theta_{i})" class="ltx_Math" display="inline" id="A3.SS2.p3.3.m3.1"><semantics id="A3.SS2.p3.3.m3.1a"><mrow id="A3.SS2.p3.3.m3.1.1" xref="A3.SS2.p3.3.m3.1.1.cmml"><mi id="A3.SS2.p3.3.m3.1.1.3" xref="A3.SS2.p3.3.m3.1.1.3.cmml">c</mi><mo id="A3.SS2.p3.3.m3.1.1.2" xref="A3.SS2.p3.3.m3.1.1.2.cmml">â¢</mo><mi id="A3.SS2.p3.3.m3.1.1.4" xref="A3.SS2.p3.3.m3.1.1.4.cmml">o</mi><mo id="A3.SS2.p3.3.m3.1.1.2a" xref="A3.SS2.p3.3.m3.1.1.2.cmml">â¢</mo><mi id="A3.SS2.p3.3.m3.1.1.5" xref="A3.SS2.p3.3.m3.1.1.5.cmml">s</mi><mo id="A3.SS2.p3.3.m3.1.1.2b" xref="A3.SS2.p3.3.m3.1.1.2.cmml">â¢</mo><mrow id="A3.SS2.p3.3.m3.1.1.1.1" xref="A3.SS2.p3.3.m3.1.1.1.1.1.cmml"><mo id="A3.SS2.p3.3.m3.1.1.1.1.2" stretchy="false" xref="A3.SS2.p3.3.m3.1.1.1.1.1.cmml">(</mo><msub id="A3.SS2.p3.3.m3.1.1.1.1.1" xref="A3.SS2.p3.3.m3.1.1.1.1.1.cmml"><mi id="A3.SS2.p3.3.m3.1.1.1.1.1.2" xref="A3.SS2.p3.3.m3.1.1.1.1.1.2.cmml">Î¸</mi><mi id="A3.SS2.p3.3.m3.1.1.1.1.1.3" xref="A3.SS2.p3.3.m3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A3.SS2.p3.3.m3.1.1.1.1.3" stretchy="false" xref="A3.SS2.p3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p3.3.m3.1b"><apply id="A3.SS2.p3.3.m3.1.1.cmml" xref="A3.SS2.p3.3.m3.1.1"><times id="A3.SS2.p3.3.m3.1.1.2.cmml" xref="A3.SS2.p3.3.m3.1.1.2"></times><ci id="A3.SS2.p3.3.m3.1.1.3.cmml" xref="A3.SS2.p3.3.m3.1.1.3">ğ‘</ci><ci id="A3.SS2.p3.3.m3.1.1.4.cmml" xref="A3.SS2.p3.3.m3.1.1.4">ğ‘œ</ci><ci id="A3.SS2.p3.3.m3.1.1.5.cmml" xref="A3.SS2.p3.3.m3.1.1.5">ğ‘ </ci><apply id="A3.SS2.p3.3.m3.1.1.1.1.1.cmml" xref="A3.SS2.p3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="A3.SS2.p3.3.m3.1.1.1.1.1.1.cmml" xref="A3.SS2.p3.3.m3.1.1.1.1">subscript</csymbol><ci id="A3.SS2.p3.3.m3.1.1.1.1.1.2.cmml" xref="A3.SS2.p3.3.m3.1.1.1.1.1.2">ğœƒ</ci><ci id="A3.SS2.p3.3.m3.1.1.1.1.1.3.cmml" xref="A3.SS2.p3.3.m3.1.1.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p3.3.m3.1c">cos(\theta_{i})</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p3.3.m3.1d">italic_c italic_o italic_s ( italic_Î¸ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> concatenated to each node at the end of each layer.</p>
</div>
<div class="ltx_para" id="A3.SS2.p4">
<p class="ltx_p" id="A3.SS2.p4.14">Unless otherwise specified, the results reported in the main paper are obtained using hyper-parameter tuning. We are performing bayesian hyperparameter tuning, setting the base learning rate at <math alttext="0.001" class="ltx_Math" display="inline" id="A3.SS2.p4.1.m1.1"><semantics id="A3.SS2.p4.1.m1.1a"><mn id="A3.SS2.p4.1.m1.1.1" xref="A3.SS2.p4.1.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.1.m1.1b"><cn id="A3.SS2.p4.1.m1.1.1.cmml" type="float" xref="A3.SS2.p4.1.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.1.m1.1c">0.001</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.1.m1.1d">0.001</annotation></semantics></math>, multiplied with a factor of <math alttext="\text{d}\in\{0.1,1.0,10.0\}" class="ltx_Math" display="inline" id="A3.SS2.p4.2.m2.3"><semantics id="A3.SS2.p4.2.m2.3a"><mrow id="A3.SS2.p4.2.m2.3.4" xref="A3.SS2.p4.2.m2.3.4.cmml"><mtext id="A3.SS2.p4.2.m2.3.4.2" xref="A3.SS2.p4.2.m2.3.4.2a.cmml">d</mtext><mo id="A3.SS2.p4.2.m2.3.4.1" xref="A3.SS2.p4.2.m2.3.4.1.cmml">âˆˆ</mo><mrow id="A3.SS2.p4.2.m2.3.4.3.2" xref="A3.SS2.p4.2.m2.3.4.3.1.cmml"><mo id="A3.SS2.p4.2.m2.3.4.3.2.1" stretchy="false" xref="A3.SS2.p4.2.m2.3.4.3.1.cmml">{</mo><mn id="A3.SS2.p4.2.m2.1.1" xref="A3.SS2.p4.2.m2.1.1.cmml">0.1</mn><mo id="A3.SS2.p4.2.m2.3.4.3.2.2" xref="A3.SS2.p4.2.m2.3.4.3.1.cmml">,</mo><mn id="A3.SS2.p4.2.m2.2.2" xref="A3.SS2.p4.2.m2.2.2.cmml">1.0</mn><mo id="A3.SS2.p4.2.m2.3.4.3.2.3" xref="A3.SS2.p4.2.m2.3.4.3.1.cmml">,</mo><mn id="A3.SS2.p4.2.m2.3.3" xref="A3.SS2.p4.2.m2.3.3.cmml">10.0</mn><mo id="A3.SS2.p4.2.m2.3.4.3.2.4" stretchy="false" xref="A3.SS2.p4.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.2.m2.3b"><apply id="A3.SS2.p4.2.m2.3.4.cmml" xref="A3.SS2.p4.2.m2.3.4"><in id="A3.SS2.p4.2.m2.3.4.1.cmml" xref="A3.SS2.p4.2.m2.3.4.1"></in><ci id="A3.SS2.p4.2.m2.3.4.2a.cmml" xref="A3.SS2.p4.2.m2.3.4.2"><mtext id="A3.SS2.p4.2.m2.3.4.2.cmml" xref="A3.SS2.p4.2.m2.3.4.2">d</mtext></ci><set id="A3.SS2.p4.2.m2.3.4.3.1.cmml" xref="A3.SS2.p4.2.m2.3.4.3.2"><cn id="A3.SS2.p4.2.m2.1.1.cmml" type="float" xref="A3.SS2.p4.2.m2.1.1">0.1</cn><cn id="A3.SS2.p4.2.m2.2.2.cmml" type="float" xref="A3.SS2.p4.2.m2.2.2">1.0</cn><cn id="A3.SS2.p4.2.m2.3.3.cmml" type="float" xref="A3.SS2.p4.2.m2.3.3">10.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.2.m2.3c">\text{d}\in\{0.1,1.0,10.0\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.2.m2.3d">d âˆˆ { 0.1 , 1.0 , 10.0 }</annotation></semantics></math> when learning the parameters corresponding to the hypergraph predictor, a batch size of <math alttext="128" class="ltx_Math" display="inline" id="A3.SS2.p4.3.m3.1"><semantics id="A3.SS2.p4.3.m3.1a"><mn id="A3.SS2.p4.3.m3.1.1" xref="A3.SS2.p4.3.m3.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.3.m3.1b"><cn id="A3.SS2.p4.3.m3.1.1.cmml" type="integer" xref="A3.SS2.p4.3.m3.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.3.m3.1c">128</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.3.m3.1d">128</annotation></semantics></math>, self-loop added into the structure. The hidden state is picked from the set of values <math alttext="\{32,64,128,256\}" class="ltx_Math" display="inline" id="A3.SS2.p4.4.m4.4"><semantics id="A3.SS2.p4.4.m4.4a"><mrow id="A3.SS2.p4.4.m4.4.5.2" xref="A3.SS2.p4.4.m4.4.5.1.cmml"><mo id="A3.SS2.p4.4.m4.4.5.2.1" stretchy="false" xref="A3.SS2.p4.4.m4.4.5.1.cmml">{</mo><mn id="A3.SS2.p4.4.m4.1.1" xref="A3.SS2.p4.4.m4.1.1.cmml">32</mn><mo id="A3.SS2.p4.4.m4.4.5.2.2" xref="A3.SS2.p4.4.m4.4.5.1.cmml">,</mo><mn id="A3.SS2.p4.4.m4.2.2" xref="A3.SS2.p4.4.m4.2.2.cmml">64</mn><mo id="A3.SS2.p4.4.m4.4.5.2.3" xref="A3.SS2.p4.4.m4.4.5.1.cmml">,</mo><mn id="A3.SS2.p4.4.m4.3.3" xref="A3.SS2.p4.4.m4.3.3.cmml">128</mn><mo id="A3.SS2.p4.4.m4.4.5.2.4" xref="A3.SS2.p4.4.m4.4.5.1.cmml">,</mo><mn id="A3.SS2.p4.4.m4.4.4" xref="A3.SS2.p4.4.m4.4.4.cmml">256</mn><mo id="A3.SS2.p4.4.m4.4.5.2.5" stretchy="false" xref="A3.SS2.p4.4.m4.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.4.m4.4b"><set id="A3.SS2.p4.4.m4.4.5.1.cmml" xref="A3.SS2.p4.4.m4.4.5.2"><cn id="A3.SS2.p4.4.m4.1.1.cmml" type="integer" xref="A3.SS2.p4.4.m4.1.1">32</cn><cn id="A3.SS2.p4.4.m4.2.2.cmml" type="integer" xref="A3.SS2.p4.4.m4.2.2">64</cn><cn id="A3.SS2.p4.4.m4.3.3.cmml" type="integer" xref="A3.SS2.p4.4.m4.3.3">128</cn><cn id="A3.SS2.p4.4.m4.4.4.cmml" type="integer" xref="A3.SS2.p4.4.m4.4.4">256</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.4.m4.4c">\{32,64,128,256\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.4.m4.4d">{ 32 , 64 , 128 , 256 }</annotation></semantics></math>, the number of AllDeepSets layers from <math alttext="\{1,2\}" class="ltx_Math" display="inline" id="A3.SS2.p4.5.m5.2"><semantics id="A3.SS2.p4.5.m5.2a"><mrow id="A3.SS2.p4.5.m5.2.3.2" xref="A3.SS2.p4.5.m5.2.3.1.cmml"><mo id="A3.SS2.p4.5.m5.2.3.2.1" stretchy="false" xref="A3.SS2.p4.5.m5.2.3.1.cmml">{</mo><mn id="A3.SS2.p4.5.m5.1.1" xref="A3.SS2.p4.5.m5.1.1.cmml">1</mn><mo id="A3.SS2.p4.5.m5.2.3.2.2" xref="A3.SS2.p4.5.m5.2.3.1.cmml">,</mo><mn id="A3.SS2.p4.5.m5.2.2" xref="A3.SS2.p4.5.m5.2.2.cmml">2</mn><mo id="A3.SS2.p4.5.m5.2.3.2.3" stretchy="false" xref="A3.SS2.p4.5.m5.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.5.m5.2b"><set id="A3.SS2.p4.5.m5.2.3.1.cmml" xref="A3.SS2.p4.5.m5.2.3.2"><cn id="A3.SS2.p4.5.m5.1.1.cmml" type="integer" xref="A3.SS2.p4.5.m5.1.1">1</cn><cn id="A3.SS2.p4.5.m5.2.2.cmml" type="integer" xref="A3.SS2.p4.5.m5.2.2">2</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.5.m5.2c">\{1,2\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.5.m5.2d">{ 1 , 2 }</annotation></semantics></math>, the number of layers for the used MLPs from <math alttext="\{2,3,4\}" class="ltx_Math" display="inline" id="A3.SS2.p4.6.m6.3"><semantics id="A3.SS2.p4.6.m6.3a"><mrow id="A3.SS2.p4.6.m6.3.4.2" xref="A3.SS2.p4.6.m6.3.4.1.cmml"><mo id="A3.SS2.p4.6.m6.3.4.2.1" stretchy="false" xref="A3.SS2.p4.6.m6.3.4.1.cmml">{</mo><mn id="A3.SS2.p4.6.m6.1.1" xref="A3.SS2.p4.6.m6.1.1.cmml">2</mn><mo id="A3.SS2.p4.6.m6.3.4.2.2" xref="A3.SS2.p4.6.m6.3.4.1.cmml">,</mo><mn id="A3.SS2.p4.6.m6.2.2" xref="A3.SS2.p4.6.m6.2.2.cmml">3</mn><mo id="A3.SS2.p4.6.m6.3.4.2.3" xref="A3.SS2.p4.6.m6.3.4.1.cmml">,</mo><mn id="A3.SS2.p4.6.m6.3.3" xref="A3.SS2.p4.6.m6.3.3.cmml">4</mn><mo id="A3.SS2.p4.6.m6.3.4.2.4" stretchy="false" xref="A3.SS2.p4.6.m6.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.6.m6.3b"><set id="A3.SS2.p4.6.m6.3.4.1.cmml" xref="A3.SS2.p4.6.m6.3.4.2"><cn id="A3.SS2.p4.6.m6.1.1.cmml" type="integer" xref="A3.SS2.p4.6.m6.1.1">2</cn><cn id="A3.SS2.p4.6.m6.2.2.cmml" type="integer" xref="A3.SS2.p4.6.m6.2.2">3</cn><cn id="A3.SS2.p4.6.m6.3.3.cmml" type="integer" xref="A3.SS2.p4.6.m6.3.3">4</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.6.m6.3c">\{2,3,4\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.6.m6.3d">{ 2 , 3 , 4 }</annotation></semantics></math>, the number of hyperedges from <math alttext="\{1,2,3,5,7\}" class="ltx_Math" display="inline" id="A3.SS2.p4.7.m7.5"><semantics id="A3.SS2.p4.7.m7.5a"><mrow id="A3.SS2.p4.7.m7.5.6.2" xref="A3.SS2.p4.7.m7.5.6.1.cmml"><mo id="A3.SS2.p4.7.m7.5.6.2.1" stretchy="false" xref="A3.SS2.p4.7.m7.5.6.1.cmml">{</mo><mn id="A3.SS2.p4.7.m7.1.1" xref="A3.SS2.p4.7.m7.1.1.cmml">1</mn><mo id="A3.SS2.p4.7.m7.5.6.2.2" xref="A3.SS2.p4.7.m7.5.6.1.cmml">,</mo><mn id="A3.SS2.p4.7.m7.2.2" xref="A3.SS2.p4.7.m7.2.2.cmml">2</mn><mo id="A3.SS2.p4.7.m7.5.6.2.3" xref="A3.SS2.p4.7.m7.5.6.1.cmml">,</mo><mn id="A3.SS2.p4.7.m7.3.3" xref="A3.SS2.p4.7.m7.3.3.cmml">3</mn><mo id="A3.SS2.p4.7.m7.5.6.2.4" xref="A3.SS2.p4.7.m7.5.6.1.cmml">,</mo><mn id="A3.SS2.p4.7.m7.4.4" xref="A3.SS2.p4.7.m7.4.4.cmml">5</mn><mo id="A3.SS2.p4.7.m7.5.6.2.5" xref="A3.SS2.p4.7.m7.5.6.1.cmml">,</mo><mn id="A3.SS2.p4.7.m7.5.5" xref="A3.SS2.p4.7.m7.5.5.cmml">7</mn><mo id="A3.SS2.p4.7.m7.5.6.2.6" stretchy="false" xref="A3.SS2.p4.7.m7.5.6.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.7.m7.5b"><set id="A3.SS2.p4.7.m7.5.6.1.cmml" xref="A3.SS2.p4.7.m7.5.6.2"><cn id="A3.SS2.p4.7.m7.1.1.cmml" type="integer" xref="A3.SS2.p4.7.m7.1.1">1</cn><cn id="A3.SS2.p4.7.m7.2.2.cmml" type="integer" xref="A3.SS2.p4.7.m7.2.2">2</cn><cn id="A3.SS2.p4.7.m7.3.3.cmml" type="integer" xref="A3.SS2.p4.7.m7.3.3">3</cn><cn id="A3.SS2.p4.7.m7.4.4.cmml" type="integer" xref="A3.SS2.p4.7.m7.4.4">5</cn><cn id="A3.SS2.p4.7.m7.5.5.cmml" type="integer" xref="A3.SS2.p4.7.m7.5.5">7</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.7.m7.5c">\{1,2,3,5,7\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.7.m7.5d">{ 1 , 2 , 3 , 5 , 7 }</annotation></semantics></math> (except for the synthetic setup where the number of hyperedges is set to <math alttext="1" class="ltx_Math" display="inline" id="A3.SS2.p4.8.m8.1"><semantics id="A3.SS2.p4.8.m8.1a"><mn id="A3.SS2.p4.8.m8.1.1" xref="A3.SS2.p4.8.m8.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.8.m8.1b"><cn id="A3.SS2.p4.8.m8.1.1.cmml" type="integer" xref="A3.SS2.p4.8.m8.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.8.m8.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.8.m8.1d">1</annotation></semantics></math> and <math alttext="2" class="ltx_Math" display="inline" id="A3.SS2.p4.9.m9.1"><semantics id="A3.SS2.p4.9.m9.1a"><mn id="A3.SS2.p4.9.m9.1.1" xref="A3.SS2.p4.9.m9.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.9.m9.1b"><cn id="A3.SS2.p4.9.m9.1.1.cmml" type="integer" xref="A3.SS2.p4.9.m9.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.9.m9.1c">2</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.9.m9.1d">2</annotation></semantics></math> respectively), the dimension of hyperedges from <math alttext="\{3,4,5,6\}" class="ltx_Math" display="inline" id="A3.SS2.p4.10.m10.4"><semantics id="A3.SS2.p4.10.m10.4a"><mrow id="A3.SS2.p4.10.m10.4.5.2" xref="A3.SS2.p4.10.m10.4.5.1.cmml"><mo id="A3.SS2.p4.10.m10.4.5.2.1" stretchy="false" xref="A3.SS2.p4.10.m10.4.5.1.cmml">{</mo><mn id="A3.SS2.p4.10.m10.1.1" xref="A3.SS2.p4.10.m10.1.1.cmml">3</mn><mo id="A3.SS2.p4.10.m10.4.5.2.2" xref="A3.SS2.p4.10.m10.4.5.1.cmml">,</mo><mn id="A3.SS2.p4.10.m10.2.2" xref="A3.SS2.p4.10.m10.2.2.cmml">4</mn><mo id="A3.SS2.p4.10.m10.4.5.2.3" xref="A3.SS2.p4.10.m10.4.5.1.cmml">,</mo><mn id="A3.SS2.p4.10.m10.3.3" xref="A3.SS2.p4.10.m10.3.3.cmml">5</mn><mo id="A3.SS2.p4.10.m10.4.5.2.4" xref="A3.SS2.p4.10.m10.4.5.1.cmml">,</mo><mn id="A3.SS2.p4.10.m10.4.4" xref="A3.SS2.p4.10.m10.4.4.cmml">6</mn><mo id="A3.SS2.p4.10.m10.4.5.2.5" stretchy="false" xref="A3.SS2.p4.10.m10.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.10.m10.4b"><set id="A3.SS2.p4.10.m10.4.5.1.cmml" xref="A3.SS2.p4.10.m10.4.5.2"><cn id="A3.SS2.p4.10.m10.1.1.cmml" type="integer" xref="A3.SS2.p4.10.m10.1.1">3</cn><cn id="A3.SS2.p4.10.m10.2.2.cmml" type="integer" xref="A3.SS2.p4.10.m10.2.2">4</cn><cn id="A3.SS2.p4.10.m10.3.3.cmml" type="integer" xref="A3.SS2.p4.10.m10.3.3">5</cn><cn id="A3.SS2.p4.10.m10.4.4.cmml" type="integer" xref="A3.SS2.p4.10.m10.4.4">6</cn></set></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.10.m10.4c">\{3,4,5,6\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.10.m10.4d">{ 3 , 4 , 5 , 6 }</annotation></semantics></math> (except for the synthetic setup where the number of hyperedges is set to <math alttext="3" class="ltx_Math" display="inline" id="A3.SS2.p4.11.m11.1"><semantics id="A3.SS2.p4.11.m11.1a"><mn id="A3.SS2.p4.11.m11.1.1" xref="A3.SS2.p4.11.m11.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.11.m11.1b"><cn id="A3.SS2.p4.11.m11.1.1.cmml" type="integer" xref="A3.SS2.p4.11.m11.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.11.m11.1c">3</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.11.m11.1d">3</annotation></semantics></math>), nonlinearities used for the similarity score are either sigmoid, sparsemax or softmax, the algorithm for <math alttext="k" class="ltx_Math" display="inline" id="A3.SS2.p4.12.m12.1"><semantics id="A3.SS2.p4.12.m12.1a"><mi id="A3.SS2.p4.12.m12.1.1" xref="A3.SS2.p4.12.m12.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.12.m12.1b"><ci id="A3.SS2.p4.12.m12.1.1.cmml" xref="A3.SS2.p4.12.m12.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.12.m12.1c">k</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.12.m12.1d">italic_k</annotation></semantics></math>-subset sampling is either AIMLE or SIMPLE, with their associated noise distribution sum of gamma or gumbel. For the NBA dataset, we are training for <math alttext="300" class="ltx_Math" display="inline" id="A3.SS2.p4.13.m13.1"><semantics id="A3.SS2.p4.13.m13.1a"><mn id="A3.SS2.p4.13.m13.1.1" xref="A3.SS2.p4.13.m13.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.13.m13.1b"><cn id="A3.SS2.p4.13.m13.1.1.cmml" type="integer" xref="A3.SS2.p4.13.m13.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.13.m13.1c">300</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.13.m13.1d">300</annotation></semantics></math> epochs, while for the Particle Simulation we are training for <math alttext="1000" class="ltx_Math" display="inline" id="A3.SS2.p4.14.m14.1"><semantics id="A3.SS2.p4.14.m14.1a"><mn id="A3.SS2.p4.14.m14.1.1" xref="A3.SS2.p4.14.m14.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p4.14.m14.1b"><cn id="A3.SS2.p4.14.m14.1.1.cmml" type="integer" xref="A3.SS2.p4.14.m14.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p4.14.m14.1c">1000</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p4.14.m14.1d">1000</annotation></semantics></math> epochs.</p>
</div>
<div class="ltx_para" id="A3.SS2.p5">
<p class="ltx_p" id="A3.SS2.p5.1">The code for loading the NBA dataset is based on the official code for Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib42" title="">42</a>]</cite><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/MediaBrain-SJTU/GroupNet - under MIT License</span></span></span>. The code for the various <math alttext="k" class="ltx_Math" display="inline" id="A3.SS2.p5.1.m1.1"><semantics id="A3.SS2.p5.1.m1.1a"><mi id="A3.SS2.p5.1.m1.1.1" xref="A3.SS2.p5.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p5.1.m1.1b"><ci id="A3.SS2.p5.1.m1.1.1.cmml" xref="A3.SS2.p5.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p5.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p5.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling algorithms is based on the code associated with AIMLE<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/EdinburghNLP/torch-adaptive-imle - under MIT License</span></span></span>Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib9" title="">9</a>]</cite>, IMLE<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/uclnlp/torch-imle under MIT License</span></span></span>Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib46" title="">46</a>]</cite> and SIMPLE<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://github.com/UCLA-StarAI/SIMPLE - custom License, open for research</span></span></span>Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib8" title="">8</a>]</cite> methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.p6">
<p class="ltx_p" id="A3.SS2.p6.12"><span class="ltx_text ltx_font_bold" id="A3.SS2.p6.12.1">Metric details.</span> To validate to what extent our model is able to predict the correct hypergraph structure, we are computing the overlap between the predicted hypergraph and the ground-truth connectivity used to generate the trajectory. For a model predicting <math alttext="K" class="ltx_Math" display="inline" id="A3.SS2.p6.1.m1.1"><semantics id="A3.SS2.p6.1.m1.1a"><mi id="A3.SS2.p6.1.m1.1.1" xref="A3.SS2.p6.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.1.m1.1b"><ci id="A3.SS2.p6.1.m1.1.1.cmml" xref="A3.SS2.p6.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.1.m1.1d">italic_K</annotation></semantics></math> hyperedges, letâ€™s consider the set of predicted hyperedges as <math alttext="P=\{p_{1},p_{2}..p_{K}\}" class="ltx_math_unparsed" display="inline" id="A3.SS2.p6.2.m2.1"><semantics id="A3.SS2.p6.2.m2.1a"><mrow id="A3.SS2.p6.2.m2.1b"><mi id="A3.SS2.p6.2.m2.1.1">P</mi><mo id="A3.SS2.p6.2.m2.1.2">=</mo><mrow id="A3.SS2.p6.2.m2.1.3"><mo id="A3.SS2.p6.2.m2.1.3.1" stretchy="false">{</mo><msub id="A3.SS2.p6.2.m2.1.3.2"><mi id="A3.SS2.p6.2.m2.1.3.2.2">p</mi><mn id="A3.SS2.p6.2.m2.1.3.2.3">1</mn></msub><mo id="A3.SS2.p6.2.m2.1.3.3">,</mo><msub id="A3.SS2.p6.2.m2.1.3.4"><mi id="A3.SS2.p6.2.m2.1.3.4.2">p</mi><mn id="A3.SS2.p6.2.m2.1.3.4.3">2</mn></msub><mo id="A3.SS2.p6.2.m2.1.3.5" lspace="0em" rspace="0.0835em">.</mo><mo id="A3.SS2.p6.2.m2.1.3.6" lspace="0.0835em" rspace="0.167em">.</mo><msub id="A3.SS2.p6.2.m2.1.3.7"><mi id="A3.SS2.p6.2.m2.1.3.7.2">p</mi><mi id="A3.SS2.p6.2.m2.1.3.7.3">K</mi></msub><mo id="A3.SS2.p6.2.m2.1.3.8" stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="A3.SS2.p6.2.m2.1c">P=\{p_{1},p_{2}..p_{K}\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.2.m2.1d">italic_P = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT . . italic_p start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math> and the target hyperedges as <math alttext="G=\{g_{1},g_{2}..g_{K}\}" class="ltx_math_unparsed" display="inline" id="A3.SS2.p6.3.m3.1"><semantics id="A3.SS2.p6.3.m3.1a"><mrow id="A3.SS2.p6.3.m3.1b"><mi id="A3.SS2.p6.3.m3.1.1">G</mi><mo id="A3.SS2.p6.3.m3.1.2">=</mo><mrow id="A3.SS2.p6.3.m3.1.3"><mo id="A3.SS2.p6.3.m3.1.3.1" stretchy="false">{</mo><msub id="A3.SS2.p6.3.m3.1.3.2"><mi id="A3.SS2.p6.3.m3.1.3.2.2">g</mi><mn id="A3.SS2.p6.3.m3.1.3.2.3">1</mn></msub><mo id="A3.SS2.p6.3.m3.1.3.3">,</mo><msub id="A3.SS2.p6.3.m3.1.3.4"><mi id="A3.SS2.p6.3.m3.1.3.4.2">g</mi><mn id="A3.SS2.p6.3.m3.1.3.4.3">2</mn></msub><mo id="A3.SS2.p6.3.m3.1.3.5" lspace="0em" rspace="0.0835em">.</mo><mo id="A3.SS2.p6.3.m3.1.3.6" lspace="0.0835em" rspace="0.167em">.</mo><msub id="A3.SS2.p6.3.m3.1.3.7"><mi id="A3.SS2.p6.3.m3.1.3.7.2">g</mi><mi id="A3.SS2.p6.3.m3.1.3.7.3">K</mi></msub><mo id="A3.SS2.p6.3.m3.1.3.8" stretchy="false">}</mo></mrow></mrow><annotation encoding="application/x-tex" id="A3.SS2.p6.3.m3.1c">G=\{g_{1},g_{2}..g_{K}\}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.3.m3.1d">italic_G = { italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT . . italic_g start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT }</annotation></semantics></math>. For each element <math alttext="i" class="ltx_Math" display="inline" id="A3.SS2.p6.4.m4.1"><semantics id="A3.SS2.p6.4.m4.1a"><mi id="A3.SS2.p6.4.m4.1.1" xref="A3.SS2.p6.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.4.m4.1b"><ci id="A3.SS2.p6.4.m4.1.1.cmml" xref="A3.SS2.p6.4.m4.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.4.m4.1d">italic_i</annotation></semantics></math>, we are computing the percentage of the nodes that are in both the prediction <math alttext="p_{i}" class="ltx_Math" display="inline" id="A3.SS2.p6.5.m5.1"><semantics id="A3.SS2.p6.5.m5.1a"><msub id="A3.SS2.p6.5.m5.1.1" xref="A3.SS2.p6.5.m5.1.1.cmml"><mi id="A3.SS2.p6.5.m5.1.1.2" xref="A3.SS2.p6.5.m5.1.1.2.cmml">p</mi><mi id="A3.SS2.p6.5.m5.1.1.3" xref="A3.SS2.p6.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.5.m5.1b"><apply id="A3.SS2.p6.5.m5.1.1.cmml" xref="A3.SS2.p6.5.m5.1.1"><csymbol cd="ambiguous" id="A3.SS2.p6.5.m5.1.1.1.cmml" xref="A3.SS2.p6.5.m5.1.1">subscript</csymbol><ci id="A3.SS2.p6.5.m5.1.1.2.cmml" xref="A3.SS2.p6.5.m5.1.1.2">ğ‘</ci><ci id="A3.SS2.p6.5.m5.1.1.3.cmml" xref="A3.SS2.p6.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.5.m5.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.5.m5.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and the ground-truth hyperedge <math alttext="g_{i}" class="ltx_Math" display="inline" id="A3.SS2.p6.6.m6.1"><semantics id="A3.SS2.p6.6.m6.1a"><msub id="A3.SS2.p6.6.m6.1.1" xref="A3.SS2.p6.6.m6.1.1.cmml"><mi id="A3.SS2.p6.6.m6.1.1.2" xref="A3.SS2.p6.6.m6.1.1.2.cmml">g</mi><mi id="A3.SS2.p6.6.m6.1.1.3" xref="A3.SS2.p6.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.6.m6.1b"><apply id="A3.SS2.p6.6.m6.1.1.cmml" xref="A3.SS2.p6.6.m6.1.1"><csymbol cd="ambiguous" id="A3.SS2.p6.6.m6.1.1.1.cmml" xref="A3.SS2.p6.6.m6.1.1">subscript</csymbol><ci id="A3.SS2.p6.6.m6.1.1.2.cmml" xref="A3.SS2.p6.6.m6.1.1.2">ğ‘”</ci><ci id="A3.SS2.p6.6.m6.1.1.3.cmml" xref="A3.SS2.p6.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.6.m6.1c">g_{i}</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.6.m6.1d">italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. Since we are computing the element-wise overlap between two unordered sets, we fix the order of the ground-truth list <math alttext="G" class="ltx_Math" display="inline" id="A3.SS2.p6.7.m7.1"><semantics id="A3.SS2.p6.7.m7.1a"><mi id="A3.SS2.p6.7.m7.1.1" xref="A3.SS2.p6.7.m7.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.7.m7.1b"><ci id="A3.SS2.p6.7.m7.1.1.cmml" xref="A3.SS2.p6.7.m7.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.7.m7.1c">G</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.7.m7.1d">italic_G</annotation></semantics></math>, and compute the metric against all the possible permutations of <math alttext="P" class="ltx_Math" display="inline" id="A3.SS2.p6.8.m8.1"><semantics id="A3.SS2.p6.8.m8.1a"><mi id="A3.SS2.p6.8.m8.1.1" xref="A3.SS2.p6.8.m8.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.8.m8.1b"><ci id="A3.SS2.p6.8.m8.1.1.cmml" xref="A3.SS2.p6.8.m8.1.1">ğ‘ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.8.m8.1c">P</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.8.m8.1d">italic_P</annotation></semantics></math>. The overlap corresponding to the best permutation represents our reported metric. This metric is a scalar between <math alttext="0" class="ltx_Math" display="inline" id="A3.SS2.p6.9.m9.1"><semantics id="A3.SS2.p6.9.m9.1a"><mn id="A3.SS2.p6.9.m9.1.1" xref="A3.SS2.p6.9.m9.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.9.m9.1b"><cn id="A3.SS2.p6.9.m9.1.1.cmml" type="integer" xref="A3.SS2.p6.9.m9.1.1">0</cn></annotation-xml></semantics></math> and <math alttext="1" class="ltx_Math" display="inline" id="A3.SS2.p6.10.m10.1"><semantics id="A3.SS2.p6.10.m10.1a"><mn id="A3.SS2.p6.10.m10.1.1" xref="A3.SS2.p6.10.m10.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.10.m10.1b"><cn id="A3.SS2.p6.10.m10.1.1.cmml" type="integer" xref="A3.SS2.p6.10.m10.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.10.m10.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.10.m10.1d">1</annotation></semantics></math>, with <math alttext="0" class="ltx_Math" display="inline" id="A3.SS2.p6.11.m11.1"><semantics id="A3.SS2.p6.11.m11.1a"><mn id="A3.SS2.p6.11.m11.1.1" xref="A3.SS2.p6.11.m11.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.11.m11.1b"><cn id="A3.SS2.p6.11.m11.1.1.cmml" type="integer" xref="A3.SS2.p6.11.m11.1.1">0</cn></annotation-xml></semantics></math> representing completely non-overlapping sets, and <math alttext="1" class="ltx_Math" display="inline" id="A3.SS2.p6.12.m12.1"><semantics id="A3.SS2.p6.12.m12.1a"><mn id="A3.SS2.p6.12.m12.1.1" xref="A3.SS2.p6.12.m12.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.SS2.p6.12.m12.1b"><cn id="A3.SS2.p6.12.m12.1.1.cmml" type="integer" xref="A3.SS2.p6.12.m12.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p6.12.m12.1c">1</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p6.12.m12.1d">1</annotation></semantics></math> denoting perfect matching.</p>
</div>
<div class="ltx_para ltx_noindent" id="A3.SS2.p7">
<p class="ltx_p" id="A3.SS2.p7.9"><span class="ltx_text ltx_font_bold" id="A3.SS2.p7.9.1">Computational complexity.</span> We analyse the computational complexity of the hypergraph-inference component for the SPHINX architecture (hypergraph predictor + sampling) when using the SIMPLE <math alttext="k" class="ltx_Math" display="inline" id="A3.SS2.p7.1.m1.1"><semantics id="A3.SS2.p7.1.m1.1a"><mi id="A3.SS2.p7.1.m1.1.1" xref="A3.SS2.p7.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.1.m1.1b"><ci id="A3.SS2.p7.1.m1.1.1.cmml" xref="A3.SS2.p7.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling algorithm. The overall complexity would be obtained by adding the complexity specific to the hypergraph neural network used to process the higher-order structure. If <math alttext="N" class="ltx_Math" display="inline" id="A3.SS2.p7.2.m2.1"><semantics id="A3.SS2.p7.2.m2.1a"><mi id="A3.SS2.p7.2.m2.1.1" xref="A3.SS2.p7.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.2.m2.1b"><ci id="A3.SS2.p7.2.m2.1.1.cmml" xref="A3.SS2.p7.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.2.m2.1d">italic_N</annotation></semantics></math> is the number of nodes, <math alttext="K" class="ltx_Math" display="inline" id="A3.SS2.p7.3.m3.1"><semantics id="A3.SS2.p7.3.m3.1a"><mi id="A3.SS2.p7.3.m3.1.1" xref="A3.SS2.p7.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.3.m3.1b"><ci id="A3.SS2.p7.3.m3.1.1.cmml" xref="A3.SS2.p7.3.m3.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.3.m3.1c">K</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.3.m3.1d">italic_K</annotation></semantics></math> is the cardinality of the predicted hyperedges and <math alttext="M" class="ltx_Math" display="inline" id="A3.SS2.p7.4.m4.1"><semantics id="A3.SS2.p7.4.m4.1a"><mi id="A3.SS2.p7.4.m4.1.1" xref="A3.SS2.p7.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.4.m4.1b"><ci id="A3.SS2.p7.4.m4.1.1.cmml" xref="A3.SS2.p7.4.m4.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.4.m4.1d">italic_M</annotation></semantics></math> is the number of inferred hyperedges, the vectorized complexity for the sampling module is <math alttext="O(logN\times logK)" class="ltx_Math" display="inline" id="A3.SS2.p7.5.m5.1"><semantics id="A3.SS2.p7.5.m5.1a"><mrow id="A3.SS2.p7.5.m5.1.1" xref="A3.SS2.p7.5.m5.1.1.cmml"><mi id="A3.SS2.p7.5.m5.1.1.3" xref="A3.SS2.p7.5.m5.1.1.3.cmml">O</mi><mo id="A3.SS2.p7.5.m5.1.1.2" xref="A3.SS2.p7.5.m5.1.1.2.cmml">â¢</mo><mrow id="A3.SS2.p7.5.m5.1.1.1.1" xref="A3.SS2.p7.5.m5.1.1.1.1.1.cmml"><mo id="A3.SS2.p7.5.m5.1.1.1.1.2" stretchy="false" xref="A3.SS2.p7.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="A3.SS2.p7.5.m5.1.1.1.1.1" xref="A3.SS2.p7.5.m5.1.1.1.1.1.cmml"><mrow id="A3.SS2.p7.5.m5.1.1.1.1.1.2" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.cmml"><mrow id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.cmml"><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.2" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.2.cmml">l</mi><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1.cmml">â¢</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.3" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.3.cmml">o</mi><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1a" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1.cmml">â¢</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.4" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.4.cmml">g</mi><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1b" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1.cmml">â¢</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.5" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.5.cmml">N</mi></mrow><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.1.cmml">Ã—</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.2.3" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.3.cmml">l</mi></mrow><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.1" xref="A3.SS2.p7.5.m5.1.1.1.1.1.1.cmml">â¢</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.3" xref="A3.SS2.p7.5.m5.1.1.1.1.1.3.cmml">o</mi><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.1a" xref="A3.SS2.p7.5.m5.1.1.1.1.1.1.cmml">â¢</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.4" xref="A3.SS2.p7.5.m5.1.1.1.1.1.4.cmml">g</mi><mo id="A3.SS2.p7.5.m5.1.1.1.1.1.1b" xref="A3.SS2.p7.5.m5.1.1.1.1.1.1.cmml">â¢</mo><mi id="A3.SS2.p7.5.m5.1.1.1.1.1.5" xref="A3.SS2.p7.5.m5.1.1.1.1.1.5.cmml">K</mi></mrow><mo id="A3.SS2.p7.5.m5.1.1.1.1.3" stretchy="false" xref="A3.SS2.p7.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.5.m5.1b"><apply id="A3.SS2.p7.5.m5.1.1.cmml" xref="A3.SS2.p7.5.m5.1.1"><times id="A3.SS2.p7.5.m5.1.1.2.cmml" xref="A3.SS2.p7.5.m5.1.1.2"></times><ci id="A3.SS2.p7.5.m5.1.1.3.cmml" xref="A3.SS2.p7.5.m5.1.1.3">ğ‘‚</ci><apply id="A3.SS2.p7.5.m5.1.1.1.1.1.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1"><times id="A3.SS2.p7.5.m5.1.1.1.1.1.1.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.1"></times><apply id="A3.SS2.p7.5.m5.1.1.1.1.1.2.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2"><times id="A3.SS2.p7.5.m5.1.1.1.1.1.2.1.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.1"></times><apply id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2"><times id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.1"></times><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.2.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.2">ğ‘™</ci><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.3.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.3">ğ‘œ</ci><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.4.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.4">ğ‘”</ci><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.5.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.2.5">ğ‘</ci></apply><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.2.3.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.2.3">ğ‘™</ci></apply><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.3.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.3">ğ‘œ</ci><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.4.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.4">ğ‘”</ci><ci id="A3.SS2.p7.5.m5.1.1.1.1.1.5.cmml" xref="A3.SS2.p7.5.m5.1.1.1.1.1.5">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.5.m5.1c">O(logN\times logK)</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.5.m5.1d">italic_O ( italic_l italic_o italic_g italic_N Ã— italic_l italic_o italic_g italic_K )</annotation></semantics></math> and the complexity of slot-attention with <math alttext="Q" class="ltx_Math" display="inline" id="A3.SS2.p7.6.m6.1"><semantics id="A3.SS2.p7.6.m6.1a"><mi id="A3.SS2.p7.6.m6.1.1" xref="A3.SS2.p7.6.m6.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.6.m6.1b"><ci id="A3.SS2.p7.6.m6.1.1.cmml" xref="A3.SS2.p7.6.m6.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.6.m6.1c">Q</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.6.m6.1d">italic_Q</annotation></semantics></math> iterations and one slot is <math alttext="O(Q\times N)" class="ltx_Math" display="inline" id="A3.SS2.p7.7.m7.1"><semantics id="A3.SS2.p7.7.m7.1a"><mrow id="A3.SS2.p7.7.m7.1.1" xref="A3.SS2.p7.7.m7.1.1.cmml"><mi id="A3.SS2.p7.7.m7.1.1.3" xref="A3.SS2.p7.7.m7.1.1.3.cmml">O</mi><mo id="A3.SS2.p7.7.m7.1.1.2" xref="A3.SS2.p7.7.m7.1.1.2.cmml">â¢</mo><mrow id="A3.SS2.p7.7.m7.1.1.1.1" xref="A3.SS2.p7.7.m7.1.1.1.1.1.cmml"><mo id="A3.SS2.p7.7.m7.1.1.1.1.2" stretchy="false" xref="A3.SS2.p7.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="A3.SS2.p7.7.m7.1.1.1.1.1" xref="A3.SS2.p7.7.m7.1.1.1.1.1.cmml"><mi id="A3.SS2.p7.7.m7.1.1.1.1.1.2" xref="A3.SS2.p7.7.m7.1.1.1.1.1.2.cmml">Q</mi><mo id="A3.SS2.p7.7.m7.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A3.SS2.p7.7.m7.1.1.1.1.1.1.cmml">Ã—</mo><mi id="A3.SS2.p7.7.m7.1.1.1.1.1.3" xref="A3.SS2.p7.7.m7.1.1.1.1.1.3.cmml">N</mi></mrow><mo id="A3.SS2.p7.7.m7.1.1.1.1.3" stretchy="false" xref="A3.SS2.p7.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.7.m7.1b"><apply id="A3.SS2.p7.7.m7.1.1.cmml" xref="A3.SS2.p7.7.m7.1.1"><times id="A3.SS2.p7.7.m7.1.1.2.cmml" xref="A3.SS2.p7.7.m7.1.1.2"></times><ci id="A3.SS2.p7.7.m7.1.1.3.cmml" xref="A3.SS2.p7.7.m7.1.1.3">ğ‘‚</ci><apply id="A3.SS2.p7.7.m7.1.1.1.1.1.cmml" xref="A3.SS2.p7.7.m7.1.1.1.1"><times id="A3.SS2.p7.7.m7.1.1.1.1.1.1.cmml" xref="A3.SS2.p7.7.m7.1.1.1.1.1.1"></times><ci id="A3.SS2.p7.7.m7.1.1.1.1.1.2.cmml" xref="A3.SS2.p7.7.m7.1.1.1.1.1.2">ğ‘„</ci><ci id="A3.SS2.p7.7.m7.1.1.1.1.1.3.cmml" xref="A3.SS2.p7.7.m7.1.1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.7.m7.1c">O(Q\times N)</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.7.m7.1d">italic_O ( italic_Q Ã— italic_N )</annotation></semantics></math>. Then, the overall complexity for predicting <math alttext="M" class="ltx_Math" display="inline" id="A3.SS2.p7.8.m8.1"><semantics id="A3.SS2.p7.8.m8.1a"><mi id="A3.SS2.p7.8.m8.1.1" xref="A3.SS2.p7.8.m8.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A3.SS2.p7.8.m8.1b"><ci id="A3.SS2.p7.8.m8.1.1.cmml" xref="A3.SS2.p7.8.m8.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p7.8.m8.1c">M</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.8.m8.1d">italic_M</annotation></semantics></math> hyperedges is <math alttext="O(M\times Q\times N+M\times logN\times logK))" class="ltx_math_unparsed" display="inline" id="A3.SS2.p7.9.m9.1"><semantics id="A3.SS2.p7.9.m9.1a"><mrow id="A3.SS2.p7.9.m9.1b"><mi id="A3.SS2.p7.9.m9.1.1">O</mi><mrow id="A3.SS2.p7.9.m9.1.2"><mo id="A3.SS2.p7.9.m9.1.2.1" stretchy="false">(</mo><mi id="A3.SS2.p7.9.m9.1.2.2">M</mi><mo id="A3.SS2.p7.9.m9.1.2.3" lspace="0.222em" rspace="0.222em">Ã—</mo><mi id="A3.SS2.p7.9.m9.1.2.4">Q</mi><mo id="A3.SS2.p7.9.m9.1.2.5" lspace="0.222em" rspace="0.222em">Ã—</mo><mi id="A3.SS2.p7.9.m9.1.2.6">N</mi><mo id="A3.SS2.p7.9.m9.1.2.7">+</mo><mi id="A3.SS2.p7.9.m9.1.2.8">M</mi><mo id="A3.SS2.p7.9.m9.1.2.9" lspace="0.222em" rspace="0.222em">Ã—</mo><mi id="A3.SS2.p7.9.m9.1.2.10">l</mi><mi id="A3.SS2.p7.9.m9.1.2.11">o</mi><mi id="A3.SS2.p7.9.m9.1.2.12">g</mi><mi id="A3.SS2.p7.9.m9.1.2.13">N</mi><mo id="A3.SS2.p7.9.m9.1.2.14" lspace="0.222em" rspace="0.222em">Ã—</mo><mi id="A3.SS2.p7.9.m9.1.2.15">l</mi><mi id="A3.SS2.p7.9.m9.1.2.16">o</mi><mi id="A3.SS2.p7.9.m9.1.2.17">g</mi><mi id="A3.SS2.p7.9.m9.1.2.18">K</mi><mo id="A3.SS2.p7.9.m9.1.2.19" stretchy="false">)</mo></mrow><mo id="A3.SS2.p7.9.m9.1.3" stretchy="false">)</mo></mrow><annotation encoding="application/x-tex" id="A3.SS2.p7.9.m9.1c">O(M\times Q\times N+M\times logN\times logK))</annotation><annotation encoding="application/x-llamapun" id="A3.SS2.p7.9.m9.1d">italic_O ( italic_M Ã— italic_Q Ã— italic_N + italic_M Ã— italic_l italic_o italic_g italic_N Ã— italic_l italic_o italic_g italic_K ) )</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Additional experiments</h2>
<figure class="ltx_figure" id="A4.2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="A4.1.fig1" style="width:208.1pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel" id="A4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="A4.T3.4.1">Ablation study on the One-Triangle dataset.</span> Taking into account the higher-order interaction is crucial for predicting the trajectory. Both predicting the hyperedges sequentially and the constrained <math alttext="k" class="ltx_Math" display="inline" id="A4.T3.2.m1.1"><semantics id="A4.T3.2.m1.1b"><mi id="A4.T3.2.m1.1.1" xref="A4.T3.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.T3.2.m1.1c"><ci id="A4.T3.2.m1.1.1.cmml" xref="A4.T3.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T3.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A4.T3.2.m1.1e">italic_k</annotation></semantics></math>-subset sampling are important for accurate hypergraph prediction.
</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A4.1.fig1.1" style="width:433.6pt;height:241.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(103.7pt,-57.7pt) scale(1.91643252213583,1.91643252213583) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.1.fig1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.1.fig1.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A4.1.fig1.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.1.fig1.1.1.1.1.2">1 step</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.1.fig1.1.1.1.1.3">5 steps</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.1.fig1.1.1.1.1.4">25 steps</th>
</tr>
<tr class="ltx_tr" id="A4.1.fig1.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A4.1.fig1.1.1.2.2.1">Golden standard</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.1.fig1.1.1.2.2.2">1.0e-8</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.1.fig1.1.1.2.2.3">1.0e-7</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.1.fig1.1.1.2.2.4">1.0e-6</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.1.fig1.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A4.1.fig1.1.1.3.1.1">Random structure</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.1.fig1.1.1.3.1.2">1.1e-4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.1.fig1.1.1.3.1.3">1.1e-3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.1.fig1.1.1.3.1.4">2.4e-2</td>
</tr>
<tr class="ltx_tr" id="A4.1.fig1.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.1.fig1.1.1.4.2.1">No structure</th>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.4.2.2">1.1e-4</td>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.4.2.3">1.2e-3</td>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.4.2.4">2.4e-2</td>
</tr>
<tr class="ltx_tr" id="A4.1.fig1.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.1.fig1.1.1.5.3.1">LSTM</th>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.5.3.2">2.0e-5</td>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.5.3.3">1.0e-1</td>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.5.3.4">1.7e-1</td>
</tr>
<tr class="ltx_tr" id="A4.1.fig1.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.1.fig1.1.1.6.4.1">SPHINX w Gumbel</th>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.6.4.2">1.0e-4</td>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.6.4.3">1.0e-3</td>
<td class="ltx_td ltx_align_center" id="A4.1.fig1.1.1.6.4.4">2.3e-2</td>
</tr>
<tr class="ltx_tr" id="A4.1.fig1.1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A4.1.fig1.1.1.7.5.1">SPHINX</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.1.fig1.1.1.7.5.2">3.6e-6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.1.fig1.1.1.7.5.3">3.9e-5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.1.fig1.1.1.7.5.4">1.1e-3</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="A4.2.fig2" style="width:208.1pt;">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_table ltx_figure_panel" id="A4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text ltx_font_bold" id="A4.T4.4.1">Ablation study on the Two-Triangles dataset,</span> reinforcing the conclusions from the One-Triangle dataset. Having a learnable hypergraph structure improves the trajectory prediction, while the constrained <math alttext="k" class="ltx_Math" display="inline" id="A4.T4.2.m1.1"><semantics id="A4.T4.2.m1.1b"><mi id="A4.T4.2.m1.1.1" xref="A4.T4.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.T4.2.m1.1c"><ci id="A4.T4.2.m1.1.1.cmml" xref="A4.T4.2.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T4.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A4.T4.2.m1.1e">italic_k</annotation></semantics></math>-subset sampling is superior to Gumbel-Softmax. Moreover, the model further benefits from a sequential prediction of slots. </figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A4.2.fig2.1" style="width:433.6pt;height:267.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(99.9pt,-61.6pt) scale(1.85505662293334,1.85505662293334) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.2.fig2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.2.fig2.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A4.2.fig2.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.2.fig2.1.1.1.1.2">1 step</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.2.fig2.1.1.1.1.3">5 steps</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A4.2.fig2.1.1.1.1.4">25 steps</th>
</tr>
<tr class="ltx_tr" id="A4.2.fig2.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A4.2.fig2.1.1.2.2.1">Golden standard</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.2.fig2.1.1.2.2.2">4.0e-8</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.2.fig2.1.1.2.2.3">5.0e-7</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A4.2.fig2.1.1.2.2.4">9.0e-6</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.2.fig2.1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A4.2.fig2.1.1.3.1.1">Random structure</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.fig2.1.1.3.1.2">1.1e-4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.fig2.1.1.3.1.3">1.1e-3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A4.2.fig2.1.1.3.1.4">2.0e-2</td>
</tr>
<tr class="ltx_tr" id="A4.2.fig2.1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.2.fig2.1.1.4.2.1">No structure</th>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.4.2.2">1.1e-4</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.4.2.3">1.2e-3</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.4.2.4">2.5e-2</td>
</tr>
<tr class="ltx_tr" id="A4.2.fig2.1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.2.fig2.1.1.5.3.1">LSTM</th>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.5.3.2">3.0e-5</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.5.3.3">9.5e-2</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.5.3.4">1.7e-1</td>
</tr>
<tr class="ltx_tr" id="A4.2.fig2.1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.2.fig2.1.1.6.4.1">SPHINX w/o sequen.</th>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.6.4.2">5.0e-5</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.6.4.3">5.0e-4</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.6.4.4">1.0e-2</td>
</tr>
<tr class="ltx_tr" id="A4.2.fig2.1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A4.2.fig2.1.1.7.5.1">SPHINX w Gumbel</th>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.7.5.2">1.0e-4</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.7.5.3">1.1e-3</td>
<td class="ltx_td ltx_align_center" id="A4.2.fig2.1.1.7.5.4">2.5e-2</td>
</tr>
<tr class="ltx_tr" id="A4.2.fig2.1.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A4.2.fig2.1.1.8.6.1">SPHINX</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.fig2.1.1.8.6.2">2.0e-5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.fig2.1.1.8.6.3">2.0e-4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A4.2.fig2.1.1.8.6.4">6.0e-3</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
</div>
</div>
</figure>
<section class="ltx_subsection" id="A4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Full results on Particle Simulation</h3>
<div class="ltx_para" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">Due to page limits, in the main paper we only report the bar-plot for our synthetic experiments. Here we also include the numerical values (see TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.T3" title="Table 3 â€£ Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a> and TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.T4" title="Table 4 â€£ Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">4</span></a>), together with two additional models: one LSTM baseline, similar to the one proposed in Â <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib19" title="">19</a>]</cite>, and a ground-truth-based oracle, to better understand the lower bound for our model.</p>
</div>
<div class="ltx_para" id="A4.SS1.p2">
<p class="ltx_p" id="A4.SS1.p2.1">In the following, we will describe all the baselines used in the Particle Simulations ablation study.</p>
</div>
<div class="ltx_para" id="A4.SS1.p3">
<p class="ltx_p" id="A4.SS1.p3.1"><span class="ltx_text ltx_font_italic" id="A4.SS1.p3.1.1">Golden standard</span> represents the lower bound in terms of MSE for our model. Instead of predicting the hypergraph structure, this model uses the ground-truth connectivity. The <span class="ltx_text ltx_font_italic" id="A4.SS1.p3.1.2">oracle</span> hypergraph is then fed into the hypergraph neural network for predicting the next timestep. The purpose of this model is to understand what is the target performance we can aim for, while taking into account the possible limitation of the hypergraph processor (AllDeepSets in our case).</p>
</div>
<div class="ltx_para" id="A4.SS1.p4">
<p class="ltx_p" id="A4.SS1.p4.1"><span class="ltx_text ltx_font_italic" id="A4.SS1.p4.1.1">Random structure</span> follows the same pipeline used to train the <span class="ltx_text ltx_font_italic" id="A4.SS1.p4.1.2">Golden standard</span> baseline. However, instead of the ground-truth connectivity, this model uses a randomly sampled hypergraph. The goal is to understand how much of our performance comes from having a strong decoder, compared to the advantage of predicting a real, suitable hypergraph structure.</p>
</div>
<div class="ltx_para" id="A4.SS1.p5">
<p class="ltx_p" id="A4.SS1.p5.1"><span class="ltx_text ltx_font_italic" id="A4.SS1.p5.1.1">No structure</span> entirely ignores the higher-order interaction, by setting the incidence matrix to zero. The purpose of this baseline is to understand to what extent our datasets require higher-order interactions.</p>
</div>
<div class="ltx_para" id="A4.SS1.p6">
<p class="ltx_p" id="A4.SS1.p6.1"><span class="ltx_text ltx_font_italic" id="A4.SS1.p6.1.1">LSTM.</span> Inspired by the baselines inÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib19" title="">19</a>]</cite>, we designed an LSTM-basedÂ <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#bib.bib55" title="">55</a>]</cite> model which receives all the nodes concatenated, and predicts, at each timestep, the future coordinates for all the nodes. While capable of capturing relationships between nodes, this model doesnâ€™t have an inductive bias towards modelling higher-order interactions.</p>
</div>
<div class="ltx_para" id="A4.SS1.p7">
<p class="ltx_p" id="A4.SS1.p7.1"><span class="ltx_text ltx_font_italic" id="A4.SS1.p7.1.1">SPHINX w/o sequential</span> uses the same processing as our full proposed model. However, instead of a sequential slot-attention, it uses the classical slot-attention clustering, which predicts all the slots simultaneously. Comparison with this baseline sheds light on the importance of predicting the hyperedges sequentially.</p>
</div>
<div class="ltx_para" id="A4.SS1.p8">
<p class="ltx_p" id="A4.SS1.p8.1"><span class="ltx_text ltx_font_italic" id="A4.SS1.p8.1.1">SPHINX w Gumbel</span> is a modification of our full SPHINX model, by replacing the <math alttext="k" class="ltx_Math" display="inline" id="A4.SS1.p8.1.m1.1"><semantics id="A4.SS1.p8.1.m1.1a"><mi id="A4.SS1.p8.1.m1.1.1" xref="A4.SS1.p8.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.SS1.p8.1.m1.1b"><ci id="A4.SS1.p8.1.m1.1.1.cmml" xref="A4.SS1.p8.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.p8.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A4.SS1.p8.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling with the Gumbel-Softmax, frequently used in both graph and hypergraph inference models. While allowing us to propagate gradients through the sampling step, the Gumbel-Softmax has no constraints on the number of nodes contained in each hyperedge, sampling independently for each node-hyperedge incidence relationship.</p>
</div>
<section class="ltx_paragraph" id="A4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="A4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A4.SS1.SSS0.Px1.p1.3">TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.T3" title="Table 3 â€£ Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">3</span></a> and TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.T4" title="Table 4 â€£ Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">4</span></a> show the results of the ablation study on both the One-Triangle and Two-Triangles datasets. Compared to the model using either perturb structure (<span class="ltx_text ltx_font_italic" id="A4.SS1.SSS0.Px1.p1.3.1">Random structure</span>) or the one completely ignoring the higher-order connectivity (<span class="ltx_text ltx_font_italic" id="A4.SS1.SSS0.Px1.p1.3.2">No structure</span>), our model shows clearly advantage on both datasets, showing that learning to infer the hypergraphs is a critical step in the higher-order processing pipeline. Moreover, all the experiments show a clear advantage for the <math alttext="k" class="ltx_Math" display="inline" id="A4.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="A4.SS1.SSS0.Px1.p1.1.m1.1a"><mi id="A4.SS1.SSS0.Px1.p1.1.m1.1.1" xref="A4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="A4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A4.SS1.SSS0.Px1.p1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.SSS0.Px1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A4.SS1.SSS0.Px1.p1.1.m1.1d">italic_k</annotation></semantics></math>-subset sampling compared to the classical Gumbel-Softmax, with the sequential prediction further increasing the performance. The LSTM baseline performs well on the next step prediction task, but the performance deteriorates severely on the medium (<math alttext="5" class="ltx_Math" display="inline" id="A4.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="A4.SS1.SSS0.Px1.p1.2.m2.1a"><mn id="A4.SS1.SSS0.Px1.p1.2.m2.1.1" xref="A4.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A4.SS1.SSS0.Px1.p1.2.m2.1b"><cn id="A4.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" type="integer" xref="A4.SS1.SSS0.Px1.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.SSS0.Px1.p1.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="A4.SS1.SSS0.Px1.p1.2.m2.1d">5</annotation></semantics></math> steps) and long-range prediction (<math alttext="25" class="ltx_Math" display="inline" id="A4.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="A4.SS1.SSS0.Px1.p1.3.m3.1a"><mn id="A4.SS1.SSS0.Px1.p1.3.m3.1.1" xref="A4.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A4.SS1.SSS0.Px1.p1.3.m3.1b"><cn id="A4.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" type="integer" xref="A4.SS1.SSS0.Px1.p1.3.m3.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.SS1.SSS0.Px1.p1.3.m3.1c">25</annotation><annotation encoding="application/x-llamapun" id="A4.SS1.SSS0.Px1.p1.3.m3.1d">25</annotation></semantics></math> steps). It is interesting to notice that, even if the model discovers the hypergraph structure almost perfectly (see Figure 4 in the main paper), there is still a gap in performance between our learnable SPHINX and the Golden standard model.</p>
</div>
<figure class="ltx_figure" id="A4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="180" id="A4.F7.g1" src="extracted/5900948/figures/slot_number.png" width="538"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_bold" id="A4.F7.2.1">Experiments on Two-Triangles dataset investigating the importance of choosing the correct number of predicted hyperedges</span>. Having less hyperedges than the real number (two) negatively impact the performance. However, when increasing the number of hyperedges above the true value, the performance does not deteriorate, indicating that the model is robust at discovering the hypergraph structure, as long as enough slots are provided.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Varying. number of hyperedges</h3>
<div class="ltx_para" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.4">Although the number of parameters does not scale with the number of inferred hyperedges, by construction we are restricted to predict maximum <math alttext="M" class="ltx_Math" display="inline" id="A4.SS2.p1.1.m1.1"><semantics id="A4.SS2.p1.1.m1.1a"><mi id="A4.SS2.p1.1.m1.1.1" xref="A4.SS2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.1.m1.1b"><ci id="A4.SS2.p1.1.m1.1.1.cmml" xref="A4.SS2.p1.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="A4.SS2.p1.1.m1.1d">italic_M</annotation></semantics></math> hyperedges, where <math alttext="M" class="ltx_Math" display="inline" id="A4.SS2.p1.2.m2.1"><semantics id="A4.SS2.p1.2.m2.1a"><mi id="A4.SS2.p1.2.m2.1.1" xref="A4.SS2.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.2.m2.1b"><ci id="A4.SS2.p1.2.m2.1.1.cmml" xref="A4.SS2.p1.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="A4.SS2.p1.2.m2.1d">italic_M</annotation></semantics></math> is set as hyperparameter. This is mainly due to the use of binary feature vector <math alttext="b" class="ltx_Math" display="inline" id="A4.SS2.p1.3.m3.1"><semantics id="A4.SS2.p1.3.m3.1a"><mi id="A4.SS2.p1.3.m3.1.1" xref="A4.SS2.p1.3.m3.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.3.m3.1b"><ci id="A4.SS2.p1.3.m3.1.1.cmml" xref="A4.SS2.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.3.m3.1c">b</annotation><annotation encoding="application/x-llamapun" id="A4.SS2.p1.3.m3.1d">italic_b</annotation></semantics></math> encoding the history predicted so far, which has a fixed dimension <math alttext="\{0,1\}^{N\times(M-1)}" class="ltx_Math" display="inline" id="A4.SS2.p1.4.m4.3"><semantics id="A4.SS2.p1.4.m4.3a"><msup id="A4.SS2.p1.4.m4.3.4" xref="A4.SS2.p1.4.m4.3.4.cmml"><mrow id="A4.SS2.p1.4.m4.3.4.2.2" xref="A4.SS2.p1.4.m4.3.4.2.1.cmml"><mo id="A4.SS2.p1.4.m4.3.4.2.2.1" stretchy="false" xref="A4.SS2.p1.4.m4.3.4.2.1.cmml">{</mo><mn id="A4.SS2.p1.4.m4.2.2" xref="A4.SS2.p1.4.m4.2.2.cmml">0</mn><mo id="A4.SS2.p1.4.m4.3.4.2.2.2" xref="A4.SS2.p1.4.m4.3.4.2.1.cmml">,</mo><mn id="A4.SS2.p1.4.m4.3.3" xref="A4.SS2.p1.4.m4.3.3.cmml">1</mn><mo id="A4.SS2.p1.4.m4.3.4.2.2.3" stretchy="false" xref="A4.SS2.p1.4.m4.3.4.2.1.cmml">}</mo></mrow><mrow id="A4.SS2.p1.4.m4.1.1.1" xref="A4.SS2.p1.4.m4.1.1.1.cmml"><mi id="A4.SS2.p1.4.m4.1.1.1.3" xref="A4.SS2.p1.4.m4.1.1.1.3.cmml">N</mi><mo id="A4.SS2.p1.4.m4.1.1.1.2" lspace="0.222em" rspace="0.222em" xref="A4.SS2.p1.4.m4.1.1.1.2.cmml">Ã—</mo><mrow id="A4.SS2.p1.4.m4.1.1.1.1.1" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.cmml"><mo id="A4.SS2.p1.4.m4.1.1.1.1.1.2" stretchy="false" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><mrow id="A4.SS2.p1.4.m4.1.1.1.1.1.1" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.cmml"><mi id="A4.SS2.p1.4.m4.1.1.1.1.1.1.2" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.2.cmml">M</mi><mo id="A4.SS2.p1.4.m4.1.1.1.1.1.1.1" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="A4.SS2.p1.4.m4.1.1.1.1.1.1.3" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="A4.SS2.p1.4.m4.1.1.1.1.1.3" stretchy="false" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></msup><annotation-xml encoding="MathML-Content" id="A4.SS2.p1.4.m4.3b"><apply id="A4.SS2.p1.4.m4.3.4.cmml" xref="A4.SS2.p1.4.m4.3.4"><csymbol cd="ambiguous" id="A4.SS2.p1.4.m4.3.4.1.cmml" xref="A4.SS2.p1.4.m4.3.4">superscript</csymbol><set id="A4.SS2.p1.4.m4.3.4.2.1.cmml" xref="A4.SS2.p1.4.m4.3.4.2.2"><cn id="A4.SS2.p1.4.m4.2.2.cmml" type="integer" xref="A4.SS2.p1.4.m4.2.2">0</cn><cn id="A4.SS2.p1.4.m4.3.3.cmml" type="integer" xref="A4.SS2.p1.4.m4.3.3">1</cn></set><apply id="A4.SS2.p1.4.m4.1.1.1.cmml" xref="A4.SS2.p1.4.m4.1.1.1"><times id="A4.SS2.p1.4.m4.1.1.1.2.cmml" xref="A4.SS2.p1.4.m4.1.1.1.2"></times><ci id="A4.SS2.p1.4.m4.1.1.1.3.cmml" xref="A4.SS2.p1.4.m4.1.1.1.3">ğ‘</ci><apply id="A4.SS2.p1.4.m4.1.1.1.1.1.1.cmml" xref="A4.SS2.p1.4.m4.1.1.1.1.1"><minus id="A4.SS2.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.1"></minus><ci id="A4.SS2.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.2">ğ‘€</ci><cn id="A4.SS2.p1.4.m4.1.1.1.1.1.1.3.cmml" type="integer" xref="A4.SS2.p1.4.m4.1.1.1.1.1.1.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.SS2.p1.4.m4.3c">\{0,1\}^{N\times(M-1)}</annotation><annotation encoding="application/x-llamapun" id="A4.SS2.p1.4.m4.3d">{ 0 , 1 } start_POSTSUPERSCRIPT italic_N Ã— ( italic_M - 1 ) end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A4.SS2.p2">
<p class="ltx_p" id="A4.SS2.p2.1">To establish to what extent the value we choose as the number of hyperedges impacts the performance, we conduct an ablation study by varying the number of slots predicted by our method. The results in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.03208v1#A4.F7" title="Figure 7 â€£ Results. â€£ D.1 Full results on Particle Simulation â€£ Appendix D Additional experiments â€£ SPHINX: Structural Prediction using Hypergraph Inference Network"><span class="ltx_text ltx_ref_tag">7</span></a> show that picking a number of slots larger than the real one doesnâ€™t harm the performance. Visual analysis of the learned hypergraph reveals that, when offering more slots than needed, the model tends to produce redundancy, associating the extra slots to hyperedges that were already discovered.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Oct  4 07:49:02 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
