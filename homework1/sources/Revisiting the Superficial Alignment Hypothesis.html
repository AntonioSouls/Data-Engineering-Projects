<!DOCTYPE html><html lang="en" data-theme="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Revisiting the Superficial Alignment Hypothesis</title>
<!--Generated on Fri Sep 27 21:36:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">




<base href="https://arxiv.org/html/2410.03717v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2410.03717v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode" aria-label="System preference">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="https://arxiv.org/html/2410.03717v1/#myForm">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2410.03717v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2410.03717v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        
        
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist"><li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#abstract" title="Abstract">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        Abstract
      </span>
    </a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S1" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S2" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Key Takeaways</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Post-training Data Scaling</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS1" title="In 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experiment Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS2" title="In 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS2.SSS0.Px1" title="In 3.2 Results ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Model performance for a task follows a power-law relationship with fine-tuning data.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS2.SSS0.Px2" title="In 3.2 Results ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Larger models in a model family learn better than smaller models with more data.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS3" title="In 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>General Purpose Alignment vs Task Specific Finetuning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS3.SSS0.Px1" title="In 3.3 General Purpose Alignment vs Task Specific Finetuning ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Task specific post-training largely outperforms stylistic fine-tuning when evaluated objectively.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Learning Reasoning and Style</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4.SS1" title="In 4 Learning Reasoning and Style ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experiment Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4.SS2" title="In 4 Learning Reasoning and Style ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4.SS2.SSS0.Px1" title="In 4.2 Results ‣ 4 Learning Reasoning and Style ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Style and formatting improvements saturate quickly.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4.SS2.SSS0.Px2" title="In 4.2 Results ‣ 4 Learning Reasoning and Style ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Reasoning performance continues to improve with more data.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Learning New Knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.SS1" title="In 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experiment Design</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.SS2" title="In 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Introducing new knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.SS2.SSS1" title="In 5.2 Introducing new knowledge ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.SS2.SSS1.Px1" title="In 5.2.1 Results ‣ 5.2 Introducing new knowledge ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Post-training a model for reasoning helps models learn and integrate new knowledge better.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.SS2.SSS1.Px2" title="In 5.2.1 Results ‣ 5.2 Introducing new knowledge ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title">Models hallucination is mitigated by post-training for reasoning, but is not eliminated.</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S6" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S7" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S8" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Acknowledgements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1" title="In Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS1" title="In Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Math contamination ablation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS2" title="In Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Ablation studies for introducing new knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3" title="In Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Dataset Creation and Formatting</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS1" title="In A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3.1 </span>GSM8k Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS2" title="In A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3.2 </span>SubQA Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS3" title="In A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3.3 </span>Conifer and Dolly Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS4" title="In A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3.4 </span>Facts100 Dataset</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS4" title="In Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Error Analysis Prompt Templates</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS5" title="In Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>Training and inference parameters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS6" title="In Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.6 </span>Power law fit coefficients</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
    <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib" title="References">
      <span class="ltx_text ltx_ref_title">
        <span class="ltx_tag ltx_tag_ref"></span>
        References
      </span>
    </a></li></ol></nav>

<div class="ltx_page_content"><div class="package-alerts ltx_document" role="status" aria-label="Conversion errors have been found">
      <button aria-label="Dismiss alert">
          <span aria-hidden="true"><svg role="presentation" width="20" height="20" viewBox="0 0 44 44" aria-hidden="true" focusable="false">
          <path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
          <path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
          </svg></span>
      </button>
      <p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
          <ul arial-label="Unsupported packages used in this paper">
              <li>failed: fontawesome5</li>
          </ul>
      <p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
    </div><div id="target-section" class="section"><a id="license-tr" href="https://info.arxiv.org/help/license/index.html#licenses-available">License: CC BY 4.0</a><div id="watermark-tr">arXiv:2410.03717v1 [cs.CL] 27 Sep 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Revisiting the Superficial Alignment Hypothesis</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohit Raghavendra<sup class="ltx_sup" id="id1.1.id1">°</sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Georgia Institute of Technology
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Vaskar Nath
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Scale AI
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sean Hendryx
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Scale AI
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract" id="abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id2.id1">The Superficial Alignment Hypothesis posits that almost all of a language model’s abilities and knowledge are learned during pre-training, while post-training is about giving a model the right style and format. We re-examine these claims by empirically studying the scaling behavior of post-training with increasing finetuning examples and evaluating them using objective task-specific standardized benchmarks.
Through experiments with the Llama-3, Mistral, and Llama-2 model families of multiple sizes, we observe that, similar to the pre-training scaling laws, post-training task performance scales as a power law against the number of finetuning examples. This power law relationship holds across a broad array of capabilities, including mathematical reasoning, coding, instruction following, and multihop-reasoning. In addition, for tasks like math and multihop reasoning, we observe that a handful of examples merely align the model stylistically but do not saturate performance on the benchmarks. Model performance is instead correlated with its reasoning ability and it improves significantly with more examples, illustrating the need for holistic evaluation programs leveraging objective benchmarks in addition to measurement of alignment to human preferences. We also observe that language models are not necessarily limited to using knowledge learned during pre-training. With appropriate post-training, a model’s ability to integrate new knowledge greatly improves on downstream tasks like multihop question-answering.
Taken together, these results shed new light on the Superficial Alignment Hypothesis, suggesting that it is, at best, an over-simplification.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_italic" id="p1.1.1">Correspondence to</span>
<span class="ltx_ERROR undefined" id="p1.1.2">\faEnvelope</span>&nbsp;<span class="ltx_text ltx_font_typewriter" id="p1.1.3">sean.hendryx@scale.com</span> and <span class="ltx_text ltx_font_typewriter" id="p1.1.4">mraghavendra6@gatech.edu</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs) based on the Transformer architecture have achieved state-of-the-art performance on tasks that involve instruction following, problem-solving, and reasoning <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib26" title="">2017</a>, Achiam et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib1" title="">2023</a>, Dubey et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib7" title="">2024</a>)</cite>. The standard pipeline for building LLMs powered applications involves unsupervised training of a model on a giant corpus of data to gain general language understanding capability, referred to as <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">pre-training</span> <cite class="ltx_cite ltx_citemacro_citep">(Radford et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib21" title="">2019</a>, Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib4" title="">2020</a>)</cite>. The model is further improved using <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">post-training</span>, which involves finetuning it to excel at a particular domain or behave like a helpful chatbot. This process is also referred to as alignment. The predominant way to do this is through Supervised Finetuning (SFT) where the language model is provided with a prompt, and the model is finetuned to respond to the task <cite class="ltx_cite ltx_citemacro_citep">(Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib28" title="">2022</a>)</cite>. An additional step is Reinforcement Learning through Human Feedback (RLHF) where a model is trained using reinforcement learning to generate human-preferred responses, by being rewarded for good responses and penalized for bad responses <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib20" title="">2022</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To achieve the post-training goal of responding appropriately to various user queries, LLMs need to develop several task-specific capabilities, like mathematics, reasoning, utilizing knowledge, and tool use. To teach a model these capabilities, model builders collect human-annotated or synthetically generated data and finetune the model to obtain the desired behavior. Since data collection at scale is labor and cost-intensive, it is essential to understand the qualitative and quantitative value of obtaining additional post-training data. Studies like LIMA <cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib32" title="">2024</a>)</cite> have hypothesized that post-training alignment is all about learning the style and format of the desired behavior. Specifically, it puts forward the Superficial Alignment Hypothesis, whose claims are:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">C1:</span> A model’s knowledge is learned entirely during pre-training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">C3:</span> Post-training is largely about style and doesn’t does not teach a model new capabilities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">C2:</span> A small number of examples can saturate a model’s performance for a given task.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">However, the experiments from LIMA and follow-up works <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib16" title="">2023</a>)</cite> primarily evaluate chatbot style interaction capabilities - tasks that require mostly cosmetic changes to a model’s response style. It is unclear how these models improve on task-specific reasoning capabilities during post-training. They are also evaluated using a subjective win-rate comparison, over open-ended prompts. This doesn’t provide an objective pattern to analyze model behavior and thus fails to provide useful information about the nature of model performance and dataset size. For researchers and practitioners who finetune LLMs to perform specific tasks, understanding scaling behavior with more data is crucial in aiding data collection and annotation efforts. There is also a need to study if these LLMs are limited to the knowledge acquired during pre-training, or if we can introduce new knowledge and show how to utilize it effectively. So, we design three research questions to better investigate these claims:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<ol class="ltx_enumerate" id="S1.I2">
<li class="ltx_item" id="S1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I2.i1.p1">
<p class="ltx_p" id="S1.I2.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I2.i1.p1.1.1">How does post-training model performance scale with dataset size?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I2.i2.p1">
<p class="ltx_p" id="S1.I2.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I2.i2.p1.1.1">Is the model significantly improving on task-related capabilities or just learning the response style?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I2.i3.p1">
<p class="ltx_p" id="S1.I2.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I2.i3.p1.1.1">Can a model integrate new knowledge from beyond the pertaining knowledge cutoff?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In the following section, we summarise the key results from the study, followed by sections that detail the experimental setup, results, and conclusions for each of the research questions outlined above.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Key Takeaways</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">Post-training performance on a task has a power law relationship of the form
<math alttext="P\propto D^{1/b}" class="ltx_Math" display="inline" id="S2.I1.i1.p1.1.m1.1"><semantics id="S2.I1.i1.p1.1.m1.1a"><mrow id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.2.cmml">P</mi><mo id="S2.I1.i1.p1.1.m1.1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.1.cmml">∝</mo><msup id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.3.2" xref="S2.I1.i1.p1.1.m1.1.1.3.2.cmml">D</mi><mrow id="S2.I1.i1.p1.1.m1.1.1.3.3" xref="S2.I1.i1.p1.1.m1.1.1.3.3.cmml"><mn id="S2.I1.i1.p1.1.m1.1.1.3.3.2" xref="S2.I1.i1.p1.1.m1.1.1.3.3.2.cmml">1</mn><mo id="S2.I1.i1.p1.1.m1.1.1.3.3.1" xref="S2.I1.i1.p1.1.m1.1.1.3.3.1.cmml">/</mo><mi id="S2.I1.i1.p1.1.m1.1.1.3.3.3" xref="S2.I1.i1.p1.1.m1.1.1.3.3.3.cmml">b</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1">proportional-to</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2">𝑃</ci><apply id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2">𝐷</ci><apply id="S2.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.3"><divide id="S2.I1.i1.p1.1.m1.1.1.3.3.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.3.1"></divide><cn id="S2.I1.i1.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="S2.I1.i1.p1.1.m1.1.1.3.3.2">1</cn><ci id="S2.I1.i1.p1.1.m1.1.1.3.3.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.3.3">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">P\propto D^{1/b}</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i1.p1.1.m1.1d">italic_P ∝ italic_D start_POSTSUPERSCRIPT 1 / italic_b end_POSTSUPERSCRIPT</annotation></semantics></math> with the number of post-training samples, similar to scaling laws established for pertaining and inference <cite class="ltx_cite ltx_citemacro_citep">(Kaplan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib14" title="">2020</a>, Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib3" title="">2024</a>)</cite>, across models of multiple families and sizes. (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3" title="3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">3</span></a>)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">Evaluating alignment models using win-rates as shown in <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib32" title="">2024</a>)</cite> could be misleading for reasoning-based tasks. For instance, LLM-based judges can prefer model generations that exhibit a chatbot-style answer for mathematical questions, even though the model might be poor at mathematical abilities as observed on math benchmarks. (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.SS3" title="3.3 General Purpose Alignment vs Task Specific Finetuning ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">3.3</span></a>)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">Through extensive error analysis on tasks like math and multihop reasoning, we see that when a model is finetuned for a task, the improvements in task-specific style and formatting saturate in just 100 examples, as hypothesized by the Superficial Alignment Hypothesis. However, the model’s performance on the task is directly correlated with its improvements in reasoning ability, which improves notably during post-training with more finetuning examples. (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4" title="4 Learning Reasoning and Style ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">4</span></a>)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1">Post-training a model for reasoning can also help a model integrate knowledge beyond its pre-training knowledge cutoff. Compared to pre-trained models, post-trained models learn and use new knowledge on downstream tasks effectively. (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5" title="5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">5</span></a>)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">These experiments help frame the Superficial Alignment Hypothesis in a new light. Most importantly, the focus on post-training should not be entirely on stylistic alignment, but also on measuring downstream task metrics. When seen through this lens, we see that after finetuning on a few high-quality examples, LLMs behave in the right style and format, especially when evaluated through subjective techniques like win rate. However, this doesn’t necessarily warrant the conclusion that the model has been aligned for the task. When evaluated for their objective task-specific performance, we see that the models do improve significantly with additional data on many tasks during post-training over their pre-trained counterparts. In addition, these improvements are primarily driven by improvements in reasoning and analytical abilities during post-training. Good post-training is also an effective way for LLMs to learn and integrate new knowledge from beyond their knowledge cut-off.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Post-training Data Scaling</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1"><span class="ltx_text ltx_font_italic" id="S3.p1.1.1">How does post-training model performance scale with dataset size?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The primary implication of the Superficial Alignment Hypothesis is that pre-training is all that matters, and with a rather small set of examples, we can align a model during post-training. However, this is a broad claim that is supported by a limited set of chatbot-style experiments. Post-training a model involves instruction following, problem-solving, and coding, and unlike chatbot-style dialogue whose evaluation is subjective and comparative, these capabilities can be judged using standardized benchmarks. For researchers and model builders who aim to improve performance on such tasks, it is important to understand performance scaling on such benchmarks with increasing fine-tuning data.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experiment Design</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.1.1">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.2.1">Test Benchmark</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.3.1">Train Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.2.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.2.1.1.4.1"># train examples</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.2.2.1.1">Math</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.2.2.1.2">GSM8k Test</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.2.2.1.3">GSM8k Train</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.2.2.1.4">7,500</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.3.2.1">Multihop QnA</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.3.2.2">SubQA Test</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.3.2.3">SubQA Train</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.3.2.4">2,700</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.4.3.1">Coding</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.4.3.2">HumanEval+</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.4.3.3">StarCoder Self-Align Train</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.4.3.4">10,000</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.2.5.4.1">Instruction Following</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.5.4.2">IFEval</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.2.5.4.3">Conifer Hard Messages</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.2.5.4.4">5,000</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.6.5.1">Instruction Following</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.6.5.2">IFEval</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.2.6.5.3">Dolly15k</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S3.T1.2.6.5.4">15,000</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.3.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.4.2" style="font-size:90%;">Experiment training and test benchmark details</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We look at four tasks (training datasets used are in parenthesis) - mathematical problem solving (GSM8k <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib5" title="">2021</a>)</cite>), instruction following (<cite class="ltx_cite ltx_citemacro_citep">(Sun et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib23" title="">2024</a>, Conover et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib6" title="">2023</a>)</cite>), coding (StarCoder Self-Align <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://huggingface.co/datasets/bigcode/self-oss-instruct-sc2-exec-filter-50k</span></span></span>) and multihop question answering (SubQA <cite class="ltx_cite ltx_citemacro_citep">(Tang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib24" title="">2021</a>)</cite>). Starting from the base model and finetuning with increasing dataset size, we observe how performance scales during post-training.
For each task, we ran evaluations using a standard framework where available <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib8" title="">2024</a>, Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib17" title="">2023</a>, Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib33" title="">2023</a>)</cite>. More details about the training data are available in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.T1" title="Table 1 ‣ 3.1 Experiment Design ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">1</span></a> and additional dataset construction details can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3" title="A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.3</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">For our experiments, we finetune Llama-3, Llama-2 and Mistral model families on these tasks <cite class="ltx_cite ltx_citemacro_citep">(Dubey et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib7" title="">2024</a>, Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib25" title="">2023</a>, Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib13" title="">2023</a>)</cite>. We chose base models because it is likely that instruct models are already extensively finetuned for these tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We first finetuned the smallest (sub-10 Billion parameter) models from these model families, with the dataset splits of 0, 100, 500, 1000, 5000, and 10000 examples until the training dataset was exhausted. To study the effects of model parameter size, we also scale up the models in the Llama-2 and Llama-3 families from 7B to 70B parameters - a 10X increase. Since full-parameter fine-tuning of 70B models on a multi-node GPU cluster is resource-intensive, we limited the number of training runs for the 70B model sizes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">To ensure fairness, every model in a model family was trained with the same set of hyperparameters for a given task and dataset size, for 3 epochs over the base model with the default chat template from HuggingFace. More details about the hyperparameters for training and inference can be found in <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS5" title="A.5 Training and inference parameters ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.5</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S3.F1.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/data_scaling_log.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.4.2.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S3.F1.2.1" style="font-size:90%;">Performance improvements as finetuning data is scaled up, for models in the sub-10 Billion parameter range. The points are fitted with a power law curve of the form <math alttext="P\propto D^{1/b}" class="ltx_Math" display="inline" id="S3.F1.2.1.m1.1"><semantics id="S3.F1.2.1.m1.1b"><mrow id="S3.F1.2.1.m1.1.1" xref="S3.F1.2.1.m1.1.1.cmml"><mi id="S3.F1.2.1.m1.1.1.2" xref="S3.F1.2.1.m1.1.1.2.cmml">P</mi><mo id="S3.F1.2.1.m1.1.1.1" xref="S3.F1.2.1.m1.1.1.1.cmml">∝</mo><msup id="S3.F1.2.1.m1.1.1.3" xref="S3.F1.2.1.m1.1.1.3.cmml"><mi id="S3.F1.2.1.m1.1.1.3.2" xref="S3.F1.2.1.m1.1.1.3.2.cmml">D</mi><mrow id="S3.F1.2.1.m1.1.1.3.3" xref="S3.F1.2.1.m1.1.1.3.3.cmml"><mn id="S3.F1.2.1.m1.1.1.3.3.2" xref="S3.F1.2.1.m1.1.1.3.3.2.cmml">1</mn><mo id="S3.F1.2.1.m1.1.1.3.3.1" xref="S3.F1.2.1.m1.1.1.3.3.1.cmml">/</mo><mi id="S3.F1.2.1.m1.1.1.3.3.3" xref="S3.F1.2.1.m1.1.1.3.3.3.cmml">b</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.F1.2.1.m1.1c"><apply id="S3.F1.2.1.m1.1.1.cmml" xref="S3.F1.2.1.m1.1.1"><csymbol cd="latexml" id="S3.F1.2.1.m1.1.1.1.cmml" xref="S3.F1.2.1.m1.1.1.1">proportional-to</csymbol><ci id="S3.F1.2.1.m1.1.1.2.cmml" xref="S3.F1.2.1.m1.1.1.2">𝑃</ci><apply id="S3.F1.2.1.m1.1.1.3.cmml" xref="S3.F1.2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.F1.2.1.m1.1.1.3.1.cmml" xref="S3.F1.2.1.m1.1.1.3">superscript</csymbol><ci id="S3.F1.2.1.m1.1.1.3.2.cmml" xref="S3.F1.2.1.m1.1.1.3.2">𝐷</ci><apply id="S3.F1.2.1.m1.1.1.3.3.cmml" xref="S3.F1.2.1.m1.1.1.3.3"><divide id="S3.F1.2.1.m1.1.1.3.3.1.cmml" xref="S3.F1.2.1.m1.1.1.3.3.1"></divide><cn id="S3.F1.2.1.m1.1.1.3.3.2.cmml" type="integer" xref="S3.F1.2.1.m1.1.1.3.3.2">1</cn><ci id="S3.F1.2.1.m1.1.1.3.3.3.cmml" xref="S3.F1.2.1.m1.1.1.3.3.3">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.2.1.m1.1d">P\propto D^{1/b}</annotation><annotation encoding="application/x-llamapun" id="S3.F1.2.1.m1.1e">italic_P ∝ italic_D start_POSTSUPERSCRIPT 1 / italic_b end_POSTSUPERSCRIPT</annotation></semantics></math>. Model performance consistently scales in a power law fashion, across model families.
</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Model performance for a task follows a power-law relationship with fine-tuning data.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.3">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.F1" title="Figure 1 ‣ 3.2 Results ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">1</span></a> shows the performance scaling with increasing post-training data for the smallest, sub-10 Billion parameter models, with the power-law fit line. Task accuracy <math alttext="P" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.1.m1.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.1.m1.1c">P</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.1.m1.1d">italic_P</annotation></semantics></math> closely follows a power-law of the form <math alttext="P\propto D^{1/b}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS2.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml">P</mi><mo id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml">∝</mo><msup id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">D</mi><mrow id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.cmml"><mn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.2" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.2.cmml">1</mn><mo id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.1" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.1.cmml">/</mo><mi id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.3" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.3.cmml">b</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.1">proportional-to</csymbol><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.2">𝑃</ci><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.2">𝐷</ci><apply id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3"><divide id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.1"></divide><cn id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.2">1</cn><ci id="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.SSS0.Px1.p1.2.m2.1.1.3.3.3">𝑏</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.2.m2.1c">P\propto D^{1/b}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.2.m2.1d">italic_P ∝ italic_D start_POSTSUPERSCRIPT 1 / italic_b end_POSTSUPERSCRIPT</annotation></semantics></math> with the number of finetuning examples <math alttext="D" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS2.SSS0.Px1.p1.3.m3.1a"><mi id="S3.SS2.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p1.3.m3.1b"><ci id="S3.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px1.p1.3.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p1.3.m3.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p1.3.m3.1d">italic_D</annotation></semantics></math>, for all the models on all the tasks. This power-law relationship is in line with several other empirical scaling laws of LLMs with data size during pre-training, quantization, and inference <cite class="ltx_cite ltx_citemacro_citep">(Kaplan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib14" title="">2020</a>, Michaud et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib18" title="">2024</a>, Brown et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib3" title="">2024</a>)</cite>. The coefficients for the power law curves are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS6" title="A.6 Power law fit coefficients ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.6</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.1">In addition, model improvement curves do not cross each other. Better base models for a task are consistently better during post-training as well. This is in line with other works that relate pertaining performance with downstream task performance <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib29" title="">2024a</a>)</cite>. Performance scaling with data is also more consistent and predictable on reasoning-centric tasks like Math, Multihop QnA, and Coding, as opposed to subjective tasks like Instruction Following.
We also perform additional ablations on scaling curves with different dataset quality for Instruction Following in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS3" title="A.3.3 Conifer and Dolly Dataset ‣ A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.3.3</span></a>, and evaluations on the GSM1k benchmark <cite class="ltx_cite ltx_citemacro_citep">(Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib30" title="">2024b</a>)</cite> for math to check for dataset contamination, in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS1" title="A.1 Math contamination ablation ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="316" id="S3.F2.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/model_scaling.png" width="538">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Performance scaling curves with increasing model size for models in the same family.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Larger models in a model family learn better than smaller models with more data.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.F2" title="Figure 2 ‣ Model performance for a task follows a power-law relationship with fine-tuning data. ‣ 3.2 Results ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">2</span></a> shows results for model scaling. All models of the family follow the same power law distribution. As expected, larger models consistently outperform smaller models for the same training data. However, the improvement is not always just an upward parallel shift. The performance of larger models curves upwards with more training datasets, indicating an increasing rate of improvements with additional data. The coefficients for the power law curves are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS6" title="A.6 Power law fit coefficients ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.6</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p2.1">Putting these results together, we see that larger and better base models scale even better during post-training. This highlights the role of pre-training in preparing a model to learn better during post-training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>General Purpose Alignment vs Task Specific Finetuning</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The LIMA paper also introduced the LIMA dataset, a collection of 1,000 carefully curated prompts that was intended to align a pre-trained model to be on par with state-of-the-art post-trained models. It is based on the hypothesis that the model has inherently learned most of its capabilities during pre-training and thus, the model just needs to adopt a stylistic format to answer questions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">In this section, we finetune the Llama-3 8b model with the LIMA dataset, using the same training setup as the rest of the datasets. We call this model <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.1">LIMA-1k</span>. We also finetune a pre-trained model with 1,000 examples specific to a task - GSM8k for math and SubQA for multihop reasoning. This ensures that the LIMA and task-specific models are trained with a similar data <span class="ltx_text ltx_inline-quote ltx_outerquote" id="S3.SS3.p2.1.2">“budget”</span>. We call models finetuned with task-specific datasets <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.3">Task-1k</span>. We then evaluate the performance of the chat-bot style aligned LIMA-1k against task-specific fine-tuned Task-1k model on the task-specific benchmarks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T2.2.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S3.T2.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.1.1.2.1">Task Accuracy</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S3.T2.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.2.1.1.3.1">Win Rate</span></th>
</tr>
<tr class="ltx_tr" id="S3.T2.2.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_border_r" id="S3.T2.2.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.2.1">LIMA-1k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T2.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.3.1">Task-1k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.4.1">LIMA-1k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.5.1">Task-1k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.2.2.2.6"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.6.1">Neither</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.2.3.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T2.2.3.1.1">
<span class="ltx_text ltx_font_bold" id="S3.T2.2.3.1.1.1">Math</span> (GSM8k Test)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.2">14.7%</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.2.3.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.2.3.1.3.1">46.5%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.2.3.1.4.1">84.4%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.5">0.24%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.2.3.1.6">14.2%</td>
</tr>
<tr class="ltx_tr" id="S3.T2.2.4.2">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S3.T2.2.4.2.1">
<span class="ltx_text ltx_font_bold" id="S3.T2.2.4.2.1.1">Multihop QnA</span> (SubQA Test)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.4.2.2">21%</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T2.2.4.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.2.4.2.3.1">36%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.4.2.4">20%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.4.2.5"><span class="ltx_text ltx_font_bold" id="S3.T2.2.4.2.5.1">57%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.2.4.2.6">23%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T2.3.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S3.T2.4.2" style="font-size:90%;">Comparision of task-specific finetuning v/s LIMA style stylistic alignment.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Task specific post-training largely outperforms stylistic fine-tuning when evaluated objectively.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">From the results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.T2" title="Table 2 ‣ 3.3 General Purpose Alignment vs Task Specific Finetuning ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">2</span></a>, we observe the marked difference that domain-specific data and post-training make against just chat-bot style alignment. For the same number of examples, domain-specific post-training greatly outperforms general-purpose chatbot style alignment.
In addition, since several works, including LIMA, report win-rate against other models as a performance metric, we also calculate the win-rate of the responses from <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.1">LIMA-1k</span> and <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.2">Task-1k</span> models on the GSM8k and SubQA test set prompts. We use the same prompt from LIMA to judge wins between responses and use GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib19" title="">2024</a>)</cite> to predict wins. As seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.T2" title="Table 2 ‣ 3.3 General Purpose Alignment vs Task Specific Finetuning ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">2</span></a>, the win-rate metric is an unreliable indicator of a model’s accuracy on a specific task. For instance, for the GSM8k Math task, Even though the <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS0.Px1.p1.1.3">LIMA-1k</span> model generates a significant number of incorrect responses, it gets a higher win-rate than the task-specific fine-tuned model. This highlights the need for task-specific objective evaluations in addition to comparative win-rate metrics in foundation model evaluation programs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Learning Reasoning and Style</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text ltx_font_italic" id="S4.p1.1.1">Is the model significantly improving on task-related capabilities or just learning the response style?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In this section, we investigate what is driving the improvements in these tasks with more data, specifically aiming to delineate improvements in style/formatting versus improvements in reasoning. We do this by evaluating the generations of models with different finetuning levels.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Design</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We evaluate finetuned model generations over math (GSM8k dataset) and multihop QnA (SubQA dataset). We took the Llama-3 8b base model as well as fine-tuned models using 100, 1000, and full training splits of the two datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">Both GSM8k and SubQA responses use the Socratic Method of generating subquestions to arrive at the final answer. So, the model is finetuned to follow this specific style of generating a subquestion-answer reasoning chain, a delimiter, followed by the final answer. Examples of expected model response styles and formats are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS1" title="A.3.1 GSM8k Dataset ‣ A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.3.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS2" title="A.3.2 SubQA Dataset ‣ A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.3.2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">We then collect all the <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.1">incorrect responses</span> from these models on the test split and annotated them using GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib19" title="">2024</a>)</cite>. If the responses fail to stick to the previously specified format, it is annotated as <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.2">Incorrect Formatting</span>. If the responses contain an error in their subquestion-answer reasoning steps, we annotate it as <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.3">Incorrect Reasoning</span>. For math, we also check for <span class="ltx_text ltx_font_italic" id="S4.SS1.p3.1.4">Incorrect Arithmetic Calculations</span>, since they are a major source of model errors. Each error category was evaluated independently for a response, using a tailored prompt. So, an error response can belong to multiple categories. More details about the prompt used for this categorization are in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS4" title="A.4 Error Analysis Prompt Templates ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="393" id="S4.F3.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/style_substance.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S4.F3.3.2" style="font-size:90%;">Breakdown of error responses by models finetuned with datasets of increasing data scales. The first group in each chart shows the Total Mistakes made on the test set by the models. Each error response is then independently evaluated for the different mistake types and thus can belong to multiple error types. There is a clear trend of models saturating on style and formatting improvements with just a few examples. However, reasoning and arithmetic errors continue to get better.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Style and formatting improvements saturate quickly.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">From Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S4.F3" title="Figure 3 ‣ 4.2 Results ‣ 4 Learning Reasoning and Style ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">3</span></a> we see that the models get better at style and format errors with just 100 examples. If one just takes a passing look at the responses from this model, they could incorrectly conclude that the model is <span class="ltx_text ltx_inline-quote ltx_outerquote" id="S4.SS2.SSS0.Px1.p1.1.1">“aligned”</span> to answer math or multi-hop questions. However, all of these responses are still incorrect for the task for which we fine-tune the model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Reasoning performance continues to improve with more data.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.2">Models continue to get better at reasoning and question understanding with more examples. The total number of mistakes a model makes highly correlates with reasoning errors (<math alttext="r^{2}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS2.SSS0.Px2.p1.1.m1.1a"><msup id="S4.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">r</mi><mn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.2">𝑟</ci><cn id="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.SSS0.Px2.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.1.m1.1c">r^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px2.p1.1.m1.1d">italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> value of 0.98 for math and 0.99 for multihop QnA on Llama-3 8B) as opposed to total mistakes and formatting errors (<math alttext="r^{2}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS2.SSS0.Px2.p1.2.m2.1a"><msup id="S4.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">r</mi><mn id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.2">𝑟</ci><cn id="S4.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" type="integer" xref="S4.SS2.SSS0.Px2.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.m2.1c">r^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px2.p1.2.m2.1d">italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> value of 0.93 for math and 0.83 for multihop QnA). It also signifies that a model’s capabilities are not entirely learned during pre-training, because models can significantly improve their reasoning, or learn to apply it effectively, during post-training. This leads us to the idea that the superficial alignment hypothesis could be limited in scope to improvements on style-and-formatting alignment tasks. It doesn’t accurately characterize the improvements in capabilities that post-training is more effective at.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Learning New Knowledge</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_italic" id="S5.p1.1.1">Can a model integrate new knowledge from beyond the pertaining knowledge cutoff?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In this section, we examine how post-training can help LLMs learn new knowledge after the pre-taining knowledge cutoff, and more importantly, use it correctly on downstream tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Experiment Design</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We first created <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.1">Facts100</span>, a hand-curated dataset of 100 news events that occurred after March 2023, the knowledge cutoff of the Llama-3-8b base model. The news events are from across the world and cover domains such as entertainment, sports, business, politics and science. We then created two questions for each event, as shown in example <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.F4" title="Figure 4 ‣ 5.1 Experiment Design ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">4</span></a>:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">Direct Question</span>: A single-hop direct question related to the news event and its entity.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">Multihop Question</span>: A multistep reasoning style question that first requires recalling what happened in the event in the first step <span class="ltx_text ltx_font_italic" id="S5.I1.i2.p1.1.2">and using it</span> to answer in the second step. This checks if the model learns how to use the learned knowledge in the right way</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="190" id="S5.F4.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/facts_example.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S5.F4.3.2" style="font-size:90%;">Example of an Event and Question Pairs from the curated Facts100 dataset.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T3.2.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.2.1.1.2.1">Direct Qn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T3.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T3.2.1.1.3.1">Multihop Qn</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T3.2.2.1.1">Base Model</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.1.2">8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.2.2.1.3">12</td>
</tr>
<tr class="ltx_tr" id="S5.T3.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T3.2.3.2.1">Post-trained Model</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.3.2.2">32</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.2.3.2.3">27</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T3.3.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="S5.T3.4.2" style="font-size:90%;">Accuracy of the models on the Facts100 dataset before introducing new knowledge.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">To finetune and evaluate models on this task, we adopt the same task setting as the multihop QnA from the previous section. We evaluated the Llama-3 8B pre-trained model, as well as a multihop reasoning post-trained model. The post-trained model was finetuned on SubQARecall, a modification of the multihop reasoning QnA dataset SubQA from the previous section, augmented to recall the relevant event first before answering the question (more details in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS2" title="A.3.2 SubQA Dataset ‣ A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.3.2</span></a>. This post-training is meant to impart reasoning ability to the model while maintaining the same knowledge cutoff, since the SubQA dataset doesn’t contain any new information after the cutoff.
<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We didn’t finetune the Llama-3 8B instruct model on the new facts because it performed poorly. This is because it is strongly aligned to refuse to answer questions beyond its finetuning cutoff data. Attempts to get the model to overcome this behavior through finetuning (ex: increasing learning rate) led to behavior degradation. Although unlearning methods can help undo this behavior, it is out of the scope of this study.</span></span></span> As seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.T3" title="Table 3 ‣ 5.1 Experiment Design ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">3</span></a>, both the models perform poorly on the Facts100 questions, since they have almost no knowledge of most of the new events that are crucial to answer these questions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Introducing new knowledge</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">There are two primary ways to introduce new knowledge to a model - finetuning on the new events or during inference as part of the prompt. The latter is a simplified Retrieval Augmented Generation (RAG) setup <cite class="ltx_cite ltx_citemacro_cite">Lewis et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib15" title="">2020</a>)</cite>. We investigate the role of post-training in both of these cases.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">Event SFT:</span> To train the model to learn this new information, we finetune a model on the Direct Question as the prompt and the Event + Answer as the response. The format is the same as the SubQARecall to keep the data in-distribution.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">Event RAG-Oracle:</span> In this method, we simulate a RAG setup in which knowledge is added in the prompt during inference instead of training on it. To isolate the errors introduced by the retriever component of RAG, we directly add the corresponding event in the prompt, emulating a perfect retriever i.e. an Oracle.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T4.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S5.T4.2.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S5.T4.2.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T4.2.1.1.2.1">Event SFT</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S5.T4.2.1.1.3"><span class="ltx_text ltx_font_bold" id="S5.T4.2.1.1.3.1">Event RAG-Oracle</span></th>
</tr>
<tr class="ltx_tr" id="S5.T4.2.2.2">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r" id="S5.T4.2.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.2.2.2.2"><span class="ltx_text ltx_font_bold" id="S5.T4.2.2.2.2.1">Direct Qn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S5.T4.2.2.2.3"><span class="ltx_text ltx_font_bold" id="S5.T4.2.2.2.3.1">Multihop Qn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.2.2.2.4"><span class="ltx_text ltx_font_bold" id="S5.T4.2.2.2.4.1">Direct Qn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S5.T4.2.2.2.5"><span class="ltx_text ltx_font_bold" id="S5.T4.2.2.2.5.1">Multihop Qn</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.2.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S5.T4.2.3.1.1">Base Model</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.3.1.2">65</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.2.3.1.3">37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.3.1.4">49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.2.3.1.5">34</td>
</tr>
<tr class="ltx_tr" id="S5.T4.2.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S5.T4.2.4.2.1"><span class="ltx_text ltx_font_bold" id="S5.T4.2.4.2.1.1">Post-trained Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.4.2.2"><span class="ltx_text ltx_font_bold" id="S5.T4.2.4.2.2.1">81</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.2.4.2.3"><span class="ltx_text ltx_font_bold" id="S5.T4.2.4.2.3.1">55</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.4.2.4"><span class="ltx_text ltx_font_bold" id="S5.T4.2.4.2.4.1">86</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.2.4.2.5"><span class="ltx_text ltx_font_bold" id="S5.T4.2.4.2.5.1">71</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T4.3.1.1" style="font-size:90%;">Table 4</span>: </span><span class="ltx_text" id="S5.T4.4.2" style="font-size:90%;">Accuracy of the models on the Facst100 dataset with new knowledge, introduced through Event SFT and RAG-Oracle.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S5.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.2.1 </span>Results</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS2.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Post-training a model for reasoning helps models learn and integrate new knowledge better.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS1.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS1.Px1.p1.1">As seen in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.T4" title="Table 4 ‣ 5.2 Introducing new knowledge ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">4</span></a>, models post-trained for reasoning are significantly better at learning new knowledge (Direct Question) as well as integrating the new knowledge (Multihop Reasoning Question). However, SFT or RAG on the pre-trained model fails to show the same improvement on the harder multi-hop questions. Note that this answer is just one hop from the answer to the direct question but requires it to reason through the steps. This shows that the model can’t correctly use this new information in the right way on reasoning tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.Px1.p2">
<p class="ltx_p" id="S5.SS2.SSS1.Px1.p2.1">However, if the model is first post-trained to do reasoning, it gets better at absorbing new information and using it in multihop reasoning tasks. This post-training was done on data from before the knowledge cutoff. Such post-training led to a marked difference in both SFT and RAG-based methods for introducing new knowledge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Models hallucination is mitigated by post-training for reasoning, but is not eliminated.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS1.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS1.Px2.p1.1">Several studies have shown that LLMs hallucinate when introduced to new knowledge. Since all of the models in our experiments are finetuned to recall the event first and generate the answer based on it, we can easily check for hallucination in the recalled event. We also analyze the subsequent reasoning chain for reasoning errors. Both of these are done using GPT-4o and the prompt used is shown in the Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS3.SSS4" title="A.3.4 Facts100 Dataset ‣ A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.3.4</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="304" id="S5.F5.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/facts_error.png" width="359">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.4.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S5.F5.5.2" style="font-size:90%;">Error Analysis on the New Fact Multihop Questions after fine-tuning. <span class="ltx_text ltx_font_bold" id="S5.F5.5.2.1">BM</span> stands for the pre-trained base model and <span class="ltx_text ltx_font_bold" id="S5.F5.5.2.2">PM</span> for the multihop reasoning post-trained model.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS1.Px2.p2">
<p class="ltx_p" id="S5.SS2.SSS1.Px2.p2.1">From Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S5.F5" title="Figure 5 ‣ Models hallucination is mitigated by post-training for reasoning, but is not eliminated. ‣ 5.2.1 Results ‣ 5.2 Introducing new knowledge ‣ 5 Learning New Knowledge ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">5</span></a>, we see that hallucinations about the event are a major factor in erroneous model responses. Even after introducing new knowledge, base models hallucinate significantly. This is in line with other works that demonstrate that finetuning models with new knowledge can lead to hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Gekhman et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib9" title="">2024</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.SS2.SSS1.Px2.p3">
<p class="ltx_p" id="S5.SS2.SSS1.Px2.p3.1">However, models post-trained for reasoning make a marked improvement in both hallucination and reasoning errors. Although hallucination is not completely mitigated, the true value of finetuning is in preparing the model to reason with the new knowledge it receives. In addition, RAG-based methods are better than SFT for introducing new knowledge because the relevant information being in the context is a lot more useful. We also do a variety of ablation studies to compare against continual pre-training and LIMA-based finetuning, which are detailed in the Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.SS2" title="A.2 Ablation studies for introducing new knowledge ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.p1.1.1">Language Model Alignment:</span> LLMs are first pretrained to gain general language understanding and world modeling, which is then followed by an alignment phase that involves SFT and RLHF to appropriately respond to user’s prompts <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib20" title="">2022</a>, Wei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib27" title="">2021</a>, Dubey et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib7" title="">2024</a>)</cite>. Several recent works laid out their hypothesis on whether alignment is more about learning style and might not even be necessary because of In-Context Learning <cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib32" title="">2024</a>, Lin et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib16" title="">2023</a>)</cite>. More recent works by <cite class="ltx_cite ltx_citemacro_citet">Zhao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib31" title="">2024</a>)</cite> show that instruction tuning on better base models can outperform In Context Learning.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Scaling Laws:</span> Several works like <cite class="ltx_cite ltx_citemacro_cite">Hoffmann et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib11" title="">2022</a>), Kaplan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib14" title="">2020</a>), Bahri et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib2" title="">2024</a>), Michaud et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib18" title="">2024</a>)</cite> have studied and developed scaling laws for LLM Pretraining in terms of the dataset token count and the model parameter count against the cross-entropy loss. However, <cite class="ltx_cite ltx_citemacro_citet">Schaeffer et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib22" title="">2024</a>)</cite> show that it is hard to predict scaling laws for downstream task performance because of constraints in the action space. <cite class="ltx_cite ltx_citemacro_citet">Isik et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib12" title="">2024</a>), Hernandez et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib10" title="">2021</a>)</cite> derive scaling laws for finetuning as a function of pretraining data and transfer learning respectively, and not post-training or instruction following. However, researchers and model builders improve model performance by collecting individual prompt-response examples rather than collective dataset tokens <cite class="ltx_cite ltx_citemacro_citep">(Dubey et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#bib.bib7" title="">2024</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions and Future Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1"><span class="ltx_text ltx_font_bold" id="S7.p1.1.1">Conclusions:</span> LLM post-training is a complex endeavor that involves improvements to instruction following, stylistic formatting, reasoning abilities, and general alignment to human preferences. LLMs can imitate the required style with <span class="ltx_text ltx_inline-quote ltx_outerquote" id="S7.p1.1.2">“superficial”</span> finetuning using a handful of examples, leading to the Superficial Alignment Hypothesis. However, a solely stylistic evaluation fails to characterize the many aspects of reasoning and task-specific capabilities that are key goals of finetuning. In fact, task-specific skills &amp; reasoning significantly improve after post-training with more examples compared to the pre-trained model. These improvements closely follow a power law in our experiments with the number of finetuning examples across multiple model families and sizes. We also see that these improvements are driven by the model’s reasoning ability during generation, and are not limited to the model’s alignment to formatting or style. In addition, we see that the win rate against other models can be a misleading metric to measure tasks that require complex reasoning, signaling the need for holistic evaluation programs leveraging standardized, objective benchmarks, in addition to measurement of alignment to human preferences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">We also observe that good post-training can help LLMs overcome problems associated with knowledge cutoff, by enabling them to better utilize knowledge from beyond the pre-training corpus either via further finetuning or RAG. These results put together highlight the qualitative and quantitative characteristics of post-training, and the role of data scaling in this.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1"><span class="ltx_text ltx_font_bold" id="S7.p3.1.1">Limitations and future work:</span> In this work we showed the performance improvement of a model on a task when it is finetuned with increasing task-specific data. However, frontier LLMs are trained to excel at multiple tasks, and we don’t thoroughly understand how finetuning for one task or domain affects the performance on others. A big open question would be investigating how to take advantage of this scaling behavior while preventing model degradation on existing capabilities. Similarly, we showed how models can learn new knowledge beyond their pre-training data cutoff, but the issue of hallucination isn’t solved. Further research in effectively introducing new knowledge, like continual learning methods during post-training can shed light on this.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">In this work, we also limited the scope to supervised finetuning, on tasks that involve text generation. However, the implications from this opens up several interesting directions to explore further. Most notably, LLM post-training involves RLHF after supervised finetuning, and it would be interesting to see how RLHF can contribute to these improvements and how it scales with more data.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Acknowledgements</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">We would like to thank Hugh Zhang for their helpful reviews and feedback over the course of this project.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia&nbsp;Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et&nbsp;al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahri et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, and Utkarsh Sharma.

</span>
<span class="ltx_bibblock">Explaining neural scaling laws.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the National Academy of Sciences</em>, 121(27):e2311878121, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc&nbsp;V Le, Christopher Ré, and Azalia Mirhoseini.

</span>
<span class="ltx_bibblock">Large language monkeys: Scaling inference compute with repeated sampling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2407.21787</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.F. Balcan, and H.&nbsp;Lin (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;33, pp.&nbsp; 1877–1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2110.14168</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conover et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin.

</span>
<span class="ltx_bibblock">Free dolly: Introducing the world’s first truly open instruction-tuned llm, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" title="">https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et&nbsp;al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le&nbsp;Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, 07 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zenodo.org/records/12608602" title="">https://zenodo.org/records/12608602</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gekhman et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, and Jonathan Herzig.

</span>
<span class="ltx_bibblock">Does fine-tuning llms on new knowledge encourage hallucinations?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2405.05904</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hernandez et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Danny Hernandez, Jared Kaplan, Tom Henighan, and Sam McCandlish.

</span>
<span class="ltx_bibblock">Scaling laws for transfer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2102.01293</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de&nbsp;Las Casas, Lisa&nbsp;Anne Hendricks, Johannes Welbl, Aidan Clark, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training compute-optimal large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2203.15556</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Isik et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Berivan Isik, Natalia Ponomareva, Hussein Hazimeh, Dimitris Paparas, Sergei Vassilvitskii, and Sanmi Koyejo.

</span>
<span class="ltx_bibblock">Scaling laws for downstream task performance of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2402.04177</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom&nbsp;B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et&nbsp;al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Advances in Neural Information Processing Systems</em>, 33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bill&nbsp;Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha Dziri, Melanie Sclar, Khyathi Chandu, Chandra Bhagavatula, and Yejin Choi.

</span>
<span class="ltx_bibblock">The unlocking spell on base llms: Rethinking alignment via in-context learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">The Twelfth International Conference on Learning Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawei Liu, Chunqiu&nbsp;Steven Xia, Yuyao Wang, and Lingming Zhang.

</span>
<span class="ltx_bibblock">Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Thirty-seventh Conference on Neural Information Processing Systems</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=1qvx610Cu7" title="">https://openreview.net/forum?id=1qvx610Cu7</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michaud et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eric Michaud, Ziming Liu, Uzay Girit, and Max Tegmark.

</span>
<span class="ltx_bibblock">The quantization model of neural scaling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Hello gpt-4o, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/hello-gpt-4o/" title="">https://openai.com/index/hello-gpt-4o/</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-08.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in neural information processing systems</em>, 35:27730–27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schaeffer et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rylan Schaeffer, Hailey Schoelkopf, Brando Miranda, Gabriel Mukobi, Varun Madan, Adam Ibrahim, Herbie Bradley, Stella Biderman, and Sanmi Koyejo.

</span>
<span class="ltx_bibblock">Why has predicting downstream capabilities of frontier ai models with scale remained elusive?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2406.04391</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoran Sun, Lixin Liu, Junjie Li, Fengyu Wang, Baohua Dong, Ran Lin, and Ruohui Huang.

</span>
<span class="ltx_bibblock">Conifer: Improving complex constrained instruction-following ability of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2404.02823</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yixuan Tang, Hwee&nbsp;Tou Ng, and Anthony K.&nbsp;H. Tung.

</span>
<span class="ltx_bibblock">Do multi-hop question answering systems know how to answer the single-hop sub-questions?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">EACL</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan&nbsp;N Gomez, Ł&nbsp;ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In I.&nbsp;Guyon, U.&nbsp;Von Luxburg, S.&nbsp;Bengio, H.&nbsp;Wallach, R.&nbsp;Fergus, S.&nbsp;Vishwanathan, and R.&nbsp;Garnett (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;30. Curran Associates, Inc., 2017.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2109.01652</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M. Dai, and Quoc&nbsp;V Le.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">International Conference on Learning Representations</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=gEZrGCozdqR" title="">https://openreview.net/forum?id=gEZrGCozdqR</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Biao Zhang, Zhongtao Liu, Colin Cherry, and Orhan Firat.

</span>
<span class="ltx_bibblock">When scaling meets llm finetuning: The effect of data, model and finetuning method.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2402.17193</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugh Zhang, Jeff Da, Dean Lee, Vaughn Robinson, Catherine Wu, Will Song, Tiffany Zhao, Pranav Raja, Dylan Slack, Qin Lyu, et&nbsp;al.

</span>
<span class="ltx_bibblock">A careful examination of large language model performance on grade school arithmetic.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2405.00332</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hao Zhao, Maksym Andriushchenko, Francesco Croce, and Nicolas Flammarion.

</span>
<span class="ltx_bibblock">Is in-context learning sufficient for instruction following in llms?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2405.19874</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi&nbsp;Luan, Denny Zhou, and Le&nbsp;Hou.

</span>
<span class="ltx_bibblock">Instruction-following evaluation for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2311.07911</em>, 2023.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Math contamination ablation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="293" id="A1.F6.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/gsm1k_eval.png" width="299">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="A1.F6.3.2" style="font-size:90%;">GSM1k benchmark</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Since there is a risk that the model might be contaminated with the GSM8k test set during pre-training, we cross-verified the GSM8k-trained Llama-3-8b models with the GSM1k private leaderboard. We observe a similar scaling trend on the new benchmark as well.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Ablation studies for introducing new knowledge</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">We also try various ways of introducing new knowledge into the model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p2.1.1">Continued Pretraining:</span> The base/posttrained model is first fine-tuned directly on the new events for 3 epochs with the same batch size. The idea is to continue pertaining on the new knowledge corpus.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A1.SS2.p3.1.1">LIMA:</span> We also tried fine-tuning the base model with the LIMA dataset first to make it a general purpose Question-Answering model and provide the required new event as part of the prompt during evaluation, through RAG.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T5.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T5.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A1.T5.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T5.2.1.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T5.2.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T5.2.1.1.2.1">Direct Qn</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T5.2.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T5.2.1.1.3.1">Multihop Qn</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T5.2.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T5.2.2.1.1">Base Model + Continued Pretraining</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.2.2.1.2">35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.2.2.1.3">16</td>
</tr>
<tr class="ltx_tr" id="A1.T5.2.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A1.T5.2.3.2.1">Base Model + LIMA + RAG</td>
<td class="ltx_td ltx_align_center" id="A1.T5.2.3.2.2">58</td>
<td class="ltx_td ltx_align_center" id="A1.T5.2.3.2.3">48</td>
</tr>
<tr class="ltx_tr" id="A1.T5.2.4.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A1.T5.2.4.3.1">Base Model + SFT + RAG</td>
<td class="ltx_td ltx_align_center" id="A1.T5.2.4.3.2">100</td>
<td class="ltx_td ltx_align_center" id="A1.T5.2.4.3.3">51</td>
</tr>
<tr class="ltx_tr" id="A1.T5.2.5.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A1.T5.2.5.4.1">Posttrained Model w/ Continued Pretraining</td>
<td class="ltx_td ltx_align_center" id="A1.T5.2.5.4.2">34</td>
<td class="ltx_td ltx_align_center" id="A1.T5.2.5.4.3">39</td>
</tr>
<tr class="ltx_tr" id="A1.T5.2.6.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="A1.T5.2.6.5.1">Posttrained Model w/ SFT + RAG</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.2.6.5.2">100</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.2.6.5.3">71</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T5.3.1.1" style="font-size:90%;">Table 5</span>: </span><span class="ltx_text" id="A1.T5.4.2" style="font-size:90%;">Ablation study of different ways to introduce new knowledge.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS2.p4">
<p class="ltx_p" id="A1.SS2.p4.1">From table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.T5" title="Table 5 ‣ A.2 Ablation studies for introducing new knowledge ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">5</span></a>, we see that continuing pretraining with new knowledge on the base model or LIMA-style fine-tuning is not effective at introducing new knowledge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS2.p5">
<p class="ltx_p" id="A1.SS2.p5.1">Note that although SFT + RAG models have a perfect score on Direct Question, it is because the SFT models are finetuned on Direct Question-Answer in the first place and is thus, a result of memorization.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Dataset Creation and Formatting</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="A1.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.1 </span>GSM8k Dataset</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.SSS1.p1">
<p class="ltx_p" id="A1.SS3.SSS1.p1.1">We chose the Socratic split of the GSM8k dataset since it contains well-developed subquestion-answer steps. This makes it easy to evaluate finetuned model responses for following this format, as well as evaluating the reasoning itself.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS1.p2">
<p class="ltx_p" id="A1.SS3.SSS1.p2.1">An example question-answer pair is given below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS1.p3">
<svg class="ltx_picture" height="118.94" id="A1.SS3.SSS1.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,118.94) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 115.01 C 0 117.18 1.76 118.94 3.94 118.94 L 596.06 118.94 C 598.24 118.94 600 117.18 600 115.01 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 115.01 C 0 117.18 1.76 118.94 3.94 118.94 L 596.06 118.94 C 598.24 118.94 600 117.18 600 115.01 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="95.32" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.1.1">System Message:</span> You are an expert in mathematics. Solve the following math problem</span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.2.1">Prompt:</span></span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.3">Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?</span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.4">Answer:</span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.5.1">Response:</span></span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.6">How many clips did Natalia sell in May? ** Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.</span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.7">How many clips did Natalia sell altogether in April and May? ** Natalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.</span>
<span class="ltx_p" id="A1.SS3.SSS1.p3.pic1.1.1.1.1.1.8">#### 72</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.2 </span>SubQA Dataset</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.SSS2.p1">
<p class="ltx_p" id="A1.SS3.SSS2.p1.1">We modify the SubQA dataset to build a multi-hop reasoning dataset. The original SubQA dataset contains a select 1,000 subset of HotpotQA bridge-style questions, and two human-verified subquestions for it. For each of the thousand questions, we construct a multi-hop reasoning chain by chaining together the two subquestions, as shown below.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS2.p2">
<svg class="ltx_picture" height="49.84" id="A1.SS3.SSS2.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,49.84) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 45.9 C 0 48.07 1.76 49.84 3.94 49.84 L 596.06 49.84 C 598.24 49.84 600 48.07 600 45.9 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 45.9 C 0 48.07 1.76 49.84 3.94 49.84 L 596.06 49.84 C 598.24 49.84 600 48.07 600 45.9 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="26.21" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS2.p2.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS2.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p2.pic1.1.1.1.1.1.1.1">Question</span>: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p2.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p2.pic1.1.1.1.1.1.2.1">Answer</span>: Chief of Protocol</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p3">
<p class="ltx_p" id="A1.SS3.SSS2.p3.1">Subquestion 1:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS2.p4">
<svg class="ltx_picture" height="52.53" id="A1.SS3.SSS2.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,52.53) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 48.59 C 0 50.76 1.76 52.53 3.94 52.53 L 596.06 52.53 C 598.24 52.53 600 50.76 600 48.59 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 48.59 C 0 50.76 1.76 52.53 3.94 52.53 L 596.06 52.53 C 598.24 52.53 600 50.76 600 48.59 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="28.9" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS2.p4.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS2.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p4.pic1.1.1.1.1.1.1.1">Question</span>: Which woman portrayed Corliss Archer in the film Kiss and Tell?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p4.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p4.pic1.1.1.1.1.1.2.1">Answer</span>: Shirley Temple</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p5">
<p class="ltx_p" id="A1.SS3.SSS2.p5.1">Subquestion 2:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS2.p6">
<svg class="ltx_picture" height="40.23" id="A1.SS3.SSS2.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,40.23) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 36.29 C 0 38.46 1.76 40.23 3.94 40.23 L 596.06 40.23 C 598.24 40.23 600 38.46 600 36.29 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 36.29 C 0 38.46 1.76 40.23 3.94 40.23 L 596.06 40.23 C 598.24 40.23 600 38.46 600 36.29 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="16.6" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS2.p6.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS2.p6.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p6.pic1.1.1.1.1.1.1.1">Question</span>: What government position was held by Shirley Temple?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p6.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p6.pic1.1.1.1.1.1.2.1">Answer</span>: Chief of Protocol</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p7">
<p class="ltx_p" id="A1.SS3.SSS2.p7.1">Generated multi-hop question and reasoning-based answer that the model is fine-tuned on along with the system message:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS2.p8">
<svg class="ltx_picture" height="149.46" id="A1.SS3.SSS2.p8.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,149.46) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 145.52 C 0 147.7 1.76 149.46 3.94 149.46 L 596.06 149.46 C 598.24 149.46 600 147.7 600 145.52 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 145.52 C 0 147.7 1.76 149.46 3.94 149.46 L 596.06 149.46 C 598.24 149.46 600 147.7 600 145.52 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="125.84" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3.1">System Message</span>: You are a helpful assistant. If you are asked a question, answer it carefully and if you are given an instruction, follow it thoroughly. If the question contains some context, use it to answer the question or follow the instruction</span>
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.4"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.4.1">Prompt</span>: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.5"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.5.1">Response</span>: What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.6">Let’s answer this step-by-step</span>
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">Which woman portrayed Corliss Archer in the film Kiss and Tell? <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS2.p8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">→</annotation></semantics></math> Shirley Temple</span>
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">What government position was held by Shirley Temple? <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1b"><ci id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math> Chief of Staff</span>
<span class="ltx_p" id="A1.SS3.SSS2.p8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.7">The final answer is Chief of Staff</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p9">
<p class="ltx_p" id="A1.SS3.SSS2.p9.1">The SubQARecall version of the dataset was a simple modification of the response format, in which we added an event recall step first, which can be used to evaluate hallucinations. The event annotation was done using GPT-4o using the steps from the response. An example response format for this modified dataset is given below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS2.p10">
<svg class="ltx_picture" height="169.03" id="A1.SS3.SSS2.p10.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,169.03) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 165.1 C 0 167.27 1.76 169.03 3.94 169.03 L 596.06 169.03 C 598.24 169.03 600 167.27 600 165.1 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 165.1 C 0 167.27 1.76 169.03 3.94 169.03 L 596.06 169.03 C 598.24 169.03 600 167.27 600 165.1 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="145.41" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3.1">System Message</span>: You are a helpful assistant. If you are asked a question, answer it carefully and if you are given an instruction, follow it thoroughly. If the question contains some context, use it to answer the question or follow the instruction</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.4"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.4.1">Prompt</span>:</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.5">What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.6"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.6.1">Response</span>:</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.7">Event Recall: Shirley Temple played the role of Corliss Archer in the film Kiss and Tell and also held the position of Chief of Staff.</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.8">What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.9">Let’s answer this step-by-step</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">Which woman portrayed Corliss Archer in the film Kiss and Tell? <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS2.p10.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">→</annotation></semantics></math> Shirley Temple</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">What government position was held by Shirley Temple? <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1b"><ci id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1d">→</annotation></semantics></math> Chief of Staff</span>
<span class="ltx_p" id="A1.SS3.SSS2.p10.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.10">The final answer is Chief of Staff</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p11">
<p class="ltx_p" id="A1.SS3.SSS2.p11.1">For evaluation, simple string matching ignores answers that are correct but differently worded. It also introduces false positives if the model just contains the final answer as part of its response instead of actually giving it as the answer. So, we use GPT-4o to evaluate the model response and provide the question, the correct answer, and the model-generated answer.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p12">
<p class="ltx_p" id="A1.SS3.SSS2.p12.1">The evaluation prompt for this task is given below</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS2.p13">
<svg class="ltx_picture" height="203.5" id="A1.SS3.SSS2.p13.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,203.5) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 199.57 C 0 201.74 1.76 203.5 3.94 203.5 L 596.06 203.5 C 598.24 203.5 600 201.74 600 199.57 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 199.57 C 0 201.74 1.76 203.5 3.94 203.5 L 596.06 203.5 C 598.24 203.5 600 201.74 600 199.57 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="179.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.1.1">System Message</span>: You are grading responses to a question. You are given a question, response and the answer key.</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.2.1">Prompt</span>: Check if the response to the question is correct, as inferred by the answer key. Here are some guidelines:</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.3">1. Make sure that the response is actually answering the question and not just writing things about the question.</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.4">2. If the response is just listing things or spewing exposition related to the question and not actually answering it, it is incorrect. It must be a direct or a multistep reasoning answer to the question.</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.5">3. The final need not exactly match the answer key, but it should be close enough to be considered correct.</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.6">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.6.1">“No Error”</span> if the response is correct and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.6.2">“Error”</span> if it is incorrect and nothing else.</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.7">Now grade this:</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.8">Question - {question}</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.9">Answer - {answer}</span>
<span class="ltx_p" id="A1.SS3.SSS2.p13.pic1.1.1.1.1.1.10">response - {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p14">
<p class="ltx_p" id="A1.SS3.SSS2.p14.1">A random subset of 100 multihop questions were held out for evaluation and the rest are used for training.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS2.p15">
<p class="ltx_p" id="A1.SS3.SSS2.p15.1">With this, we get a training dataset of 2,700 questions consisting of 1800 one-hop questions and 900 multi-hop questions. The evaluation set consists of the 100 held-out multihop questions. Since the models are fine-tuned specifically to follow the format of subquestion-answer reasoning steps, we can easily evaluate if they follow the expected reasoning format, as well as evaluate the correctness of the reasoning steps themselves.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.3 </span>Conifer and Dolly Dataset</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.SSS3.p1">
<p class="ltx_p" id="A1.SS3.SSS3.p1.1">The Conifer dataset has multiturn instruction following prompt-response dialogue examples and at each turn, the prompts gets harder, with more constraints and better responses.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS3.p2">
<p class="ltx_p" id="A1.SS3.SSS3.p2.1">For the Instruction Following Tasks, Dolly is of lower quality for the IFEval benchmark because the prompts are very different from the benchmark prompts and do not include constraints and directions. Conifer is a better dataset as it is targeted for constrained instruction following, similar to the IFEval prompts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS3.p3">
<p class="ltx_p" id="A1.SS3.SSS3.p3.1">An example prompt-response pair from Conifer is given below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS3.p4">
<svg class="ltx_picture" height="384.61" id="A1.SS3.SSS3.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,384.61) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 380.68 C 0 382.85 1.76 384.61 3.94 384.61 L 596.06 384.61 C 598.24 384.61 600 382.85 600 380.68 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 380.68 C 0 382.85 1.76 384.61 3.94 384.61 L 596.06 384.61 C 598.24 384.61 600 382.85 600 380.68 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="360.99" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.1.1">System Message</span>: You are a helpful assistant. If you are asked a question, answer it carefully and if you are given an instruction, follow it thoroughly. If the question contains some context, use it to answer the question or follow the instruction</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.2.1">Prompt</span>:</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.3">Can you provide examples of effective strategies for engaging senior partners in the investment sector through cold-calling? Ensure to cover:</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.4">1. Across industries such as Private Equity and Venture Capital;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.5">2. When communicating with C-suite executives and Managing Directors;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.6">3. A concise and to-the-point, data-driven approach;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.7">4. Objectives include pitching a new investment opportunity and building a relationship;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.8">5. Adherence to financial promotion rules;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.9">6. Consideration of time zone differences and avoidance of holidays;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.10">7. Demonstrating a thorough understanding of the partner’s portfolio and recent industry trends;</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.11">8. Provide a bulleted list.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.12"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.12.1">Response</span>:</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.13">Effective strategies for engaging senior partners in the investment sector through cold-calling include:</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.14">- Tailoring the pitch to the specific industry, whether it’s Private Equity or Venture Capital, highlighting relevant trends and opportunities.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.15">- Addressing C-suite executives and Managing Directors with respect and understanding of their time constraints, ensuring brevity and relevance in the conversation.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.16">- Utilizing a data-driven approach to substantiate the investment opportunity, presenting clear metrics and potential ROI.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.17">- Clearly stating the purpose of the call, whether it’s to introduce a new investment opportunity or to initiate a relationship for future collaboration.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.18">- Ensuring compliance with financial promotion rules by providing accurate information and not making misleading claims.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.19">- Scheduling calls considering the recipient’s time zone and avoiding holidays to respect their personal time.</span>
<span class="ltx_p" id="A1.SS3.SSS3.p4.pic1.1.1.1.1.1.20">- Demonstrating knowledge of the partner’s current portfolio and aligning the pitch with their investment strategy and recent industry trends.</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS3.SSS3.p5">
<p class="ltx_p" id="A1.SS3.SSS3.p5.1">An example prompt-response pair from the Dolly dataset is given below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS3.p6">
<svg class="ltx_picture" height="152.15" id="A1.SS3.SSS3.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,152.15) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 148.22 C 0 150.39 1.76 152.15 3.94 152.15 L 596.06 152.15 C 598.24 152.15 600 150.39 600 148.22 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 148.22 C 0 150.39 1.76 152.15 3.94 152.15 L 596.06 152.15 C 598.24 152.15 600 150.39 600 148.22 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="128.53" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.1.1">System Message</span>: You are a helpful assistant. If you are asked a question, answer it carefully and if you are given an instruction, follow it thoroughly. If the question contains some context, use it to answer the question or follow the instruction</span>
<span class="ltx_p" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.2.1">Prompt</span>:</span>
<span class="ltx_p" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.3">How do I start running?</span>
<span class="ltx_p" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.4.1">Response:</span></span>
<span class="ltx_p" id="A1.SS3.SSS3.p6.pic1.1.1.1.1.1.5">Make sure you get comfortable running shoes and attire. Start with achievable goal in mind like a 5K race. If you never ran before, start gradually from a walk, to brisk walk, light jog aiming for 15-30mins initially. Slowly increase your running time and distance as your fitness level improves. One of the most important things is cool down and gentle stretching. Always listen to your body, and take rest days when needed to prevent injury.</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="268" id="A1.F7.g1" src="https://arxiv.org/html/2410.03717v1/extracted/5885555/images/quality_scaling.png" width="299">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="A1.F7.3.2" style="font-size:90%;">Model performance scales better with higher quality datasets</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.SSS3.p7">
<p class="ltx_p" id="A1.SS3.SSS3.p7.1">We also do an ablation study of fine-tuning Llama-3-8b against Conifer’s hard and easy split as well. We take dialogue examples with at least 4 turns and consider all first turns to create the ConiferEasy dataset and all last turns to create the ConiferHard dataset. Note that both of these are now single-turn prompt-response datasets. We also compare these models against the Dolly15k dataset. As seen in figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.F7" title="Figure 7 ‣ A.3.3 Conifer and Dolly Dataset ‣ A.3 Dataset Creation and Formatting ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">7</span></a>, for the same number of examples, we see that model performance scales better with better dataset quality. This highlights the importance of high-quality datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="A1.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.4 </span>Facts100 Dataset</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS3.SSS4.p1">
<p class="ltx_p" id="A1.SS3.SSS4.p1.1">The prompts used for evaluating hallucination and reasoning errors in the responses for the Facts100 multihop questions are given below:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS4.p2">
<svg class="ltx_picture" height="170.29" id="A1.SS3.SSS4.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,170.29) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 166.36 C 0 168.53 1.76 170.29 3.94 170.29 L 596.06 170.29 C 598.24 170.29 600 168.53 600 166.36 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 166.36 C 0 168.53 1.76 170.29 3.94 170.29 L 596.06 170.29 C 598.24 170.29 600 168.53 600 166.36 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="146.67" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.1.1">Prompt</span>: You are evaluating incorrect responses to a multi-hop reasoning question. You are given a question, a response, and an event related to the question.</span>
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.2">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.2.1">“Error”</span> if the response hallucinates about the event in the response i.e. incorrectly recalls or uses the event and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.2.2">“No Error”</span> otherwise, and nothing else.</span>
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.3">Your job is only to check the use of the event and not the correctness of the final answer.</span>
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.4">Now grade this:</span>
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.5">Question - {question}</span>
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.6">Event - {event}</span>
<span class="ltx_p" id="A1.SS3.SSS4.p2.pic1.1.1.1.1.1.7">response - {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS4.p3">
<svg class="ltx_picture" height="186.9" id="A1.SS3.SSS4.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,186.9) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 182.96 C 0 185.14 1.76 186.9 3.94 186.9 L 596.06 186.9 C 598.24 186.9 600 185.14 600 182.96 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 182.96 C 0 185.14 1.76 186.9 3.94 186.9 L 596.06 186.9 C 598.24 186.9 600 185.14 600 182.96 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="163.28" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.1.1">Prompt</span>: You are evaluating responses to a multihop reasoning question. You are given a question and a response.</span>
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.2">The question is structured such that it requires a step-by-step reasoning chain to arrive at the final answer.</span>
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.3">Your job is only to check the inaccuracy of the reasoning chain if it has one (and not of the final answer or event).</span>
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.4">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.4.1">“Error”</span> if the reasoning of the response is incorrect and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.4.2">“No Error”</span> otherwise or if it has no reasoning, and nothing else.</span>
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.5">Now grade this:</span>
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.6">Question - {question}</span>
<span class="ltx_p" id="A1.SS3.SSS4.p3.pic1.1.1.1.1.1.7">response - {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Error Analysis Prompt Templates</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS4.p1">
<p class="ltx_p" id="A1.SS4.p1.1">GSM8k error analysis prompts. The placeholders inside {} are replaced by the actual question, correct answer, and the model response.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p2">
<svg class="ltx_picture" height="137.09" id="A1.SS4.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,137.09) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 133.15 C 0 135.32 1.76 137.09 3.94 137.09 L 596.06 137.09 C 598.24 137.09 600 135.32 600 133.15 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 133.15 C 0 135.32 1.76 137.09 3.94 137.09 L 596.06 137.09 C 598.24 137.09 600 135.32 600 133.15 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="113.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS4.p2.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS4.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p2.pic1.1.1.1.1.1.1.1">FORMAT ANNOTATION PROMPT:</span></span>
<span class="ltx_p" id="A1.SS4.p2.pic1.1.1.1.1.1.2">You are given a math question, a solution, and a response. The response is supposed to be an explanation of the solution followed by the delimiter ’####’ and the final answer.</span>
<span class="ltx_p" id="A1.SS4.p2.pic1.1.1.1.1.1.3">You are to check if the response follows this format. Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p2.pic1.1.1.1.1.1.3.1">“No Error”</span> if it follows it, and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p2.pic1.1.1.1.1.1.3.2">“Error”</span> if it is not, and nothing else. It doesn’t matter if the final answer is correct or not.</span>
<span class="ltx_p" id="A1.SS4.p2.pic1.1.1.1.1.1.4">Now grade this:</span>
<span class="ltx_p" id="A1.SS4.p2.pic1.1.1.1.1.1.5">Question: {question}</span>
<span class="ltx_p" id="A1.SS4.p2.pic1.1.1.1.1.1.6">Response: {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p3">
<svg class="ltx_picture" height="186.9" id="A1.SS4.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,186.9) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 182.96 C 0 185.14 1.76 186.9 3.94 186.9 L 596.06 186.9 C 598.24 186.9 600 185.14 600 182.96 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 182.96 C 0 185.14 1.76 186.9 3.94 186.9 L 596.06 186.9 C 598.24 186.9 600 185.14 600 182.96 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="163.28" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS4.p3.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p3.pic1.1.1.1.1.1.1.1">CALCULATION ANNOTATION PROMPT:</span></span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.2">You are given a math question, a solution, and a response. The response is supposed to be an explanation of the solution followed by the delimiter ’####’ and the final answer.</span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.3">You are to check if the response contains any arithmetic or calculation errors. You are not required to check if the reasoning in the response is correct or not, just the arithmetic calculations.</span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.4">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p3.pic1.1.1.1.1.1.4.1">“No Error”</span> if has no calculation errors, and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p3.pic1.1.1.1.1.1.4.2">“Error”</span> if it does, and nothing else.</span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.5">Now grade this:</span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.6">Question: {question}</span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.7">Solution: {solution}</span>
<span class="ltx_p" id="A1.SS4.p3.pic1.1.1.1.1.1.8">Response: {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p4">
<svg class="ltx_picture" height="203.5" id="A1.SS4.p4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,203.5) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 199.57 C 0 201.74 1.76 203.5 3.94 203.5 L 596.06 203.5 C 598.24 203.5 600 201.74 600 199.57 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 199.57 C 0 201.74 1.76 203.5 3.94 203.5 L 596.06 203.5 C 598.24 203.5 600 201.74 600 199.57 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="179.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS4.p4.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p4.pic1.1.1.1.1.1.1.1">REASONING ANNOTATION PROMPT:</span></span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.2">You are given a math question, the solution, and an incorrect response. The response is supposed to be an explanation of the solution followed by the delimiter ’####’ and the final answer.</span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.3">You are to check if the response contains any understanding or reasoning errors, in any of its steps. You are not required to check if the arithmetic calculations in the response are correct or not, just the reasoning.</span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.4">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p4.pic1.1.1.1.1.1.4.1">“No Error”</span> if has no reasoning or understanding errors, and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p4.pic1.1.1.1.1.1.4.2">“Error”</span> if it does, and nothing else.</span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.5">Now grade this:</span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.6">Question: {question}</span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.7">Solution: {solution}</span>
<span class="ltx_p" id="A1.SS4.p4.pic1.1.1.1.1.1.8">Response: {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.SS4.p5">
<p class="ltx_p" id="A1.SS4.p5.1">SubQA Error Analysis prompt:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p6">
<svg class="ltx_picture" height="186.9" id="A1.SS4.p6.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,186.9) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 182.96 C 0 185.14 1.76 186.9 3.94 186.9 L 596.06 186.9 C 598.24 186.9 600 185.14 600 182.96 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 182.96 C 0 185.14 1.76 186.9 3.94 186.9 L 596.06 186.9 C 598.24 186.9 600 185.14 600 182.96 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="163.28" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS4.p6.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p6.pic1.1.1.1.1.1.1.1">FORMAT ANNOTATION PROMPT:</span></span>
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.2">You are evaluating responses to a multihop reasoning question. You are given a question and a response. The question is a multihop reasoning question and the response is supposed to have detailed subquestion-answer style reasoning steps, followed by the final answer.</span>
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.3">Your job is to only check if the response is answered in this format. It doesn’t matter if the final answer is correct or not.</span>
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.4">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p6.pic1.1.1.1.1.1.4.1">“Error”</span> if it doesn’t follow this format or jumps straight to the final answer and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p6.pic1.1.1.1.1.1.4.2">“No Error”</span> if the response attempts to answer it step-by-step, and nothing else.</span>
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.5">Now grade this:</span>
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.6">Question: {question}</span>
<span class="ltx_p" id="A1.SS4.p6.pic1.1.1.1.1.1.7">Response: {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS4.p7">
<svg class="ltx_picture" height="203.5" id="A1.SS4.p7.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,203.5) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 3.94 L 0 199.57 C 0 201.74 1.76 203.5 3.94 203.5 L 596.06 203.5 C 598.24 203.5 600 201.74 600 199.57 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 0 3.94 L 0 199.57 C 0 201.74 1.76 203.5 3.94 203.5 L 596.06 203.5 C 598.24 203.5 600 201.74 600 199.57 L 600 3.94 C 600 1.76 598.24 0 596.06 0 L 3.94 0 C 1.76 0 0 1.76 0 3.94 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 19.68 11.81)"><foreignObject color="#000000" height="179.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="560.63">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.SS4.p7.pic1.1.1.1.1.1" style="width:405.2pt;">
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.SS4.p7.pic1.1.1.1.1.1.1.1">REASONING ANNOTATION PROMPT:</span></span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.2">You are grading responses to a multihop reasoning question. You are given a question, intermediate step question-answer pairs that lead to the final answer as well as a model-generated response to grade.</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.3">Check if the response correctly uses the given intermediate step question-answer to answer the question.</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.4">Return <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p7.pic1.1.1.1.1.1.4.1">“Error”</span> if the response has an incorrect intermediate reasoning step and <span class="ltx_text ltx_inline-quote ltx_outerquote" id="A1.SS4.p7.pic1.1.1.1.1.1.4.2">“No Error”</span>, and nothing else.</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.5">Now grade this:</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.6">Question - {question}</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.7">Intermediate Step Question - {subquestion}</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.8">Intermediate Step Answer - {subanswer}</span>
<span class="ltx_p" id="A1.SS4.p7.pic1.1.1.1.1.1.9">Response - {response}</span>
</span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Training and inference parameters</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS5.p1">
<p class="ltx_p" id="A1.SS5.p1.1">No PeFT methods were used, and the learning rate was set to 1e-5 with cosine decay to 0. We found that batch size has a big effect on model performance for smaller dataset sizes. The final batch sizes we used are in table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.T6" title="Table 6 ‣ A.5 Training and inference parameters ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">6</span></a></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T6.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T6.2.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A1.T6.2.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A1.T6.2.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T6.2.1.1.2.1">8b &amp; 13b models</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T6.2.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T6.2.1.1.3.1">70b models</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T6.2.2.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T6.2.2.1.1">0 - 100</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.2.2.1.2">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T6.2.2.1.3">16</td>
</tr>
<tr class="ltx_tr" id="A1.T6.2.3.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="A1.T6.2.3.2.1">101 - 1000</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.2.3.2.2">8</td>
<td class="ltx_td ltx_align_center" id="A1.T6.2.3.2.3">32</td>
</tr>
<tr class="ltx_tr" id="A1.T6.2.4.3">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A1.T6.2.4.3.1">1001+</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T6.2.4.3.2">16</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T6.2.4.3.3">128</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T6.3.1.1" style="font-size:90%;">Table 6</span>: </span><span class="ltx_text" id="A1.T6.4.2" style="font-size:90%;">Batch sizes used.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS5.p2">
<p class="ltx_p" id="A1.SS5.p2.1">The evaluation was also done in a 0-shot setting to isolate improvements gained from adding few-shot examples. Sampling was done with a temperature 0f 0.4, top-p value of 0.95, and a repetition penalty of 1.1.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Power law fit coefficients</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A1.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T7.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T7.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="A1.T7.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T7.2.1.1.1.1">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T7.2.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T7.2.1.1.2.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A1.T7.2.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T7.2.1.1.3.1">a</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A1.T7.2.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T7.2.1.1.4.1">b</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T7.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T7.2.2.1.1" rowspan="3"><span class="ltx_text" id="A1.T7.2.2.1.1.1">Math</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.2.1.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.2.1.3">19.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.2.2.1.4">7.66</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.3.2.1">mistral-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.3.2.2">8.14</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.3.2.3">4.97</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.4.3.1">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.4.3.2">4.21</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.4.3.3">5.47</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T7.2.5.4.1" rowspan="3"><span class="ltx_text" id="A1.T7.2.5.4.1.1">Multihop QnA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.5.4.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.5.4.3">11.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.2.5.4.4">7.77</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.6.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.6.5.1">mistral-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.6.5.2">5.40</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.6.5.3">7.75</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.7.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.7.6.1">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.7.6.2">8.27</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.7.6.3">9.39</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T7.2.8.7.1" rowspan="3"><span class="ltx_text" id="A1.T7.2.8.7.1.1">Coding</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.8.7.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.8.7.3">27.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.2.8.7.4">23.43</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.9.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.9.8.1">mistral-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.9.8.2">17.10</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.9.8.3">17.47</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.10.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.10.9.1">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.10.9.2">3.95</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.10.9.3">7.11</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T7.2.11.10.1" rowspan="3"><span class="ltx_text" id="A1.T7.2.11.10.1.1">IF-Conifer</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.11.10.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.11.10.3">31.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.2.11.10.4">11.90</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.12.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.12.11.1">mistral-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.12.11.2">21.76</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.12.11.3">9.28</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.13.12">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.13.12.1">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.13.12.2">17.83</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.13.12.3">10.00</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T7.2.14.13.1" rowspan="3"><span class="ltx_text" id="A1.T7.2.14.13.1.1">IF-Dolly</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.14.13.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.2.14.13.3">30.94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.2.14.13.4">21.12</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.15.14">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.15.14.1">mistral-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.2.15.14.2">23.76</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.15.14.3">15.15</td>
</tr>
<tr class="ltx_tr" id="A1.T7.2.16.15">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T7.2.16.15.1">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T7.2.16.15.2">17.04</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T7.2.16.15.3">14.54</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T7.3.1.1" style="font-size:90%;">Table 7</span>: </span><span class="ltx_text" id="A1.T7.4.2" style="font-size:90%;">Dataset scaling power law coefficients</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.1">Coefficients for the power law curves of the form <math alttext="P=aD^{1/b}" class="ltx_Math" display="inline" id="A1.SS6.p1.1.m1.1"><semantics id="A1.SS6.p1.1.m1.1a"><mrow id="A1.SS6.p1.1.m1.1.1" xref="A1.SS6.p1.1.m1.1.1.cmml"><mi id="A1.SS6.p1.1.m1.1.1.2" xref="A1.SS6.p1.1.m1.1.1.2.cmml">P</mi><mo id="A1.SS6.p1.1.m1.1.1.1" xref="A1.SS6.p1.1.m1.1.1.1.cmml">=</mo><mrow id="A1.SS6.p1.1.m1.1.1.3" xref="A1.SS6.p1.1.m1.1.1.3.cmml"><mi id="A1.SS6.p1.1.m1.1.1.3.2" xref="A1.SS6.p1.1.m1.1.1.3.2.cmml">a</mi><mo id="A1.SS6.p1.1.m1.1.1.3.1" xref="A1.SS6.p1.1.m1.1.1.3.1.cmml">⁢</mo><msup id="A1.SS6.p1.1.m1.1.1.3.3" xref="A1.SS6.p1.1.m1.1.1.3.3.cmml"><mi id="A1.SS6.p1.1.m1.1.1.3.3.2" xref="A1.SS6.p1.1.m1.1.1.3.3.2.cmml">D</mi><mrow id="A1.SS6.p1.1.m1.1.1.3.3.3" xref="A1.SS6.p1.1.m1.1.1.3.3.3.cmml"><mn id="A1.SS6.p1.1.m1.1.1.3.3.3.2" xref="A1.SS6.p1.1.m1.1.1.3.3.3.2.cmml">1</mn><mo id="A1.SS6.p1.1.m1.1.1.3.3.3.1" xref="A1.SS6.p1.1.m1.1.1.3.3.3.1.cmml">/</mo><mi id="A1.SS6.p1.1.m1.1.1.3.3.3.3" xref="A1.SS6.p1.1.m1.1.1.3.3.3.3.cmml">b</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS6.p1.1.m1.1b"><apply id="A1.SS6.p1.1.m1.1.1.cmml" xref="A1.SS6.p1.1.m1.1.1"><eq id="A1.SS6.p1.1.m1.1.1.1.cmml" xref="A1.SS6.p1.1.m1.1.1.1"></eq><ci id="A1.SS6.p1.1.m1.1.1.2.cmml" xref="A1.SS6.p1.1.m1.1.1.2">𝑃</ci><apply id="A1.SS6.p1.1.m1.1.1.3.cmml" xref="A1.SS6.p1.1.m1.1.1.3"><times id="A1.SS6.p1.1.m1.1.1.3.1.cmml" xref="A1.SS6.p1.1.m1.1.1.3.1"></times><ci id="A1.SS6.p1.1.m1.1.1.3.2.cmml" xref="A1.SS6.p1.1.m1.1.1.3.2">𝑎</ci><apply id="A1.SS6.p1.1.m1.1.1.3.3.cmml" xref="A1.SS6.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="A1.SS6.p1.1.m1.1.1.3.3.1.cmml" xref="A1.SS6.p1.1.m1.1.1.3.3">superscript</csymbol><ci id="A1.SS6.p1.1.m1.1.1.3.3.2.cmml" xref="A1.SS6.p1.1.m1.1.1.3.3.2">𝐷</ci><apply id="A1.SS6.p1.1.m1.1.1.3.3.3.cmml" xref="A1.SS6.p1.1.m1.1.1.3.3.3"><divide id="A1.SS6.p1.1.m1.1.1.3.3.3.1.cmml" xref="A1.SS6.p1.1.m1.1.1.3.3.3.1"></divide><cn id="A1.SS6.p1.1.m1.1.1.3.3.3.2.cmml" type="integer" xref="A1.SS6.p1.1.m1.1.1.3.3.3.2">1</cn><ci id="A1.SS6.p1.1.m1.1.1.3.3.3.3.cmml" xref="A1.SS6.p1.1.m1.1.1.3.3.3.3">𝑏</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS6.p1.1.m1.1c">P=aD^{1/b}</annotation><annotation encoding="application/x-llamapun" id="A1.SS6.p1.1.m1.1d">italic_P = italic_a italic_D start_POSTSUPERSCRIPT 1 / italic_b end_POSTSUPERSCRIPT</annotation></semantics></math> are in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.F1" title="Figure 1 ‣ 3.2 Results ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">1</span></a> are in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.T7" title="Table 7 ‣ A.6 Power law fit coefficients ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">7</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T8.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T8.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.1.1.1">Model Family</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.1.1.2">Task</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.1.1.3">Model</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.1.1.4">a</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.1.1.5">b</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.2.2.1" rowspan="6"><span class="ltx_text" id="A1.T8.2.2.2.1.1">llama-3</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.2.2.2" rowspan="2"><span class="ltx_text" id="A1.T8.2.2.2.2.1">Math</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.2.2.3">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.2.2.4">18.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.2.2.5">7.28</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.3.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.3.3.1">llama-3-70b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.3.3.2">32.07</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.3.3.3">9.07</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.4.4.1" rowspan="2"><span class="ltx_text" id="A1.T8.2.4.4.1.1">Multihop QnA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.4.4.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.4.4.3">10.81</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.4.4.4">6.91</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.5.5.1">llama-3-70b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.5.5.2">23.58</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.5.5.3">8.37</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.6.6.1" rowspan="2"><span class="ltx_text" id="A1.T8.2.6.6.1.1">IF-Conifer</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.6.6.2">llama-3-8b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.6.6.3">33.35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.6.6.4">13.52</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.7.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.7.7.1">llama-3-70b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.7.7.2">37.85</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.7.7.3">11.83</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T8.2.8.8.1" rowspan="9"><span class="ltx_text" id="A1.T8.2.8.8.1.1">llama-2</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.8.8.2" rowspan="3"><span class="ltx_text" id="A1.T8.2.8.8.2.1">Math</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.8.8.3">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.8.8.4">4.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.8.8.5">6.11</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.9.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.9.9.1">llama-2-13b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.9.9.2">10.63</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.9.9.3">7.28</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.10.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.10.10.1">llama-2-70b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.10.10.2">22.41</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.10.10.3">6.91</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.2.11.11.1" rowspan="3"><span class="ltx_text" id="A1.T8.2.11.11.1.1">Multihop QnA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.11.11.2">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.11.11.3">8.37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.11.11.4">9.33</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.12.12">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.12.12.1">llama-2-13b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.12.12.2">9.83</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.12.12.3">6.81</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.13.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.13.13.1">llama-2-70b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.13.13.2">23.09</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.13.13.3">9.61</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T8.2.14.14.1" rowspan="3"><span class="ltx_text" id="A1.T8.2.14.14.1.1">IF-Conifer</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.14.14.2">llama-2-7b</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.2.14.14.3">16.86</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.2.14.14.4">9.51</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.15.15">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.15.15.1">llama-2-13b</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.2.15.15.2">23.73</td>
<td class="ltx_td ltx_align_center" id="A1.T8.2.15.15.3">10.48</td>
</tr>
<tr class="ltx_tr" id="A1.T8.2.16.16">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T8.2.16.16.1">llama-2-70b</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T8.2.16.16.2">27.23</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="A1.T8.2.16.16.3">8.67</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T8.3.1.1" style="font-size:90%;">Table 8</span>: </span><span class="ltx_text" id="A1.T8.4.2" style="font-size:90%;">Power law coefficients for Model size scaling experiment</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS6.p2">
<p class="ltx_p" id="A1.SS6.p2.1">Coefficients for the power law curves in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#S3.F2" title="Figure 2 ‣ Model performance for a task follows a power-law relationship with fine-tuning data. ‣ 3.2 Results ‣ 3 Post-training Data Scaling ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">2</span></a> are in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03717v1#A1.T8" title="Table 8 ‣ A.6 Power law fit coefficients ‣ Appendix A Appendix ‣ Revisiting the Superficial Alignment Hypothesis"><span class="ltx_text ltx_ref_tag">8</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>

</div>


<button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button><div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer></body></html>