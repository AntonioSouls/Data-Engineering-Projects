<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Next state prediction gives rise to entangled, yet compositional representations of objects</title>
<!--Generated on Mon Oct  7 11:27:25 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.04940v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S1" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S2" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S3" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S3.SS1" title="In 3 Methods â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Models</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S3.SS1.SSS1" title="In 3.1 Models â€£ 3 Methods â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Slotted models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S3.SS2" title="In 3 Methods â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Assessing object representations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4.SS1" title="In 4 Experiments â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Object slots are not necessary for learning object dynamics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4.SS2" title="In 4 Experiments â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Predicting object dynamics improves object separability</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>The benefits of partially entangled representations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5.SS1" title="In 5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Distributed and slotted representational alignment increases with more data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S6" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S6.SS1" title="In 6 Discussion â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S6.SS2" title="In 6 Discussion â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A1" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A2" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Architecture and hyperparameters</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A2.SS1" title="In Appendix B Architecture and hyperparameters â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Convolutional Neural Networks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A2.SS2" title="In Appendix B Architecture and hyperparameters â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Transformer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A2.SS3" title="In Appendix B Architecture and hyperparameters â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Hyperparameters</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A3" title="In Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Object decodability baseline</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A3.SS1" title="In Appendix C Object decodability baseline â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Slotted representations are recoverable from distributed representations</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Next state prediction gives rise to entangled, yet compositional representations of objects</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tankred Saanum<sup class="ltx_sup" id="id6.6.id1"><span class="ltx_text ltx_font_italic" id="id6.6.id1.1">1,â€ </span></sup>
<br class="ltx_break"/>&amp;Luca M. Schulze Buschoff<sup class="ltx_sup" id="id7.7.id2"><span class="ltx_text ltx_font_italic" id="id7.7.id2.1">2</span></sup>
<br class="ltx_break"/>&amp;Peter Dayan<sup class="ltx_sup" id="id8.8.id3"><span class="ltx_text ltx_font_italic" id="id8.8.id3.1">âˆ—,1,3</span></sup>
<br class="ltx_break"/>&amp;Eric Schulz<sup class="ltx_sup" id="id9.9.id4"><span class="ltx_text ltx_font_italic" id="id9.9.id4.1">âˆ—,2</span></sup>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id10.10.id5">\AND</span>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â <sup class="ltx_sup" id="id11.11.id6">â€ </sup><span class="ltx_text ltx_font_typewriter" id="id12.12.id7">tankred.saanum@tuebingen.mpg.de</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id13.id1">Compositional representations are thought to enable humans to generalize across combinatorially vast state spaces. Models with learnable object slots, which encode information about objects in separate latent codes, have shown promise for this type of generalization but rely on strong architectural priors. Models with distributed representations, on the other hand, use overlapping, potentially entangled neural codes, and their ability to support compositional generalization remains underexplored. In this paper we examine whether distributed models can develop linearly separable representations of objects, like slotted models, through unsupervised training on videos of object interactions. We show that, surprisingly, models with distributed representations often match or outperform models with object slots in downstream prediction tasks. Furthermore, we find that linearly separable object representations can emerge without object-centric priors, with auxiliary objectives like next-state prediction playing a key role. Finally, we observe that distributed modelsâ€™ object representations are never fully disentangled, even if they are linearly separable: Multiple objects can be encoded through partially overlapping neural populations while still being highly separable with a linear classifier. We hypothesize that maintaining partially shared codes enables distributed models to better compress object dynamics, potentially enhancing generalization.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><sup class="ltx_sup" id="footnote1.1">1</sup>Max Planck Institute for Biological Cybernetics, TÃ¼bingen, Germany</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1a"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><sup class="ltx_sup" id="footnote1a.1">2</sup>Institute for Human-Centered AI, Helmholtz Computational Health Center, Munich, Germany</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1b"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><sup class="ltx_sup" id="footnote1b.1">3</sup>University of TÃ¼bingen</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote1c"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><sup class="ltx_sup" id="footnote1c.1">*</sup>Equal advising.</span></span></span>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Humans naturally decompose scenes, events and processes in terms of the objects that feature in them <cite class="ltx_cite ltx_citemacro_citep">(Tenenbaum etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib47" title="">2011</a>; Lake etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib30" title="">2017</a>)</cite>. These object-centric construals have been argued to explain humansâ€™ ability to reason and generalize successfully <cite class="ltx_cite ltx_citemacro_citep">(Goodman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib13" title="">2008</a>; Lake etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib29" title="">2015</a>; SchulzeÂ Buschoff etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib42" title="">2023</a>)</cite>. It has therefore long been a chief aim in machine learning research to design models and agents that learn to represent the world compositionally, e.g. in terms of the building blocks that compose it. In computer vision, models with <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">object slots</em> learn to encode scenes into a latent, compositional code, where each object in the scene is modelled by a distinct part of the latent space. This strong architectural assumption allows the models to learn representations that improve compositional generalization <cite class="ltx_cite ltx_citemacro_citep">(Brady etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib3" title="">2023</a>; Wiedemer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib48" title="">2023</a>)</cite> and reasoning about objects <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib49" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Slotted representations are often contrasted with distributed representations. Models with distributed representations encode information about a scene, and potentially the objects that compose it, in overlapping populations of neurons. Can models with distributed representations learn to encode objects in a compositional way without supervision? And can distributed coding schemes offer advantages over <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">purely</em> object-centric coding schemes?</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">By compressing properties of multiple objects in a shared code, models with distributed representations could potentially gain richer representations where scene similarities are more abundant <cite class="ltx_cite ltx_citemacro_citep">(Smola &amp; SchÃ¶lkopf, <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib46" title="">1998</a>; Lucas etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib35" title="">2015</a>; Demircan etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib7" title="">2023</a>; Garvert etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib11" title="">2023</a>)</cite>. For instance, if two objects are represented similarly, the model could use what it knows about the dynamics of one object to generalize about the dynamics of the other object. This could in turn facilitate learning, potentially at the loss of fully separable object representations.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="368" id="S1.F1.1.g1" src="x1.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the decoding analysis and datasets. <span class="ltx_text ltx_font_bold" id="S1.F1.4.1">A</span>: We propose a simple test for assessing compositional object representations. After unsupervised pre-training on object videos, we evaluate the linear separability of modelsâ€™ latent object representations. This is done by training a linear classifier on the absolute differences of two successive encoded frames where only one object changes. <span class="ltx_text ltx_font_bold" id="S1.F1.5.2">B</span>: We evaluate the models on five datasets of dynamically interacting objects, ranging from simple depictions of blocks and sprites to realistic simulations of 3D objects.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In our study, we offer experimental evidence that <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">models with distributed representations can learn compositional construals of objects</span> in an unsupervised manner, when trained on sufficiently large datasets. Across 5 datasets that consist of dynamically interacting objects we see that models with distributed representations either match or outperform their slot-based counterparts in the tasks they were trained to perform (image reconstruction or dynamics prediction). Next, we define a simple metric inspired by <cite class="ltx_cite ltx_citemacro_cite">Higgins etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib19" title="">2016</a>)</cite> that quantifies how accurately object identities can be linearly decoded from a modelâ€™s latent representations (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">1</span></a>). We see that as training data size increases, the models with distributed representations develop gradually more disentangled representations of objects. However, while object representations become separable, their properties remain encoded through <em class="ltx_emph ltx_font_italic" id="S1.p4.1.2">partially</em> overlapping populations of neurons, potentially allowing for richer generalization. Investigating the effect of training objective and loss function on the separability metric, we find that next-state prediction is a crucial component for the development of separable object representations for models without object slots.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">While we see object disentanglement emerge without any supervision or regularization, this disentanglement is not absolute. Distributed models represent object properties in partially shared latent spaces. We speculate that this can facilitate generalization: When comparing modelsâ€™ representations of object dynamics, we see clear clustering based on object identity (indicating separable object representations), but also clustering based on what type of transformation was applied to the object. This means that transformations such as object rotations, object scaling or object movements are represented more similarly, independently of which object they are applied to. Such compositional codes for group transformations of objects are made possible by the fact that all objects share a common latent space, instead of occupying separate ones, suggesting that there are benefits to distributed coding schemes.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Object-centric representations have been argued to improve the sample efficiency and generalization ability of vision and dynamics models in compositional domains <cite class="ltx_cite ltx_citemacro_citep">(Elsayed etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib10" title="">2022</a>; Kipf etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib26" title="">2019</a>; Wiedemer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib48" title="">2023</a>; Wu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib49" title="">2022</a>; Locatello etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib34" title="">2020b</a>)</cite>. Object-centric representations, given an appropriate model architecture, can also be learned in an unsupervised manner <cite class="ltx_cite ltx_citemacro_citep">(Kipf etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib26" title="">2019</a>; Locatello etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib34" title="">2020b</a>; Brady etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib3" title="">2023</a>)</cite> and on real-world datasets <cite class="ltx_cite ltx_citemacro_citep">(Seitzer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib44" title="">2022</a>)</cite>. Previous studies have highlighted the importance of architectural features, like object-slots <cite class="ltx_cite ltx_citemacro_citep">(Greff etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib15" title="">2020</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib14" title="">2019</a>; Dittadi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib8" title="">2021</a>)</cite>, as well as data properties, like having access to temporal information <cite class="ltx_cite ltx_citemacro_citep">(Zadaianchuk etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib52" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">There is a considerable overlap in the literature on object-centric and disentangled representations. A disentangled representation is one <span class="ltx_ERROR undefined" id="S2.p2.1.1">\say</span>which separates the factors of variation, explicitly representing the important attributes of the data <cite class="ltx_cite ltx_citemacro_citep">(Bengio etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib2" title="">2013</a>; Locatello etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib33" title="">2020a</a>; Higgins etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib19" title="">2016</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib21" title="">2018</a>)</cite>. In a disentangled representation, a change in a single ground truth factor should lead to a change in a single factor in the learned representation <cite class="ltx_cite ltx_citemacro_citep">(Locatello etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib32" title="">2019</a>; Ridgeway &amp; Mozer, <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib40" title="">2018</a>; Kim &amp; Mnih, <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib23" title="">2018</a>)</cite>. Information bottlenecks methods like <math alttext="\beta" class="ltx_Math" display="inline" id="S2.p2.1.m1.1"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">Î²</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">ğ›½</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="S2.p2.1.m1.1d">italic_Î²</annotation></semantics></math>-VAEs have also been shown to be able to disentangle object features <cite class="ltx_cite ltx_citemacro_citep">(Burgess etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib4" title="">2018</a>; Higgins etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib20" title="">2017</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">In recent work, <cite class="ltx_cite ltx_citemacro_citet">Brady etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib3" title="">2023</a>)</cite> put forward a measure of representational object-centricness that measures <span class="ltx_ERROR undefined" id="S2.p3.1.1">\say</span>if there exists an invertible function between each ground-truth slot and exactly one inferred latent slot. We work with a related metric suitable for generic model classes (e.g. without image decoders) that instead measures the degree to which changes to individual objects can be predicted from changes in a modelâ€™s latent representations.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Models</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">We focus on models that learn representations of scenes in an unsupervised manner, e.g. without information about object identities provided as labels or masks. Unsupervised training regimes, such as auto-encoding <cite class="ltx_cite ltx_citemacro_citep">(Kingma, <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib24" title="">2013</a>)</cite>, denoising <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib18" title="">2022</a>)</cite> and contrastive objectives <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib6" title="">2020</a>)</cite> have shown promise as representation learning tools in many domains, ranging from image and language understanding <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib39" title="">2021</a>)</cite> to reinforcement learning <cite class="ltx_cite ltx_citemacro_citep">(Schwarzer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib43" title="">2020</a>; Gelada etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib12" title="">2019</a>; Saanum etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib41" title="">2024</a>)</cite>. In this paper we investigate two classes of such training objectives: <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.1">i</em>) Reconstruction-based or auto-encoding objectives, where the goal is to encode and reconstruct images of scenes of objects. And <em class="ltx_emph ltx_font_italic" id="S3.SS1.p1.1.2">ii</em>), contrastive objectives, where the goal is to maximize embedding similarities of positive pairs and minimize similarities of negative pairs. Accordingly, the models rely on an image encoder, a Convolutional Neural Net (CNN) in our case, to map images of objects to latent representations. For auto-encoding models we additionally equip the model with a CNN decoder that maps the latent representation back to pixel-space.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<table class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table" id="A3.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle z_{t}=e_{\theta}(x_{t})" class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><msub id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml">z</mi><mi id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.3.2.cmml">e</mi><mi id="S3.E1.m1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"></eq><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2">ğ‘§</ci><ci id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><apply id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E1.m1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle z_{t}=e_{\theta}(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_e start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\tilde{x}_{t}=g_{\theta}(z_{t})" class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><msub id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><mover accent="true" id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.3.2.2" xref="S3.E2.m1.1.1.3.2.2.cmml">x</mi><mo id="S3.E2.m1.1.1.3.2.1" xref="S3.E2.m1.1.1.3.2.1.cmml">~</mo></mover><mi id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.3" xref="S3.E2.m1.1.1.1.3.cmml"><mi id="S3.E2.m1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.3.2.cmml">g</mi><mi id="S3.E2.m1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E2.m1.1.1.1.2" xref="S3.E2.m1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><eq id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2"></eq><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.3">subscript</csymbol><apply id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2"><ci id="S3.E2.m1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.3.2.1">~</ci><ci id="S3.E2.m1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2">ğ‘¥</ci></apply><ci id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><times id="S3.E2.m1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.3.2">ğ‘”</ci><ci id="S3.E2.m1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\tilde{x}_{t}=g_{\theta}(z_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.8">Here <math alttext="z_{t}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">ğ‘§</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">z_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the modelâ€™s representation, and <math alttext="e_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><msub id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2" xref="S3.SS1.p3.2.m2.1.1.2.cmml">e</mi><mi id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2">ğ‘’</ci><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">e_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">italic_e start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="g_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">g</mi><mi id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ğ‘”</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">g_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_g start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> are the CNN encoder and decoder. <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><msub id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><mi id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2.cmml">x</mi><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\tilde{x}_{t}" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><msub id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mover accent="true" id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2.2" xref="S3.SS1.p3.5.m5.1.1.2.2.cmml">x</mi><mo id="S3.SS1.p3.5.m5.1.1.2.1" xref="S3.SS1.p3.5.m5.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">subscript</csymbol><apply id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2"><ci id="S3.SS1.p3.5.m5.1.1.2.1.cmml" xref="S3.SS1.p3.5.m5.1.1.2.1">~</ci><ci id="S3.SS1.p3.5.m5.1.1.2.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2.2">ğ‘¥</ci></apply><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\tilde{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> are the image and reconstruction, respectively. We subscript image and representation variables with the time-point <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p3.6.m6.1"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.6.m6.1d">italic_t</annotation></semantics></math> since our data are dynamic. Having access to this temporal information about the data, we also consider models that use future-state prediction as an auxiliary objective for representation learning. Observing how objects interact dynamically can provide the models with useful cues about object identities, and could facilitate learning systematic representations of objects <cite class="ltx_cite ltx_citemacro_citep">(Zadaianchuk etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib52" title="">2024</a>)</cite>. When modelling the dynamics of the object data, we equip the model with a latent dynamics module that predicts the modelâ€™s representation at the next time point <math alttext="t+1" class="ltx_Math" display="inline" id="S3.SS1.p3.7.m7.1"><semantics id="S3.SS1.p3.7.m7.1a"><mrow id="S3.SS1.p3.7.m7.1.1" xref="S3.SS1.p3.7.m7.1.1.cmml"><mi id="S3.SS1.p3.7.m7.1.1.2" xref="S3.SS1.p3.7.m7.1.1.2.cmml">t</mi><mo id="S3.SS1.p3.7.m7.1.1.1" xref="S3.SS1.p3.7.m7.1.1.1.cmml">+</mo><mn id="S3.SS1.p3.7.m7.1.1.3" xref="S3.SS1.p3.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.7.m7.1b"><apply id="S3.SS1.p3.7.m7.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1"><plus id="S3.SS1.p3.7.m7.1.1.1.cmml" xref="S3.SS1.p3.7.m7.1.1.1"></plus><ci id="S3.SS1.p3.7.m7.1.1.2.cmml" xref="S3.SS1.p3.7.m7.1.1.2">ğ‘¡</ci><cn id="S3.SS1.p3.7.m7.1.1.3.cmml" type="integer" xref="S3.SS1.p3.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.7.m7.1c">t+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.7.m7.1d">italic_t + 1</annotation></semantics></math>, given the current representation, and an action <math alttext="a_{t}" class="ltx_Math" display="inline" id="S3.SS1.p3.8.m8.1"><semantics id="S3.SS1.p3.8.m8.1a"><msub id="S3.SS1.p3.8.m8.1.1" xref="S3.SS1.p3.8.m8.1.1.cmml"><mi id="S3.SS1.p3.8.m8.1.1.2" xref="S3.SS1.p3.8.m8.1.1.2.cmml">a</mi><mi id="S3.SS1.p3.8.m8.1.1.3" xref="S3.SS1.p3.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.8.m8.1b"><apply id="S3.SS1.p3.8.m8.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.8.m8.1.1.1.cmml" xref="S3.SS1.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p3.8.m8.1.1.2.cmml" xref="S3.SS1.p3.8.m8.1.1.2">ğ‘</ci><ci id="S3.SS1.p3.8.m8.1.1.3.cmml" xref="S3.SS1.p3.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.8.m8.1c">a_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.8.m8.1d">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, if the dynamics data is accompanied by actions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\tilde{z}_{t+1}=d_{\theta}(z_{t},a_{t})" class="ltx_Math" display="block" id="S3.E3.m1.2"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml"><msub id="S3.E3.m1.2.2.4" xref="S3.E3.m1.2.2.4.cmml"><mover accent="true" id="S3.E3.m1.2.2.4.2" xref="S3.E3.m1.2.2.4.2.cmml"><mi id="S3.E3.m1.2.2.4.2.2" xref="S3.E3.m1.2.2.4.2.2.cmml">z</mi><mo id="S3.E3.m1.2.2.4.2.1" xref="S3.E3.m1.2.2.4.2.1.cmml">~</mo></mover><mrow id="S3.E3.m1.2.2.4.3" xref="S3.E3.m1.2.2.4.3.cmml"><mi id="S3.E3.m1.2.2.4.3.2" xref="S3.E3.m1.2.2.4.3.2.cmml">t</mi><mo id="S3.E3.m1.2.2.4.3.1" xref="S3.E3.m1.2.2.4.3.1.cmml">+</mo><mn id="S3.E3.m1.2.2.4.3.3" xref="S3.E3.m1.2.2.4.3.3.cmml">1</mn></mrow></msub><mo id="S3.E3.m1.2.2.3" xref="S3.E3.m1.2.2.3.cmml">=</mo><mrow id="S3.E3.m1.2.2.2" xref="S3.E3.m1.2.2.2.cmml"><msub id="S3.E3.m1.2.2.2.4" xref="S3.E3.m1.2.2.2.4.cmml"><mi id="S3.E3.m1.2.2.2.4.2" xref="S3.E3.m1.2.2.2.4.2.cmml">d</mi><mi id="S3.E3.m1.2.2.2.4.3" xref="S3.E3.m1.2.2.2.4.3.cmml">Î¸</mi></msub><mo id="S3.E3.m1.2.2.2.3" xref="S3.E3.m1.2.2.2.3.cmml">â¢</mo><mrow id="S3.E3.m1.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.3.cmml"><mo id="S3.E3.m1.2.2.2.2.2.3" stretchy="false" xref="S3.E3.m1.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E3.m1.2.2.2.2.2.4" xref="S3.E3.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.E3.m1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.2" xref="S3.E3.m1.2.2.2.2.2.2.2.cmml">a</mi><mi id="S3.E3.m1.2.2.2.2.2.2.3" xref="S3.E3.m1.2.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E3.m1.2.2.2.2.2.5" stretchy="false" xref="S3.E3.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2"><eq id="S3.E3.m1.2.2.3.cmml" xref="S3.E3.m1.2.2.3"></eq><apply id="S3.E3.m1.2.2.4.cmml" xref="S3.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.4.1.cmml" xref="S3.E3.m1.2.2.4">subscript</csymbol><apply id="S3.E3.m1.2.2.4.2.cmml" xref="S3.E3.m1.2.2.4.2"><ci id="S3.E3.m1.2.2.4.2.1.cmml" xref="S3.E3.m1.2.2.4.2.1">~</ci><ci id="S3.E3.m1.2.2.4.2.2.cmml" xref="S3.E3.m1.2.2.4.2.2">ğ‘§</ci></apply><apply id="S3.E3.m1.2.2.4.3.cmml" xref="S3.E3.m1.2.2.4.3"><plus id="S3.E3.m1.2.2.4.3.1.cmml" xref="S3.E3.m1.2.2.4.3.1"></plus><ci id="S3.E3.m1.2.2.4.3.2.cmml" xref="S3.E3.m1.2.2.4.3.2">ğ‘¡</ci><cn id="S3.E3.m1.2.2.4.3.3.cmml" type="integer" xref="S3.E3.m1.2.2.4.3.3">1</cn></apply></apply><apply id="S3.E3.m1.2.2.2.cmml" xref="S3.E3.m1.2.2.2"><times id="S3.E3.m1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.3"></times><apply id="S3.E3.m1.2.2.2.4.cmml" xref="S3.E3.m1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.4.1.cmml" xref="S3.E3.m1.2.2.2.4">subscript</csymbol><ci id="S3.E3.m1.2.2.2.4.2.cmml" xref="S3.E3.m1.2.2.2.4.2">ğ‘‘</ci><ci id="S3.E3.m1.2.2.2.4.3.cmml" xref="S3.E3.m1.2.2.2.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E3.m1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E3.m1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.2">ğ‘</ci><ci id="S3.E3.m1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\tilde{z}_{t+1}=d_{\theta}(z_{t},a_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.2d">over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.4">Here <math alttext="d_{\theta}" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><msub id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><mi id="S3.SS1.p5.1.m1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.2.cmml">d</mi><mi id="S3.SS1.p5.1.m1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2">ğ‘‘</ci><ci id="S3.SS1.p5.1.m1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">d_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">italic_d start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT</annotation></semantics></math> denotes the dynamics module, which is a Multi-Layer Perceptron (MLP) in the case that the dynamics are Markovian, e.g. fully predictable from the information provided in the current observation <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.SS1.p5.2.m2.1"><semantics id="S3.SS1.p5.2.m2.1a"><msub id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml"><mi id="S3.SS1.p5.2.m2.1.1.2" xref="S3.SS1.p5.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS1.p5.2.m2.1.1.3" xref="S3.SS1.p5.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><apply id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.2.m2.1.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p5.2.m2.1.1.2.cmml" xref="S3.SS1.p5.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p5.2.m2.1.1.3.cmml" xref="S3.SS1.p5.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> (and potentially action <math alttext="a_{t}" class="ltx_Math" display="inline" id="S3.SS1.p5.3.m3.1"><semantics id="S3.SS1.p5.3.m3.1a"><msub id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><mi id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml">a</mi><mi id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2">ğ‘</ci><ci id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">a_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.3.m3.1d">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>). In non-Markovian settings we use a causal Transformer that integrates information across representations of past observations <math alttext="(z_{t-n},...,z_{t-1},z_{t})" class="ltx_Math" display="inline" id="S3.SS1.p5.4.m4.4"><semantics id="S3.SS1.p5.4.m4.4a"><mrow id="S3.SS1.p5.4.m4.4.4.3" xref="S3.SS1.p5.4.m4.4.4.4.cmml"><mo id="S3.SS1.p5.4.m4.4.4.3.4" stretchy="false" xref="S3.SS1.p5.4.m4.4.4.4.cmml">(</mo><msub id="S3.SS1.p5.4.m4.2.2.1.1" xref="S3.SS1.p5.4.m4.2.2.1.1.cmml"><mi id="S3.SS1.p5.4.m4.2.2.1.1.2" xref="S3.SS1.p5.4.m4.2.2.1.1.2.cmml">z</mi><mrow id="S3.SS1.p5.4.m4.2.2.1.1.3" xref="S3.SS1.p5.4.m4.2.2.1.1.3.cmml"><mi id="S3.SS1.p5.4.m4.2.2.1.1.3.2" xref="S3.SS1.p5.4.m4.2.2.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p5.4.m4.2.2.1.1.3.1" xref="S3.SS1.p5.4.m4.2.2.1.1.3.1.cmml">âˆ’</mo><mi id="S3.SS1.p5.4.m4.2.2.1.1.3.3" xref="S3.SS1.p5.4.m4.2.2.1.1.3.3.cmml">n</mi></mrow></msub><mo id="S3.SS1.p5.4.m4.4.4.3.5" xref="S3.SS1.p5.4.m4.4.4.4.cmml">,</mo><mi id="S3.SS1.p5.4.m4.1.1" mathvariant="normal" xref="S3.SS1.p5.4.m4.1.1.cmml">â€¦</mi><mo id="S3.SS1.p5.4.m4.4.4.3.6" xref="S3.SS1.p5.4.m4.4.4.4.cmml">,</mo><msub id="S3.SS1.p5.4.m4.3.3.2.2" xref="S3.SS1.p5.4.m4.3.3.2.2.cmml"><mi id="S3.SS1.p5.4.m4.3.3.2.2.2" xref="S3.SS1.p5.4.m4.3.3.2.2.2.cmml">z</mi><mrow id="S3.SS1.p5.4.m4.3.3.2.2.3" xref="S3.SS1.p5.4.m4.3.3.2.2.3.cmml"><mi id="S3.SS1.p5.4.m4.3.3.2.2.3.2" xref="S3.SS1.p5.4.m4.3.3.2.2.3.2.cmml">t</mi><mo id="S3.SS1.p5.4.m4.3.3.2.2.3.1" xref="S3.SS1.p5.4.m4.3.3.2.2.3.1.cmml">âˆ’</mo><mn id="S3.SS1.p5.4.m4.3.3.2.2.3.3" xref="S3.SS1.p5.4.m4.3.3.2.2.3.3.cmml">1</mn></mrow></msub><mo id="S3.SS1.p5.4.m4.4.4.3.7" xref="S3.SS1.p5.4.m4.4.4.4.cmml">,</mo><msub id="S3.SS1.p5.4.m4.4.4.3.3" xref="S3.SS1.p5.4.m4.4.4.3.3.cmml"><mi id="S3.SS1.p5.4.m4.4.4.3.3.2" xref="S3.SS1.p5.4.m4.4.4.3.3.2.cmml">z</mi><mi id="S3.SS1.p5.4.m4.4.4.3.3.3" xref="S3.SS1.p5.4.m4.4.4.3.3.3.cmml">t</mi></msub><mo id="S3.SS1.p5.4.m4.4.4.3.8" stretchy="false" xref="S3.SS1.p5.4.m4.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m4.4b"><vector id="S3.SS1.p5.4.m4.4.4.4.cmml" xref="S3.SS1.p5.4.m4.4.4.3"><apply id="S3.SS1.p5.4.m4.2.2.1.1.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m4.2.2.1.1.1.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p5.4.m4.2.2.1.1.2.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1.2">ğ‘§</ci><apply id="S3.SS1.p5.4.m4.2.2.1.1.3.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1.3"><minus id="S3.SS1.p5.4.m4.2.2.1.1.3.1.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1.3.1"></minus><ci id="S3.SS1.p5.4.m4.2.2.1.1.3.2.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1.3.2">ğ‘¡</ci><ci id="S3.SS1.p5.4.m4.2.2.1.1.3.3.cmml" xref="S3.SS1.p5.4.m4.2.2.1.1.3.3">ğ‘›</ci></apply></apply><ci id="S3.SS1.p5.4.m4.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1">â€¦</ci><apply id="S3.SS1.p5.4.m4.3.3.2.2.cmml" xref="S3.SS1.p5.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m4.3.3.2.2.1.cmml" xref="S3.SS1.p5.4.m4.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p5.4.m4.3.3.2.2.2.cmml" xref="S3.SS1.p5.4.m4.3.3.2.2.2">ğ‘§</ci><apply id="S3.SS1.p5.4.m4.3.3.2.2.3.cmml" xref="S3.SS1.p5.4.m4.3.3.2.2.3"><minus id="S3.SS1.p5.4.m4.3.3.2.2.3.1.cmml" xref="S3.SS1.p5.4.m4.3.3.2.2.3.1"></minus><ci id="S3.SS1.p5.4.m4.3.3.2.2.3.2.cmml" xref="S3.SS1.p5.4.m4.3.3.2.2.3.2">ğ‘¡</ci><cn id="S3.SS1.p5.4.m4.3.3.2.2.3.3.cmml" type="integer" xref="S3.SS1.p5.4.m4.3.3.2.2.3.3">1</cn></apply></apply><apply id="S3.SS1.p5.4.m4.4.4.3.3.cmml" xref="S3.SS1.p5.4.m4.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m4.4.4.3.3.1.cmml" xref="S3.SS1.p5.4.m4.4.4.3.3">subscript</csymbol><ci id="S3.SS1.p5.4.m4.4.4.3.3.2.cmml" xref="S3.SS1.p5.4.m4.4.4.3.3.2">ğ‘§</ci><ci id="S3.SS1.p5.4.m4.4.4.3.3.3.cmml" xref="S3.SS1.p5.4.m4.4.4.3.3.3">ğ‘¡</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m4.4c">(z_{t-n},...,z_{t-1},z_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.4.m4.4d">( italic_z start_POSTSUBSCRIPT italic_t - italic_n end_POSTSUBSCRIPT , â€¦ , italic_z start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> to predict the dynamics. See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A2" title="Appendix B Architecture and hyperparameters â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">B</span></a> for details on the model architecture and hyperparameters.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1">For the auto-encoding models, we train the encoder and decoder to reconstruct the <em class="ltx_emph ltx_font_italic" id="S3.SS1.p6.1.1">current</em> frame from the current representation in the static setting, and the <em class="ltx_emph ltx_font_italic" id="S3.SS1.p6.1.2">next</em> frame from the predicted <em class="ltx_emph ltx_font_italic" id="S3.SS1.p6.1.3">next</em> latent representation in the dynamic setting. Here, we additionally train the dynamics model to minimize the distance between the predicted and actual representation of the next frame. This leaves us with the following loss functions:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p7">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A3.EGx2">
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{{AE-static}}}=||x_{t}-g_{\theta}(z_{t})||^{2}_%
{2}" class="ltx_Math" display="inline" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml">â„’</mi><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3a.cmml">AE-static</mtext></msub><mo id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">=</mo><msubsup id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.2.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E4.m1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E4.m1.1.1.1.3" xref="S3.E4.m1.1.1.1.3.cmml">2</mn><mn id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml">2</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"></eq><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2">â„’</ci><ci id="S3.E4.m1.1.1.3.3a.cmml" xref="S3.E4.m1.1.1.3.3"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.1.1.3.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.3.3">AE-static</mtext></ci></apply><apply id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1">subscript</csymbol><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1">superscript</csymbol><apply id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1"><minus id="S3.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.2">ğ‘”</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply><cn id="S3.E4.m1.1.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.1.1.1.1.3">2</cn></apply><cn id="S3.E4.m1.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\displaystyle\mathcal{L}_{\text{{AE-static}}}=||x_{t}-g_{\theta}(z_{t})||^{2}_%
{2}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">caligraphic_L start_POSTSUBSCRIPT AE-static end_POSTSUBSCRIPT = | | italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_g start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{{AE-dynamic}}}=||x_{t+1}-g_{\theta}(\tilde{z}_%
{t+1})||^{2}_{2}+||z_{t+1}-d_{\theta}(z_{t},a_{t})||^{2}_{2}" class="ltx_Math" display="inline" id="S3.E5.m2.2"><semantics id="S3.E5.m2.2a"><mrow id="S3.E5.m2.2.2" xref="S3.E5.m2.2.2.cmml"><msub id="S3.E5.m2.2.2.4" xref="S3.E5.m2.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m2.2.2.4.2" xref="S3.E5.m2.2.2.4.2.cmml">â„’</mi><mtext class="ltx_mathvariant_bold" id="S3.E5.m2.2.2.4.3" xref="S3.E5.m2.2.2.4.3a.cmml">AE-dynamic</mtext></msub><mo id="S3.E5.m2.2.2.3" xref="S3.E5.m2.2.2.3.cmml">=</mo><mrow id="S3.E5.m2.2.2.2" xref="S3.E5.m2.2.2.2.cmml"><msubsup id="S3.E5.m2.1.1.1.1" xref="S3.E5.m2.1.1.1.1.cmml"><mrow id="S3.E5.m2.1.1.1.1.1.1.1" xref="S3.E5.m2.1.1.1.1.1.1.2.cmml"><mo id="S3.E5.m2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m2.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E5.m2.1.1.1.1.1.1.1.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m2.1.1.1.1.1.1.1.1.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m2.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mrow id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.1.cmml">+</mo><mn id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E5.m2.1.1.1.1.1.1.1.1.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.2.cmml">g</mi><mi id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">z</mi><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mrow id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">+</mo><mn id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m2.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E5.m2.1.1.1.1.3" xref="S3.E5.m2.1.1.1.1.3.cmml">2</mn><mn id="S3.E5.m2.1.1.1.1.1.3" xref="S3.E5.m2.1.1.1.1.1.3.cmml">2</mn></msubsup><mo id="S3.E5.m2.2.2.2.3" xref="S3.E5.m2.2.2.2.3.cmml">+</mo><msubsup id="S3.E5.m2.2.2.2.2" xref="S3.E5.m2.2.2.2.2.cmml"><mrow id="S3.E5.m2.2.2.2.2.1.1.1" xref="S3.E5.m2.2.2.2.2.1.1.2.cmml"><mo id="S3.E5.m2.2.2.2.2.1.1.1.2" stretchy="false" xref="S3.E5.m2.2.2.2.2.1.1.2.1.cmml">â€–</mo><mrow id="S3.E5.m2.2.2.2.2.1.1.1.1" xref="S3.E5.m2.2.2.2.2.1.1.1.1.cmml"><msub id="S3.E5.m2.2.2.2.2.1.1.1.1.4" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.cmml"><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.4.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.2.cmml">z</mi><mrow id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.cmml"><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.2.cmml">t</mi><mo id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.1" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.1.cmml">+</mo><mn id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.3.cmml">1</mn></mrow></msub><mo id="S3.E5.m2.2.2.2.2.1.1.1.1.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S3.E5.m2.2.2.2.2.1.1.1.1.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.cmml"><msub id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.cmml"><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.2.cmml">d</mi><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.3.cmml">Î¸</mi></msub><mo id="S3.E5.m2.2.2.2.2.1.1.1.1.2.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.3.cmml">â¢</mo><mrow id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.3.cmml"><mo id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.4" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.2" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.2.cmml">a</mi><mi id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.3" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m2.2.2.2.2.1.1.1.3" stretchy="false" xref="S3.E5.m2.2.2.2.2.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E5.m2.2.2.2.2.3" xref="S3.E5.m2.2.2.2.2.3.cmml">2</mn><mn id="S3.E5.m2.2.2.2.2.1.3" xref="S3.E5.m2.2.2.2.2.1.3.cmml">2</mn></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m2.2b"><apply id="S3.E5.m2.2.2.cmml" xref="S3.E5.m2.2.2"><eq id="S3.E5.m2.2.2.3.cmml" xref="S3.E5.m2.2.2.3"></eq><apply id="S3.E5.m2.2.2.4.cmml" xref="S3.E5.m2.2.2.4"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.4.1.cmml" xref="S3.E5.m2.2.2.4">subscript</csymbol><ci id="S3.E5.m2.2.2.4.2.cmml" xref="S3.E5.m2.2.2.4.2">â„’</ci><ci id="S3.E5.m2.2.2.4.3a.cmml" xref="S3.E5.m2.2.2.4.3"><mtext class="ltx_mathvariant_bold" id="S3.E5.m2.2.2.4.3.cmml" mathsize="70%" xref="S3.E5.m2.2.2.4.3">AE-dynamic</mtext></ci></apply><apply id="S3.E5.m2.2.2.2.cmml" xref="S3.E5.m2.2.2.2"><plus id="S3.E5.m2.2.2.2.3.cmml" xref="S3.E5.m2.2.2.2.3"></plus><apply id="S3.E5.m2.1.1.1.1.cmml" xref="S3.E5.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m2.1.1.1.1.2.cmml" xref="S3.E5.m2.1.1.1.1">subscript</csymbol><apply id="S3.E5.m2.1.1.1.1.1.cmml" xref="S3.E5.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m2.1.1.1.1.1.2.cmml" xref="S3.E5.m2.1.1.1.1">superscript</csymbol><apply id="S3.E5.m2.1.1.1.1.1.1.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m2.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1"><minus id="S3.E5.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3"><plus id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.1"></plus><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.2">ğ‘¡</ci><cn id="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S3.E5.m2.1.1.1.1.1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1"><times id="S3.E5.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.2">ğ‘”</ci><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2"><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘§</ci></apply><apply id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3"><plus id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></plus><ci id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘¡</ci><cn id="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S3.E5.m2.1.1.1.1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply></apply><cn id="S3.E5.m2.1.1.1.1.1.3.cmml" type="integer" xref="S3.E5.m2.1.1.1.1.1.3">2</cn></apply><cn id="S3.E5.m2.1.1.1.1.3.cmml" type="integer" xref="S3.E5.m2.1.1.1.1.3">2</cn></apply><apply id="S3.E5.m2.2.2.2.2.cmml" xref="S3.E5.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.2.2.2.cmml" xref="S3.E5.m2.2.2.2.2">subscript</csymbol><apply id="S3.E5.m2.2.2.2.2.1.cmml" xref="S3.E5.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.2.2.1.2.cmml" xref="S3.E5.m2.2.2.2.2">superscript</csymbol><apply id="S3.E5.m2.2.2.2.2.1.1.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1"><csymbol cd="latexml" id="S3.E5.m2.2.2.2.2.1.1.2.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.2">norm</csymbol><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1"><minus id="S3.E5.m2.2.2.2.2.1.1.1.1.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.3"></minus><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.4.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.2.2.1.1.1.1.4.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4">subscript</csymbol><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.4.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.2">ğ‘§</ci><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3"><plus id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.1"></plus><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.2">ğ‘¡</ci><cn id="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.3.cmml" type="integer" xref="S3.E5.m2.2.2.2.2.1.1.1.1.4.3.3">1</cn></apply></apply><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2"><times id="S3.E5.m2.2.2.2.2.1.1.1.1.2.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.3"></times><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.2">ğ‘‘</ci><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2"><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.2">ğ‘</ci><ci id="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E5.m2.2.2.2.2.1.1.1.1.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></apply><cn id="S3.E5.m2.2.2.2.2.1.3.cmml" type="integer" xref="S3.E5.m2.2.2.2.2.1.3">2</cn></apply><cn id="S3.E5.m2.2.2.2.2.3.cmml" type="integer" xref="S3.E5.m2.2.2.2.2.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m2.2c">\displaystyle\mathcal{L}_{\text{{AE-dynamic}}}=||x_{t+1}-g_{\theta}(\tilde{z}_%
{t+1})||^{2}_{2}+||z_{t+1}-d_{\theta}(z_{t},a_{t})||^{2}_{2}</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m2.2d">caligraphic_L start_POSTSUBSCRIPT AE-dynamic end_POSTSUBSCRIPT = | | italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT - italic_g start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + | | italic_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">We refer to these models as the <em class="ltx_emph ltx_font_italic" id="S3.SS1.p8.1.1">auto-encoder</em> and <em class="ltx_emph ltx_font_italic" id="S3.SS1.p8.1.2">sequential auto-encoder</em>, respectively.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p9">
<p class="ltx_p" id="S3.SS1.p9.7">For the contrastive models, we consider both a static and dynamic training scheme as well. In the static case, we present the model with a frame <math alttext="x_{t}" class="ltx_Math" display="inline" id="S3.SS1.p9.1.m1.1"><semantics id="S3.SS1.p9.1.m1.1a"><msub id="S3.SS1.p9.1.m1.1.1" xref="S3.SS1.p9.1.m1.1.1.cmml"><mi id="S3.SS1.p9.1.m1.1.1.2" xref="S3.SS1.p9.1.m1.1.1.2.cmml">x</mi><mi id="S3.SS1.p9.1.m1.1.1.3" xref="S3.SS1.p9.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.1.m1.1b"><apply id="S3.SS1.p9.1.m1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.1.m1.1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p9.1.m1.1.1.2.cmml" xref="S3.SS1.p9.1.m1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p9.1.m1.1.1.3.cmml" xref="S3.SS1.p9.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.1.m1.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> as well as a randomly augmented view of the same frame <math alttext="h(x_{t})" class="ltx_Math" display="inline" id="S3.SS1.p9.2.m2.1"><semantics id="S3.SS1.p9.2.m2.1a"><mrow id="S3.SS1.p9.2.m2.1.1" xref="S3.SS1.p9.2.m2.1.1.cmml"><mi id="S3.SS1.p9.2.m2.1.1.3" xref="S3.SS1.p9.2.m2.1.1.3.cmml">h</mi><mo id="S3.SS1.p9.2.m2.1.1.2" xref="S3.SS1.p9.2.m2.1.1.2.cmml">â¢</mo><mrow id="S3.SS1.p9.2.m2.1.1.1.1" xref="S3.SS1.p9.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS1.p9.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS1.p9.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p9.2.m2.1.1.1.1.1" xref="S3.SS1.p9.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.p9.2.m2.1.1.1.1.1.2" xref="S3.SS1.p9.2.m2.1.1.1.1.1.2.cmml">x</mi><mi id="S3.SS1.p9.2.m2.1.1.1.1.1.3" xref="S3.SS1.p9.2.m2.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS1.p9.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS1.p9.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.2.m2.1b"><apply id="S3.SS1.p9.2.m2.1.1.cmml" xref="S3.SS1.p9.2.m2.1.1"><times id="S3.SS1.p9.2.m2.1.1.2.cmml" xref="S3.SS1.p9.2.m2.1.1.2"></times><ci id="S3.SS1.p9.2.m2.1.1.3.cmml" xref="S3.SS1.p9.2.m2.1.1.3">â„</ci><apply id="S3.SS1.p9.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p9.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p9.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p9.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.p9.2.m2.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p9.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.p9.2.m2.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.2.m2.1c">h(x_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.2.m2.1d">italic_h ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Laskin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib31" title="">2020</a>; Grill etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib17" title="">2020</a>)</cite>. The model is then trained to minimize the embedding distance between the original and augmented view of the image, while maximizing the embedding distance between the original image and its representations of augmented views of other frames <math alttext="x^{-}" class="ltx_Math" display="inline" id="S3.SS1.p9.3.m3.1"><semantics id="S3.SS1.p9.3.m3.1a"><msup id="S3.SS1.p9.3.m3.1.1" xref="S3.SS1.p9.3.m3.1.1.cmml"><mi id="S3.SS1.p9.3.m3.1.1.2" xref="S3.SS1.p9.3.m3.1.1.2.cmml">x</mi><mo id="S3.SS1.p9.3.m3.1.1.3" xref="S3.SS1.p9.3.m3.1.1.3.cmml">âˆ’</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.3.m3.1b"><apply id="S3.SS1.p9.3.m3.1.1.cmml" xref="S3.SS1.p9.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.3.m3.1.1.1.cmml" xref="S3.SS1.p9.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p9.3.m3.1.1.2.cmml" xref="S3.SS1.p9.3.m3.1.1.2">ğ‘¥</ci><minus id="S3.SS1.p9.3.m3.1.1.3.cmml" xref="S3.SS1.p9.3.m3.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.3.m3.1c">x^{-}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.3.m3.1d">italic_x start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT</annotation></semantics></math> in the batch, up to a margin <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS1.p9.4.m4.1"><semantics id="S3.SS1.p9.4.m4.1a"><mi id="S3.SS1.p9.4.m4.1.1" xref="S3.SS1.p9.4.m4.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.4.m4.1b"><ci id="S3.SS1.p9.4.m4.1.1.cmml" xref="S3.SS1.p9.4.m4.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.4.m4.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.4.m4.1d">italic_Î»</annotation></semantics></math>. In the dynamic setting we train the contrastive model as follows: Given an initial latent representation (and potentially action), we train the encoder and dynamics model to produce a prediction that is as close as possible to the encoded representation of the next frame <math alttext="z_{t+1}" class="ltx_Math" display="inline" id="S3.SS1.p9.5.m5.1"><semantics id="S3.SS1.p9.5.m5.1a"><msub id="S3.SS1.p9.5.m5.1.1" xref="S3.SS1.p9.5.m5.1.1.cmml"><mi id="S3.SS1.p9.5.m5.1.1.2" xref="S3.SS1.p9.5.m5.1.1.2.cmml">z</mi><mrow id="S3.SS1.p9.5.m5.1.1.3" xref="S3.SS1.p9.5.m5.1.1.3.cmml"><mi id="S3.SS1.p9.5.m5.1.1.3.2" xref="S3.SS1.p9.5.m5.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p9.5.m5.1.1.3.1" xref="S3.SS1.p9.5.m5.1.1.3.1.cmml">+</mo><mn id="S3.SS1.p9.5.m5.1.1.3.3" xref="S3.SS1.p9.5.m5.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.5.m5.1b"><apply id="S3.SS1.p9.5.m5.1.1.cmml" xref="S3.SS1.p9.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.5.m5.1.1.1.cmml" xref="S3.SS1.p9.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p9.5.m5.1.1.2.cmml" xref="S3.SS1.p9.5.m5.1.1.2">ğ‘§</ci><apply id="S3.SS1.p9.5.m5.1.1.3.cmml" xref="S3.SS1.p9.5.m5.1.1.3"><plus id="S3.SS1.p9.5.m5.1.1.3.1.cmml" xref="S3.SS1.p9.5.m5.1.1.3.1"></plus><ci id="S3.SS1.p9.5.m5.1.1.3.2.cmml" xref="S3.SS1.p9.5.m5.1.1.3.2">ğ‘¡</ci><cn id="S3.SS1.p9.5.m5.1.1.3.3.cmml" type="integer" xref="S3.SS1.p9.5.m5.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.5.m5.1c">z_{t+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.5.m5.1d">italic_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT</annotation></semantics></math>, and that is maximally far away from encoded representations of other frames <math alttext="z^{-}" class="ltx_Math" display="inline" id="S3.SS1.p9.6.m6.1"><semantics id="S3.SS1.p9.6.m6.1a"><msup id="S3.SS1.p9.6.m6.1.1" xref="S3.SS1.p9.6.m6.1.1.cmml"><mi id="S3.SS1.p9.6.m6.1.1.2" xref="S3.SS1.p9.6.m6.1.1.2.cmml">z</mi><mo id="S3.SS1.p9.6.m6.1.1.3" xref="S3.SS1.p9.6.m6.1.1.3.cmml">âˆ’</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.6.m6.1b"><apply id="S3.SS1.p9.6.m6.1.1.cmml" xref="S3.SS1.p9.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.6.m6.1.1.1.cmml" xref="S3.SS1.p9.6.m6.1.1">superscript</csymbol><ci id="S3.SS1.p9.6.m6.1.1.2.cmml" xref="S3.SS1.p9.6.m6.1.1.2">ğ‘§</ci><minus id="S3.SS1.p9.6.m6.1.1.3.cmml" xref="S3.SS1.p9.6.m6.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.6.m6.1c">z^{-}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.6.m6.1d">italic_z start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT</annotation></semantics></math>, up to a margin <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS1.p9.7.m7.1"><semantics id="S3.SS1.p9.7.m7.1a"><mi id="S3.SS1.p9.7.m7.1.1" xref="S3.SS1.p9.7.m7.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.7.m7.1b"><ci id="S3.SS1.p9.7.m7.1.1.cmml" xref="S3.SS1.p9.7.m7.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.7.m7.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p9.7.m7.1d">italic_Î»</annotation></semantics></math>. The loss functions take the following form:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p10">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A3.EGx3">
<tbody id="S3.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{{contrastive-static}}}=||z_{t}-e_{\theta}(h(x_%
{t}))||_{2}^{2}+\max(0,\lambda-||e_{\theta}(h(x^{-}))-z_{t}||_{2}^{2})" class="ltx_Math" display="inline" id="S3.E6.m1.4"><semantics id="S3.E6.m1.4a"><mrow id="S3.E6.m1.4.4" xref="S3.E6.m1.4.4.cmml"><msub id="S3.E6.m1.4.4.4" xref="S3.E6.m1.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.4.4.4.2" xref="S3.E6.m1.4.4.4.2.cmml">â„’</mi><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.4.3" xref="S3.E6.m1.4.4.4.3a.cmml">contrastive-static</mtext></msub><mo id="S3.E6.m1.4.4.3" xref="S3.E6.m1.4.4.3.cmml">=</mo><mrow id="S3.E6.m1.4.4.2" xref="S3.E6.m1.4.4.2.cmml"><msubsup id="S3.E6.m1.3.3.1.1" xref="S3.E6.m1.3.3.1.1.cmml"><mrow id="S3.E6.m1.3.3.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E6.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.3.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml">h</mi><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="S3.E6.m1.3.3.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E6.m1.3.3.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.3.cmml">2</mn><mn id="S3.E6.m1.3.3.1.1.3" xref="S3.E6.m1.3.3.1.1.3.cmml">2</mn></msubsup><mo id="S3.E6.m1.4.4.2.3" xref="S3.E6.m1.4.4.2.3.cmml">+</mo><mrow id="S3.E6.m1.4.4.2.2.1" xref="S3.E6.m1.4.4.2.2.2.cmml"><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">max</mi><mo id="S3.E6.m1.4.4.2.2.1a" xref="S3.E6.m1.4.4.2.2.2.cmml">â¡</mo><mrow id="S3.E6.m1.4.4.2.2.1.1" xref="S3.E6.m1.4.4.2.2.2.cmml"><mo id="S3.E6.m1.4.4.2.2.1.1.2" stretchy="false" xref="S3.E6.m1.4.4.2.2.2.cmml">(</mo><mn id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml">0</mn><mo id="S3.E6.m1.4.4.2.2.1.1.3" xref="S3.E6.m1.4.4.2.2.2.cmml">,</mo><mrow id="S3.E6.m1.4.4.2.2.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.cmml"><mi id="S3.E6.m1.4.4.2.2.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.3.cmml">Î»</mi><mo id="S3.E6.m1.4.4.2.2.1.1.1.2" xref="S3.E6.m1.4.4.2.2.1.1.1.2.cmml">âˆ’</mo><msubsup id="S3.E6.m1.4.4.2.2.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.cmml"><mrow id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.2.cmml"><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.2.cmml">e</mi><mi id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">h</mi><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">âˆ’</mo></msup><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><msub id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.2.cmml">z</mi><mi id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E6.m1.4.4.2.2.1.1.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E6.m1.4.4.2.2.1.1.1.1.3" xref="S3.E6.m1.4.4.2.2.1.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S3.E6.m1.4.4.2.2.1.1.4" stretchy="false" xref="S3.E6.m1.4.4.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.4b"><apply id="S3.E6.m1.4.4.cmml" xref="S3.E6.m1.4.4"><eq id="S3.E6.m1.4.4.3.cmml" xref="S3.E6.m1.4.4.3"></eq><apply id="S3.E6.m1.4.4.4.cmml" xref="S3.E6.m1.4.4.4"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.4.1.cmml" xref="S3.E6.m1.4.4.4">subscript</csymbol><ci id="S3.E6.m1.4.4.4.2.cmml" xref="S3.E6.m1.4.4.4.2">â„’</ci><ci id="S3.E6.m1.4.4.4.3a.cmml" xref="S3.E6.m1.4.4.4.3"><mtext class="ltx_mathvariant_bold" id="S3.E6.m1.4.4.4.3.cmml" mathsize="70%" xref="S3.E6.m1.4.4.4.3">contrastive-static</mtext></ci></apply><apply id="S3.E6.m1.4.4.2.cmml" xref="S3.E6.m1.4.4.2"><plus id="S3.E6.m1.4.4.2.3.cmml" xref="S3.E6.m1.4.4.2.3"></plus><apply id="S3.E6.m1.3.3.1.1.cmml" xref="S3.E6.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1">superscript</csymbol><apply id="S3.E6.m1.3.3.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1">subscript</csymbol><apply id="S3.E6.m1.3.3.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.2">norm</csymbol><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1"><minus id="S3.E6.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.2"></minus><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1"><times id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2"></times><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1"><times id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">â„</ci><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></apply><cn id="S3.E6.m1.3.3.1.1.1.3.cmml" type="integer" xref="S3.E6.m1.3.3.1.1.1.3">2</cn></apply><cn id="S3.E6.m1.3.3.1.1.3.cmml" type="integer" xref="S3.E6.m1.3.3.1.1.3">2</cn></apply><apply id="S3.E6.m1.4.4.2.2.2.cmml" xref="S3.E6.m1.4.4.2.2.1"><max id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"></max><cn id="S3.E6.m1.2.2.cmml" type="integer" xref="S3.E6.m1.2.2">0</cn><apply id="S3.E6.m1.4.4.2.2.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1"><minus id="S3.E6.m1.4.4.2.2.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.2"></minus><ci id="S3.E6.m1.4.4.2.2.1.1.1.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.3">ğœ†</ci><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.2.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1">superscript</csymbol><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.2.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1">subscript</csymbol><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1"><minus id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.2"></minus><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1"><times id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.2">ğ‘’</ci><ci id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1"><times id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2"></times><ci id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3">â„</ci><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><minus id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3"></minus></apply></apply></apply><apply id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.2">ğ‘§</ci><ci id="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply><cn id="S3.E6.m1.4.4.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S3.E6.m1.4.4.2.2.1.1.1.1.1.3">2</cn></apply><cn id="S3.E6.m1.4.4.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.E6.m1.4.4.2.2.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.4c">\displaystyle\mathcal{L}_{\text{{contrastive-static}}}=||z_{t}-e_{\theta}(h(x_%
{t}))||_{2}^{2}+\max(0,\lambda-||e_{\theta}(h(x^{-}))-z_{t}||_{2}^{2})</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.4d">caligraphic_L start_POSTSUBSCRIPT contrastive-static end_POSTSUBSCRIPT = | | italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - italic_e start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_h ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + roman_max ( 0 , italic_Î» - | | italic_e start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_h ( italic_x start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ) ) - italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
<tbody id="S3.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\text{{contrastive-dynamic}}}=||z_{t+1}-d_{\theta}(z%
_{t},a_{t})||_{2}^{2}+\max(0,\lambda-||z^{-}-d_{\theta}(z_{t},a_{t})||_{2}^{2})" class="ltx_Math" display="inline" id="S3.E7.m1.4"><semantics id="S3.E7.m1.4a"><mrow id="S3.E7.m1.4.4" xref="S3.E7.m1.4.4.cmml"><msub id="S3.E7.m1.4.4.4" xref="S3.E7.m1.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.4.4.4.2" xref="S3.E7.m1.4.4.4.2.cmml">â„’</mi><mtext class="ltx_mathvariant_bold" id="S3.E7.m1.4.4.4.3" xref="S3.E7.m1.4.4.4.3a.cmml">contrastive-dynamic</mtext></msub><mo id="S3.E7.m1.4.4.3" xref="S3.E7.m1.4.4.3.cmml">=</mo><mrow id="S3.E7.m1.4.4.2" xref="S3.E7.m1.4.4.2.cmml"><msubsup id="S3.E7.m1.3.3.1.1" xref="S3.E7.m1.3.3.1.1.cmml"><mrow id="S3.E7.m1.3.3.1.1.1.1.1" xref="S3.E7.m1.3.3.1.1.1.1.2.cmml"><mo id="S3.E7.m1.3.3.1.1.1.1.1.2" stretchy="false" xref="S3.E7.m1.3.3.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E7.m1.3.3.1.1.1.1.1.1" xref="S3.E7.m1.3.3.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.3.3.1.1.1.1.1.1.4" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.cmml"><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.4.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.2.cmml">z</mi><mrow id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.cmml"><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.2.cmml">t</mi><mo id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.1" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.1.cmml">+</mo><mn id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.3.cmml">1</mn></mrow></msub><mo id="S3.E7.m1.3.3.1.1.1.1.1.1.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S3.E7.m1.3.3.1.1.1.1.1.1.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.cmml"><msub id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.cmml"><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.2.cmml">d</mi><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.3.cmml">Î¸</mi></msub><mo id="S3.E7.m1.3.3.1.1.1.1.1.1.2.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.3.cmml">â¢</mo><mrow id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.3.cmml"><mo id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.4" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.2.cmml">a</mi><mi id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E7.m1.3.3.1.1.1.1.1.3" stretchy="false" xref="S3.E7.m1.3.3.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E7.m1.3.3.1.1.1.3" xref="S3.E7.m1.3.3.1.1.1.3.cmml">2</mn><mn id="S3.E7.m1.3.3.1.1.3" xref="S3.E7.m1.3.3.1.1.3.cmml">2</mn></msubsup><mo id="S3.E7.m1.4.4.2.3" xref="S3.E7.m1.4.4.2.3.cmml">+</mo><mrow id="S3.E7.m1.4.4.2.2.1" xref="S3.E7.m1.4.4.2.2.2.cmml"><mi id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml">max</mi><mo id="S3.E7.m1.4.4.2.2.1a" xref="S3.E7.m1.4.4.2.2.2.cmml">â¡</mo><mrow id="S3.E7.m1.4.4.2.2.1.1" xref="S3.E7.m1.4.4.2.2.2.cmml"><mo id="S3.E7.m1.4.4.2.2.1.1.2" stretchy="false" xref="S3.E7.m1.4.4.2.2.2.cmml">(</mo><mn id="S3.E7.m1.2.2" xref="S3.E7.m1.2.2.cmml">0</mn><mo id="S3.E7.m1.4.4.2.2.1.1.3" xref="S3.E7.m1.4.4.2.2.2.cmml">,</mo><mrow id="S3.E7.m1.4.4.2.2.1.1.1" xref="S3.E7.m1.4.4.2.2.1.1.1.cmml"><mi id="S3.E7.m1.4.4.2.2.1.1.1.3" xref="S3.E7.m1.4.4.2.2.1.1.1.3.cmml">Î»</mi><mo id="S3.E7.m1.4.4.2.2.1.1.1.2" xref="S3.E7.m1.4.4.2.2.1.1.1.2.cmml">âˆ’</mo><msubsup id="S3.E7.m1.4.4.2.2.1.1.1.1" xref="S3.E7.m1.4.4.2.2.1.1.1.1.cmml"><mrow id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.2.cmml"><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.2.cmml">z</mi><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.3.cmml">âˆ’</mo></msup><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.cmml"><msub id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.cmml"><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.2.cmml">d</mi><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.3.cmml">Î¸</mi></msub><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.3.cmml">â¢</mo><mrow id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.3.cmml"><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.3" stretchy="false" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.3.cmml">(</mo><msub id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.4" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.3.cmml">,</mo><msub id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">a</mi><mi id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.5" stretchy="false" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.E7.m1.4.4.2.2.1.1.1.1.1.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E7.m1.4.4.2.2.1.1.1.1.3" xref="S3.E7.m1.4.4.2.2.1.1.1.1.3.cmml">2</mn></msubsup></mrow><mo id="S3.E7.m1.4.4.2.2.1.1.4" stretchy="false" xref="S3.E7.m1.4.4.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.4b"><apply id="S3.E7.m1.4.4.cmml" xref="S3.E7.m1.4.4"><eq id="S3.E7.m1.4.4.3.cmml" xref="S3.E7.m1.4.4.3"></eq><apply id="S3.E7.m1.4.4.4.cmml" xref="S3.E7.m1.4.4.4"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.4.1.cmml" xref="S3.E7.m1.4.4.4">subscript</csymbol><ci id="S3.E7.m1.4.4.4.2.cmml" xref="S3.E7.m1.4.4.4.2">â„’</ci><ci id="S3.E7.m1.4.4.4.3a.cmml" xref="S3.E7.m1.4.4.4.3"><mtext class="ltx_mathvariant_bold" id="S3.E7.m1.4.4.4.3.cmml" mathsize="70%" xref="S3.E7.m1.4.4.4.3">contrastive-dynamic</mtext></ci></apply><apply id="S3.E7.m1.4.4.2.cmml" xref="S3.E7.m1.4.4.2"><plus id="S3.E7.m1.4.4.2.3.cmml" xref="S3.E7.m1.4.4.2.3"></plus><apply id="S3.E7.m1.3.3.1.1.cmml" xref="S3.E7.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1">superscript</csymbol><apply id="S3.E7.m1.3.3.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1">subscript</csymbol><apply id="S3.E7.m1.3.3.1.1.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.2">norm</csymbol><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1"><minus id="S3.E7.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.3"></minus><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.4.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.1.1.1.1.4.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.4.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.2">ğ‘§</ci><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3"><plus id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.1"></plus><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.2">ğ‘¡</ci><cn id="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.3.cmml" type="integer" xref="S3.E7.m1.3.3.1.1.1.1.1.1.4.3.3">1</cn></apply></apply><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2"><times id="S3.E7.m1.3.3.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.3"></times><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.2">ğ‘‘</ci><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2"><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.2">ğ‘</ci><ci id="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E7.m1.3.3.1.1.1.1.1.1.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></apply><cn id="S3.E7.m1.3.3.1.1.1.3.cmml" type="integer" xref="S3.E7.m1.3.3.1.1.1.3">2</cn></apply><cn id="S3.E7.m1.3.3.1.1.3.cmml" type="integer" xref="S3.E7.m1.3.3.1.1.3">2</cn></apply><apply id="S3.E7.m1.4.4.2.2.2.cmml" xref="S3.E7.m1.4.4.2.2.1"><max id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"></max><cn id="S3.E7.m1.2.2.cmml" type="integer" xref="S3.E7.m1.2.2">0</cn><apply id="S3.E7.m1.4.4.2.2.1.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1"><minus id="S3.E7.m1.4.4.2.2.1.1.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.2"></minus><ci id="S3.E7.m1.4.4.2.2.1.1.1.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.3">ğœ†</ci><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1">superscript</csymbol><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1">subscript</csymbol><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1"><minus id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.3"></minus><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4">superscript</csymbol><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.2">ğ‘§</ci><minus id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.4.3"></minus></apply><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2"><times id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.3"></times><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.2">ğ‘‘</ci><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.4.3">ğœƒ</ci></apply><interval closure="open" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2"><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.2">ğ‘</ci><ci id="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.1.1.1.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></apply><cn id="S3.E7.m1.4.4.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S3.E7.m1.4.4.2.2.1.1.1.1.1.3">2</cn></apply><cn id="S3.E7.m1.4.4.2.2.1.1.1.1.3.cmml" type="integer" xref="S3.E7.m1.4.4.2.2.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.4c">\displaystyle\mathcal{L}_{\text{{contrastive-dynamic}}}=||z_{t+1}-d_{\theta}(z%
_{t},a_{t})||_{2}^{2}+\max(0,\lambda-||z^{-}-d_{\theta}(z_{t},a_{t})||_{2}^{2})</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.4d">caligraphic_L start_POSTSUBSCRIPT contrastive-dynamic end_POSTSUBSCRIPT = | | italic_z start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + roman_max ( 0 , italic_Î» - | | italic_z start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT - italic_d start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p11">
<p class="ltx_p" id="S3.SS1.p11.1">We refer to the static contrastive model as <em class="ltx_emph ltx_font_italic" id="S3.SS1.p11.1.1">CRL</em>, for Contrastive Representation Learner, and the dynamic contrastive model as <em class="ltx_emph ltx_font_italic" id="S3.SS1.p11.1.2">CWM</em>, for Contrastive World Model.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Slotted models</h4>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">We compare the auto-encoding models and CWM to baselines which attempt to learn slotted representations. As a baseline to the auto-encoding models, we implement Slot Attention <cite class="ltx_cite ltx_citemacro_citep">(Locatello etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib34" title="">2020b</a>)</cite>, an auto-encoder that reconstructs images as an additive composition of multiple object slots. The slots compete to represent the objects in the scene using an iterative attention mechanism, and the full model is trained with a simple auto-encoding objective as in equationÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S3.E5" title="In 3.1 Models â€£ 3 Methods â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.p2.1">The contrastive dynamics model is compared to a <em class="ltx_emph ltx_font_italic" id="S3.SS1.SSS1.p2.1.1">structured</em> variant, the Contrastive Structured World Model (CSWM) <cite class="ltx_cite ltx_citemacro_citep">(Kipf etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib26" title="">2019</a>)</cite>, that decomposes the scene into distinct object slots, and uses a graph neural network to predict how these object slots evolve over time. In non-Markovian settings, we replace the graph neural network with a Transformer encoder that applies spatio-temporal attention over a sequence of past object-slot representations, akin to the Slotformer architecture <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib49" title="">2022</a>)</cite>. Here too, the loss function exactly matches the one used to train the contrastive dynamics model with distributed representations.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Assessing object representations</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.12">How can we quantify the degree to which a non-slotted model has learned systematic object representations? While many metrics are possible, we propose one which is both simple and has connections to other metrics proposed to quantify representation disentanglement. If a representation of an object <math alttext="o_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">o</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">o_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is disentangled from representations of other objects <math alttext="o^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">o</mi><mo id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">o^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_o start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>, then a change to <math alttext="o_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msub id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">o</mi><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">o_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> should only change one subspace of the modelsâ€™ latent representation <math alttext="z" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_z</annotation></semantics></math>. Additionally, this subspace should not be affected by changes to any of the other objects <math alttext="o^{\prime}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><msup id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">o</mi><mo id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">o^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">italic_o start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>. In other words, each object is represented across completely non-overlapping populations of neurons. Complete disentanglement is a tall order for models without the structural properties of slotted models. To get a continuous relaxation of this absolute object disentanglement metric we ask a related question of the modelsâ€™ latent spaces: Given a set of changes to individual objects in a scene, how accurately can a linear classifier predict which object was changed from the resulting absolute difference in the modelâ€™s latent representations? The accuracy of this linear classifier on an evaluation set is our proposed metric. This metric is in fact a variation of the disentanglement metric proposed in <cite class="ltx_cite ltx_citemacro_cite">Higgins etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib19" title="">2016</a>)</cite>, but applied to objects rather than ground truth generative features. Even if a model attains a perfect score on this metric, it does not necessarily mean that it represent objects in perfectly disjoint, non-overlapping populations of neurons. To illustrate, if a change to object <math alttext="o_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m6.1"><semantics id="S3.SS2.p1.6.m6.1a"><msub id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml">o</mi><mi id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">o_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m6.1d">italic_o start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> always changes latent <math alttext="z^{1}" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m7.1"><semantics id="S3.SS2.p1.7.m7.1a"><msup id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml"><mi id="S3.SS2.p1.7.m7.1.1.2" xref="S3.SS2.p1.7.m7.1.1.2.cmml">z</mi><mn id="S3.SS2.p1.7.m7.1.1.3" xref="S3.SS2.p1.7.m7.1.1.3.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><apply id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">superscript</csymbol><ci id="S3.SS2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.p1.7.m7.1.1.2">ğ‘§</ci><cn id="S3.SS2.p1.7.m7.1.1.3.cmml" type="integer" xref="S3.SS2.p1.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">z^{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m7.1d">italic_z start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT</annotation></semantics></math> marginally and latent <math alttext="z^{2}" class="ltx_Math" display="inline" id="S3.SS2.p1.8.m8.1"><semantics id="S3.SS2.p1.8.m8.1a"><msup id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml"><mi id="S3.SS2.p1.8.m8.1.1.2" xref="S3.SS2.p1.8.m8.1.1.2.cmml">z</mi><mn id="S3.SS2.p1.8.m8.1.1.3" xref="S3.SS2.p1.8.m8.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><apply id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.8.m8.1.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">superscript</csymbol><ci id="S3.SS2.p1.8.m8.1.1.2.cmml" xref="S3.SS2.p1.8.m8.1.1.2">ğ‘§</ci><cn id="S3.SS2.p1.8.m8.1.1.3.cmml" type="integer" xref="S3.SS2.p1.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">z^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.8.m8.1d">italic_z start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> greatly, and a change to object <math alttext="o_{j}" class="ltx_Math" display="inline" id="S3.SS2.p1.9.m9.1"><semantics id="S3.SS2.p1.9.m9.1a"><msub id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml"><mi id="S3.SS2.p1.9.m9.1.1.2" xref="S3.SS2.p1.9.m9.1.1.2.cmml">o</mi><mi id="S3.SS2.p1.9.m9.1.1.3" xref="S3.SS2.p1.9.m9.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><apply id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.9.m9.1.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p1.9.m9.1.1.2.cmml" xref="S3.SS2.p1.9.m9.1.1.2">ğ‘œ</ci><ci id="S3.SS2.p1.9.m9.1.1.3.cmml" xref="S3.SS2.p1.9.m9.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">o_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.9.m9.1d">italic_o start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> changes <math alttext="z^{1}" class="ltx_Math" display="inline" id="S3.SS2.p1.10.m10.1"><semantics id="S3.SS2.p1.10.m10.1a"><msup id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml"><mi id="S3.SS2.p1.10.m10.1.1.2" xref="S3.SS2.p1.10.m10.1.1.2.cmml">z</mi><mn id="S3.SS2.p1.10.m10.1.1.3" xref="S3.SS2.p1.10.m10.1.1.3.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><apply id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p1.10.m10.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.2">ğ‘§</ci><cn id="S3.SS2.p1.10.m10.1.1.3.cmml" type="integer" xref="S3.SS2.p1.10.m10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">z^{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.10.m10.1d">italic_z start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT</annotation></semantics></math> greatly and <math alttext="z^{2}" class="ltx_Math" display="inline" id="S3.SS2.p1.11.m11.1"><semantics id="S3.SS2.p1.11.m11.1a"><msup id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml"><mi id="S3.SS2.p1.11.m11.1.1.2" xref="S3.SS2.p1.11.m11.1.1.2.cmml">z</mi><mn id="S3.SS2.p1.11.m11.1.1.3" xref="S3.SS2.p1.11.m11.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><apply id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.11.m11.1.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1">superscript</csymbol><ci id="S3.SS2.p1.11.m11.1.1.2.cmml" xref="S3.SS2.p1.11.m11.1.1.2">ğ‘§</ci><cn id="S3.SS2.p1.11.m11.1.1.3.cmml" type="integer" xref="S3.SS2.p1.11.m11.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">z^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.11.m11.1d">italic_z start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> marginally, a linear classifier can reliably separate the two objects in terms of the change in <math alttext="z" class="ltx_Math" display="inline" id="S3.SS2.p1.12.m12.1"><semantics id="S3.SS2.p1.12.m12.1a"><mi id="S3.SS2.p1.12.m12.1.1" xref="S3.SS2.p1.12.m12.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.m12.1b"><ci id="S3.SS2.p1.12.m12.1.1.cmml" xref="S3.SS2.p1.12.m12.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.m12.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.12.m12.1d">italic_z</annotation></semantics></math>, despite them having entangled representations. In other words, it is possible to use overlapping neural codes to represent objects, while still having object representations that are linearly separable. We investigate this further in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5" title="5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.6">In practice, we implement our metric by constructing datasets consisting of pairs of images <math alttext="(x_{t}^{i},x_{t+1}^{i})" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.2"><semantics id="S3.SS2.p2.1.m1.2a"><mrow id="S3.SS2.p2.1.m1.2.2.2" xref="S3.SS2.p2.1.m1.2.2.3.cmml"><mo id="S3.SS2.p2.1.m1.2.2.2.3" stretchy="false" xref="S3.SS2.p2.1.m1.2.2.3.cmml">(</mo><msubsup id="S3.SS2.p2.1.m1.1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.1.1.2.2" xref="S3.SS2.p2.1.m1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS2.p2.1.m1.1.1.1.1.2.3" xref="S3.SS2.p2.1.m1.1.1.1.1.2.3.cmml">t</mi><mi id="S3.SS2.p2.1.m1.1.1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.SS2.p2.1.m1.2.2.2.4" xref="S3.SS2.p2.1.m1.2.2.3.cmml">,</mo><msubsup id="S3.SS2.p2.1.m1.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.cmml"><mi id="S3.SS2.p2.1.m1.2.2.2.2.2.2" xref="S3.SS2.p2.1.m1.2.2.2.2.2.2.cmml">x</mi><mrow id="S3.SS2.p2.1.m1.2.2.2.2.2.3" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.cmml"><mi id="S3.SS2.p2.1.m1.2.2.2.2.2.3.2" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.2.cmml">t</mi><mo id="S3.SS2.p2.1.m1.2.2.2.2.2.3.1" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.1.cmml">+</mo><mn id="S3.SS2.p2.1.m1.2.2.2.2.2.3.3" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p2.1.m1.2.2.2.2.3" xref="S3.SS2.p2.1.m1.2.2.2.2.3.cmml">i</mi></msubsup><mo id="S3.SS2.p2.1.m1.2.2.2.5" stretchy="false" xref="S3.SS2.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.2b"><interval closure="open" id="S3.SS2.p2.1.m1.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2"><apply id="S3.SS2.p2.1.m1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.SS2.p2.1.m1.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p2.1.m1.1.1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.1.1.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.1.m1.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2">superscript</csymbol><apply id="S3.SS2.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2.2">ğ‘¥</ci><apply id="S3.SS2.p2.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3"><plus id="S3.SS2.p2.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.1"></plus><ci id="S3.SS2.p2.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.2">ğ‘¡</ci><cn id="S3.SS2.p2.1.m1.2.2.2.2.2.3.3.cmml" type="integer" xref="S3.SS2.p2.1.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S3.SS2.p2.1.m1.2.2.2.2.3.cmml" xref="S3.SS2.p2.1.m1.2.2.2.2.3">ğ‘–</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.2c">(x_{t}^{i},x_{t+1}^{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.2d">( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT , italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math> from the data domain on which a model was trained. The only difference between these two images is that a single object has changed from time <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_t</annotation></semantics></math> to <math alttext="t+1" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">t</mi><mo id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">+</mo><mn id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><plus id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1"></plus><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">ğ‘¡</ci><cn id="S3.SS2.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS2.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">t+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_t + 1</annotation></semantics></math>. For each such pair we associate it with a label <math alttext="y^{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.1"><semantics id="S3.SS2.p2.4.m4.1a"><msup id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml">y</mi><mi id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">ğ‘¦</ci><ci id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">y^{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.1d">italic_y start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>, a categorical variable indicating <em class="ltx_emph ltx_font_italic" id="S3.SS2.p2.6.1">which</em> object was altered from <math alttext="t" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_t</annotation></semantics></math> to <math alttext="t+1" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><mrow id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">t</mi><mo id="S3.SS2.p2.6.m6.1.1.1" xref="S3.SS2.p2.6.m6.1.1.1.cmml">+</mo><mn id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><plus id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1.1"></plus><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">ğ‘¡</ci><cn id="S3.SS2.p2.6.m6.1.1.3.cmml" type="integer" xref="S3.SS2.p2.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">t+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_t + 1</annotation></semantics></math>. We then extract a modelâ€™s representation of each frame in the pair (after it has been trained), and compute the vector of absolute differences between these two representations:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="|\Delta^{i}|=|e_{\theta}(x_{t}^{i})-e_{\theta}(x_{t+1}^{i})|" class="ltx_Math" display="block" id="S3.E8.m1.2"><semantics id="S3.E8.m1.2a"><mrow id="S3.E8.m1.2.2" xref="S3.E8.m1.2.2.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.2.cmml"><mo id="S3.E8.m1.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.1.1.1.2.1.cmml">|</mo><msup id="S3.E8.m1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.1.1.1.1.1.2" mathvariant="normal" xref="S3.E8.m1.1.1.1.1.1.2.cmml">Î”</mi><mi id="S3.E8.m1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.3.cmml">i</mi></msup><mo id="S3.E8.m1.1.1.1.1.3" stretchy="false" xref="S3.E8.m1.1.1.1.2.1.cmml">|</mo></mrow><mo id="S3.E8.m1.2.2.3" xref="S3.E8.m1.2.2.3.cmml">=</mo><mrow id="S3.E8.m1.2.2.2.1" xref="S3.E8.m1.2.2.2.2.cmml"><mo id="S3.E8.m1.2.2.2.1.2" stretchy="false" xref="S3.E8.m1.2.2.2.2.1.cmml">|</mo><mrow id="S3.E8.m1.2.2.2.1.1" xref="S3.E8.m1.2.2.2.1.1.cmml"><mrow id="S3.E8.m1.2.2.2.1.1.1" xref="S3.E8.m1.2.2.2.1.1.1.cmml"><msub id="S3.E8.m1.2.2.2.1.1.1.3" xref="S3.E8.m1.2.2.2.1.1.1.3.cmml"><mi id="S3.E8.m1.2.2.2.1.1.1.3.2" xref="S3.E8.m1.2.2.2.1.1.1.3.2.cmml">e</mi><mi id="S3.E8.m1.2.2.2.1.1.1.3.3" xref="S3.E8.m1.2.2.2.1.1.1.3.3.cmml">Î¸</mi></msub><mo id="S3.E8.m1.2.2.2.1.1.1.2" xref="S3.E8.m1.2.2.2.1.1.1.2.cmml">â¢</mo><mrow id="S3.E8.m1.2.2.2.1.1.1.1.1" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml"><mo id="S3.E8.m1.2.2.2.1.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E8.m1.2.2.2.1.1.1.1.1.1" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.2" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.3" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.3.cmml">t</mi><mi id="S3.E8.m1.2.2.2.1.1.1.1.1.1.3" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E8.m1.2.2.2.1.1.1.1.1.3" stretchy="false" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.2.2.2.1.1.3" xref="S3.E8.m1.2.2.2.1.1.3.cmml">âˆ’</mo><mrow id="S3.E8.m1.2.2.2.1.1.2" xref="S3.E8.m1.2.2.2.1.1.2.cmml"><msub id="S3.E8.m1.2.2.2.1.1.2.3" xref="S3.E8.m1.2.2.2.1.1.2.3.cmml"><mi id="S3.E8.m1.2.2.2.1.1.2.3.2" xref="S3.E8.m1.2.2.2.1.1.2.3.2.cmml">e</mi><mi id="S3.E8.m1.2.2.2.1.1.2.3.3" xref="S3.E8.m1.2.2.2.1.1.2.3.3.cmml">Î¸</mi></msub><mo id="S3.E8.m1.2.2.2.1.1.2.2" xref="S3.E8.m1.2.2.2.1.1.2.2.cmml">â¢</mo><mrow id="S3.E8.m1.2.2.2.1.1.2.1.1" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.cmml"><mo id="S3.E8.m1.2.2.2.1.1.2.1.1.2" stretchy="false" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.cmml">(</mo><msubsup id="S3.E8.m1.2.2.2.1.1.2.1.1.1" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.cmml"><mi id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.2" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.2.cmml">x</mi><mrow id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.cmml"><mi id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.2" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.1" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.1.cmml">+</mo><mn id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.3" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E8.m1.2.2.2.1.1.2.1.1.1.3" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.3.cmml">i</mi></msubsup><mo id="S3.E8.m1.2.2.2.1.1.2.1.1.3" stretchy="false" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E8.m1.2.2.2.1.3" stretchy="false" xref="S3.E8.m1.2.2.2.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.2b"><apply id="S3.E8.m1.2.2.cmml" xref="S3.E8.m1.2.2"><eq id="S3.E8.m1.2.2.3.cmml" xref="S3.E8.m1.2.2.3"></eq><apply id="S3.E8.m1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1"><abs id="S3.E8.m1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.2"></abs><apply id="S3.E8.m1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.2">Î”</ci><ci id="S3.E8.m1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.E8.m1.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.1"><abs id="S3.E8.m1.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.1.2"></abs><apply id="S3.E8.m1.2.2.2.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1"><minus id="S3.E8.m1.2.2.2.1.1.3.cmml" xref="S3.E8.m1.2.2.2.1.1.3"></minus><apply id="S3.E8.m1.2.2.2.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1"><times id="S3.E8.m1.2.2.2.1.1.1.2.cmml" xref="S3.E8.m1.2.2.2.1.1.1.2"></times><apply id="S3.E8.m1.2.2.2.1.1.1.3.cmml" xref="S3.E8.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.1.1.1.3.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.2.2.2.1.1.1.3.2.cmml" xref="S3.E8.m1.2.2.2.1.1.1.3.2">ğ‘’</ci><ci id="S3.E8.m1.2.2.2.1.1.1.3.3.cmml" xref="S3.E8.m1.2.2.2.1.1.1.3.3">ğœƒ</ci></apply><apply id="S3.E8.m1.2.2.2.1.1.1.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1">superscript</csymbol><apply id="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.E8.m1.2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.2.2.2.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><apply id="S3.E8.m1.2.2.2.1.1.2.cmml" xref="S3.E8.m1.2.2.2.1.1.2"><times id="S3.E8.m1.2.2.2.1.1.2.2.cmml" xref="S3.E8.m1.2.2.2.1.1.2.2"></times><apply id="S3.E8.m1.2.2.2.1.1.2.3.cmml" xref="S3.E8.m1.2.2.2.1.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.1.1.2.3.1.cmml" xref="S3.E8.m1.2.2.2.1.1.2.3">subscript</csymbol><ci id="S3.E8.m1.2.2.2.1.1.2.3.2.cmml" xref="S3.E8.m1.2.2.2.1.1.2.3.2">ğ‘’</ci><ci id="S3.E8.m1.2.2.2.1.1.2.3.3.cmml" xref="S3.E8.m1.2.2.2.1.1.2.3.3">ğœƒ</ci></apply><apply id="S3.E8.m1.2.2.2.1.1.2.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.1.1.2.1.1.1.1.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1">superscript</csymbol><apply id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.1.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1">subscript</csymbol><ci id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.2.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.2">ğ‘¥</ci><apply id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3"><plus id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.1.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.1"></plus><ci id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.2.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.2">ğ‘¡</ci><cn id="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.3.cmml" type="integer" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.2.3.3">1</cn></apply></apply><ci id="S3.E8.m1.2.2.2.1.1.2.1.1.1.3.cmml" xref="S3.E8.m1.2.2.2.1.1.2.1.1.1.3">ğ‘–</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.2c">|\Delta^{i}|=|e_{\theta}(x_{t}^{i})-e_{\theta}(x_{t+1}^{i})|</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.2d">| roman_Î” start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT | = | italic_e start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) - italic_e start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ) |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.4">From the set of ensuing absolute difference vectors <math alttext="\mathcal{X}=(|\Delta^{1}|,...,|\Delta^{n}|)" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.3"><semantics id="S3.SS2.p4.1.m1.3a"><mrow id="S3.SS2.p4.1.m1.3.3" xref="S3.SS2.p4.1.m1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.1.m1.3.3.4" xref="S3.SS2.p4.1.m1.3.3.4.cmml">ğ’³</mi><mo id="S3.SS2.p4.1.m1.3.3.3" xref="S3.SS2.p4.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS2.p4.1.m1.3.3.2.2" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml"><mo id="S3.SS2.p4.1.m1.3.3.2.2.3" stretchy="false" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">(</mo><mrow id="S3.SS2.p4.1.m1.2.2.1.1.1.1" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2.cmml"><mo id="S3.SS2.p4.1.m1.2.2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2.1.cmml">|</mo><msup id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.2" mathvariant="normal" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.2.cmml">Î”</mi><mn id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.3" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.3.cmml">1</mn></msup><mo id="S3.SS2.p4.1.m1.2.2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2.1.cmml">|</mo></mrow><mo id="S3.SS2.p4.1.m1.3.3.2.2.4" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">,</mo><mi id="S3.SS2.p4.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p4.1.m1.1.1.cmml">â€¦</mi><mo id="S3.SS2.p4.1.m1.3.3.2.2.5" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">,</mo><mrow id="S3.SS2.p4.1.m1.3.3.2.2.2.1" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2.cmml"><mo id="S3.SS2.p4.1.m1.3.3.2.2.2.1.2" stretchy="false" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2.1.cmml">|</mo><msup id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.cmml"><mi id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.2" mathvariant="normal" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.2.cmml">Î”</mi><mi id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.3" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.3.cmml">n</mi></msup><mo id="S3.SS2.p4.1.m1.3.3.2.2.2.1.3" stretchy="false" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2.1.cmml">|</mo></mrow><mo id="S3.SS2.p4.1.m1.3.3.2.2.6" stretchy="false" xref="S3.SS2.p4.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.3b"><apply id="S3.SS2.p4.1.m1.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3"><eq id="S3.SS2.p4.1.m1.3.3.3.cmml" xref="S3.SS2.p4.1.m1.3.3.3"></eq><ci id="S3.SS2.p4.1.m1.3.3.4.cmml" xref="S3.SS2.p4.1.m1.3.3.4">ğ’³</ci><vector id="S3.SS2.p4.1.m1.3.3.2.3.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2"><apply id="S3.SS2.p4.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1"><abs id="S3.SS2.p4.1.m1.2.2.1.1.1.2.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.2"></abs><apply id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1">superscript</csymbol><ci id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.2">Î”</ci><cn id="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p4.1.m1.2.2.1.1.1.1.1.3">1</cn></apply></apply><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">â€¦</ci><apply id="S3.SS2.p4.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1"><abs id="S3.SS2.p4.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.2"></abs><apply id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.1.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1">superscript</csymbol><ci id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.2">Î”</ci><ci id="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.3.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.1.1.3">ğ‘›</ci></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.3c">\mathcal{X}=(|\Delta^{1}|,...,|\Delta^{n}|)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.3d">caligraphic_X = ( | roman_Î” start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT | , â€¦ , | roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT | )</annotation></semantics></math> we train a linear classifier to predict the corresponding object labels <math alttext="\mathcal{Y}=(y^{1},...,y^{n})" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.3"><semantics id="S3.SS2.p4.2.m2.3a"><mrow id="S3.SS2.p4.2.m2.3.3" xref="S3.SS2.p4.2.m2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.2.m2.3.3.4" xref="S3.SS2.p4.2.m2.3.3.4.cmml">ğ’´</mi><mo id="S3.SS2.p4.2.m2.3.3.3" xref="S3.SS2.p4.2.m2.3.3.3.cmml">=</mo><mrow id="S3.SS2.p4.2.m2.3.3.2.2" xref="S3.SS2.p4.2.m2.3.3.2.3.cmml"><mo id="S3.SS2.p4.2.m2.3.3.2.2.3" stretchy="false" xref="S3.SS2.p4.2.m2.3.3.2.3.cmml">(</mo><msup id="S3.SS2.p4.2.m2.2.2.1.1.1" xref="S3.SS2.p4.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS2.p4.2.m2.2.2.1.1.1.2" xref="S3.SS2.p4.2.m2.2.2.1.1.1.2.cmml">y</mi><mn id="S3.SS2.p4.2.m2.2.2.1.1.1.3" xref="S3.SS2.p4.2.m2.2.2.1.1.1.3.cmml">1</mn></msup><mo id="S3.SS2.p4.2.m2.3.3.2.2.4" xref="S3.SS2.p4.2.m2.3.3.2.3.cmml">,</mo><mi id="S3.SS2.p4.2.m2.1.1" mathvariant="normal" xref="S3.SS2.p4.2.m2.1.1.cmml">â€¦</mi><mo id="S3.SS2.p4.2.m2.3.3.2.2.5" xref="S3.SS2.p4.2.m2.3.3.2.3.cmml">,</mo><msup id="S3.SS2.p4.2.m2.3.3.2.2.2" xref="S3.SS2.p4.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS2.p4.2.m2.3.3.2.2.2.2" xref="S3.SS2.p4.2.m2.3.3.2.2.2.2.cmml">y</mi><mi id="S3.SS2.p4.2.m2.3.3.2.2.2.3" xref="S3.SS2.p4.2.m2.3.3.2.2.2.3.cmml">n</mi></msup><mo id="S3.SS2.p4.2.m2.3.3.2.2.6" stretchy="false" xref="S3.SS2.p4.2.m2.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.3b"><apply id="S3.SS2.p4.2.m2.3.3.cmml" xref="S3.SS2.p4.2.m2.3.3"><eq id="S3.SS2.p4.2.m2.3.3.3.cmml" xref="S3.SS2.p4.2.m2.3.3.3"></eq><ci id="S3.SS2.p4.2.m2.3.3.4.cmml" xref="S3.SS2.p4.2.m2.3.3.4">ğ’´</ci><vector id="S3.SS2.p4.2.m2.3.3.2.3.cmml" xref="S3.SS2.p4.2.m2.3.3.2.2"><apply id="S3.SS2.p4.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.p4.2.m2.2.2.1.1.1">superscript</csymbol><ci id="S3.SS2.p4.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p4.2.m2.2.2.1.1.1.2">ğ‘¦</ci><cn id="S3.SS2.p4.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p4.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">â€¦</ci><apply id="S3.SS2.p4.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p4.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p4.2.m2.3.3.2.2.2">superscript</csymbol><ci id="S3.SS2.p4.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p4.2.m2.3.3.2.2.2.2">ğ‘¦</ci><ci id="S3.SS2.p4.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS2.p4.2.m2.3.3.2.2.2.3">ğ‘›</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.3c">\mathcal{Y}=(y^{1},...,y^{n})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.3d">caligraphic_Y = ( italic_y start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , â€¦ , italic_y start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT )</annotation></semantics></math> while minimizing the <math alttext="L_{1}" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><msub id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">L</mi><mn id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">ğ¿</ci><cn id="S3.SS2.p4.3.m3.1.1.3.cmml" type="integer" xref="S3.SS2.p4.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">L_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> norm of the learned coefficients, as recommended by <cite class="ltx_cite ltx_citemacro_cite">Higgins etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib19" title="">2016</a>)</cite>. We report the accuracy on a left out subset of <math alttext="(\mathcal{X},\mathcal{Y})" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.2"><semantics id="S3.SS2.p4.4.m4.2a"><mrow id="S3.SS2.p4.4.m4.2.3.2" xref="S3.SS2.p4.4.m4.2.3.1.cmml"><mo id="S3.SS2.p4.4.m4.2.3.2.1" stretchy="false" xref="S3.SS2.p4.4.m4.2.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml">ğ’³</mi><mo id="S3.SS2.p4.4.m4.2.3.2.2" xref="S3.SS2.p4.4.m4.2.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.4.m4.2.2" xref="S3.SS2.p4.4.m4.2.2.cmml">ğ’´</mi><mo id="S3.SS2.p4.4.m4.2.3.2.3" stretchy="false" xref="S3.SS2.p4.4.m4.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.2b"><interval closure="open" id="S3.SS2.p4.4.m4.2.3.1.cmml" xref="S3.SS2.p4.4.m4.2.3.2"><ci id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">ğ’³</ci><ci id="S3.SS2.p4.4.m4.2.2.cmml" xref="S3.SS2.p4.4.m4.2.2">ğ’´</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.2c">(\mathcal{X},\mathcal{Y})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.2d">( caligraphic_X , caligraphic_Y )</annotation></semantics></math> that the classifier was not trained on.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.3">We trained the two classes of distributed models, as well as their object-centric counterparts, on five datasets of dynamically interacting objects. Two of these datasets, <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.1">cubes</span> and <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.2">3-body physics</span>, were introduced in <cite class="ltx_cite ltx_citemacro_cite">Kipf etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib26" title="">2019</a>)</cite> to showcase how object-centric representations facilitate learning of object dynamics. Extending the evaluation, we created our own dataset of object interactions based on the dSprites environment <cite class="ltx_cite ltx_citemacro_citep">(Matthey etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib36" title="">2017</a>)</cite>. This dataset consisted of four sprites with different shapes and colors traversing latent generative factors, such as <math alttext="(x,y)" class="ltx_Math" display="inline" id="S4.p1.1.m1.2"><semantics id="S4.p1.1.m1.2a"><mrow id="S4.p1.1.m1.2.3.2" xref="S4.p1.1.m1.2.3.1.cmml"><mo id="S4.p1.1.m1.2.3.2.1" stretchy="false" xref="S4.p1.1.m1.2.3.1.cmml">(</mo><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">x</mi><mo id="S4.p1.1.m1.2.3.2.2" xref="S4.p1.1.m1.2.3.1.cmml">,</mo><mi id="S4.p1.1.m1.2.2" xref="S4.p1.1.m1.2.2.cmml">y</mi><mo id="S4.p1.1.m1.2.3.2.3" stretchy="false" xref="S4.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.2b"><interval closure="open" id="S4.p1.1.m1.2.3.1.cmml" xref="S4.p1.1.m1.2.3.2"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">ğ‘¥</ci><ci id="S4.p1.1.m1.2.2.cmml" xref="S4.p1.1.m1.2.2">ğ‘¦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.2c">(x,y)</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.2d">( italic_x , italic_y )</annotation></semantics></math>-coordinates, scale and orientation, on a random walk. Lastly, we trained our models on two more complex Multi-Object Video (MOVi) datasets generated using the Kubric simulator <cite class="ltx_cite ltx_citemacro_citep">(Greff etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib16" title="">2022</a>)</cite>, a 3D physics engine for simulating realistic object interactions. We generated one dataset consisting of <math alttext="14,000" class="ltx_Math" display="inline" id="S4.p1.2.m2.2"><semantics id="S4.p1.2.m2.2a"><mrow id="S4.p1.2.m2.2.3.2" xref="S4.p1.2.m2.2.3.1.cmml"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">14</mn><mo id="S4.p1.2.m2.2.3.2.1" xref="S4.p1.2.m2.2.3.1.cmml">,</mo><mn id="S4.p1.2.m2.2.2" xref="S4.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.2b"><list id="S4.p1.2.m2.2.3.1.cmml" xref="S4.p1.2.m2.2.3.2"><cn id="S4.p1.2.m2.1.1.cmml" type="integer" xref="S4.p1.2.m2.1.1">14</cn><cn id="S4.p1.2.m2.2.2.cmml" type="integer" xref="S4.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.2c">14,000</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.2d">14 , 000</annotation></semantics></math> videos with a constant set of five cubes with fixed physical properties that interacted (initial object conditions such as directional velocities and position were randomized for each video). We refer to this dataset as <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.3">MOVi (simple)</span>, due to the constant object properties. Additionally we trained models on the <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.4">MOVi-A</span> dataset, consisting of almost <math alttext="10,000" class="ltx_Math" display="inline" id="S4.p1.3.m3.2"><semantics id="S4.p1.3.m3.2a"><mrow id="S4.p1.3.m3.2.3.2" xref="S4.p1.3.m3.2.3.1.cmml"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">10</mn><mo id="S4.p1.3.m3.2.3.2.1" xref="S4.p1.3.m3.2.3.1.cmml">,</mo><mn id="S4.p1.3.m3.2.2" xref="S4.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.2b"><list id="S4.p1.3.m3.2.3.1.cmml" xref="S4.p1.3.m3.2.3.2"><cn id="S4.p1.3.m3.1.1.cmml" type="integer" xref="S4.p1.3.m3.1.1">10</cn><cn id="S4.p1.3.m3.2.2.cmml" type="integer" xref="S4.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.2c">10,000</annotation><annotation encoding="application/x-llamapun" id="S4.p1.3.m3.2d">10 , 000</annotation></semantics></math> videos where the number of objects, their shapes and physical properties, such as mass and friction, are not fixed and vary across videos. The <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.5">cubes</span> and <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.6">Multi-dSprites</span> datasets had action variables that accompanied the videos, and were predictive of the way the objects would change from one frame to another. The other datasets were action-free. All models were trained for 100 epochs with five random seeds on the <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.7">cubes, 3-body physics</span> and <span class="ltx_text ltx_font_typewriter" id="S4.p1.3.8">multi-dSprites</span> datasets, and for 125 epochs with three random seeds on the MOVi datasets. Furthermore, to assess the effect of dataset size on our evaluation metrics, we split each dataset up in different sizes.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.5">We evaluated the slotted CSWM and distributed CWM modelsâ€™ prediction abilities by measuring the accuracy with which they could predict novel object trajectories of length <math alttext="n" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_n</annotation></semantics></math> from an unseen evaluation set in an open loop manner. Prediction accuracy was estimated as the percentage of test trajectories where the predicted latent state <math alttext="\tilde{z}_{t+n}" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mover accent="true" id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml"><mi id="S4.p2.2.m2.1.1.2.2" xref="S4.p2.2.m2.1.1.2.2.cmml">z</mi><mo id="S4.p2.2.m2.1.1.2.1" xref="S4.p2.2.m2.1.1.2.1.cmml">~</mo></mover><mrow id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml"><mi id="S4.p2.2.m2.1.1.3.2" xref="S4.p2.2.m2.1.1.3.2.cmml">t</mi><mo id="S4.p2.2.m2.1.1.3.1" xref="S4.p2.2.m2.1.1.3.1.cmml">+</mo><mi id="S4.p2.2.m2.1.1.3.3" xref="S4.p2.2.m2.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><apply id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2"><ci id="S4.p2.2.m2.1.1.2.1.cmml" xref="S4.p2.2.m2.1.1.2.1">~</ci><ci id="S4.p2.2.m2.1.1.2.2.cmml" xref="S4.p2.2.m2.1.1.2.2">ğ‘§</ci></apply><apply id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3"><plus id="S4.p2.2.m2.1.1.3.1.cmml" xref="S4.p2.2.m2.1.1.3.1"></plus><ci id="S4.p2.2.m2.1.1.3.2.cmml" xref="S4.p2.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S4.p2.2.m2.1.1.3.3.cmml" xref="S4.p2.2.m2.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">\tilde{z}_{t+n}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">over~ start_ARG italic_z end_ARG start_POSTSUBSCRIPT italic_t + italic_n end_POSTSUBSCRIPT</annotation></semantics></math> at the end of the trajectory was closest in terms of Euclidean distance to the modelâ€™s representation of the last frame in the trajectory <math alttext="z_{t+n}" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><msub id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">z</mi><mrow id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml"><mi id="S4.p2.3.m3.1.1.3.2" xref="S4.p2.3.m3.1.1.3.2.cmml">t</mi><mo id="S4.p2.3.m3.1.1.3.1" xref="S4.p2.3.m3.1.1.3.1.cmml">+</mo><mi id="S4.p2.3.m3.1.1.3.3" xref="S4.p2.3.m3.1.1.3.3.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">ğ‘§</ci><apply id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3"><plus id="S4.p2.3.m3.1.1.3.1.cmml" xref="S4.p2.3.m3.1.1.3.1"></plus><ci id="S4.p2.3.m3.1.1.3.2.cmml" xref="S4.p2.3.m3.1.1.3.2">ğ‘¡</ci><ci id="S4.p2.3.m3.1.1.3.3.cmml" xref="S4.p2.3.m3.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">z_{t+n}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">italic_z start_POSTSUBSCRIPT italic_t + italic_n end_POSTSUBSCRIPT</annotation></semantics></math> out of 1000 evaluation trajectories. For the <span class="ltx_text ltx_font_typewriter" id="S4.p2.5.1">cubes, 3-body physics</span> and <span class="ltx_text ltx_font_typewriter" id="S4.p2.5.2">Multi-dSprites</span> datasets, we conducted the evaluations with a trajectory length of <math alttext="n=10" class="ltx_Math" display="inline" id="S4.p2.4.m4.1"><semantics id="S4.p2.4.m4.1a"><mrow id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mi id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml">n</mi><mo id="S4.p2.4.m4.1.1.1" xref="S4.p2.4.m4.1.1.1.cmml">=</mo><mn id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><eq id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1"></eq><ci id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2">ğ‘›</ci><cn id="S4.p2.4.m4.1.1.3.cmml" type="integer" xref="S4.p2.4.m4.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">n=10</annotation><annotation encoding="application/x-llamapun" id="S4.p2.4.m4.1d">italic_n = 10</annotation></semantics></math>, and a trajectory length of <math alttext="n=3" class="ltx_Math" display="inline" id="S4.p2.5.m5.1"><semantics id="S4.p2.5.m5.1a"><mrow id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><mi id="S4.p2.5.m5.1.1.2" xref="S4.p2.5.m5.1.1.2.cmml">n</mi><mo id="S4.p2.5.m5.1.1.1" xref="S4.p2.5.m5.1.1.1.cmml">=</mo><mn id="S4.p2.5.m5.1.1.3" xref="S4.p2.5.m5.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><eq id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1.1"></eq><ci id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1.2">ğ‘›</ci><cn id="S4.p2.5.m5.1.1.3.cmml" type="integer" xref="S4.p2.5.m5.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">n=3</annotation><annotation encoding="application/x-llamapun" id="S4.p2.5.m5.1d">italic_n = 3</annotation></semantics></math> in the more complex MOVi datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">To assess object-separability we created evaluation videos for all five datasets. In these evaluation sets only single objects from the respective object domain were changed while all other objects in the scene remained fixed. After training models on each of the datasets, we assessed how well one could linearly classify which object had moved using the protocol described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S3.SS2" title="3.2 Assessing object representations â€£ 3 Methods â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">3.2</span></a>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Object slots are not necessary for learning object dynamics</h3>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S4.F2.1.g1" src="extracted/5906950/figures/prediction_accuracy.png" width="548"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Prediction accuracies for slotted and non-slotted contrastive dynamics models. In all five datasets we see that the CWM is not only competitive, but sometimes outperforms the CSWM when it comes to predicting object dynamics. Scores are averaged over five seeds, with error bars depicting the standard error of the mean.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Evaluating the prediction accuracy of the CSWM and CWM, we observe that object-slots are not necessary for accurately predicting object dynamics. In fact, the CWM models often outperformed their slotted counterparts (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4.F2" title="Figure 2 â€£ 4.1 Object slots are not necessary for learning object dynamics â€£ 4 Experiments â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">2</span></a>). As expected, we see test accuracy generally increase with training set size. This suggests that compositional generalization about objects, the ability to generalize about properties of objects in novel constellations and combinations, does not require explicit object-centric priors as provided by slotted architectures.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Predicting object dynamics improves object separability</h3>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="197" id="S4.F3.1.g1" src="extracted/5906950/figures/object_decodability_contrastive.png" width="548"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Object decoding accuracy as a function of training set size, for contrastive models. CWM representations of objects become more linearly separable with dataset size, despite no architectural components that encourage the formation of object-centric representations. However, contrastive learning without next step prediction (CRL) does not give rise to object-centric representations, suggesting an important role for information provided by dynamic data. Scores are averaged over five seeds (three seeds in the MOVi domains), with error bars depicting standard error of the mean.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="197" id="S4.F4.1.g1" src="extracted/5906950/figures/object_decodability_autoencoder.png" width="548"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Object decoding accuracy as a function of training set size, for auto-encoding models. The dynamic training scheme yields a monotonic increase in object separability with training set size in four out of five datasets. Scores are averaged over five seeds (three seeds in MOVi domains), with error bars depicting standard error of the mean.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2">If models without object-slots can successfully generalize about object dynamics in combinatorially novel scenarios, is this because they too develop separable and compositional representations of objects? We evaluated the degree to which CWMâ€™s representations of objects were linearly separable. Here we observe that representations of objects get more and more separable with a linear decoder as the models are provided with more training examples. In simpler domains like the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.2.1">cubes</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.2.2">3-body physics</span>, the models attain scores close to a <math alttext="100\%" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">100</mn><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1">percent</csymbol><cn id="S4.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">100\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">100 %</annotation></semantics></math> in the largest data setting (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4.F3" title="Figure 3 â€£ 4.2 Predicting object dynamics improves object separability â€£ 4 Experiments â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">3</span></a>). In the more challenging domains like <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p1.2.3">Multi-dSprites</span> and the MOVi environments, where multiple objects are moving and interacting simultaneously, the decodability is lower, but substantially larger than chance at around <math alttext="70\%" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mn id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">70</mn><mo id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1">percent</csymbol><cn id="S4.SS2.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS2.p1.2.m2.1.1.2">70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">70\%</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">70 %</annotation></semantics></math>. For comparison, evaluating randomly initialized networks with the same metric only gives slightly better than chance object decodability scores, meaning that default representations for these models are strongly entangled (see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#A3" title="Appendix C Object decodability baseline â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">C</span></a>). Moreover, we see the same trend where larger training set sizes translate to better decodability. This suggests that, even for complex datasets with multiple interacting, realistically rendered objects, systematic and separable representations of objects can potentially emerge with scale.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">To assess the importance of next-state prediction, we evaluate the object-separability of the CRLâ€™s representations. Surprisingly, the CRL attains separability scores that are close to chance, suggesting that training on dynamic object data offers valuable information for learning composable representations in the contrastive setting.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="321" id="S4.F5.1.g1" src="x2.png" width="760"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Reconstructions and LPIPS similarity for different models on the <span class="ltx_text ltx_font_typewriter" id="S4.F5.4.1">MOVi (simple)</span> and <span class="ltx_text ltx_font_typewriter" id="S4.F5.5.2">MOVi-A</span> datasets. Auto-encoding models without object slots approach or match the reconstruction ability of Slot Attention on novel object configurations in the MOVi domain.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Do these trends hold for models with non-contrastive learning objectives? We evaluated the static and sequential variants of the auto-encoding models. First, we observe a significantly stronger tendency for the <em class="ltx_emph ltx_font_italic" id="S4.SS2.p3.1.1">sequential</em> auto-encoder to develop separable object representations (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4.F4" title="Figure 4 â€£ 4.2 Predicting object dynamics improves object separability â€£ 4 Experiments â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">4</span></a>). This also suggests that providing the models with information about object dynamics in the form of a training signal can facilitate the development of composable object representations. In fact, it is only in the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.2">Multi-dSprites</span> domain that the static autoencoder shows a monotonic increase in object separability with training set size. Comparing auto-encoding objectives to the contrastive objective, we see that object separability was generally lower for auto-encoding models in the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.3">cubes</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p3.1.4">3-body physics</span> datasets.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">Next we assessed the reconstruction quality of the static and sequential auto-encoder, and compared them to Slot Attention. We used the LPIPS <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib54" title="">2018</a>)</cite> perceptual similarity metric to quantify reconstruction fidelity on novel object configurations in the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p4.1.1">MOVi-A</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.p4.1.2">MOVi (simple)</span> datasets. While we see that Slot Attention has a small edge on the distributed models in terms of fidelity, both the static and sequential auto-encoder approach Slot Attention with more data (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S4.F5" title="Figure 5 â€£ 4.2 Predicting object dynamics improves object separability â€£ 4 Experiments â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">5</span></a>). Lastly, the auto-encoder performs better than the sequential auto-encoder on the test set, despite attaining substantially lower object separability scores in the MOVi domain.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>The benefits of partially entangled representations</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Even though unsupervised training on images of objects leads to linearly decodable representations of objects, especially in the dynamic model class, the representations of objects do not ever become completely disjoint (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5.F6" title="Figure 6 â€£ 5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">6</span></a>). That is, the models rely on distributed codes in their latent spaces that often represent distinct objects using overlapping populations of neurons. Yet this does not seem to impact the modelsâ€™ ability to perform compositional generalization, e.g. predict dynamics and reconstruct scenes of novel compositions of objects.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.8">To get a better qualitative understanding for the degree of object separability, we analysed the trained CWMâ€™s and their slotted counterpartsâ€™ representations and the degree to which they showed systematic similarities. We obtained object representations of <math alttext="300" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mn id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><cn id="S5.p2.1.m1.1.1.cmml" type="integer" xref="S5.p2.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">300</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">300</annotation></semantics></math> initial frames <math alttext="x_{t}" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><msub id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml"><mi id="S5.p2.2.m2.1.1.2" xref="S5.p2.2.m2.1.1.2.cmml">x</mi><mi id="S5.p2.2.m2.1.1.3" xref="S5.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><apply id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p2.2.m2.1.1.1.cmml" xref="S5.p2.2.m2.1.1">subscript</csymbol><ci id="S5.p2.2.m2.1.1.2.cmml" xref="S5.p2.2.m2.1.1.2">ğ‘¥</ci><ci id="S5.p2.2.m2.1.1.3.cmml" xref="S5.p2.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and successor frames <math alttext="x_{t+1}" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><msub id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml"><mi id="S5.p2.3.m3.1.1.2" xref="S5.p2.3.m3.1.1.2.cmml">x</mi><mrow id="S5.p2.3.m3.1.1.3" xref="S5.p2.3.m3.1.1.3.cmml"><mi id="S5.p2.3.m3.1.1.3.2" xref="S5.p2.3.m3.1.1.3.2.cmml">t</mi><mo id="S5.p2.3.m3.1.1.3.1" xref="S5.p2.3.m3.1.1.3.1.cmml">+</mo><mn id="S5.p2.3.m3.1.1.3.3" xref="S5.p2.3.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><apply id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.p2.3.m3.1.1.1.cmml" xref="S5.p2.3.m3.1.1">subscript</csymbol><ci id="S5.p2.3.m3.1.1.2.cmml" xref="S5.p2.3.m3.1.1.2">ğ‘¥</ci><apply id="S5.p2.3.m3.1.1.3.cmml" xref="S5.p2.3.m3.1.1.3"><plus id="S5.p2.3.m3.1.1.3.1.cmml" xref="S5.p2.3.m3.1.1.3.1"></plus><ci id="S5.p2.3.m3.1.1.3.2.cmml" xref="S5.p2.3.m3.1.1.3.2">ğ‘¡</ci><cn id="S5.p2.3.m3.1.1.3.3.cmml" type="integer" xref="S5.p2.3.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">x_{t+1}</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">italic_x start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT</annotation></semantics></math> where only one object changed in one aspect from <math alttext="t" class="ltx_Math" display="inline" id="S5.p2.4.m4.1"><semantics id="S5.p2.4.m4.1a"><mi id="S5.p2.4.m4.1.1" xref="S5.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p2.4.m4.1b"><ci id="S5.p2.4.m4.1.1.cmml" xref="S5.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S5.p2.4.m4.1d">italic_t</annotation></semantics></math> to <math alttext="t+1" class="ltx_Math" display="inline" id="S5.p2.5.m5.1"><semantics id="S5.p2.5.m5.1a"><mrow id="S5.p2.5.m5.1.1" xref="S5.p2.5.m5.1.1.cmml"><mi id="S5.p2.5.m5.1.1.2" xref="S5.p2.5.m5.1.1.2.cmml">t</mi><mo id="S5.p2.5.m5.1.1.1" xref="S5.p2.5.m5.1.1.1.cmml">+</mo><mn id="S5.p2.5.m5.1.1.3" xref="S5.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.5.m5.1b"><apply id="S5.p2.5.m5.1.1.cmml" xref="S5.p2.5.m5.1.1"><plus id="S5.p2.5.m5.1.1.1.cmml" xref="S5.p2.5.m5.1.1.1"></plus><ci id="S5.p2.5.m5.1.1.2.cmml" xref="S5.p2.5.m5.1.1.2">ğ‘¡</ci><cn id="S5.p2.5.m5.1.1.3.cmml" type="integer" xref="S5.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.5.m5.1c">t+1</annotation><annotation encoding="application/x-llamapun" id="S5.p2.5.m5.1d">italic_t + 1</annotation></semantics></math> in the <span class="ltx_text ltx_font_typewriter" id="S5.p2.8.1">cubes</span> and <span class="ltx_text ltx_font_typewriter" id="S5.p2.8.2">Multi-dSprites</span> domains. We chose these domains since they had actions that accompanied the dynamics. Earlier, we used the absolute difference between these representations <math alttext="|\Delta|" class="ltx_Math" display="inline" id="S5.p2.6.m6.1"><semantics id="S5.p2.6.m6.1a"><mrow id="S5.p2.6.m6.1.2.2" xref="S5.p2.6.m6.1.2.1.cmml"><mo id="S5.p2.6.m6.1.2.2.1" stretchy="false" xref="S5.p2.6.m6.1.2.1.1.cmml">|</mo><mi id="S5.p2.6.m6.1.1" mathvariant="normal" xref="S5.p2.6.m6.1.1.cmml">Î”</mi><mo id="S5.p2.6.m6.1.2.2.2" stretchy="false" xref="S5.p2.6.m6.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.6.m6.1b"><apply id="S5.p2.6.m6.1.2.1.cmml" xref="S5.p2.6.m6.1.2.2"><abs id="S5.p2.6.m6.1.2.1.1.cmml" xref="S5.p2.6.m6.1.2.2.1"></abs><ci id="S5.p2.6.m6.1.1.cmml" xref="S5.p2.6.m6.1.1">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.6.m6.1c">|\Delta|</annotation><annotation encoding="application/x-llamapun" id="S5.p2.6.m6.1d">| roman_Î” |</annotation></semantics></math> to get a sense of how objects were represented. However, one could also use these absolute differences to get a sense of how <em class="ltx_emph ltx_font_italic" id="S5.p2.8.3">transformations</em> or <em class="ltx_emph ltx_font_italic" id="S5.p2.8.4">actions</em> that acted on objects were represented. For instance, pushing the red cube along the <math alttext="y" class="ltx_Math" display="inline" id="S5.p2.7.m7.1"><semantics id="S5.p2.7.m7.1a"><mi id="S5.p2.7.m7.1.1" xref="S5.p2.7.m7.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S5.p2.7.m7.1b"><ci id="S5.p2.7.m7.1.1.cmml" xref="S5.p2.7.m7.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.7.m7.1c">y</annotation><annotation encoding="application/x-llamapun" id="S5.p2.7.m7.1d">italic_y</annotation></semantics></math>-axis on the grid might cause a similar change in representation as pushing the <em class="ltx_emph ltx_font_italic" id="S5.p2.8.5">blue</em> cube along the <math alttext="y" class="ltx_Math" display="inline" id="S5.p2.8.m8.1"><semantics id="S5.p2.8.m8.1a"><mi id="S5.p2.8.m8.1.1" xref="S5.p2.8.m8.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S5.p2.8.m8.1b"><ci id="S5.p2.8.m8.1.1.cmml" xref="S5.p2.8.m8.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.8.m8.1c">y</annotation><annotation encoding="application/x-llamapun" id="S5.p2.8.m8.1d">italic_y</annotation></semantics></math>-axis, even though the same action is applied to different objects. Analogously, in the <span class="ltx_text ltx_font_typewriter" id="S5.p2.8.6">Multi-dSprites</span> domain, shrinking or rotating the heart sprite could induce similar representational changes as shrinking and rotating the square sprite. We do not expect to see this for slotted models, as they are more likely to represent the properties of different objects in orthogonal sub-spaces.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="606" id="S5.F6.1.g1" src="x3.png" width="761"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="S5.F6.6.1">A</span>: Representational similarity matrices showing cosine similarity of state transitions <math alttext="|\Delta|" class="ltx_Math" display="inline" id="S5.F6.3.m1.1"><semantics id="S5.F6.3.m1.1b"><mrow id="S5.F6.3.m1.1.2.2" xref="S5.F6.3.m1.1.2.1.cmml"><mo id="S5.F6.3.m1.1.2.2.1" stretchy="false" xref="S5.F6.3.m1.1.2.1.1.cmml">|</mo><mi id="S5.F6.3.m1.1.1" mathvariant="normal" xref="S5.F6.3.m1.1.1.cmml">Î”</mi><mo id="S5.F6.3.m1.1.2.2.2" stretchy="false" xref="S5.F6.3.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F6.3.m1.1c"><apply id="S5.F6.3.m1.1.2.1.cmml" xref="S5.F6.3.m1.1.2.2"><abs id="S5.F6.3.m1.1.2.1.1.cmml" xref="S5.F6.3.m1.1.2.2.1"></abs><ci id="S5.F6.3.m1.1.1.cmml" xref="S5.F6.3.m1.1.1">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F6.3.m1.1d">|\Delta|</annotation><annotation encoding="application/x-llamapun" id="S5.F6.3.m1.1e">| roman_Î” |</annotation></semantics></math> for the CSWM and CWM on the cubes (left) and Multi-dSprites datasets (right). The cosine similarities are either ordered according to which object changed, or which action was performend on one the objects. In both cases, clusters are visible, though object clusters are more prominent in the slotted models, and action clusters more prominent in the distributed models. The cosine similarities are averaged over five seeds. <span class="ltx_text ltx_font_bold" id="S5.F6.7.2">B</span>: CSWM intra-object similarity is significantly higher than its intra-action similarity, since object dynamics are isolated in separate subspaces. On the other hand, the CWMâ€™s intra-action similarities are much closer to the intra-object similarities, allowing for richer generalization while preserving object separability.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.p3">
<p class="ltx_p" id="S5.p3.2">For both model types and datasets we obtained the absolute representational change <math alttext="|\Delta|" class="ltx_Math" display="inline" id="S5.p3.1.m1.1"><semantics id="S5.p3.1.m1.1a"><mrow id="S5.p3.1.m1.1.2.2" xref="S5.p3.1.m1.1.2.1.cmml"><mo id="S5.p3.1.m1.1.2.2.1" stretchy="false" xref="S5.p3.1.m1.1.2.1.1.cmml">|</mo><mi id="S5.p3.1.m1.1.1" mathvariant="normal" xref="S5.p3.1.m1.1.1.cmml">Î”</mi><mo id="S5.p3.1.m1.1.2.2.2" stretchy="false" xref="S5.p3.1.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><apply id="S5.p3.1.m1.1.2.1.cmml" xref="S5.p3.1.m1.1.2.2"><abs id="S5.p3.1.m1.1.2.1.1.cmml" xref="S5.p3.1.m1.1.2.2.1"></abs><ci id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">Î”</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">|\Delta|</annotation><annotation encoding="application/x-llamapun" id="S5.p3.1.m1.1d">| roman_Î” |</annotation></semantics></math> for all <math alttext="300" class="ltx_Math" display="inline" id="S5.p3.2.m2.1"><semantics id="S5.p3.2.m2.1a"><mn id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><cn id="S5.p3.2.m2.1.1.cmml" type="integer" xref="S5.p3.2.m2.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">300</annotation><annotation encoding="application/x-llamapun" id="S5.p3.2.m2.1d">300</annotation></semantics></math> frame pairs and computed pairwise similarity matrices using cosine similarity as our metric (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5.F6" title="Figure 6 â€£ 5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">6</span></a>A). These matrices contained information about which <em class="ltx_emph ltx_font_italic" id="S5.p3.2.1">transitions</em> were represented similarly for both distributed and slotted models. First we sorted these similarity matrices according to <em class="ltx_emph ltx_font_italic" id="S5.p3.2.2">which object</em> changed. Here we see five clear object clusters for both models in the <span class="ltx_text ltx_font_typewriter" id="S5.p3.2.3">cubes</span> domain, and four clusters in the <span class="ltx_text ltx_font_typewriter" id="S5.p3.2.4">Multi-dSprites</span> domain, albeit to a lesser degree for the distributed models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Next, we sorted the similarity matrices according to <em class="ltx_emph ltx_font_italic" id="S5.p4.1.1">which transformation or action</em> was applied to the objects. While action clusters are identifiable for the CSWM, intra-action similarities were significantly lower than for the CWM (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5.F6" title="Figure 6 â€£ 5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">6</span></a>B). Representing object properties in a shared representational space not only allows for systematic representations of objects, but can also give rise to systematic representations of <em class="ltx_emph ltx_font_italic" id="S5.p4.1.2">transformations</em> that act on objects.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Distributed and slotted representational alignment increases with more data</h3>
<figure class="ltx_figure" id="S5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="S5.F7.1.g1" src="extracted/5906950/figures/rsa.png" width="548"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Alignment with slot models as determinted by representational similarity alignment (RSA) <cite class="ltx_cite ltx_citemacro_citep">(Kriegeskorte etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib28" title="">2008</a>; Kornblith etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib27" title="">2019</a>)</cite>. The representations of the contrastive model (CWM) become more aligned with itsâ€™ slotted counterpart with more data.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">It has recently been argued that deep neural network modelsâ€™ representations tend to grow more and more similar as training data size and model sizes increase <cite class="ltx_cite ltx_citemacro_citep">(Huh etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib22" title="">2024</a>)</cite>. Do we see a similar convergence in latent representations of scenes composed of objects?</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">We extracted representations from all five seeds and all dataset sizes for CWM and the Auto-encoding models in the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.1">cubes, 3-body physics</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.1.2">Multi-dSprites</span> domains, and compared them to the corresponding representations of the object-centric CSWM models. Next we computed the Euclidean distance between all pairs of representations for all models in the three different domains, and then calculated the degree of correlation between these distance matrices of the different models. If two modelsâ€™ distance matrices were highly positively correlated, they perceived the same pairs of images as similar and dissimilar. In other words, their representations show a high degree of <em class="ltx_emph ltx_font_italic" id="S5.SS1.p2.1.3">alignment</em>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">In all three domains we see that the CWMâ€™s representations grow more and more aligned to those of the CSWM with more data, reaching a score of around <math alttext="0.8" class="ltx_Math" display="inline" id="S5.SS1.p3.1.m1.1"><semantics id="S5.SS1.p3.1.m1.1a"><mn id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><cn id="S5.SS1.p3.1.m1.1.1.cmml" type="float" xref="S5.SS1.p3.1.m1.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">0.8</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.1.m1.1d">0.8</annotation></semantics></math> on average in the largest data setting (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5.F7" title="Figure 7 â€£ 5.1 Distributed and slotted representational alignment increases with more data â€£ 5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">7</span></a>). This indicates that, while alignment can increase substantially with enough data, simple architectural features can leave gaps, as for instance shown in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#S5" title="5 The benefits of partially entangled representations â€£ Next state prediction gives rise to entangled, yet compositional representations of objects"><span class="ltx_text ltx_ref_tag">5</span></a>. We did not observe this trend with the auto-encoder, which showed a significantly lower level of alignment with the CSWM. This suggests that, while data can drive alignment, this has to be paired with an appropriate loss function.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Limitations</h3>
<div class="ltx_para ltx_noindent" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">Our study has focused on unsupervised representation learning models, paired with static and dynamic prediction objectives. However, the space of unsupervised learning techniques is vast. Future work should investigate object-separability in <em class="ltx_emph ltx_font_italic" id="S6.SS1.p1.1.1">self-supervised</em> representation learning settings <cite class="ltx_cite ltx_citemacro_citep">(Grill etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib17" title="">2020</a>; Zbontar etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib53" title="">2021</a>; Schwarzer etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib43" title="">2020</a>)</cite>. Moreover, other model architectures like Vision Transformers <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib9" title="">2020</a>)</cite> are promising, as their attention patterns have been shown to match segmentation masks of natural images of objects <cite class="ltx_cite ltx_citemacro_citep">(Caron etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib5" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">The degree to which these properties scale to naturalistic and real-world video datasets is unclear. A natural next step is to compare larger slotted architectures, such as VideoSAUR <cite class="ltx_cite ltx_citemacro_citep">(Zadaianchuk etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib52" title="">2024</a>)</cite>, to distributed models on naturalistic videos. It is possible that in these complex, real world domains, relying on richer, more entangled representations can facilitate generalization. Lastly, regularization and information bottleneck methods may significantly aid in learning separable object representations as well <cite class="ltx_cite ltx_citemacro_citep">(Alemi etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib1" title="">2016</a>; Shamir etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib45" title="">2010</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Conclusion</h3>
<div class="ltx_para ltx_noindent" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">We have shown that models without object slots can learn object representations that are disentangled enough to be <em class="ltx_emph ltx_font_italic" id="S6.SS2.p1.1.1">separable</em>, but entangled enough to support generalization about <em class="ltx_emph ltx_font_italic" id="S6.SS2.p1.1.2">transformations</em> of objects. Furthermore, training models to predict object dynamics significantly improved object separability. We believe our findings are important because they highlight multiple ways in which a representation can be beneficial for generalization: Slotted models can seamlessly decompose the world into its constituent objects, facilitating compositional generalization. Models with simpler, unconstrained latent spaces can decompose the world in ways that also separate objects, while allowing information about one objectâ€™s dynamics and properties to permeate to others.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank the HCAI lab for valuable feedback and comments throughout the project. This work was supported by the Institute for Human-Centered AI at the Helmholtz Center for Computational Health, the Volkswagen Foundation, the Max Planck Society, the German Federal Ministry of Education and Research (BMBF): TÃ¼bingen AI Center, FKZ: 01IS18039A, and funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germanyâ€™s Excellence Strategyâ€“EXC2064/1â€“390727645.15/18.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alemi etÂ al. (2016)</span>
<span class="ltx_bibblock">
AlexanderÂ A Alemi, Ian Fischer, JoshuaÂ V Dillon, and Kevin Murphy.

</span>
<span class="ltx_bibblock">Deep variational information bottleneck.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:1612.00410</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio etÂ al. (2013)</span>
<span class="ltx_bibblock">
Yoshua Bengio, Aaron Courville, and Pascal Vincent.

</span>
<span class="ltx_bibblock">Representation learning: A review and new perspectives.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">IEEE transactions on pattern analysis and machine intelligence</em>, 35(8):1798â€“1828, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brady etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jack Brady, RolandÂ S Zimmermann, Yash Sharma, Bernhard SchÃ¶lkopf, Julius von KÃ¼gelgen, and Wieland Brendel.

</span>
<span class="ltx_bibblock">Provably learning object-centric representations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2305.14229</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burgess etÂ al. (2018)</span>
<span class="ltx_bibblock">
ChristopherÂ P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner.

</span>
<span class="ltx_bibblock">Understanding disentangling in <math alttext="beta" class="ltx_Math" display="inline" id="bib.bib4.1.m1.1"><semantics id="bib.bib4.1.m1.1a"><mrow id="bib.bib4.1.m1.1.1" xref="bib.bib4.1.m1.1.1.cmml"><mi id="bib.bib4.1.m1.1.1.2" xref="bib.bib4.1.m1.1.1.2.cmml">b</mi><mo id="bib.bib4.1.m1.1.1.1" xref="bib.bib4.1.m1.1.1.1.cmml">â¢</mo><mi id="bib.bib4.1.m1.1.1.3" xref="bib.bib4.1.m1.1.1.3.cmml">e</mi><mo id="bib.bib4.1.m1.1.1.1a" xref="bib.bib4.1.m1.1.1.1.cmml">â¢</mo><mi id="bib.bib4.1.m1.1.1.4" xref="bib.bib4.1.m1.1.1.4.cmml">t</mi><mo id="bib.bib4.1.m1.1.1.1b" xref="bib.bib4.1.m1.1.1.1.cmml">â¢</mo><mi id="bib.bib4.1.m1.1.1.5" xref="bib.bib4.1.m1.1.1.5.cmml">a</mi></mrow><annotation-xml encoding="MathML-Content" id="bib.bib4.1.m1.1b"><apply id="bib.bib4.1.m1.1.1.cmml" xref="bib.bib4.1.m1.1.1"><times id="bib.bib4.1.m1.1.1.1.cmml" xref="bib.bib4.1.m1.1.1.1"></times><ci id="bib.bib4.1.m1.1.1.2.cmml" xref="bib.bib4.1.m1.1.1.2">ğ‘</ci><ci id="bib.bib4.1.m1.1.1.3.cmml" xref="bib.bib4.1.m1.1.1.3">ğ‘’</ci><ci id="bib.bib4.1.m1.1.1.4.cmml" xref="bib.bib4.1.m1.1.1.4">ğ‘¡</ci><ci id="bib.bib4.1.m1.1.1.5.cmml" xref="bib.bib4.1.m1.1.1.5">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib4.1.m1.1c">beta</annotation><annotation encoding="application/x-llamapun" id="bib.bib4.1.m1.1d">italic_b italic_e italic_t italic_a</annotation></semantics></math>-vae.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.2.1">arXiv preprint arXiv:1804.03599</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caron etÂ al. (2021)</span>
<span class="ltx_bibblock">
Mathilde Caron, Hugo Touvron, Ishan Misra, HervÃ© JÃ©gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.

</span>
<span class="ltx_bibblock">Emerging properties in self-supervised vision transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the IEEE/CVF international conference on computer vision</em>, pp.Â  9650â€“9660, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2020)</span>
<span class="ltx_bibblock">
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">A simple framework for contrastive learning of visual representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International conference on machine learning</em>, pp.Â  1597â€“1607. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Demircan etÂ al. (2023)</span>
<span class="ltx_bibblock">
Can Demircan, Tankred Saanum, Leonardo Pettini, Marcel Binz, BlazejÂ M Baczkowski, Paula Kaanders, ChristianÂ F Doeller, MonaÂ M Garvert, and Eric Schulz.

</span>
<span class="ltx_bibblock">Language aligned visual representations predict human behavior in naturalistic learning tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2306.09377</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dittadi etÂ al. (2021)</span>
<span class="ltx_bibblock">
Andrea Dittadi, Samuele Papa, Michele DeÂ Vita, Bernhard SchÃ¶lkopf, Ole Winther, and Francesco Locatello.

</span>
<span class="ltx_bibblock">Generalization and robustness implications in object-centric learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2107.00637</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy etÂ al. (2020)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, etÂ al.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">International Conference on Learning Representations</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elsayed etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gamaleldin Elsayed, Aravindh Mahendran, Sjoerd van Steenkiste, Klaus Greff, MichaelÂ C Mozer, and Thomas Kipf.

</span>
<span class="ltx_bibblock">Savi++: Towards end-to-end object-centric learning from real-world videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in Neural Information Processing Systems</em>, 35:28940â€“28954, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garvert etÂ al. (2023)</span>
<span class="ltx_bibblock">
MonaÂ M Garvert, Tankred Saanum, Eric Schulz, NicolasÂ W Schuck, and ChristianÂ F Doeller.

</span>
<span class="ltx_bibblock">Hippocampal spatio-predictive cognitive maps adaptively guide reward generalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Nature Neuroscience</em>, 26(4):615â€“626, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gelada etÂ al. (2019)</span>
<span class="ltx_bibblock">
Carles Gelada, Saurabh Kumar, Jacob Buckman, Ofir Nachum, and MarcÂ G Bellemare.

</span>
<span class="ltx_bibblock">Deepmdp: Learning continuous latent space models for representation learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">International conference on machine learning</em>, pp.Â  2170â€“2179. PMLR, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodman etÂ al. (2008)</span>
<span class="ltx_bibblock">
NoahÂ D Goodman, JoshuaÂ B Tenenbaum, Jacob Feldman, and ThomasÂ L Griffiths.

</span>
<span class="ltx_bibblock">A rational analysis of rule-based concept learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Cognitive science</em>, 32(1):108â€“154, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Greff etÂ al. (2019)</span>
<span class="ltx_bibblock">
Klaus Greff, RaphaÃ«lÂ Lopez Kaufman, Rishabh Kabra, Nick Watters, Christopher Burgess, Daniel Zoran, Loic Matthey, Matthew Botvinick, and Alexander Lerchner.

</span>
<span class="ltx_bibblock">Multi-object representation learning with iterative variational inference.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">International Conference on Machine Learning</em>, pp.Â  2424â€“2433. PMLR, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Greff etÂ al. (2020)</span>
<span class="ltx_bibblock">
Klaus Greff, Sjoerd VanÂ Steenkiste, and JÃ¼rgen Schmidhuber.

</span>
<span class="ltx_bibblock">On the binding problem in artificial neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2012.05208</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Greff etÂ al. (2022)</span>
<span class="ltx_bibblock">
Klaus Greff, Francois Belletti, Lucas Beyer, Carl Doersch, Yilun Du, Daniel Duckworth, DavidÂ J Fleet, Dan Gnanapragasam, Florian Golemo, Charles Herrmann, Thomas Kipf, Abhijit Kundu, Dmitry Lagun, Issam Laradji, Hsueh-TiÂ (Derek) Liu, Henning Meyer, Yishu Miao, Derek Nowrouzezahrai, Cengiz Oztireli, Etienne Pot, Noha Radwan, Daniel Rebain, Sara Sabour, Mehdi S.Â M. Sajjadi, Matan Sela, Vincent Sitzmann, Austin Stone, Deqing Sun, Suhani Vora, Ziyu Wang, Tianhao Wu, KwangÂ Moo Yi, Fangcheng Zhong, and Andrea Tagliasacchi.

</span>
<span class="ltx_bibblock">Kubric: a scalable dataset generator.

</span>
<span class="ltx_bibblock">2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grill etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jean-Bastien Grill, Florian Strub, Florent AltchÃ©, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo AvilaÂ Pires, Zhaohan Guo, Mohammad GheshlaghiÂ Azar, etÂ al.

</span>
<span class="ltx_bibblock">Bootstrap your own latent-a new approach to self-supervised learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Advances in neural information processing systems</em>, 33:21271â€“21284, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2022)</span>
<span class="ltx_bibblock">
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr DollÃ¡r, and Ross Girshick.

</span>
<span class="ltx_bibblock">Masked autoencoders are scalable vision learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.Â  16000â€“16009, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Higgins etÂ al. (2016)</span>
<span class="ltx_bibblock">
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.

</span>
<span class="ltx_bibblock">beta-vae: Learning basic visual concepts with a constrained variational framework.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International conference on learning representations</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Higgins etÂ al. (2017)</span>
<span class="ltx_bibblock">
Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, ChristopherÂ P Burgess, Matko Bosnjak, Murray Shanahan, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner.

</span>
<span class="ltx_bibblock">Scan: Learning hierarchical compositional visual concepts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:1707.03389</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Higgins etÂ al. (2018)</span>
<span class="ltx_bibblock">
Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende, and Alexander Lerchner.

</span>
<span class="ltx_bibblock">Towards a definition of disentangled representations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:1812.02230</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huh etÂ al. (2024)</span>
<span class="ltx_bibblock">
Minyoung Huh, Brian Cheung, Tongzhou Wang, and Phillip Isola.

</span>
<span class="ltx_bibblock">The platonic representation hypothesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2405.07987</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim &amp; Mnih (2018)</span>
<span class="ltx_bibblock">
Hyunjik Kim and Andriy Mnih.

</span>
<span class="ltx_bibblock">Disentangling by factorising.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">International Conference on Machine Learning</em>, pp.Â  2649â€“2658. PMLR, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma (2013)</span>
<span class="ltx_bibblock">
DiederikÂ P Kingma.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:1312.6114</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Ba (2014)</span>
<span class="ltx_bibblock">
DiederikÂ P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kipf etÂ al. (2019)</span>
<span class="ltx_bibblock">
Thomas Kipf, Elise VanÂ der Pol, and Max Welling.

</span>
<span class="ltx_bibblock">Contrastive learning of structured world models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:1911.12247</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kornblith etÂ al. (2019)</span>
<span class="ltx_bibblock">
Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Similarity of neural network representations revisited.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">International conference on machine learning</em>, pp.Â  3519â€“3529. PMLR, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kriegeskorte etÂ al. (2008)</span>
<span class="ltx_bibblock">
Nikolaus Kriegeskorte, Marieke Mur, and PeterÂ A Bandettini.

</span>
<span class="ltx_bibblock">Representational similarity analysis-connecting the branches of systems neuroscience.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Frontiers in systems neuroscience</em>, 2:249, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lake etÂ al. (2015)</span>
<span class="ltx_bibblock">
BrendenÂ M Lake, Ruslan Salakhutdinov, and JoshuaÂ B Tenenbaum.

</span>
<span class="ltx_bibblock">Human-level concept learning through probabilistic program induction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Science</em>, 350(6266):1332â€“1338, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lake etÂ al. (2017)</span>
<span class="ltx_bibblock">
BrendenÂ M Lake, TomerÂ D Ullman, JoshuaÂ B Tenenbaum, and SamuelÂ J Gershman.

</span>
<span class="ltx_bibblock">Building machines that learn and think like people.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Behavioral and brain sciences</em>, 40:e253, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laskin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Michael Laskin, Aravind Srinivas, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Curl: Contrastive unsupervised representations for reinforcement learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">International conference on machine learning</em>, pp.Â  5639â€“5650. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Locatello etÂ al. (2019)</span>
<span class="ltx_bibblock">
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard SchÃ¶lkopf, and Olivier Bachem.

</span>
<span class="ltx_bibblock">Challenging common assumptions in the unsupervised learning of disentangled representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">international conference on machine learning</em>, pp.Â  4114â€“4124. PMLR, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Locatello etÂ al. (2020a)</span>
<span class="ltx_bibblock">
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar RÃ¤tsch, Sylvain Gelly, Bernhard SchÃ¶lkopf, and Olivier Bachem.

</span>
<span class="ltx_bibblock">A sober look at the unsupervised learning of disentangled representations and their evaluation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">The Journal of Machine Learning Research</em>, 21(1):8629â€“8690, 2020a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Locatello etÂ al. (2020b)</span>
<span class="ltx_bibblock">
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold, Jakob Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf.

</span>
<span class="ltx_bibblock">Object-centric learning with slot attention.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Advances in Neural Information Processing Systems</em>, 33:11525â€“11538, 2020b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lucas etÂ al. (2015)</span>
<span class="ltx_bibblock">
ChristopherÂ G Lucas, ThomasÂ L Griffiths, JosephÂ J Williams, and MichaelÂ L Kalish.

</span>
<span class="ltx_bibblock">A rational model of function learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Psychonomic bulletin &amp; review</em>, 22(5):1193â€“1215, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Matthey etÂ al. (2017)</span>
<span class="ltx_bibblock">
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.

</span>
<span class="ltx_bibblock">dsprites: Disentanglement testing sprites dataset, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nair &amp; Hinton (2010)</span>
<span class="ltx_bibblock">
Vinod Nair and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Rectified linear units improve restricted boltzmann machines.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Icml</em>, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, etÂ al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, JongÂ Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, etÂ al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">International conference on machine learning</em>, pp.Â  8748â€“8763. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ridgeway &amp; Mozer (2018)</span>
<span class="ltx_bibblock">
Karl Ridgeway and MichaelÂ C Mozer.

</span>
<span class="ltx_bibblock">Learning deep disentangled embeddings with the f-statistic loss.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Advances in neural information processing systems</em>, 31, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saanum etÂ al. (2024)</span>
<span class="ltx_bibblock">
Tankred Saanum, Peter Dayan, and Eric Schulz.

</span>
<span class="ltx_bibblock">Predicting the future with simple world models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2401.17835</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">SchulzeÂ Buschoff etÂ al. (2023)</span>
<span class="ltx_bibblock">
LucaÂ M SchulzeÂ Buschoff, Eric Schulz, and Marcel Binz.

</span>
<span class="ltx_bibblock">The acquisition of physical knowledge in generative neural networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 40th international conference on machine learning</em>, pp.Â  30321â€“30341, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schwarzer etÂ al. (2020)</span>
<span class="ltx_bibblock">
Max Schwarzer, Ankesh Anand, Rishab Goel, RÂ Devon Hjelm, Aaron Courville, and Philip Bachman.

</span>
<span class="ltx_bibblock">Data-efficient reinforcement learning with self-predictive representations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2007.05929</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seitzer etÂ al. (2022)</span>
<span class="ltx_bibblock">
Maximilian Seitzer, Max Horn, Andrii Zadaianchuk, Dominik Zietlow, Tianjun Xiao, Carl-Johann Simon-Gabriel, Tong He, Zheng Zhang, Bernhard SchÃ¶lkopf, Thomas Brox, etÂ al.

</span>
<span class="ltx_bibblock">Bridging the gap to real-world object-centric learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2209.14860</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shamir etÂ al. (2010)</span>
<span class="ltx_bibblock">
Ohad Shamir, Sivan Sabato, and Naftali Tishby.

</span>
<span class="ltx_bibblock">Learning and generalization with the information bottleneck.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Theoretical Computer Science</em>, 411(29-30):2696â€“2711, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smola &amp; SchÃ¶lkopf (1998)</span>
<span class="ltx_bibblock">
AlexÂ J Smola and Bernhard SchÃ¶lkopf.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Learning with kernels</em>, volumeÂ 4.

</span>
<span class="ltx_bibblock">Citeseer, 1998.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tenenbaum etÂ al. (2011)</span>
<span class="ltx_bibblock">
JoshuaÂ B Tenenbaum, Charles Kemp, ThomasÂ L Griffiths, and NoahÂ D Goodman.

</span>
<span class="ltx_bibblock">How to grow a mind: Statistics, structure, and abstraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">science</em>, 331(6022):1279â€“1285, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wiedemer etÂ al. (2023)</span>
<span class="ltx_bibblock">
ThaddÃ¤us Wiedemer, Jack Brady, Alexander Panfilov, Attila Juhos, Matthias Bethge, and Wieland Brendel.

</span>
<span class="ltx_bibblock">Provable compositional generalization for object-centric learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2310.05327</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Ziyi Wu, Nikita Dvornik, Klaus Greff, Thomas Kipf, and Animesh Garg.

</span>
<span class="ltx_bibblock">Slotformer: Unsupervised visual dynamics simulation with object-centric models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2210.05861</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yarats etÂ al. (2021a)</span>
<span class="ltx_bibblock">
Denis Yarats, Rob Fergus, Alessandro Lazaric, and Lerrel Pinto.

</span>
<span class="ltx_bibblock">Mastering visual continuous control: Improved data-augmented reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2107.09645</em>, 2021a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yarats etÂ al. (2021b)</span>
<span class="ltx_bibblock">
Denis Yarats, Amy Zhang, Ilya Kostrikov, Brandon Amos, Joelle Pineau, and Rob Fergus.

</span>
<span class="ltx_bibblock">Improving sample efficiency in model-free reinforcement learning from images.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the aaai conference on artificial intelligence</em>, volumeÂ 35, pp.Â  10674â€“10681, 2021b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zadaianchuk etÂ al. (2024)</span>
<span class="ltx_bibblock">
Andrii Zadaianchuk, Maximilian Seitzer, and Georg Martius.

</span>
<span class="ltx_bibblock">Object-centric learning for real-world videos by predicting temporal feature similarities.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zbontar etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jure Zbontar, LiÂ Jing, Ishan Misra, Yann LeCun, and StÃ©phane Deny.

</span>
<span class="ltx_bibblock">Barlow twins: Self-supervised learning via redundancy reduction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">International conference on machine learning</em>, pp.Â  12310â€“12320. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Richard Zhang, Phillip Isola, AlexeiÂ A Efros, Eli Shechtman, and Oliver Wang.

</span>
<span class="ltx_bibblock">The unreasonable effectiveness of deep features as a perceptual metric.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pp.Â  586â€“595, 2018.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Architecture and hyperparameters</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Convolutional Neural Networks</h3>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.3">For our image encoders we rely on a standard CNN architecture used in other works such as <cite class="ltx_cite ltx_citemacro_cite">Yarats etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib51" title="">2021b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib50" title="">a</a>)</cite>. For the <span class="ltx_text ltx_font_typewriter" id="A2.SS1.p1.3.1">3-body physics</span> dataset we stacked two frames, as in <cite class="ltx_cite ltx_citemacro_cite">Kipf etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib26" title="">2019</a>)</cite> to provide information about directional velocity.</p>
<div class="ltx_listing ltx_lstlisting ltx_listing" id="A2.SS1.p1.4" style="background-color:#FFFFFF;">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,aW1wb3J0IHRvcmNoCmZyb20gdG9yY2ggaW1wb3J0IG5uCmVuY29kZXIgID0gIG5uLlNlcXVlbnRpYWwoCiAgICAgICAgICAgICAgICBubi5Db252MmQobnVtX2NoYW5uZWxzLCAzMiwgMywgc3RyaWRlPTIpLAogICAgICAgICAgICAgICAgbm4uUmVMVSgpLAoKICAgICAgICAgICAgICAgIG5uLkNvbnYyZCgzMiwgMzIsIDMsIHN0cmlkZT0xKSwKICAgICAgICAgICAgICAgIG5uLlJlTFUoKSwKCiAgICAgICAgICAgICAgICBubi5Db252MmQoMzIsIDMyLCAzLCBzdHJpZGU9MSksCiAgICAgICAgICAgICAgICBubi5SZUxVKCksCgogICAgICAgICAgICAgICAgbm4uQ29udjJkKDMyLCAzMiwgMywgc3RyaWRlPTEpLAogICAgICAgICAgICAgICAgbm4uUmVMVSgpCiAgICAgICAgICAgICAgICAp">â¬‡</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx1.1" style="color:#8570E0;">import</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.2"> </span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx1.3" style="color:#008080;">torch</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx2.1" style="color:#8570E0;">from</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.2"> </span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx2.3" style="color:#008080;">torch</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.4"> </span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx2.5" style="color:#8570E0;">import</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.6"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx2.7" style="color:#BD0404;">nn</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx3.1" style="color:#008080;">encoder</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.2"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.3">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.4"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx3.5" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.6">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx3.7" style="color:#8570E0;">Sequential</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.8">(</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx4.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx4.4" style="color:#8570E0;">Conv2d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.5">(</span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx4.6" style="color:#008080;">num_channels</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.8"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.9">32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.10"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.11">3,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.12"> </span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx4.13" style="color:#008080;">stride</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.14">=2),</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx5.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx5.4" style="color:#8570E0;">ReLU</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.5">(),</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx7.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx7.4" style="color:#8570E0;">Conv2d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.5">(32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.6"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.7">32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.8"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.9">3,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.10"> </span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx7.11" style="color:#008080;">stride</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.12">=1),</span>
</div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx8.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx8.4" style="color:#8570E0;">ReLU</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.5">(),</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx10.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx10.4" style="color:#8570E0;">Conv2d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.5">(32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.6"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.7">32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.8"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.9">3,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.10"> </span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx10.11" style="color:#008080;">stride</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.12">=1),</span>
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx11.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx11.4" style="color:#8570E0;">ReLU</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.5">(),</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
</div>
<div class="ltx_listingline" id="lstnumberx13">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx13.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx13.4" style="color:#8570E0;">Conv2d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.5">(32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.6"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.7">32,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.8"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.9">3,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.10"> </span><span class="ltx_text ltx_lst_keywords3 ltx_font_typewriter ltx_font_bold" id="lstnumberx13.11" style="color:#008080;">stride</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.12">=1),</span>
</div>
<div class="ltx_listingline" id="lstnumberx14">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.1"> </span><span class="ltx_text ltx_lst_keywords2 ltx_font_typewriter ltx_font_bold" id="lstnumberx14.2" style="color:#BD0404;">nn</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.3">.</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter ltx_font_bold" id="lstnumberx14.4" style="color:#8570E0;">ReLU</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.5">()</span>
</div>
<div class="ltx_listingline" id="lstnumberx15">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.1"> </span><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.2">)</span>
</div>
</div>
<p class="ltx_p" id="A2.SS1.p1.2">This network is followed by an MLP with <math alttext="2" class="ltx_Math" display="inline" id="A2.SS1.p1.1.m1.1"><semantics id="A2.SS1.p1.1.m1.1a"><mn id="A2.SS1.p1.1.m1.1.1" xref="A2.SS1.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.1.m1.1b"><cn id="A2.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A2.SS1.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.1.m1.1d">2</annotation></semantics></math> hidden layers and <math alttext="512" class="ltx_Math" display="inline" id="A2.SS1.p1.2.m2.1"><semantics id="A2.SS1.p1.2.m2.1a"><mn id="A2.SS1.p1.2.m2.1.1" xref="A2.SS1.p1.2.m2.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.2.m2.1b"><cn id="A2.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A2.SS1.p1.2.m2.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.2.m2.1c">512</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.2.m2.1d">512</annotation></semantics></math> hidden units. All models used ReLU <cite class="ltx_cite ltx_citemacro_citep">(Nair &amp; Hinton, <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib37" title="">2010</a>)</cite> activation functions and were optimized using Adam <cite class="ltx_cite ltx_citemacro_cite">Kingma &amp; Ba (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib25" title="">2014</a>)</cite>. The CSWM and Slot Attention models were trained using the hyperparameters and encoder architectures provided in <cite class="ltx_cite ltx_citemacro_cite">Kipf etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib26" title="">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Locatello etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib34" title="">2020b</a>)</cite>, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Transformer</h3>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.6">We use the causal Transformer architecture of GPT-2 <cite class="ltx_cite ltx_citemacro_citep">(Radford etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.04940v1#bib.bib38" title="">2019</a>)</cite>, building on the implementation in the <span class="ltx_text ltx_font_typewriter" id="A2.SS2.p1.6.1">nanoGPT</span> repository<span class="ltx_note ltx_role_footnote" id="footnote1d"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>See <span class="ltx_ref ltx_ref_self">https://github.com/karpathy/nanoGPT</span></span></span></span>. In the slotted dynamics model, the transformer applied attention over the sequence of slots per time-step. Assuming <math alttext="K" class="ltx_Math" display="inline" id="A2.SS2.p1.1.m1.1"><semantics id="A2.SS2.p1.1.m1.1a"><mi id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.1b"><ci id="A2.SS2.p1.1.m1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.1.m1.1d">italic_K</annotation></semantics></math> slots and <math alttext="T" class="ltx_Math" display="inline" id="A2.SS2.p1.2.m2.1"><semantics id="A2.SS2.p1.2.m2.1a"><mi id="A2.SS2.p1.2.m2.1.1" xref="A2.SS2.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.2.m2.1b"><ci id="A2.SS2.p1.2.m2.1.1.cmml" xref="A2.SS2.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.2.m2.1d">italic_T</annotation></semantics></math> time-steps, the transformer applied attention over a sequence of <math alttext="K\times T" class="ltx_Math" display="inline" id="A2.SS2.p1.3.m3.1"><semantics id="A2.SS2.p1.3.m3.1a"><mrow id="A2.SS2.p1.3.m3.1.1" xref="A2.SS2.p1.3.m3.1.1.cmml"><mi id="A2.SS2.p1.3.m3.1.1.2" xref="A2.SS2.p1.3.m3.1.1.2.cmml">K</mi><mo id="A2.SS2.p1.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="A2.SS2.p1.3.m3.1.1.1.cmml">Ã—</mo><mi id="A2.SS2.p1.3.m3.1.1.3" xref="A2.SS2.p1.3.m3.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.3.m3.1b"><apply id="A2.SS2.p1.3.m3.1.1.cmml" xref="A2.SS2.p1.3.m3.1.1"><times id="A2.SS2.p1.3.m3.1.1.1.cmml" xref="A2.SS2.p1.3.m3.1.1.1"></times><ci id="A2.SS2.p1.3.m3.1.1.2.cmml" xref="A2.SS2.p1.3.m3.1.1.2">ğ¾</ci><ci id="A2.SS2.p1.3.m3.1.1.3.cmml" xref="A2.SS2.p1.3.m3.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.3.m3.1c">K\times T</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.3.m3.1d">italic_K Ã— italic_T</annotation></semantics></math> data-points. In <span class="ltx_text ltx_font_typewriter" id="A2.SS2.p1.6.2">MOVi (simple)</span> we trained CSWM with <math alttext="6" class="ltx_Math" display="inline" id="A2.SS2.p1.4.m4.1"><semantics id="A2.SS2.p1.4.m4.1a"><mn id="A2.SS2.p1.4.m4.1.1" xref="A2.SS2.p1.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.4.m4.1b"><cn id="A2.SS2.p1.4.m4.1.1.cmml" type="integer" xref="A2.SS2.p1.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.4.m4.1c">6</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.4.m4.1d">6</annotation></semantics></math> object slots, allowing each slot to model one object plus a background slot. In <span class="ltx_text ltx_font_typewriter" id="A2.SS2.p1.6.3">MOVi-A</span> we trained CSWM with <math alttext="11" class="ltx_Math" display="inline" id="A2.SS2.p1.5.m5.1"><semantics id="A2.SS2.p1.5.m5.1a"><mn id="A2.SS2.p1.5.m5.1.1" xref="A2.SS2.p1.5.m5.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.5.m5.1b"><cn id="A2.SS2.p1.5.m5.1.1.cmml" type="integer" xref="A2.SS2.p1.5.m5.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.5.m5.1c">11</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.5.m5.1d">11</annotation></semantics></math> object slots, allowing for <math alttext="10" class="ltx_Math" display="inline" id="A2.SS2.p1.6.m6.1"><semantics id="A2.SS2.p1.6.m6.1a"><mn id="A2.SS2.p1.6.m6.1.1" xref="A2.SS2.p1.6.m6.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.6.m6.1b"><cn id="A2.SS2.p1.6.m6.1.1.cmml" type="integer" xref="A2.SS2.p1.6.m6.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.6.m6.1c">10</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.6.m6.1d">10</annotation></semantics></math> separate object representations plus the background. The Slot Attention model was trained with the same number of slots as CSWM. The transformers were trained with the following hyperparameters:</p>
</div>
<figure class="ltx_table" id="A2.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Transformer hyperparameters.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top" id="A2.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T1.1.1.1.1.1">Hyperparameter</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T1.1.1.1.2.1">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T1.1.2.1.1">MLP Hidden units</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T1.1.2.1.2">2048</td>
</tr>
<tr class="ltx_tr" id="A2.T1.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T1.1.3.2.1">Transformer blocks</td>
<td class="ltx_td ltx_align_center" id="A2.T1.1.3.2.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T1.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T1.1.4.3.1">Context length</td>
<td class="ltx_td ltx_align_center" id="A2.T1.1.4.3.2">4</td>
</tr>
<tr class="ltx_tr" id="A2.T1.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T1.1.5.4.1">Heads</td>
<td class="ltx_td ltx_align_center" id="A2.T1.1.5.4.2">8</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Hyperparameters</h3>
<div class="ltx_para ltx_noindent" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.1">Below are specific hyperparameters for the different distributed model classes.</p>
</div>
<figure class="ltx_table" id="A2.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Contrastive model hyperparameters.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top" id="A2.T2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T2.2.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T2.2.3.1.1"><span class="ltx_text ltx_font_bold" id="A2.T2.2.3.1.1.1">Hyperparameter</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T2.2.3.1.2"><span class="ltx_text ltx_font_bold" id="A2.T2.2.3.1.2.1">Value</span></td>
</tr>
<tr class="ltx_tr" id="A2.T2.2.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T2.2.4.2.1">Hidden units</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T2.2.4.2.2">512</td>
</tr>
<tr class="ltx_tr" id="A2.T2.2.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T2.2.5.3.1">Batch size</th>
<td class="ltx_td ltx_align_center" id="A2.T2.2.5.3.2">512 (1024 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T2.2.6.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T2.2.6.4.1">MLP hidden layers</th>
<td class="ltx_td ltx_align_center" id="A2.T2.2.6.4.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T2.1.1.1">Latent dimensions <math alttext="|z_{t}|" class="ltx_Math" display="inline" id="A2.T2.1.1.1.m1.1"><semantics id="A2.T2.1.1.1.m1.1a"><mrow id="A2.T2.1.1.1.m1.1.1.1" xref="A2.T2.1.1.1.m1.1.1.2.cmml"><mo id="A2.T2.1.1.1.m1.1.1.1.2" stretchy="false" xref="A2.T2.1.1.1.m1.1.1.2.1.cmml">|</mo><msub id="A2.T2.1.1.1.m1.1.1.1.1" xref="A2.T2.1.1.1.m1.1.1.1.1.cmml"><mi id="A2.T2.1.1.1.m1.1.1.1.1.2" xref="A2.T2.1.1.1.m1.1.1.1.1.2.cmml">z</mi><mi id="A2.T2.1.1.1.m1.1.1.1.1.3" xref="A2.T2.1.1.1.m1.1.1.1.1.3.cmml">t</mi></msub><mo id="A2.T2.1.1.1.m1.1.1.1.3" stretchy="false" xref="A2.T2.1.1.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T2.1.1.1.m1.1b"><apply id="A2.T2.1.1.1.m1.1.1.2.cmml" xref="A2.T2.1.1.1.m1.1.1.1"><abs id="A2.T2.1.1.1.m1.1.1.2.1.cmml" xref="A2.T2.1.1.1.m1.1.1.1.2"></abs><apply id="A2.T2.1.1.1.m1.1.1.1.1.cmml" xref="A2.T2.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A2.T2.1.1.1.m1.1.1.1.1.1.cmml" xref="A2.T2.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="A2.T2.1.1.1.m1.1.1.1.1.2.cmml" xref="A2.T2.1.1.1.m1.1.1.1.1.2">ğ‘§</ci><ci id="A2.T2.1.1.1.m1.1.1.1.1.3.cmml" xref="A2.T2.1.1.1.m1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.1.1.1.m1.1c">|z_{t}|</annotation><annotation encoding="application/x-llamapun" id="A2.T2.1.1.1.m1.1d">| italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT |</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A2.T2.1.1.2">50 (500 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T2.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T2.2.2.1">Margin <math alttext="\lambda" class="ltx_Math" display="inline" id="A2.T2.2.2.1.m1.1"><semantics id="A2.T2.2.2.1.m1.1a"><mi id="A2.T2.2.2.1.m1.1.1" xref="A2.T2.2.2.1.m1.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="A2.T2.2.2.1.m1.1b"><ci id="A2.T2.2.2.1.m1.1.1.cmml" xref="A2.T2.2.2.1.m1.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.T2.2.2.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="A2.T2.2.2.1.m1.1d">italic_Î»</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A2.T2.2.2.2">1 (100 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T2.2.7.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T2.2.7.5.1">Learning rate</th>
<td class="ltx_td ltx_align_center" id="A2.T2.2.7.5.2">0.001 (0.0004 for MOVi)</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="A2.SS3.p2">
<p class="ltx_p" id="A2.SS3.p2.1">For auto-encoding models we use the transpose of the encoder networks presented above. These models are trained with the following hyperparameters:</p>
</div>
<figure class="ltx_table" id="A2.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Auto-encoder hyperparameters.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top" id="A2.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="A2.T3.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T3.1.2.1.1.1">Hyperparameter</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="A2.T3.1.2.1.2.1">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T3.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T3.1.3.1.1">Hidden units</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T3.1.3.1.2">512</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T3.1.4.2.1">Batch size</th>
<td class="ltx_td ltx_align_center" id="A2.T3.1.4.2.2">512 (64 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T3.1.5.3.1">MLP hidden layers</th>
<td class="ltx_td ltx_align_center" id="A2.T3.1.5.3.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T3.1.1.1">Latent dimensions <math alttext="|z_{t}|" class="ltx_Math" display="inline" id="A2.T3.1.1.1.m1.1"><semantics id="A2.T3.1.1.1.m1.1a"><mrow id="A2.T3.1.1.1.m1.1.1.1" xref="A2.T3.1.1.1.m1.1.1.2.cmml"><mo id="A2.T3.1.1.1.m1.1.1.1.2" stretchy="false" xref="A2.T3.1.1.1.m1.1.1.2.1.cmml">|</mo><msub id="A2.T3.1.1.1.m1.1.1.1.1" xref="A2.T3.1.1.1.m1.1.1.1.1.cmml"><mi id="A2.T3.1.1.1.m1.1.1.1.1.2" xref="A2.T3.1.1.1.m1.1.1.1.1.2.cmml">z</mi><mi id="A2.T3.1.1.1.m1.1.1.1.1.3" xref="A2.T3.1.1.1.m1.1.1.1.1.3.cmml">t</mi></msub><mo id="A2.T3.1.1.1.m1.1.1.1.3" stretchy="false" xref="A2.T3.1.1.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T3.1.1.1.m1.1b"><apply id="A2.T3.1.1.1.m1.1.1.2.cmml" xref="A2.T3.1.1.1.m1.1.1.1"><abs id="A2.T3.1.1.1.m1.1.1.2.1.cmml" xref="A2.T3.1.1.1.m1.1.1.1.2"></abs><apply id="A2.T3.1.1.1.m1.1.1.1.1.cmml" xref="A2.T3.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A2.T3.1.1.1.m1.1.1.1.1.1.cmml" xref="A2.T3.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="A2.T3.1.1.1.m1.1.1.1.1.2.cmml" xref="A2.T3.1.1.1.m1.1.1.1.1.2">ğ‘§</ci><ci id="A2.T3.1.1.1.m1.1.1.1.1.3.cmml" xref="A2.T3.1.1.1.m1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T3.1.1.1.m1.1c">|z_{t}|</annotation><annotation encoding="application/x-llamapun" id="A2.T3.1.1.1.m1.1d">| italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT |</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A2.T3.1.1.2">50 (500 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T3.1.6.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T3.1.6.4.1">Learning rate</th>
<td class="ltx_td ltx_align_center" id="A2.T3.1.6.4.2">0.001 (0.0004 for MOVi)</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A2.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Sequential auto-encoder hyperparameters.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_top" id="A2.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T4.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="A2.T4.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T4.1.2.1.1.1">Hyperparameter</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A2.T4.1.2.1.2"><span class="ltx_text ltx_font_bold" id="A2.T4.1.2.1.2.1">Value</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T4.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T4.1.3.1.1">Hidden units</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T4.1.3.1.2">512</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T4.1.4.2.1">Batch size</th>
<td class="ltx_td ltx_align_center" id="A2.T4.1.4.2.2">512 (124 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T4.1.5.3.1">MLP hidden layers</th>
<td class="ltx_td ltx_align_center" id="A2.T4.1.5.3.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T4.1.1.1">Latent dimensions <math alttext="|z_{t}|" class="ltx_Math" display="inline" id="A2.T4.1.1.1.m1.1"><semantics id="A2.T4.1.1.1.m1.1a"><mrow id="A2.T4.1.1.1.m1.1.1.1" xref="A2.T4.1.1.1.m1.1.1.2.cmml"><mo id="A2.T4.1.1.1.m1.1.1.1.2" stretchy="false" xref="A2.T4.1.1.1.m1.1.1.2.1.cmml">|</mo><msub id="A2.T4.1.1.1.m1.1.1.1.1" xref="A2.T4.1.1.1.m1.1.1.1.1.cmml"><mi id="A2.T4.1.1.1.m1.1.1.1.1.2" xref="A2.T4.1.1.1.m1.1.1.1.1.2.cmml">z</mi><mi id="A2.T4.1.1.1.m1.1.1.1.1.3" xref="A2.T4.1.1.1.m1.1.1.1.1.3.cmml">t</mi></msub><mo id="A2.T4.1.1.1.m1.1.1.1.3" stretchy="false" xref="A2.T4.1.1.1.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.1.1.1.m1.1b"><apply id="A2.T4.1.1.1.m1.1.1.2.cmml" xref="A2.T4.1.1.1.m1.1.1.1"><abs id="A2.T4.1.1.1.m1.1.1.2.1.cmml" xref="A2.T4.1.1.1.m1.1.1.1.2"></abs><apply id="A2.T4.1.1.1.m1.1.1.1.1.cmml" xref="A2.T4.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A2.T4.1.1.1.m1.1.1.1.1.1.cmml" xref="A2.T4.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="A2.T4.1.1.1.m1.1.1.1.1.2.cmml" xref="A2.T4.1.1.1.m1.1.1.1.1.2">ğ‘§</ci><ci id="A2.T4.1.1.1.m1.1.1.1.1.3.cmml" xref="A2.T4.1.1.1.m1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.1.1.1.m1.1c">|z_{t}|</annotation><annotation encoding="application/x-llamapun" id="A2.T4.1.1.1.m1.1d">| italic_z start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT |</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="A2.T4.1.1.2">50 (500 for MOVi)</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.6.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A2.T4.1.6.4.1">Learning rate</th>
<td class="ltx_td ltx_align_center" id="A2.T4.1.6.4.2">0.001 (0.0004 for MOVi)</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Object decodability baseline</h2>
<figure class="ltx_figure" id="A3.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="197" id="A3.F8.1.g1" src="extracted/5906950/figures/object_decodability_random.png" width="548"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>When initializing the image encoders randomly, the linear decodability of objects is higher than chance, but substantially lower than the level of trained models. </figcaption>
</figure>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Slotted representations are recoverable from distributed representations</h3>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.2">We assessed the degree to which CWMs representations could be mapped to discrete object slots in the <span class="ltx_text ltx_font_typewriter" id="A3.SS1.p1.2.1">cubes</span> dataset. We trained a slot decoder network with the same architecture as the Slot Attention model to reconstruct images from the representations of CWM. Assuming <math alttext="K" class="ltx_Math" display="inline" id="A3.SS1.p1.1.m1.1"><semantics id="A3.SS1.p1.1.m1.1a"><mi id="A3.SS1.p1.1.m1.1.1" xref="A3.SS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.1.m1.1b"><ci id="A3.SS1.p1.1.m1.1.1.cmml" xref="A3.SS1.p1.1.m1.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.1.m1.1d">italic_K</annotation></semantics></math> object slots, the decoder was trained to reconstruct the original frame as an additive composition of <math alttext="K" class="ltx_Math" display="inline" id="A3.SS1.p1.2.m2.1"><semantics id="A3.SS1.p1.2.m2.1a"><mi id="A3.SS1.p1.2.m2.1.1" xref="A3.SS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A3.SS1.p1.2.m2.1b"><ci id="A3.SS1.p1.2.m2.1.1.cmml" xref="A3.SS1.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.p1.2.m2.1d">italic_K</annotation></semantics></math> individual objects. Crucially, we froze CWMâ€™s encoder, meaning that the decoder could only use information learned through the contrastive dynamic training to recompose the scene. We see that the slot decoder can not only learn to reconstruct the scenes with high fidelity, but also reconstruct the scenes by individually reconstructing the cubes and composing them.</p>
</div>
<figure class="ltx_figure" id="A3.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="195" id="A3.F9.1.g1" src="extracted/5906950/figures/contrastive2slots.png" width="548"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Training a slot-decoder to reconstruct scenes from CWMâ€™s learned representations leads to scene re-compositions that track the original ground truth objects.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Oct  7 11:27:25 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
