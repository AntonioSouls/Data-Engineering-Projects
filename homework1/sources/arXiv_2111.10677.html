<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2111.10677] VideoPose: Estimating 6D object pose from videos</title><meta property="og:description" content="We introduce a simple yet effective algorithm that uses convolutional neural networks to directly estimate object poses from videos.
Our approach leverages the temporal information from a video sequence, and is computa…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="VideoPose: Estimating 6D object pose from videos">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="VideoPose: Estimating 6D object pose from videos">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2111.10677">

<!--Generated on Tue Mar 19 16:47:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">VideoPose: Estimating <math id="id1.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="id1.m1.1b"><mn id="id1.m1.1.1" xref="id1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="id1.m1.1c"><cn type="integer" id="id1.m1.1.1.cmml" xref="id1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="id1.m1.1d">6</annotation></semantics></math>D object pose from videos</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Apoorva Beedu<sup id="id3.2.id1" class="ltx_sup">∗</sup>
<br class="ltx_break">Georgia Institute of Technology
<br class="ltx_break"><span id="id4.3.id2" class="ltx_text ltx_font_typewriter" style="font-size:90%;">abeedu3@gatech.edu</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhile Ren
<br class="ltx_break">Georgia Institute of Technology
<br class="ltx_break"><span id="id5.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">jrenzhile@gmail.com</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Varun Agrawal
<br class="ltx_break">Georgia Institute of Technology
<br class="ltx_break"><span id="id6.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">varunagrawal@gatech.edu</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Irfan Essa
<br class="ltx_break">Georgia Institute of Technology
<br class="ltx_break"><span id="id7.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">irfan@gatech.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">We introduce a simple yet effective algorithm that uses convolutional neural networks to directly estimate object poses from videos.
Our approach leverages the temporal information from a video sequence, and is computationally efficient and robust to support robotic and AR domains. Our proposed network takes a pre-trained 2D object detector as input, and aggregates visual features through a recurrent neural network to make predictions at each frame.
Experimental evaluation on the YCB-Video dataset show that our approach is on par with the state-of-the-art algorithms. Further, with a speed of 30 fps, it is also more efficient than the state-of-the-art, and therefore applicable to a variety of applications that require real-time object pose estimation.
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.4" class="ltx_p">Estimating the <math id="S1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p1.1.m1.1a"><mn id="S1.p1.1.m1.1.1" xref="S1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p1.1.m1.1b"><cn type="integer" id="S1.p1.1.m1.1.1.cmml" xref="S1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.1.m1.1c">3</annotation></semantics></math>D translation and <math id="S1.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S1.p1.2.m2.1a"><mn id="S1.p1.2.m2.1.1" xref="S1.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S1.p1.2.m2.1b"><cn type="integer" id="S1.p1.2.m2.1.1.cmml" xref="S1.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.2.m2.1c">3</annotation></semantics></math>D rotation for every object in an image is a core building block for many applications in robotics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and augmented reality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
The classical solution for such <math id="S1.p1.3.m3.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S1.p1.3.m3.1a"><mn id="S1.p1.3.m3.1.1" xref="S1.p1.3.m3.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S1.p1.3.m3.1b"><cn type="integer" id="S1.p1.3.m3.1.1.cmml" xref="S1.p1.3.m3.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.3.m3.1c">6</annotation></semantics></math>-DOF pose estimation problems utilises a feature point matching mechanism, followed by Perspective-n-Point (PnP) to correct the estimated pose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
However, such approaches fail when objects are texture-less or heavily occluded. Typical ways of refining the <math id="S1.p1.4.m4.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S1.p1.4.m4.1a"><mn id="S1.p1.4.m4.1.1" xref="S1.p1.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S1.p1.4.m4.1b"><cn type="integer" id="S1.p1.4.m4.1.1.cmml" xref="S1.p1.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p1.4.m4.1c">6</annotation></semantics></math>DOF estimation involves using additional depth data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> or post-processing methods like ICP or other deep learning based methods  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, which increase computational costs. Other approaches treat it as a classification problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, resulting in reduced performance as the output space is not continuous.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In robotics, augmented reality, and mobile applications, the input signals are usually videos rather than a single image. Li <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">et al. </em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> utilize multiple frames from different viewing angles to estimate single object poses, which does not work robustly in complex scenes. Wen <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">et al. </em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> and Deng <em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">et al. </em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> use tracking methods to estimate the poses, however these methods do not explicitly exploit the temporal information in the videos. The idea of using more than one frame to estimate object poses has seen limited exploration. As the object poses in a video sequence are implicitly related to camera transformations and do not change abruptly between frames, and as different viewpoints of the objects aid in the pose estimation  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, we believe that modelling a temporal relationship can only help the task.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Motivated by this, in our proposed approach, we utilize a simple CNN-based architecture to extract useful features, and subsequently aggregate the information across consecutive frames using a recurrent neural network (RNN).
The training is performed on the YCB-Video dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> and the approach achieves comparable performance to state-of-the-art approaches, while requiring lower computational costs. We also conduct extensive ablation studies and demonstrate the effectiveness of our network design.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The primary contributions of our paper are:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.2" class="ltx_p">We introduce a simple yet effective neural network architecture for estimating <math id="S1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S1.I1.i1.p1.1.m1.1a"><mn id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><cn type="integer" id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">6</annotation></semantics></math>-DOF object poses from videos. Our system first extracts image features and estimates depth and labels, then use a temporal module to aggregate information across frames and estimate <math id="S1.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S1.I1.i1.p1.2.m2.1a"><mn id="S1.I1.i1.p1.2.m2.1.1" xref="S1.I1.i1.p1.2.m2.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.2.m2.1b"><cn type="integer" id="S1.I1.i1.p1.2.m2.1.1.cmml" xref="S1.I1.i1.p1.2.m2.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.2.m2.1c">6</annotation></semantics></math>-DOF pose of every object in the current frame.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We perform extensive ablation studies on different design choices of the system, and show that using videos, as opposed to using single images, can improve the predictions significantly at an improved computational speed of 30 fps.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2111.10677/assets/pics/Overview.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="370" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of our VideoPose framework for 6D object pose estimation. We use the same encoder as in  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. <math id="S1.F1.2.m1.1" class="ltx_Math" alttext="Z4" display="inline"><semantics id="S1.F1.2.m1.1b"><mrow id="S1.F1.2.m1.1.1" xref="S1.F1.2.m1.1.1.cmml"><mi id="S1.F1.2.m1.1.1.2" xref="S1.F1.2.m1.1.1.2.cmml">Z</mi><mo lspace="0em" rspace="0em" id="S1.F1.2.m1.1.1.1" xref="S1.F1.2.m1.1.1.1.cmml">​</mo><mn id="S1.F1.2.m1.1.1.3" xref="S1.F1.2.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.2.m1.1c"><apply id="S1.F1.2.m1.1.1.cmml" xref="S1.F1.2.m1.1.1"><times id="S1.F1.2.m1.1.1.1.cmml" xref="S1.F1.2.m1.1.1.1"></times><ci id="S1.F1.2.m1.1.1.2.cmml" xref="S1.F1.2.m1.1.1.2">𝑍</ci><cn type="integer" id="S1.F1.2.m1.1.1.3.cmml" xref="S1.F1.2.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.2.m1.1d">Z4</annotation></semantics></math> is the fused features from Fig  <a href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> </figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Estimating the <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">6</annotation></semantics></math>-DOF pose of objects in the scene is a widely studied task. The classical methods either use template-based or feature-based approaches. In template-based methods, a template is matched to different locations in the image, and a similarity score is computed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. However, these template matching methods could fail to make predictions for textureless objects and cluttered environments. In feature based methods, local features are extracted, and correspondence between known 3D objects and local 2D features is established using PnP to recover 6D poses. However, these methods also require sufficient textures on the object to compute local features and face difficulty in generalising well to new environments as they are often trained on small datasets.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Convolutional Neural Networks (CNNs) have proven to be an effective tool in many computer vision tasks. However, they rely heavily on the availability of large-scale annotated datasets. Thus, the YCB-Video dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, T-LESS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, and OccludedLINEMOD dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> were introduced. These datasets have enabled the emergence of novel network designs such as PoseCNN, DPOD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and PVNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. To further increase the amount of accurate annotated data, Trembly <em id="S2.p2.1.1" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> introduced synthetically generated photo-realistic data, which when trained on, gave improved performances on the estimation task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. In this paper, we use the challenging YCB-Video dataset, as it is a popular dataset that serves as a testbed for many recent algorithms.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Building on those datasets, various CNN architectures have been introduced to learn effective representations of objects, and thus estimate accurate 6D poses. Kehl <em id="S2.p3.1.1" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> extends SSD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> by adding an additional viewpoint classification branch to the network. Rad <em id="S2.p3.1.2" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> and Telkin <em id="S2.p3.1.3" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> predict 2D projections from 3D bounding box estimations. However, these methods fail to deal with pose ambiguities and objects under heavy occlusion.
Most notably, PoseCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> uses a Hough voting scheme to vote for the center of the object and then use the bounding boxes to estimate the <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S2.p3.1.m1.1a"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><cn type="integer" id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">3</annotation></semantics></math>D rotation.
To address the problems of heavy occlusions and ambiguities,<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> learn to detect keypoints and then perform PnP. However, these methods also encounter similar problems of pose ambiguities for symmetric and partially occluded objects.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Other methods involve a hybrid approach where the model learns to perform multiple tasks. Song <em id="S2.p4.1.1" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> enforce consistencies among keypoints, edges, and object symmetries. Billings <em id="S2.p4.1.2" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> predict silhouettes of objects along with object poses. There is also a growing trend of designing model agnostic features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> that can handle novel objects. These directions are beyond the scope of our paper, as our goal is to find the best practice for pose estimation in videos when the objects of interest are given.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2111.10677/assets/pics/SimpleRNN.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of a simple temporal RNN network: <math id="S2.F2.4.m1.1" class="ltx_Math" alttext="Z_{t-1}" display="inline"><semantics id="S2.F2.4.m1.1b"><msub id="S2.F2.4.m1.1.1" xref="S2.F2.4.m1.1.1.cmml"><mi id="S2.F2.4.m1.1.1.2" xref="S2.F2.4.m1.1.1.2.cmml">Z</mi><mrow id="S2.F2.4.m1.1.1.3" xref="S2.F2.4.m1.1.1.3.cmml"><mi id="S2.F2.4.m1.1.1.3.2" xref="S2.F2.4.m1.1.1.3.2.cmml">t</mi><mo id="S2.F2.4.m1.1.1.3.1" xref="S2.F2.4.m1.1.1.3.1.cmml">−</mo><mn id="S2.F2.4.m1.1.1.3.3" xref="S2.F2.4.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.F2.4.m1.1c"><apply id="S2.F2.4.m1.1.1.cmml" xref="S2.F2.4.m1.1.1"><csymbol cd="ambiguous" id="S2.F2.4.m1.1.1.1.cmml" xref="S2.F2.4.m1.1.1">subscript</csymbol><ci id="S2.F2.4.m1.1.1.2.cmml" xref="S2.F2.4.m1.1.1.2">𝑍</ci><apply id="S2.F2.4.m1.1.1.3.cmml" xref="S2.F2.4.m1.1.1.3"><minus id="S2.F2.4.m1.1.1.3.1.cmml" xref="S2.F2.4.m1.1.1.3.1"></minus><ci id="S2.F2.4.m1.1.1.3.2.cmml" xref="S2.F2.4.m1.1.1.3.2">𝑡</ci><cn type="integer" id="S2.F2.4.m1.1.1.3.3.cmml" xref="S2.F2.4.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.m1.1d">Z_{t-1}</annotation></semantics></math> is the feature from the previous time-step and <math id="S2.F2.5.m2.1" class="ltx_Math" alttext="Z_{t}" display="inline"><semantics id="S2.F2.5.m2.1b"><msub id="S2.F2.5.m2.1.1" xref="S2.F2.5.m2.1.1.cmml"><mi id="S2.F2.5.m2.1.1.2" xref="S2.F2.5.m2.1.1.2.cmml">Z</mi><mi id="S2.F2.5.m2.1.1.3" xref="S2.F2.5.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.F2.5.m2.1c"><apply id="S2.F2.5.m2.1.1.cmml" xref="S2.F2.5.m2.1.1"><csymbol cd="ambiguous" id="S2.F2.5.m2.1.1.1.cmml" xref="S2.F2.5.m2.1.1">subscript</csymbol><ci id="S2.F2.5.m2.1.1.2.cmml" xref="S2.F2.5.m2.1.1.2">𝑍</ci><ci id="S2.F2.5.m2.1.1.3.cmml" xref="S2.F2.5.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.5.m2.1d">Z_{t}</annotation></semantics></math> is the <math id="S2.F2.6.m3.1" class="ltx_Math" alttext="Z3" display="inline"><semantics id="S2.F2.6.m3.1b"><mrow id="S2.F2.6.m3.1.1" xref="S2.F2.6.m3.1.1.cmml"><mi id="S2.F2.6.m3.1.1.2" xref="S2.F2.6.m3.1.1.2.cmml">Z</mi><mo lspace="0em" rspace="0em" id="S2.F2.6.m3.1.1.1" xref="S2.F2.6.m3.1.1.1.cmml">​</mo><mn id="S2.F2.6.m3.1.1.3" xref="S2.F2.6.m3.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.6.m3.1c"><apply id="S2.F2.6.m3.1.1.cmml" xref="S2.F2.6.m3.1.1"><times id="S2.F2.6.m3.1.1.1.cmml" xref="S2.F2.6.m3.1.1.1"></times><ci id="S2.F2.6.m3.1.1.2.cmml" xref="S2.F2.6.m3.1.1.2">𝑍</ci><cn type="integer" id="S2.F2.6.m3.1.1.3.cmml" xref="S2.F2.6.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.6.m3.1d">Z3</annotation></semantics></math> from Fig <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</figcaption>
</figure>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">To refine the predicted poses, several works use additional depth information and perform a standard ICP algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, or directly learn from RGB-D inputs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
We argue that since the input signals to robots and/or mobile devices are typically video sequences, instead of heavily relying on additional depth information, estimating poses in videos by exploiting the temporal data could already refine the single pose estimations.
A notable work from Deng <em id="S2.p5.1.1" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> introduces the PoseRBPF algorithm that uses particle filters to track objects in video sequences.
This state-of-the-art algorithm provides accurate estimations at a high computational cost.
Wen <em id="S2.p5.1.2" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> also perform tracking, but use synthetic rendering of the object at the previous time-step.
In contrast to the above papers, we show that a simple temporal module that aggregates information across different frames at a high computational speed performs comparable or better than using single frames.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.5" class="ltx_p">Given an RGB video stream, our goal is to estimate the <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p1.1.m1.1a"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><cn type="integer" id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">3</annotation></semantics></math>D rotation and <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p1.2.m2.1a"><mn id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><cn type="integer" id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">3</annotation></semantics></math>D translation of all the objects in every frame of the video.
We assume the system has access to the <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p1.3.m3.1a"><mn id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><cn type="integer" id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">3</annotation></semantics></math>D model of the object. In the following sections, <math id="S3.p1.4.m4.1" class="ltx_Math" alttext="\boldsymbol{R}" display="inline"><semantics id="S3.p1.4.m4.1a"><mi id="S3.p1.4.m4.1.1" xref="S3.p1.4.m4.1.1.cmml">𝑹</mi><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.1b"><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">𝑹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.1c">\boldsymbol{R}</annotation></semantics></math> denotes the rotation matrix with respect to the annotated canonical object pose, and <math id="S3.p1.5.m5.1" class="ltx_Math" alttext="\boldsymbol{T}" display="inline"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">𝑻</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">𝑻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">\boldsymbol{T}</annotation></semantics></math> is the translation from the object to the camera.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Overview of the network</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">Our pipeline, shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> consists of two stages. The first stage corresponds to the feature extractor, depth estimator and semantic label predictor. The second has a temporal RNN and a Regressor.
For extracting image features, we use a simple VGG-<math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="integer" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">16</annotation></semantics></math> model similar to  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, and fine-tune the last <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><cn type="integer" id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">2</annotation></semantics></math> layers to encode features from the depth and semantic prediction tasks.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Pose Estimation relies on accurate object detection. The object detection module is responsible for giving the class-id and Region-Of-Interest (ROI). During training, we use the ground truth bounding box and during testing, we use the predictions and bounding box from the PoseCNN model. This can ideally be replaced with any lightweight feature extraction model such as MobileNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to make the inference faster, but we choose bounding boxes from PoseCNN for fair comparison to prior works.
We learn the depth and semantic segmentation using a Decoder consisting of 3 CNN layers. The final layer from the feature extractor and the penultimate layer of the depth estimator are concatenated and pooled together by using ROI Align <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> which is passed through the temporal layer. We believe that adding depth features can aid in the estimation, when depth information is not available.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Temporal block</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">To use the features from the previous step, we project the image features from the previous step to current step using the camera transformation matrix <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">M</annotation></semantics></math> as <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="M_{t}*\text{feat}*M^{-1}_{t-1}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">M</mi><mi id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">t</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">∗</mo><mtext id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3a.cmml">feat</mtext><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p1.2.m2.1.1.1a" xref="S3.SS2.p1.2.m2.1.1.1.cmml">∗</mo><msubsup id="S3.SS2.p1.2.m2.1.1.4" xref="S3.SS2.p1.2.m2.1.1.4.cmml"><mi id="S3.SS2.p1.2.m2.1.1.4.2.2" xref="S3.SS2.p1.2.m2.1.1.4.2.2.cmml">M</mi><mrow id="S3.SS2.p1.2.m2.1.1.4.3" xref="S3.SS2.p1.2.m2.1.1.4.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.4.3.2" xref="S3.SS2.p1.2.m2.1.1.4.3.2.cmml">t</mi><mo id="S3.SS2.p1.2.m2.1.1.4.3.1" xref="S3.SS2.p1.2.m2.1.1.4.3.1.cmml">−</mo><mn id="S3.SS2.p1.2.m2.1.1.4.3.3" xref="S3.SS2.p1.2.m2.1.1.4.3.3.cmml">1</mn></mrow><mrow id="S3.SS2.p1.2.m2.1.1.4.2.3" xref="S3.SS2.p1.2.m2.1.1.4.2.3.cmml"><mo id="S3.SS2.p1.2.m2.1.1.4.2.3a" xref="S3.SS2.p1.2.m2.1.1.4.2.3.cmml">−</mo><mn id="S3.SS2.p1.2.m2.1.1.4.2.3.2" xref="S3.SS2.p1.2.m2.1.1.4.2.3.2.cmml">1</mn></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><times id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></times><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">𝑀</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3">𝑡</ci></apply><ci id="S3.SS2.p1.2.m2.1.1.3a.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><mtext id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">feat</mtext></ci><apply id="S3.SS2.p1.2.m2.1.1.4.cmml" xref="S3.SS2.p1.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.4.1.cmml" xref="S3.SS2.p1.2.m2.1.1.4">subscript</csymbol><apply id="S3.SS2.p1.2.m2.1.1.4.2.cmml" xref="S3.SS2.p1.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.4.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.4">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.4.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.4.2.2">𝑀</ci><apply id="S3.SS2.p1.2.m2.1.1.4.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.4.2.3"><minus id="S3.SS2.p1.2.m2.1.1.4.2.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.4.2.3"></minus><cn type="integer" id="S3.SS2.p1.2.m2.1.1.4.2.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.4.2.3.2">1</cn></apply></apply><apply id="S3.SS2.p1.2.m2.1.1.4.3.cmml" xref="S3.SS2.p1.2.m2.1.1.4.3"><minus id="S3.SS2.p1.2.m2.1.1.4.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.4.3.1"></minus><ci id="S3.SS2.p1.2.m2.1.1.4.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.4.3.2">𝑡</ci><cn type="integer" id="S3.SS2.p1.2.m2.1.1.4.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.4.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">M_{t}*\text{feat}*M^{-1}_{t-1}</annotation></semantics></math>, which is subsequently concatenated with the features from the current time-step.
This is passed to an Encoder network and its output is divided into two parts – the first 128 layers representing the memory, and the remaining 256 layers representing the fused features.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">The fused features are further passed through a regressor module to estimate the poses, and the memory features are used for the next time-step. We perform the transformation based on the ground truth camera transformations.
This is illustrated in Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:397.5pt;height:402.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-26.1pt,26.4pt) scale(0.883847881135808,0.883847881135808) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">PoseCNN</td>
<td id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">
<table id="S3.T1.1.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1.1.3.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">PoseRBPF</td>
</tr>
<tr id="S3.T1.1.1.1.1.3.1.2" class="ltx_tr">
<td id="S3.T1.1.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(50 particles)</td>
</tr>
</table>
</td>
<td id="S3.T1.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">
<table id="S3.T1.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">VideoPose</td>
</tr>
<tr id="S3.T1.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S3.T1.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(GT BBox)</td>
</tr>
</table>
</td>
<td id="S3.T1.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" colspan="2">
<table id="S3.T1.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T1.1.1.1.1.5.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">VideoPose</td>
</tr>
<tr id="S3.T1.1.1.1.1.5.1.2" class="ltx_tr">
<td id="S3.T1.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(PoseCNN BBox)</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T1.1.1.2.2" class="ltx_tr">
<td id="S3.T1.1.1.2.2.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S3.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
<td id="S3.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S3.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
<td id="S3.T1.1.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S3.T1.1.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
<td id="S3.T1.1.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S3.T1.1.1.2.2.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
</tr>
<tr id="S3.T1.1.1.3.3" class="ltx_tr">
<td id="S3.T1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">002_master_chef_can</td>
<td id="S3.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.9</td>
<td id="S3.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84</td>
<td id="S3.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.3.3.4.1" class="ltx_text ltx_font_bold">56.1</span></td>
<td id="S3.T1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.6</td>
<td id="S3.T1.1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.5</td>
<td id="S3.T1.1.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.0</td>
<td id="S3.T1.1.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.3.3.8.1" class="ltx_text ltx_framed ltx_framed_underline">52.1</span></td>
<td id="S3.T1.1.1.3.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.3.3.9.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">84.3</span></td>
</tr>
<tr id="S3.T1.1.1.4.4" class="ltx_tr">
<td id="S3.T1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">003_cracker_box</td>
<td id="S3.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">51.7</td>
<td id="S3.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.9</td>
<td id="S3.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.4.4.4.1" class="ltx_text ltx_font_bold">73.4</span></td>
<td id="S3.T1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.4.4.5.1" class="ltx_text ltx_font_bold">85.2</span></td>
<td id="S3.T1.1.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9</td>
<td id="S3.T1.1.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.3</td>
<td id="S3.T1.1.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.9</td>
<td id="S3.T1.1.1.4.4.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.6</td>
</tr>
<tr id="S3.T1.1.1.5.5" class="ltx_tr">
<td id="S3.T1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">004_sugar_box</td>
<td id="S3.T1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.6</td>
<td id="S3.T1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84.3</td>
<td id="S3.T1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.5.5.4.1" class="ltx_text ltx_font_bold">73.9</span></td>
<td id="S3.T1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.5.5.5.1" class="ltx_text ltx_font_bold">86.5</span></td>
<td id="S3.T1.1.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.1</td>
<td id="S3.T1.1.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.9</td>
<td id="S3.T1.1.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.2</td>
<td id="S3.T1.1.1.5.5.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.6</td>
</tr>
<tr id="S3.T1.1.1.6.6" class="ltx_tr">
<td id="S3.T1.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">005_tomato_soup_can</td>
<td id="S3.T1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66</td>
<td id="S3.T1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.9</td>
<td id="S3.T1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.6.6.4.1" class="ltx_text ltx_font_bold">71.1</span></td>
<td id="S3.T1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.0</td>
<td id="S3.T1.1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.6</td>
<td id="S3.T1.1.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.3</td>
<td id="S3.T1.1.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.0</td>
<td id="S3.T1.1.1.6.6.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.6.6.9.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">83.2</span></td>
</tr>
<tr id="S3.T1.1.1.7.7" class="ltx_tr">
<td id="S3.T1.1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">006_mustard_bottle</td>
<td id="S3.T1.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79.9</td>
<td id="S3.T1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.7.7.3.1" class="ltx_text ltx_font_bold">90.2</span></td>
<td id="S3.T1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.7.7.4.1" class="ltx_text ltx_font_bold">80.0</span></td>
<td id="S3.T1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.0</td>
<td id="S3.T1.1.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.9</td>
<td id="S3.T1.1.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.9</td>
<td id="S3.T1.1.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.7</td>
<td id="S3.T1.1.1.7.7.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.7</td>
</tr>
<tr id="S3.T1.1.1.8.8" class="ltx_tr">
<td id="S3.T1.1.1.8.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">007_tuna_fish_can</td>
<td id="S3.T1.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.8.8.2.1" class="ltx_text ltx_font_bold">70.4</span></td>
<td id="S3.T1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.8.8.3.1" class="ltx_text ltx_font_bold">87.9</span></td>
<td id="S3.T1.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.1</td>
<td id="S3.T1.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.8</td>
<td id="S3.T1.1.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.1</td>
<td id="S3.T1.1.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.3</td>
<td id="S3.T1.1.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">53.1</td>
<td id="S3.T1.1.1.8.8.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.10</td>
</tr>
<tr id="S3.T1.1.1.9.9" class="ltx_tr">
<td id="S3.T1.1.1.9.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">008_pudding_box</td>
<td id="S3.T1.1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.9.9.2.1" class="ltx_text ltx_font_bold">62.9</span></td>
<td id="S3.T1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.9.9.3.1" class="ltx_text ltx_font_bold">79</span></td>
<td id="S3.T1.1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.8</td>
<td id="S3.T1.1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.2</td>
<td id="S3.T1.1.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.7</td>
<td id="S3.T1.1.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.6</td>
<td id="S3.T1.1.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.9</td>
<td id="S3.T1.1.1.9.9.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.32</td>
</tr>
<tr id="S3.T1.1.1.10.10" class="ltx_tr">
<td id="S3.T1.1.1.10.10.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">009_gelatin_box</td>
<td id="S3.T1.1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.2</td>
<td id="S3.T1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.1</td>
<td id="S3.T1.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.10.10.4.1" class="ltx_text ltx_font_bold">83.1</span></td>
<td id="S3.T1.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.10.10.5.1" class="ltx_text ltx_font_bold">89.7</span></td>
<td id="S3.T1.1.1.10.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76</td>
<td id="S3.T1.1.1.10.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.2</td>
<td id="S3.T1.1.1.10.10.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.8</td>
<td id="S3.T1.1.1.10.10.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84.6</td>
</tr>
<tr id="S3.T1.1.1.11.11" class="ltx_tr">
<td id="S3.T1.1.1.11.11.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">010_potted_meat_can</td>
<td id="S3.T1.1.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.11.11.2.1" class="ltx_text ltx_font_bold">59.6</span></td>
<td id="S3.T1.1.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.11.11.3.1" class="ltx_text ltx_font_bold">78.5</span></td>
<td id="S3.T1.1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.0</td>
<td id="S3.T1.1.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.3</td>
<td id="S3.T1.1.1.11.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">45.9</td>
<td id="S3.T1.1.1.11.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.7</td>
<td id="S3.T1.1.1.11.11.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.4</td>
<td id="S3.T1.1.1.11.11.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.6</td>
</tr>
<tr id="S3.T1.1.1.12.12" class="ltx_tr">
<td id="S3.T1.1.1.12.12.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">011_banana</td>
<td id="S3.T1.1.1.12.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.12.12.2.1" class="ltx_text ltx_font_bold">72.3</span></td>
<td id="S3.T1.1.1.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.12.12.3.1" class="ltx_text ltx_font_bold">85.9</span></td>
<td id="S3.T1.1.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.8</td>
<td id="S3.T1.1.1.12.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.2</td>
<td id="S3.T1.1.1.12.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.6</td>
<td id="S3.T1.1.1.12.12.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.7</td>
<td id="S3.T1.1.1.12.12.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.4</td>
<td id="S3.T1.1.1.12.12.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.1</td>
</tr>
<tr id="S3.T1.1.1.13.13" class="ltx_tr">
<td id="S3.T1.1.1.13.13.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">019_pitcher_base</td>
<td id="S3.T1.1.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52.5</td>
<td id="S3.T1.1.1.13.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.8</td>
<td id="S3.T1.1.1.13.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.13.13.4.1" class="ltx_text ltx_font_bold">74.0</span></td>
<td id="S3.T1.1.1.13.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.13.13.5.1" class="ltx_text ltx_font_bold">87.5</span></td>
<td id="S3.T1.1.1.13.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60</td>
<td id="S3.T1.1.1.13.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.5</td>
<td id="S3.T1.1.1.13.13.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.8</td>
<td id="S3.T1.1.1.13.13.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.13.13.9.1" class="ltx_text ltx_framed ltx_framed_underline">77.30</span></td>
</tr>
<tr id="S3.T1.1.1.14.14" class="ltx_tr">
<td id="S3.T1.1.1.14.14.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">021_bleach_cleanser</td>
<td id="S3.T1.1.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.5</td>
<td id="S3.T1.1.1.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.14.14.3.1" class="ltx_text ltx_font_bold">71.9</span></td>
<td id="S3.T1.1.1.14.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.14.14.4.1" class="ltx_text ltx_font_bold">51.6</span></td>
<td id="S3.T1.1.1.14.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.7</td>
<td id="S3.T1.1.1.14.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41</td>
<td id="S3.T1.1.1.14.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.9</td>
<td id="S3.T1.1.1.14.14.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29.5</td>
<td id="S3.T1.1.1.14.14.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.4</td>
</tr>
<tr id="S3.T1.1.1.15.15" class="ltx_tr">
<td id="S3.T1.1.1.15.15.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">024_bowl</td>
<td id="S3.T1.1.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.5</td>
<td id="S3.T1.1.1.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.7</td>
<td id="S3.T1.1.1.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.15.15.4.1" class="ltx_text ltx_font_bold">26.4</span></td>
<td id="S3.T1.1.1.15.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.15.15.5.1" class="ltx_text ltx_font_bold">88.2</span></td>
<td id="S3.T1.1.1.15.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.5</td>
<td id="S3.T1.1.1.15.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.2</td>
<td id="S3.T1.1.1.15.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.6</td>
<td id="S3.T1.1.1.15.15.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.1</td>
</tr>
<tr id="S3.T1.1.1.16.16" class="ltx_tr">
<td id="S3.T1.1.1.16.16.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">025_mug</td>
<td id="S3.T1.1.1.16.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.7</td>
<td id="S3.T1.1.1.16.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78</td>
<td id="S3.T1.1.1.16.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.16.16.4.1" class="ltx_text ltx_font_bold">67.3</span></td>
<td id="S3.T1.1.1.16.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.16.16.5.1" class="ltx_text ltx_font_bold">83.7</span></td>
<td id="S3.T1.1.1.16.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.3</td>
<td id="S3.T1.1.1.16.16.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.4</td>
<td id="S3.T1.1.1.16.16.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.2</td>
<td id="S3.T1.1.1.16.16.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.9</td>
</tr>
<tr id="S3.T1.1.1.17.17" class="ltx_tr">
<td id="S3.T1.1.1.17.17.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">035_power_drill</td>
<td id="S3.T1.1.1.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.1</td>
<td id="S3.T1.1.1.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.8</td>
<td id="S3.T1.1.1.17.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.17.17.4.1" class="ltx_text ltx_font_bold">64.4</span></td>
<td id="S3.T1.1.1.17.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.17.17.5.1" class="ltx_text ltx_font_bold">80.6</span></td>
<td id="S3.T1.1.1.17.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.4</td>
<td id="S3.T1.1.1.17.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.9</td>
<td id="S3.T1.1.1.17.17.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.5</td>
<td id="S3.T1.1.1.17.17.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.9</td>
</tr>
<tr id="S3.T1.1.1.18.18" class="ltx_tr">
<td id="S3.T1.1.1.18.18.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">036_wood_block</td>
<td id="S3.T1.1.1.18.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.18.18.2.1" class="ltx_text ltx_font_bold">31.8</span></td>
<td id="S3.T1.1.1.18.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.18.18.3.1" class="ltx_text ltx_font_bold">65.8</span></td>
<td id="S3.T1.1.1.18.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0</td>
<td id="S3.T1.1.1.18.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.0</td>
<td id="S3.T1.1.1.18.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S3.T1.1.1.18.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.30</td>
<td id="S3.T1.1.1.18.18.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S3.T1.1.1.18.18.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13.6</td>
</tr>
<tr id="S3.T1.1.1.19.19" class="ltx_tr">
<td id="S3.T1.1.1.19.19.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">037_scissors</td>
<td id="S3.T1.1.1.19.19.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.19.19.2.1" class="ltx_text ltx_font_bold">35.8</span></td>
<td id="S3.T1.1.1.19.19.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.2</td>
<td id="S3.T1.1.1.19.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.6</td>
<td id="S3.T1.1.1.19.19.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">30.9</td>
<td id="S3.T1.1.1.19.19.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29.5</td>
<td id="S3.T1.1.1.19.19.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.5</td>
<td id="S3.T1.1.1.19.19.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">27.9</td>
<td id="S3.T1.1.1.19.19.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.19.19.9.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">72.1</span></td>
</tr>
<tr id="S3.T1.1.1.20.20" class="ltx_tr">
<td id="S3.T1.1.1.20.20.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">040_large_marker</td>
<td id="S3.T1.1.1.20.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.20.20.2.1" class="ltx_text ltx_font_bold">58</span></td>
<td id="S3.T1.1.1.20.20.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.20.20.3.1" class="ltx_text ltx_font_bold">71.4</span></td>
<td id="S3.T1.1.1.20.20.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">45.7</td>
<td id="S3.T1.1.1.20.20.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.1</td>
<td id="S3.T1.1.1.20.20.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.6</td>
<td id="S3.T1.1.1.20.20.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.6</td>
<td id="S3.T1.1.1.20.20.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.5</td>
<td id="S3.T1.1.1.20.20.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.2</td>
</tr>
<tr id="S3.T1.1.1.21.21" class="ltx_tr">
<td id="S3.T1.1.1.21.21.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">051_large_clamp</td>
<td id="S3.T1.1.1.21.21.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">25</td>
<td id="S3.T1.1.1.21.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.9</td>
<td id="S3.T1.1.1.21.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.21.21.4.1" class="ltx_text ltx_font_bold">27.0</span></td>
<td id="S3.T1.1.1.21.21.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.21.21.5.1" class="ltx_text ltx_font_bold">73.3</span></td>
<td id="S3.T1.1.1.21.21.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14</td>
<td id="S3.T1.1.1.21.21.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.5</td>
<td id="S3.T1.1.1.21.21.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.5</td>
<td id="S3.T1.1.1.21.21.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.21.21.9.1" class="ltx_text ltx_framed ltx_framed_underline">55.3</span></td>
</tr>
<tr id="S3.T1.1.1.22.22" class="ltx_tr">
<td id="S3.T1.1.1.22.22.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">052_extra_large_clamp</td>
<td id="S3.T1.1.1.22.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">15.8</td>
<td id="S3.T1.1.1.22.22.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47</td>
<td id="S3.T1.1.1.22.22.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.22.22.4.1" class="ltx_text ltx_font_bold">50.4</span></td>
<td id="S3.T1.1.1.22.22.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.22.22.5.1" class="ltx_text ltx_font_bold">68.7</span></td>
<td id="S3.T1.1.1.22.22.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.3</td>
<td id="S3.T1.1.1.22.22.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.9</td>
<td id="S3.T1.1.1.22.22.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.1</td>
<td id="S3.T1.1.1.22.22.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.0</td>
</tr>
<tr id="S3.T1.1.1.23.23" class="ltx_tr">
<td id="S3.T1.1.1.23.23.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">061_foam_brick</td>
<td id="S3.T1.1.1.23.23.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.4</td>
<td id="S3.T1.1.1.23.23.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.8</td>
<td id="S3.T1.1.1.23.23.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.23.23.4.1" class="ltx_text ltx_font_bold">75.8</span></td>
<td id="S3.T1.1.1.23.23.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.23.23.5.1" class="ltx_text ltx_font_bold">88.4</span></td>
<td id="S3.T1.1.1.23.23.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.1</td>
<td id="S3.T1.1.1.23.23.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.7</td>
<td id="S3.T1.1.1.23.23.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T1.1.1.23.23.8.1" class="ltx_text ltx_framed ltx_framed_underline">40.9</span></td>
<td id="S3.T1.1.1.23.23.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.5</td>
</tr>
<tr id="S3.T1.1.1.24.24" class="ltx_tr">
<td id="S3.T1.1.1.24.24.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt">ALL</td>
<td id="S3.T1.1.1.24.24.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">53.7</td>
<td id="S3.T1.1.1.24.24.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.24.24.3.1" class="ltx_text ltx_font_bold">75.9</span></td>
<td id="S3.T1.1.1.24.24.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.24.24.4.1" class="ltx_text ltx_font_bold">57.1</span></td>
<td id="S3.T1.1.1.24.24.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">74.8</td>
<td id="S3.T1.1.1.24.24.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">39.7</td>
<td id="S3.T1.1.1.24.24.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">71.2</td>
<td id="S3.T1.1.1.24.24.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">35.4</td>
<td id="S3.T1.1.1.24.24.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_tt">68.3</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Quantitative Evaluation of 6D poses (ADD and ADD-S) on the YCB-Video Dataset. <span id="S3.T1.3.1" class="ltx_text ltx_font_bold">Bold</span> values compare between PoseCNN, PoseRBPF and VideoPose using the PoseCNN bbox. Values in green compares the columns with PoseRBPF, underlined values compare with PoseCNN</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>6D Pose Regresssion</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.8" class="ltx_p">The translation vector <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\boldsymbol{T}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">𝑻</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\boldsymbol{T}</annotation></semantics></math> is the object location in the camera coordinate system. A naive way of estimating <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\boldsymbol{T}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mi id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">𝑻</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><ci id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">𝑻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\boldsymbol{T}</annotation></semantics></math> is to directly regress to it. However, doing so cannot handle multiple object instances or generalise well to new objects. To tackle this problem, Xiang <em id="S3.SS3.p1.8.1" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> estimate <math id="S3.SS3.p1.3.m3.1" class="ltx_Math" alttext="\boldsymbol{T}" display="inline"><semantics id="S3.SS3.p1.3.m3.1a"><mi id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml">𝑻</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><ci id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">𝑻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">\boldsymbol{T}</annotation></semantics></math> by localising the <math id="S3.SS3.p1.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS3.p1.4.m4.1a"><mn id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><cn type="integer" id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">2</annotation></semantics></math>D object center in the image and estimating object distance from the camera. Suppose <math id="S3.SS3.p1.5.m5.2" class="ltx_Math" alttext="\mathbf{c}=(c_{x},c_{y})^{T}" display="inline"><semantics id="S3.SS3.p1.5.m5.2a"><mrow id="S3.SS3.p1.5.m5.2.2" xref="S3.SS3.p1.5.m5.2.2.cmml"><mi id="S3.SS3.p1.5.m5.2.2.4" xref="S3.SS3.p1.5.m5.2.2.4.cmml">𝐜</mi><mo id="S3.SS3.p1.5.m5.2.2.3" xref="S3.SS3.p1.5.m5.2.2.3.cmml">=</mo><msup id="S3.SS3.p1.5.m5.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.cmml"><mrow id="S3.SS3.p1.5.m5.2.2.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p1.5.m5.2.2.2.2.2.3" xref="S3.SS3.p1.5.m5.2.2.2.2.3.cmml">(</mo><msub id="S3.SS3.p1.5.m5.1.1.1.1.1.1" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.1.1.1.1.2" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1.2.cmml">c</mi><mi id="S3.SS3.p1.5.m5.1.1.1.1.1.1.3" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.SS3.p1.5.m5.2.2.2.2.2.4" xref="S3.SS3.p1.5.m5.2.2.2.2.3.cmml">,</mo><msub id="S3.SS3.p1.5.m5.2.2.2.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.5.m5.2.2.2.2.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2.2.cmml">c</mi><mi id="S3.SS3.p1.5.m5.2.2.2.2.2.2.3" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2.3.cmml">y</mi></msub><mo stretchy="false" id="S3.SS3.p1.5.m5.2.2.2.2.2.5" xref="S3.SS3.p1.5.m5.2.2.2.2.3.cmml">)</mo></mrow><mi id="S3.SS3.p1.5.m5.2.2.2.4" xref="S3.SS3.p1.5.m5.2.2.2.4.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.2b"><apply id="S3.SS3.p1.5.m5.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2"><eq id="S3.SS3.p1.5.m5.2.2.3.cmml" xref="S3.SS3.p1.5.m5.2.2.3"></eq><ci id="S3.SS3.p1.5.m5.2.2.4.cmml" xref="S3.SS3.p1.5.m5.2.2.4">𝐜</ci><apply id="S3.SS3.p1.5.m5.2.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.2.2.2.3.cmml" xref="S3.SS3.p1.5.m5.2.2.2">superscript</csymbol><interval closure="open" id="S3.SS3.p1.5.m5.2.2.2.2.3.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2"><apply id="S3.SS3.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1.2">𝑐</ci><ci id="S3.SS3.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.1.3">𝑥</ci></apply><apply id="S3.SS3.p1.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.2.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.5.m5.2.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2.2">𝑐</ci><ci id="S3.SS3.p1.5.m5.2.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2.3">𝑦</ci></apply></interval><ci id="S3.SS3.p1.5.m5.2.2.2.4.cmml" xref="S3.SS3.p1.5.m5.2.2.2.4">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.2c">\mathbf{c}=(c_{x},c_{y})^{T}</annotation></semantics></math> are the centers of the object in the frame and <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="T_{z}" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><msub id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml"><mi id="S3.SS3.p1.6.m6.1.1.2" xref="S3.SS3.p1.6.m6.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.6.m6.1.1.3" xref="S3.SS3.p1.6.m6.1.1.3.cmml">z</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><apply id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.6.m6.1.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.6.m6.1.1.2.cmml" xref="S3.SS3.p1.6.m6.1.1.2">𝑇</ci><ci id="S3.SS3.p1.6.m6.1.1.3.cmml" xref="S3.SS3.p1.6.m6.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">T_{z}</annotation></semantics></math> is either learnt or estimated from the depth image, then <math id="S3.SS3.p1.7.m7.1" class="ltx_Math" alttext="T_{x}" display="inline"><semantics id="S3.SS3.p1.7.m7.1a"><msub id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml"><mi id="S3.SS3.p1.7.m7.1.1.2" xref="S3.SS3.p1.7.m7.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.7.m7.1.1.3" xref="S3.SS3.p1.7.m7.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.1b"><apply id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.p1.7.m7.1.1.2">𝑇</ci><ci id="S3.SS3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.p1.7.m7.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.1c">T_{x}</annotation></semantics></math> and <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="T_{y}" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><msub id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml"><mi id="S3.SS3.p1.8.m8.1.1.2" xref="S3.SS3.p1.8.m8.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.8.m8.1.1.3" xref="S3.SS3.p1.8.m8.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><apply id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.8.m8.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.2">𝑇</ci><ci id="S3.SS3.p1.8.m8.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">T_{y}</annotation></semantics></math> can be estimated as:</p>
<table id="A0.EGx1" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\displaystyle\begin{bmatrix}c_{x}\\
c_{y}\end{bmatrix}=\begin{bmatrix}f_{x}\displaystyle\frac{T_{x}}{T_{z}}+p_{x}\\
f_{y}\displaystyle\frac{T_{y}}{T_{z}}+p_{y}\end{bmatrix}," display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.2.cmml"><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.2.1.cmml">[</mo><mtable displaystyle="true" rowspacing="0pt" id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mtr id="S3.E1.m1.1.1.1.1a" xref="S3.E1.m1.1.1.1.1.cmml"><mtd id="S3.E1.m1.1.1.1.1b" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">x</mi></msub></mtd></mtr><mtr id="S3.E1.m1.1.1.1.1c" xref="S3.E1.m1.1.1.1.1.cmml"><mtd id="S3.E1.m1.1.1.1.1d" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.2.1.1" xref="S3.E1.m1.1.1.1.1.2.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.2.1.1.2" xref="S3.E1.m1.1.1.1.1.2.1.1.2.cmml">c</mi><mi id="S3.E1.m1.1.1.1.1.2.1.1.3" xref="S3.E1.m1.1.1.1.1.2.1.1.3.cmml">y</mi></msub></mtd></mtr></mtable><mo id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.2.1.cmml">]</mo></mrow><mo id="S3.E1.m1.3.3.1.1.1" xref="S3.E1.m1.3.3.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.2.cmml"><mo id="S3.E1.m1.2.2.3.1" xref="S3.E1.m1.2.2.2.1.cmml">[</mo><mtable displaystyle="true" rowspacing="0pt" id="S3.E1.m1.2.2.1.1" xref="S3.E1.m1.2.2.1.1.cmml"><mtr id="S3.E1.m1.2.2.1.1a" xref="S3.E1.m1.2.2.1.1.cmml"><mtd id="S3.E1.m1.2.2.1.1b" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.cmml"><msub id="S3.E1.m1.2.2.1.1.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.2.cmml">f</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.cmml">x</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.1.1.1.2.1" xref="S3.E1.m1.2.2.1.1.1.1.1.2.1.cmml">​</mo><mfrac id="S3.E1.m1.2.2.1.1.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.cmml"><msub id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.2.cmml">T</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.3.cmml">x</mi></msub><msub id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.2.cmml">T</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.3.cmml">z</mi></msub></mfrac></mrow><mo id="S3.E1.m1.2.2.1.1.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.1.1.cmml">+</mo><msub id="S3.E1.m1.2.2.1.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.2" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.1.1.1.3.3" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml">x</mi></msub></mrow></mtd></mtr><mtr id="S3.E1.m1.2.2.1.1c" xref="S3.E1.m1.2.2.1.1.cmml"><mtd id="S3.E1.m1.2.2.1.1d" xref="S3.E1.m1.2.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.2.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.cmml"><mrow id="S3.E1.m1.2.2.1.1.2.1.1.2" xref="S3.E1.m1.2.2.1.1.2.1.1.2.cmml"><msub id="S3.E1.m1.2.2.1.1.2.1.1.2.2" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.1.1.2.2.2" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2.2.cmml">f</mi><mi id="S3.E1.m1.2.2.1.1.2.1.1.2.2.3" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2.3.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.1.1.2.1.1.2.1" xref="S3.E1.m1.2.2.1.1.2.1.1.2.1.cmml">​</mo><mfrac id="S3.E1.m1.2.2.1.1.2.1.1.2.3" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.cmml"><msub id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.cmml"><mi id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.2" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.2.cmml">T</mi><mi id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.3" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.3.cmml">y</mi></msub><msub id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.2" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.2.cmml">T</mi><mi id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.3" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.3.cmml">z</mi></msub></mfrac></mrow><mo id="S3.E1.m1.2.2.1.1.2.1.1.1" xref="S3.E1.m1.2.2.1.1.2.1.1.1.cmml">+</mo><msub id="S3.E1.m1.2.2.1.1.2.1.1.3" xref="S3.E1.m1.2.2.1.1.2.1.1.3.cmml"><mi id="S3.E1.m1.2.2.1.1.2.1.1.3.2" xref="S3.E1.m1.2.2.1.1.2.1.1.3.2.cmml">p</mi><mi id="S3.E1.m1.2.2.1.1.2.1.1.3.3" xref="S3.E1.m1.2.2.1.1.2.1.1.3.3.cmml">y</mi></msub></mrow></mtd></mtr></mtable><mo id="S3.E1.m1.2.2.3.2" xref="S3.E1.m1.2.2.2.1.cmml">]</mo></mrow></mrow><mo id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1"><eq id="S3.E1.m1.3.3.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.3"><csymbol cd="latexml" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.3.1">matrix</csymbol><matrix id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><matrixrow id="S3.E1.m1.1.1.1.1a.cmml" xref="S3.E1.m1.1.1.1.1"><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">𝑐</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">𝑥</ci></apply></matrixrow><matrixrow id="S3.E1.m1.1.1.1.1b.cmml" xref="S3.E1.m1.1.1.1.1"><apply id="S3.E1.m1.1.1.1.1.2.1.1.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1.2">𝑐</ci><ci id="S3.E1.m1.1.1.1.1.2.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.2.1.1.3">𝑦</ci></apply></matrixrow></matrix></apply><apply id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2.3"><csymbol cd="latexml" id="S3.E1.m1.2.2.2.1.cmml" xref="S3.E1.m1.2.2.3.1">matrix</csymbol><matrix id="S3.E1.m1.2.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1"><matrixrow id="S3.E1.m1.2.2.1.1a.cmml" xref="S3.E1.m1.2.2.1.1"><apply id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1"><plus id="S3.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2"><times id="S3.E1.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.1"></times><apply id="S3.E1.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.2">𝑓</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.2.3">𝑥</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3"><divide id="S3.E1.m1.2.2.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3"></divide><apply id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.2">𝑇</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.2.3">𝑥</ci></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.2">𝑇</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.2.3.3.3">𝑧</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.2">𝑝</ci><ci id="S3.E1.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.1.3.3">𝑥</ci></apply></apply></matrixrow><matrixrow id="S3.E1.m1.2.2.1.1b.cmml" xref="S3.E1.m1.2.2.1.1"><apply id="S3.E1.m1.2.2.1.1.2.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1"><plus id="S3.E1.m1.2.2.1.1.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.1"></plus><apply id="S3.E1.m1.2.2.1.1.2.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2"><times id="S3.E1.m1.2.2.1.1.2.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.1"></times><apply id="S3.E1.m1.2.2.1.1.2.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.1.2.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.1.2.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2.2">𝑓</ci><ci id="S3.E1.m1.2.2.1.1.2.1.1.2.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.2.3">𝑦</ci></apply><apply id="S3.E1.m1.2.2.1.1.2.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3"><divide id="S3.E1.m1.2.2.1.1.2.1.1.2.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3"></divide><apply id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.2">𝑇</ci><ci id="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.2.3">𝑦</ci></apply><apply id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.2">𝑇</ci><ci id="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.2.3.3.3">𝑧</ci></apply></apply></apply><apply id="S3.E1.m1.2.2.1.1.2.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.2.1.1.3.1.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.3">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.2.1.1.3.2.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.3.2">𝑝</ci><ci id="S3.E1.m1.2.2.1.1.2.1.1.3.3.cmml" xref="S3.E1.m1.2.2.1.1.2.1.1.3.3">𝑦</ci></apply></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\displaystyle\begin{bmatrix}c_{x}\\
c_{y}\end{bmatrix}=\begin{bmatrix}f_{x}\displaystyle\frac{T_{x}}{T_{z}}+p_{x}\\
f_{y}\displaystyle\frac{T_{y}}{T_{z}}+p_{y}\end{bmatrix},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.p1.14" class="ltx_p">where <math id="S3.SS3.p1.9.m1.1" class="ltx_Math" alttext="f_{x}" display="inline"><semantics id="S3.SS3.p1.9.m1.1a"><msub id="S3.SS3.p1.9.m1.1.1" xref="S3.SS3.p1.9.m1.1.1.cmml"><mi id="S3.SS3.p1.9.m1.1.1.2" xref="S3.SS3.p1.9.m1.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.9.m1.1.1.3" xref="S3.SS3.p1.9.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.9.m1.1b"><apply id="S3.SS3.p1.9.m1.1.1.cmml" xref="S3.SS3.p1.9.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.9.m1.1.1.1.cmml" xref="S3.SS3.p1.9.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.9.m1.1.1.2.cmml" xref="S3.SS3.p1.9.m1.1.1.2">𝑓</ci><ci id="S3.SS3.p1.9.m1.1.1.3.cmml" xref="S3.SS3.p1.9.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.9.m1.1c">f_{x}</annotation></semantics></math> and <math id="S3.SS3.p1.10.m2.1" class="ltx_Math" alttext="f_{y}" display="inline"><semantics id="S3.SS3.p1.10.m2.1a"><msub id="S3.SS3.p1.10.m2.1.1" xref="S3.SS3.p1.10.m2.1.1.cmml"><mi id="S3.SS3.p1.10.m2.1.1.2" xref="S3.SS3.p1.10.m2.1.1.2.cmml">f</mi><mi id="S3.SS3.p1.10.m2.1.1.3" xref="S3.SS3.p1.10.m2.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.10.m2.1b"><apply id="S3.SS3.p1.10.m2.1.1.cmml" xref="S3.SS3.p1.10.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.10.m2.1.1.1.cmml" xref="S3.SS3.p1.10.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.10.m2.1.1.2.cmml" xref="S3.SS3.p1.10.m2.1.1.2">𝑓</ci><ci id="S3.SS3.p1.10.m2.1.1.3.cmml" xref="S3.SS3.p1.10.m2.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.10.m2.1c">f_{y}</annotation></semantics></math> are focal lengths and <math id="S3.SS3.p1.11.m3.2" class="ltx_Math" alttext="(\textit{$p_{x}$},\textit{$p_{y}$})^{\textit{T}}" display="inline"><semantics id="S3.SS3.p1.11.m3.2a"><msup id="S3.SS3.p1.11.m3.2.3" xref="S3.SS3.p1.11.m3.2.3.cmml"><mrow id="S3.SS3.p1.11.m3.2.3.2.2" xref="S3.SS3.p1.11.m3.2.3.2.1.cmml"><mo stretchy="false" id="S3.SS3.p1.11.m3.2.3.2.2.1" xref="S3.SS3.p1.11.m3.2.3.2.1.cmml">(</mo><msub id="S3.SS3.p1.11.m3.1.1.1" xref="S3.SS3.p1.11.m3.1.1.1.cmml"><mi id="S3.SS3.p1.11.m3.1.1.1.3" xref="S3.SS3.p1.11.m3.1.1.1.3.cmml">p</mi><mi id="S3.SS3.p1.11.m3.1.1.1.4" xref="S3.SS3.p1.11.m3.1.1.1.4.cmml">x</mi></msub><mo id="S3.SS3.p1.11.m3.2.3.2.2.2" xref="S3.SS3.p1.11.m3.2.3.2.1.cmml">,</mo><msub id="S3.SS3.p1.11.m3.2.2.1" xref="S3.SS3.p1.11.m3.2.2.1.cmml"><mi id="S3.SS3.p1.11.m3.2.2.1.3" xref="S3.SS3.p1.11.m3.2.2.1.3.cmml">p</mi><mi id="S3.SS3.p1.11.m3.2.2.1.4" xref="S3.SS3.p1.11.m3.2.2.1.4.cmml">y</mi></msub><mo stretchy="false" id="S3.SS3.p1.11.m3.2.3.2.2.3" xref="S3.SS3.p1.11.m3.2.3.2.1.cmml">)</mo></mrow><mtext class="ltx_mathvariant_italic" id="S3.SS3.p1.11.m3.2.3.3" xref="S3.SS3.p1.11.m3.2.3.3a.cmml">T</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.11.m3.2b"><apply id="S3.SS3.p1.11.m3.2.3.cmml" xref="S3.SS3.p1.11.m3.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m3.2.3.1.cmml" xref="S3.SS3.p1.11.m3.2.3">superscript</csymbol><interval closure="open" id="S3.SS3.p1.11.m3.2.3.2.1.cmml" xref="S3.SS3.p1.11.m3.2.3.2.2"><apply id="S3.SS3.p1.11.m3.1.1.1.cmml" xref="S3.SS3.p1.11.m3.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m3.1.1.1.2.cmml" xref="S3.SS3.p1.11.m3.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.11.m3.1.1.1.3.cmml" xref="S3.SS3.p1.11.m3.1.1.1.3">𝑝</ci><ci id="S3.SS3.p1.11.m3.1.1.1.4.cmml" xref="S3.SS3.p1.11.m3.1.1.1.4">𝑥</ci></apply><apply id="S3.SS3.p1.11.m3.2.2.1.cmml" xref="S3.SS3.p1.11.m3.2.2.1"><csymbol cd="ambiguous" id="S3.SS3.p1.11.m3.2.2.1.2.cmml" xref="S3.SS3.p1.11.m3.2.2.1">subscript</csymbol><ci id="S3.SS3.p1.11.m3.2.2.1.3.cmml" xref="S3.SS3.p1.11.m3.2.2.1.3">𝑝</ci><ci id="S3.SS3.p1.11.m3.2.2.1.4.cmml" xref="S3.SS3.p1.11.m3.2.2.1.4">𝑦</ci></apply></interval><ci id="S3.SS3.p1.11.m3.2.3.3a.cmml" xref="S3.SS3.p1.11.m3.2.3.3"><mtext class="ltx_mathvariant_italic" mathsize="70%" id="S3.SS3.p1.11.m3.2.3.3.cmml" xref="S3.SS3.p1.11.m3.2.3.3">T</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.11.m3.2c">(\textit{$p_{x}$},\textit{$p_{y}$})^{\textit{T}}</annotation></semantics></math> are principal points. Since we have rough estimates of object locations from the noisy object detection inputs, we train our model to estimate <math id="S3.SS3.p1.12.m4.3" class="ltx_Math" alttext="\Delta c_{x},\Delta c_{y},\text{and}\ T_{z}" display="inline"><semantics id="S3.SS3.p1.12.m4.3a"><mrow id="S3.SS3.p1.12.m4.3.3.3" xref="S3.SS3.p1.12.m4.3.3.4.cmml"><mrow id="S3.SS3.p1.12.m4.1.1.1.1" xref="S3.SS3.p1.12.m4.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.SS3.p1.12.m4.1.1.1.1.2" xref="S3.SS3.p1.12.m4.1.1.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.12.m4.1.1.1.1.1" xref="S3.SS3.p1.12.m4.1.1.1.1.1.cmml">​</mo><msub id="S3.SS3.p1.12.m4.1.1.1.1.3" xref="S3.SS3.p1.12.m4.1.1.1.1.3.cmml"><mi id="S3.SS3.p1.12.m4.1.1.1.1.3.2" xref="S3.SS3.p1.12.m4.1.1.1.1.3.2.cmml">c</mi><mi id="S3.SS3.p1.12.m4.1.1.1.1.3.3" xref="S3.SS3.p1.12.m4.1.1.1.1.3.3.cmml">x</mi></msub></mrow><mo id="S3.SS3.p1.12.m4.3.3.3.4" xref="S3.SS3.p1.12.m4.3.3.4.cmml">,</mo><mrow id="S3.SS3.p1.12.m4.2.2.2.2" xref="S3.SS3.p1.12.m4.2.2.2.2.cmml"><mi mathvariant="normal" id="S3.SS3.p1.12.m4.2.2.2.2.2" xref="S3.SS3.p1.12.m4.2.2.2.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.12.m4.2.2.2.2.1" xref="S3.SS3.p1.12.m4.2.2.2.2.1.cmml">​</mo><msub id="S3.SS3.p1.12.m4.2.2.2.2.3" xref="S3.SS3.p1.12.m4.2.2.2.2.3.cmml"><mi id="S3.SS3.p1.12.m4.2.2.2.2.3.2" xref="S3.SS3.p1.12.m4.2.2.2.2.3.2.cmml">c</mi><mi id="S3.SS3.p1.12.m4.2.2.2.2.3.3" xref="S3.SS3.p1.12.m4.2.2.2.2.3.3.cmml">y</mi></msub></mrow><mo id="S3.SS3.p1.12.m4.3.3.3.5" xref="S3.SS3.p1.12.m4.3.3.4.cmml">,</mo><mrow id="S3.SS3.p1.12.m4.3.3.3.3" xref="S3.SS3.p1.12.m4.3.3.3.3.cmml"><mtext id="S3.SS3.p1.12.m4.3.3.3.3.2" xref="S3.SS3.p1.12.m4.3.3.3.3.2a.cmml">and</mtext><mo lspace="0.500em" rspace="0em" id="S3.SS3.p1.12.m4.3.3.3.3.1" xref="S3.SS3.p1.12.m4.3.3.3.3.1.cmml">​</mo><msub id="S3.SS3.p1.12.m4.3.3.3.3.3" xref="S3.SS3.p1.12.m4.3.3.3.3.3.cmml"><mi id="S3.SS3.p1.12.m4.3.3.3.3.3.2" xref="S3.SS3.p1.12.m4.3.3.3.3.3.2.cmml">T</mi><mi id="S3.SS3.p1.12.m4.3.3.3.3.3.3" xref="S3.SS3.p1.12.m4.3.3.3.3.3.3.cmml">z</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.12.m4.3b"><list id="S3.SS3.p1.12.m4.3.3.4.cmml" xref="S3.SS3.p1.12.m4.3.3.3"><apply id="S3.SS3.p1.12.m4.1.1.1.1.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1"><times id="S3.SS3.p1.12.m4.1.1.1.1.1.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1.1"></times><ci id="S3.SS3.p1.12.m4.1.1.1.1.2.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1.2">Δ</ci><apply id="S3.SS3.p1.12.m4.1.1.1.1.3.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.12.m4.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.12.m4.1.1.1.1.3.2.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1.3.2">𝑐</ci><ci id="S3.SS3.p1.12.m4.1.1.1.1.3.3.cmml" xref="S3.SS3.p1.12.m4.1.1.1.1.3.3">𝑥</ci></apply></apply><apply id="S3.SS3.p1.12.m4.2.2.2.2.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2"><times id="S3.SS3.p1.12.m4.2.2.2.2.1.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2.1"></times><ci id="S3.SS3.p1.12.m4.2.2.2.2.2.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2.2">Δ</ci><apply id="S3.SS3.p1.12.m4.2.2.2.2.3.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS3.p1.12.m4.2.2.2.2.3.1.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2.3">subscript</csymbol><ci id="S3.SS3.p1.12.m4.2.2.2.2.3.2.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2.3.2">𝑐</ci><ci id="S3.SS3.p1.12.m4.2.2.2.2.3.3.cmml" xref="S3.SS3.p1.12.m4.2.2.2.2.3.3">𝑦</ci></apply></apply><apply id="S3.SS3.p1.12.m4.3.3.3.3.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3"><times id="S3.SS3.p1.12.m4.3.3.3.3.1.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.1"></times><ci id="S3.SS3.p1.12.m4.3.3.3.3.2a.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.2"><mtext id="S3.SS3.p1.12.m4.3.3.3.3.2.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.2">and</mtext></ci><apply id="S3.SS3.p1.12.m4.3.3.3.3.3.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.12.m4.3.3.3.3.3.1.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.3">subscript</csymbol><ci id="S3.SS3.p1.12.m4.3.3.3.3.3.2.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.3.2">𝑇</ci><ci id="S3.SS3.p1.12.m4.3.3.3.3.3.3.cmml" xref="S3.SS3.p1.12.m4.3.3.3.3.3.3">𝑧</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.12.m4.3c">\Delta c_{x},\Delta c_{y},\text{and}\ T_{z}</annotation></semantics></math>. We then estimate <math id="S3.SS3.p1.13.m5.1" class="ltx_Math" alttext="T_{x}" display="inline"><semantics id="S3.SS3.p1.13.m5.1a"><msub id="S3.SS3.p1.13.m5.1.1" xref="S3.SS3.p1.13.m5.1.1.cmml"><mi id="S3.SS3.p1.13.m5.1.1.2" xref="S3.SS3.p1.13.m5.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.13.m5.1.1.3" xref="S3.SS3.p1.13.m5.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.13.m5.1b"><apply id="S3.SS3.p1.13.m5.1.1.cmml" xref="S3.SS3.p1.13.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.13.m5.1.1.1.cmml" xref="S3.SS3.p1.13.m5.1.1">subscript</csymbol><ci id="S3.SS3.p1.13.m5.1.1.2.cmml" xref="S3.SS3.p1.13.m5.1.1.2">𝑇</ci><ci id="S3.SS3.p1.13.m5.1.1.3.cmml" xref="S3.SS3.p1.13.m5.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.13.m5.1c">T_{x}</annotation></semantics></math> and <math id="S3.SS3.p1.14.m6.1" class="ltx_Math" alttext="T_{y}" display="inline"><semantics id="S3.SS3.p1.14.m6.1a"><msub id="S3.SS3.p1.14.m6.1.1" xref="S3.SS3.p1.14.m6.1.1.cmml"><mi id="S3.SS3.p1.14.m6.1.1.2" xref="S3.SS3.p1.14.m6.1.1.2.cmml">T</mi><mi id="S3.SS3.p1.14.m6.1.1.3" xref="S3.SS3.p1.14.m6.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.14.m6.1b"><apply id="S3.SS3.p1.14.m6.1.1.cmml" xref="S3.SS3.p1.14.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.14.m6.1.1.1.cmml" xref="S3.SS3.p1.14.m6.1.1">subscript</csymbol><ci id="S3.SS3.p1.14.m6.1.1.2.cmml" xref="S3.SS3.p1.14.m6.1.1.2">𝑇</ci><ci id="S3.SS3.p1.14.m6.1.1.3.cmml" xref="S3.SS3.p1.14.m6.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.14.m6.1c">T_{y}</annotation></semantics></math> using the following equation:</p>
<table id="A0.EGx2" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.3" class="ltx_Math" alttext="\displaystyle\begin{bmatrix}c_{x}+\Delta c_{x}\\
c_{y}+\Delta c_{y}\end{bmatrix}=\begin{bmatrix}f_{x}\displaystyle\frac{T_{x}}{T_{z}}+p_{x}\\
f_{y}\displaystyle\frac{T_{y}}{T_{z}}+p_{y}\end{bmatrix}." display="block"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.3.3.1.1" xref="S3.E2.m1.3.3.1.1.cmml"><mrow id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.2.cmml"><mo id="S3.E2.m1.1.1.3.1" xref="S3.E2.m1.1.1.2.1.cmml">[</mo><mtable displaystyle="true" rowspacing="0pt" id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mtr id="S3.E2.m1.1.1.1.1a" xref="S3.E2.m1.1.1.1.1.cmml"><mtd id="S3.E2.m1.1.1.1.1b" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3.cmml">x</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E2.m1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S3.E2.m1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.3.cmml">x</mi></msub></mrow></mrow></mtd></mtr><mtr id="S3.E2.m1.1.1.1.1c" xref="S3.E2.m1.1.1.1.1.cmml"><mtd id="S3.E2.m1.1.1.1.1d" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.1.1" xref="S3.E2.m1.1.1.1.1.2.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.2.1.1.2" xref="S3.E2.m1.1.1.1.1.2.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.1.1.2.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.2.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.1.1.2.3.cmml">y</mi></msub><mo id="S3.E2.m1.1.1.1.1.2.1.1.1" xref="S3.E2.m1.1.1.1.1.2.1.1.1.cmml">+</mo><mrow id="S3.E2.m1.1.1.1.1.2.1.1.3" xref="S3.E2.m1.1.1.1.1.2.1.1.3.cmml"><mi mathvariant="normal" id="S3.E2.m1.1.1.1.1.2.1.1.3.2" xref="S3.E2.m1.1.1.1.1.2.1.1.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.1.1.3.1" xref="S3.E2.m1.1.1.1.1.2.1.1.3.1.cmml">​</mo><msub id="S3.E2.m1.1.1.1.1.2.1.1.3.3" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3.2.cmml">c</mi><mi id="S3.E2.m1.1.1.1.1.2.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3.3.cmml">y</mi></msub></mrow></mrow></mtd></mtr></mtable><mo id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.2.1.cmml">]</mo></mrow><mo id="S3.E2.m1.3.3.1.1.1" xref="S3.E2.m1.3.3.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.2.cmml"><mo id="S3.E2.m1.2.2.3.1" xref="S3.E2.m1.2.2.2.1.cmml">[</mo><mtable displaystyle="true" rowspacing="0pt" id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mtr id="S3.E2.m1.2.2.1.1a" xref="S3.E2.m1.2.2.1.1.cmml"><mtd id="S3.E2.m1.2.2.1.1b" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"><msub id="S3.E2.m1.2.2.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.2.cmml">f</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.3.cmml">x</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.1.2.1" xref="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml">​</mo><mfrac id="S3.E2.m1.2.2.1.1.1.1.1.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.cmml"><msub id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.2.cmml">T</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.3.cmml">x</mi></msub><msub id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.2.cmml">T</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.3.cmml">z</mi></msub></mfrac></mrow><mo id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml">+</mo><msub id="S3.E2.m1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3.cmml">x</mi></msub></mrow></mtd></mtr><mtr id="S3.E2.m1.2.2.1.1c" xref="S3.E2.m1.2.2.1.1.cmml"><mtd id="S3.E2.m1.2.2.1.1d" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.2.1.1" xref="S3.E2.m1.2.2.1.1.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.1.1.2.cmml"><msub id="S3.E2.m1.2.2.1.1.2.1.1.2.2" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2.2.cmml">f</mi><mi id="S3.E2.m1.2.2.1.1.2.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2.3.cmml">y</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2.1.1.2.1" xref="S3.E2.m1.2.2.1.1.2.1.1.2.1.cmml">​</mo><mfrac id="S3.E2.m1.2.2.1.1.2.1.1.2.3" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.cmml"><msub id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.2" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.2.cmml">T</mi><mi id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.3" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.3.cmml">y</mi></msub><msub id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.2" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.2.cmml">T</mi><mi id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.3" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.3.cmml">z</mi></msub></mfrac></mrow><mo id="S3.E2.m1.2.2.1.1.2.1.1.1" xref="S3.E2.m1.2.2.1.1.2.1.1.1.cmml">+</mo><msub id="S3.E2.m1.2.2.1.1.2.1.1.3" xref="S3.E2.m1.2.2.1.1.2.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.2.1.1.3.2.cmml">p</mi><mi id="S3.E2.m1.2.2.1.1.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.2.1.1.3.3.cmml">y</mi></msub></mrow></mtd></mtr></mtable><mo id="S3.E2.m1.2.2.3.2" xref="S3.E2.m1.2.2.2.1.cmml">]</mo></mrow></mrow><mo lspace="0em" id="S3.E2.m1.3.3.1.2" xref="S3.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.1.1.cmml" xref="S3.E2.m1.3.3.1"><eq id="S3.E2.m1.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1"></eq><apply id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.3"><csymbol cd="latexml" id="S3.E2.m1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.3.1">matrix</csymbol><matrix id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1"><matrixrow id="S3.E2.m1.1.1.1.1a.cmml" xref="S3.E2.m1.1.1.1.1"><apply id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"><plus id="S3.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.2.3">𝑥</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.2">Δ</ci><apply id="S3.E2.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.3.3.3">𝑥</ci></apply></apply></apply></matrixrow><matrixrow id="S3.E2.m1.1.1.1.1b.cmml" xref="S3.E2.m1.1.1.1.1"><apply id="S3.E2.m1.1.1.1.1.2.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1"><plus id="S3.E2.m1.1.1.1.1.2.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.1"></plus><apply id="S3.E2.m1.1.1.1.1.2.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.2.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.2.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.2.3">𝑦</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3"><times id="S3.E2.m1.1.1.1.1.2.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3.1"></times><ci id="S3.E2.m1.1.1.1.1.2.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3.2">Δ</ci><apply id="S3.E2.m1.1.1.1.1.2.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3.2">𝑐</ci><ci id="S3.E2.m1.1.1.1.1.2.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.1.1.3.3.3">𝑦</ci></apply></apply></apply></matrixrow></matrix></apply><apply id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.3"><csymbol cd="latexml" id="S3.E2.m1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.3.1">matrix</csymbol><matrix id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1.1"><matrixrow id="S3.E2.m1.2.2.1.1a.cmml" xref="S3.E2.m1.2.2.1.1"><apply id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><plus id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"></plus><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2"><times id="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.1"></times><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.2">𝑓</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.3">𝑥</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3"><divide id="S3.E2.m1.2.2.1.1.1.1.1.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3"></divide><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.2">𝑇</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.2.3">𝑥</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.2">𝑇</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.3.3.3">𝑧</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3">𝑥</ci></apply></apply></matrixrow><matrixrow id="S3.E2.m1.2.2.1.1b.cmml" xref="S3.E2.m1.2.2.1.1"><apply id="S3.E2.m1.2.2.1.1.2.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1"><plus id="S3.E2.m1.2.2.1.1.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.1"></plus><apply id="S3.E2.m1.2.2.1.1.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2"><times id="S3.E2.m1.2.2.1.1.2.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.1"></times><apply id="S3.E2.m1.2.2.1.1.2.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.1.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2.2">𝑓</ci><ci id="S3.E2.m1.2.2.1.1.2.1.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.2.3">𝑦</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3"><divide id="S3.E2.m1.2.2.1.1.2.1.1.2.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3"></divide><apply id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.2">𝑇</ci><ci id="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.2.3">𝑦</ci></apply><apply id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.2">𝑇</ci><ci id="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.2.3.3.3">𝑧</ci></apply></apply></apply><apply id="S3.E2.m1.2.2.1.1.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.3.2">𝑝</ci><ci id="S3.E2.m1.2.2.1.1.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.2.1.1.3.3">𝑦</ci></apply></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\displaystyle\begin{bmatrix}c_{x}+\Delta c_{x}\\
c_{y}+\Delta c_{y}\end{bmatrix}=\begin{bmatrix}f_{x}\displaystyle\frac{T_{x}}{T_{z}}+p_{x}\\
f_{y}\displaystyle\frac{T_{y}}{T_{z}}+p_{y}\end{bmatrix}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.8" class="ltx_p">The fused features from the temporal module are then fed to 2 disconnected regressor blocks - a <math id="S3.SS3.p2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS3.p2.1.m1.1a"><mn id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><cn type="integer" id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">2</annotation></semantics></math> layer FCN Regressor module, with 512 dimensions and <math id="S3.SS3.p2.2.m2.1" class="ltx_Math" alttext="3\times n" display="inline"><semantics id="S3.SS3.p2.2.m2.1a"><mrow id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mn id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p2.2.m2.1.1.1" xref="S3.SS3.p2.2.m2.1.1.1.cmml">×</mo><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><times id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1.1"></times><cn type="integer" id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">3</cn><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">3\times n</annotation></semantics></math> where <math id="S3.SS3.p2.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS3.p2.3.m3.1a"><mi id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><ci id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">n</annotation></semantics></math> is the number of objects for the translation and a <math id="S3.SS3.p2.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.SS3.p2.4.m4.1a"><mn id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><cn type="integer" id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">2</annotation></semantics></math> layer FCN regressor the temporal features are fed to a regressor with 512 dimensions and <math id="S3.SS3.p2.5.m5.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S3.SS3.p2.5.m5.1a"><mrow id="S3.SS3.p2.5.m5.1b"><mn id="S3.SS3.p2.5.m5.1.1">4</mn><mo lspace="0.222em" id="S3.SS3.p2.5.m5.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S3.SS3.p2.5.m5.1c">4\times</annotation></semantics></math>. We disconnect <math id="S3.SS3.p2.6.m6.2" class="ltx_Math" alttext="T_{x},T_{y}" display="inline"><semantics id="S3.SS3.p2.6.m6.2a"><mrow id="S3.SS3.p2.6.m6.2.2.2" xref="S3.SS3.p2.6.m6.2.2.3.cmml"><msub id="S3.SS3.p2.6.m6.1.1.1.1" xref="S3.SS3.p2.6.m6.1.1.1.1.cmml"><mi id="S3.SS3.p2.6.m6.1.1.1.1.2" xref="S3.SS3.p2.6.m6.1.1.1.1.2.cmml">T</mi><mi id="S3.SS3.p2.6.m6.1.1.1.1.3" xref="S3.SS3.p2.6.m6.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.SS3.p2.6.m6.2.2.2.3" xref="S3.SS3.p2.6.m6.2.2.3.cmml">,</mo><msub id="S3.SS3.p2.6.m6.2.2.2.2" xref="S3.SS3.p2.6.m6.2.2.2.2.cmml"><mi id="S3.SS3.p2.6.m6.2.2.2.2.2" xref="S3.SS3.p2.6.m6.2.2.2.2.2.cmml">T</mi><mi id="S3.SS3.p2.6.m6.2.2.2.2.3" xref="S3.SS3.p2.6.m6.2.2.2.2.3.cmml">y</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.6.m6.2b"><list id="S3.SS3.p2.6.m6.2.2.3.cmml" xref="S3.SS3.p2.6.m6.2.2.2"><apply id="S3.SS3.p2.6.m6.1.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.1.1.1.1.1.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p2.6.m6.1.1.1.1.2.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.2">𝑇</ci><ci id="S3.SS3.p2.6.m6.1.1.1.1.3.cmml" xref="S3.SS3.p2.6.m6.1.1.1.1.3">𝑥</ci></apply><apply id="S3.SS3.p2.6.m6.2.2.2.2.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p2.6.m6.2.2.2.2.1.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p2.6.m6.2.2.2.2.2.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.2">𝑇</ci><ci id="S3.SS3.p2.6.m6.2.2.2.2.3.cmml" xref="S3.SS3.p2.6.m6.2.2.2.2.3">𝑦</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.6.m6.2c">T_{x},T_{y}</annotation></semantics></math> and <math id="S3.SS3.p2.7.m7.1" class="ltx_Math" alttext="T_{z}" display="inline"><semantics id="S3.SS3.p2.7.m7.1a"><msub id="S3.SS3.p2.7.m7.1.1" xref="S3.SS3.p2.7.m7.1.1.cmml"><mi id="S3.SS3.p2.7.m7.1.1.2" xref="S3.SS3.p2.7.m7.1.1.2.cmml">T</mi><mi id="S3.SS3.p2.7.m7.1.1.3" xref="S3.SS3.p2.7.m7.1.1.3.cmml">z</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.7.m7.1b"><apply id="S3.SS3.p2.7.m7.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.7.m7.1.1.1.cmml" xref="S3.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.p2.7.m7.1.1.2.cmml" xref="S3.SS3.p2.7.m7.1.1.2">𝑇</ci><ci id="S3.SS3.p2.7.m7.1.1.3.cmml" xref="S3.SS3.p2.7.m7.1.1.3">𝑧</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.7.m7.1c">T_{z}</annotation></semantics></math> by training two separate linear layers to account for the different dimensions learnt.
Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, we represent the rotation <math id="S3.SS3.p2.8.m8.1" class="ltx_Math" alttext="\boldsymbol{R}" display="inline"><semantics id="S3.SS3.p2.8.m8.1a"><mi id="S3.SS3.p2.8.m8.1.1" xref="S3.SS3.p2.8.m8.1.1.cmml">𝑹</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.8.m8.1b"><ci id="S3.SS3.p2.8.m8.1.1.cmml" xref="S3.SS3.p2.8.m8.1.1">𝑹</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.8.m8.1c">\boldsymbol{R}</annotation></semantics></math> using quaternions.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Training Strategy</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.4" class="ltx_p">We use the <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="L_{1}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">L</mi><mn id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">𝐿</ci><cn type="integer" id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">L_{1}</annotation></semantics></math> loss to learn depth (<math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="L_{\text{depth}}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">L</mi><mtext id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3a.cmml">depth</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">𝐿</ci><ci id="S3.SS4.p1.2.m2.1.1.3a.cmml" xref="S3.SS4.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">depth</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">L_{\text{depth}}</annotation></semantics></math>), and cross entropy loss for semantic segmentation (<math id="S3.SS4.p1.3.m3.1" class="ltx_Math" alttext="L_{\text{label}}" display="inline"><semantics id="S3.SS4.p1.3.m3.1a"><msub id="S3.SS4.p1.3.m3.1.1" xref="S3.SS4.p1.3.m3.1.1.cmml"><mi id="S3.SS4.p1.3.m3.1.1.2" xref="S3.SS4.p1.3.m3.1.1.2.cmml">L</mi><mtext id="S3.SS4.p1.3.m3.1.1.3" xref="S3.SS4.p1.3.m3.1.1.3a.cmml">label</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m3.1b"><apply id="S3.SS4.p1.3.m3.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m3.1.1.1.cmml" xref="S3.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.p1.3.m3.1.1.2.cmml" xref="S3.SS4.p1.3.m3.1.1.2">𝐿</ci><ci id="S3.SS4.p1.3.m3.1.1.3a.cmml" xref="S3.SS4.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS4.p1.3.m3.1.1.3.cmml" xref="S3.SS4.p1.3.m3.1.1.3">label</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m3.1c">L_{\text{label}}</annotation></semantics></math>).
The pose estimation loss is obtained by projecting the <math id="S3.SS4.p1.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS4.p1.4.m4.1a"><mn id="S3.SS4.p1.4.m4.1.1" xref="S3.SS4.p1.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m4.1b"><cn type="integer" id="S3.SS4.p1.4.m4.1.1.cmml" xref="S3.SS4.p1.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m4.1c">3</annotation></semantics></math>D points using the estimated and ground truth pose, and then computing their distance:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.5" class="ltx_Math" alttext="L_{\text{pose}}(\mathbf{\widetilde{q}},\mathbf{q})=\frac{1}{m}\sum\limits_{x\in M}||(R(\mathbf{\widetilde{q}})x+\mathbf{\widetilde{t}})-(R(\textbf{q})x+\mathbf{t})||^{2}," display="block"><semantics id="S3.E3.m1.5a"><mrow id="S3.E3.m1.5.5.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1" xref="S3.E3.m1.5.5.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.3" xref="S3.E3.m1.5.5.1.1.3.cmml"><msub id="S3.E3.m1.5.5.1.1.3.2" xref="S3.E3.m1.5.5.1.1.3.2.cmml"><mi id="S3.E3.m1.5.5.1.1.3.2.2" xref="S3.E3.m1.5.5.1.1.3.2.2.cmml">L</mi><mtext id="S3.E3.m1.5.5.1.1.3.2.3" xref="S3.E3.m1.5.5.1.1.3.2.3a.cmml">pose</mtext></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.3.1" xref="S3.E3.m1.5.5.1.1.3.1.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.3.3.2" xref="S3.E3.m1.5.5.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.3.2.1" xref="S3.E3.m1.5.5.1.1.3.3.1.cmml">(</mo><mover accent="true" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mi id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">𝐪</mi><mo id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml">~</mo></mover><mo id="S3.E3.m1.5.5.1.1.3.3.2.2" xref="S3.E3.m1.5.5.1.1.3.3.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝐪</mi><mo stretchy="false" id="S3.E3.m1.5.5.1.1.3.3.2.3" xref="S3.E3.m1.5.5.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.5.5.1.1.2" xref="S3.E3.m1.5.5.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.5.5.1.1.1" xref="S3.E3.m1.5.5.1.1.1.cmml"><mfrac id="S3.E3.m1.5.5.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.3.cmml"><mn id="S3.E3.m1.5.5.1.1.1.3.2" xref="S3.E3.m1.5.5.1.1.1.3.2.cmml">1</mn><mi id="S3.E3.m1.5.5.1.1.1.3.3" xref="S3.E3.m1.5.5.1.1.1.3.3.cmml">m</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.2.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.cmml"><munder id="S3.E3.m1.5.5.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.2.2.cmml">∑</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.2.3" xref="S3.E3.m1.5.5.1.1.1.1.2.3.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.2.3.2" xref="S3.E3.m1.5.5.1.1.1.1.2.3.2.cmml">x</mi><mo id="S3.E3.m1.5.5.1.1.1.1.2.3.1" xref="S3.E3.m1.5.5.1.1.1.1.2.3.1.cmml">∈</mo><mi id="S3.E3.m1.5.5.1.1.1.1.2.3.3" xref="S3.E3.m1.5.5.1.1.1.1.2.3.3.cmml">M</mi></mrow></munder><msup id="S3.E3.m1.5.5.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E3.m1.3.3.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.3.2.1" xref="S3.E3.m1.3.3.cmml">(</mo><mover accent="true" id="S3.E3.m1.3.3" xref="S3.E3.m1.3.3.cmml"><mi id="S3.E3.m1.3.3.2" xref="S3.E3.m1.3.3.2.cmml">𝐪</mi><mo id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.cmml">~</mo></mover><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S3.E3.m1.3.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1a" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.4" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.4.cmml">x</mi></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mover accent="true" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">𝐭</mi><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.cmml">−</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.cmml">(</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.cmml"><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.cmml"><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.2" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">​</mo><mrow id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.3.2" xref="S3.E3.m1.4.4a.cmml"><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.3.2.1" xref="S3.E3.m1.4.4a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml">q</mtext><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.3.2.2" xref="S3.E3.m1.4.4a.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.1a" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml">​</mo><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.4" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.4.cmml">x</mi></mrow><mo id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.1" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.1.cmml">+</mo><mi id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.3.cmml">𝐭</mi></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E3.m1.5.5.1.1.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E3.m1.5.5.1.1.1.1.1.3" xref="S3.E3.m1.5.5.1.1.1.1.1.3.cmml">2</mn></msup></mrow></mrow></mrow><mo id="S3.E3.m1.5.5.1.2" xref="S3.E3.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.5b"><apply id="S3.E3.m1.5.5.1.1.cmml" xref="S3.E3.m1.5.5.1"><eq id="S3.E3.m1.5.5.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.2"></eq><apply id="S3.E3.m1.5.5.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.3"><times id="S3.E3.m1.5.5.1.1.3.1.cmml" xref="S3.E3.m1.5.5.1.1.3.1"></times><apply id="S3.E3.m1.5.5.1.1.3.2.cmml" xref="S3.E3.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.3.2.1.cmml" xref="S3.E3.m1.5.5.1.1.3.2">subscript</csymbol><ci id="S3.E3.m1.5.5.1.1.3.2.2.cmml" xref="S3.E3.m1.5.5.1.1.3.2.2">𝐿</ci><ci id="S3.E3.m1.5.5.1.1.3.2.3a.cmml" xref="S3.E3.m1.5.5.1.1.3.2.3"><mtext mathsize="70%" id="S3.E3.m1.5.5.1.1.3.2.3.cmml" xref="S3.E3.m1.5.5.1.1.3.2.3">pose</mtext></ci></apply><interval closure="open" id="S3.E3.m1.5.5.1.1.3.3.1.cmml" xref="S3.E3.m1.5.5.1.1.3.3.2"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><ci id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1">~</ci><ci id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2">𝐪</ci></apply><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝐪</ci></interval></apply><apply id="S3.E3.m1.5.5.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1"><times id="S3.E3.m1.5.5.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.2"></times><apply id="S3.E3.m1.5.5.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.3"><divide id="S3.E3.m1.5.5.1.1.1.3.1.cmml" xref="S3.E3.m1.5.5.1.1.1.3"></divide><cn type="integer" id="S3.E3.m1.5.5.1.1.1.3.2.cmml" xref="S3.E3.m1.5.5.1.1.1.3.2">1</cn><ci id="S3.E3.m1.5.5.1.1.1.3.3.cmml" xref="S3.E3.m1.5.5.1.1.1.3.3">𝑚</ci></apply><apply id="S3.E3.m1.5.5.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1"><apply id="S3.E3.m1.5.5.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.5.5.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2.2"></sum><apply id="S3.E3.m1.5.5.1.1.1.1.2.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2.3"><in id="S3.E3.m1.5.5.1.1.1.1.2.3.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2.3.1"></in><ci id="S3.E3.m1.5.5.1.1.1.1.2.3.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2.3.2">𝑥</ci><ci id="S3.E3.m1.5.5.1.1.1.1.2.3.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.2.3.3">𝑀</ci></apply></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.5.5.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.5.5.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1"><minus id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.3"></minus><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1"><plus id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.2">𝑅</ci><apply id="S3.E3.m1.3.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.3.2"><ci id="S3.E3.m1.3.3.1.cmml" xref="S3.E3.m1.3.3.1">~</ci><ci id="S3.E3.m1.3.3.2.cmml" xref="S3.E3.m1.3.3.2">𝐪</ci></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.4">𝑥</ci></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3"><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.1">~</ci><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.2">𝐭</ci></apply></apply><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1"><plus id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.1"></plus><apply id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2"><times id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.1.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.1"></times><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.2.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.2">𝑅</ci><ci id="S3.E3.m1.4.4a.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4">q</mtext></ci><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.4.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.2.4">𝑥</ci></apply><ci id="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.1.1.1.2.1.1.3">𝐭</ci></apply></apply></apply><cn type="integer" id="S3.E3.m1.5.5.1.1.1.1.1.3.cmml" xref="S3.E3.m1.5.5.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.5c">L_{\text{pose}}(\mathbf{\widetilde{q}},\mathbf{q})=\frac{1}{m}\sum\limits_{x\in M}||(R(\mathbf{\widetilde{q}})x+\mathbf{\widetilde{t}})-(R(\textbf{q})x+\mathbf{t})||^{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.8" class="ltx_p">where <math id="S3.SS4.p1.5.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS4.p1.5.m1.1a"><mi id="S3.SS4.p1.5.m1.1.1" xref="S3.SS4.p1.5.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m1.1b"><ci id="S3.SS4.p1.5.m1.1.1.cmml" xref="S3.SS4.p1.5.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m1.1c">M</annotation></semantics></math> denotes the set of 3D points, <math id="S3.SS4.p1.6.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS4.p1.6.m2.1a"><mi id="S3.SS4.p1.6.m2.1.1" xref="S3.SS4.p1.6.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.6.m2.1b"><ci id="S3.SS4.p1.6.m2.1.1.cmml" xref="S3.SS4.p1.6.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.6.m2.1c">m</annotation></semantics></math> is total number of points. <math id="S3.SS4.p1.7.m3.1" class="ltx_Math" alttext="R(\mathbf{\widetilde{q}})" display="inline"><semantics id="S3.SS4.p1.7.m3.1a"><mrow id="S3.SS4.p1.7.m3.1.2" xref="S3.SS4.p1.7.m3.1.2.cmml"><mi id="S3.SS4.p1.7.m3.1.2.2" xref="S3.SS4.p1.7.m3.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.7.m3.1.2.1" xref="S3.SS4.p1.7.m3.1.2.1.cmml">​</mo><mrow id="S3.SS4.p1.7.m3.1.2.3.2" xref="S3.SS4.p1.7.m3.1.1.cmml"><mo stretchy="false" id="S3.SS4.p1.7.m3.1.2.3.2.1" xref="S3.SS4.p1.7.m3.1.1.cmml">(</mo><mover accent="true" id="S3.SS4.p1.7.m3.1.1" xref="S3.SS4.p1.7.m3.1.1.cmml"><mi id="S3.SS4.p1.7.m3.1.1.2" xref="S3.SS4.p1.7.m3.1.1.2.cmml">𝐪</mi><mo id="S3.SS4.p1.7.m3.1.1.1" xref="S3.SS4.p1.7.m3.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.SS4.p1.7.m3.1.2.3.2.2" xref="S3.SS4.p1.7.m3.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.7.m3.1b"><apply id="S3.SS4.p1.7.m3.1.2.cmml" xref="S3.SS4.p1.7.m3.1.2"><times id="S3.SS4.p1.7.m3.1.2.1.cmml" xref="S3.SS4.p1.7.m3.1.2.1"></times><ci id="S3.SS4.p1.7.m3.1.2.2.cmml" xref="S3.SS4.p1.7.m3.1.2.2">𝑅</ci><apply id="S3.SS4.p1.7.m3.1.1.cmml" xref="S3.SS4.p1.7.m3.1.2.3.2"><ci id="S3.SS4.p1.7.m3.1.1.1.cmml" xref="S3.SS4.p1.7.m3.1.1.1">~</ci><ci id="S3.SS4.p1.7.m3.1.1.2.cmml" xref="S3.SS4.p1.7.m3.1.1.2">𝐪</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.7.m3.1c">R(\mathbf{\widetilde{q}})</annotation></semantics></math> and <math id="S3.SS4.p1.8.m4.1" class="ltx_Math" alttext="R(\mathbf{q})" display="inline"><semantics id="S3.SS4.p1.8.m4.1a"><mrow id="S3.SS4.p1.8.m4.1.2" xref="S3.SS4.p1.8.m4.1.2.cmml"><mi id="S3.SS4.p1.8.m4.1.2.2" xref="S3.SS4.p1.8.m4.1.2.2.cmml">R</mi><mo lspace="0em" rspace="0em" id="S3.SS4.p1.8.m4.1.2.1" xref="S3.SS4.p1.8.m4.1.2.1.cmml">​</mo><mrow id="S3.SS4.p1.8.m4.1.2.3.2" xref="S3.SS4.p1.8.m4.1.2.cmml"><mo stretchy="false" id="S3.SS4.p1.8.m4.1.2.3.2.1" xref="S3.SS4.p1.8.m4.1.2.cmml">(</mo><mi id="S3.SS4.p1.8.m4.1.1" xref="S3.SS4.p1.8.m4.1.1.cmml">𝐪</mi><mo stretchy="false" id="S3.SS4.p1.8.m4.1.2.3.2.2" xref="S3.SS4.p1.8.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.8.m4.1b"><apply id="S3.SS4.p1.8.m4.1.2.cmml" xref="S3.SS4.p1.8.m4.1.2"><times id="S3.SS4.p1.8.m4.1.2.1.cmml" xref="S3.SS4.p1.8.m4.1.2.1"></times><ci id="S3.SS4.p1.8.m4.1.2.2.cmml" xref="S3.SS4.p1.8.m4.1.2.2">𝑅</ci><ci id="S3.SS4.p1.8.m4.1.1.cmml" xref="S3.SS4.p1.8.m4.1.1">𝐪</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.8.m4.1c">R(\mathbf{q})</annotation></semantics></math> indicate the rotation matrix computed from the quaternion representation as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>.
In addition, we also add a cosine loss on the quaternions, and regularisation loss to force the norm of the quaternion to be 1. Quaternions that represent rotations are unit norm, and forcing the norm to be bounded by 1 helps in the learning process by reducing the scope.</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.4" class="ltx_Math" alttext="L_{\text{reg}}=||1-\text{norm}(\mathbf{\widetilde{q}})||,~{}~{}~{}L_{\text{inner\_prod}}=1-\langle\mathbf{\widetilde{q}},\textbf{q}\rangle." display="block"><semantics id="S3.E4.m1.4a"><mrow id="S3.E4.m1.4.4.1"><mrow id="S3.E4.m1.4.4.1.1.2" xref="S3.E4.m1.4.4.1.1.3.cmml"><mrow id="S3.E4.m1.4.4.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.cmml"><msub id="S3.E4.m1.4.4.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.3.cmml"><mi id="S3.E4.m1.4.4.1.1.1.1.3.2" xref="S3.E4.m1.4.4.1.1.1.1.3.2.cmml">L</mi><mtext id="S3.E4.m1.4.4.1.1.1.1.3.3" xref="S3.E4.m1.4.4.1.1.1.1.3.3a.cmml">reg</mtext></msub><mo id="S3.E4.m1.4.4.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.2.cmml">=</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.cmml"><mn id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.cmml"><mtext id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.2a.cmml">norm</mtext><mo lspace="0em" rspace="0em" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.1.cmml">​</mo><mrow id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.3.2" xref="S3.E4.m1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.3.2.1" xref="S3.E4.m1.1.1.cmml">(</mo><mover accent="true" id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><mi id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml">𝐪</mi><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.3.2.2" xref="S3.E4.m1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E4.m1.4.4.1.1.1.1.1.1.3" xref="S3.E4.m1.4.4.1.1.1.1.1.2.1.cmml">‖</mo></mrow></mrow><mo rspace="1.157em" id="S3.E4.m1.4.4.1.1.2.3" xref="S3.E4.m1.4.4.1.1.3a.cmml">,</mo><mrow id="S3.E4.m1.4.4.1.1.2.2" xref="S3.E4.m1.4.4.1.1.2.2.cmml"><msub id="S3.E4.m1.4.4.1.1.2.2.2" xref="S3.E4.m1.4.4.1.1.2.2.2.cmml"><mi id="S3.E4.m1.4.4.1.1.2.2.2.2" xref="S3.E4.m1.4.4.1.1.2.2.2.2.cmml">L</mi><mtext id="S3.E4.m1.4.4.1.1.2.2.2.3" xref="S3.E4.m1.4.4.1.1.2.2.2.3a.cmml">inner_prod</mtext></msub><mo id="S3.E4.m1.4.4.1.1.2.2.1" xref="S3.E4.m1.4.4.1.1.2.2.1.cmml">=</mo><mrow id="S3.E4.m1.4.4.1.1.2.2.3" xref="S3.E4.m1.4.4.1.1.2.2.3.cmml"><mn id="S3.E4.m1.4.4.1.1.2.2.3.2" xref="S3.E4.m1.4.4.1.1.2.2.3.2.cmml">1</mn><mo id="S3.E4.m1.4.4.1.1.2.2.3.1" xref="S3.E4.m1.4.4.1.1.2.2.3.1.cmml">−</mo><mrow id="S3.E4.m1.4.4.1.1.2.2.3.3.2" xref="S3.E4.m1.4.4.1.1.2.2.3.3.1.cmml"><mo stretchy="false" id="S3.E4.m1.4.4.1.1.2.2.3.3.2.1" xref="S3.E4.m1.4.4.1.1.2.2.3.3.1.cmml">⟨</mo><mover accent="true" id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml"><mi id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml">𝐪</mi><mo id="S3.E4.m1.2.2.1" xref="S3.E4.m1.2.2.1.cmml">~</mo></mover><mo id="S3.E4.m1.4.4.1.1.2.2.3.3.2.2" xref="S3.E4.m1.4.4.1.1.2.2.3.3.1.cmml">,</mo><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3a.cmml">q</mtext><mo stretchy="false" id="S3.E4.m1.4.4.1.1.2.2.3.3.2.3" xref="S3.E4.m1.4.4.1.1.2.2.3.3.1.cmml">⟩</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E4.m1.4.4.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.4b"><apply id="S3.E4.m1.4.4.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.3a.cmml" xref="S3.E4.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E4.m1.4.4.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1"><eq id="S3.E4.m1.4.4.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.2"></eq><apply id="S3.E4.m1.4.4.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.2">𝐿</ci><ci id="S3.E4.m1.4.4.1.1.1.1.3.3a.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.3"><mtext mathsize="70%" id="S3.E4.m1.4.4.1.1.1.1.3.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.3.3">reg</mtext></ci></apply><apply id="S3.E4.m1.4.4.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1"><minus id="S3.E4.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S3.E4.m1.4.4.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.2">1</cn><apply id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3"><times id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.2a.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.2"><mtext id="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.2">norm</mtext></ci><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.4.4.1.1.1.1.1.1.1.3.3.2"><ci id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1">~</ci><ci id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2">𝐪</ci></apply></apply></apply></apply></apply><apply id="S3.E4.m1.4.4.1.1.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2"><eq id="S3.E4.m1.4.4.1.1.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.2.2.1"></eq><apply id="S3.E4.m1.4.4.1.1.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.4.4.1.1.2.2.2.1.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2">subscript</csymbol><ci id="S3.E4.m1.4.4.1.1.2.2.2.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2.2">𝐿</ci><ci id="S3.E4.m1.4.4.1.1.2.2.2.3a.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2.3"><mtext mathsize="70%" id="S3.E4.m1.4.4.1.1.2.2.2.3.cmml" xref="S3.E4.m1.4.4.1.1.2.2.2.3">inner_prod</mtext></ci></apply><apply id="S3.E4.m1.4.4.1.1.2.2.3.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3"><minus id="S3.E4.m1.4.4.1.1.2.2.3.1.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.1"></minus><cn type="integer" id="S3.E4.m1.4.4.1.1.2.2.3.2.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.2">1</cn><list id="S3.E4.m1.4.4.1.1.2.2.3.3.1.cmml" xref="S3.E4.m1.4.4.1.1.2.2.3.3.2"><apply id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2"><ci id="S3.E4.m1.2.2.1.cmml" xref="S3.E4.m1.2.2.1">~</ci><ci id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2">𝐪</ci></apply><ci id="S3.E4.m1.3.3a.cmml" xref="S3.E4.m1.3.3"><mtext class="ltx_mathvariant_bold" id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3">q</mtext></ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.4c">L_{\text{reg}}=||1-\text{norm}(\mathbf{\widetilde{q}})||,~{}~{}~{}L_{\text{inner\_prod}}=1-\langle\mathbf{\widetilde{q}},\textbf{q}\rangle.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.p1.9" class="ltx_p">The total loss can be defined as</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.5" class="ltx_Math" alttext="L(\mathbf{\widetilde{q}},\mathbf{q},\mathbf{\widetilde{t}},\mathbf{t})=L_{\text{depth}}+L_{\text{label}}+L_{\text{pose}}+L_{\text{reg}}+L_{\text{inner\_prod}}." display="block"><semantics id="S3.E5.m1.5a"><mrow id="S3.E5.m1.5.5.1" xref="S3.E5.m1.5.5.1.1.cmml"><mrow id="S3.E5.m1.5.5.1.1" xref="S3.E5.m1.5.5.1.1.cmml"><mrow id="S3.E5.m1.5.5.1.1.2" xref="S3.E5.m1.5.5.1.1.2.cmml"><mi id="S3.E5.m1.5.5.1.1.2.2" xref="S3.E5.m1.5.5.1.1.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.5.5.1.1.2.1" xref="S3.E5.m1.5.5.1.1.2.1.cmml">​</mo><mrow id="S3.E5.m1.5.5.1.1.2.3.2" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml"><mo stretchy="false" id="S3.E5.m1.5.5.1.1.2.3.2.1" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">(</mo><mover accent="true" id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml"><mi id="S3.E5.m1.1.1.2" xref="S3.E5.m1.1.1.2.cmml">𝐪</mi><mo id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.cmml">~</mo></mover><mo id="S3.E5.m1.5.5.1.1.2.3.2.2" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">,</mo><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">𝐪</mi><mo id="S3.E5.m1.5.5.1.1.2.3.2.3" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">,</mo><mover accent="true" id="S3.E5.m1.3.3" xref="S3.E5.m1.3.3.cmml"><mi id="S3.E5.m1.3.3.2" xref="S3.E5.m1.3.3.2.cmml">𝐭</mi><mo id="S3.E5.m1.3.3.1" xref="S3.E5.m1.3.3.1.cmml">~</mo></mover><mo id="S3.E5.m1.5.5.1.1.2.3.2.4" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">,</mo><mi id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml">𝐭</mi><mo stretchy="false" id="S3.E5.m1.5.5.1.1.2.3.2.5" xref="S3.E5.m1.5.5.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.5.5.1.1.1" xref="S3.E5.m1.5.5.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.5.5.1.1.3" xref="S3.E5.m1.5.5.1.1.3.cmml"><msub id="S3.E5.m1.5.5.1.1.3.2" xref="S3.E5.m1.5.5.1.1.3.2.cmml"><mi id="S3.E5.m1.5.5.1.1.3.2.2" xref="S3.E5.m1.5.5.1.1.3.2.2.cmml">L</mi><mtext id="S3.E5.m1.5.5.1.1.3.2.3" xref="S3.E5.m1.5.5.1.1.3.2.3a.cmml">depth</mtext></msub><mo id="S3.E5.m1.5.5.1.1.3.1" xref="S3.E5.m1.5.5.1.1.3.1.cmml">+</mo><msub id="S3.E5.m1.5.5.1.1.3.3" xref="S3.E5.m1.5.5.1.1.3.3.cmml"><mi id="S3.E5.m1.5.5.1.1.3.3.2" xref="S3.E5.m1.5.5.1.1.3.3.2.cmml">L</mi><mtext id="S3.E5.m1.5.5.1.1.3.3.3" xref="S3.E5.m1.5.5.1.1.3.3.3a.cmml">label</mtext></msub><mo id="S3.E5.m1.5.5.1.1.3.1a" xref="S3.E5.m1.5.5.1.1.3.1.cmml">+</mo><msub id="S3.E5.m1.5.5.1.1.3.4" xref="S3.E5.m1.5.5.1.1.3.4.cmml"><mi id="S3.E5.m1.5.5.1.1.3.4.2" xref="S3.E5.m1.5.5.1.1.3.4.2.cmml">L</mi><mtext id="S3.E5.m1.5.5.1.1.3.4.3" xref="S3.E5.m1.5.5.1.1.3.4.3a.cmml">pose</mtext></msub><mo id="S3.E5.m1.5.5.1.1.3.1b" xref="S3.E5.m1.5.5.1.1.3.1.cmml">+</mo><msub id="S3.E5.m1.5.5.1.1.3.5" xref="S3.E5.m1.5.5.1.1.3.5.cmml"><mi id="S3.E5.m1.5.5.1.1.3.5.2" xref="S3.E5.m1.5.5.1.1.3.5.2.cmml">L</mi><mtext id="S3.E5.m1.5.5.1.1.3.5.3" xref="S3.E5.m1.5.5.1.1.3.5.3a.cmml">reg</mtext></msub><mo id="S3.E5.m1.5.5.1.1.3.1c" xref="S3.E5.m1.5.5.1.1.3.1.cmml">+</mo><msub id="S3.E5.m1.5.5.1.1.3.6" xref="S3.E5.m1.5.5.1.1.3.6.cmml"><mi id="S3.E5.m1.5.5.1.1.3.6.2" xref="S3.E5.m1.5.5.1.1.3.6.2.cmml">L</mi><mtext id="S3.E5.m1.5.5.1.1.3.6.3" xref="S3.E5.m1.5.5.1.1.3.6.3a.cmml">inner_prod</mtext></msub></mrow></mrow><mo lspace="0em" id="S3.E5.m1.5.5.1.2" xref="S3.E5.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.5b"><apply id="S3.E5.m1.5.5.1.1.cmml" xref="S3.E5.m1.5.5.1"><eq id="S3.E5.m1.5.5.1.1.1.cmml" xref="S3.E5.m1.5.5.1.1.1"></eq><apply id="S3.E5.m1.5.5.1.1.2.cmml" xref="S3.E5.m1.5.5.1.1.2"><times id="S3.E5.m1.5.5.1.1.2.1.cmml" xref="S3.E5.m1.5.5.1.1.2.1"></times><ci id="S3.E5.m1.5.5.1.1.2.2.cmml" xref="S3.E5.m1.5.5.1.1.2.2">𝐿</ci><vector id="S3.E5.m1.5.5.1.1.2.3.1.cmml" xref="S3.E5.m1.5.5.1.1.2.3.2"><apply id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1"><ci id="S3.E5.m1.1.1.1.cmml" xref="S3.E5.m1.1.1.1">~</ci><ci id="S3.E5.m1.1.1.2.cmml" xref="S3.E5.m1.1.1.2">𝐪</ci></apply><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">𝐪</ci><apply id="S3.E5.m1.3.3.cmml" xref="S3.E5.m1.3.3"><ci id="S3.E5.m1.3.3.1.cmml" xref="S3.E5.m1.3.3.1">~</ci><ci id="S3.E5.m1.3.3.2.cmml" xref="S3.E5.m1.3.3.2">𝐭</ci></apply><ci id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4">𝐭</ci></vector></apply><apply id="S3.E5.m1.5.5.1.1.3.cmml" xref="S3.E5.m1.5.5.1.1.3"><plus id="S3.E5.m1.5.5.1.1.3.1.cmml" xref="S3.E5.m1.5.5.1.1.3.1"></plus><apply id="S3.E5.m1.5.5.1.1.3.2.cmml" xref="S3.E5.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.2.1.cmml" xref="S3.E5.m1.5.5.1.1.3.2">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.3.2.2.cmml" xref="S3.E5.m1.5.5.1.1.3.2.2">𝐿</ci><ci id="S3.E5.m1.5.5.1.1.3.2.3a.cmml" xref="S3.E5.m1.5.5.1.1.3.2.3"><mtext mathsize="70%" id="S3.E5.m1.5.5.1.1.3.2.3.cmml" xref="S3.E5.m1.5.5.1.1.3.2.3">depth</mtext></ci></apply><apply id="S3.E5.m1.5.5.1.1.3.3.cmml" xref="S3.E5.m1.5.5.1.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.3.1.cmml" xref="S3.E5.m1.5.5.1.1.3.3">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.3.3.2.cmml" xref="S3.E5.m1.5.5.1.1.3.3.2">𝐿</ci><ci id="S3.E5.m1.5.5.1.1.3.3.3a.cmml" xref="S3.E5.m1.5.5.1.1.3.3.3"><mtext mathsize="70%" id="S3.E5.m1.5.5.1.1.3.3.3.cmml" xref="S3.E5.m1.5.5.1.1.3.3.3">label</mtext></ci></apply><apply id="S3.E5.m1.5.5.1.1.3.4.cmml" xref="S3.E5.m1.5.5.1.1.3.4"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.4.1.cmml" xref="S3.E5.m1.5.5.1.1.3.4">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.3.4.2.cmml" xref="S3.E5.m1.5.5.1.1.3.4.2">𝐿</ci><ci id="S3.E5.m1.5.5.1.1.3.4.3a.cmml" xref="S3.E5.m1.5.5.1.1.3.4.3"><mtext mathsize="70%" id="S3.E5.m1.5.5.1.1.3.4.3.cmml" xref="S3.E5.m1.5.5.1.1.3.4.3">pose</mtext></ci></apply><apply id="S3.E5.m1.5.5.1.1.3.5.cmml" xref="S3.E5.m1.5.5.1.1.3.5"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.5.1.cmml" xref="S3.E5.m1.5.5.1.1.3.5">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.3.5.2.cmml" xref="S3.E5.m1.5.5.1.1.3.5.2">𝐿</ci><ci id="S3.E5.m1.5.5.1.1.3.5.3a.cmml" xref="S3.E5.m1.5.5.1.1.3.5.3"><mtext mathsize="70%" id="S3.E5.m1.5.5.1.1.3.5.3.cmml" xref="S3.E5.m1.5.5.1.1.3.5.3">reg</mtext></ci></apply><apply id="S3.E5.m1.5.5.1.1.3.6.cmml" xref="S3.E5.m1.5.5.1.1.3.6"><csymbol cd="ambiguous" id="S3.E5.m1.5.5.1.1.3.6.1.cmml" xref="S3.E5.m1.5.5.1.1.3.6">subscript</csymbol><ci id="S3.E5.m1.5.5.1.1.3.6.2.cmml" xref="S3.E5.m1.5.5.1.1.3.6.2">𝐿</ci><ci id="S3.E5.m1.5.5.1.1.3.6.3a.cmml" xref="S3.E5.m1.5.5.1.1.3.6.3"><mtext mathsize="70%" id="S3.E5.m1.5.5.1.1.3.6.3.cmml" xref="S3.E5.m1.5.5.1.1.3.6.3">inner_prod</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.5c">L(\mathbf{\widetilde{q}},\mathbf{q},\mathbf{\widetilde{t}},\mathbf{t})=L_{\text{depth}}+L_{\text{label}}+L_{\text{pose}}+L_{\text{reg}}+L_{\text{inner\_prod}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Now we compare our method with PoseCNN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> and PoseRBPF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. We also conduct ablation studies on the choice of model architecture, and the number of video frames the model requires to perform well.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluate the proposed method on the YCB-Video dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Details of which are explained in sec <a href="#S4.SS3" title="4.3 Implementation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>. <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">The YCB-Video Dataset</span> contains 92 RGB-D video sequences of 21 objects. The dataset contains textured and textureless objects of varying shape, and different levels of occlusion where about <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="15\%" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">15</mn><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">15\%</annotation></semantics></math> of objects are heavily occluded. Objects are annotated with 6D poses, segmentation masks and depth images. For our purposes, We create smaller video sequences of 10 RGB images by taking every alternate frame from the video. 
<br class="ltx_break"></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Metrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.3" class="ltx_p">We use two metrics to report on the YCB-Dataset. ADD is the average distance between the corresponding points on the 3D object at the ground truth and predicted poses. Given the estimated <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="[\mathbf{\widetilde{R}}|\mathbf{\widetilde{t}}]" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p1.1.m1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">[</mo><mrow id="S4.SS2.p1.1.m1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.cmml"><mover accent="true" id="S4.SS2.p1.1.m1.1.1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.1.1.2.cmml"><mi id="S4.SS2.p1.1.m1.1.1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.1.1.2.2.cmml">𝐑</mi><mo id="S4.SS2.p1.1.m1.1.1.1.1.2.1" xref="S4.SS2.p1.1.m1.1.1.1.1.2.1.cmml">~</mo></mover><mo fence="false" id="S4.SS2.p1.1.m1.1.1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.1.1.cmml">|</mo><mover accent="true" id="S4.SS2.p1.1.m1.1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.1.1.3.cmml"><mi id="S4.SS2.p1.1.m1.1.1.1.1.3.2" xref="S4.SS2.p1.1.m1.1.1.1.1.3.2.cmml">𝐭</mi><mo id="S4.SS2.p1.1.m1.1.1.1.1.3.1" xref="S4.SS2.p1.1.m1.1.1.1.1.3.1.cmml">~</mo></mover></mrow><mo stretchy="false" id="S4.SS2.p1.1.m1.1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="S4.SS2.p1.1.m1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.1">conditional</csymbol><apply id="S4.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.2"><ci id="S4.SS2.p1.1.m1.1.1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.2.1">~</ci><ci id="S4.SS2.p1.1.m1.1.1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.2.2">𝐑</ci></apply><apply id="S4.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.3"><ci id="S4.SS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.3.1">~</ci><ci id="S4.SS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="S4.SS2.p1.1.m1.1.1.1.1.3.2">𝐭</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">[\mathbf{\widetilde{R}}|\mathbf{\widetilde{t}}]</annotation></semantics></math> and the ground truth poses <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="[\mathbf{R}|\mathbf{t}]" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mrow id="S4.SS2.p1.2.m2.1.1.1" xref="S4.SS2.p1.2.m2.1.1.2.cmml"><mo stretchy="false" id="S4.SS2.p1.2.m2.1.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml">[</mo><mrow id="S4.SS2.p1.2.m2.1.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.1.1.2" xref="S4.SS2.p1.2.m2.1.1.1.1.2.cmml">𝐑</mi><mo fence="false" id="S4.SS2.p1.2.m2.1.1.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.1.1.cmml">|</mo><mi id="S4.SS2.p1.2.m2.1.1.1.1.3" xref="S4.SS2.p1.2.m2.1.1.1.1.3.cmml">𝐭</mi></mrow><mo stretchy="false" id="S4.SS2.p1.2.m2.1.1.1.3" xref="S4.SS2.p1.2.m2.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.2.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.2">delimited-[]</csymbol><apply id="S4.SS2.p1.2.m2.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.1">conditional</csymbol><ci id="S4.SS2.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.2">𝐑</ci><ci id="S4.SS2.p1.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.3">𝐭</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">[\mathbf{R}|\mathbf{t}]</annotation></semantics></math>, ADD-S, designed for symmetric objects, calculates the mean distance from each <math id="S4.SS2.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.SS2.p1.3.m3.1a"><mn id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><cn type="integer" id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">3</annotation></semantics></math>D point to a closest point on the target model.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Implementation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.6" class="ltx_p">VideoPose is implemented using the PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> framework. We use a learning rate of <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="5e^{-4}" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mn id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">​</mo><msup id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml"><mi id="S4.SS3.p1.1.m1.1.1.3.2" xref="S4.SS3.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S4.SS3.p1.1.m1.1.1.3.3" xref="S4.SS3.p1.1.m1.1.1.3.3.cmml"><mo id="S4.SS3.p1.1.m1.1.1.3.3a" xref="S4.SS3.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.SS3.p1.1.m1.1.1.3.3.2" xref="S4.SS3.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><times id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">5</cn><apply id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.3.1.cmml" xref="S4.SS3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.3.2.cmml" xref="S4.SS3.p1.1.m1.1.1.3.2">𝑒</ci><apply id="S4.SS3.p1.1.m1.1.1.3.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3"><minus id="S4.SS3.p1.1.m1.1.1.3.3.1.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.SS3.p1.1.m1.1.1.3.3.2.cmml" xref="S4.SS3.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">5e^{-4}</annotation></semantics></math> and the Adam optimiser <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> with a weight decay of <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="1e^{-5}" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mn id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">​</mo><msup id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml"><mi id="S4.SS3.p1.2.m2.1.1.3.2" xref="S4.SS3.p1.2.m2.1.1.3.2.cmml">e</mi><mrow id="S4.SS3.p1.2.m2.1.1.3.3" xref="S4.SS3.p1.2.m2.1.1.3.3.cmml"><mo id="S4.SS3.p1.2.m2.1.1.3.3a" xref="S4.SS3.p1.2.m2.1.1.3.3.cmml">−</mo><mn id="S4.SS3.p1.2.m2.1.1.3.3.2" xref="S4.SS3.p1.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><times id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">1</cn><apply id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.3">superscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.2">𝑒</ci><apply id="S4.SS3.p1.2.m2.1.1.3.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3"><minus id="S4.SS3.p1.2.m2.1.1.3.3.1.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3"></minus><cn type="integer" id="S4.SS3.p1.2.m2.1.1.3.3.2.cmml" xref="S4.SS3.p1.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">1e^{-5}</annotation></semantics></math>.
Learning rate is multiplied by <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="0.8" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mn id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><cn type="float" id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">0.8</annotation></semantics></math> after every <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mn id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><cn type="integer" id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">5</annotation></semantics></math> epochs, until it hits a lower bound of <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="1e^{-6}" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mrow id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mn id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS3.p1.5.m5.1.1.1" xref="S4.SS3.p1.5.m5.1.1.1.cmml">​</mo><msup id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml"><mi id="S4.SS3.p1.5.m5.1.1.3.2" xref="S4.SS3.p1.5.m5.1.1.3.2.cmml">e</mi><mrow id="S4.SS3.p1.5.m5.1.1.3.3" xref="S4.SS3.p1.5.m5.1.1.3.3.cmml"><mo id="S4.SS3.p1.5.m5.1.1.3.3a" xref="S4.SS3.p1.5.m5.1.1.3.3.cmml">−</mo><mn id="S4.SS3.p1.5.m5.1.1.3.3.2" xref="S4.SS3.p1.5.m5.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><times id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1.1"></times><cn type="integer" id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2">1</cn><apply id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3">superscript</csymbol><ci id="S4.SS3.p1.5.m5.1.1.3.2.cmml" xref="S4.SS3.p1.5.m5.1.1.3.2">𝑒</ci><apply id="S4.SS3.p1.5.m5.1.1.3.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3"><minus id="S4.SS3.p1.5.m5.1.1.3.3.1.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3"></minus><cn type="integer" id="S4.SS3.p1.5.m5.1.1.3.3.2.cmml" xref="S4.SS3.p1.5.m5.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">1e^{-6}</annotation></semantics></math>.
For the feature encoder, we freeze the VGG<math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mn id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><cn type="integer" id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">16</annotation></semantics></math> weights from PoseCNN, and train rest of the network from scratch.
We create video samples of 10 frames and train our model for  100 epochs with the learning schedule described above.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.5" class="ltx_p">During training, we augment the input images with colour-jitter and noise, and for the bounding box, we augment it by extending the height and width randomly between <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">0</cn></annotation-xml></semantics></math> and <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mn id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">10</mn><mo id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">10\%</annotation></semantics></math> of the height and width of the object.
While training the temporal block, we create videos with random time jumps in between. For instance, given a large video sequence, we create video samples <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="1:n:10*n" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mn id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.3.m3.1.1.3" xref="S4.SS3.p2.3.m3.1.1.3.cmml">:</mo><mi id="S4.SS3.p2.3.m3.1.1.4" xref="S4.SS3.p2.3.m3.1.1.4.cmml">n</mi><mo lspace="0.278em" rspace="0.278em" id="S4.SS3.p2.3.m3.1.1.5" xref="S4.SS3.p2.3.m3.1.1.5.cmml">:</mo><mrow id="S4.SS3.p2.3.m3.1.1.6" xref="S4.SS3.p2.3.m3.1.1.6.cmml"><mn id="S4.SS3.p2.3.m3.1.1.6.2" xref="S4.SS3.p2.3.m3.1.1.6.2.cmml">10</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p2.3.m3.1.1.6.1" xref="S4.SS3.p2.3.m3.1.1.6.1.cmml">∗</mo><mi id="S4.SS3.p2.3.m3.1.1.6.3" xref="S4.SS3.p2.3.m3.1.1.6.3.cmml">n</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><and id="S4.SS3.p2.3.m3.1.1a.cmml" xref="S4.SS3.p2.3.m3.1.1"></and><apply id="S4.SS3.p2.3.m3.1.1b.cmml" xref="S4.SS3.p2.3.m3.1.1"><ci id="S4.SS3.p2.3.m3.1.1.3.cmml" xref="S4.SS3.p2.3.m3.1.1.3">:</ci><cn type="integer" id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">1</cn><ci id="S4.SS3.p2.3.m3.1.1.4.cmml" xref="S4.SS3.p2.3.m3.1.1.4">𝑛</ci></apply><apply id="S4.SS3.p2.3.m3.1.1c.cmml" xref="S4.SS3.p2.3.m3.1.1"><ci id="S4.SS3.p2.3.m3.1.1.5.cmml" xref="S4.SS3.p2.3.m3.1.1.5">:</ci><share href="#S4.SS3.p2.3.m3.1.1.4.cmml" id="S4.SS3.p2.3.m3.1.1d.cmml" xref="S4.SS3.p2.3.m3.1.1"></share><apply id="S4.SS3.p2.3.m3.1.1.6.cmml" xref="S4.SS3.p2.3.m3.1.1.6"><times id="S4.SS3.p2.3.m3.1.1.6.1.cmml" xref="S4.SS3.p2.3.m3.1.1.6.1"></times><cn type="integer" id="S4.SS3.p2.3.m3.1.1.6.2.cmml" xref="S4.SS3.p2.3.m3.1.1.6.2">10</cn><ci id="S4.SS3.p2.3.m3.1.1.6.3.cmml" xref="S4.SS3.p2.3.m3.1.1.6.3">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">1:n:10*n</annotation></semantics></math>, where n is a random number between <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mn id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><cn type="integer" id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">1</annotation></semantics></math> and <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mn id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><cn type="integer" id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">10</annotation></semantics></math>, thus forcing the model to account for small and large jumps between consecutive frames.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Evaluation</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.2" class="ltx_p">We compare our results with PoseCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> for single frame prediction and PoseRBPF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> for videos in Table <a href="#S3.T1" title="Table 1 ‣ 3.2 Temporal block ‣ 3 Approach ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We compare two different approaches for computing the ROI: <math id="S4.SS4.p1.1.m1.1" class="ltx_math_unparsed" alttext="1)" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1b"><mn id="S4.SS4.p1.1.m1.1.1">1</mn><mo stretchy="false" id="S4.SS4.p1.1.m1.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">1)</annotation></semantics></math> Using the ground truth; <math id="S4.SS4.p1.2.m2.1" class="ltx_math_unparsed" alttext="2)" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mrow id="S4.SS4.p1.2.m2.1b"><mn id="S4.SS4.p1.2.m2.1.1">2</mn><mo stretchy="false" id="S4.SS4.p1.2.m2.1.2">)</mo></mrow><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">2)</annotation></semantics></math> Using the ROI predicted by PoseCNN. In order to maintain comparable FPS, the PoseRBPF is computed using 50 particles.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">We observe that, VideoPose, when using the bounding boxes from PoseCNN, has a small drop in the accuracy, showing that our method is robust to noises in the ROIs. For objects where our method is not comparable to the sota, we further look into the AUC curves in Fig.  <a href="#S4.F3" title="Figure 3 ‣ 4.4 Evaluation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and note that our method outperforms PoseCNN in rotation for symmetric objects like foam_brick and large_marker, and in translation for scissors and mustard_bottle which are non-symmetric.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F3.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" style="width:248.4pt;">
<img src="/html/2111.10677/assets/plots/006_mustard_bottle.png" id="S4.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="685" height="371" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F3.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_middle" style="width:245.9pt;">
<img src="/html/2111.10677/assets/plots/040_large_marker.png" id="S4.F3.2.g1" class="ltx_graphics ltx_img_landscape" width="685" height="371" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F3.3" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:248.4pt;">
<img src="/html/2111.10677/assets/plots/037_scissors.png" id="S4.F3.3.g1" class="ltx_graphics ltx_img_landscape" width="685" height="371" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S4.F3.4" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:245.9pt;">
<img src="/html/2111.10677/assets/plots/061_foam_brick.png" id="S4.F3.4.g1" class="ltx_graphics ltx_img_landscape" width="685" height="371" alt="Refer to caption">
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>AUC with rotation and translation curves for few objects</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:216.8pt;height:265.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-77.2pt,94.7pt) scale(0.583955591155548,0.583955591155548) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">PoseCNN</th>
<th id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">
<table id="S4.T2.1.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.1.1.1.3.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">VideoPose</td>
</tr>
<tr id="S4.T2.1.1.1.1.3.1.2" class="ltx_tr">
<td id="S4.T2.1.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(ConvGRU)</td>
</tr>
</table>
</th>
<th id="S4.T2.1.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2">
<table id="S4.T2.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T2.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">VideoPose</td>
</tr>
<tr id="S4.T2.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T2.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(baseline)</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.2.1" class="ltx_tr">
<td id="S4.T2.1.1.2.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S4.T2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S4.T2.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
<td id="S4.T2.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S4.T2.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
<td id="S4.T2.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD</td>
<td id="S4.T2.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ADD-S</td>
</tr>
<tr id="S4.T2.1.1.3.2" class="ltx_tr">
<td id="S4.T2.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">002_master_chef_can</td>
<td id="S4.T2.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50.9</td>
<td id="S4.T2.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">84</td>
<td id="S4.T2.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.34</td>
<td id="S4.T2.1.1.3.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.86</td>
<td id="S4.T2.1.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.3.2.6.1" class="ltx_text ltx_font_bold">55.5</span></td>
<td id="S4.T2.1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.3.2.7.1" class="ltx_text ltx_font_bold">85.0</span></td>
</tr>
<tr id="S4.T2.1.1.4.3" class="ltx_tr">
<td id="S4.T2.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">003_cracker_box</td>
<td id="S4.T2.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.4.3.2.1" class="ltx_text ltx_font_bold">51.7</span></td>
<td id="S4.T2.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.4.3.3.1" class="ltx_text ltx_font_bold">76.9</span></td>
<td id="S4.T2.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.51</td>
<td id="S4.T2.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.14</td>
<td id="S4.T2.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10.9</td>
<td id="S4.T2.1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.3</td>
</tr>
<tr id="S4.T2.1.1.5.4" class="ltx_tr">
<td id="S4.T2.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">004_sugar_box</td>
<td id="S4.T2.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.5.4.2.1" class="ltx_text ltx_font_bold">68.6</span></td>
<td id="S4.T2.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.5.4.3.1" class="ltx_text ltx_font_bold">84.3</span></td>
<td id="S4.T2.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.73</td>
<td id="S4.T2.1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.76</td>
<td id="S4.T2.1.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47.1</td>
<td id="S4.T2.1.1.5.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.9</td>
</tr>
<tr id="S4.T2.1.1.6.5" class="ltx_tr">
<td id="S4.T2.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">005_tomato_soup_can</td>
<td id="S4.T2.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66</td>
<td id="S4.T2.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.9</td>
<td id="S4.T2.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.6.5.4.1" class="ltx_text ltx_font_bold">66.99</span></td>
<td id="S4.T2.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.6.5.5.1" class="ltx_text ltx_font_bold">83.49</span></td>
<td id="S4.T2.1.1.6.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.6</td>
<td id="S4.T2.1.1.6.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.3</td>
</tr>
<tr id="S4.T2.1.1.7.6" class="ltx_tr">
<td id="S4.T2.1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">006_mustard_bottle</td>
<td id="S4.T2.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.7.6.2.1" class="ltx_text ltx_font_bold">79.9</span></td>
<td id="S4.T2.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.7.6.3.1" class="ltx_text ltx_font_bold">90.2</span></td>
<td id="S4.T2.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.33</td>
<td id="S4.T2.1.1.7.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">88.96</td>
<td id="S4.T2.1.1.7.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67.9</td>
<td id="S4.T2.1.1.7.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.9</td>
</tr>
<tr id="S4.T2.1.1.8.7" class="ltx_tr">
<td id="S4.T2.1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">007_tuna_fish_can</td>
<td id="S4.T2.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.8.7.2.1" class="ltx_text ltx_font_bold">70.4</span></td>
<td id="S4.T2.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.8.7.3.1" class="ltx_text ltx_font_bold">87.9</span></td>
<td id="S4.T2.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60.58</td>
<td id="S4.T2.1.1.8.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.35</td>
<td id="S4.T2.1.1.8.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.1</td>
<td id="S4.T2.1.1.8.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.3</td>
</tr>
<tr id="S4.T2.1.1.9.8" class="ltx_tr">
<td id="S4.T2.1.1.9.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">008_pudding_box</td>
<td id="S4.T2.1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.9.8.2.1" class="ltx_text ltx_font_bold">62.9</span></td>
<td id="S4.T2.1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.9.8.3.1" class="ltx_text ltx_font_bold">79</span></td>
<td id="S4.T2.1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.56</td>
<td id="S4.T2.1.1.9.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.77</td>
<td id="S4.T2.1.1.9.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.7</td>
<td id="S4.T2.1.1.9.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.6</td>
</tr>
<tr id="S4.T2.1.1.10.9" class="ltx_tr">
<td id="S4.T2.1.1.10.9.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">009_gelatin_box</td>
<td id="S4.T2.1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.2</td>
<td id="S4.T2.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.1</td>
<td id="S4.T2.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.10.9.4.1" class="ltx_text ltx_font_bold">81.06</span></td>
<td id="S4.T2.1.1.10.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.10.9.5.1" class="ltx_text ltx_font_bold">89.32</span></td>
<td id="S4.T2.1.1.10.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76</td>
<td id="S4.T2.1.1.10.9.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.2</td>
</tr>
<tr id="S4.T2.1.1.11.10" class="ltx_tr">
<td id="S4.T2.1.1.11.10.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">010_potted_meat_can</td>
<td id="S4.T2.1.1.11.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.6</td>
<td id="S4.T2.1.1.11.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.5</td>
<td id="S4.T2.1.1.11.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.11.10.4.1" class="ltx_text ltx_font_bold">61.54</span></td>
<td id="S4.T2.1.1.11.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.11.10.5.1" class="ltx_text ltx_font_bold">83.64</span></td>
<td id="S4.T2.1.1.11.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">45.9</td>
<td id="S4.T2.1.1.11.10.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.7</td>
</tr>
<tr id="S4.T2.1.1.12.11" class="ltx_tr">
<td id="S4.T2.1.1.12.11.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">011_banana</td>
<td id="S4.T2.1.1.12.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.12.11.2.1" class="ltx_text ltx_font_bold">72.3</span></td>
<td id="S4.T2.1.1.12.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.12.11.3.1" class="ltx_text ltx_font_bold">85.9</span></td>
<td id="S4.T2.1.1.12.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">22.31</td>
<td id="S4.T2.1.1.12.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.59</td>
<td id="S4.T2.1.1.12.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.6</td>
<td id="S4.T2.1.1.12.11.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">70.7</td>
</tr>
<tr id="S4.T2.1.1.13.12" class="ltx_tr">
<td id="S4.T2.1.1.13.12.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">019_pitcher_base</td>
<td id="S4.T2.1.1.13.12.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52.5</td>
<td id="S4.T2.1.1.13.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">76.8</td>
<td id="S4.T2.1.1.13.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.13.12.4.1" class="ltx_text ltx_font_bold">70.54</span></td>
<td id="S4.T2.1.1.13.12.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.13.12.5.1" class="ltx_text ltx_font_bold">85.92</span></td>
<td id="S4.T2.1.1.13.12.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">60</td>
<td id="S4.T2.1.1.13.12.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">82.5</td>
</tr>
<tr id="S4.T2.1.1.14.13" class="ltx_tr">
<td id="S4.T2.1.1.14.13.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">021_bleach_cleanser</td>
<td id="S4.T2.1.1.14.13.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.14.13.2.1" class="ltx_text ltx_font_bold">50.5</span></td>
<td id="S4.T2.1.1.14.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.14.13.3.1" class="ltx_text ltx_font_bold">71.9</span></td>
<td id="S4.T2.1.1.14.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">46.93</td>
<td id="S4.T2.1.1.14.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.11</td>
<td id="S4.T2.1.1.14.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41</td>
<td id="S4.T2.1.1.14.13.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.9</td>
</tr>
<tr id="S4.T2.1.1.15.14" class="ltx_tr">
<td id="S4.T2.1.1.15.14.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">024_bowl</td>
<td id="S4.T2.1.1.15.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.5</td>
<td id="S4.T2.1.1.15.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.7</td>
<td id="S4.T2.1.1.15.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.15.14.4.1" class="ltx_text ltx_font_bold">12.78</span></td>
<td id="S4.T2.1.1.15.14.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.15.14.5.1" class="ltx_text ltx_font_bold">80.08</span></td>
<td id="S4.T2.1.1.15.14.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.5</td>
<td id="S4.T2.1.1.15.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.2</td>
</tr>
<tr id="S4.T2.1.1.16.15" class="ltx_tr">
<td id="S4.T2.1.1.16.15.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">025_mug</td>
<td id="S4.T2.1.1.16.15.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.7</td>
<td id="S4.T2.1.1.16.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78</td>
<td id="S4.T2.1.1.16.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.16.15.4.1" class="ltx_text ltx_font_bold">67.62</span></td>
<td id="S4.T2.1.1.16.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.16.15.5.1" class="ltx_text ltx_font_bold">88.79</span></td>
<td id="S4.T2.1.1.16.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.3</td>
<td id="S4.T2.1.1.16.15.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.4</td>
</tr>
<tr id="S4.T2.1.1.17.16" class="ltx_tr">
<td id="S4.T2.1.1.17.16.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">035_power_drill</td>
<td id="S4.T2.1.1.17.16.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.17.16.2.1" class="ltx_text ltx_font_bold">55.1</span></td>
<td id="S4.T2.1.1.17.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.17.16.3.1" class="ltx_text ltx_font_bold">75.8</span></td>
<td id="S4.T2.1.1.17.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.99</td>
<td id="S4.T2.1.1.17.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.21</td>
<td id="S4.T2.1.1.17.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">26.4</td>
<td id="S4.T2.1.1.17.16.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.9</td>
</tr>
<tr id="S4.T2.1.1.18.17" class="ltx_tr">
<td id="S4.T2.1.1.18.17.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">036_wood_block</td>
<td id="S4.T2.1.1.18.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.18.17.2.1" class="ltx_text ltx_font_bold">31.8</span></td>
<td id="S4.T2.1.1.18.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.18.17.3.1" class="ltx_text ltx_font_bold">65.8</span></td>
<td id="S4.T2.1.1.18.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S4.T2.1.1.18.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">28.72</td>
<td id="S4.T2.1.1.18.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.00</td>
<td id="S4.T2.1.1.18.17.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">16.30</td>
</tr>
<tr id="S4.T2.1.1.19.18" class="ltx_tr">
<td id="S4.T2.1.1.19.18.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">037_scissors</td>
<td id="S4.T2.1.1.19.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">35.8</td>
<td id="S4.T2.1.1.19.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.2</td>
<td id="S4.T2.1.1.19.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.19.18.4.1" class="ltx_text ltx_font_bold">50.08</span></td>
<td id="S4.T2.1.1.19.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.19.18.5.1" class="ltx_text ltx_font_bold">73.39</span></td>
<td id="S4.T2.1.1.19.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">29.5</td>
<td id="S4.T2.1.1.19.18.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">62.5</td>
</tr>
<tr id="S4.T2.1.1.20.19" class="ltx_tr">
<td id="S4.T2.1.1.20.19.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">040_large_marker</td>
<td id="S4.T2.1.1.20.19.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.20.19.2.1" class="ltx_text ltx_font_bold">58</span></td>
<td id="S4.T2.1.1.20.19.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.20.19.3.1" class="ltx_text ltx_font_bold">71.4</span></td>
<td id="S4.T2.1.1.20.19.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">36.81</td>
<td id="S4.T2.1.1.20.19.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">53.89</td>
<td id="S4.T2.1.1.20.19.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">21.6</td>
<td id="S4.T2.1.1.20.19.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.6</td>
</tr>
<tr id="S4.T2.1.1.21.20" class="ltx_tr">
<td id="S4.T2.1.1.21.20.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">051_large_clamp</td>
<td id="S4.T2.1.1.21.20.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.21.20.2.1" class="ltx_text ltx_font_bold">25</span></td>
<td id="S4.T2.1.1.21.20.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.9</td>
<td id="S4.T2.1.1.21.20.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20.72</td>
<td id="S4.T2.1.1.21.20.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.21.20.5.1" class="ltx_text ltx_font_bold">69.33</span></td>
<td id="S4.T2.1.1.21.20.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">14</td>
<td id="S4.T2.1.1.21.20.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.5</td>
</tr>
<tr id="S4.T2.1.1.22.21" class="ltx_tr">
<td id="S4.T2.1.1.22.21.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">052_extra_large_clamp</td>
<td id="S4.T2.1.1.22.21.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.22.21.2.1" class="ltx_text ltx_font_bold">15.8</span></td>
<td id="S4.T2.1.1.22.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">47</td>
<td id="S4.T2.1.1.22.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.93</td>
<td id="S4.T2.1.1.22.21.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.22.21.5.1" class="ltx_text ltx_font_bold">55.39</span></td>
<td id="S4.T2.1.1.22.21.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.3</td>
<td id="S4.T2.1.1.22.21.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">49.9</td>
</tr>
<tr id="S4.T2.1.1.23.22" class="ltx_tr">
<td id="S4.T2.1.1.23.22.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">061_foam_brick</td>
<td id="S4.T2.1.1.23.22.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.4</td>
<td id="S4.T2.1.1.23.22.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.23.22.3.1" class="ltx_text ltx_font_bold">87.8</span></td>
<td id="S4.T2.1.1.23.22.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.1.23.22.4.1" class="ltx_text ltx_font_bold">44.78</span></td>
<td id="S4.T2.1.1.23.22.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.14</td>
<td id="S4.T2.1.1.23.22.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.1</td>
<td id="S4.T2.1.1.23.22.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.7</td>
</tr>
<tr id="S4.T2.1.1.24.23" class="ltx_tr">
<td id="S4.T2.1.1.24.23.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">ALL</td>
<td id="S4.T2.1.1.24.23.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.1.1.24.23.2.1" class="ltx_text ltx_font_bold">53.7</span></td>
<td id="S4.T2.1.1.24.23.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.1.1.24.23.3.1" class="ltx_text ltx_font_bold">75.9</span></td>
<td id="S4.T2.1.1.24.23.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">44.09</td>
<td id="S4.T2.1.1.24.23.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">73.90</td>
<td id="S4.T2.1.1.24.23.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">39.7</td>
<td id="S4.T2.1.1.24.23.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">71.2</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of performance between different architectures. <span id="S4.T2.3.1" class="ltx_text ltx_font_bold">Bold</span> values represent the best method for a given object.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.T4.1" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:463.9pt;height:28.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-67.3pt,4.1pt) scale(0.775,0.775) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Methods</th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> (50)</th>
<th id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> (200)</th>
<th id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Ours(RNN)</th>
<th id="S4.T4.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Ours(ConvGRU)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.2.1" class="ltx_tr">
<td id="S4.T4.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Time (fps)</td>
<td id="S4.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">5.88</td>
<td id="S4.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">20</td>
<td id="S4.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">5</td>
<td id="S4.T4.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">30</td>
<td id="S4.T4.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">25</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of frame rates for different methods: PoseCNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, PoseRBPF (50 particles) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, PoseRBPF (200 particles) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, VideoPose (baseline) and VideoPose(ConvGRU)</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.T4.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:277.1pt;height:40.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-46.2pt,6.8pt) scale(0.75,0.75) ;">
<table id="S4.T4.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.2.1.1.1" class="ltx_tr">
<th id="S4.T4.2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Methods</th>
<th id="S4.T4.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Position=2</th>
<th id="S4.T4.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Position=5</th>
<th id="S4.T4.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Position=10</th>
<th id="S4.T4.2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Position=15</th>
<th id="S4.T4.2.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Position=19</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.2.1.2.1" class="ltx_tr">
<td id="S4.T4.2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">ADD</td>
<td id="S4.T4.2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.6</td>
<td id="S4.T4.2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.61</td>
<td id="S4.T4.2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">44.08</td>
<td id="S4.T4.2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">41.3457</td>
<td id="S4.T4.2.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.79</td>
</tr>
<tr id="S4.T4.2.1.3.2" class="ltx_tr">
<td id="S4.T4.2.1.3.2.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">ADD-S</td>
<td id="S4.T4.2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">71.77</td>
<td id="S4.T4.2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">71.83</td>
<td id="S4.T4.2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">73.9</td>
<td id="S4.T4.2.1.3.2.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">71.71</td>
<td id="S4.T4.2.1.3.2.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">71.18</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Studying the number of previous frames required for a good estimate. Position refers to the location of the keyframe in a video sequence of 20 frames.</figcaption>
</figure>
<div id="S4.SS4.p3" class="ltx_para ltx_noindent">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text ltx_font_bold">Impact of different temporal blocks</span> We also perform ablation studies on different architectures used to capture the temporality, as shown in Table <a href="#S4.T2" title="Table 2 ‣ 4.4 Evaluation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Instead of the baseline temporal RNN in fig.  <a href="#S2.F2" title="Figure 2 ‣ 2 Related Work ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we use a ConvGRU  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> as the temporal module and observe that it handles the temporal information more effectively. The performance is comparable to or better than PoseCNN and PoseRBPF for more than 50% of the objects.
We treat this ablation study as a proof that using previous estimates can aid in the pose estimation, regardless of the temporal module used.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para ltx_noindent">
<p id="S4.SS4.p4.1" class="ltx_p"><span id="S4.SS4.p4.1.1" class="ltx_text ltx_font_bold">Time efficiency</span> We compare the time efficiency of our model with the baseline models.
The run time for PoseCNN is taken from Wang <em id="S4.SS4.p4.1.2" class="ltx_emph ltx_font_italic">et al. </em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. From Table <a href="#S4.T4" title="Table 4 ‣ 4.4 Evaluation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we see that VideoPose with ConvGRU, is slightly faster than PoseRBPF while providing an increase in the performance. As the baseline temporal RNN is more lightweight than ConvGRUs, we get about 50% increase in the speed compared to PoseRBPF, while maintaining the accuracy. 
<br class="ltx_break"></p>
</div>
<div id="S4.SS4.p5" class="ltx_para ltx_noindent">
<p id="S4.SS4.p5.2" class="ltx_p"><span id="S4.SS4.p5.1.1" class="ltx_text ltx_font_bold">Qualitative Analysis of the <math id="S4.SS4.p5.1.1.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S4.SS4.p5.1.1.m1.1a"><mn id="S4.SS4.p5.1.1.m1.1.1" xref="S4.SS4.p5.1.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.1.1.m1.1b"><cn type="integer" id="S4.SS4.p5.1.1.m1.1.1.cmml" xref="S4.SS4.p5.1.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.1.1.m1.1c">6</annotation></semantics></math>D predictions</span> We show three examples of the predictions by VideoPose, PoseCNN, and ground truth poses in Table <a href="#S4.T5" title="Table 5 ‣ 4.4 Evaluation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> <a href="#S4.T6" title="Table 6 ‣ 4.4 Evaluation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The columns represent the <math id="S4.SS4.p5.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.SS4.p5.2.m1.1a"><mn id="S4.SS4.p5.2.m1.1.1" xref="S4.SS4.p5.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.2.m1.1b"><cn type="integer" id="S4.SS4.p5.2.m1.1.1.cmml" xref="S4.SS4.p5.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.2.m1.1c">2</annotation></semantics></math>D projections of predictions using VideoPose, PoseCNN, and the ground truth poses, and rows specify the time-steps. More results are shown in the supplementary. We notice that the poses between frames are more consistent when estimated through videos as opposed to single images. We also observe that the initial frame estimation is as critical for our approach, as it is for other refinement methods.
<br class="ltx_break"></p>
</div>
<div id="S4.SS4.p6" class="ltx_para ltx_noindent">
<p id="S4.SS4.p6.2" class="ltx_p"><span id="S4.SS4.p6.2.1" class="ltx_text ltx_font_bold">Effect of number of previous frames used</span> Table <a href="#S4.T4" title="Table 4 ‣ 4.4 Evaluation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the effect of number of previous frames used. We see that we get the best performance at position 10, and it reduces a little for later positions. It is worth noting that the model was trained for a video sequence of length 10. So the little performance drop for <math id="S4.SS4.p6.1.m1.1" class="ltx_Math" alttext="15th" display="inline"><semantics id="S4.SS4.p6.1.m1.1a"><mrow id="S4.SS4.p6.1.m1.1.1" xref="S4.SS4.p6.1.m1.1.1.cmml"><mn id="S4.SS4.p6.1.m1.1.1.2" xref="S4.SS4.p6.1.m1.1.1.2.cmml">15</mn><mo lspace="0em" rspace="0em" id="S4.SS4.p6.1.m1.1.1.1" xref="S4.SS4.p6.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p6.1.m1.1.1.3" xref="S4.SS4.p6.1.m1.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p6.1.m1.1.1.1a" xref="S4.SS4.p6.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p6.1.m1.1.1.4" xref="S4.SS4.p6.1.m1.1.1.4.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.1.m1.1b"><apply id="S4.SS4.p6.1.m1.1.1.cmml" xref="S4.SS4.p6.1.m1.1.1"><times id="S4.SS4.p6.1.m1.1.1.1.cmml" xref="S4.SS4.p6.1.m1.1.1.1"></times><cn type="integer" id="S4.SS4.p6.1.m1.1.1.2.cmml" xref="S4.SS4.p6.1.m1.1.1.2">15</cn><ci id="S4.SS4.p6.1.m1.1.1.3.cmml" xref="S4.SS4.p6.1.m1.1.1.3">𝑡</ci><ci id="S4.SS4.p6.1.m1.1.1.4.cmml" xref="S4.SS4.p6.1.m1.1.1.4">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.1.m1.1c">15th</annotation></semantics></math> and <math id="S4.SS4.p6.2.m2.1" class="ltx_Math" alttext="19th" display="inline"><semantics id="S4.SS4.p6.2.m2.1a"><mrow id="S4.SS4.p6.2.m2.1.1" xref="S4.SS4.p6.2.m2.1.1.cmml"><mn id="S4.SS4.p6.2.m2.1.1.2" xref="S4.SS4.p6.2.m2.1.1.2.cmml">19</mn><mo lspace="0em" rspace="0em" id="S4.SS4.p6.2.m2.1.1.1" xref="S4.SS4.p6.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS4.p6.2.m2.1.1.3" xref="S4.SS4.p6.2.m2.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p6.2.m2.1.1.1a" xref="S4.SS4.p6.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS4.p6.2.m2.1.1.4" xref="S4.SS4.p6.2.m2.1.1.4.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p6.2.m2.1b"><apply id="S4.SS4.p6.2.m2.1.1.cmml" xref="S4.SS4.p6.2.m2.1.1"><times id="S4.SS4.p6.2.m2.1.1.1.cmml" xref="S4.SS4.p6.2.m2.1.1.1"></times><cn type="integer" id="S4.SS4.p6.2.m2.1.1.2.cmml" xref="S4.SS4.p6.2.m2.1.1.2">19</cn><ci id="S4.SS4.p6.2.m2.1.1.3.cmml" xref="S4.SS4.p6.2.m2.1.1.3">𝑡</ci><ci id="S4.SS4.p6.2.m2.1.1.4.cmml" xref="S4.SS4.p6.2.m2.1.1.4">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p6.2.m2.1c">19th</annotation></semantics></math> position shows that our model, even when trained for a video sequence of 10, can effectively model longer sequences. This is due to the ablation of the video samples during training as discussed in  <a href="#S4.SS3" title="4.3 Implementation ‣ 4 Experiments ‣ VideoPose: Estimating 6D object pose from videos" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<div id="S4.T5.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:612.4pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.7pt,58.6pt) scale(0.838931090259451,0.838931090259451) ;">
<div id="S4.T5.5.5" class="ltx_inline-block ltx_transformed_outer" style="width:592.2pt;height:729pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T5.5.5.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.5.5.5.6.1" class="ltx_tr">
<th id="S4.T5.5.5.5.6.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T5.5.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">VideoPose                                              PoseCNN                                              GT</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 1</th>
<td id="S4.T5.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_3_0053_000338.png" id="S4.T5.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T5.2.2.2.2" class="ltx_tr">
<th id="S4.T5.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 2</th>
<td id="S4.T5.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_3_0053_000339.png" id="S4.T5.2.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T5.3.3.3.3" class="ltx_tr">
<th id="S4.T5.3.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 3</th>
<td id="S4.T5.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_3_0053_000340.png" id="S4.T5.3.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T5.4.4.4.4" class="ltx_tr">
<th id="S4.T5.4.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 4</th>
<td id="S4.T5.4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_3_0053_000341.png" id="S4.T5.4.4.4.4.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T5.5.5.5.5" class="ltx_tr">
<th id="S4.T5.5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">t = 5</th>
<td id="S4.T5.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_3_0053_000342.png" id="S4.T5.5.5.5.5.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Visualisations of the estimated poses on YCB-Dataset for 3 different. Each row represents results at different time-steps. The columns are VideoPose, PoseCNN and Ground truth visualisations respectively.</figcaption>
</figure>
<figure id="S4.T6" class="ltx_table">
<div id="S4.T6.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:612.4pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.7pt,58.6pt) scale(0.838931090259451,0.838931090259451) ;">
<div id="S4.T6.5.5" class="ltx_inline-block ltx_transformed_outer" style="width:592.2pt;height:729pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="S4.T6.5.5.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.5.5.5.6.1" class="ltx_tr">
<th id="S4.T6.5.5.5.6.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T6.5.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">VideoPose                                              PoseCNN                                              GT</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 1</th>
<td id="S4.T6.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_54_0058_000517.png" id="S4.T6.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T6.2.2.2.2" class="ltx_tr">
<th id="S4.T6.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 2</th>
<td id="S4.T6.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_54_0058_000518.png" id="S4.T6.2.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T6.3.3.3.3" class="ltx_tr">
<th id="S4.T6.3.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 3</th>
<td id="S4.T6.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_54_0058_000519.png" id="S4.T6.3.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T6.4.4.4.4" class="ltx_tr">
<th id="S4.T6.4.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 4</th>
<td id="S4.T6.4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_54_0058_000520.png" id="S4.T6.4.4.4.4.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="S4.T6.5.5.5.5" class="ltx_tr">
<th id="S4.T6.5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">t = 5</th>
<td id="S4.T6.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_54_0058_000522.png" id="S4.T6.5.5.5.5.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Visualisations of the estimated poses on YCB-Dataset. Each row represents results at different time-steps. The columns are VideoPose, PoseCNN and Ground truth visualisations respectively.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.2" class="ltx_p">In this work, we introduce VideoPose, a simple convolutional neural network architecture to estimate object 6D poses from videos. We demonstrate that by using the <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S5.p1.1.m1.1a"><mn id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><cn type="integer" id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">6</annotation></semantics></math>D predictions from the previous frames, we can significantly improve <math id="S5.p1.2.m2.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S5.p1.2.m2.1a"><mn id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><cn type="integer" id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">6</annotation></semantics></math>D predictions in the subsequent frames. We also conduct an extensive ablation study on different design choices of the network, and show that our model is able to learn and utilise the features from previous predictions regardless of the network choices. Finally, the proposed network performs in real-time at 30fps, thereby improving the time efficiency over previous approaches. As a future work, we would like to further improve our architecture with a better temporal module and model the relationship with the camera transformation and the objects. Our method successfully maintains consistency in pose estimation between frames, however, still depends on the initial frame estimation. We would like to investigate further on improving this, while maintaining the computational efficiency. 
<br class="ltx_break"></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Nicolas Ballas, Li Yao, Chris Pal, and Aaron Courville.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Delving deeper into convolutional networks for learning video
representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1511.06432</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Gideon Billings and Matthew Johnson-Roberson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Silhonet: An rgb method for 6d object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Robotics and Automation Letters</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 4(4):3727–3734, 2019.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Eric Brachmann, Alexander Krull, Frank Michel, Stefan Gumhold, Jamie Shotton,
and Carsten Rother.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Learning 6D object pose estimation using 3d object coordinates.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib3.5.3" class="ltx_text" style="font-size:90%;">, pages 536–551.
Springer, 2014.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Multi-view 3D object detection network for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 1907–1915, 2017.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Xinke Deng, Arsalan Mousavian, Yu Xiang, Fei Xia, Timothy Bretl, and Dieter
Fox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Poserbpf: A rao-blackwellized particle filter for 6d object pose
tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Robotics: Science and Systems (RSS)</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Clemens Eppner, Arsalan Mousavian, and Dieter Fox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">A billion ways to grasp: An evaluation of grasp sampling schemes on a
dense, physics-based grasp data set.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1912.05604</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Mask r-cnn.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib7.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib7.5.3" class="ltx_text" style="font-size:90%;">, pages 2961–2969, 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Stefan Hinterstoisser, Cedric Cagniart, Slobodan Ilic, Peter Sturm, Nassir
Navab, Pascal Fua, and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Gradient response maps for real-time detection of textureless
objects.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence
(TPAMI)</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 34(5):876–888, 2011.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Stefan Hinterstoisser, Vincent Lepetit, Slobodan Ilic, Stefan Holzer, Gary
Bradski, Kurt Konolige, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Model based training, detection and pose estimation of texture-less
3d objects in heavily cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Asian Conference on Computer Vision
(ACCV)</span><span id="bib.bib9.5.3" class="ltx_text" style="font-size:90%;">, pages 548–562. Springer, 2012.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Tomás Hodan, Pavel Haluza, Stepán Obdrzálek, Jiri Matas, Manolis
I. A. Lourakis, and Xenophon Zabulis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">T-less: An rgb-d dataset for 6d pose estimation of texture-less
objects.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Winter Conference on Applications of Computer Vision
(WACV)</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, pages 880–888, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,
Tobias Weyand, Marco Andreetto, and Hartwig Adam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">MobileNets: Efficient convolutional neural networks for mobile
vision applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1704.04861</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Yinlin Hu, Joachim Hugonot, Pascal Fua, and Mathieu Salzmann.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Segmentation-driven 6d object pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages 3385–3394, 2019.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Wadim Kehl, Fabian Manhardt, Federico Tombari, Slobodan Ilic, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Ssd-6d: Making rgb-based 3d detection and 6d pose estimation great
again.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. of the IEEE International Conference on Computer Vision
(ICCV)</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, pages 1530–1538, 2017.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Diederik P Kingma and Jimmy Ba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Adam: A method for stochastic optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1412.6980</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Yoshinori Konishi, Kosuke Hattori, and Manabu Hashimoto.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Real-time 6D object pose estimation on CPU.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1811.08588</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Alexander Krull, Eric Brachmann, Frank Michel, Michael Ying Yang, Stefan
Gumhold, and Carsten Rother.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Learning analysis-by-synthesis for 6d pose estimation in rgb-d
images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. of the IEEE International Conference on Computer Vision
(ICCV)</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 954–962, 2015.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Yann Labbé, Justin Carpentier, Mathieu Aubry, and Josef Sivic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Cosypose: Consistent multi-view multi-object 6d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 574–591.
Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Chi Li, Jin Bai, and Gregory D Hager.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">A unified framework for multi-view multi-class object pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 254–269, 2018.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Yi Li, Gu Wang, Xiangyang Ji, Yu Xiang, and Dieter Fox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">DeepIm: Deep iterative matching for 6d pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 683–698, 2018.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
Cheng-Yang Fu, and Alexander C Berg.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Ssd: Single shot multibox detector.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European conference on computer vision</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 21–37.
Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Eric Marchand, Hideaki Uchiyama, and Fabien Spindler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Pose estimation for augmented reality: a hands-on survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on visualization and computer graphics</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">,
22(12):2633–2651, 2015.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Markus Oberweger, Mahdi Rad, and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Making deep heatmaps robust to partial occlusions for 3d object pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 119–134, 2018.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Kiru Park, Timothy Patten, and Markus Vincze.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Pix2pose: Pixel-wise coordinate regression of objects for 6d pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib23.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib23.5.3" class="ltx_text" style="font-size:90%;">, pages 7668–7677, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Automatic differentiation in PyTorch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">NIPS Autodiff Workshop</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Pvnet: Pixel-wise voting network for 6dof pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 4561–4570, 2019.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Mahdi Rad and Vincent Lepetit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Bb8: A scalable, accurate, robust to partial occlusion method for
predicting the 3d poses of challenging objects without using depth.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. of the IEEE International Conference on Computer Vision
(ICCV)</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, pages 3848–3856, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Ashutosh Saxena, Justin Driemeyer, and Andrew Y Ng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Robotic grasping of novel objects using vision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The International Journal of Robotics Research (IJRR)</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">,
27(2):157–173, 2008.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Chen Song, Jiaru Song, and Qixing Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Hybridpose: 6d object pose estimation under hybrid representations,
2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Bugra Tekin, Sudipta N Sinha, and Pascal Fua.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Real-time seamless single shot 6d object pose prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 292–301, 2018.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Jonathan Tremblay, Thang To, and Stan Birchfield.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Falling things: A synthetic dataset for 3d object detection and pose
estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition Workshops</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 2038–2041, 2018.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Jonathan Tremblay, Thang To, Balakumar Sundaralingam, Yu Xiang, Dieter Fox, and
Stanley T. Birchfield.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Deep object pose estimation for semantic robotic grasping of
household objects.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Conference on Robot Learning (CoRL)</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Shubham Tulsiani and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Viewpoints and keypoints.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 1510–1519, 2015.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Chen Wang, Danfei Xu, Yuke Zhu, Roberto Martín-Martín, Cewu Lu, Li
Fei-Fei, and Silvio Savarese.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Densefusion: 6d object pose estimation by iterative dense fusion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR)</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
He Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran Song, and
Leonidas J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Normalized object coordinate space for category-level 6d object pose
and size estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 2642–2651, 2019.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Bowen Wen, Chaitanya Mitash, Baozhang Ren, and Kostas E Bekris.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">se (3)-tracknet: Data-driven 6d pose tracking by calibrating image
residuals in synthetic domains.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS)</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 10367–10373. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Yu Xiang, Tanner Schmidt, Venkatraman Narayanan, and Dieter Fox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Posecnn: A convolutional neural network for 6d object pose estimation
in cluttered scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Sergey Zakharov, Ivan Shugurov, and Slobodan Ilic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Dpod: 6d pose object detector and refiner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer
Vision</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages 1941–1950, 2019.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure id="A0.T7" class="ltx_table">
<div id="A0.T7.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:447.2pt;height:551.1pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-72.5pt,89.2pt) scale(0.755032856746605,0.755032856746605) ;">
<div id="A0.T7.5.5" class="ltx_inline-block ltx_transformed_outer" style="width:592.2pt;height:729pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="A0.T7.5.5.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A0.T7.5.5.5.6.1" class="ltx_tr">
<th id="A0.T7.5.5.5.6.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="A0.T7.5.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">VideoPose                                              PoseCNN                                              GT</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A0.T7.1.1.1.1" class="ltx_tr">
<th id="A0.T7.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 1</th>
<td id="A0.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_38_0056_000431.png" id="A0.T7.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T7.2.2.2.2" class="ltx_tr">
<th id="A0.T7.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 2</th>
<td id="A0.T7.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_38_0056_000433.png" id="A0.T7.2.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T7.3.3.3.3" class="ltx_tr">
<th id="A0.T7.3.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 3</th>
<td id="A0.T7.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_38_0056_000435.png" id="A0.T7.3.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T7.4.4.4.4" class="ltx_tr">
<th id="A0.T7.4.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 4</th>
<td id="A0.T7.4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_38_0056_000437.png" id="A0.T7.4.4.4.4.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T7.5.5.5.5" class="ltx_tr">
<th id="A0.T7.5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">t = 5</th>
<td id="A0.T7.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_38_0056_000441.png" id="A0.T7.5.5.5.5.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Visualisations of the estimated poses on YCB-Dataset. Each row represents results at different time-steps. The columns are VideoPose, PoseCNN and Ground truth visualisations respectively.</figcaption>
</figure>
<figure id="A0.T8" class="ltx_table">
<div id="A0.T8.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:612.4pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.7pt,58.6pt) scale(0.838931090259451,0.838931090259451) ;">
<div id="A0.T8.5.5" class="ltx_inline-block ltx_transformed_outer" style="width:592.2pt;height:729pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="A0.T8.5.5.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A0.T8.5.5.5.6.1" class="ltx_tr">
<th id="A0.T8.5.5.5.6.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="A0.T8.5.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">VideoPose                                              PoseCNN                                              GT</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A0.T8.1.1.1.1" class="ltx_tr">
<th id="A0.T8.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 1</th>
<td id="A0.T8.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_60_0052_000423.png" id="A0.T8.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T8.2.2.2.2" class="ltx_tr">
<th id="A0.T8.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 2</th>
<td id="A0.T8.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_60_0052_000424.png" id="A0.T8.2.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T8.3.3.3.3" class="ltx_tr">
<th id="A0.T8.3.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 3</th>
<td id="A0.T8.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_60_0052_000425.png" id="A0.T8.3.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T8.4.4.4.4" class="ltx_tr">
<th id="A0.T8.4.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 4</th>
<td id="A0.T8.4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_60_0052_000426.png" id="A0.T8.4.4.4.4.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T8.5.5.5.5" class="ltx_tr">
<th id="A0.T8.5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">t = 5</th>
<td id="A0.T8.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_60_0052_000427.png" id="A0.T8.5.5.5.5.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Visualisations of the estimated poses on YCB-Dataset. Each row represents results at different time-steps. The columns are VideoPose, PoseCNN and Ground truth visualisations respectively.</figcaption>
</figure>
<figure id="A0.T9" class="ltx_table">
<div id="A0.T9.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:496.9pt;height:612.4pt;vertical-align:-1.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.7pt,58.6pt) scale(0.838931090259451,0.838931090259451) ;">
<div id="A0.T9.5.5" class="ltx_inline-block ltx_transformed_outer" style="width:592.2pt;height:729pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table id="A0.T9.5.5.5" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A0.T9.5.5.5.6.1" class="ltx_tr">
<th id="A0.T9.5.5.5.6.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="A0.T9.5.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">VideoPose                                              PoseCNN                                              GT</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A0.T9.1.1.1.1" class="ltx_tr">
<th id="A0.T9.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 1</th>
<td id="A0.T9.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_14_0051_000814.png" id="A0.T9.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T9.2.2.2.2" class="ltx_tr">
<th id="A0.T9.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 2</th>
<td id="A0.T9.2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_14_0051_000817.png" id="A0.T9.2.2.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T9.3.3.3.3" class="ltx_tr">
<th id="A0.T9.3.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 3</th>
<td id="A0.T9.3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_14_0051_000817.png" id="A0.T9.3.3.3.3.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T9.4.4.4.4" class="ltx_tr">
<th id="A0.T9.4.4.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">t = 4</th>
<td id="A0.T9.4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_14_0051_000819.png" id="A0.T9.4.4.4.4.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
<tr id="A0.T9.5.5.5.5" class="ltx_tr">
<th id="A0.T9.5.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">t = 5</th>
<td id="A0.T9.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><img src="/html/2111.10677/assets/pics/output/keyframe_video_14_0051_000821.png" id="A0.T9.5.5.5.5.1.g1" class="ltx_graphics ltx_img_landscape" width="754" height="189" alt="[Uncaptioned image]"></td>
</tr>
</tbody>
</table>
</span></div>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Visualisations of the estimated poses on YCB-Dataset. Each row represents results at different time-steps. The columns are VideoPose, PoseCNN and Ground truth visualisations respectively.</figcaption>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2111.10676" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2111.10677" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2111.10677">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2111.10677" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2111.10678" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 16:47:29 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
